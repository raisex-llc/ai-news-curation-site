[
  {
    "title": "A faster way to solve complex planning problems",
    "description": "By eliminating redundant computations, a new data-driven method can streamline processes like scheduling trains, routing delivery drivers, or assigning airline crews.",
    "summary": "By eliminating redundant computations, a new data-driven method can streamline processes like scheduling trains, routing delivery drivers, or assigning airline crews.",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/faster-way-solve-complex-planning-problems-0416",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Long-Horizon-01.jpg"
  },
  {
    "title": "Building networks of data science talent",
    "description": "Through collaborations with organizations like BREIT in Peru, the MIT Institute for Data, Systems, and Society is upskilling hundreds of learners around the world in data science and machine learning.",
    "summary": "Through collaborations with organizations like BREIT in Peru, the MIT Institute for Data, Systems, and Society is upskilling hundreds of learners around the world in data science and machine learning.",
    "pubDate": "Tue, 27 May 2025 16:11:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/building-networks-data-science-talent-0527",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-breit-idss-killian.jpg"
  },
  {
    "title": "üêØ Liger GRPO meets TRL",
    "description": "",
    "summary": "üêØ Liger GRPO meets TRL TL; DR Liger supercharges TRL‚Äôs Group Relative Policy Optimization GRPO Train...",
    "pubDate": "Sun, 25 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/liger-grpo",
    "thumbnail": "https://huggingface.co/blog/assets/liger-grpo/thumbnail.png"
  },
  {
    "title": "Groq on Hugging Face Inference Providers üî•",
    "description": "",
    "summary": "Groq on Hugging Face Inference Providers üî• We're thrilled to share that Groq is now a supported Infe...",
    "pubDate": "Mon, 16 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-groq",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-groq.jpg"
  },
  {
    "title": "Interactively explore your Huggingface dataset with one line of code",
    "description": "",
    "summary": "Interactively explore your Huggingface dataset with one line of code The Hugging Face datasets libra...",
    "pubDate": "Wed, 25 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/scalable-data-inspection",
    "thumbnail": "https://huggingface.co/blog/assets/scalable-data-inspection/thumbnail.png"
  },
  {
    "title": "Think How to Think: Mitigating Overthinking with Autonomous Difficulty Cognition in Large Reasoning Models",
    "description": "arXiv:2507.02663v1 Announce Type: new Abstract: Recent Long Reasoning Models(LRMs) have demonstrated remarkable capabilities in handling complex reasoning tasks, but are hindered by excessive overthinking. To explore its essence, our empirical analysis reveals that LRMs are primarily limited to recognizing task properties (i.e., difficulty levels) like humans before solving the problem, leading to a one-size-fits-all reasoning process. Inspired by this, a pressing and natural question emerges: Can we bootstrap such ability to further alleviate the overthinking phenomenon in LRMs? In this paper, we propose Think-How-to-Think (TH2T), a novel two-stage fine-tuning strategy that progressively inspires LRMs' difficulty cognition and redundancy cognition. First, we introduce difficulty-hypnosis in the prefixes of model outputs to intervene in the internal reasoning trajectory. Combined with a heterogeneous short and long reasoning dataset, the trained model enhances its sensitivity to task difficulty, enabling native, differentiated reasoning strategies across various tasks. Second, we further extend redundancy-hypnosis to the internal reasoning process, guiding the model to identify redundant structures within the reasoning steps and generate more concise reasoning outputs. Experiments on 7B/14B/32B models demonstrate that TH2T significantly reduces inference costs (more than 70% on easy tasks and 40% on hard tasks) while maintaining performance stability. The resulting outputs exhibit clear difficulty-aware capabilities and reduced redundancy (e.g., reflection).",
    "summary": "arXiv:2507.02663v1 Announce Type: new Abstract: Recent Long Reasoning Models(LRMs) have demonstrated remarkable capabilities in handling complex reasoning tasks, but are hindered by excessive overthinking. To explore its essence, our empirical analysis reveals that LRMs are primarily limited to recognizing task properties (i.e., difficulty levels) like humans before solving the problem, leading to a one-size-fits-all reasoning process. Inspired by this, a pressing and natural question emerges: Can we bootstrap such ability to further alleviate the overthinking phenomenon in LRMs? In this paper, we propose Think-How-to-Think (TH2T), a novel two-stage fine-tuning strategy that progressively inspires LRMs' difficulty cognition and redundancy cognition. First, we introduce difficulty-hypnosis in the prefixes of model outputs to intervene in the internal reasoning trajectory. Combined with a heterogeneous short and long reasoning dataset, the trained model enhances its sensitivity to task difficulty, enabling native, differentiated reasoning strategies across various tasks. Second, we further extend redundancy-hypnosis to the internal reasoning process, guiding the model to identify redundant structures within the reasoning steps and generate more concise reasoning outputs. Experiments on 7B/14B/32B models demonstrate that TH2T significantly reduces inference costs (more than 70% on easy tasks and 40% on hard tasks) while maintaining performance stability. The resulting outputs exhibit clear difficulty-aware capabilities and reduced redundancy (e.g., reflection).",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02663",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Integrating Large Language Models in Financial Investments and Market Analysis: A Survey",
    "description": "arXiv:2507.01990v1 Announce Type: cross Abstract: Large Language Models (LLMs) have been employed in financial decision making, enhancing analytical capabilities for investment strategies. Traditional investment strategies often utilize quantitative models, fundamental analysis, and technical indicators. However, LLMs have introduced new capabilities to process and analyze large volumes of structured and unstructured data, extract meaningful insights, and enhance decision-making in real-time. This survey provides a structured overview of recent research on LLMs within the financial domain, categorizing research contributions into four main frameworks: LLM-based Frameworks and Pipelines, Hybrid Integration Methods, Fine-Tuning and Adaptation Approaches, and Agent-Based Architectures. This study provides a structured review of recent LLMs research on applications in stock selection, risk assessment, sentiment analysis, trading, and financial forecasting. By reviewing the existing literature, this study highlights the capabilities, challenges, and potential directions of LLMs in financial markets.",
    "summary": "arXiv:2507.01990v1 Announce Type: cross Abstract: Large Language Models (LLMs) have been employed in financial decision making, enhancing analytical capabilities for investment strategies. Traditional investment strategies often utilize quantitative models, fundamental analysis, and technical indicators. However, LLMs have introduced new capabilities to process and analyze large volumes of structured and unstructured data, extract meaningful insights, and enhance decision-making in real-time. This survey provides a structured overview of recent research on LLMs within the financial domain, categorizing research contributions into four main frameworks: LLM-based Frameworks and Pipelines, Hybrid Integration Methods, Fine-Tuning and Adaptation Approaches, and Agent-Based Architectures. This study provides a structured review of recent LLMs research on applications in stock selection, risk assessment, sentiment analysis, trading, and financial forecasting. By reviewing the existing literature, this study highlights the capabilities, challenges, and potential directions of LLMs in financial markets.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01990",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Stable Diffusion XL on Mac with Advanced Core ML Quantization",
    "description": "",
    "summary": "Stable Diffusion XL on Mac with Advanced Core ML Quantization Stable Diffusion XL was released yeste...",
    "pubDate": "Thu, 27 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-xl-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/stable-diffusion-xl-coreml/thumbnail.png"
  },
  {
    "title": "New tools and features in the Responses API",
    "description": "New features in the Responses API: Remote MCP, image gen, Code Interpreter, and more. Powering faster, smarter agents with GPT-4o & o-series models, plus new features for reliability and efficiency.",
    "summary": "New features in the Responses API: Remote MCP, image gen, Code Interpreter, and more. Powering faster, smarter agents with GPT-4o & o-series models, plus new features for reliability and efficiency.",
    "pubDate": "Wed, 21 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-and-features-in-the-responses-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Lessons learned on language model safety and misuse",
    "description": "We describe our latest thinking in the hope of helping other AI developers address safety and misuse of deployed¬†models.",
    "summary": "We describe our latest thinking in the hope of helping other AI developers address safety and misuse of deployed¬†models.",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-model-safety-and-misuse",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Memory and new controls for ChatGPT",
    "description": "We‚Äôre testing the ability for ChatGPT to remember things you discuss to make future chats more helpful. You‚Äôre in control of ChatGPT‚Äôs memory.",
    "summary": "We‚Äôre testing the ability for ChatGPT to remember things you discuss to make future chats more helpful. You‚Äôre in control of ChatGPT‚Äôs memory.",
    "pubDate": "Tue, 13 Feb 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/memory-and-new-controls-for-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The N Implementation Details of RLHF with PPO",
    "description": "",
    "summary": "The N Implementation Details of RLHF with PPO RLHF / ChatGPT has been a popular research topic these...",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo",
    "thumbnail": "https://huggingface.co/blog/assets/167_the_n_implementation_details_of_rlhf_with_ppo/thumbnail.png"
  },
  {
    "title": "Gradio 3.0 is Out!",
    "description": "",
    "summary": "Gradio 3.0 is Out! Machine Learning Demos Machine learning demos are an increasingly vital part of r...",
    "pubDate": "Mon, 16 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-blocks",
    "thumbnail": "https://huggingface.co/blog/assets/68_gradio_blocks/block-party.png"
  },
  {
    "title": "Getting started with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Getting Started with Hugging Face Inference Endpoints Training machine learning models has become qu...",
    "pubDate": "Fri, 14 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/109_inference_endpoints/endpoints05.png"
  },
  {
    "title": "Helen Toner joins OpenAI‚Äôs board of directors",
    "description": "Today, we‚Äôre excited to announce the appointment of Helen Toner to our board of directors.",
    "summary": "Today, we‚Äôre excited to announce the appointment of Helen Toner to our board of directors.",
    "pubDate": "Wed, 08 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/helen-toner-joins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The 5 Most Under-Rated Tools on Hugging Face",
    "description": "",
    "summary": "The 5 Most Under-Rated Tools on Hugging Face The Hugging Face Hub boasts over 850K public models, wi...",
    "pubDate": "Thu, 22 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unsung-heroes",
    "thumbnail": "https://huggingface.co/blog/assets/unsung-heroes/new-thumbnail.png"
  },
  {
    "title": "Economics and reasoning with OpenAI o1",
    "description": "Economist Tyler Cowen explains how OpenAI o1 tackles complex economic questions.",
    "summary": "Economist Tyler Cowen explains how OpenAI o1 tackles complex economic questions.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-economics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SDXL in 4 steps with Latent Consistency LoRAs",
    "description": "",
    "summary": "SDXL in 4 steps with Latent Consistency LoRAs Latent Consistency Models (LCM) are a way to decrease ...",
    "pubDate": "Thu, 09 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lcm_lora",
    "thumbnail": "https://huggingface.co/blog/assets/lcm_sdxl/lcm_thumbnail.png"
  },
  {
    "title": "Quantifying the Cross-sectoral Intersecting Discrepancies within Multiple Groups Using Latent Class Analysis Towards Fairness",
    "description": "arXiv:2407.03133v4 Announce Type: replace-cross Abstract: The growing interest in fair AI development is evident. The ''Leave No One Behind'' initiative urges us to address multiple and intersecting forms of inequality in accessing services, resources, and opportunities, emphasising the significance of fairness in AI. This is particularly relevant as an increasing number of AI tools are applied to decision-making processes, such as resource allocation and service scheme development, across various sectors such as health, energy, and housing. Therefore, exploring joint inequalities in these sectors is significant and valuable for thoroughly understanding overall inequality and unfairness. This research introduces an innovative approach to quantify cross-sectoral intersecting discrepancies among user-defined groups using latent class analysis. These discrepancies can be used to approximate inequality and provide valuable insights to fairness issues. We validate our approach using both proprietary and public datasets, including both EVENS and Census 2021 (England & Wales) datasets, to examine cross-sectoral intersecting discrepancies among different ethnic groups. We also verify the reliability of the quantified discrepancy by conducting a correlation analysis with a government public metric. Our findings reveal significant discrepancies both among minority ethnic groups and between minority ethnic groups and non-minority ethnic groups, emphasising the need for targeted interventions in policy-making processes. Furthermore, we demonstrate how the proposed approach can provide valuable insights into ensuring fairness in machine learning systems.",
    "summary": "arXiv:2407.03133v4 Announce Type: replace-cross Abstract: The growing interest in fair AI development is evident. The ''Leave No One Behind'' initiative urges us to address multiple and intersecting forms of inequality in accessing services, resources, and opportunities, emphasising the significance of fairness in AI. This is particularly relevant as an increasing number of AI tools are applied to decision-making processes, such as resource allocation and service scheme development, across various sectors such as health, energy, and housing. Therefore, exploring joint inequalities in these sectors is significant and valuable for thoroughly understanding overall inequality and unfairness. This research introduces an innovative approach to quantify cross-sectoral intersecting discrepancies among user-defined groups using latent class analysis. These discrepancies can be used to approximate inequality and provide valuable insights to fairness issues. We validate our approach using both proprietary and public datasets, including both EVENS and Census 2021 (England & Wales) datasets, to examine cross-sectoral intersecting discrepancies among different ethnic groups. We also verify the reliability of the quantified discrepancy by conducting a correlation analysis with a government public metric. Our findings reveal significant discrepancies both among minority ethnic groups and between minority ethnic groups and non-minority ethnic groups, emphasising the need for targeted interventions in policy-making processes. Furthermore, we demonstrate how the proposed approach can provide valuable insights into ensuring fairness in machine learning systems.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.03133",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Next-Token Prediction Task Assumes Optimal Data Ordering for LLM Training in Proof Generation",
    "description": "arXiv:2411.00863v2 Announce Type: replace-cross Abstract: In the field of large language model (LLM)-based proof generation, despite extensive training on large datasets such as ArXiv, LLMs still exhibit only modest performance on proving tasks of moderate difficulty. We believe that this is partly due to the widespread presence of suboptimal ordering within the data for each proof used in training. For example, published proofs often follow a purely logical order, where each step logically proceeds from the previous steps based on the deductive rules. This order is designed to facilitate the verification of the proof's soundness, rather than to help people and models learn the discovery process of the proof. In proof generation, we argue that the optimal order for one training data sample occurs when the relevant intermediate supervision for a particular proof step in the proof is always positioned to the left of that proof step. We call such order the intuitively sequential order. We validate our claims using two tasks: intuitionistic propositional logic theorem-proving and digit multiplication. Our experiments verify the order effect and provide support for our explanations. We demonstrate that training is most effective when the proof is in the intuitively sequential order. Moreover, the order effect and the performance gap between models trained on different data orders can be substantial -- with an 11 percent improvement in proof success rate observed in the propositional logic theorem-proving task, between models trained on the optimal order compared to the worst order. Lastly, we define a common type of order issue in advanced math proofs and find that 17.3 percent of theorems with nontrivial proofs in the first two chapters of a widely used graduate-level mathematics textbook suffer from this issue. A detailed list of those proofs is provided in the appendix.",
    "summary": "arXiv:2411.00863v2 Announce Type: replace-cross Abstract: In the field of large language model (LLM)-based proof generation, despite extensive training on large datasets such as ArXiv, LLMs still exhibit only modest performance on proving tasks of moderate difficulty. We believe that this is partly due to the widespread presence of suboptimal ordering within the data for each proof used in training. For example, published proofs often follow a purely logical order, where each step logically proceeds from the previous steps based on the deductive rules. This order is designed to facilitate the verification of the proof's soundness, rather than to help people and models learn the discovery process of the proof. In proof generation, we argue that the optimal order for one training data sample occurs when the relevant intermediate supervision for a particular proof step in the proof is always positioned to the left of that proof step. We call such order the intuitively sequential order. We validate our claims using two tasks: intuitionistic propositional logic theorem-proving and digit multiplication. Our experiments verify the order effect and provide support for our explanations. We demonstrate that training is most effective when the proof is in the intuitively sequential order. Moreover, the order effect and the performance gap between models trained on different data orders can be substantial -- with an 11 percent improvement in proof success rate observed in the propositional logic theorem-proving task, between models trained on the optimal order compared to the worst order. Lastly, we define a common type of order issue in advanced math proofs and find that 17.3 percent of theorems with nontrivial proofs in the first two chapters of a widely used graduate-level mathematics textbook suffer from this issue. A detailed list of those proofs is provided in the appendix.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.00863",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Pre-Train BERT with Hugging Face Transformers and Habana Gaudi",
    "description": "",
    "summary": "Pre-Training BERT with Hugging Face Transformers and Habana Gaudi In this Tutorial, you will learn h...",
    "pubDate": "Mon, 22 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pretraining-bert",
    "thumbnail": "https://huggingface.co/blog/assets/99_pretraining_bert/thumbnail.png"
  },
  {
    "title": "OpenAI and Microsoft extend partnership",
    "description": "We‚Äôre happy to announce that OpenAI and¬†Microsoft¬†are extending our¬†partnership.",
    "summary": "We‚Äôre happy to announce that OpenAI and¬†Microsoft¬†are extending our¬†partnership.",
    "pubDate": "Mon, 23 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-microsoft-extend-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Navigating the challenges and opportunities of synthetic voices",
    "description": "We‚Äôre sharing lessons from a small scale preview of Voice Engine, a model for creating custom voices.",
    "summary": "We‚Äôre sharing lessons from a small scale preview of Voice Engine, a model for creating custom voices.",
    "pubDate": "Fri, 29 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/navigating-the-challenges-and-opportunities-of-synthetic-voices",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters",
    "description": "arXiv:2507.02085v1 Announce Type: cross Abstract: Geometric diffusion models have shown remarkable success in molecular dynamics and structure generation. However, efficiently fine-tuning them for downstream tasks with varying geometric controls remains underexplored. In this work, we propose an SE(3)-equivariant adapter framework ( GeoAda) that enables flexible and parameter-efficient fine-tuning for controlled generative tasks without modifying the original model architecture. GeoAda introduces a structured adapter design: control signals are first encoded through coupling operators, then processed by a trainable copy of selected pretrained model layers, and finally projected back via decoupling operators followed by an equivariant zero-initialized convolution. By fine-tuning only these lightweight adapter modules, GeoAda preserves the model's geometric consistency while mitigating overfitting and catastrophic forgetting. We theoretically prove that the proposed adapters maintain SE(3)-equivariance, ensuring that the geometric inductive biases of the pretrained diffusion model remain intact during adaptation. We demonstrate the wide applicability of GeoAda across diverse geometric control types, including frame control, global control, subgraph control, and a broad range of application domains such as particle dynamics, molecular dynamics, human motion prediction, and molecule generation. Empirical results show that GeoAda achieves state-of-the-art fine-tuning performance while preserving original task accuracy, whereas other baselines experience significant performance degradation due to overfitting and catastrophic forgetting.",
    "summary": "arXiv:2507.02085v1 Announce Type: cross Abstract: Geometric diffusion models have shown remarkable success in molecular dynamics and structure generation. However, efficiently fine-tuning them for downstream tasks with varying geometric controls remains underexplored. In this work, we propose an SE(3)-equivariant adapter framework ( GeoAda) that enables flexible and parameter-efficient fine-tuning for controlled generative tasks without modifying the original model architecture. GeoAda introduces a structured adapter design: control signals are first encoded through coupling operators, then processed by a trainable copy of selected pretrained model layers, and finally projected back via decoupling operators followed by an equivariant zero-initialized convolution. By fine-tuning only these lightweight adapter modules, GeoAda preserves the model's geometric consistency while mitigating overfitting and catastrophic forgetting. We theoretically prove that the proposed adapters maintain SE(3)-equivariance, ensuring that the geometric inductive biases of the pretrained diffusion model remain intact during adaptation. We demonstrate the wide applicability of GeoAda across diverse geometric control types, including frame control, global control, subgraph control, and a broad range of application domains such as particle dynamics, molecular dynamics, human motion prediction, and molecule generation. Empirical results show that GeoAda achieves state-of-the-art fine-tuning performance while preserving original task accuracy, whereas other baselines experience significant performance degradation due to overfitting and catastrophic forgetting.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02085",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards an Explainable Comparison and Alignment of Feature Embeddings",
    "description": "arXiv:2506.06231v2 Announce Type: replace-cross Abstract: While several feature embedding models have been developed in the literature, comparisons of these embeddings have largely focused on their numerical performance in classification-related downstream applications. However, an interpretable comparison of different embeddings requires identifying and analyzing mismatches between sample groups clustered within the embedding spaces. In this work, we propose the emph{Spectral Pairwise Embedding Comparison (SPEC)} framework to compare embeddings and identify their differences in clustering a reference dataset. Our approach examines the kernel matrices derived from two embeddings and leverages the eigendecomposition of the difference kernel matrix to detect sample clusters that are captured differently by the two embeddings. We present a scalable implementation of this kernel-based approach, with computational complexity that grows linearly with the sample size. Furthermore, we introduce an optimization problem using this framework to align two embeddings, ensuring that clusters identified in one embedding are also captured in the other model. We provide numerical results demonstrating the SPEC's application to compare and align embeddings on large-scale datasets such as ImageNet and MS-COCO. The project page is available at https://mjalali.github.io/SPEC/.",
    "summary": "arXiv:2506.06231v2 Announce Type: replace-cross Abstract: While several feature embedding models have been developed in the literature, comparisons of these embeddings have largely focused on their numerical performance in classification-related downstream applications. However, an interpretable comparison of different embeddings requires identifying and analyzing mismatches between sample groups clustered within the embedding spaces. In this work, we propose the emph{Spectral Pairwise Embedding Comparison (SPEC)} framework to compare embeddings and identify their differences in clustering a reference dataset. Our approach examines the kernel matrices derived from two embeddings and leverages the eigendecomposition of the difference kernel matrix to detect sample clusters that are captured differently by the two embeddings. We present a scalable implementation of this kernel-based approach, with computational complexity that grows linearly with the sample size. Furthermore, we introduce an optimization problem using this framework to align two embeddings, ensuring that clusters identified in one embedding are also captured in the other model. We provide numerical results demonstrating the SPEC's application to compare and align embeddings on large-scale datasets such as ImageNet and MS-COCO. The project page is available at https://mjalali.github.io/SPEC/.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.06231",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-Tuning GPT-4o Webinar",
    "description": "Fine-Tuning GPT-4o Webinar",
    "summary": "Fine-Tuning GPT-4o Webinar",
    "pubDate": "Mon, 26 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/fine-tuning-gpt-4o-webinar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "State of open video generation models in Diffusers",
    "description": "",
    "summary": "State of open video generation models in Diffusers OpenAI‚Äôs Sora demo marked a striking advance in A...",
    "pubDate": "Mon, 27 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/video_gen",
    "thumbnail": "https://huggingface.co/blog/assets/video_gen/thumbnail.png"
  },
  {
    "title": "Uncertainty-Guided Coarse-to-Fine Tumor Segmentation with Anatomy-Aware Post-Processing",
    "description": "arXiv:2504.12215v2 Announce Type: replace-cross Abstract: Reliable tumor segmentation in thoracic computed tomography (CT) remains challenging due to boundary ambiguity, class imbalance, and anatomical variability. We propose an uncertainty-guided, coarse-to-fine segmentation framework that combines full-volume tumor localization with refined region-of-interest (ROI) segmentation, enhanced by anatomically aware post-processing. The first-stage model generates a coarse prediction, followed by anatomically informed filtering based on lung overlap, proximity to lung surfaces, and component size. The resulting ROIs are segmented by a second-stage model trained with uncertainty-aware loss functions to improve accuracy and boundary calibration in ambiguous regions. Experiments on private and public datasets demonstrate improvements in Dice and Hausdorff scores, with fewer false positives and enhanced spatial interpretability. These results highlight the value of combining uncertainty modeling and anatomical priors in cascaded segmentation pipelines for robust and clinically meaningful tumor delineation. On the Orlando dataset, our framework improved Swin UNETR Dice from 0.4690 to 0.6447. Reduction in spurious components was strongly correlated with segmentation gains, underscoring the value of anatomically informed post-processing.",
    "summary": "arXiv:2504.12215v2 Announce Type: replace-cross Abstract: Reliable tumor segmentation in thoracic computed tomography (CT) remains challenging due to boundary ambiguity, class imbalance, and anatomical variability. We propose an uncertainty-guided, coarse-to-fine segmentation framework that combines full-volume tumor localization with refined region-of-interest (ROI) segmentation, enhanced by anatomically aware post-processing. The first-stage model generates a coarse prediction, followed by anatomically informed filtering based on lung overlap, proximity to lung surfaces, and component size. The resulting ROIs are segmented by a second-stage model trained with uncertainty-aware loss functions to improve accuracy and boundary calibration in ambiguous regions. Experiments on private and public datasets demonstrate improvements in Dice and Hausdorff scores, with fewer false positives and enhanced spatial interpretability. These results highlight the value of combining uncertainty modeling and anatomical priors in cascaded segmentation pipelines for robust and clinically meaningful tumor delineation. On the Orlando dataset, our framework improved Swin UNETR Dice from 0.4690 to 0.6447. Reduction in spurious components was strongly correlated with segmentation gains, underscoring the value of anatomically informed post-processing.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.12215",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Synthesizable by Design: A Retrosynthesis-Guided Framework for Molecular Analog Generation",
    "description": "arXiv:2507.02752v1 Announce Type: cross Abstract: The disconnect between AI-generated molecules with desirable properties and their synthetic feasibility remains a critical bottleneck in computational drug and material discovery. While generative AI has accelerated the proposal of candidate molecules, many of these structures prove challenging or impossible to synthesize using established chemical reactions. Here, we introduce SynTwins, a novel retrosynthesis-guided molecular analog design framework that designs synthetically accessible molecular analogs by emulating expert chemist strategies through a three-step process: retrosynthesis, similar building block searching, and virtual synthesis. In comparative evaluations, SynTwins demonstrates superior performance in generating synthetically accessible analogs compared to state-of-the-art machine learning models while maintaining high structural similarity to original target molecules. Furthermore, when integrated with existing molecule optimization frameworks, our hybrid approach produces synthetically feasible molecules with property profiles comparable to unconstrained molecule generators, yet its synthesizability ensured. Our comprehensive benchmarking across diverse molecular datasets demonstrates that SynTwins effectively bridges the gap between computational design and experimental synthesis, providing a practical solution for accelerating the discovery of synthesizable molecules with desired properties for a wide range of applications.",
    "summary": "arXiv:2507.02752v1 Announce Type: cross Abstract: The disconnect between AI-generated molecules with desirable properties and their synthetic feasibility remains a critical bottleneck in computational drug and material discovery. While generative AI has accelerated the proposal of candidate molecules, many of these structures prove challenging or impossible to synthesize using established chemical reactions. Here, we introduce SynTwins, a novel retrosynthesis-guided molecular analog design framework that designs synthetically accessible molecular analogs by emulating expert chemist strategies through a three-step process: retrosynthesis, similar building block searching, and virtual synthesis. In comparative evaluations, SynTwins demonstrates superior performance in generating synthetically accessible analogs compared to state-of-the-art machine learning models while maintaining high structural similarity to original target molecules. Furthermore, when integrated with existing molecule optimization frameworks, our hybrid approach produces synthetically feasible molecules with property profiles comparable to unconstrained molecule generators, yet its synthesizability ensured. Our comprehensive benchmarking across diverse molecular datasets demonstrates that SynTwins effectively bridges the gap between computational design and experimental synthesis, providing a practical solution for accelerating the discovery of synthesizable molecules with desired properties for a wide range of applications.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02752",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Questions for the Record",
    "description": "The following are the Questions for the Record following Sam Altman's testimony before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "summary": "The following are the Questions for the Record following Sam Altman's testimony before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/sam-altman-senate-questions-for-the-record",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerate Large Model Training using DeepSpeed",
    "description": "",
    "summary": "Accelerate Large Model Training using DeepSpeed In this post we will look at how we can leverage the...",
    "pubDate": "Tue, 28 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-deepspeed",
    "thumbnail": "https://huggingface.co/blog/assets/83_accelerate_deepspeed/deepspeed-thumbnail.png"
  },
  {
    "title": "Offline Reinforcement Learning for Learning to Dispatch for Job Shop Scheduling",
    "description": "arXiv:2409.10589v4 Announce Type: replace-cross Abstract: The Job Shop Scheduling Problem (JSSP) is a complex combinatorial optimization problem. While online Reinforcement Learning (RL) has shown promise by quickly finding acceptable solutions for JSSP, it faces key limitations: it requires extensive training interactions from scratch leading to sample inefficiency, cannot leverage existing high-quality solutions from traditional methods like Constraint Programming (CP), and require simulated environments to train in, which are impracticable to build for complex scheduling environments. We introduce Offline Learned Dispatching (Offline-LD), an offline reinforcement learning approach for JSSP, which addresses these limitations by learning from historical scheduling data. Our approach is motivated by scenarios where historical scheduling data and expert solutions are available or scenarios where online training of RL approaches with simulated environments is impracticable. Offline-LD introduces maskable variants of two Q-learning methods, namely, Maskable Quantile Regression DQN (mQRDQN) and discrete maskable Soft Actor-Critic (d-mSAC), that are able to learn from historical data, through Conservative Q-Learning (CQL). Moreover, we present a novel entropy bonus modification for d-mSAC, for maskable action spaces. Moreover, we introduce a novel reward normalization method for JSSP in an offline RL setting. Our experiments demonstrate that Offline-LD outperforms online RL on both generated and benchmark instances when trained on only 100 solutions generated by CP. Notably, introducing noise to the expert dataset yields comparable or superior results to using the expert dataset, with the same amount of instances, a promising finding for real-world applications, where data is inherently noisy and imperfect.",
    "summary": "arXiv:2409.10589v4 Announce Type: replace-cross Abstract: The Job Shop Scheduling Problem (JSSP) is a complex combinatorial optimization problem. While online Reinforcement Learning (RL) has shown promise by quickly finding acceptable solutions for JSSP, it faces key limitations: it requires extensive training interactions from scratch leading to sample inefficiency, cannot leverage existing high-quality solutions from traditional methods like Constraint Programming (CP), and require simulated environments to train in, which are impracticable to build for complex scheduling environments. We introduce Offline Learned Dispatching (Offline-LD), an offline reinforcement learning approach for JSSP, which addresses these limitations by learning from historical scheduling data. Our approach is motivated by scenarios where historical scheduling data and expert solutions are available or scenarios where online training of RL approaches with simulated environments is impracticable. Offline-LD introduces maskable variants of two Q-learning methods, namely, Maskable Quantile Regression DQN (mQRDQN) and discrete maskable Soft Actor-Critic (d-mSAC), that are able to learn from historical data, through Conservative Q-Learning (CQL). Moreover, we present a novel entropy bonus modification for d-mSAC, for maskable action spaces. Moreover, we introduce a novel reward normalization method for JSSP in an offline RL setting. Our experiments demonstrate that Offline-LD outperforms online RL on both generated and benchmark instances when trained on only 100 solutions generated by CP. Notably, introducing noise to the expert dataset yields comparable or superior results to using the expert dataset, with the same amount of instances, a promising finding for real-world applications, where data is inherently noisy and imperfect.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.10589",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration",
    "description": "",
    "summary": "Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration The mission of ...",
    "pubDate": "Wed, 15 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel",
    "thumbnail": "https://huggingface.co/blog/assets/80_intel/01.png"
  },
  {
    "title": "From Chunks to Blocks: Accelerating Uploads and Downloads on the Hub",
    "description": "",
    "summary": "From Chunks to Blocks: Accelerating Uploads and Downloads on the Hub Content-defined chunking (CDC) ...",
    "pubDate": "Wed, 12 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/from-chunks-to-blocks",
    "thumbnail": "https://huggingface.co/blog/assets/from-chunks-to-blocks/thumbnail.png"
  },
  {
    "title": "A Deepdive into Aya Vision: Advancing the Frontier of Multilingual Multimodality",
    "description": "",
    "summary": "A Deepdive into Aya Vision: Advancing the Frontier of Multilingual Multimodality With the release of...",
    "pubDate": "Tue, 04 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aya-vision",
    "thumbnail": "https://huggingface.co/blog/assets/aya-vision/thumbnail.png"
  },
  {
    "title": "Gemini Robotics brings AI into the physical world",
    "description": "Introducing Gemini Robotics and Gemini Robotics-ER, AI models designed for robots to understand, act and react to the physical world.",
    "summary": "Introducing Gemini Robotics and Gemini Robotics-ER, AI models designed for robots to understand, act and react to the physical world.",
    "pubDate": "Wed, 12 Mar 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/",
    "thumbnail": "https://lh3.googleusercontent.com/J74rVi68EPPNMBLxhxI76Bli7QggLtYRYfp5Pk2HVPtSt2NIIk2VmLktQbwDZeIlZiW3AHwlpLNcswHuz_ecR-oj4kI-mtF53yYsGJKfvPugAw5ulQ=w1200-h630-n-nu"
  },
  {
    "title": "Extracting Concepts from GPT-4",
    "description": "Using new techniques for scaling sparse autoencoders, we automatically identified 16 million patterns in GPT-4's computations.",
    "summary": "Using new techniques for scaling sparse autoencoders, we automatically identified 16 million patterns in GPT-4's computations.",
    "pubDate": "Thu, 06 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/extracting-concepts-from-gpt-4",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeRobot goes to driving school: World‚Äôs largest open-source self-driving dataset",
    "description": "",
    "summary": "LeRobot goes to driving school TL;DR of L2D, the world's largest self-driving dataset! - 90+ TeraByt...",
    "pubDate": "Tue, 11 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lerobot-goes-to-driving-school",
    "thumbnail": "https://huggingface.co/blog/assets/193_l2d/lerobot-driver.gif"
  },
  {
    "title": "NVIDIA's GTC 2025 Announcement for Physical AI Developers: New Open Models and Datasets",
    "description": "",
    "summary": "NVIDIA's GTC 2025 Announcement for Physical AI Developers: New Open Models and Datasets At its annua...",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nvidia-physical-ai",
    "thumbnail": "https://huggingface.co/blog/assets/nvidia-physical-ai/thumbnail.png"
  },
  {
    "title": "Introducing Optimum: The Optimization Toolkit for Transformers at Scale",
    "description": "",
    "summary": "Introducing ü§ó Optimum: The Optimization Toolkit for Transformers at Scale This post is the first ste...",
    "pubDate": "Tue, 14 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hardware-partners-program",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Disrupting deceptive uses of AI by covert influence operations",
    "description": "We‚Äôve terminated accounts linked to covert influence operations; no significant audience increase due to our services.",
    "summary": "We‚Äôve terminated accounts linked to covert influence operations; no significant audience increase due to our services.",
    "pubDate": "Thu, 30 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-deceptive-uses-of-AI-by-covert-influence-operations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 2",
    "description": "",
    "summary": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 2 In a recent post, we introduced...",
    "pubDate": "Mon, 06 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-sapphire-rapids-inference",
    "thumbnail": "https://huggingface.co/blog/assets/129_intel_sapphire_rapids_inference/01.png"
  },
  {
    "title": "Dell Enterprise Hub is all you need to build AI on premises",
    "description": "",
    "summary": "Dell Enterprise Hub is all you need to build AI on premises This week at Dell Tech World, we announc...",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dell-ai-applications",
    "thumbnail": "https://huggingface.co/blog/assets/dell-ai-applications/dell-post-thumbnail.png"
  },
  {
    "title": "Introducing Training Cluster as a Service - a new collaboration with NVIDIA",
    "description": "",
    "summary": "Introducing Training Cluster as a Service - a new collaboration with NVIDIA Today at GTC Paris, we a...",
    "pubDate": "Wed, 11 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nvidia-training-cluster",
    "thumbnail": "https://huggingface.co/blog/assets/nvidia-training-cluster/nvidia-training-cluster-thumbnail-compressed.png"
  },
  {
    "title": "Will Hurd joins OpenAI‚Äôs board of directors",
    "description": "OpenAI is committed to developing general-purpose artificial intelligence that benefits all humanity, and we believe that achieving our goal requires expertise in public policy as well as technology. So, we‚Äôre delighted to announce that Congressman¬†Will Hurd¬†has joined our board of directors.",
    "summary": "OpenAI is committed to developing general-purpose artificial intelligence that benefits all humanity, and we believe that achieving our goal requires expertise in public policy as well as technology. So, we‚Äôre delighted to announce that Congressman¬†Will Hurd¬†has joined our board of directors.",
    "pubDate": "Mon, 03 May 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/will-hurd-joins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the ChatGPT app for iOS",
    "description": "The ChatGPT app syncs your conversations, supports voice input, and brings our latest model improvements to your fingertips.",
    "summary": "The ChatGPT app syncs your conversations, supports voice input, and brings our latest model improvements to your fingertips.",
    "pubDate": "Thu, 18 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-chatgpt-app-for-ios",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network",
    "description": "arXiv:2507.02827v1 Announce Type: cross Abstract: The primary objective of human activity recognition (HAR) is to infer ongoing human actions from sensor data, a task that finds broad applications in health monitoring, safety protection, and sports analysis. Despite proliferating research, HAR still faces key challenges, including the scarcity of labeled samples for rare activities, insufficient extraction of high-level features, and suboptimal model performance on lightweight devices. To address these issues, this paper proposes a comprehensive optimization approach centered on multi-attention interaction mechanisms. First, an unsupervised, statistics-guided diffusion model is employed to perform data augmentation, thereby alleviating the problems of labeled data scarcity and severe class imbalance. Second, a multi-branch spatio-temporal interaction network is designed, which captures multi-scale features of sequential data through parallel residual branches with 3*3, 5*5, and 7*7 convolutional kernels. Simultaneously, temporal attention mechanisms are incorporated to identify critical time points, while spatial attention enhances inter-sensor interactions. A cross-branch feature fusion unit is further introduced to improve the overall feature representation capability. Finally, an adaptive multi-loss function fusion strategy is integrated, allowing for dynamic adjustment of loss weights and overall model optimization. Experimental results on three public datasets, WISDM, PAMAP2, and OPPORTUNITY, demonstrate that the proposed unsupervised data augmentation spatio-temporal attention diffusion network (USAD) achieves accuracies of 98.84%, 93.81%, and 80.92% respectively, significantly outperforming existing approaches. Furthermore, practical deployment on embedded devices verifies the efficiency and feasibility of the proposed method.",
    "summary": "arXiv:2507.02827v1 Announce Type: cross Abstract: The primary objective of human activity recognition (HAR) is to infer ongoing human actions from sensor data, a task that finds broad applications in health monitoring, safety protection, and sports analysis. Despite proliferating research, HAR still faces key challenges, including the scarcity of labeled samples for rare activities, insufficient extraction of high-level features, and suboptimal model performance on lightweight devices. To address these issues, this paper proposes a comprehensive optimization approach centered on multi-attention interaction mechanisms. First, an unsupervised, statistics-guided diffusion model is employed to perform data augmentation, thereby alleviating the problems of labeled data scarcity and severe class imbalance. Second, a multi-branch spatio-temporal interaction network is designed, which captures multi-scale features of sequential data through parallel residual branches with 3*3, 5*5, and 7*7 convolutional kernels. Simultaneously, temporal attention mechanisms are incorporated to identify critical time points, while spatial attention enhances inter-sensor interactions. A cross-branch feature fusion unit is further introduced to improve the overall feature representation capability. Finally, an adaptive multi-loss function fusion strategy is integrated, allowing for dynamic adjustment of loss weights and overall model optimization. Experimental results on three public datasets, WISDM, PAMAP2, and OPPORTUNITY, demonstrate that the proposed unsupervised data augmentation spatio-temporal attention diffusion network (USAD) achieves accuracies of 98.84%, 93.81%, and 80.92% respectively, significantly outperforming existing approaches. Furthermore, practical deployment on embedded devices verifies the efficiency and feasibility of the proposed method.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02827",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Data Partnerships",
    "description": "Working together to create open-source and private datasets for AI training.",
    "summary": "Working together to create open-source and private datasets for AI training.",
    "pubDate": "Thu, 09 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/data-partnerships",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Discovering the minutiae of backend systems",
    "description": "Christian Gibson is an engineer on the Supercomputing team at OpenAI.",
    "summary": "Christian Gibson is an engineer on the Supercomputing team at OpenAI.",
    "pubDate": "Thu, 08 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/discovering-the-minutiae-of-backend-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "We‚Äôre bringing the Financial Times‚Äô world-class journalism to ChatGPT",
    "description": "We will also collaborate on new AI experiences for FT readers.",
    "summary": "We will also collaborate on new AI experiences for FT readers.",
    "pubDate": "Mon, 29 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/content-partnership-with-financial-times",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Disrupting malicious uses of AI",
    "description": "Ensuring AI benefits humanity by advancing democratic AI, preventing misuse, and protecting against authoritarian threats.",
    "summary": "Ensuring AI benefits humanity by advancing democratic AI, preventing misuse, and protecting against authoritarian threats.",
    "pubDate": "Fri, 21 Feb 2025 06:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes",
    "description": "arXiv:2409.06416v2 Announce Type: replace-cross Abstract: Much of the cost and effort required during the software testing process is invested in performing test maintenance - the addition, removal, or modification of test cases to keep the test suite in sync with the system-under-test or to otherwise improve its quality. Tool support could reduce the cost - and improve the quality - of test maintenance by automating aspects of the process or by providing guidance and support to developers. In this study, we explore the capabilities and applications of large language models (LLMs) - complex machine learning models adapted to textual analysis - to support test maintenance. We conducted a case study at Ericsson AB where we explore the triggers that indicate the need for test maintenance, the actions that LLMs can take, and the considerations that must be made when deploying LLMs in an industrial setting. We also propose and demonstrate a multi-agent architecture that can predict which tests require maintenance following a change to the source code. Collectively, these contributions advance our theoretical and practical understanding of how LLMs can be deployed to benefit industrial test maintenance processes.",
    "summary": "arXiv:2409.06416v2 Announce Type: replace-cross Abstract: Much of the cost and effort required during the software testing process is invested in performing test maintenance - the addition, removal, or modification of test cases to keep the test suite in sync with the system-under-test or to otherwise improve its quality. Tool support could reduce the cost - and improve the quality - of test maintenance by automating aspects of the process or by providing guidance and support to developers. In this study, we explore the capabilities and applications of large language models (LLMs) - complex machine learning models adapted to textual analysis - to support test maintenance. We conducted a case study at Ericsson AB where we explore the triggers that indicate the need for test maintenance, the actions that LLMs can take, and the considerations that must be made when deploying LLMs in an industrial setting. We also propose and demonstrate a multi-agent architecture that can predict which tests require maintenance following a change to the source code. Collectively, these contributions advance our theoretical and practical understanding of how LLMs can be deployed to benefit industrial test maintenance processes.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.06416",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Distributional Soft Actor-Critic with Diffusion Policy",
    "description": "arXiv:2507.01381v2 Announce Type: replace-cross Abstract: Reinforcement learning has been proven to be highly effective in handling complex control tasks. Traditional methods typically use unimodal distributions, such as Gaussian distributions, to model the output of value distributions. However, unimodal distribution often and easily causes bias in value function estimation, leading to poor algorithm performance. This paper proposes a distributional reinforcement learning algorithm called DSAC-D (Distributed Soft Actor Critic with Diffusion Policy) to address the challenges of estimating bias in value functions and obtaining multimodal policy representations. A multimodal distributional policy iteration framework that can converge to the optimal policy was established by introducing policy entropy and value distribution function. A diffusion value network that can accurately characterize the distribution of multi peaks was constructed by generating a set of reward samples through reverse sampling using a diffusion model. Based on this, a distributional reinforcement learning algorithm with dual diffusion of the value network and the policy network was derived. MuJoCo testing tasks demonstrate that the proposed algorithm not only learns multimodal policy, but also achieves state-of-the-art (SOTA) performance in all 9 control tasks, with significant suppression of estimation bias and total average return improvement of over 10% compared to existing mainstream algorithms. The results of real vehicle testing show that DSAC-D can accurately characterize the multimodal distribution of different driving styles, and the diffusion policy network can characterize multimodal trajectories.",
    "summary": "arXiv:2507.01381v2 Announce Type: replace-cross Abstract: Reinforcement learning has been proven to be highly effective in handling complex control tasks. Traditional methods typically use unimodal distributions, such as Gaussian distributions, to model the output of value distributions. However, unimodal distribution often and easily causes bias in value function estimation, leading to poor algorithm performance. This paper proposes a distributional reinforcement learning algorithm called DSAC-D (Distributed Soft Actor Critic with Diffusion Policy) to address the challenges of estimating bias in value functions and obtaining multimodal policy representations. A multimodal distributional policy iteration framework that can converge to the optimal policy was established by introducing policy entropy and value distribution function. A diffusion value network that can accurately characterize the distribution of multi peaks was constructed by generating a set of reward samples through reverse sampling using a diffusion model. Based on this, a distributional reinforcement learning algorithm with dual diffusion of the value network and the policy network was derived. MuJoCo testing tasks demonstrate that the proposed algorithm not only learns multimodal policy, but also achieves state-of-the-art (SOTA) performance in all 9 control tasks, with significant suppression of estimation bias and total average return improvement of over 10% compared to existing mainstream algorithms. The results of real vehicle testing show that DSAC-D can accurately characterize the multimodal distribution of different driving styles, and the diffusion policy network can characterize multimodal trajectories.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01381",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The International 2018: Results",
    "description": "OpenAI Five lost two games against top Dota 2 players at The International in Vancouver this week, maintaining a good chance of winning for the first 20‚Äì35 minutes of both¬†games.",
    "summary": "OpenAI Five lost two games against top Dota 2 players at The International in Vancouver this week, maintaining a good chance of winning for the first 20‚Äì35 minutes of both¬†games.",
    "pubDate": "Thu, 23 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-international-2018-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks",
    "description": "arXiv:2507.02735v1 Announce Type: cross Abstract: Prompt injection attacks pose a significant security threat to LLM-integrated applications. Model-level defenses have shown strong effectiveness, but are currently deployed into commercial-grade models in a closed-source manner. We believe open-source models are needed by the AI security community, where co-development of attacks and defenses through open research drives scientific progress in mitigation against prompt injection attacks. To this end, we develop Meta SecAlign, the first open-source and open-weight LLM with built-in model-level defense that achieves commercial-grade model performance. We provide complete details of our training recipe, which utilizes an improved version of the SOTA SecAlign defense. Evaluations on 9 utility benchmarks and 7 security benchmarks show that Meta SecAlign, despite being trained on a generic instruction-tuning dataset, confers security in unseen downstream tasks, including tool-calling and agentic web navigation, in addition general instruction-following. Our best model -- Meta-SecAlign-70B -- achieves state-of-the-art robustness against prompt injection attacks and comparable utility to closed-source commercial LLM with model-level defense.",
    "summary": "arXiv:2507.02735v1 Announce Type: cross Abstract: Prompt injection attacks pose a significant security threat to LLM-integrated applications. Model-level defenses have shown strong effectiveness, but are currently deployed into commercial-grade models in a closed-source manner. We believe open-source models are needed by the AI security community, where co-development of attacks and defenses through open research drives scientific progress in mitigation against prompt injection attacks. To this end, we develop Meta SecAlign, the first open-source and open-weight LLM with built-in model-level defense that achieves commercial-grade model performance. We provide complete details of our training recipe, which utilizes an improved version of the SOTA SecAlign defense. Evaluations on 9 utility benchmarks and 7 security benchmarks show that Meta SecAlign, despite being trained on a generic instruction-tuning dataset, confers security in unseen downstream tasks, including tool-calling and agentic web navigation, in addition general instruction-following. Our best model -- Meta-SecAlign-70B -- achieves state-of-the-art robustness against prompt injection attacks and comparable utility to closed-source commercial LLM with model-level defense.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02735",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome aMUSEd: Efficient Text-to-Image Generation",
    "description": "",
    "summary": "Welcome aMUSEd: Efficient Text-to-Image Generation We‚Äôre excited to present an efficient non-diffusi...",
    "pubDate": "Thu, 04 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/amused",
    "thumbnail": "https://huggingface.co/blog/assets/amused/thumbnail.png"
  },
  {
    "title": "A Dive into Pretraining Strategies for Vision-Language Models",
    "description": "",
    "summary": "A Dive into Vision-Language Models Human learning is inherently multi-modal as jointly leveraging mu...",
    "pubDate": "Fri, 03 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vision_language_pretraining",
    "thumbnail": "https://huggingface.co/blog//assets/128_vision_language_pretraining/thumbnail.png"
  },
  {
    "title": "Organizational update from OpenAI",
    "description": "It‚Äôs been a year of dramatic change and growth at OpenAI.",
    "summary": "It‚Äôs been a year of dramatic change and growth at OpenAI.",
    "pubDate": "Tue, 29 Dec 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/organizational-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Expanding on how Voice Engine works and our safety research",
    "description": "Exploring the technology behind our text-to-speech model.",
    "summary": "Exploring the technology behind our text-to-speech model.",
    "pubDate": "Fri, 07 Jun 2024 17:45:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expanding-on-how-voice-engine-works-and-our-safety-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DeepMind‚Äôs latest research at NeurIPS 2022",
    "description": "NeurIPS is the world‚Äôs largest conference in artificial intelligence (AI) and machine learning (ML), and we‚Äôre proud to support the event as Diamond sponsors, helping foster the exchange of research advances in the AI and ML community. Teams from across DeepMind are presenting 47 papers, including 35 external collaborations in virtual panels and poster sessions.",
    "summary": "NeurIPS is the world‚Äôs largest conference in artificial intelligence (AI) and machine learning (ML), and we‚Äôre proud to support the event as Diamond sponsors, helping foster the exchange of research advances in the AI and ML community. Teams from across DeepMind are presenting 47 papers, including 35 external collaborations in virtual panels and poster sessions.",
    "pubDate": "Fri, 25 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/deepminds-latest-research-at-neurips-2022/",
    "thumbnail": "https://lh3.googleusercontent.com/MFZKdGWHOzJ6nM8NufhIfpts0R-v9D4jQqnC416FT8ArwmNC2Ztke2S50WVtUhO0g1u8AGmYEyWMDC7LO0a16ydHBMei9GmJO4NjykhpLKw1TVtd4Mg=w1200-h630-n-nu"
  },
  {
    "title": "Learning Day",
    "description": "At OpenAI, each Thursday is Learning Day: a day where employees have the option to self-study technical skills that will make them better at their job but which aren‚Äôt being learned from daily work.",
    "summary": "At OpenAI, each Thursday is Learning Day: a day where employees have the option to self-study technical skills that will make them better at their job but which aren‚Äôt being learned from daily work.",
    "pubDate": "Thu, 01 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-day",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Minne Atairu & Sora",
    "description": "Interdisciplinary artist Minne Atairu discusses how Sora helps realize her vision.",
    "summary": "Interdisciplinary artist Minne Atairu discusses how Sora helps realize her vision.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-minne-atairu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI Japan",
    "description": "We are excited to announce our first office in Asia and we‚Äôre releasing a GPT-4 custom model optimized for the Japanese language.",
    "summary": "We are excited to announce our first office in Asia and we‚Äôre releasing a GPT-4 custom model optimized for the Japanese language.",
    "pubDate": "Sun, 14 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-japan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemma: Introducing new state-of-the-art open models",
    "description": "Gemma is built for responsible AI development from the same research and technology used to create Gemini models.",
    "summary": "Gemma is built for responsible AI development from the same research and technology used to create Gemini models.",
    "pubDate": "Wed, 21 Feb 2024 13:06:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemma-introducing-new-state-of-the-art-open-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemma-social-share.width-1300.jpg"
  },
  {
    "title": "OpenAI Fellows Summer 2018: Final projects",
    "description": "Our first cohort of OpenAI Fellows has concluded, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship.",
    "summary": "Our first cohort of OpenAI Fellows has concluded, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship.",
    "pubDate": "Wed, 19 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-summer-fellows-2018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bringing intelligence to every workflow",
    "description": "Notion is a connected workspace where teams write, plan, and organize everything from meeting notes to product roadmaps. Today, it‚Äôs also a deeply AI-powered platform, used by millions to summarize content, generate writing, and ask questions in natural language across their entire workspace.",
    "summary": "Notion is a connected workspace where teams write, plan, and organize everything from meeting notes to product roadmaps. Today, it‚Äôs also a deeply AI-powered platform, used by millions to summarize content, generate writing, and ask questions in natural language across their entire workspace.",
    "pubDate": "Thu, 03 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/notion",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making automatic speech recognition work on large files with Wav2Vec2 in ü§ó Transformers",
    "description": "",
    "summary": "Making automatic speech recognition work on large files with Wav2Vec2 in ü§ó Transformers Tl;dr: This ...",
    "pubDate": "Tue, 01 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/asr-chunking",
    "thumbnail": "https://huggingface.co/blog/assets/49_asr_chunking/thumbnail.png"
  },
  {
    "title": "The Annotated Diffusion Model",
    "description": "",
    "summary": "The Annotated Diffusion Model In this blog post, we'll take a deeper look into Denoising Diffusion P...",
    "pubDate": "Tue, 07 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/annotated-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/78_annotated-diffusion/thumbnail.png"
  },
  {
    "title": "CinePile 2.0 - making stronger datasets with adversarial refinement",
    "description": "",
    "summary": "CinePile 2.0 - making stronger datasets with adversarial refinement In this blog post we share the j...",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cinepile2",
    "thumbnail": "https://huggingface.co/blog/assets/188_cinepile2/thumbnail.png"
  },
  {
    "title": "Getting Started with Sentiment Analysis on Twitter",
    "description": "",
    "summary": "Getting Started with Sentiment Analysis on Twitter Sentiment analysis is the automatic process of cl...",
    "pubDate": "Thu, 07 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-twitter",
    "thumbnail": "https://huggingface.co/blog/assets/85_sentiment_analysis_twitter/thumbnail.png"
  },
  {
    "title": "Releasing Swift Transformers: Run On-Device LLMs in Apple Devices",
    "description": "",
    "summary": "Releasing Swift Transformers: Run On-Device LLMs in Apple Devices I have a lot of respect for iOS/Ma...",
    "pubDate": "Tue, 08 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/swift-coreml-llm",
    "thumbnail": "https://huggingface.co/blog/assets/swift-coreml-llm/thumbnail.png"
  },
  {
    "title": "Disrupting a covert Iranian influence operation",
    "description": "We banned accounts linked to a covert Iranian influence operation using ChatGPT to generate website and social media content focused on multiple topics, including the U.S. presidential campaign. We have seen no indication that this content reached a meaningful audience.",
    "summary": "We banned accounts linked to a covert Iranian influence operation using ChatGPT to generate website and social media content focused on multiple topics, including the U.S. presidential campaign. We have seen no indication that this content reached a meaningful audience.",
    "pubDate": "Fri, 16 Aug 2024 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-a-covert-iranian-influence-operation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How NuminaMath Won the 1st AIMO Progress Prize",
    "description": "",
    "summary": "How NuminaMath Won the 1st AIMO Progress Prize This year, Numina and Hugging Face collaborated to co...",
    "pubDate": "Thu, 11 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/winning-aimo-progress-prize",
    "thumbnail": "https://huggingface.co/blog/assets/winning-aimo-progress-prize/thumbnail.png"
  },
  {
    "title": "Putting AI to work at Upwork",
    "description": "Upwork puts AI to work, uniting team members, operations and product development",
    "summary": "Upwork puts AI to work, uniting team members, operations and product development",
    "pubDate": "Tue, 20 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/upwork",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our next-generation model: Gemini 1.5",
    "description": "The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities.",
    "summary": "The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities.",
    "pubDate": "Thu, 15 Feb 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/our-next-generation-model-gemini-15/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/final_gemini_1.5_blog_social_share_800x418.width-1300.png"
  },
  {
    "title": "Comment on NTIA AI Accountability Policy",
    "description": "The National Telecommunications and Information Administration (NTIA) request for comments on AI Accountability policy.",
    "summary": "The National Telecommunications and Information Administration (NTIA) request for comments on AI Accountability policy.",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/comment-on-ntia-ai-accountability-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Optimum-NVIDIA - Unlock blazingly fast LLM inference in just 1 line of code",
    "description": "",
    "summary": "Optimum-NVIDIA on Hugging Face enables blazingly fast LLM inference in just 1 line of code Large Lan...",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-nvidia",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_nvidia/hf_nvidia_banner.png"
  },
  {
    "title": "Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities",
    "description": "arXiv:2507.02125v1 Announce Type: cross Abstract: The blockchain oracle problem, which refers to the challenge of injecting reliable external data into decentralized systems, remains a fundamental limitation to the development of trustless applications. While recent years have seen a proliferation of architectural, cryptographic, and economic strategies to mitigate this issue, no one has yet fully resolved the fundamental question of how a blockchain can gain knowledge about the off-chain world. In this position paper, we critically assess the role artificial intelligence (AI) can play in tackling the oracle problem. Drawing from both academic literature and practitioner implementations, we examine how AI techniques such as anomaly detection, language-based fact extraction, dynamic reputation modeling, and adversarial resistance can enhance oracle systems. We observe that while AI introduces powerful tools for improving data quality, source selection, and system resilience, it cannot eliminate the reliance on unverifiable off-chain inputs. Therefore, this study supports the idea that AI should be understood as a complementary layer of inference and filtering within a broader oracle design, not a substitute for trust assumptions.",
    "summary": "arXiv:2507.02125v1 Announce Type: cross Abstract: The blockchain oracle problem, which refers to the challenge of injecting reliable external data into decentralized systems, remains a fundamental limitation to the development of trustless applications. While recent years have seen a proliferation of architectural, cryptographic, and economic strategies to mitigate this issue, no one has yet fully resolved the fundamental question of how a blockchain can gain knowledge about the off-chain world. In this position paper, we critically assess the role artificial intelligence (AI) can play in tackling the oracle problem. Drawing from both academic literature and practitioner implementations, we examine how AI techniques such as anomaly detection, language-based fact extraction, dynamic reputation modeling, and adversarial resistance can enhance oracle systems. We observe that while AI introduces powerful tools for improving data quality, source selection, and system resilience, it cannot eliminate the reliance on unverifiable off-chain inputs. Therefore, this study supports the idea that AI should be understood as a complementary layer of inference and filtering within a broader oracle design, not a substitute for trust assumptions.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02125",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Awakening Sleeping Beauties at The Met",
    "description": "AI can enrich lives through beauty and creativity, and its artistic potential shines in 'Sleeping Beauties: Reawakening Fashion,' a collaborative exhibit from The Met's Costume Institute.",
    "summary": "AI can enrich lives through beauty and creativity, and its artistic potential shines in 'Sleeping Beauties: Reawakening Fashion,' a collaborative exhibit from The Met's Costume Institute.",
    "pubDate": "Wed, 14 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-met-museum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeMaterial: an open source initiative to accelerate materials discovery and research",
    "description": "",
    "summary": "LeMaterial: an open source initiative to accelerate materials discovery and research Today, we are t...",
    "pubDate": "Tue, 10 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lematerial",
    "thumbnail": "https://huggingface.co/blog/assets/lematerial/thumbnail_lematerial.png"
  },
  {
    "title": "SmolVLA: Efficient Vision-Language-Action Model trained on Lerobot Community Data",
    "description": "",
    "summary": "SmolVLA: Efficient Vision-Language-Action Model trained on Lerobot Community Data üß≠TL;DR Today, we i...",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvla",
    "thumbnail": "https://huggingface.co/blog/assets/smolvla/SmolVLA_thumbnail.png"
  },
  {
    "title": "Spinning Up in Deep RL: Workshop review",
    "description": "On February 2, we held our first Spinning Up Workshop as part of our new education initiative at OpenAI.",
    "summary": "On February 2, we held our first Spinning Up Workshop as part of our new education initiative at OpenAI.",
    "pubDate": "Tue, 26 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spinning-up-in-deep-rl-workshop-review",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome Mixtral - a SOTA Mixture of Experts on Hugging Face",
    "description": "",
    "summary": "Welcome Mixtral - a SOTA Mixture of Experts on Hugging Face Mixtral 8x7b is an exciting large langua...",
    "pubDate": "Mon, 11 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mixtral",
    "thumbnail": "https://huggingface.co/blog/assets/mixtral/thumbnail.jpg"
  },
  {
    "title": "Deprecation of Git Authentication using password",
    "description": "",
    "summary": "Hugging Face Hub: Important Git Authentication Changes Because we are committed to improving the sec...",
    "pubDate": "Fri, 25 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/password-git-deprecation",
    "thumbnail": "https://huggingface.co/blog/assets/password-git-deprecation/thumbnail.png"
  },
  {
    "title": "Improving language model behavior by training on a curated dataset",
    "description": "Our latest research finds we can improve language model behavior with respect to specific behavioral values by fine-tuning on a small, curated¬†dataset.",
    "summary": "Our latest research finds we can improve language model behavior with respect to specific behavioral values by fine-tuning on a small, curated¬†dataset.",
    "pubDate": "Thu, 10 Jun 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-language-model-behavior",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ü§ó PEFT welcomes new merging methods",
    "description": "",
    "summary": "ü§ó PEFT welcomes new merging methods Model merging has quickly become the de-facto standard of pushin...",
    "pubDate": "Mon, 19 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/peft_merging",
    "thumbnail": "https://huggingface.co/blog/assets/peft_merging/thumbnail.png"
  },
  {
    "title": "Learning policy representations in multiagent systems",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 17 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-policy-representations-in-multiagent-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Adversarial attacks on neural network policies",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 Feb 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adversarial-attacks-on-neural-network-policies",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Intelligence Age",
    "description": "We aired our first-ever television ad during the Super Bowl to pique people‚Äôs curiosity and help us all realize how AI can open up new possibilities for us, create more fulfillment in our lives, and make us more productive, just as all the tools that came before AI did for those who came before us.",
    "summary": "We aired our first-ever television ad during the Super Bowl to pique people‚Äôs curiosity and help us all realize how AI can open up new possibilities for us, create more fulfillment in our lives, and make us more productive, just as all the tools that came before AI did for those who came before us.",
    "pubDate": "Sun, 09 Feb 2025 22:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-the-intelligence-age",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "#Exploration: A study of count-based exploration for deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 15 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/exploration",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Effective Explanations for Belief-Desire-Intention Robots: When and What to Explain",
    "description": "arXiv:2507.02016v1 Announce Type: cross Abstract: When robots perform complex and context-dependent tasks in our daily lives, deviations from expectations can confuse users. Explanations of the robot's reasoning process can help users to understand the robot intentions. However, when to provide explanations and what they contain are important to avoid user annoyance. We have investigated user preferences for explanation demand and content for a robot that helps with daily cleaning tasks in a kitchen. Our results show that users want explanations in surprising situations and prefer concise explanations that clearly state the intention behind the confusing action and the contextual factors that were relevant to this decision. Based on these findings, we propose two algorithms to identify surprising actions and to construct effective explanations for Belief-Desire-Intention (BDI) robots. Our algorithms can be easily integrated in the BDI reasoning process and pave the way for better human-robot interaction with context- and user-specific explanations.",
    "summary": "arXiv:2507.02016v1 Announce Type: cross Abstract: When robots perform complex and context-dependent tasks in our daily lives, deviations from expectations can confuse users. Explanations of the robot's reasoning process can help users to understand the robot intentions. However, when to provide explanations and what they contain are important to avoid user annoyance. We have investigated user preferences for explanation demand and content for a robot that helps with daily cleaning tasks in a kitchen. Our results show that users want explanations in surprising situations and prefer concise explanations that clearly state the intention behind the confusing action and the contextual factors that were relevant to this decision. Based on these findings, we propose two algorithms to identify surprising actions and to construct effective explanations for Belief-Desire-Intention (BDI) robots. Our algorithms can be easily integrated in the BDI reasoning process and pave the way for better human-robot interaction with context- and user-specific explanations.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02016",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Cosmopedia: how to create large-scale synthetic data for pre-training Large Language Models",
    "description": "",
    "summary": "Cosmopedia: how to create large-scale synthetic data for pre-training In this blog post, we outline ...",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cosmopedia",
    "thumbnail": "https://huggingface.co/blog/assets/cosmopedia/thumbnail.png"
  },
  {
    "title": "Data is better together",
    "description": "",
    "summary": "Data is better together: Enabling communities to collectively build better datasets together using A...",
    "pubDate": "Mon, 04 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/community-datasets/thumbnail.png"
  },
  {
    "title": "AI learns how vision and sound are connected, without human intervention",
    "description": "This new machine-learning model can match corresponding audio and visual data, which could someday help robots interact in the real world.",
    "summary": "This new machine-learning model can match corresponding audio and visual data, which could someday help robots interact in the real world.",
    "pubDate": "Thu, 22 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-learns-how-vision-and-sound-are-connected-without-human-intervention-0522",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-AV-Learning-01-press.jpg"
  },
  {
    "title": "Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving",
    "description": "arXiv:2507.02726v1 Announce Type: new Abstract: Reasoning remains a challenging task for large language models (LLMs), especially within the logically constrained environment of automated theorem proving (ATP), due to sparse rewards and the vast scale of proofs. These challenges are amplified in benchmarks like PutnamBench, which contains university-level problems requiring complex, multi-step reasoning. To address this, we introduce self-generated goal-conditioned MDPs (sG-MDPs), a new framework in which agents generate and pursue their subgoals based on the evolving proof state. Given this more structured generation of goals, the resulting problem becomes more amenable to search. We then apply Monte Carlo Tree Search (MCTS)-like algorithms to solve the sG-MDP, instantiating our approach in Bourbaki (7B), a modular system that can ensemble multiple 7B LLMs for subgoal generation and tactic synthesis. On PutnamBench, Bourbaki (7B) solves 26 problems, achieving new state-of-the-art results with models at this scale.",
    "summary": "arXiv:2507.02726v1 Announce Type: new Abstract: Reasoning remains a challenging task for large language models (LLMs), especially within the logically constrained environment of automated theorem proving (ATP), due to sparse rewards and the vast scale of proofs. These challenges are amplified in benchmarks like PutnamBench, which contains university-level problems requiring complex, multi-step reasoning. To address this, we introduce self-generated goal-conditioned MDPs (sG-MDPs), a new framework in which agents generate and pursue their subgoals based on the evolving proof state. Given this more structured generation of goals, the resulting problem becomes more amenable to search. We then apply Monte Carlo Tree Search (MCTS)-like algorithms to solve the sG-MDP, instantiating our approach in Bourbaki (7B), a modular system that can ensemble multiple 7B LLMs for subgoal generation and tactic synthesis. On PutnamBench, Bourbaki (7B) solves 26 problems, achieving new state-of-the-art results with models at this scale.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02726",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications",
    "description": "arXiv:2507.02291v1 Announce Type: cross Abstract: Data-driven semantic communication is based on superficial statistical patterns, thereby lacking interpretability and generalization, especially for applications with the presence of unseen data. To address these challenges, we propose a novel knowledge graph-enhanced zero-shot semantic communication (KGZS-SC) network. Guided by the structured semantic information from a knowledge graph-based semantic knowledge base (KG-SKB), our scheme provides generalized semantic representations and enables reasoning for unseen cases. Specifically, the KG-SKB aligns the semantic features in a shared category semantics embedding space and enhances the generalization ability of the transmitter through aligned semantic features, thus reducing communication overhead by selectively transmitting compact visual semantics. At the receiver, zero-shot learning (ZSL) is leveraged to enable direct classification for unseen cases without the demand for retraining or additional computational overhead, thereby enhancing the adaptability and efficiency of the classification process in dynamic or resource-constrained environments. The simulation results conducted on the APY datasets show that the proposed KGZS-SC network exhibits robust generalization and significantly outperforms existing SC frameworks in classifying unseen categories across a range of SNR levels.",
    "summary": "arXiv:2507.02291v1 Announce Type: cross Abstract: Data-driven semantic communication is based on superficial statistical patterns, thereby lacking interpretability and generalization, especially for applications with the presence of unseen data. To address these challenges, we propose a novel knowledge graph-enhanced zero-shot semantic communication (KGZS-SC) network. Guided by the structured semantic information from a knowledge graph-based semantic knowledge base (KG-SKB), our scheme provides generalized semantic representations and enables reasoning for unseen cases. Specifically, the KG-SKB aligns the semantic features in a shared category semantics embedding space and enhances the generalization ability of the transmitter through aligned semantic features, thus reducing communication overhead by selectively transmitting compact visual semantics. At the receiver, zero-shot learning (ZSL) is leveraged to enable direct classification for unseen cases without the demand for retraining or additional computational overhead, thereby enhancing the adaptability and efficiency of the classification process in dynamic or resource-constrained environments. The simulation results conducted on the APY datasets show that the proposed KGZS-SC network exhibits robust generalization and significantly outperforms existing SC frameworks in classifying unseen categories across a range of SNR levels.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02291",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Holistic Tokenizer for Autoregressive Image Generation",
    "description": "arXiv:2507.02358v1 Announce Type: cross Abstract: The vanilla autoregressive image generation model generates visual tokens in a step-by-step fashion, which limits the ability to capture holistic relationships among token sequences. Moreover, most visual tokenizers map local image patches into latent tokens, leading to limited global information. To address this, we introduce textit{Hita}, a novel image tokenizer for autoregressive (AR) image generation. It introduces a holistic-to-local tokenization scheme with learnable holistic queries and local patch tokens. Besides, Hita incorporates two key strategies for improved alignment with the AR generation process: 1) it arranges a sequential structure with holistic tokens at the beginning followed by patch-level tokens while using causal attention to maintain awareness of previous tokens; and 2) before feeding the de-quantized tokens into the decoder, Hita adopts a lightweight fusion module to control information flow to prioritize holistic tokens. Extensive experiments show that Hita accelerates the training speed of AR generators and outperforms those trained with vanilla tokenizers, achieving textbf{2.59 FID} and textbf{281.9 IS} on the ImageNet benchmark. A detailed analysis of the holistic representation highlights its ability to capture global image properties such as textures, materials, and shapes. Additionally, Hita also demonstrates effectiveness in zero-shot style transfer and image in-painting. The code is available at href{https://github.com/CVMI-Lab/Hita}{https://github.com/CVMI-Lab/Hita}",
    "summary": "arXiv:2507.02358v1 Announce Type: cross Abstract: The vanilla autoregressive image generation model generates visual tokens in a step-by-step fashion, which limits the ability to capture holistic relationships among token sequences. Moreover, most visual tokenizers map local image patches into latent tokens, leading to limited global information. To address this, we introduce textit{Hita}, a novel image tokenizer for autoregressive (AR) image generation. It introduces a holistic-to-local tokenization scheme with learnable holistic queries and local patch tokens. Besides, Hita incorporates two key strategies for improved alignment with the AR generation process: 1) it arranges a sequential structure with holistic tokens at the beginning followed by patch-level tokens while using causal attention to maintain awareness of previous tokens; and 2) before feeding the de-quantized tokens into the decoder, Hita adopts a lightweight fusion module to control information flow to prioritize holistic tokens. Extensive experiments show that Hita accelerates the training speed of AR generators and outperforms those trained with vanilla tokenizers, achieving textbf{2.59 FID} and textbf{281.9 IS} on the ImageNet benchmark. A detailed analysis of the holistic representation highlights its ability to capture global image properties such as textures, materials, and shapes. Additionally, Hita also demonstrates effectiveness in zero-shot style transfer and image in-painting. The code is available at href{https://github.com/CVMI-Lab/Hita}{https://github.com/CVMI-Lab/Hita}",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02358",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and Rigorous Evaluation",
    "description": "arXiv:2507.02253v1 Announce Type: new Abstract: Progress in enhancing large language model (LLM) planning and reasoning capabilities is significantly hampered by the bottleneck of scalable, reliable data generation and evaluation. To overcome this, I introduce NL2FLOW, a fully automated system for parametrically generating planning problems - expressed in natural language, a structured intermediate representation, and formal PDDL - and rigorously evaluating the quality of generated plans. I demonstrate NL2FLOW's capabilities by generating a dataset of 2296 problems in the automated workflow generation domain and evaluating multiple open-sourced, instruct-tuned LLMs. My results reveal that the highest performing models achieved 86% success in generating valid plans and 69% in generating optimal plans, specifically for problems with feasible solutions. Regression analysis shows that the influence of problem characteristics on plan generation is contingent on both model and prompt design. Notably, I observed that the highest success rate for translating natural language into a JSON representation of a plan was lower than the highest rate of generating a valid plan directly. This suggests that unnecessarily decomposing the reasoning task - introducing intermediate translation steps - may actually degrade performance, implying a benefit to models capable of reasoning directly from natural language to action. As I scale LLM reasoning to increasingly complex problems, the bottlenecks and sources of error within these systems will inevitably shift. Therefore, a dynamic understanding of these limitations - and the tools to systematically reveal them - will be crucial for unlocking the full potential of LLMs as intelligent problem solvers.",
    "summary": "arXiv:2507.02253v1 Announce Type: new Abstract: Progress in enhancing large language model (LLM) planning and reasoning capabilities is significantly hampered by the bottleneck of scalable, reliable data generation and evaluation. To overcome this, I introduce NL2FLOW, a fully automated system for parametrically generating planning problems - expressed in natural language, a structured intermediate representation, and formal PDDL - and rigorously evaluating the quality of generated plans. I demonstrate NL2FLOW's capabilities by generating a dataset of 2296 problems in the automated workflow generation domain and evaluating multiple open-sourced, instruct-tuned LLMs. My results reveal that the highest performing models achieved 86% success in generating valid plans and 69% in generating optimal plans, specifically for problems with feasible solutions. Regression analysis shows that the influence of problem characteristics on plan generation is contingent on both model and prompt design. Notably, I observed that the highest success rate for translating natural language into a JSON representation of a plan was lower than the highest rate of generating a valid plan directly. This suggests that unnecessarily decomposing the reasoning task - introducing intermediate translation steps - may actually degrade performance, implying a benefit to models capable of reasoning directly from natural language to action. As I scale LLM reasoning to increasingly complex problems, the bottlenecks and sources of error within these systems will inevitably shift. Therefore, a dynamic understanding of these limitations - and the tools to systematically reveal them - will be crucial for unlocking the full potential of LLMs as intelligent problem solvers.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02253",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel",
    "description": "",
    "summary": "Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel In this post we will look ...",
    "pubDate": "Mon, 02 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-fsdp",
    "thumbnail": "https://huggingface.co/blog/assets/62_pytorch_fsdp/fsdp-thumbnail.png"
  },
  {
    "title": "Graph Classification with Transformers",
    "description": "",
    "summary": "Graph classification with Transformers In the previous blog, we explored some of the theoretical asp...",
    "pubDate": "Fri, 14 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphml-classification",
    "thumbnail": "https://huggingface.co/blog/assets/125_intro-to-graphml/thumbnail_classification.png"
  },
  {
    "title": "OpenAI supporters",
    "description": "We‚Äôre excited to welcome new donors to OpenAI.",
    "summary": "We‚Äôre excited to welcome new donors to OpenAI.",
    "pubDate": "Tue, 20 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-supporters",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Run a Chatgpt-like Chatbot on a Single GPU with ROCm",
    "description": "",
    "summary": "Run a Chatgpt-like Chatbot on a Single GPU with ROCm Introduction ChatGPT, OpenAI's groundbreaking l...",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chatbot-amd-gpu",
    "thumbnail": "https://huggingface.co/blog/assets/chatbot-amd-gpu/thumbnail.png"
  },
  {
    "title": "Introducing the Open Ko-LLM Leaderboard: Leading the Korean LLM Evaluation Ecosystem",
    "description": "",
    "summary": "Introducing the Open Ko-LLM Leaderboard: Leading the Korean LLM Evaluation Ecosystem In the fast-evo...",
    "pubDate": "Tue, 20 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-upstage",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_upstage.png"
  },
  {
    "title": "New AI classifier for indicating AI-written text",
    "description": "We‚Äôre launching a classifier trained to distinguish between AI-written and human-written¬†text.",
    "summary": "We‚Äôre launching a classifier trained to distinguish between AI-written and human-written¬†text.",
    "pubDate": "Tue, 31 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "3 Questions: How to help students recognize potential bias in their AI datasets",
    "description": "Courses on developing AI models for health care need to focus more on identifying and addressing bias, says Leo Anthony Celi.",
    "summary": "Courses on developing AI models for health care need to focus more on identifying and addressing bias, says Leo Anthony Celi.",
    "pubDate": "Mon, 02 Jun 2025 10:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/3-questions-recognizing-potential-bias-in-ai-datasets-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_AI-Health-Data-01.jpg"
  },
  {
    "title": "Introducing the AMD 5th Gen EPYC‚Ñ¢ CPU",
    "description": "",
    "summary": "Introducing the AMD 5th Gen EPYC‚Ñ¢ CPU AMD has just unveiled its 5th generation of server-grade EPYC ...",
    "pubDate": "Thu, 10 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-amd-turin",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "Experimenting with Automatic PII Detection on the Hub using Presidio",
    "description": "",
    "summary": "Experimenting with Automatic PII Detection on the Hub using Presidio At Hugging Face, we've noticed ...",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/presidio-pii-detection",
    "thumbnail": "https://huggingface.co/blog/assets/presidio-pii-detection/thumbnail.png"
  },
  {
    "title": "OpenAI Baselines: ACKTR & A2C",
    "description": "We‚Äôre releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic variant of Asynchronous Advantage Actor Critic (A3C) which we‚Äôve found gives equal performance. ACKTR is a more sample-efficient reinforcement learning algorithm than TRPO and A2C, and requires only slightly more computation than A2C per update.",
    "summary": "We‚Äôre releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic variant of Asynchronous Advantage Actor Critic (A3C) which we‚Äôve found gives equal performance. ACKTR is a more sample-efficient reinforcement learning algorithm than TRPO and A2C, and requires only slightly more computation than A2C per update.",
    "pubDate": "Fri, 18 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-acktr-a2c",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling Kubernetes to 7,500 nodes",
    "description": "We‚Äôve scaled Kubernetes clusters to 7,500 nodes, producing a scalable infrastructure for large models like¬†GPT-3,¬†CLIP, and¬†DALL¬∑E, but also for rapid small-scale iterative research such as¬†Scaling Laws for Neural Language Models.",
    "summary": "We‚Äôve scaled Kubernetes clusters to 7,500 nodes, producing a scalable infrastructure for large models like¬†GPT-3,¬†CLIP, and¬†DALL¬∑E, but also for rapid small-scale iterative research such as¬†Scaling Laws for Neural Language Models.",
    "pubDate": "Mon, 25 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-kubernetes-to-7500-nodes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Decision Transformers on Hugging Face ü§ó",
    "description": "",
    "summary": "Introducing Decision Transformers on Hugging Face ü§ó At Hugging Face, we are contributing to the ecos...",
    "pubDate": "Mon, 28 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/decision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/58_decision-transformers/thumbnail.jpg"
  },
  {
    "title": "On Characterizations for Language Generation: Interplay of Hallucinations, Breadth, and Stability",
    "description": "arXiv:2412.18530v2 Announce Type: replace-cross Abstract: We study language generation in the limit - introduced by Kleinberg and Mullainathan [KM24] - building on classical works of Gold [Gol67] and Angluin [Ang79]. [KM24]'s main result is an algorithm for generating from any countable language collection in the limit. While their algorithm eventually generates unseen strings from the target language $K$, it sacrifices coverage or breadth, i.e., its ability to generate a rich set of strings. Recent work introduces different notions of breadth and explores when generation with breadth is possible, leaving a full characterization of these notions open. Our first set of results settles this by characterizing generation for existing notions of breadth and their natural extensions. Interestingly, our lower bounds are very flexible and hold for many performance metrics beyond breadth - for instance, showing that, in general, it is impossible to train generators which achieve a higher perplexity or lower hallucination rate for $K$ compared to other languages. Next, we study language generation with breadth and stable generators - algorithms that eventually stop changing after seeing an arbitrary but finite number of strings - and prove unconditional lower bounds for such generators, strengthening the results of [KMV25] and demonstrating that generation with many existing notions of breadth becomes equally hard, when stability is required. This gives a separation for generation with approximate breadth, between stable and unstable generators, highlighting the rich interplay between breadth, stability, and consistency in language generation.",
    "summary": "arXiv:2412.18530v2 Announce Type: replace-cross Abstract: We study language generation in the limit - introduced by Kleinberg and Mullainathan [KM24] - building on classical works of Gold [Gol67] and Angluin [Ang79]. [KM24]'s main result is an algorithm for generating from any countable language collection in the limit. While their algorithm eventually generates unseen strings from the target language $K$, it sacrifices coverage or breadth, i.e., its ability to generate a rich set of strings. Recent work introduces different notions of breadth and explores when generation with breadth is possible, leaving a full characterization of these notions open. Our first set of results settles this by characterizing generation for existing notions of breadth and their natural extensions. Interestingly, our lower bounds are very flexible and hold for many performance metrics beyond breadth - for instance, showing that, in general, it is impossible to train generators which achieve a higher perplexity or lower hallucination rate for $K$ compared to other languages. Next, we study language generation with breadth and stable generators - algorithms that eventually stop changing after seeing an arbitrary but finite number of strings - and prove unconditional lower bounds for such generators, strengthening the results of [KMV25] and demonstrating that generation with many existing notions of breadth becomes equally hard, when stability is required. This gives a separation for generation with approximate breadth, between stable and unstable generators, highlighting the rich interplay between breadth, stability, and consistency in language generation.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.18530",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "What Neuroscience Can Teach AI About Learning in Continuously Changing Environments",
    "description": "arXiv:2507.02103v1 Announce Type: new Abstract: Modern AI models, such as large language models, are usually trained once on a huge corpus of data, potentially fine-tuned for a specific task, and then deployed with fixed parameters. Their training is costly, slow, and gradual, requiring billions of repetitions. In stark contrast, animals continuously adapt to the ever-changing contingencies in their environments. This is particularly important for social species, where behavioral policies and reward outcomes may frequently change in interaction with peers. The underlying computational processes are often marked by rapid shifts in an animal's behaviour and rather sudden transitions in neuronal population activity. Such computational capacities are of growing importance for AI systems operating in the real world, like those guiding robots or autonomous vehicles, or for agentic AI interacting with humans online. Can AI learn from neuroscience? This Perspective explores this question, integrating the literature on continual and in-context learning in AI with the neuroscience of learning on behavioral tasks with shifting rules, reward probabilities, or outcomes. We will outline an agenda for how specifically insights from neuroscience may inform current developments in AI in this area, and - vice versa - what neuroscience may learn from AI, contributing to the evolving field of NeuroAI.",
    "summary": "arXiv:2507.02103v1 Announce Type: new Abstract: Modern AI models, such as large language models, are usually trained once on a huge corpus of data, potentially fine-tuned for a specific task, and then deployed with fixed parameters. Their training is costly, slow, and gradual, requiring billions of repetitions. In stark contrast, animals continuously adapt to the ever-changing contingencies in their environments. This is particularly important for social species, where behavioral policies and reward outcomes may frequently change in interaction with peers. The underlying computational processes are often marked by rapid shifts in an animal's behaviour and rather sudden transitions in neuronal population activity. Such computational capacities are of growing importance for AI systems operating in the real world, like those guiding robots or autonomous vehicles, or for agentic AI interacting with humans online. Can AI learn from neuroscience? This Perspective explores this question, integrating the literature on continual and in-context learning in AI with the neuroscience of learning on behavioral tasks with shifting rules, reward probabilities, or outcomes. We will outline an agenda for how specifically insights from neuroscience may inform current developments in AI in this area, and - vice versa - what neuroscience may learn from AI, contributing to the evolving field of NeuroAI.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02103",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI and Apple announce partnership",
    "description": "OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences.",
    "summary": "OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences.",
    "pubDate": "Mon, 10 Jun 2024 11:55:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-apple-announce-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ethics and Society Newsletter #6: Building Better AI: The Importance of Data Quality",
    "description": "",
    "summary": "Ethics and Society Newsletter #6: Building Better AI: The Importance of Data Quality In February, Re...",
    "pubDate": "Mon, 24 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-6",
    "thumbnail": "https://huggingface.co/blog/assets/182_ethics-soc-6/thumbnail.png"
  },
  {
    "title": "Planning for AGI and beyond",
    "description": "Our mission is to ensure that artificial general intelligence‚ÄîAI systems that are generally smarter than humans‚Äîbenefits all of¬†humanity.",
    "summary": "Our mission is to ensure that artificial general intelligence‚ÄîAI systems that are generally smarter than humans‚Äîbenefits all of¬†humanity.",
    "pubDate": "Fri, 24 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/planning-for-agi-and-beyond",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reinforcement learning with prediction-based rewards",
    "description": "We‚Äôve developed¬†Random Network Distillation (RND), a prediction-based method for encouraging reinforcement learning agents to explore their environments through curiosity, which for the first time exceeds average human performance on¬†Montezuma‚Äôs Revenge.",
    "summary": "We‚Äôve developed¬†Random Network Distillation (RND), a prediction-based method for encouraging reinforcement learning agents to explore their environments through curiosity, which for the first time exceeds average human performance on¬†Montezuma‚Äôs Revenge.",
    "pubDate": "Wed, 31 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reinforcement-learning-with-prediction-based-rewards",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Melding data, systems, and society",
    "description": "A new book from Professor Munther Dahleh details the creation of a unique kind of transdisciplinary center, uniting many specialties through a common need for data science.",
    "summary": "A new book from Professor Munther Dahleh details the creation of a unique kind of transdisciplinary center, uniting many specialties through a common need for data science.",
    "pubDate": "Tue, 10 Jun 2025 14:25:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/data-systems-and-society-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Data-Systems-Dahleh-book.jpg"
  },
  {
    "title": "Practical 3D Asset Generation: A Step-by-Step Guide",
    "description": "",
    "summary": "Practical 3D Asset Generation: A Step-by-Step Guide Introduction Generative AI has become an instrum...",
    "pubDate": "Tue, 01 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/3d-assets",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail-3d.jpg"
  },
  {
    "title": "Japanese Stable Diffusion",
    "description": "",
    "summary": "Japanese Stable Diffusion Stable Diffusion, developed by CompVis, Stability AI, and LAION, has gener...",
    "pubDate": "Wed, 05 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/japanese-stable-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/106_japanese_stable_diffusion/jsd_thumbnail.png"
  },
  {
    "title": "How we really judge AI",
    "description": "Forget optimists vs. Luddites. Most people evaluate AI based on its perceived capability and their need for personalization.",
    "summary": "Forget optimists vs. Luddites. Most people evaluate AI based on its perceived capability and their need for personalization.",
    "pubDate": "Tue, 10 Jun 2025 11:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/how-we-really-judge-ai-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-AI-Aversion-Appreciation-01.jpg"
  },
  {
    "title": "Hugging Face partners with TruffleHog to Scan for Secrets",
    "description": "",
    "summary": "Hugging Face partners with TruffleHog to Scan for Secrets We're excited to announce our partnership ...",
    "pubDate": "Wed, 04 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trufflesecurity-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/trufflesecurity-partnership/thumbnail.png"
  },
  {
    "title": "Welcome Gemma 2 - Google's new open LLM",
    "description": "",
    "summary": "Welcome Gemma 2 - Google‚Äôs new open LLM Google released Gemma 2, the latest addition to its family o...",
    "pubDate": "Thu, 27 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma2",
    "thumbnail": "https://huggingface.co/blog/assets/gemma2/thumbnail.jpg"
  },
  {
    "title": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "description": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "summary": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "pubDate": "Tue, 10 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-lessons-from-hundreds-of-successful-deployments",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FineVideo: behind the scenes",
    "description": "",
    "summary": "FineVideo: behind the scenes Open video datasets are scarce and therefore slowing down the developme...",
    "pubDate": "Mon, 23 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-video",
    "thumbnail": "https://huggingface.co/blog/assets/186_fine_video/thumbnail.png"
  },
  {
    "title": "Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA",
    "description": "",
    "summary": "Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA LLMs are known to b...",
    "pubDate": "Wed, 24 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/4bit-transformers-bitsandbytes",
    "thumbnail": "https://huggingface.co/blog/assets/96_hf_bitsandbytes_integration/Thumbnail_blue.png"
  },
  {
    "title": "Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search",
    "description": "arXiv:2507.02652v1 Announce Type: new Abstract: Complex information needs in real-world search scenarios demand deep reasoning and knowledge synthesis across diverse sources, which traditional retrieval-augmented generation (RAG) pipelines struggle to address effectively. Current reasoning-based approaches suffer from a fundamental limitation: they use a single model to handle both high-level planning and detailed execution, leading to inefficient reasoning and limited scalability. In this paper, we introduce HiRA, a hierarchical framework that separates strategic planning from specialized execution. Our approach decomposes complex search tasks into focused subtasks, assigns each subtask to domain-specific agents equipped with external tools and reasoning capabilities, and coordinates the results through a structured integration mechanism. This separation prevents execution details from disrupting high-level reasoning while enabling the system to leverage specialized expertise for different types of information processing. Experiments on four complex, cross-modal deep search benchmarks demonstrate that HiRA significantly outperforms state-of-the-art RAG and agent-based systems. Our results show improvements in both answer quality and system efficiency, highlighting the effectiveness of decoupled planning and execution for multi-step information seeking tasks. Our code is available at https://github.com/ignorejjj/HiRA.",
    "summary": "arXiv:2507.02652v1 Announce Type: new Abstract: Complex information needs in real-world search scenarios demand deep reasoning and knowledge synthesis across diverse sources, which traditional retrieval-augmented generation (RAG) pipelines struggle to address effectively. Current reasoning-based approaches suffer from a fundamental limitation: they use a single model to handle both high-level planning and detailed execution, leading to inefficient reasoning and limited scalability. In this paper, we introduce HiRA, a hierarchical framework that separates strategic planning from specialized execution. Our approach decomposes complex search tasks into focused subtasks, assigns each subtask to domain-specific agents equipped with external tools and reasoning capabilities, and coordinates the results through a structured integration mechanism. This separation prevents execution details from disrupting high-level reasoning while enabling the system to leverage specialized expertise for different types of information processing. Experiments on four complex, cross-modal deep search benchmarks demonstrate that HiRA significantly outperforms state-of-the-art RAG and agent-based systems. Our results show improvements in both answer quality and system efficiency, highlighting the effectiveness of decoupled planning and execution for multi-step information seeking tasks. Our code is available at https://github.com/ignorejjj/HiRA.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02652",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GPTs are GPTs: An early look at the labor market impact potential of large language models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpts-are-gpts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ü™Ü Introduction to Matryoshka Embedding Models",
    "description": "",
    "summary": "ü™Ü Introduction to Matryoshka Embedding Models In this blogpost, we will introduce you to the concept...",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/matryoshka",
    "thumbnail": "https://huggingface.co/blog/assets/matryoshka/thumbnail.png"
  },
  {
    "title": "Reimagining secure infrastructure for advanced AI",
    "description": "Securing advanced AI systems will require an evolution in infrastructure security. We‚Äôre calling for research and investment in six security measures that we believe will play key roles in protecting advanced AI. Protecting, exploring, and applying advanced artificial intelligence (AI) is our strategic imperative. OpenAI‚Äôs mission is to deliver positive impact of advanced AI to everything from healthcare to science to education ‚Äì and yes, even to cybersecurity. That work begins with building secure, trustworthy AI systems and protecting the underlying technologies from those who seek to subvert our work to cause harm.",
    "summary": "Securing advanced AI systems will require an evolution in infrastructure security. We‚Äôre calling for research and investment in six security measures that we believe will play key roles in protecting advanced AI. Protecting, exploring, and applying advanced artificial intelligence (AI) is our strategic imperative. OpenAI‚Äôs mission is to deliver positive impact of advanced AI to everything from healthcare to science to education ‚Äì and yes, even to cybersecurity. That work begins with building secure, trustworthy AI systems and protecting the underlying technologies from those who seek to subvert our work to cause harm.",
    "pubDate": "Fri, 03 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reimagining-secure-infrastructure-for-advanced-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Optimizing Bark using ü§ó Transformers",
    "description": "",
    "summary": "Optimizing a Text-To-Speech model using ü§ó Transformers ü§ó Transformers provides many of the latest st...",
    "pubDate": "Wed, 09 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimizing-bark",
    "thumbnail": "https://huggingface.co/blog/assets/bark_optimization/thumbnail.png"
  },
  {
    "title": "How AlphaChip transformed computer chip design",
    "description": "Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world.",
    "summary": "Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world.",
    "pubDate": "Thu, 26 Sep 2024 14:08:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/",
    "thumbnail": "https://lh3.googleusercontent.com/Y_xdq8eqcQlZXYk-MZ2OWPpppmWG6LAQ8DZ-LZFUh8TV5s2TBb3RK_VkMUe-skRzIop5aP6Ot9xPMWFaWmenz55EwxVFCMszpTg2EzsyOd6ftlllGyE=w1200-h630-n-nu"
  },
  {
    "title": "Open R1: How to use OlympicCoder locally for coding?",
    "description": "",
    "summary": "Open R1: How to use OlympicCoder locally for coding Everyone‚Äôs been using Claude and OpenAI as codin...",
    "pubDate": "Thu, 20 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/olympic-coder-lmstudio",
    "thumbnail": "https://huggingface.co/blog/assets/olympic-coder-lmstudio/banner.png"
  },
  {
    "title": "MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion",
    "description": "arXiv:2507.02595v1 Announce Type: cross Abstract: Multiperspective Fusion (MPF) is a novel posttraining alignment framework for large language models (LLMs) developed in response to the growing need for easy bias mitigation. Built on top of the SAGED pipeline, an automated system for constructing bias benchmarks and extracting interpretable baseline distributions, MPF leverages multiperspective generations to expose and align biases in LLM outputs with nuanced, humanlike baselines. By decomposing baseline, such as sentiment distributions from HR professionals, into interpretable perspective components, MPF guides generation through sampling and balancing of responses, weighted by the probabilities obtained in the decomposition. Empirically, we demonstrate its ability to align LLM sentiment distributions with both counterfactual baselines (absolute equality) and the HR baseline (biased for Top Univeristy), resulting in small KL divergence, reduction of calibration error and generalization to unseen questions. This shows that MPF offers a scalable and interpretable method for alignment and bias mitigation, compatible with deployed LLMs and requiring no extensive prompt engineering or finetuning.",
    "summary": "arXiv:2507.02595v1 Announce Type: cross Abstract: Multiperspective Fusion (MPF) is a novel posttraining alignment framework for large language models (LLMs) developed in response to the growing need for easy bias mitigation. Built on top of the SAGED pipeline, an automated system for constructing bias benchmarks and extracting interpretable baseline distributions, MPF leverages multiperspective generations to expose and align biases in LLM outputs with nuanced, humanlike baselines. By decomposing baseline, such as sentiment distributions from HR professionals, into interpretable perspective components, MPF guides generation through sampling and balancing of responses, weighted by the probabilities obtained in the decomposition. Empirically, we demonstrate its ability to align LLM sentiment distributions with both counterfactual baselines (absolute equality) and the HR baseline (biased for Top Univeristy), resulting in small KL divergence, reduction of calibration error and generalization to unseen questions. This shows that MPF offers a scalable and interpretable method for alignment and bias mitigation, compatible with deployed LLMs and requiring no extensive prompt engineering or finetuning.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02595",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Data Is Better Together: A Look Back and Forward",
    "description": "",
    "summary": "Data Is Better Together: A Look Back and Forward For the past few months, we have been working on th...",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dibt",
    "thumbnail": "https://huggingface.co/blog/assets/dibt/thumbnail.png"
  },
  {
    "title": "Probabilistic Time Series Forecasting with ü§ó Transformers",
    "description": "",
    "summary": "Probabilistic Time Series Forecasting with ü§ó Transformers Introduction Time series forecasting is an...",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/time-series-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/118_time-series-transformers/thumbnail.png"
  },
  {
    "title": "New funding to scale the benefits of AI",
    "description": "We are making progress on our mission to ensure that artificial general intelligence benefits all of humanity.",
    "summary": "We are making progress on our mission to ensure that artificial general intelligence benefits all of humanity.",
    "pubDate": "Wed, 02 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scale-the-benefits-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Open Arabic LLM Leaderboard 2",
    "description": "",
    "summary": "The Open Arabic LLM Leaderboard 2 Current status of Arabic LLMs leaderboards The growing availabilit...",
    "pubDate": "Mon, 10 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-arabic-v2",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_arabic.png"
  },
  {
    "title": "GPT-2: 1.5B release",
    "description": "As the final model release of¬†GPT-2‚Äôs¬†staged release, we‚Äôre releasing the largest version (1.5B parameters) of GPT-2 along with¬†code and model weights¬†to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we‚Äôve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we‚Äôre actively continuing the conversation with the AI community on responsible¬†publication.",
    "summary": "As the final model release of¬†GPT-2‚Äôs¬†staged release, we‚Äôre releasing the largest version (1.5B parameters) of GPT-2 along with¬†code and model weights¬†to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we‚Äôve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we‚Äôre actively continuing the conversation with the AI community on responsible¬†publication.",
    "pubDate": "Tue, 05 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-2-1-5b-release",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI‚Äôs commitment to child safety: adopting safety by design principles",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/child-safety-adopting-sbd-principles",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy",
    "description": "arXiv:2507.01352v2 Announce Type: replace-cross Abstract: Despite the critical role of reward models (RMs) in reinforcement learning from human feedback (RLHF), current state-of-the-art open RMs perform poorly on most existing evaluation benchmarks, failing to capture the spectrum of nuanced and sophisticated human preferences. Even approaches that incorporate advanced training techniques have not yielded meaningful performance improvements. We hypothesize that this brittleness stems primarily from limitations in preference datasets, which are often narrowly scoped, synthetically labeled, or lack rigorous quality control. To address these challenges, we present a large-scale preference dataset comprising 40 million preference pairs, named SynPref-40M. To enable data curation at scale, we design a human-AI synergistic two-stage pipeline that leverages the complementary strengths of human annotation quality and AI scalability. In this pipeline, humans provide verified annotations, while large language models perform automatic curation based on human guidance. Training on this preference mixture, we introduce Skywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B parameters, trained on a carefully curated subset of 26 million preference pairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile across a wide range of capabilities, including alignment with human preferences, objective correctness, safety, resistance to stylistic biases, and best-of-N scaling, achieving state-of-the-art performance across seven major reward model benchmarks. Ablation studies confirm that the effectiveness of our approach stems not only from data scale but also from high-quality curation. The Skywork-Reward-V2 series represents substantial progress in open reward models, highlighting the untapped potential of existing preference datasets and demonstrating how human-AI curation synergy can unlock significantly higher data quality.",
    "summary": "arXiv:2507.01352v2 Announce Type: replace-cross Abstract: Despite the critical role of reward models (RMs) in reinforcement learning from human feedback (RLHF), current state-of-the-art open RMs perform poorly on most existing evaluation benchmarks, failing to capture the spectrum of nuanced and sophisticated human preferences. Even approaches that incorporate advanced training techniques have not yielded meaningful performance improvements. We hypothesize that this brittleness stems primarily from limitations in preference datasets, which are often narrowly scoped, synthetically labeled, or lack rigorous quality control. To address these challenges, we present a large-scale preference dataset comprising 40 million preference pairs, named SynPref-40M. To enable data curation at scale, we design a human-AI synergistic two-stage pipeline that leverages the complementary strengths of human annotation quality and AI scalability. In this pipeline, humans provide verified annotations, while large language models perform automatic curation based on human guidance. Training on this preference mixture, we introduce Skywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B parameters, trained on a carefully curated subset of 26 million preference pairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile across a wide range of capabilities, including alignment with human preferences, objective correctness, safety, resistance to stylistic biases, and best-of-N scaling, achieving state-of-the-art performance across seven major reward model benchmarks. Ablation studies confirm that the effectiveness of our approach stems not only from data scale but also from high-quality curation. The Skywork-Reward-V2 series represents substantial progress in open reward models, highlighting the untapped potential of existing preference datasets and demonstrating how human-AI curation synergy can unlock significantly higher data quality.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01352",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tune Llama 2 with DPO",
    "description": "",
    "summary": "Fine-tune Llama 2 with DPO Introduction Reinforcement Learning from Human Feedback (RLHF) has become...",
    "pubDate": "Tue, 08 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dpo-trl",
    "thumbnail": "https://huggingface.co/blog/assets/157_dpo_trl/dpo_thumbnail.png"
  },
  {
    "title": "Introducing ü§ó Accelerate",
    "description": "",
    "summary": "Introducing ü§ó Accelerate ü§ó Accelerate Run your raw PyTorch training scripts on any kind of device. M...",
    "pubDate": "Fri, 16 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-library",
    "thumbnail": "https://huggingface.co/blog/assets/20_accelerate_library/accelerate_diff.png"
  },
  {
    "title": "AI Policy: ü§ó Response to the White House AI Action Plan RFI",
    "description": "",
    "summary": "AI Policy @ü§ó: Response to the White House AI Action Plan RFI On March 14, we submitted Hugging Face'...",
    "pubDate": "Wed, 19 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-action-wh-2025",
    "thumbnail": "https://huggingface.co/blog/assets/151_policy_ntia_rfc/us_policy_thumbnail.png"
  },
  {
    "title": "Bringing the Magic of AI to Mattel‚Äôs Iconic Brands",
    "description": "OpenAI and Mattel are partnering to integrate AI into iconic brands such as Barbie and Hot Wheels, aiming to enhance creative development, streamline workflows, and create new ways for fans to engage.",
    "summary": "OpenAI and Mattel are partnering to integrate AI into iconic brands such as Barbie and Hot Wheels, aiming to enhance creative development, streamline workflows, and create new ways for fans to engage.",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mattels-iconic-brands",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-tuning now available for GPT-4o",
    "description": "Fine-tune custom versions of GPT-4o to increase performance and accuracy for your applications",
    "summary": "Fine-tune custom versions of GPT-4o to increase performance and accuracy for your applications",
    "pubDate": "Tue, 20 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-fine-tuning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing GPTs",
    "description": "You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills.",
    "summary": "You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills.",
    "pubDate": "Mon, 06 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-gpts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Exploring simple optimizations for SDXL",
    "description": "",
    "summary": "Exploring simple optimizations for SDXL Stable Diffusion XL (SDXL) is the latest latent diffusion mo...",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/simple_sdxl_optimizations",
    "thumbnail": "https://huggingface.co/blog/assets/simple_sdxl_optimizations/thumbnail.png"
  },
  {
    "title": "Sora is here",
    "description": "Our video generation model, Sora, is now available to use at sora.com. Users can generate videos up to 1080p resolution, up to 20 sec long, and in widescreen, vertical or square aspect ratios. You can bring your own assets to extend, remix, and blend, or generate entirely new content from text.",
    "summary": "Our video generation model, Sora, is now available to use at sora.com. Users can generate videos up to 1080p resolution, up to 20 sec long, and in widescreen, vertical or square aspect ratios. You can bring your own assets to extend, remix, and blend, or generate entirely new content from text.",
    "pubDate": "Mon, 09 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-is-here",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New compliance and administrative tools for ChatGPT Enterprise",
    "description": "Compliance API integrations, SCIM, and GPT controls to support compliance programs, data security, and user access at scale",
    "summary": "Compliance API integrations, SCIM, and GPT controls to support compliance programs, data security, and user access at scale",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-for-chatgpt-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "StackLLaMA: A hands-on guide to train LLaMA with RLHF",
    "description": "",
    "summary": "StackLLaMA: A hands-on guide to train LLaMA with RLHF Models such as ChatGPT, GPT-4, and Claude are ...",
    "pubDate": "Wed, 05 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stackllama",
    "thumbnail": "https://huggingface.co/blog/assets/138_stackllama/thumbnail.png"
  },
  {
    "title": "Faster Assisted Generation with Dynamic Speculation",
    "description": "",
    "summary": "Faster Assisted Generation with Dynamic Speculation ‚≠ê In this blog post, we‚Äôll explore dynamic specu...",
    "pubDate": "Tue, 08 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dynamic_speculation_lookahead",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "PaliGemma 2 Mix - New Instruction Vision Language Models by Google",
    "description": "",
    "summary": "PaliGemma 2 Mix - New Instruction Vision Language Models by Google TL;DR Last December, Google relea...",
    "pubDate": "Wed, 19 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma2mix",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma2/thumbnail.png"
  },
  {
    "title": "Introducing OpenAI",
    "description": "OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact.",
    "summary": "OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact.",
    "pubDate": "Fri, 11 Dec 2015 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Banque des Territoires (CDC Group) x Polyconseil x Hugging Face: Enhancing a Major French Environmental Program with a Sovereign Data Solution",
    "description": "",
    "summary": "Banque des Territoires (CDC Group) x Polyconseil x Hugging Face: Enhancing a Major French Environmen...",
    "pubDate": "Tue, 09 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sovereign-data-solution-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/cdc_poly_hf.png"
  },
  {
    "title": "FermiNet: Quantum physics and chemistry from first principles",
    "description": "Using deep learning to solve fundamental problems in computational quantum chemistry and explore how matter interacts with light",
    "summary": "Using deep learning to solve fundamental problems in computational quantum chemistry and explore how matter interacts with light",
    "pubDate": "Thu, 22 Aug 2024 19:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ferminet-quantum-physics-and-chemistry-from-first-principles/",
    "thumbnail": "https://lh3.googleusercontent.com/u-LZOO0ynV2UCorbNrUtWS6MJ_sxTfGzObe2YzBt5Grgohx39WcsGiPNOsHwBja8C51lQBclpaovrzUVVQRzj2WpWeM7f7y5eeYt3Dx6l3gxfx9S9g=w1200-h630-n-nu"
  },
  {
    "title": "FFJORD: Free-form continuous dynamics for scalable reversible generative models",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 02 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ffjord",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Finding GPT-4‚Äôs mistakes with GPT-4",
    "description": "CriticGPT, a model based on GPT-4, writes critiques of ChatGPT responses to help human trainers spot mistakes during RLHF",
    "summary": "CriticGPT, a model based on GPT-4, writes critiques of ChatGPT responses to help human trainers spot mistakes during RLHF",
    "pubDate": "Thu, 27 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/finding-gpt4s-mistakes-with-gpt-4",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Train your first Decision Transformer",
    "description": "",
    "summary": "Train your first Decision Transformer In a previous post, we announced the launch of Decision Transf...",
    "pubDate": "Thu, 08 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-decision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/101_train-decision-transformers/thumbnail.gif"
  },
  {
    "title": "Ingredients for robotics research",
    "description": "We‚Äôre releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience Replay, all developed for our research over the past year. We‚Äôve used these environments to train models which work on physical robots. We‚Äôre also releasing a set of requests for robotics research.",
    "summary": "We‚Äôre releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience Replay, all developed for our research over the past year. We‚Äôve used these environments to train models which work on physical robots. We‚Äôre also releasing a set of requests for robotics research.",
    "pubDate": "Mon, 26 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ingredients-for-robotics-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Offline Reinforcement Learning with Penalized Action Noise Injection",
    "description": "arXiv:2507.02356v1 Announce Type: cross Abstract: Offline reinforcement learning (RL) optimizes a policy using only a fixed dataset, making it a practical approach in scenarios where interaction with the environment is costly. Due to this limitation, generalization ability is key to improving the performance of offline RL algorithms, as demonstrated by recent successes of offline RL with diffusion models. However, it remains questionable whether such diffusion models are necessary for highly performing offline RL algorithms, given their significant computational requirements during inference. In this paper, we propose Penalized Action Noise Injection (PANI), a method that simply enhances offline learning by utilizing noise-injected actions to cover the entire action space, while penalizing according to the amount of noise injected. This approach is inspired by how diffusion models have worked in offline RL algorithms. We provide a theoretical foundation for this method, showing that offline RL algorithms with such noise-injected actions solve a modified Markov Decision Process (MDP), which we call the noisy action MDP. PANI is compatible with a wide range of existing off-policy and offline RL algorithms, and despite its simplicity, it demonstrates significant performance improvements across various benchmarks.",
    "summary": "arXiv:2507.02356v1 Announce Type: cross Abstract: Offline reinforcement learning (RL) optimizes a policy using only a fixed dataset, making it a practical approach in scenarios where interaction with the environment is costly. Due to this limitation, generalization ability is key to improving the performance of offline RL algorithms, as demonstrated by recent successes of offline RL with diffusion models. However, it remains questionable whether such diffusion models are necessary for highly performing offline RL algorithms, given their significant computational requirements during inference. In this paper, we propose Penalized Action Noise Injection (PANI), a method that simply enhances offline learning by utilizing noise-injected actions to cover the entire action space, while penalizing according to the amount of noise injected. This approach is inspired by how diffusion models have worked in offline RL algorithms. We provide a theoretical foundation for this method, showing that offline RL algorithms with such noise-injected actions solve a modified Markov Decision Process (MDP), which we call the noisy action MDP. PANI is compatible with a wide range of existing off-policy and offline RL algorithms, and despite its simplicity, it demonstrates significant performance improvements across various benchmarks.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02356",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Pull Requests and Discussions ü•≥",
    "description": "",
    "summary": "Introducing Pull Requests and Discussions ü•≥ We are thrilled to announce the release of our latest co...",
    "pubDate": "Wed, 25 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-update",
    "thumbnail": "https://huggingface.co/blog/assets/76_community_update/thumbnail.png"
  },
  {
    "title": "Experiment with Gemini 2.0 Flash native image generation",
    "description": "Native image output is available in Gemini 2.0 Flash for developers to experiment with in Google AI Studio and the Gemini API.",
    "summary": "Native image output is available in Gemini 2.0 Flash for developers to experiment with in Google AI Studio and the Gemini API.",
    "pubDate": "Wed, 12 Mar 2025 14:58:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/experiment-with-gemini-20-flash-native-image-generation/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-image-generation_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory",
    "description": "arXiv:2507.02618v1 Announce Type: new Abstract: Are Large Language Models (LLMs) a new form of strategic intelligence, able to reason about goals in competitive settings? We present compelling supporting evidence. The Iterated Prisoner's Dilemma (IPD) has long served as a model for studying decision-making. We conduct the first ever series of evolutionary IPD tournaments, pitting canonical strategies (e.g., Tit-for-Tat, Grim Trigger) against agents from the leading frontier AI companies OpenAI, Google, and Anthropic. By varying the termination probability in each tournament (the 'shadow of the future'), we introduce complexity and chance, confounding memorisation. Our results show that LLMs are highly competitive, consistently surviving and sometimes even proliferating in these complex ecosystems. Furthermore, they exhibit distinctive and persistent 'strategic fingerprints': Google's Gemini models proved strategically ruthless, exploiting cooperative opponents and retaliating against defectors, while OpenAI's models remained highly cooperative, a trait that proved catastrophic in hostile environments. Anthropic's Claude emerged as the most forgiving reciprocator, showing remarkable willingness to restore cooperation even after being exploited or successfully defecting. Analysis of nearly 32,000 prose rationales provided by the models reveals that they actively reason about both the time horizon and their opponent's likely strategy, and we demonstrate that this reasoning is instrumental to their decisions. This work connects classic game theory with machine psychology, offering a rich and granular view of algorithmic decision-making under uncertainty.",
    "summary": "arXiv:2507.02618v1 Announce Type: new Abstract: Are Large Language Models (LLMs) a new form of strategic intelligence, able to reason about goals in competitive settings? We present compelling supporting evidence. The Iterated Prisoner's Dilemma (IPD) has long served as a model for studying decision-making. We conduct the first ever series of evolutionary IPD tournaments, pitting canonical strategies (e.g., Tit-for-Tat, Grim Trigger) against agents from the leading frontier AI companies OpenAI, Google, and Anthropic. By varying the termination probability in each tournament (the 'shadow of the future'), we introduce complexity and chance, confounding memorisation. Our results show that LLMs are highly competitive, consistently surviving and sometimes even proliferating in these complex ecosystems. Furthermore, they exhibit distinctive and persistent 'strategic fingerprints': Google's Gemini models proved strategically ruthless, exploiting cooperative opponents and retaliating against defectors, while OpenAI's models remained highly cooperative, a trait that proved catastrophic in hostile environments. Anthropic's Claude emerged as the most forgiving reciprocator, showing remarkable willingness to restore cooperation even after being exploited or successfully defecting. Analysis of nearly 32,000 prose rationales provided by the models reveals that they actively reason about both the time horizon and their opponent's likely strategy, and we demonstrate that this reasoning is instrumental to their decisions. This work connects classic game theory with machine psychology, offering a rich and granular view of algorithmic decision-making under uncertainty.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02618",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Exploring Quantization Backends in Diffusers",
    "description": "",
    "summary": "Exploring Quantization Backends in Diffusers Large diffusion models like Flux (a flow-based text-to-...",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers-quantization/thumbnail.png"
  },
  {
    "title": "Getting Started with Hugging Face Transformers for IPUs with Optimum",
    "description": "",
    "summary": "Getting Started with Hugging Face Transformers for IPUs with Optimum Transformer models have proven ...",
    "pubDate": "Tue, 30 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore-getting-started",
    "thumbnail": "https://huggingface.co/blog/assets/38_getting_started_graphcore/graphcore_1.png"
  },
  {
    "title": "Developing reliable AI tools for healthcare",
    "description": "We‚Äôve published our joint paper with Google Research in Nature Medicine, which proposes CoDoC (Complementarity-driven Deferral-to-Clinical Workflow), an AI system that learns when to rely on predictive AI tools or defer to a clinician for the most accurate interpretation of medical images.",
    "summary": "We‚Äôve published our joint paper with Google Research in Nature Medicine, which proposes CoDoC (Complementarity-driven Deferral-to-Clinical Workflow), an AI system that learns when to rely on predictive AI tools or defer to a clinician for the most accurate interpretation of medical images.",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/codoc-developing-reliable-ai-tools-for-healthcare/",
    "thumbnail": "https://lh3.googleusercontent.com/JCyH0sgVtuYFCB0n7g6f2NMV19yeAgvxQBqcfy9H_-DP_aW3k5h4i0bcZ9_9KCExs7rXRrCaC6s21uK5Udap6tX3zy96zOdn8YcF5WIxAFzUgru6Nw=w1200-h630-n-nu"
  },
  {
    "title": "Llama 3.1 - 405B, 70B & 8B with multilinguality and long context",
    "description": "",
    "summary": "Llama 3.1 - 405B, 70B & 8B with multilinguality and long context Llama 3.1 is out! Today we welcome ...",
    "pubDate": "Tue, 23 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama31",
    "thumbnail": "https://huggingface.co/blog/assets/llama31/thumbnail.jpg"
  },
  {
    "title": "Evolved Policy Gradients",
    "description": "We‚Äôre releasing an experimental metalearning approach called Evolved Policy Gradients, a method that evolves the loss function of learning agents, which can enable fast training on novel tasks. Agents trained with EPG can succeed at basic tasks at test time that were outside their training regime, like learning to navigate to an object on a different side of the room from where it was placed during training.",
    "summary": "We‚Äôre releasing an experimental metalearning approach called Evolved Policy Gradients, a method that evolves the loss function of learning agents, which can enable fast training on novel tasks. Agents trained with EPG can succeed at basic tasks at test time that were outside their training regime, like learning to navigate to an object on a different side of the room from where it was placed during training.",
    "pubDate": "Wed, 18 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolved-policy-gradients",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Using GPT-4o reasoning to transform cancer care",
    "description": "Color Health is working with OpenAI to pioneer a new way of accelerating cancer patients‚Äô access to treatment. Their new Cancer Copilot application uses GPT-4o to identify missing diagnostics and create tailored workup plans, enabling healthcare providers to make evidence-based decisions about cancer screening and treatment.",
    "summary": "Color Health is working with OpenAI to pioneer a new way of accelerating cancer patients‚Äô access to treatment. Their new Cancer Copilot application uses GPT-4o to identify missing diagnostics and create tailored workup plans, enabling healthcare providers to make evidence-based decisions about cancer screening and treatment.",
    "pubDate": "Mon, 17 Jun 2024 04:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/color-health",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI and Microsoft",
    "description": "We‚Äôre working with Microsoft to start running most of our large-scale experiments on Azure.",
    "summary": "We‚Äôre working with Microsoft to start running most of our large-scale experiments on Azure.",
    "pubDate": "Tue, 15 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-microsoft",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Start building with Gemini 2.0 Flash and Flash-Lite",
    "description": "Gemini 2.0 Flash-Lite is now generally available in the Gemini API for production use in Google AI Studio and for enterprise customers on Vertex AI",
    "summary": "Gemini 2.0 Flash-Lite is now generally available in the Gemini API for production use in Google AI Studio and for enterprise customers on Vertex AI",
    "pubDate": "Tue, 25 Feb 2025 18:02:12 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/start-building-with-gemini-20-flash-and-flash-lite/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Flash_Family_meta.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Hello GPT-4o",
    "description": "We‚Äôre announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.",
    "summary": "We‚Äôre announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.",
    "pubDate": "Mon, 13 May 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hello-gpt-4o",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing data residency in Asia",
    "description": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "summary": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "pubDate": "Wed, 07 May 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-data-residency-in-asia",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating over 130,000 Hugging Face models with ONNX Runtime",
    "description": "",
    "summary": "Accelerating over 130,000 Hugging Face models with ONNX Runtime What is ONNX Runtime? ONNX Runtime i...",
    "pubDate": "Wed, 04 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ort-accelerating-hf-models",
    "thumbnail": "https://huggingface.co/blog/assets/ort_accelerating_hf_models/thumbnail.png"
  },
  {
    "title": "Accelerating Document AI",
    "description": "",
    "summary": "Accelerating Document AI Enterprises are full of documents containing knowledge that isn't accessibl...",
    "pubDate": "Mon, 21 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/document-ai",
    "thumbnail": "https://huggingface.co/blog/assets/112_document-ai/thumbnail.png"
  },
  {
    "title": "Generating Human-level Text with Contrastive Search in Transformers ü§ó",
    "description": "",
    "summary": "Generating Human-level Text with Contrastive Search in Transformers ü§ó 1. Introduction: Natural langu...",
    "pubDate": "Tue, 08 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-csearch",
    "thumbnail": "https://huggingface.co/blog/assets/115_introducing_contrastive_search/thumbnail.png"
  },
  {
    "title": "Convert Transformers to ONNX with Hugging Face Optimum",
    "description": "",
    "summary": "Convert Transformers to ONNX with Hugging Face Optimum Hundreds of Transformers experiments and mode...",
    "pubDate": "Wed, 22 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/convert-transformers-to-onnx",
    "thumbnail": "https://huggingface.co/blog/assets/81_convert_transformers_to_onnx/thumbnail.png"
  },
  {
    "title": "Getting Started with Sentiment Analysis using Python",
    "description": "",
    "summary": "Getting Started with Sentiment Analysis using Python Sentiment analysis is the automated process of ...",
    "pubDate": "Wed, 02 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-python",
    "thumbnail": "https://huggingface.co/blog/assets/50_sentiment_python/thumbnail.png"
  },
  {
    "title": "Elon Musk wanted an OpenAI for-profit",
    "description": "Elon Musk‚Äôs latest legal filing against OpenAI marks his fourth attempt in less than a year to reframe his claims. However, his own words and actions speak for themselves‚Äîin 2017, Elon not only wanted, but actually created, a for-profit as OpenAI‚Äôs proposed new structure.",
    "summary": "Elon Musk‚Äôs latest legal filing against OpenAI marks his fourth attempt in less than a year to reframe his claims. However, his own words and actions speak for themselves‚Äîin 2017, Elon not only wanted, but actually created, a for-profit as OpenAI‚Äôs proposed new structure.",
    "pubDate": "Fri, 13 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/elon-musk-wanted-an-openai-for-profit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI GPT-4.5 System Card",
    "description": "We‚Äôre releasing a research preview of OpenAI GPT‚Äë4.5, our largest and most knowledgeable model yet.",
    "summary": "We‚Äôre releasing a research preview of OpenAI GPT‚Äë4.5, our largest and most knowledgeable model yet.",
    "pubDate": "Thu, 27 Feb 2025 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-5-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge",
    "description": "arXiv:2506.21506v2 Announce Type: replace Abstract: Agentic search such as Deep Research systems-where agents autonomously browse the web, synthesize information, and return comprehensive citation-backed answers-represents a major shift in how users interact with web-scale information. While promising greater efficiency and cognitive offloading, the growing complexity and open-endedness of agentic search have outpaced existing evaluation benchmarks and methodologies, which largely assume short search horizons and static answers. In this paper, we introduce Mind2Web 2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that require real-time web browsing and extensive information synthesis, constructed with over 1000 hours of human labor. To address the challenge of evaluating time-varying and complex answers, we propose a novel Agent-as-a-Judge framework. Our method constructs task-specific judge agents based on a tree-structured rubric design to automatically assess both answer correctness and source attribution. We conduct a comprehensive evaluation of ten frontier agentic search systems and human performance, along with a detailed error analysis to draw insights for future development. The best-performing system, OpenAI Deep Research, can already achieve 50-70% of human performance while spending half the time, highlighting its great potential. Altogether, Mind2Web 2 provides a rigorous foundation for developing and benchmarking the next generation of agentic search systems.",
    "summary": "arXiv:2506.21506v2 Announce Type: replace Abstract: Agentic search such as Deep Research systems-where agents autonomously browse the web, synthesize information, and return comprehensive citation-backed answers-represents a major shift in how users interact with web-scale information. While promising greater efficiency and cognitive offloading, the growing complexity and open-endedness of agentic search have outpaced existing evaluation benchmarks and methodologies, which largely assume short search horizons and static answers. In this paper, we introduce Mind2Web 2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that require real-time web browsing and extensive information synthesis, constructed with over 1000 hours of human labor. To address the challenge of evaluating time-varying and complex answers, we propose a novel Agent-as-a-Judge framework. Our method constructs task-specific judge agents based on a tree-structured rubric design to automatically assess both answer correctness and source attribution. We conduct a comprehensive evaluation of ten frontier agentic search systems and human performance, along with a detailed error analysis to draw insights for future development. The best-performing system, OpenAI Deep Research, can already achieve 50-70% of human performance while spending half the time, highlighting its great potential. Altogether, Mind2Web 2 provides a rigorous foundation for developing and benchmarking the next generation of agentic search systems.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21506",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SigLIP 2: A better multilingual vision language encoder",
    "description": "",
    "summary": "SigLIP 2: A better multilingual vision language encoder TL;DR Today Google releases a new and better...",
    "pubDate": "Fri, 21 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/siglip2",
    "thumbnail": "https://huggingface.co/blog/assets/siglip2/thumbnail.png"
  },
  {
    "title": "Fine-Tune Whisper with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune Whisper For Multilingual ASR with ü§ó Transformers In this blog, we present a step-by-step g...",
    "pubDate": "Thu, 03 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-whisper",
    "thumbnail": "https://huggingface.co/blog/assets/111_fine_tune_whisper/thumbnail.jpg"
  },
  {
    "title": "Introducing the LiveCodeBench Leaderboard - Holistic and Contamination-Free Evaluation of Code LLMs",
    "description": "",
    "summary": "Introducing the LiveCodeBench Leaderboard - Holistic and Contamination-Free Evaluation of Code LLMs ...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-livecodebench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "Introducing GPT-4o and more tools to ChatGPT free users",
    "description": "Introducing GPT-4o and more tools to ChatGPT free users We are launching our newest flagship model and making more capabilities available for free in ChatGPT.",
    "summary": "Introducing GPT-4o and more tools to ChatGPT free users We are launching our newest flagship model and making more capabilities available for free in ChatGPT.",
    "pubDate": "Mon, 13 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-and-more-tools-to-chatgpt-free",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building a custom math tutor powered by ChatGPT",
    "description": "ChatGPT and personal tutoring",
    "summary": "ChatGPT and personal tutoring",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/my-dog-the-math-tutor",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An early warning system for novel AI risks",
    "description": "New research proposes a framework for evaluating general-purpose models against novel threats",
    "summary": "New research proposes a framework for evaluating general-purpose models against novel threats",
    "pubDate": "Thu, 25 May 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/an-early-warning-system-for-novel-ai-risks/",
    "thumbnail": "https://lh3.googleusercontent.com/REkFCC8KEOAocMWBwcHOxKM6K2zRs_qpMeUhnmHYkkGSbPPCLRhPDluhoZzx2k6_b4XvgZmhUqeuko9BXZZIPLmGR1q4BycDjLuDFQ5G5FDYPKD0x08=w1200-h630-n-nu"
  },
  {
    "title": "Hugging Face on AMD Instinct MI300 GPU",
    "description": "",
    "summary": "Hugging Face on AMD Instinct MI300 GPU Join the next Hugging Cast on June 6th to ask questions to th...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-amd-mi300",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "Putting ethical principles at the core of research lifecycle",
    "description": "",
    "summary": "Putting ethical principles at the core of the research lifecycle Ethical charter - Multimodal projec...",
    "pubDate": "Thu, 19 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethical-charter-multimodal",
    "thumbnail": "https://huggingface.co/blog/assets/71_ethical-charter/thumbnail.jpg"
  },
  {
    "title": "Announcing The Stargate Project",
    "description": "Announcing The Stargate Project",
    "summary": "Announcing The Stargate Project",
    "pubDate": "Tue, 21 Jan 2025 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/announcing-the-stargate-project",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more",
    "description": "We‚Äôre releasing two updated production-ready Gemini models",
    "summary": "We‚Äôre releasing two updated production-ready Gemini models",
    "pubDate": "Tue, 24 Sep 2024 16:03:03 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini-15-Flash-Social_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Welcome Fireworks.ai on the Hub üéÜ",
    "description": "",
    "summary": "Welcome Fireworks.ai on the Hub üéÜ Following our recent announcement on Inference Providers on the Hu...",
    "pubDate": "Fri, 14 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fireworks-ai",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-fireworks.jpg"
  },
  {
    "title": "The court rejects Elon‚Äôs latest attempt to slow OpenAI down",
    "description": "We welcome the court‚Äôs March 4, 2025, decision rejecting Elon Musk‚Äôs latest attempt to slow down OpenAI for his personal benefit.",
    "summary": "We welcome the court‚Äôs March 4, 2025, decision rejecting Elon Musk‚Äôs latest attempt to slow down OpenAI for his personal benefit.",
    "pubDate": "Fri, 14 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/court-rejects-elon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Establishing Best Practices for Building Rigorous Agentic Benchmarks",
    "description": "arXiv:2507.02825v1 Announce Type: new Abstract: Benchmarks are essential for quantitatively tracking progress in AI. As AI agents become increasingly capable, researchers and practitioners have introduced agentic benchmarks to evaluate agents on complex, real-world tasks. These benchmarks typically measure agent capabilities by evaluating task outcomes via specific reward designs. However, we show that many agentic benchmarks have issues task setup or reward design. For example, SWE-bench Verified uses insufficient test cases, while TAU-bench counts empty responses as successful. Such issues can lead to under- or overestimation agents' performance by up to 100% in relative terms. To make agentic evaluation rigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of guidelines that we synthesized from our benchmark-building experience, a survey of best practices, and previously reported issues. When applied to CVE-Bench, a benchmark with a particularly complex evaluation design, ABC reduces the performance overestimation by 33%.",
    "summary": "arXiv:2507.02825v1 Announce Type: new Abstract: Benchmarks are essential for quantitatively tracking progress in AI. As AI agents become increasingly capable, researchers and practitioners have introduced agentic benchmarks to evaluate agents on complex, real-world tasks. These benchmarks typically measure agent capabilities by evaluating task outcomes via specific reward designs. However, we show that many agentic benchmarks have issues task setup or reward design. For example, SWE-bench Verified uses insufficient test cases, while TAU-bench counts empty responses as successful. Such issues can lead to under- or overestimation agents' performance by up to 100% in relative terms. To make agentic evaluation rigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of guidelines that we synthesized from our benchmark-building experience, a survey of best practices, and previously reported issues. When applied to CVE-Bench, a benchmark with a particularly complex evaluation design, ABC reduces the performance overestimation by 33%.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02825",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deploying the AI Comic Factory using the Inference API",
    "description": "",
    "summary": "Deploying the AI Comic Factory using the Inference API We recently announced Inference for PROs, our...",
    "pubDate": "Mon, 02 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-comic-factory",
    "thumbnail": "https://huggingface.co/blog/assets/165_ai_comic_factory/thumbnail.jpg"
  },
  {
    "title": "DALL¬∑E API now available in public beta",
    "description": "Starting today, developers can begin building apps with the DALL¬∑E API.",
    "summary": "Starting today, developers can begin building apps with the DALL¬∑E API.",
    "pubDate": "Thu, 03 Nov 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-api-now-available-in-public-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Speech Recognition in Unity",
    "description": "",
    "summary": "AI Speech Recognition in Unity Introduction This tutorial guides you through the process of implemen...",
    "pubDate": "Fri, 02 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-asr",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-asr-thumbnail.png"
  },
  {
    "title": "Ethics and Society Newsletter #3: Ethical Openness at Hugging Face",
    "description": "",
    "summary": "Ethics and Society Newsletter #3: Ethical Openness at Hugging Face Mission: Open and Good ML In our ...",
    "pubDate": "Thu, 30 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-3",
    "thumbnail": "https://huggingface.co/blog/assets/137_ethics_soc_3/ethics_3_thumbnail.png"
  },
  {
    "title": "Anatomical Foundation Models for Brain MRIs",
    "description": "arXiv:2408.07079v4 Announce Type: replace-cross Abstract: Deep Learning (DL) in neuroimaging has become increasingly relevant for detecting neurological conditions and neurodegenerative disorders. One of the most predominant biomarkers in neuroimaging is represented by brain age, which has been shown to be a good indicator for different conditions, such as Alzheimer's Disease. Using brain age for weakly supervised pre-training of DL models in transfer learning settings has also recently shown promising results, especially when dealing with data scarcity of different conditions. On the other hand, anatomical information of brain MRIs (e.g. cortical thickness) can provide important information for learning good representations that can be transferred to many downstream tasks. In this work, we propose AnatCL, an anatomical foundation model for brain MRIs that i.) leverages anatomical information in a weakly contrastive learning approach, and ii.) achieves state-of-the-art performances across many different downstream tasks. To validate our approach we consider 12 different downstream tasks for the diagnosis of different conditions such as Alzheimer's Disease, autism spectrum disorder, and schizophrenia. Furthermore, we also target the prediction of 10 different clinical assessment scores using structural MRI data. Our findings show that incorporating anatomical information during pre-training leads to more robust and generalizable representations. Pre-trained models can be found at: https://github.com/EIDOSLAB/AnatCL.",
    "summary": "arXiv:2408.07079v4 Announce Type: replace-cross Abstract: Deep Learning (DL) in neuroimaging has become increasingly relevant for detecting neurological conditions and neurodegenerative disorders. One of the most predominant biomarkers in neuroimaging is represented by brain age, which has been shown to be a good indicator for different conditions, such as Alzheimer's Disease. Using brain age for weakly supervised pre-training of DL models in transfer learning settings has also recently shown promising results, especially when dealing with data scarcity of different conditions. On the other hand, anatomical information of brain MRIs (e.g. cortical thickness) can provide important information for learning good representations that can be transferred to many downstream tasks. In this work, we propose AnatCL, an anatomical foundation model for brain MRIs that i.) leverages anatomical information in a weakly contrastive learning approach, and ii.) achieves state-of-the-art performances across many different downstream tasks. To validate our approach we consider 12 different downstream tasks for the diagnosis of different conditions such as Alzheimer's Disease, autism spectrum disorder, and schizophrenia. Furthermore, we also target the prediction of 10 different clinical assessment scores using structural MRI data. Our findings show that incorporating anatomical information during pre-training leads to more robust and generalizable representations. Pre-trained models can be found at: https://github.com/EIDOSLAB/AnatCL.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.07079",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Security on the path to AGI",
    "description": "At OpenAI, we proactively adapt, including by building comprehensive security measures directly into our infrastructure and models.",
    "summary": "At OpenAI, we proactively adapt, including by building comprehensive security measures directly into our infrastructure and models.",
    "pubDate": "Wed, 26 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/security-on-the-path-to-agi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Holistic Approach to Undesired Content Detection in the Real World",
    "description": "We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation.",
    "summary": "We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-holistic-approach-to-undesired-content-detection-in-the-real-world",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing Evaluation on the Hub",
    "description": "",
    "summary": "Announcing Evaluation on the Hub This project has been archived. If you want to evaluate LLMs on the...",
    "pubDate": "Tue, 28 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eval-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/82_eval_on_the_hub/thumbnail.png"
  },
  {
    "title": "OpenAI Five defeats Dota 2 world champions",
    "description": "OpenAI Five is the first AI to beat the world champions in an esports game, having won two back-to-back games versus the world champion Dota 2 team,¬†OG, at¬†Finals¬†this weekend. Both OpenAI Five and DeepMind‚Äôs AlphaStar had previously beaten good pros privately but lost their live pro matches, making this also the first time an AI has beaten esports pros on¬†livestream.",
    "summary": "OpenAI Five is the first AI to beat the world champions in an esports game, having won two back-to-back games versus the world champion Dota 2 team,¬†OG, at¬†Finals¬†this weekend. Both OpenAI Five and DeepMind‚Äôs AlphaStar had previously beaten good pros privately but lost their live pro matches, making this also the first time an AI has beaten esports pros on¬†livestream.",
    "pubDate": "Mon, 15 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-defeats-dota-2-world-champions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding complex trends with deep research",
    "description": "How OpenAI deep research helps Bain & Company understand complex industry trends.",
    "summary": "How OpenAI deep research helps Bain & Company understand complex industry trends.",
    "pubDate": "Sun, 02 Feb 2025 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Primer on the EU AI Act: What It Means for AI Providers and Deployers",
    "description": "We‚Äôre sharing a preliminary overview of the EU AI Act including upcoming deadlines and requirements, with a particular focus on prohibited and high-risk use cases",
    "summary": "We‚Äôre sharing a preliminary overview of the EU AI Act including upcoming deadlines and requirements, with a particular focus on prohibited and high-risk use cases",
    "pubDate": "Tue, 30 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/a-primer-on-the-eu-ai-act",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2020: Final projects",
    "description": "Our third class of OpenAI Scholars presented their final projects at virtual Demo Day, showcasing their research results from over the past five months.",
    "summary": "Our third class of OpenAI Scholars presented their final projects at virtual Demo Day, showcasing their research results from over the past five months.",
    "pubDate": "Thu, 09 Jul 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2020-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gathering human feedback",
    "description": "RL-Teacher is an open-source implementation of our interface to train AIs via occasional human feedback rather than hand-crafted reward functions. The underlying technique was developed as a step towards safe AI systems, but also applies to reinforcement learning problems with rewards that are hard to specify.",
    "summary": "RL-Teacher is an open-source implementation of our interface to train AIs via occasional human feedback rather than hand-crafted reward functions. The underlying technique was developed as a step towards safe AI systems, but also applies to reinforcement learning problems with rewards that are hard to specify.",
    "pubDate": "Thu, 03 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gathering-human-feedback",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Estonia and OpenAI to bring ChatGPT to schools nationwide",
    "description": "Estonia and OpenAI to bring ChatGPT to schools nationwide. OpenAI will work with the Estonian Government to provide students and teachers in the secondary school system with access to ChatGPT Edu.",
    "summary": "Estonia and OpenAI to bring ChatGPT to schools nationwide. OpenAI will work with the Estonian Government to provide students and teachers in the secondary school system with access to ChatGPT Edu.",
    "pubDate": "Tue, 25 Feb 2025 04:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/estonia-schools-and-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Total noob‚Äôs intro to Hugging Face Transformers",
    "description": "",
    "summary": "Total noob‚Äôs intro to Hugging Face Transformers Welcome to 'A Total Noob‚Äôs Introduction to Hugging F...",
    "pubDate": "Fri, 22 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/noob_intro_transformers",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/guide.png"
  },
  {
    "title": "Faster assisted generation support for Intel Gaudi",
    "description": "",
    "summary": "Faster assisted generation support for Intel Gaudi As model sizes grow, Generative AI implementation...",
    "pubDate": "Tue, 04 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/assisted-generation-support-gaudi",
    "thumbnail": "https://huggingface.co/blog/assets/assisted-generation-support-gaudi/thumbnail.png"
  },
  {
    "title": "Mixture of Reasonings: Teach Large Language Models to Reason with Adaptive Strategies",
    "description": "arXiv:2507.00606v2 Announce Type: replace-cross Abstract: Large language models (LLMs) excel in complex tasks through advanced prompting techniques like Chain-of-Thought (CoT) and Tree-of-Thought (ToT), but their reliance on manually crafted, task-specific prompts limits adaptability and efficiency. We introduce Mixture of Reasoning (MoR), a training framework that embeds diverse reasoning strategies into LLMs for autonomous, task-adaptive reasoning without external prompt engineering. MoR has two phases: Thought Generation, creating reasoning chain templates with models like GPT-4o, and SFT Dataset Construction, pairing templates with benchmark datasets for supervised fine-tuning. Our experiments show that MoR significantly enhances performance, with MoR150 achieving 0.730 (2.2% improvement) using CoT prompting and 0.734 (13.5% improvement) compared to baselines. MoR eliminates the need for task-specific prompts, offering a generalizable solution for robust reasoning across diverse tasks.",
    "summary": "arXiv:2507.00606v2 Announce Type: replace-cross Abstract: Large language models (LLMs) excel in complex tasks through advanced prompting techniques like Chain-of-Thought (CoT) and Tree-of-Thought (ToT), but their reliance on manually crafted, task-specific prompts limits adaptability and efficiency. We introduce Mixture of Reasoning (MoR), a training framework that embeds diverse reasoning strategies into LLMs for autonomous, task-adaptive reasoning without external prompt engineering. MoR has two phases: Thought Generation, creating reasoning chain templates with models like GPT-4o, and SFT Dataset Construction, pairing templates with benchmark datasets for supervised fine-tuning. Our experiments show that MoR significantly enhances performance, with MoR150 achieving 0.730 (2.2% improvement) using CoT prompting and 0.734 (13.5% improvement) compared to baselines. MoR eliminates the need for task-specific prompts, offering a generalizable solution for robust reasoning across diverse tasks.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.00606",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Content filtering methods for music recommendation: A review",
    "description": "arXiv:2507.02282v1 Announce Type: cross Abstract: Recommendation systems have become essential in modern music streaming platforms, shaping how users discover and engage with songs. One common approach in recommendation systems is collaborative filtering, which suggests content based on the preferences of users with similar listening patterns to the target user. However, this method is less effective on media where interactions are sparse. Music is one such medium, since the average user of a music streaming service will never listen to the vast majority of tracks. Due to this sparsity, there are several challenges that have to be addressed with other methods. This review examines the current state of research in addressing these challenges, with an emphasis on the role of content filtering in mitigating biases inherent in collaborative filtering approaches. We explore various methods of song classification for content filtering, including lyrical analysis using Large Language Models (LLMs) and audio signal processing techniques. Additionally, we discuss the potential conflicts between these different analysis methods and propose avenues for resolving such discrepancies.",
    "summary": "arXiv:2507.02282v1 Announce Type: cross Abstract: Recommendation systems have become essential in modern music streaming platforms, shaping how users discover and engage with songs. One common approach in recommendation systems is collaborative filtering, which suggests content based on the preferences of users with similar listening patterns to the target user. However, this method is less effective on media where interactions are sparse. Music is one such medium, since the average user of a music streaming service will never listen to the vast majority of tracks. Due to this sparsity, there are several challenges that have to be addressed with other methods. This review examines the current state of research in addressing these challenges, with an emphasis on the role of content filtering in mitigating biases inherent in collaborative filtering approaches. We explore various methods of song classification for content filtering, including lyrical analysis using Large Language Models (LLMs) and audio signal processing techniques. Additionally, we discuss the potential conflicts between these different analysis methods and propose avenues for resolving such discrepancies.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02282",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The sweet taste of a new idea",
    "description": "Sendhil Mullainathan brings a lifetime of unique perspectives to research in behavioral economics and machine learning.",
    "summary": "Sendhil Mullainathan brings a lifetime of unique perspectives to research in behavioral economics and machine learning.",
    "pubDate": "Mon, 19 May 2025 16:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/sweet-taste-new-idea-sendhil-mullainathan-0519",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-sendhil-Mullainathan.jpg"
  },
  {
    "title": "Put AI to Work for Marketing Teams",
    "description": "Put AI to Work for Marketing Teams",
    "summary": "Put AI to Work for Marketing Teams",
    "pubDate": "Thu, 31 Oct 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-for-marketing-teams",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Codex",
    "description": "Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered by codex-1. With Codex, developers can simultaneously deploy multiple agents to independently handle coding tasks such as writing features, answering questions about your codebase, fixing bugs, and proposing pull requests for review.",
    "summary": "Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered by codex-1. With Codex, developers can simultaneously deploy multiple agents to independently handle coding tasks such as writing features, answering questions about your codebase, fixing bugs, and proposing pull requests for review.",
    "pubDate": "Fri, 16 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-codex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Boosting the customer retail experience with GPT-4o mini",
    "description": "Zalando boosts the customer experience with its Assistant, powered by GPT-4o mini",
    "summary": "Zalando boosts the customer experience with its Assistant, powered by GPT-4o mini",
    "pubDate": "Wed, 11 Dec 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zalando",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Block Sparse Matrices for Smaller and Faster Language Models",
    "description": "",
    "summary": "Block Sparse Matrices for Smaller and Faster Language Models Saving space and time, one zero at a ti...",
    "pubDate": "Thu, 10 Sep 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch_block_sparse",
    "thumbnail": "https://huggingface.co/blog/assets/04_pytorch_block_sparse/thumbnail.png"
  },
  {
    "title": "OpenAI Fellows Winter 2019 & Interns Summer 2019",
    "description": "We are now accepting applications for OpenAI Fellows and Interns for 2019.",
    "summary": "We are now accepting applications for OpenAI Fellows and Interns for 2019.",
    "pubDate": "Tue, 09 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows-interns-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Self-Guided Process Reward Optimization with Redefined Step-wise Advantage for Process Reinforcement Learning",
    "description": "arXiv:2507.01551v2 Announce Type: replace-cross Abstract: Process Reinforcement Learning~(PRL) has demonstrated considerable potential in enhancing the reasoning capabilities of Large Language Models~(LLMs). However, introducing additional process reward models incurs substantial computational overhead, and there is no unified theoretical framework for process-level advantage estimation. To bridge this gap, we propose textbf{S}elf-Guided textbf{P}rocess textbf{R}eward textbf{O}ptimization~(textbf{SPRO}), a novel framework that enables process-aware RL through two key innovations: (1) we first theoretically demonstrate that process rewards can be derived intrinsically from the policy model itself, and (2) we introduce well-defined cumulative process rewards and textbf{M}asked textbf{S}tep textbf{A}dvantage (textbf{MSA}), which facilitates rigorous step-wise action advantage estimation within shared-prompt sampling groups. Our experimental results demonstrate that SPRO outperforms vaniila GRPO with 3.4x higher training efficiency and a 17.5% test accuracy improvement. Furthermore, SPRO maintains a stable and elevated policy entropy throughout training while reducing the average response length by approximately $1/3$, evidencing sufficient exploration and prevention of reward hacking. Notably, SPRO incurs no additional computational overhead compared to outcome-supervised RL methods such as GRPO, which benefit industrial implementation.",
    "summary": "arXiv:2507.01551v2 Announce Type: replace-cross Abstract: Process Reinforcement Learning~(PRL) has demonstrated considerable potential in enhancing the reasoning capabilities of Large Language Models~(LLMs). However, introducing additional process reward models incurs substantial computational overhead, and there is no unified theoretical framework for process-level advantage estimation. To bridge this gap, we propose textbf{S}elf-Guided textbf{P}rocess textbf{R}eward textbf{O}ptimization~(textbf{SPRO}), a novel framework that enables process-aware RL through two key innovations: (1) we first theoretically demonstrate that process rewards can be derived intrinsically from the policy model itself, and (2) we introduce well-defined cumulative process rewards and textbf{M}asked textbf{S}tep textbf{A}dvantage (textbf{MSA}), which facilitates rigorous step-wise action advantage estimation within shared-prompt sampling groups. Our experimental results demonstrate that SPRO outperforms vaniila GRPO with 3.4x higher training efficiency and a 17.5% test accuracy improvement. Furthermore, SPRO maintains a stable and elevated policy entropy throughout training while reducing the average response length by approximately $1/3$, evidencing sufficient exploration and prevention of reward hacking. Notably, SPRO incurs no additional computational overhead compared to outcome-supervised RL methods such as GRPO, which benefit industrial implementation.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01551",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A guide to setting up your own Hugging Face leaderboard: an end-to-end example with Vectara's hallucination leaderboard",
    "description": "",
    "summary": "A guide to setting up your own Hugging Face leaderboard: an end-to-end example with Vectara's halluc...",
    "pubDate": "Fri, 12 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-vectara",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "You could have designed state of the art positional encoding",
    "description": "",
    "summary": "You could have designed state of the art positional encoding Gall's Law A complex system that works ...",
    "pubDate": "Mon, 25 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/designing-positional-encoding",
    "thumbnail": "https://huggingface.co/blog/assets/designing-positional-encoding/thumbnail_posenc.png"
  },
  {
    "title": "Gemini 2.5 Pro Preview: even better coding performance",
    "description": "We‚Äôve seen developers doing amazing things with Gemini 2.5 Pro, so we decided to release an updated version a couple of weeks early to get into developers hands sooner.",
    "summary": "We‚Äôve seen developers doing amazing things with Gemini 2.5 Pro, so we decided to release an updated version a couple of weeks early to get into developers hands sooner.",
    "pubDate": "Tue, 06 May 2025 15:06:55 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-pro-preview-even-better-coding-performance/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini_2-5_pro_claybrook__dev_her.2e16d0ba.fill-1200x600.jpg"
  },
  {
    "title": "Timm ‚ù§Ô∏è Transformers: Use any timm model with transformers",
    "description": "",
    "summary": "Timm ‚ù§Ô∏è Transformers: Use any timm model with transformers Get lightning-fast inference, quick quant...",
    "pubDate": "Thu, 16 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/timm-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/timm-transformers/thumbnail.png"
  },
  {
    "title": "The Falcon has landed in the Hugging Face ecosystem",
    "description": "",
    "summary": "The Falcon has landed in the Hugging Face ecosystem Falcon is a new family of state-of-the-art langu...",
    "pubDate": "Mon, 05 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon",
    "thumbnail": "https://huggingface.co/blog/assets/147_falcon/falcon_thumbnail.jpg"
  },
  {
    "title": "DALL¬∑E: Creating images from text",
    "description": "We‚Äôve trained a neural network called DALL¬∑E that creates images from text captions for a wide range of concepts expressible in natural¬†language.",
    "summary": "We‚Äôve trained a neural network called DALL¬∑E that creates images from text captions for a wide range of concepts expressible in natural¬†language.",
    "pubDate": "Tue, 05 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More",
    "description": "",
    "summary": "Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More At Inceptio...",
    "pubDate": "Tue, 08 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-3c3h-aragen-ifeval",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_3c3h_aragen.png"
  },
  {
    "title": "Evaluating potential cybersecurity threats of advanced AI",
    "description": "Our framework enables cybersecurity experts to identify which defenses are necessary‚Äîand how to prioritize them",
    "summary": "Our framework enables cybersecurity experts to identify which defenses are necessary‚Äîand how to prioritize them",
    "pubDate": "Wed, 02 Apr 2025 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/evaluating-potential-cybersecurity-threats-of-advanced-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/qVftghWK2fcPAfl80FKEGIuxUxYuwlN2guNdIpH5A1nF4KYf5jufujNE7j3zv5uJ3CGPEJ47ec4UaUa1vl8H3rpuEX8jIkdQlXgCEYeGhAAEj3p06IY=w1200-h630-n-nu"
  },
  {
    "title": "Operator System Card",
    "description": "Drawing from OpenAI‚Äôs established safety frameworks, this document highlights our multi-layered approach, including model and product mitigations we‚Äôve implemented to protect against prompt engineering and jailbreaks, protect privacy and security, as well as details our external red teaming efforts, safety evaluations, and ongoing work to further refine these safeguards.",
    "summary": "Drawing from OpenAI‚Äôs established safety frameworks, this document highlights our multi-layered approach, including model and product mitigations we‚Äôve implemented to protect against prompt engineering and jailbreaks, protect privacy and security, as well as details our external red teaming efforts, safety evaluations, and ongoing work to further refine these safeguards.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/operator-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development",
    "description": "arXiv:2507.02602v1 Announce Type: cross Abstract: The increasing importance of Vision-Based Navigation (VBN) algorithms in space missions raises numerous challenges in ensuring their reliability and operational robustness. Sensor faults can lead to inaccurate outputs from navigation algorithms or even complete data processing faults, potentially compromising mission objectives. Artificial Intelligence (AI) offers a powerful solution for detecting such faults, overcoming many of the limitations associated with traditional fault detection methods. However, the primary obstacle to the adoption of AI in this context is the lack of sufficient and representative datasets containing faulty image data. This study addresses these challenges by focusing on an interplanetary exploration mission scenario. A comprehensive analysis of potential fault cases in camera sensors used within the VBN pipeline is presented. The causes and effects of these faults are systematically characterized, including their impact on image quality and navigation algorithm performance, as well as commonly employed mitigation strategies. To support this analysis, a simulation framework is introduced to recreate faulty conditions in synthetically generated images, enabling a systematic and controlled reproduction of faulty data. The resulting dataset of fault-injected images provides a valuable tool for training and testing AI-based fault detection algorithms. The final link to the dataset will be added after an embargo period. For peer-reviewers, this private link is available.",
    "summary": "arXiv:2507.02602v1 Announce Type: cross Abstract: The increasing importance of Vision-Based Navigation (VBN) algorithms in space missions raises numerous challenges in ensuring their reliability and operational robustness. Sensor faults can lead to inaccurate outputs from navigation algorithms or even complete data processing faults, potentially compromising mission objectives. Artificial Intelligence (AI) offers a powerful solution for detecting such faults, overcoming many of the limitations associated with traditional fault detection methods. However, the primary obstacle to the adoption of AI in this context is the lack of sufficient and representative datasets containing faulty image data. This study addresses these challenges by focusing on an interplanetary exploration mission scenario. A comprehensive analysis of potential fault cases in camera sensors used within the VBN pipeline is presented. The causes and effects of these faults are systematically characterized, including their impact on image quality and navigation algorithm performance, as well as commonly employed mitigation strategies. To support this analysis, a simulation framework is introduced to recreate faulty conditions in synthetically generated images, enabling a systematic and controlled reproduction of faulty data. The resulting dataset of fault-injected images provides a valuable tool for training and testing AI-based fault detection algorithms. The final link to the dataset will be added after an embargo period. For peer-reviewers, this private link is available.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02602",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "UCB exploration via Q-ensembles",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 05 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ucb-exploration-via-q-ensembles",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sim-to-real transfer of robotic control with dynamics randomization",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 18 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sim-to-real-transfer-of-robotic-control-with-dynamics-randomization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o1 System Card",
    "description": "This report outlines the safety work carried out prior to releasing OpenAI o1 and o1-mini, including external red teaming and frontier risk evaluations according to our Preparedness Framework.",
    "summary": "This report outlines the safety work carried out prior to releasing OpenAI o1 and o1-mini, including external red teaming and frontier risk evaluations according to our Preparedness Framework.",
    "pubDate": "Thu, 05 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Security Review of Gradio 5",
    "description": "",
    "summary": "A Security Review of Gradio 5 We audited Gradio 5 so that your machine learning apps are safe! In th...",
    "pubDate": "Thu, 10 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-5-security",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-5-security/thumbnail.png"
  },
  {
    "title": "Introducing the Realtime API",
    "description": "Developers can now build fast speech-to-speech experiences into their applications",
    "summary": "Developers can now build fast speech-to-speech experiences into their applications",
    "pubDate": "Tue, 01 Oct 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-realtime-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Supercharged Searching on the Hugging Face Hub",
    "description": "",
    "summary": "Supercharged Searching on the Hugging Face Hub The huggingface_hub library is a lightweight interfac...",
    "pubDate": "Tue, 25 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/searching-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/48_hubsearch/thumbnail.png"
  },
  {
    "title": "Partnership with American Journalism Project to support local news",
    "description": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
    "summary": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
    "pubDate": "Tue, 18 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/partnership-with-american-journalism-project-to-support-local-news",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-4o System Card External Testers Acknowledgements",
    "description": "GPT-4o system card external testers acknowledgements",
    "summary": "GPT-4o system card external testers acknowledgements",
    "pubDate": "Thu, 08 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-system-card/external-testers-acknowledgements",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Scalable and Quantum-Accurate Foundation Model for Biomolecular Force Field via Linearly Tensorized Quadrangle Attention",
    "description": "arXiv:2507.00884v1 Announce Type: cross Abstract: Accurate atomistic biomolecular simulations are vital for disease mechanism understanding, drug discovery, and biomaterial design, but existing simulation methods exhibit significant limitations. Classical force fields are efficient but lack accuracy for transition states and fine conformational details critical in many chemical and biological processes. Quantum Mechanics (QM) methods are highly accurate but computationally infeasible for large-scale or long-time simulations. AI-based force fields (AIFFs) aim to achieve QM-level accuracy with efficiency but struggle to balance many-body modeling complexity, accuracy, and speed, often constrained by limited training data and insufficient validation for generalizability. To overcome these challenges, we introduce LiTEN, a novel equivariant neural network with Tensorized Quadrangle Attention (TQA). TQA efficiently models three- and four-body interactions with linear complexity by reparameterizing high-order tensor features via vector operations, avoiding costly spherical harmonics. Building on LiTEN, LiTEN-FF is a robust AIFF foundation model, pre-trained on the extensive nablaDFT dataset for broad chemical generalization and fine-tuned on SPICE for accurate solvated system simulations. LiTEN achieves state-of-the-art (SOTA) performance across most evaluation subsets of rMD17, MD22, and Chignolin, outperforming leading models such as MACE, NequIP, and EquiFormer. LiTEN-FF enables the most comprehensive suite of downstream biomolecular modeling tasks to date, including QM-level conformer searches, geometry optimization, and free energy surface construction, while offering 10x faster inference than MACE-OFF for large biomolecules (~1000 atoms). In summary, we present a physically grounded, highly efficient framework that advances complex biomolecular modeling, providing a versatile foundation for drug discovery and related applications.",
    "summary": "arXiv:2507.00884v1 Announce Type: cross Abstract: Accurate atomistic biomolecular simulations are vital for disease mechanism understanding, drug discovery, and biomaterial design, but existing simulation methods exhibit significant limitations. Classical force fields are efficient but lack accuracy for transition states and fine conformational details critical in many chemical and biological processes. Quantum Mechanics (QM) methods are highly accurate but computationally infeasible for large-scale or long-time simulations. AI-based force fields (AIFFs) aim to achieve QM-level accuracy with efficiency but struggle to balance many-body modeling complexity, accuracy, and speed, often constrained by limited training data and insufficient validation for generalizability. To overcome these challenges, we introduce LiTEN, a novel equivariant neural network with Tensorized Quadrangle Attention (TQA). TQA efficiently models three- and four-body interactions with linear complexity by reparameterizing high-order tensor features via vector operations, avoiding costly spherical harmonics. Building on LiTEN, LiTEN-FF is a robust AIFF foundation model, pre-trained on the extensive nablaDFT dataset for broad chemical generalization and fine-tuned on SPICE for accurate solvated system simulations. LiTEN achieves state-of-the-art (SOTA) performance across most evaluation subsets of rMD17, MD22, and Chignolin, outperforming leading models such as MACE, NequIP, and EquiFormer. LiTEN-FF enables the most comprehensive suite of downstream biomolecular modeling tasks to date, including QM-level conformer searches, geometry optimization, and free energy surface construction, while offering 10x faster inference than MACE-OFF for large biomolecules (~1000 atoms). In summary, we present a physically grounded, highly efficient framework that advances complex biomolecular modeling, providing a versatile foundation for drug discovery and related applications.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.00884",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Celebrating an academic-industry collaboration to advance vehicle technology",
    "description": "MIT Advanced Vehicle Technology Consortium marks a decade of developing data that improve understanding of how drivers use and respond to increasingly sophisticated automotive features.",
    "summary": "MIT Advanced Vehicle Technology Consortium marks a decade of developing data that improve understanding of how drivers use and respond to increasingly sophisticated automotive features.",
    "pubDate": "Mon, 16 Jun 2025 14:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/celebrating-academic-industry-collaboration-advance-vehicle-technology-0616",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-AVT-conference.jpg"
  },
  {
    "title": "Porting fairseq wmt19 translation system to transformers",
    "description": "",
    "summary": "Porting fairseq wmt19 translation system to transformers A guest blog post by Stas Bekman This artic...",
    "pubDate": "Tue, 03 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/porting-fsmt",
    "thumbnail": "https://huggingface.co/blog/assets/07_porting_fsmt/thumbnail.png"
  },
  {
    "title": "Improved Techniques for Training Consistency Models",
    "description": "Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training.",
    "summary": "Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improved-techniques-for-training-consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The power of continuous learning",
    "description": "Lilian Weng works on Applied AI Research at OpenAI.",
    "summary": "Lilian Weng works on Applied AI Research at OpenAI.",
    "pubDate": "Fri, 23 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-power-of-continuous-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action",
    "description": "",
    "summary": "Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action Hugging Face provides a Hub platf...",
    "pubDate": "Wed, 09 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-deepfloydif-using-bentoml",
    "thumbnail": "https://huggingface.co/blog/assets/deploy-deepfloydif-using-bentoml/thumbnail.png"
  },
  {
    "title": "Driving growth and ‚ÄòWOW‚Äô moments with OpenAI",
    "description": "LY Corporation: Driving growth and ‚ÄòWOW‚Äô moments with OpenAI",
    "summary": "LY Corporation: Driving growth and ‚ÄòWOW‚Äô moments with OpenAI",
    "pubDate": "Wed, 12 Mar 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ly-corporation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection",
    "description": "arXiv:2507.02398v1 Announce Type: cross Abstract: We introduce a deepfake video detection approach that exploits pixel-wise temporal inconsistencies, which traditional spatial frequency-based detectors often overlook. Traditional detectors represent temporal information merely by stacking spatial frequency spectra across frames, resulting in the failure to detect temporal artifacts in the pixel plane. Our approach performs a 1D Fourier transform on the time axis for each pixel, extracting features highly sensitive to temporal inconsistencies, especially in areas prone to unnatural movements. To precisely locate regions containing the temporal artifacts, we introduce an attention proposal module trained in an end-to-end manner. Additionally, our joint transformer module effectively integrates pixel-wise temporal frequency features with spatio-temporal context features, expanding the range of detectable forgery artifacts. Our framework represents a significant advancement in deepfake video detection, providing robust performance across diverse and challenging detection scenarios.",
    "summary": "arXiv:2507.02398v1 Announce Type: cross Abstract: We introduce a deepfake video detection approach that exploits pixel-wise temporal inconsistencies, which traditional spatial frequency-based detectors often overlook. Traditional detectors represent temporal information merely by stacking spatial frequency spectra across frames, resulting in the failure to detect temporal artifacts in the pixel plane. Our approach performs a 1D Fourier transform on the time axis for each pixel, extracting features highly sensitive to temporal inconsistencies, especially in areas prone to unnatural movements. To precisely locate regions containing the temporal artifacts, we introduce an attention proposal module trained in an end-to-end manner. Additionally, our joint transformer module effectively integrates pixel-wise temporal frequency features with spatio-temporal context features, expanding the range of detectable forgery artifacts. Our framework represents a significant advancement in deepfake video detection, providing robust performance across diverse and challenging detection scenarios.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02398",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Outbound coordinated vulnerability disclosure policy",
    "description": "Outbound coordinated vulnerability disclosure policy",
    "summary": "Outbound coordinated vulnerability disclosure policy",
    "pubDate": "Mon, 09 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/policies/outbound-coordinated-disclosure-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing GPT-4.5",
    "description": "We‚Äôre releasing a research preview of GPT‚Äë4.5‚Äîour largest and best model for chat yet. GPT‚Äë4.5 is a step forward in scaling up pre-training and post-training.",
    "summary": "We‚Äôre releasing a research preview of GPT‚Äë4.5‚Äîour largest and best model for chat yet. GPT‚Äë4.5 is a step forward in scaling up pre-training and post-training.",
    "pubDate": "Thu, 27 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-gpt-4-5",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MuseNet",
    "description": "We‚Äôve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose unsupervised technology as¬†GPT-2, a large-scale¬†transformer¬†model trained to predict the next token in a sequence, whether audio or¬†text.",
    "summary": "We‚Äôve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose unsupervised technology as¬†GPT-2, a large-scale¬†transformer¬†model trained to predict the next token in a sequence, whether audio or¬†text.",
    "pubDate": "Thu, 25 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/musenet",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Creating Privacy Preserving AI with Substra",
    "description": "",
    "summary": "Creating Privacy Preserving AI with Substra With the recent rise of generative techniques, machine l...",
    "pubDate": "Wed, 12 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/owkin-substra",
    "thumbnail": "https://huggingface.co/blog/assets/139_owkin-substra/thumbnail.png"
  },
  {
    "title": "Transfer of adversarial robustness between perturbation types",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 03 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/transfer-of-adversarial-robustness-between-perturbation-types",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "HCVR: A Hybrid Approach with Correlation-aware Voting Rules for Feature Selection",
    "description": "arXiv:2507.02073v1 Announce Type: new Abstract: In this paper, we propose HCVR (Hybrid approach with Correlation-aware Voting Rules), a lightweight rule-based feature selection method that combines Parameter-to-Parameter (P2P) and Parameter-to-Target (P2T) correlations to eliminate redundant features and retain relevant ones. This method is a hybrid of non-iterative and iterative filtering approaches for dimensionality reduction. It is a greedy method, which works by backward elimination, eliminating possibly multiple features at every step. The rules contribute to voting for features, and a decision to keep or discard is made by majority voting. The rules make use of correlation thresholds between every pair of features, and between features and the target. We provide the results from the application of HCVR to the SPAMBASE dataset. The results showed improvement performance as compared to traditional non-iterative (CFS, mRMR and MI) and iterative (RFE, SFS and Genetic Algorithm) techniques. The effectiveness was assessed based on the performance of different classifiers after applying filtering.",
    "summary": "arXiv:2507.02073v1 Announce Type: new Abstract: In this paper, we propose HCVR (Hybrid approach with Correlation-aware Voting Rules), a lightweight rule-based feature selection method that combines Parameter-to-Parameter (P2P) and Parameter-to-Target (P2T) correlations to eliminate redundant features and retain relevant ones. This method is a hybrid of non-iterative and iterative filtering approaches for dimensionality reduction. It is a greedy method, which works by backward elimination, eliminating possibly multiple features at every step. The rules contribute to voting for features, and a decision to keep or discard is made by majority voting. The rules make use of correlation thresholds between every pair of features, and between features and the target. We provide the results from the application of HCVR to the SPAMBASE dataset. The results showed improvement performance as compared to traditional non-iterative (CFS, mRMR and MI) and iterative (RFE, SFS and Genetic Algorithm) techniques. The effectiveness was assessed based on the performance of different classifiers after applying filtering.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02073",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing GPT-4.1 in the API",
    "description": "Introducing GPT-4.1 in the API‚Äîa new family of models with across-the-board improvements, including major gains in coding, instruction following, and long-context understanding. We‚Äôre also releasing our first nano model. Available to developers worldwide starting today.",
    "summary": "Introducing GPT-4.1 in the API‚Äîa new family of models with across-the-board improvements, including major gains in coding, instruction following, and long-context understanding. We‚Äôre also releasing our first nano model. Available to developers worldwide starting today.",
    "pubDate": "Mon, 14 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-1",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Data-driven beauty and creativity with ChatGPT",
    "description": "Data-driven beauty: How The Est√©e Lauder Companies unlocks insights with ChatGPT",
    "summary": "Data-driven beauty: How The Est√©e Lauder Companies unlocks insights with ChatGPT",
    "pubDate": "Wed, 13 Nov 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/estee-lauder",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SynthID Detector ‚Äî a new portal to help identify AI-generated content",
    "description": "Learn about the new SynthID Detector portal we announced at I/O to help people understand how the content they see online was generated.",
    "summary": "Learn about the new SynthID Detector portal we announced at I/O to help people understand how the content they see online was generated.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/synthid-detector--a-new-portal-to-help-identify-ai-generated-content/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Gemini_MOD_HEADER.width-1300.jpg"
  },
  {
    "title": "Active Learning with AutoNLP and Prodigy",
    "description": "",
    "summary": "Active Learning with AutoNLP and Prodigy Active learning in the context of Machine Learning is a pro...",
    "pubDate": "Thu, 23 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autonlp-prodigy",
    "thumbnail": "https://huggingface.co/blog/assets/43_autonlp_prodigy/thumbnail.png"
  },
  {
    "title": "Releasing Outlines-core 0.1.0: structured generation in Rust and Python",
    "description": "",
    "summary": "Releasing Outlines-core 0.1.0: structured generation in Rust and Python dottxt and Hugging Face are ...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/outlines-core",
    "thumbnail": "https://huggingface.co/blog/assets/outlines-core/thumbnail.gif"
  },
  {
    "title": "DALL¬∑E now available without waitlist",
    "description": "New users can start creating straight away. Lessons learned from deployment and improvements to our safety systems make wider availability possible.",
    "summary": "New users can start creating straight away. Lessons learned from deployment and improvements to our safety systems make wider availability possible.",
    "pubDate": "Wed, 28 Sep 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-now-available-without-waitlist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Short Summary of Chinese AI Global Expansion",
    "description": "",
    "summary": "A Short Summary of Chinese AI Global Expansion In the early 15th century, Zheng He (also known as Ch...",
    "pubDate": "Thu, 03 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chinese-ai-expansion",
    "thumbnail": "https://huggingface.co/blog/assets/chinese-ai-expansion/thumbnail.png"
  },
  {
    "title": "How Hugging Face Accelerated Development of Witty Works Writing Assistant",
    "description": "",
    "summary": "How Hugging Face Accelerated Development of Witty Works Writing Assistant The Success Story of Witty...",
    "pubDate": "Wed, 01 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/classification-use-cases",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/witty-works.png"
  },
  {
    "title": "The Google for Startups Gemini kit is here",
    "description": "A blonde woman wearing a black top and red skit looks at the camera, describing the benefits of the Google for Startups Gemini Kit.",
    "summary": "A blonde woman wearing a black top and red skit looks at the camera, describing the benefits of the Google for Startups Gemini Kit.",
    "pubDate": "Thu, 26 Jun 2025 12:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/entrepreneurs/google-for-startups-gemini-ai-kit/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Paige_Thumbnail.width-1300.png"
  },
  {
    "title": "OpenAI and the CSU system bring AI to 500,000 students & faculty",
    "description": "The largest deployment of ChatGPT to date will expand the use of AI in education and help the United States build an AI-ready workforce.",
    "summary": "The largest deployment of ChatGPT to date will expand the use of AI in education and help the United States build an AI-ready workforce.",
    "pubDate": "Tue, 04 Feb 2025 11:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-the-csu-system",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "4M Models Scanned: Protect AI + Hugging Face 6 Months In",
    "description": "",
    "summary": "4M Models Scanned: Protect AI + Hugging Face 6 Months In Hugging Face and Protect AI partnered in Oc...",
    "pubDate": "Mon, 14 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pai-6-month",
    "thumbnail": "https://huggingface.co/blog/assets/pai-6-month/thumbnail.png"
  },
  {
    "title": "Learning to reason with LLMs",
    "description": "We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before it answers‚Äîit can produce a long internal chain of thought before responding to the user.",
    "summary": "We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before it answers‚Äîit can produce a long internal chain of thought before responding to the user.",
    "pubDate": "Thu, 12 Sep 2024 10:02:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-reason-with-llms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Illuminant and light direction estimation using Wasserstein distance method",
    "description": "arXiv:2503.05802v2 Announce Type: replace-cross Abstract: Illumination estimation remains a pivotal challenge in image processing, particularly for robotics, where robust environmental perception is essential under varying lighting conditions. Traditional approaches, such as RGB histograms and GIST descriptors, often fail in complex scenarios due to their sensitivity to illumination changes. This study introduces a novel method utilizing the Wasserstein distance, rooted in optimal transport theory, to estimate illuminant and light direction in images. Experiments on diverse images indoor scenes, black-and-white photographs, and night images demonstrate the method's efficacy in detecting dominant light sources and estimating their directions, outperforming traditional statistical methods in complex lighting environments. The approach shows promise for applications in light source localization, image quality assessment, and object detection enhancement. Future research may explore adaptive thresholding and integrate gradient analysis to enhance accuracy, offering a scalable solution for real-world illumination challenges in robotics and beyond.",
    "summary": "arXiv:2503.05802v2 Announce Type: replace-cross Abstract: Illumination estimation remains a pivotal challenge in image processing, particularly for robotics, where robust environmental perception is essential under varying lighting conditions. Traditional approaches, such as RGB histograms and GIST descriptors, often fail in complex scenarios due to their sensitivity to illumination changes. This study introduces a novel method utilizing the Wasserstein distance, rooted in optimal transport theory, to estimate illuminant and light direction in images. Experiments on diverse images indoor scenes, black-and-white photographs, and night images demonstrate the method's efficacy in detecting dominant light sources and estimating their directions, outperforming traditional statistical methods in complex lighting environments. The approach shows promise for applications in light source localization, image quality assessment, and object detection enhancement. Future research may explore adaptive thresholding and integrate gradient analysis to enhance accuracy, offering a scalable solution for real-world illumination challenges in robotics and beyond.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.05802",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "What Makes a Dialog Agent Useful?",
    "description": "",
    "summary": "What Makes a Dialog Agent Useful? The techniques behind ChatGPT: RLHF, IFT, CoT, Red teaming, and mo...",
    "pubDate": "Tue, 24 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dialog-agents",
    "thumbnail": "https://huggingface.co/blog/assets/dialog-agents/thumbnail.png"
  },
  {
    "title": "Goodbye cold boot - how we made LoRA inference 300% faster",
    "description": "",
    "summary": "Goodbye cold boot - how we made LoRA Inference 300% faster tl;dr: We swap the Stable Diffusion LoRA ...",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lora-adapters-dynamic-loading",
    "thumbnail": "https://huggingface.co/blog/assets/171_load_lora_adapters/thumbnail3.png"
  },
  {
    "title": "Introducing Gemma 3",
    "description": "The most capable model you can run on a single GPU or TPU.",
    "summary": "The most capable model you can run on a single GPU or TPU.",
    "pubDate": "Wed, 12 Mar 2025 08:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemma-3/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemma3_KeywordBlog_RD3_V01b_SocialShare.width-1300.png"
  },
  {
    "title": "OpenAI Baselines: DQN",
    "description": "We‚Äôre open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with performance on par with published results. We‚Äôll release the algorithms over upcoming months; today‚Äôs release includes DQN and three of its variants.",
    "summary": "We‚Äôre open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with performance on par with published results. We‚Äôll release the algorithms over upcoming months; today‚Äôs release includes DQN and three of its variants.",
    "pubDate": "Wed, 24 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-dqn",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making sense of this mess",
    "description": "",
    "summary": "Making sense of this mess When I joined Hugging Face nearly 3 years ago, the Transformers documentat...",
    "pubDate": "Fri, 07 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-docs-redesign",
    "thumbnail": "https://huggingface.co/blog/assets/transformers-docs-redesign/thumbnail.png"
  },
  {
    "title": "Coding with OpenAI o1",
    "description": "Scott Wu, CEO and Co-Founder of Cognition, explains how OpenAI o1 makes coding decisions in a more human-like way.",
    "summary": "Scott Wu, CEO and Co-Founder of Cognition, explains how OpenAI o1 makes coding decisions in a more human-like way.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-coding",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Embodied AI Agents: Modeling the World",
    "description": "arXiv:2506.22355v2 Announce Type: replace Abstract: This paper describes our research on AI agents embodied in visual, virtual or physical forms, enabling them to interact with both users and their environments. These agents, which include virtual avatars, wearable devices, and robots, are designed to perceive, learn and act within their surroundings, which makes them more similar to how humans learn and interact with the environments as compared to disembodied agents. We propose that the development of world models is central to reasoning and planning of embodied AI agents, allowing these agents to understand and predict their environment, to understand user intentions and social contexts, thereby enhancing their ability to perform complex tasks autonomously. World modeling encompasses the integration of multimodal perception, planning through reasoning for action and control, and memory to create a comprehensive understanding of the physical world. Beyond the physical world, we also propose to learn the mental world model of users to enable better human-agent collaboration.",
    "summary": "arXiv:2506.22355v2 Announce Type: replace Abstract: This paper describes our research on AI agents embodied in visual, virtual or physical forms, enabling them to interact with both users and their environments. These agents, which include virtual avatars, wearable devices, and robots, are designed to perceive, learn and act within their surroundings, which makes them more similar to how humans learn and interact with the environments as compared to disembodied agents. We propose that the development of world models is central to reasoning and planning of embodied AI agents, allowing these agents to understand and predict their environment, to understand user intentions and social contexts, thereby enhancing their ability to perform complex tasks autonomously. World modeling encompasses the integration of multimodal perception, planning through reasoning for action and control, and memory to create a comprehensive understanding of the physical world. Beyond the physical world, we also propose to learn the mental world model of users to enable better human-agent collaboration.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22355",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Klarna's AI assistant does the work of 700 full-time agents",
    "description": "Klarna is using AI to revolutionize personal shopping, customer service, and employee productivity.",
    "summary": "Klarna is using AI to revolutionize personal shopping, customer service, and employee productivity.",
    "pubDate": "Fri, 05 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/klarna",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Machine Learning Demos on arXiv",
    "description": "",
    "summary": "Hugging Face Machine Learning Demos on arXiv We‚Äôre very excited to announce that Hugging Face has co...",
    "pubDate": "Thu, 17 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arxiv",
    "thumbnail": "https://huggingface.co/blog/assets/arxiv/thumbnail.png"
  },
  {
    "title": "Scaling up BERT-like model Inference on modern CPU - Part 2",
    "description": "",
    "summary": "Scaling up BERT-like model Inference on modern CPU - Part 2 Introduction: Using Intel Software to Op...",
    "pubDate": "Thu, 04 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-cpu-scaling-part-2",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Bringing serverless GPU inference to Hugging Face users",
    "description": "",
    "summary": "Bringing serverless GPU inference to Hugging Face users Today, we are thrilled to announce the launc...",
    "pubDate": "Tue, 02 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cloudflare-workers-ai",
    "thumbnail": "https://huggingface.co/blog/assets/cloudflare-workers-ai/thumbnail.jpg"
  },
  {
    "title": "Train your ControlNet with diffusers",
    "description": "",
    "summary": "Train your ControlNet with diffusers üß® Introduction ControlNet is a neural network structure that al...",
    "pubDate": "Fri, 24 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-your-controlnet",
    "thumbnail": "https://huggingface.co/blog/assets/136_train-your-controlnet/thumbnail.png"
  },
  {
    "title": "Accelerating Stable Diffusion XL Inference with JAX on Cloud TPU v5e",
    "description": "",
    "summary": "Accelerating Stable Diffusion XL Inference with JAX on Cloud TPU v5e Generative AI models, such as S...",
    "pubDate": "Tue, 03 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_jax",
    "thumbnail": "https://huggingface.co/blog/assets/sdxl-jax/thumbnail.jpg"
  },
  {
    "title": "TGI Multi-LoRA: Deploy Once, Serve 30 Models",
    "description": "",
    "summary": "TGI Multi-LoRA: Deploy Once, Serve 30 models Are you tired of the complexity and expense of managing...",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/multi-lora-serving",
    "thumbnail": "https://huggingface.co/blog/assets/multi-lora-serving/thumbnail.png"
  },
  {
    "title": "OpenAI and Los Alamos National Laboratory announce research partnership",
    "description": "OpenAI and Los Alamos National Laboratory are working to develop safety evaluations to assess and measure biological capabilities and risks associated with frontier models.",
    "summary": "OpenAI and Los Alamos National Laboratory are working to develop safety evaluations to assess and measure biological capabilities and risks associated with frontier models.",
    "pubDate": "Wed, 10 Jul 2024 06:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-los-alamos-national-laboratory-work-together",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hindsight Experience Replay",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 05 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hindsight-experience-replay",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI o1",
    "description": "Introducing OpenAI o1",
    "summary": "Introducing OpenAI o1",
    "pubDate": "Thu, 12 Sep 2024 10:03:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-o1-preview",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Nonlinear computation in deep linear networks",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 29 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonlinear-computation-in-deep-linear-networks",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Search Live: Talk, listen and explore in real time with AI Mode",
    "description": "Logos for AI Mode in Search and Search Live in front of a black background",
    "summary": "Logos for AI Mode in Search and Search Live in front of a black background",
    "pubDate": "Wed, 18 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/search-live-ai-mode/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SearchLive_SS.width-1300.png"
  },
  {
    "title": "Machine Learning Experts - Lewis Tunstall Interview",
    "description": "",
    "summary": "Machine Learning Experts - Lewis Tunstall ü§ó Welcome to Machine Learning Experts - Lewis Tunstall Hey...",
    "pubDate": "Wed, 13 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lewis-tunstall-interview",
    "thumbnail": "https://huggingface.co/blog/assets/60_lewis_tunstall_interview/thumbnail.png"
  },
  {
    "title": "Google Cloud TPUs made available to Hugging Face users",
    "description": "",
    "summary": "Google Cloud TPUs made available to Hugging Face users We're excited to share some great news! AI bu...",
    "pubDate": "Tue, 09 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tpu-inference-endpoints-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/tpu-inference-endpoints-spaces/thumbnail.png"
  },
  {
    "title": "Forecasting potential misuses of language models for disinformation campaigns and how to reduce risk",
    "description": "OpenAI researchers collaborated with Georgetown University‚Äôs Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report¬†here.",
    "summary": "OpenAI researchers collaborated with Georgetown University‚Äôs Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report¬†here.",
    "pubDate": "Wed, 11 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/forecasting-misuse",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-tuning Stable Diffusion models on Intel CPUs",
    "description": "",
    "summary": "Fine-tuning Stable Diffusion Models on Intel CPUs Diffusion models helped popularize generative AI t...",
    "pubDate": "Fri, 14 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-finetuning-intel",
    "thumbnail": "https://huggingface.co/blog/assets/stable-diffusion-finetuning-intel/01.png"
  },
  {
    "title": "OpenAI and Elon Musk",
    "description": "We are dedicated to the OpenAI mission and have pursued it every step of the way.",
    "summary": "We are dedicated to the OpenAI mission and have pursued it every step of the way.",
    "pubDate": "Tue, 05 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-elon-musk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An Introduction to Q-Learning Part 2",
    "description": "",
    "summary": "An Introduction to Q-Learning Part 2/2 Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 2,...",
    "pubDate": "Fri, 20 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-q-part2",
    "thumbnail": "https://huggingface.co/blog/assets/73_deep_rl_q_part2/thumbnail.gif"
  },
  {
    "title": "Introducing smolagents: simple agents that write actions in code.",
    "description": "",
    "summary": "Introducing smolagents, a simple library to build agents Today we are launching smolagents , a very ...",
    "pubDate": "Tue, 31 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents/thumbnail.png"
  },
  {
    "title": "Open-R1: a fully open reproduction of DeepSeek-R1",
    "description": "",
    "summary": "Open-R1: a fully open reproduction of DeepSeek-R1 What is DeepSeek-R1? If you‚Äôve ever struggled with...",
    "pubDate": "Tue, 28 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-r1",
    "thumbnail": "https://huggingface.co/blog/assets/open-r1/thumbnails.png"
  },
  {
    "title": "Finally, a Replacement for BERT: Introducing ModernBERT",
    "description": "",
    "summary": "Finally, a Replacement for BERT TL;DR This blog post introduces ModernBERT, a family of state-of-the...",
    "pubDate": "Thu, 19 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/modernbert",
    "thumbnail": "https://huggingface.co/blog/assets/modernbert/thumbnail.png"
  },
  {
    "title": "New generative media models and tools, built with and for creators",
    "description": "We‚Äôre introducing Veo, our most capable model for generating high-definition video, and Imagen 3, our highest quality text-to-image model. We‚Äôre also sharing new demo recordings created with our Music AI Sandbox.",
    "summary": "We‚Äôre introducing Veo, our most capable model for generating high-definition video, and Imagen 3, our highest quality text-to-image model. We‚Äôre also sharing new demo recordings created with our Music AI Sandbox.",
    "pubDate": "Tue, 14 May 2024 17:57:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/new-generative-media-models-and-tools-built-with-and-for-creators/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO24_Gen_Media_Header_1.width-1300.png"
  },
  {
    "title": "Urban Region Pre-training and Prompting: A Graph-based Approach",
    "description": "arXiv:2408.05920v4 Announce Type: replace Abstract: Urban region representation is crucial for various urban downstream tasks. However, despite the proliferation of methods and their success, acquiring general urban region knowledge and adapting to different tasks remains challenging. Existing work pays limited attention to the fine-grained functional layout semantics in urban regions, limiting their ability to capture transferable knowledge across regions. Further, inadequate handling of the unique features and relationships required for different downstream tasks may also hinder effective task adaptation. In this paper, we propose a $textbf{G}$raph-based $textbf{U}$rban $textbf{R}$egion $textbf{P}$re-training and $textbf{P}$rompting framework ($textbf{GURPP}$) for region representation learning. Specifically, we first construct an urban region graph and develop a subgraph-centric urban region pre-training model to capture the heterogeneous and transferable patterns of entity interactions. This model pre-trains knowledge-rich region embeddings using contrastive learning and multi-view learning methods. To further refine these representations, we design two graph-based prompting methods: a manually-defined prompt to incorporate explicit task knowledge and a task-learnable prompt to discover hidden knowledge, which enhances the adaptability of these embeddings to different tasks. Extensive experiments on various urban region prediction tasks and different cities demonstrate the superior performance of our framework.",
    "summary": "arXiv:2408.05920v4 Announce Type: replace Abstract: Urban region representation is crucial for various urban downstream tasks. However, despite the proliferation of methods and their success, acquiring general urban region knowledge and adapting to different tasks remains challenging. Existing work pays limited attention to the fine-grained functional layout semantics in urban regions, limiting their ability to capture transferable knowledge across regions. Further, inadequate handling of the unique features and relationships required for different downstream tasks may also hinder effective task adaptation. In this paper, we propose a $textbf{G}$raph-based $textbf{U}$rban $textbf{R}$egion $textbf{P}$re-training and $textbf{P}$rompting framework ($textbf{GURPP}$) for region representation learning. Specifically, we first construct an urban region graph and develop a subgraph-centric urban region pre-training model to capture the heterogeneous and transferable patterns of entity interactions. This model pre-trains knowledge-rich region embeddings using contrastive learning and multi-view learning methods. To further refine these representations, we design two graph-based prompting methods: a manually-defined prompt to incorporate explicit task knowledge and a task-learnable prompt to discover hidden knowledge, which enhances the adaptability of these embeddings to different tasks. Extensive experiments on various urban region prediction tasks and different cities demonstrate the superior performance of our framework.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.05920",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Better language models and their implications",
    "description": "We‚Äôve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization‚Äîall without task-specific¬†training.",
    "summary": "We‚Äôve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization‚Äîall without task-specific¬†training.",
    "pubDate": "Thu, 14 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/better-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Operator",
    "description": "A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in the U.S.",
    "summary": "A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in the U.S.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-operator",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "„Ç¢„Éâ„Éì„ÄÅCC„Å´Âªâ‰æ°„Éó„É©„É≥Êñ∞Ë®≠„ÄÅAI„ÇÑ„É¢„Éê„Ç§„É´Áâà„Å´Âà∂Èôê„ÄÄÂæìÊù•„ÅÆ„Éï„É´„Éó„É©„É≥„ÅØÊúàÈ°ç9080ÂÜÜ„Å´ÂÄ§‰∏ä„Åí",
    "description": "„Ç¢„Éâ„Éì„Åå„ÄÅ„ÇØ„É™„Ç®„Ç§„ÉÜ„Ç£„Éñ„ÉÑ„Éº„É´„ÄåCreative Cloud„Äç„Ç≥„É≥„Éó„É™„Éº„Éà„Éó„É©„É≥„ÅÆÂªâ‰æ°Áâà„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÁîüÊàêAI„Å™„Å©‰∏ÄÈÉ®Ê©üËÉΩ„ÇíÂà∂Èôê„Åó„Åü„ÄåCreative Cloud Standard„Äç„Éó„É©„É≥„ÇíÊñ∞Ë®≠„ÄÇÂæìÊù•„ÅÆ„Éó„É©„É≥„ÅØ„ÄåCreative Cloud Pro„Äç„Å®„Åó„Å¶„ÄÅÂÆüË≥™ÁöÑ„Å™ÂÄ§‰∏ä„Åí„ÅÆ‰∏äÊèê‰æõ„Åô„Çã„ÄÇ„Å©„Å°„Çâ„ÇÇ8Êúà1Êó•„Å´Êèê‰æõ„ÇíÂßã„ÇÅ„Çã„ÄÇ",
    "summary": "„Ç¢„Éâ„Éì„Åå„ÄÅ„ÇØ„É™„Ç®„Ç§„ÉÜ„Ç£„Éñ„ÉÑ„Éº„É´„ÄåCreative Cloud„Äç„Ç≥„É≥„Éó„É™„Éº„Éà„Éó„É©„É≥„ÅÆÂªâ‰æ°Áâà„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÁîüÊàêAI„Å™„Å©‰∏ÄÈÉ®Ê©üËÉΩ„ÇíÂà∂Èôê„Åó„Åü„ÄåCreative Cloud Standard„Äç„Éó„É©„É≥„ÇíÊñ∞Ë®≠„ÄÇÂæìÊù•„ÅÆ„Éó„É©„É≥„ÅØ„ÄåCreative Cloud Pro„Äç„Å®„Åó„Å¶„ÄÅÂÆüË≥™ÁöÑ„Å™ÂÄ§‰∏ä„Åí„ÅÆ‰∏äÊèê‰æõ„Åô„Çã„ÄÇ„Å©„Å°„Çâ„ÇÇ8Êúà1Êó•„Å´Êèê‰æõ„ÇíÂßã„ÇÅ„Çã„ÄÇ",
    "pubDate": "Fri, 04 Jul 2025 15:33:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2507/04/news094.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2507/04/cover_news094.png"
  },
  {
    "title": "Faster Text Generation with TensorFlow and XLA",
    "description": "",
    "summary": "Faster Text Generation with TensorFlow and XLA TL;DR: Text Generation on ü§ó transformers using Tensor...",
    "pubDate": "Wed, 27 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-xla-generate",
    "thumbnail": "https://huggingface.co/blog/assets/91_tf_xla_generate/thumbnail.png"
  },
  {
    "title": "Open-sourcing Knowledge Distillation Code and Weights of SD-Small and SD-Tiny",
    "description": "",
    "summary": "Open-sourcing Knowledge Distillation Code and Weights of SD-Small and SD-Tiny In recent times, the A...",
    "pubDate": "Tue, 01 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd_distillation",
    "thumbnail": "https://huggingface.co/blog/assets/distill_sd/thumbnail.png"
  },
  {
    "title": "Open-source DeepResearch ‚Äì Freeing our search agents",
    "description": "",
    "summary": "Open-source DeepResearch ‚Äì Freeing our search agents TLDR Yesterday, OpenAI released Deep Research, ...",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-deep-research",
    "thumbnail": "https://huggingface.co/blog/assets/open-deep-research/thumbnail.png"
  },
  {
    "title": "AIn't Nothing But a Survey? Using Large Language Models for Coding German Open-Ended Survey Responses on Survey Motivation",
    "description": "arXiv:2506.14634v3 Announce Type: replace-cross Abstract: The recent development and wider accessibility of LLMs have spurred discussions about how they can be used in survey research, including classifying open-ended survey responses. Due to their linguistic capacities, it is possible that LLMs are an efficient alternative to time-consuming manual coding and the pre-training of supervised machine learning models. As most existing research on this topic has focused on English-language responses relating to non-complex topics or on single LLMs, it is unclear whether its findings generalize and how the quality of these classifications compares to established methods. In this study, we investigate to what extent different LLMs can be used to code open-ended survey responses in other contexts, using German data on reasons for survey participation as an example. We compare several state-of-the-art LLMs and several prompting approaches, and evaluate the LLMs' performance by using human expert codings. Overall performance differs greatly between LLMs, and only a fine-tuned LLM achieves satisfactory levels of predictive performance. Performance differences between prompting approaches are conditional on the LLM used. Finally, LLMs' unequal classification performance across different categories of reasons for survey participation results in different categorical distributions when not using fine-tuning. We discuss the implications of these findings, both for methodological research on coding open-ended responses and for their substantive analysis, and for practitioners processing or substantively analyzing such data. Finally, we highlight the many trade-offs researchers need to consider when choosing automated methods for open-ended response classification in the age of LLMs. In doing so, our study contributes to the growing body of research about the conditions under which LLMs can be efficiently, accurately, and reliably leveraged in survey research.",
    "summary": "arXiv:2506.14634v3 Announce Type: replace-cross Abstract: The recent development and wider accessibility of LLMs have spurred discussions about how they can be used in survey research, including classifying open-ended survey responses. Due to their linguistic capacities, it is possible that LLMs are an efficient alternative to time-consuming manual coding and the pre-training of supervised machine learning models. As most existing research on this topic has focused on English-language responses relating to non-complex topics or on single LLMs, it is unclear whether its findings generalize and how the quality of these classifications compares to established methods. In this study, we investigate to what extent different LLMs can be used to code open-ended survey responses in other contexts, using German data on reasons for survey participation as an example. We compare several state-of-the-art LLMs and several prompting approaches, and evaluate the LLMs' performance by using human expert codings. Overall performance differs greatly between LLMs, and only a fine-tuned LLM achieves satisfactory levels of predictive performance. Performance differences between prompting approaches are conditional on the LLM used. Finally, LLMs' unequal classification performance across different categories of reasons for survey participation results in different categorical distributions when not using fine-tuning. We discuss the implications of these findings, both for methodological research on coding open-ended responses and for their substantive analysis, and for practitioners processing or substantively analyzing such data. Finally, we highlight the many trade-offs researchers need to consider when choosing automated methods for open-ended response classification in the age of LLMs. In doing so, our study contributes to the growing body of research about the conditions under which LLMs can be efficiently, accurately, and reliably leveraged in survey research.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14634",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing SWE-bench Verified",
    "description": "We‚Äôre releasing a human-validated subset of SWE-bench that more reliably evaluates AI models‚Äô ability to solve real-world software issues.",
    "summary": "We‚Äôre releasing a human-validated subset of SWE-bench that more reliably evaluates AI models‚Äô ability to solve real-world software issues.",
    "pubDate": "Tue, 13 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-swe-bench-verified",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Washington Post partners with OpenAI on search content",
    "description": "The Washington Post is partnering with with OpenAI to integrate news into ChatGPT, providing users with summaries, quotes, and direct links to original reporting.",
    "summary": "The Washington Post is partnering with with OpenAI to integrate news into ChatGPT, providing users with summaries, quotes, and direct links to original reporting.",
    "pubDate": "Tue, 22 Apr 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/the-washington-post-partners-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Clarifying Before Reasoning: A Coq Prover with Structural Context",
    "description": "arXiv:2507.02541v1 Announce Type: new Abstract: In this work, we investigate whether improving task clarity can enhance reasoning ability of large language models, focusing on theorem proving in Coq. We introduce a concept-level metric to evaluate task clarity and show that adding structured semantic context to the standard input used by modern LLMs, leads to a 1.85$times$ improvement in clarity score (44.5%~$rightarrow$~82.3%). Using the general-purpose model texttt{DeepSeek-V3}, our approach leads to a 2.1$times$ improvement in proof success (21.8%~$rightarrow$~45.8%) and outperforms the previous state-of-the-art texttt{Graph2Tac} (33.2%). We evaluate this on 1,386 theorems randomly sampled from 15 standard Coq packages, following the same evaluation protocol as texttt{Graph2Tac}. Furthermore, fine-tuning smaller models on our structured data can achieve even higher performance (48.6%). Our method uses selective concept unfolding to enrich task descriptions, and employs a Planner--Executor architecture. These findings highlight the value of structured task representations in bridging the gap between understanding and reasoning.",
    "summary": "arXiv:2507.02541v1 Announce Type: new Abstract: In this work, we investigate whether improving task clarity can enhance reasoning ability of large language models, focusing on theorem proving in Coq. We introduce a concept-level metric to evaluate task clarity and show that adding structured semantic context to the standard input used by modern LLMs, leads to a 1.85$times$ improvement in clarity score (44.5%~$rightarrow$~82.3%). Using the general-purpose model texttt{DeepSeek-V3}, our approach leads to a 2.1$times$ improvement in proof success (21.8%~$rightarrow$~45.8%) and outperforms the previous state-of-the-art texttt{Graph2Tac} (33.2%). We evaluate this on 1,386 theorems randomly sampled from 15 standard Coq packages, following the same evaluation protocol as texttt{Graph2Tac}. Furthermore, fine-tuning smaller models on our structured data can achieve even higher performance (48.6%). Our method uses selective concept unfolding to enrich task descriptions, and employs a Planner--Executor architecture. These findings highlight the value of structured task representations in bridging the gap between understanding and reasoning.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02541",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From OpenAI to Open LLMs with Messages API",
    "description": "",
    "summary": "From OpenAI to Open LLMs with Messages API on Hugging Face We are excited to introduce the Messages ...",
    "pubDate": "Thu, 08 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-messages-api",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-messages-api/thumbnail.jpg"
  },
  {
    "title": "Learning with opponent-learning awareness",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-with-opponent-learning-awareness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing ChatGPT and Whisper APIs",
    "description": "Developers can now integrate ChatGPT and Whisper models into their apps and products through our API.",
    "summary": "Developers can now integrate ChatGPT and Whisper models into their apps and products through our API.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-and-whisper-apis",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemini 2.5: Our most intelligent AI model",
    "description": "Gemini 2.5 is our most intelligent AI model, now with thinking built in.",
    "summary": "Gemini 2.5 is our most intelligent AI model, now with thinking built in.",
    "pubDate": "Tue, 25 Mar 2025 17:00:36 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-2-5-our-most-intelligent-ai-model/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_keyword_social_share_text.width-1300.png"
  },
  {
    "title": "Êù±‰∫¨ÈÉΩ„ÄÅÈÉΩÁ´ãÈ´òÊ†°„Å´DeepLÂ∞éÂÖ•„ÄÄË®à1‰∏á‰∫∫„ÅÆÁîüÂæí„Å®ÊïôÂì°„ÅåÂà©Áî®‰∏≠„ÄÄ„ÄåËã±Ë™ûÂ≠¶Áøí„ÇÑÊ•≠ÂãôÊîØÊè¥„Å´Ê¥ªÁî®„Äç",
    "description": "ÈÉΩÁ´ãÈ´òÊ†°„Å´DeepL„ÅÆÁøªË®≥„ÉÑ„Éº„É´„ÇíÂ∞éÂÖ•‚îÄ‚îÄ„Ç™„É≥„É©„Ç§„É≥„ÉÜ„Ç≠„Çπ„ÉàÁøªË®≥„ÅßÁü•„Çâ„Çå„ÇãÁã¨DeepL„ÅØ„ÄÅÊù±‰∫¨ÈÉΩÊïôËÇ≤ÂßîÂì°‰ºö„ÅÆÂ∞éÂÖ•‰∫ã‰æã„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ",
    "summary": "ÈÉΩÁ´ãÈ´òÊ†°„Å´DeepL„ÅÆÁøªË®≥„ÉÑ„Éº„É´„ÇíÂ∞éÂÖ•‚îÄ‚îÄ„Ç™„É≥„É©„Ç§„É≥„ÉÜ„Ç≠„Çπ„ÉàÁøªË®≥„ÅßÁü•„Çâ„Çå„ÇãÁã¨DeepL„ÅØ„ÄÅÊù±‰∫¨ÈÉΩÊïôËÇ≤ÂßîÂì°‰ºö„ÅÆÂ∞éÂÖ•‰∫ã‰æã„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 11:05:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news065.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news065.jpg"
  },
  {
    "title": "Introducing HealthBench",
    "description": "HealthBench is a new evaluation benchmark for AI in healthcare which evaluates models in realistic scenarios. Built with input from 250+ physicians, it aims to provide a shared standard for model performance and safety in health.",
    "summary": "HealthBench is a new evaluation benchmark for AI in healthcare which evaluates models in realistic scenarios. Built with input from 250+ physicians, it aims to provide a shared standard for model performance and safety in health.",
    "pubDate": "Mon, 12 May 2025 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/healthbench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "NPHardEval Leaderboard: Unveiling the Reasoning Abilities of Large Language Models through Complexity Classes and Dynamic Updates",
    "description": "",
    "summary": "NPHardEval Leaderboard: Unveiling the Reasoning Abilities of Large Language Models through Complexit...",
    "pubDate": "Fri, 02 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-nphardeval",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_nphardeval.png"
  },
  {
    "title": "Sam Altman returns as CEO, OpenAI has a new initial board",
    "description": "Mira Murati as CTO, Greg Brockman returns as President. Read messages from CEO Sam Altman and board chair Bret Taylor.",
    "summary": "Mira Murati as CTO, Greg Brockman returns as President. Read messages from CEO Sam Altman and board chair Bret Taylor.",
    "pubDate": "Wed, 29 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Lowe‚Äôs leverages AI to power home improvement retail",
    "description": "A conversation with Chandhu Nair, Senior Vice President of Data, AI, and Innovation.",
    "summary": "A conversation with Chandhu Nair, Senior Vice President of Data, AI, and Innovation.",
    "pubDate": "Mon, 05 May 2025 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lowes-chandhu-nair",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Results of the Open Source AI Game Jam",
    "description": "",
    "summary": "Results of the Open Source AI Game Jam From July 7th to July 11th, we hosted our first Open Source A...",
    "pubDate": "Fri, 21 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/game-jam-first-edition-results",
    "thumbnail": "https://huggingface.co/blog/assets/game-jam-first-edition-results/thumbnail.jpg"
  },
  {
    "title": "Scaling robotics datasets with video encoding",
    "description": "",
    "summary": "Scaling robotics datasets with video encoding Over the past few years, text and image-based models h...",
    "pubDate": "Tue, 27 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/video-encoding",
    "thumbnail": "https://huggingface.co/blog/assets/video-encoding/thumbnail.png"
  },
  {
    "title": "Case Study: Millisecond Latency using Hugging Face Infinity and modern CPUs",
    "description": "",
    "summary": "Case Study: Millisecond Latency using Hugging Face Infinity and modern CPUs Inference Endpoints to e...",
    "pubDate": "Thu, 13 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/infinity-cpu-performance",
    "thumbnail": "https://huggingface.co/blog/assets/46_infinity_cpu_performance/thumbnail.png"
  },
  {
    "title": "CLIP: Connecting text and images",
    "description": "We‚Äôre introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the ‚Äúzero-shot‚Äù capabilities of GPT-2 and¬†GPT-3.",
    "summary": "We‚Äôre introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the ‚Äúzero-shot‚Äù capabilities of GPT-2 and¬†GPT-3.",
    "pubDate": "Tue, 05 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/clip",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building an autonomous financial analyst with o1 and o3-mini",
    "description": "Endex builds the future of financial analysis, powered by OpenAI‚Äôs reasoning models.",
    "summary": "Endex builds the future of financial analysis, powered by OpenAI‚Äôs reasoning models.",
    "pubDate": "Thu, 27 Feb 2025 09:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/endex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TacticAI: an AI assistant for football tactics",
    "description": "As part of our multi-year collaboration with Liverpool FC, we develop a full AI system that can advise coaches on corner kicks",
    "summary": "As part of our multi-year collaboration with Liverpool FC, we develop a full AI system that can advise coaches on corner kicks",
    "pubDate": "Tue, 19 Mar 2024 16:03:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/tacticai-ai-assistant-for-football-tactics/",
    "thumbnail": "https://lh3.googleusercontent.com/pPa45NPPYrOc4QHbcLIsmueJXi9hKNFdB0rbnRMdiRH0Gf3fgIc_g26-UbFxHVzqUT85QA-N3IvPpQaDevlp3OeF3RIiLQjmuONVRVyX1et0WYEKTQ=w1200-h630-n-nu"
  },
  {
    "title": "Enhancing news in ChatGPT with The Atlantic",
    "description": "The Atlantic is announcing a strategic content and product partnership with OpenAI, which positions The Atlantic as a premium news source within OpenAI. The Atlantic‚Äôs articles will be discoverable within OpenAI‚Äôs products, including ChatGPT, and as a partner, The Atlantic will help to shape how news is surfaced and presented in future real-time discovery products.",
    "summary": "The Atlantic is announcing a strategic content and product partnership with OpenAI, which positions The Atlantic as a premium news source within OpenAI. The Atlantic‚Äôs articles will be discoverable within OpenAI‚Äôs products, including ChatGPT, and as a partner, The Atlantic will help to shape how news is surfaced and presented in future real-time discovery products.",
    "pubDate": "Wed, 29 May 2024 07:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/enhancing-news-in-chatgpt-with-the-atlantic",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploying ü§ó ViT on Vertex AI",
    "description": "",
    "summary": "Deploying ü§ó ViT on Vertex AI In the previous posts, we showed how to deploy a Vision Transformers (V...",
    "pubDate": "Fri, 19 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-vertex-ai",
    "thumbnail": "https://huggingface.co/blog/assets/97_vertex_ai/image1.png"
  },
  {
    "title": "AI Agent„ÅåÂõûÁ≠î„Å´Âõ∞„Å£„ÅüÊôÇ„Å´Slack„Åß‰∫∫Èñì„Å´Âä©Ë®Ä„ÇíÊ±Ç„ÇÅ„Çâ„Çå„ÇãMCP„ÇíÊ§úË®º„Åó„Åü",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØ„ÄÅAI Agent„ÅåËá™Ë∫´„ÅßËß£Ê±∫„Åß„Åç„Å™„ÅÑÂïèÈ°å„Å´Áõ¥Èù¢„Åó„ÅüÈöõ„Å´„ÄÅSlack„ÇíÈÄö„Åò„Å¶‰∫∫Èñì„Å´Âä©Ë®Ä„ÇíÊ±Ç„ÇÅ„Çã„Åì„Å®„Åå„Åß„Åç„ÇãMCPÔºàModel Context ProtocolÔºâ„ÄÅAskOnSlack [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5928' rel='nofollow'>AI Agent„ÅåÂõûÁ≠î„Å´Âõ∞„Å£„ÅüÊôÇ„Å´Slack„Åß‰∫∫Èñì„Å´Âä©Ë®Ä„ÇíÊ±Ç„ÇÅ„Çâ„Çå„ÇãMCP„ÇíÊ§úË®º„Åó„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØ„ÄÅAI Agent„ÅåËá™Ë∫´„ÅßËß£Ê±∫„Åß„Åç„Å™„ÅÑÂïèÈ°å„Å´Áõ¥Èù¢„Åó„ÅüÈöõ„Å´„ÄÅSlack„ÇíÈÄö„Åò„Å¶‰∫∫Èñì„Å´Âä©Ë®Ä„ÇíÊ±Ç„ÇÅ„Çã„Åì„Å®„Åå„Åß„Åç„ÇãMCPÔºàModel Context ProtocolÔºâ„ÄÅAskOnSlack [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5928' rel='nofollow'>AI Agent„ÅåÂõûÁ≠î„Å´Âõ∞„Å£„ÅüÊôÇ„Å´Slack„Åß‰∫∫Èñì„Å´Âä©Ë®Ä„ÇíÊ±Ç„ÇÅ„Çâ„Çå„ÇãMCP„ÇíÊ§úË®º„Åó„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Wed, 02 Jul 2025 06:52:11 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5928",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/07/f81fd2e4c52864042852c112ce927ae2.png"
  },
  {
    "title": "„ÉÅ„É£„ÉÉ„ÉàAI„Å´‚ÄúÊÑüÊÉÖ„ÇíÂÖ±Êúâ‚Äù„Åß„Åç„Çã‰∫∫„ÅØ64.9ÔºÖ„ÄÅ„ÄåË¶™Âèã„Äç„ÄåÊØç„Äç„Çí‰∏äÂõû„Çã„ÄÄÈõªÈÄöË™øÊüª",
    "description": "„ÉÅ„É£„ÉÉ„ÉàAI„Å´ÊÑüÊÉÖ„ÇíÂÖ±Êúâ„Åß„Åç„Çã‰∫∫„ÅØ64.9ÔºÖ„Åß„ÄÅË¶™Âèã„ÇÑÊØçË¶™„Çí‰∏äÂõû„Çã‚Äï‚ÄïÈõªÈÄö„ÅØ„Åì„Çì„Å™Ë™øÊüªÁµêÊûú„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ„ÉÅ„É£„ÉÉ„ÉàAI„ÇíÈÄ±1Âõû‰ª•‰∏äÂà©Áî®„Åô„Çã12ÔΩû69Ê≠≥„ÅÆ1000‰∫∫„Å´Web„Åß„Ç¢„É≥„Ç±„Éº„Éà„ÇíÂÆüÊñΩ„ÄÇ„ÉÅ„É£„ÉÉ„ÉàAI„Å®„ÅÆÊé•„ÅóÊñπ„ÇÑ„ÄÅ‰∏ñ‰ª£„Åî„Å®„ÅÆÊ¥ªÁî®„ÅÆÂÇæÂêë„Å™„Å©„ÅåÂà§Êòé„Åó„Åü„Å®„ÅÑ„ÅÜ„ÄÇ",
    "summary": "„ÉÅ„É£„ÉÉ„ÉàAI„Å´ÊÑüÊÉÖ„ÇíÂÖ±Êúâ„Åß„Åç„Çã‰∫∫„ÅØ64.9ÔºÖ„Åß„ÄÅË¶™Âèã„ÇÑÊØçË¶™„Çí‰∏äÂõû„Çã‚Äï‚ÄïÈõªÈÄö„ÅØ„Åì„Çì„Å™Ë™øÊüªÁµêÊûú„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ„ÉÅ„É£„ÉÉ„ÉàAI„ÇíÈÄ±1Âõû‰ª•‰∏äÂà©Áî®„Åô„Çã12ÔΩû69Ê≠≥„ÅÆ1000‰∫∫„Å´Web„Åß„Ç¢„É≥„Ç±„Éº„Éà„ÇíÂÆüÊñΩ„ÄÇ„ÉÅ„É£„ÉÉ„ÉàAI„Å®„ÅÆÊé•„ÅóÊñπ„ÇÑ„ÄÅ‰∏ñ‰ª£„Åî„Å®„ÅÆÊ¥ªÁî®„ÅÆÂÇæÂêë„Å™„Å©„ÅåÂà§Êòé„Åó„Åü„Å®„ÅÑ„ÅÜ„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 14:08:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news080.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news080.jpg"
  },
  {
    "title": "Snorkel AI x Hugging Face: unlock foundation models for enterprises",
    "description": "",
    "summary": "Snorkel AI x Hugging Face: unlock foundation models for enterprises This article is a cross-post fro...",
    "pubDate": "Thu, 06 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/snorkel-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/snorkel.png"
  },
  {
    "title": "Roboschool",
    "description": "We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym.",
    "summary": "We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym.",
    "pubDate": "Mon, 15 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/roboschool",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Advancing Gemini's security safeguards",
    "description": "We‚Äôve made Gemini 2.5 our most secure model family to date.",
    "summary": "We‚Äôve made Gemini 2.5 our most secure model family to date.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
    "thumbnail": "https://lh3.googleusercontent.com/Uh_O6Nx1GWznAfODatYYz2sxiDekdb6HWnnSsy-cfmTxfjdUEEleh9w4cBdwUfBnyQBS-t1xW4UZXrMmC-rI6bz31hCrm5nHLt6Cp1FJAT7X9Upv5g=w1200-h630-n-nu"
  },
  {
    "title": "Spring Update",
    "description": "Introducing GPT-4o and making more capabilities available for free in ChatGPT.",
    "summary": "Introducing GPT-4o and making more capabilities available for free in ChatGPT.",
    "pubDate": "Mon, 13 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spring-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Partnering with Axios expands OpenAI‚Äôs work with the news industry",
    "description": "Publishers representing hundreds of newsrooms and content brands are using OpenAI partnerships and grant programs to adopt AI tools and strengthen the news ecosystem, while ChatGPT users gain access to information from leading, reliable publications.",
    "summary": "Publishers representing hundreds of newsrooms and content brands are using OpenAI partnerships and grant programs to adopt AI tools and strengthen the news ecosystem, while ChatGPT users gain access to information from leading, reliable publications.",
    "pubDate": "Wed, 15 Jan 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/partnering-with-axios-expands-openai-work-with-the-news-industry",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemini Robotics On-Device brings AI to local robotic devices",
    "description": "We‚Äôre introducing an efficient, on-device robotics model with general-purpose dexterity and fast task adaptation.",
    "summary": "We‚Äôre introducing an efficient, on-device robotics model with general-purpose dexterity and fast task adaptation.",
    "pubDate": "Tue, 24 Jun 2025 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-robotics-on-device-brings-ai-to-local-robotic-devices/",
    "thumbnail": "https://lh3.googleusercontent.com/Jt_Vw7PIJEZtXcMIKM1HbWbBCLxv7RUyjyf07eHp-YOfxMCUZA6mPI9kSCaz65UkMoGcZ8CwlD3dNBvy7bnnYchjSkWyN-SugglT3dmg1A9KdoDqdQM=w1200-h630-n-nu"
  },
  {
    "title": "„Çπ„Éû„Éõ„Ç≤„Éº„É†„ÄåD4DJ„Äç„ÄÅ„É©„Ç§„Éñ„Ç§„Éô„É≥„Éà„ÅÆ„Ç≠„Éº„Éì„Ç∏„É•„Ç¢„É´„Å´ÁîüÊàêAIÂà©Áî®„ÄÄSNS„ÅÆÂèçÂøúÂèó„ÅëÊòé„Çâ„Åã„Å´",
    "description": "„Ç≤„Éº„É†ÈñãÁô∫„Å™„Å©„ÇíÊâãÊéõ„Åë„ÇãDONUTS„ÅØ„ÄÅ„Çπ„Éû„Éº„Éà„Éï„Ç©„É≥Âêë„Åë„Ç≤„Éº„É†„ÄåD4DJ„Äç„ÅÆ„É©„Ç§„Éñ„Ç§„Éô„É≥„Éà„ÅÆ„Ç≠„Éº„Éì„Ç∏„É•„Ç¢„É´„Å´ÁîüÊàêAI„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Åü„Å®„ÄÅÂÖ¨ÂºèX„ÅßÊòé„Çâ„Åã„Å´„Åó„Åü„ÄÇX„Åß„ÅØ„ÄÅÁ¥∞ÈÉ®„ÅÆ‰π±„Çå„Å™„Å©„Åã„Çâ„Ç≠„Éº„Éì„Ç∏„É•„Ç¢„É´„Å´ÂØæ„Åó„ÄåÁîªÂÉèÁîüÊàêAI„Çí‰Ωø„Å£„Å¶„ÅÑ„Çã„ÅÆ„Åß„ÅØÔºü„Äç„Å™„Å©„ÅÆÂ£∞„Åå‰∏ä„Åå„Å£„Å¶„ÅÑ„Åü„ÄÇ",
    "summary": "„Ç≤„Éº„É†ÈñãÁô∫„Å™„Å©„ÇíÊâãÊéõ„Åë„ÇãDONUTS„ÅØ„ÄÅ„Çπ„Éû„Éº„Éà„Éï„Ç©„É≥Âêë„Åë„Ç≤„Éº„É†„ÄåD4DJ„Äç„ÅÆ„É©„Ç§„Éñ„Ç§„Éô„É≥„Éà„ÅÆ„Ç≠„Éº„Éì„Ç∏„É•„Ç¢„É´„Å´ÁîüÊàêAI„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Åü„Å®„ÄÅÂÖ¨ÂºèX„ÅßÊòé„Çâ„Åã„Å´„Åó„Åü„ÄÇX„Åß„ÅØ„ÄÅÁ¥∞ÈÉ®„ÅÆ‰π±„Çå„Å™„Å©„Åã„Çâ„Ç≠„Éº„Éì„Ç∏„É•„Ç¢„É´„Å´ÂØæ„Åó„ÄåÁîªÂÉèÁîüÊàêAI„Çí‰Ωø„Å£„Å¶„ÅÑ„Çã„ÅÆ„Åß„ÅØÔºü„Äç„Å™„Å©„ÅÆÂ£∞„Åå‰∏ä„Åå„Å£„Å¶„ÅÑ„Åü„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 19:51:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news113.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news113.jpg"
  },
  {
    "title": "Efficient training of language models to fill in the middle",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 28 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/efficient-training-of-language-models-to-fill-in-the-middle",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Catching halibut with ChatGPT",
    "description": "Using ChatGPT to catch halibut",
    "summary": "Using ChatGPT to catch halibut",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fishing-for-first-timers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New model predicts a chemical reaction‚Äôs point of no return",
    "description": "Chemists could use this quick computational method to design more efficient reactions that yield useful compounds, from fuels to pharmaceuticals.",
    "summary": "Chemists could use this quick computational method to design more efficient reactions that yield useful compounds, from fuels to pharmaceuticals.",
    "pubDate": "Wed, 23 Apr 2025 11:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-model-predicts-chemical-reactions-no-return-point-0423",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/BetterPredict-01-press.jpg"
  },
  {
    "title": "Large Language Models: A New Moore's Law?",
    "description": "",
    "summary": "Large Language Models: A New Moore's Law? A few days ago, Microsoft and NVIDIA introduced Megatron-T...",
    "pubDate": "Tue, 26 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/large-language-models",
    "thumbnail": "https://huggingface.co/blog/assets/33_large_language_models/01_model_size.jpg"
  },
  {
    "title": "Ethics and Society Newsletter #4: Bias in Text-to-Image Models",
    "description": "",
    "summary": "Ethics and Society Newsletter #4: Bias in Text-to-Image Models TL;DR: We need better ways of evaluat...",
    "pubDate": "Mon, 26 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-4",
    "thumbnail": "https://huggingface.co/blog/assets/152_ethics_soc_4/ethics_4_thumbnail.png"
  },
  {
    "title": "New ways to manage your data in ChatGPT",
    "description": "ChatGPT users can now turn off chat history, allowing you to choose which conversations can be used to train our models.",
    "summary": "ChatGPT users can now turn off chat history, allowing you to choose which conversations can be used to train our models.",
    "pubDate": "Tue, 25 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Guiding Text Generation with Constrained Beam Search in ü§ó Transformers",
    "description": "",
    "summary": "Guiding Text Generation with Constrained Beam Search in ü§ó Transformers Introduction This blog post a...",
    "pubDate": "Fri, 11 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/constrained-beam-search",
    "thumbnail": "https://huggingface.co/blog/assets/53_constrained_beam_search/thumbnail.png"
  },
  {
    "title": "Fine-Tune W2V2-Bert for low-resource ASR with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune W2V2-Bert for low-resource ASR with ü§ó Transformers New (01/2024): This blog post is strong...",
    "pubDate": "Fri, 19 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-w2v2-bert",
    "thumbnail": "https://huggingface.co/blog/assets/fine-tune-w2v2-bert/w2v_thumbnail.png"
  },
  {
    "title": "Novel AI model inspired by neural dynamics from the brain",
    "description": "New type of ‚Äústate-space model‚Äù leverages principles of harmonic oscillators.",
    "summary": "New type of ‚Äústate-space model‚Äù leverages principles of harmonic oscillators.",
    "pubDate": "Fri, 02 May 2025 15:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/novel-ai-model-inspired-neural-dynamics-from-brain-0502",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-LinOSS.jpg"
  },
  {
    "title": "Disrupting malicious uses of AI by state-affiliated threat actors",
    "description": "We terminated accounts associated with state-affiliated threat actors. Our findings show our models offer only limited, incremental capabilities for malicious cybersecurity tasks.",
    "summary": "We terminated accounts associated with state-affiliated threat actors. Our findings show our models offer only limited, incremental capabilities for malicious cybersecurity tasks.",
    "pubDate": "Wed, 14 Feb 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-malicious-uses-of-ai-by-state-affiliated-threat-actors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Universal Image Segmentation with Mask2Former and OneFormer",
    "description": "",
    "summary": "Universal Image Segmentation with Mask2Former and OneFormer This guide introduces Mask2Former and On...",
    "pubDate": "Thu, 19 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mask2former",
    "thumbnail": "https://huggingface.co/blog/assets/127_mask2former/thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT search",
    "description": "Get fast, timely answers with links to relevant web sources",
    "summary": "Get fast, timely answers with links to relevant web sources",
    "pubDate": "Thu, 31 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-search",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SafeCoder vs. Closed-source Code Assistants",
    "description": "",
    "summary": "SafeCoder vs. Closed-source Code Assistants For decades, software developers have designed methodolo...",
    "pubDate": "Mon, 11 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safecoder-vs-closed-source-code-assistants",
    "thumbnail": "https://huggingface.co/blog/assets/safecoder-vs-closed-source-code-assistants/image.png"
  },
  {
    "title": "SmolVLM2: Bringing Video Understanding to Every Device",
    "description": "",
    "summary": "SmolVLM2: Bringing Video Understanding to Every Device TL;DR: SmolVLM can now watch üì∫ with even bett...",
    "pubDate": "Thu, 20 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvlm2",
    "thumbnail": "https://huggingface.co/blog/assets/smolvlm2/banner.png"
  },
  {
    "title": "A Deepdive into Aya Expanse: Advancing the Frontier of Multilinguality",
    "description": "",
    "summary": "A Deepdive into Aya Expanse: Advancing the Frontier of Multilinguality This is a guest blog post by ...",
    "pubDate": "Thu, 24 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aya-expanse",
    "thumbnail": "https://huggingface.co/blog/assets/aya-expanse/thumbnail.jpg"
  },
  {
    "title": "Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon",
    "description": "",
    "summary": "Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon Large language models (LLM...",
    "pubDate": "Tue, 16 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/generative-ai-models-on-intel-cpu",
    "thumbnail": "https://huggingface.co/blog/assets/143_q8chat/thumbnail.png"
  },
  {
    "title": "ScreenSuite - The most comprehensive evaluation suite for GUI Agents!",
    "description": "",
    "summary": "ScreenSuite - The most comprehensive evaluation suite for GUI Agents! Releasing ScreenSuite, the mos...",
    "pubDate": "Fri, 06 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/screensuite",
    "thumbnail": "https://huggingface.co/blog/assets/screensuite/thumbnail.png"
  },
  {
    "title": "„É™„Ç≥„Éº„ÄÅGENIAC„Åß„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„ÄÇ7Êúà„Å´ÁÑ°ÂÑüÂÖ¨Èñã",
    "description": "<p>„É™„Ç≥„Éº„ÅØ„ÄÅÁµåÊ∏àÁî£Ê•≠ÁúÅ„Åä„Çà„Å≥NEDO„ÅåÊé®ÈÄ≤„Åô„ÇãGENIAC„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Å´„Åä„ÅÑ„Å¶„ÄÅÊó•Êú¨‰ºÅÊ•≠Âêë„ÅëÂõ≥Ë°®„ÇíÂê´„ÇÄ„Éâ„Ç≠„É•„É°„É≥„ÉàË™≠„ÅøÂèñ„Çä„Å´ÁâπÂåñ„Åó„Åü„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„Åó„Åæ„Åó„Åü„ÄÇ7Êúà29Êó•ÈñãÂÇ¨„ÅÆMIRU2025„ÅßË´ñÊñáÁô∫Ë°® [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/'>„É™„Ç≥„Éº„ÄÅGENIAC„Åß„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„ÄÇ7Êúà„Å´ÁÑ°ÂÑüÂÖ¨Èñã</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>„É™„Ç≥„Éº„ÅØ„ÄÅÁµåÊ∏àÁî£Ê•≠ÁúÅ„Åä„Çà„Å≥NEDO„ÅåÊé®ÈÄ≤„Åô„ÇãGENIAC„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Å´„Åä„ÅÑ„Å¶„ÄÅÊó•Êú¨‰ºÅÊ•≠Âêë„ÅëÂõ≥Ë°®„ÇíÂê´„ÇÄ„Éâ„Ç≠„É•„É°„É≥„ÉàË™≠„ÅøÂèñ„Çä„Å´ÁâπÂåñ„Åó„Åü„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„Åó„Åæ„Åó„Åü„ÄÇ7Êúà29Êó•ÈñãÂÇ¨„ÅÆMIRU2025„ÅßË´ñÊñáÁô∫Ë°® [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/'>„É™„Ç≥„Éº„ÄÅGENIAC„Åß„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„ÄÇ7Êúà„Å´ÁÑ°ÂÑüÂÖ¨Èñã</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Tue, 24 Jun 2025 07:52:10 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/ricoh-genia-multimodal-llm.png"
  },
  {
    "title": "Unsupervised Cognition",
    "description": "arXiv:2409.18624v3 Announce Type: replace Abstract: Unsupervised learning methods have a soft inspiration in cognition models. To this day, the most successful unsupervised learning methods revolve around clustering samples in a mathematical space. In this paper we propose a primitive-based, unsupervised learning approach for decision-making inspired by a novel cognition framework. This representation-centric approach models the input space constructively as a distributed hierarchical structure in an input-agnostic way. We compared our approach with both current state-of-the-art unsupervised learning classification, with current state-of-the-art small and incomplete datasets classification, and with current state-of-the-art cancer type classification. We show how our proposal outperforms previous state-of-the-art. We also evaluate some cognition-like properties of our proposal where it not only outperforms the compared algorithms (even supervised learning ones), but it also shows a different, more cognition-like, behaviour.",
    "summary": "arXiv:2409.18624v3 Announce Type: replace Abstract: Unsupervised learning methods have a soft inspiration in cognition models. To this day, the most successful unsupervised learning methods revolve around clustering samples in a mathematical space. In this paper we propose a primitive-based, unsupervised learning approach for decision-making inspired by a novel cognition framework. This representation-centric approach models the input space constructively as a distributed hierarchical structure in an input-agnostic way. We compared our approach with both current state-of-the-art unsupervised learning classification, with current state-of-the-art small and incomplete datasets classification, and with current state-of-the-art cancer type classification. We show how our proposal outperforms previous state-of-the-art. We also evaluate some cognition-like properties of our proposal where it not only outperforms the compared algorithms (even supervised learning ones), but it also shows a different, more cognition-like, behaviour.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.18624",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Machine Learning Experts - Sasha Luccioni Interview",
    "description": "",
    "summary": "Machine Learning Experts - Sasha Luccioni ü§ó Welcome to Machine Learning Experts - Sasha Luccioni üöÄ I...",
    "pubDate": "Tue, 17 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sasha-luccioni-interview",
    "thumbnail": "https://huggingface.co/blog/assets/69_sasha_luccioni_interview/thumbnail.png"
  },
  {
    "title": "Text-Aware Image Restoration with Diffusion Models",
    "description": "arXiv:2506.09993v2 Announce Type: replace-cross Abstract: Image restoration aims to recover degraded images. However, existing diffusion-based restoration methods, despite great success in natural image restoration, often struggle to faithfully reconstruct textual regions in degraded images. Those methods frequently generate plausible but incorrect text-like patterns, a phenomenon we refer to as text-image hallucination. In this paper, we introduce Text-Aware Image Restoration (TAIR), a novel restoration task that requires the simultaneous recovery of visual contents and textual fidelity. To tackle this task, we present SA-Text, a large-scale benchmark of 100K high-quality scene images densely annotated with diverse and complex text instances. Furthermore, we propose a multi-task diffusion framework, called TeReDiff, that integrates internal features from diffusion models into a text-spotting module, enabling both components to benefit from joint training. This allows for the extraction of rich text representations, which are utilized as prompts in subsequent denoising steps. Extensive experiments demonstrate that our approach consistently outperforms state-of-the-art restoration methods, achieving significant gains in text recognition accuracy. See our project page: https://cvlab-kaist.github.io/TAIR/",
    "summary": "arXiv:2506.09993v2 Announce Type: replace-cross Abstract: Image restoration aims to recover degraded images. However, existing diffusion-based restoration methods, despite great success in natural image restoration, often struggle to faithfully reconstruct textual regions in degraded images. Those methods frequently generate plausible but incorrect text-like patterns, a phenomenon we refer to as text-image hallucination. In this paper, we introduce Text-Aware Image Restoration (TAIR), a novel restoration task that requires the simultaneous recovery of visual contents and textual fidelity. To tackle this task, we present SA-Text, a large-scale benchmark of 100K high-quality scene images densely annotated with diverse and complex text instances. Furthermore, we propose a multi-task diffusion framework, called TeReDiff, that integrates internal features from diffusion models into a text-spotting module, enabling both components to benefit from joint training. This allows for the extraction of rich text representations, which are utilized as prompts in subsequent denoising steps. Extensive experiments demonstrate that our approach consistently outperforms state-of-the-art restoration methods, achieving significant gains in text recognition accuracy. See our project page: https://cvlab-kaist.github.io/TAIR/",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.09993",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome, Gradio 5",
    "description": "",
    "summary": "Welcome, Gradio 5 We‚Äôve been hard at work over the past few months, and we are excited to now announ...",
    "pubDate": "Wed, 09 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-5",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-5/thumbnail.png"
  },
  {
    "title": "Hear a podcast discussion about Gemini‚Äôs coding capabilities.",
    "description": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-600x600.format-webp.webp' />The latest episode of the Google AI: Release Notes podcast focuses on how the Gemini team built one of the world‚Äôs leading AI coding models.Host Logan Kilpatrick chats w‚Ä¶",
    "summary": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-600x600.format-webp.webp' />The latest episode of the Google AI: Release Notes podcast focuses on how the Gemini team built one of the world‚Äôs leading AI coding models.Host Logan Kilpatrick chats w‚Ä¶",
    "pubDate": "Wed, 18 Jun 2025 10:28:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/gemini/gemini-coding-podcast/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-1440x810.png"
  },
  {
    "title": "Using GPT-4 to improve teaching and learning in Brazil",
    "description": "Improving teaching and learning in Brazil",
    "summary": "Improving teaching and learning in Brazil",
    "pubDate": "Tue, 17 Sep 2024 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/arco-education",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "2023, year of open LLMs",
    "description": "",
    "summary": "2023, year of open LLMs 2023 has seen a surge of public interest in Large Language Models (LLMs), an...",
    "pubDate": "Mon, 18 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/2023-in-llms",
    "thumbnail": "https://huggingface.co/blog/assets/cv_state/thumbnail.png"
  },
  {
    "title": "Answer Matching Outperforms Multiple Choice for Language Model Evaluation",
    "description": "arXiv:2507.02856v1 Announce Type: cross Abstract: Multiple choice benchmarks have long been the workhorse of language model evaluation because grading multiple choice is objective and easy to automate. However, we show multiple choice questions from popular benchmarks can often be answered without even seeing the question. These shortcuts arise from a fundamental limitation of discriminative evaluation not shared by evaluations of the model's free-form, generative answers. Until recently, there appeared to be no viable, scalable alternative to multiple choice--but, we show that this has changed. We consider generative evaluation via what we call answer matching: Give the candidate model the question without the options, have it generate a free-form response, then use a modern language model with the reference answer to determine if the response matches the reference. To compare the validity of different evaluation strategies, we annotate MMLU-Pro and GPQA-Diamond to obtain human grading data, and measure the agreement of each evaluation approach. We find answer matching using recent models--even small ones--achieves near-perfect agreement, in the range of inter-annotator agreement. In contrast, both multiple choice evaluation and using LLM-as-a-judge without reference answers aligns poorly with human grading. Improving evaluations via answer matching is not merely a conceptual concern: the rankings of several models change significantly when evaluating their free-form responses with answer matching. In light of these findings, we discuss how to move the evaluation ecosystem from multiple choice to answer matching.",
    "summary": "arXiv:2507.02856v1 Announce Type: cross Abstract: Multiple choice benchmarks have long been the workhorse of language model evaluation because grading multiple choice is objective and easy to automate. However, we show multiple choice questions from popular benchmarks can often be answered without even seeing the question. These shortcuts arise from a fundamental limitation of discriminative evaluation not shared by evaluations of the model's free-form, generative answers. Until recently, there appeared to be no viable, scalable alternative to multiple choice--but, we show that this has changed. We consider generative evaluation via what we call answer matching: Give the candidate model the question without the options, have it generate a free-form response, then use a modern language model with the reference answer to determine if the response matches the reference. To compare the validity of different evaluation strategies, we annotate MMLU-Pro and GPQA-Diamond to obtain human grading data, and measure the agreement of each evaluation approach. We find answer matching using recent models--even small ones--achieves near-perfect agreement, in the range of inter-annotator agreement. In contrast, both multiple choice evaluation and using LLM-as-a-judge without reference answers aligns poorly with human grading. Improving evaluations via answer matching is not merely a conceptual concern: the rankings of several models change significantly when evaluating their free-form responses with answer matching. In light of these findings, we discuss how to move the evaluation ecosystem from multiple choice to answer matching.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02856",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Creating an AI-powered Magic Studio",
    "description": "Canva is a visual communication platform, enjoyed by more than 175 million people monthly to make presentations, videos, documents, websites, social media graphics and more. A majority of the world‚Äôs knowledge workers lack design training, but Canva‚Äôs combination of an easy-to-use interface, vast libraries, and time-saving tools allows anyone to create visually compelling content.",
    "summary": "Canva is a visual communication platform, enjoyed by more than 175 million people monthly to make presentations, videos, documents, websites, social media graphics and more. A majority of the world‚Äôs knowledge workers lack design training, but Canva‚Äôs combination of an easy-to-use interface, vast libraries, and time-saving tools allows anyone to create visually compelling content.",
    "pubDate": "Thu, 16 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/canva",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SNSÊäïÁ®ø„ÅÆÁÇé‰∏ä„É™„Çπ„ÇØ„ÇíAI„ÅßÁ¢∫Ë™ç„ÄÄ„ÄåAIÁÇé‰∏ä„ÉÅ„Çß„ÉÉ„Ç´„Éº„Äç„Ç¢„Éó„É™ÁÑ°ÊñôÂÖ¨Èñã",
    "description": "SNS„Å™„Å©„Å´„ÉÜ„Ç≠„Çπ„Éà„ÇíÊäïÁ®ø„Åô„ÇãÂâç„Å´„ÄÅÂÜÖÂÆπ„Å´ÁÇé‰∏ä„É™„Çπ„ÇØ„Åå„Å™„ÅÑ„Åã„ÇíAI„Åå„ÉÅ„Çß„ÉÉ„ÇØ„Åô„Çã„Ç¢„Éó„É™„ÄåAIÁÇé‰∏ä„ÉÅ„Çß„ÉÉ„Ç´„Éº„Äç„ÅÆÁÑ°ÊñôÈÖçÂ∏É„Åå„Çπ„Çø„Éº„Éà„ÄÇ",
    "summary": "SNS„Å™„Å©„Å´„ÉÜ„Ç≠„Çπ„Éà„ÇíÊäïÁ®ø„Åô„ÇãÂâç„Å´„ÄÅÂÜÖÂÆπ„Å´ÁÇé‰∏ä„É™„Çπ„ÇØ„Åå„Å™„ÅÑ„Åã„ÇíAI„Åå„ÉÅ„Çß„ÉÉ„ÇØ„Åô„Çã„Ç¢„Éó„É™„ÄåAIÁÇé‰∏ä„ÉÅ„Çß„ÉÉ„Ç´„Éº„Äç„ÅÆÁÑ°ÊñôÈÖçÂ∏É„Åå„Çπ„Çø„Éº„Éà„ÄÇ",
    "pubDate": "Fri, 04 Jul 2025 15:21:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/04/news089.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/04/cover_news089.png"
  },
  {
    "title": "OpenAI„ÅÆÂÖ±ÂêåÂâµÊ•≠ËÄÖ„Çµ„ÉÑ„Ç±„Éê„ÉºÊ∞è„ÄÅSSI„ÅÆCEO„Å´„ÄÄ„ÉÄ„Éã„Ç®„É´„Éª„Ç∞„É≠„ÇπÊ∞è„ÅØÈÄÄÁ§æ",
    "description": "‰ª£CEO„ÅÆ„ÉÄ„Éã„Ç®„É´„Éª„Ç∞„É≠„ÇπÊ∞è„ÅØÈÄÄÁ§æ„Åó„ÄÅMeta„Å´ÁßªÁ±ç„Åô„Çã„Å®„Åø„Çâ„Çå„Çã„ÄÇ„Çµ„ÉÑ„Ç±„Éê„ÉºÊ∞è„ÅØMeta„Å´„Çà„ÇãË≤∑Âèé„ÅÆÂôÇ„ÇÇË™ç„ÇÅ„Åü‰∏ä„Åß„ÄÅÁã¨Á´ã„ÇíÁ∂≠ÊåÅ„Åô„ÇãÂßøÂã¢„ÇíÁ§∫„Åó„Åü„ÄÇ",
    "summary": "‰ª£CEO„ÅÆ„ÉÄ„Éã„Ç®„É´„Éª„Ç∞„É≠„ÇπÊ∞è„ÅØÈÄÄÁ§æ„Åó„ÄÅMeta„Å´ÁßªÁ±ç„Åô„Çã„Å®„Åø„Çâ„Çå„Çã„ÄÇ„Çµ„ÉÑ„Ç±„Éê„ÉºÊ∞è„ÅØMeta„Å´„Çà„ÇãË≤∑Âèé„ÅÆÂôÇ„ÇÇË™ç„ÇÅ„Åü‰∏ä„Åß„ÄÅÁã¨Á´ã„ÇíÁ∂≠ÊåÅ„Åô„ÇãÂßøÂã¢„ÇíÁ§∫„Åó„Åü„ÄÇ",
    "pubDate": "Fri, 04 Jul 2025 07:03:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2507/04/news058.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2507/04/cover_news058.jpg"
  },
  {
    "title": "Google for Nonprofits will expand to 100+ new countries and launch 10+ new no-cost AI features",
    "description": "Collage on a white background showing people in multiple different situations including two people in suits sitting on the back of an ambulance, and an adult and child using a laptop together",
    "summary": "Collage on a white background showing people in multiple different situations including two people in suits sitting on the back of an ambulance, and an adult and child using a laptop together",
    "pubDate": "Wed, 11 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/google-org/google-nonprofits-updates-june-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GoogleforNonProfit_SS.width-1300.png"
  },
  {
    "title": "OpenAI‚Äôs technology explained",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-technology-explained",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Featherless AI on Hugging Face Inference Providers üî•",
    "description": "",
    "summary": "Featherless AI on Hugging Face Inference Providers üî• We're thrilled to share that Featherless AI is ...",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-featherless",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-featherless.jpg"
  },
  {
    "title": "Position: A Theory of Deep Learning Must Include Compositional Sparsity",
    "description": "arXiv:2507.02550v1 Announce Type: cross Abstract: Overparametrized Deep Neural Networks (DNNs) have demonstrated remarkable success in a wide variety of domains too high-dimensional for classical shallow networks subject to the curse of dimensionality. However, open questions about fundamental principles, that govern the learning dynamics of DNNs, remain. In this position paper we argue that it is the ability of DNNs to exploit the compositionally sparse structure of the target function driving their success. As such, DNNs can leverage the property that most practically relevant functions can be composed from a small set of constituent functions, each of which relies only on a low-dimensional subset of all inputs. We show that this property is shared by all efficiently Turing-computable functions and is therefore highly likely present in all current learning problems. While some promising theoretical insights on questions concerned with approximation and generalization exist in the setting of compositionally sparse functions, several important questions on the learnability and optimization of DNNs remain. Completing the picture of the role of compositional sparsity in deep learning is essential to a comprehensive theory of artificial, and even general, intelligence.",
    "summary": "arXiv:2507.02550v1 Announce Type: cross Abstract: Overparametrized Deep Neural Networks (DNNs) have demonstrated remarkable success in a wide variety of domains too high-dimensional for classical shallow networks subject to the curse of dimensionality. However, open questions about fundamental principles, that govern the learning dynamics of DNNs, remain. In this position paper we argue that it is the ability of DNNs to exploit the compositionally sparse structure of the target function driving their success. As such, DNNs can leverage the property that most practically relevant functions can be composed from a small set of constituent functions, each of which relies only on a low-dimensional subset of all inputs. We show that this property is shared by all efficiently Turing-computable functions and is therefore highly likely present in all current learning problems. While some promising theoretical insights on questions concerned with approximation and generalization exist in the setting of compositionally sparse functions, several important questions on the learnability and optimization of DNNs remain. Completing the picture of the role of compositional sparsity in deep learning is essential to a comprehensive theory of artificial, and even general, intelligence.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02550",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "quanto: a pytorch quantization toolkit",
    "description": "",
    "summary": "Quanto: a PyTorch quantization backend for Optimum Quantization is a technique to reduce the computa...",
    "pubDate": "Mon, 18 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/quanto-introduction",
    "thumbnail": "https://huggingface.co/blog/assets/169_quanto_intro/thumbnail.png"
  },
  {
    "title": "Making education data accessible",
    "description": "Zelma uses GPT-4 to make education data accessible.",
    "summary": "Zelma uses GPT-4 to make education data accessible.",
    "pubDate": "Thu, 28 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zelma",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI and compute",
    "description": "We‚Äôre releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore‚Äôs Law had a 2-year doubling period)[^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it‚Äôs worth preparing for the implications of systems far outside today‚Äôs capabilities.",
    "summary": "We‚Äôre releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore‚Äôs Law had a 2-year doubling period)[^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it‚Äôs worth preparing for the implications of systems far outside today‚Äôs capabilities.",
    "pubDate": "Wed, 16 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-and-compute",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How Good LLM-Generated Password Policies Are?",
    "description": "arXiv:2506.08320v2 Announce Type: replace-cross Abstract: Generative AI technologies, particularly Large Language Models (LLMs), are rapidly being adopted across industry, academia, and government sectors, owing to their remarkable capabilities in natural language processing. However, despite their strengths, the inconsistency and unpredictability of LLM outputs present substantial challenges, especially in security-critical domains such as access control. One critical issue that emerges prominently is the consistency of LLM-generated responses, which is paramount for ensuring secure and reliable operations. In this paper, we study the application of LLMs within the context of Cybersecurity Access Control Systems. Specifically, we investigate the consistency and accuracy of LLM-generated password policies, translating natural language prompts into executable pwquality.conf configuration files. Our experimental methodology adopts two distinct approaches: firstly, we utilize pre-trained LLMs to generate configuration files purely from natural language prompts without additional guidance. Secondly, we provide these models with official pwquality.conf documentation to serve as an informative baseline. We systematically assess the soundness, accuracy, and consistency of these AI-generated configurations. Our findings underscore significant challenges in the current generation of LLMs and contribute valuable insights into refining the deployment of LLMs in Access Control Systems.",
    "summary": "arXiv:2506.08320v2 Announce Type: replace-cross Abstract: Generative AI technologies, particularly Large Language Models (LLMs), are rapidly being adopted across industry, academia, and government sectors, owing to their remarkable capabilities in natural language processing. However, despite their strengths, the inconsistency and unpredictability of LLM outputs present substantial challenges, especially in security-critical domains such as access control. One critical issue that emerges prominently is the consistency of LLM-generated responses, which is paramount for ensuring secure and reliable operations. In this paper, we study the application of LLMs within the context of Cybersecurity Access Control Systems. Specifically, we investigate the consistency and accuracy of LLM-generated password policies, translating natural language prompts into executable pwquality.conf configuration files. Our experimental methodology adopts two distinct approaches: firstly, we utilize pre-trained LLMs to generate configuration files purely from natural language prompts without additional guidance. Secondly, we provide these models with official pwquality.conf documentation to serve as an informative baseline. We systematically assess the soundness, accuracy, and consistency of these AI-generated configurations. Our findings underscore significant challenges in the current generation of LLMs and contribute valuable insights into refining the deployment of LLMs in Access Control Systems.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.08320",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Storage Regions on the HF Hub",
    "description": "",
    "summary": "Introducing Storage Regions on the Hub As part of our Enterprise Hub plan, we recently released supp...",
    "pubDate": "Fri, 03 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/regions",
    "thumbnail": "https://huggingface.co/blog/assets/172_regions/thumbnail.png"
  },
  {
    "title": "Better exploration with parameter noise",
    "description": "We‚Äôve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts performance. This exploration method is simple to implement and very rarely decreases performance, so it‚Äôs worth trying on any problem.",
    "summary": "We‚Äôve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts performance. This exploration method is simple to implement and very rarely decreases performance, so it‚Äôs worth trying on any problem.",
    "pubDate": "Thu, 27 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/better-exploration-with-parameter-noise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome Gemma - Google's new open LLM",
    "description": "",
    "summary": "Welcome Gemma - Google‚Äôs new open LLM An update to the Gemma models was released two months after th...",
    "pubDate": "Wed, 21 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma",
    "thumbnail": "https://huggingface.co/blog/assets/gemma/thumbnail.jpg"
  },
  {
    "title": "Introducing ChatGPT Plus",
    "description": "We‚Äôre launching a pilot subscription plan for ChatGPT, a conversational AI that can chat with you, answer follow-up questions, and challenge incorrect¬†assumptions.",
    "summary": "We‚Äôre launching a pilot subscription plan for ChatGPT, a conversational AI that can chat with you, answer follow-up questions, and challenge incorrect¬†assumptions.",
    "pubDate": "Wed, 01 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Inference for PROs",
    "description": "",
    "summary": "Inference for PROs Today, we're introducing Inference for PRO users - a community offering that give...",
    "pubDate": "Fri, 22 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-pro",
    "thumbnail": "https://huggingface.co/blog/assets/inference_pro/thumbnail.png"
  },
  {
    "title": "Photonic processor could streamline 6G wireless signal processing",
    "description": "By performing deep learning at the speed of light, this chip could give edge devices new capabilities for real-time data analysis.",
    "summary": "By performing deep learning at the speed of light, this chip could give edge devices new capabilities for real-time data analysis.",
    "pubDate": "Wed, 11 Jun 2025 14:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/photonic-processor-could-streamline-6g-wireless-signal-processing-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Photonic-Process-01-press.jpg"
  },
  {
    "title": "Introducing OpenAI Dublin",
    "description": "We‚Äôre growing our presence in Europe with an office in Dublin, Ireland.",
    "summary": "We‚Äôre growing our presence in Europe with an office in Dublin, Ireland.",
    "pubDate": "Wed, 13 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-dublin",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Prover-Verifier Games improve legibility of language model outputs",
    "description": "desc",
    "summary": "desc",
    "pubDate": "Wed, 17 Jul 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/prover-verifier-games-improve-legibility",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Policy Gradient with PyTorch",
    "description": "",
    "summary": "Policy Gradient with PyTorch Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 5, of the‚ö†Ô∏è ...",
    "pubDate": "Thu, 30 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-pg",
    "thumbnail": "https://huggingface.co/blog/assets/85_policy_gradient/thumbnail.gif"
  },
  {
    "title": "Introducing the Open FinLLM Leaderboard",
    "description": "",
    "summary": "Introducing the Open FinLLM Leaderboard Finding the best LLM models for finance use cases The growin...",
    "pubDate": "Fri, 04 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-finbench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_finbench.png"
  },
  {
    "title": "The Open Medical-LLM Leaderboard: Benchmarking Large Language Models in Healthcare",
    "description": "",
    "summary": "The Open Medical-LLM Leaderboard: Benchmarking Large Language Models in Healthcare Over the years, L...",
    "pubDate": "Fri, 19 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-medicalllm",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_medicalllm.png"
  },
  {
    "title": "Using Machine Learning to Aid Survivors and Race through Time",
    "description": "",
    "summary": "Using Machine Learning to Aid Survivors and Race through Time On February 6, 2023, earthquakes measu...",
    "pubDate": "Fri, 03 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/using-ml-for-disasters",
    "thumbnail": "https://huggingface.co/blog/assets/using-ml-for-disasters/thumbnail.png"
  },
  {
    "title": "DALL¬∑E: Introducing outpainting",
    "description": "Extend creativity and tell a bigger story with DALL¬∑E images of any¬†size.",
    "summary": "Extend creativity and tell a bigger story with DALL¬∑E images of any¬†size.",
    "pubDate": "Wed, 31 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-introducing-outpainting",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Federated Learning using Hugging Face and Flower",
    "description": "",
    "summary": "Federated Learning using Hugging Face and Flower This tutorial will show how to leverage Hugging Fac...",
    "pubDate": "Mon, 27 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fl-with-flower",
    "thumbnail": "https://huggingface.co/blog/assets/fl-with-flower/thumbnail.png"
  },
  {
    "title": "Teacher‚Äìstudent curriculum learning",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 01 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teacher-student-curriculum-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Cloudflare„ÅåAI„ÇØ„É≠„Éº„É©„ÉºÂØæÁ≠ñ„ÇíÂÆüË£Ö„ÄÄWeb„Ç≥„É≥„ÉÜ„É≥„ÉÑ„ÅÆÁÑ°Êñ≠ÂèéÈõÜ„Çí„Éñ„É≠„ÉÉ„ÇØ",
    "description": "Cloudflare„ÅØAI„ÇØ„É≠„Éº„É©„Éº„Å´„Çà„ÇãWeb„Ç≥„É≥„ÉÜ„É≥„ÉÑ„ÅÆÁÑ°Êñ≠ÂèéÈõÜ„ÇíÂàùÊúüË®≠ÂÆö„Åß„Éñ„É≠„ÉÉ„ÇØ„Åô„ÇãÊ©üËÉΩ„ÇíÂ∞éÂÖ•„Åó„Åü„ÄÇWeb„Çµ„Ç§„ÉàÈÅãÂñ∂ËÄÖ„ÅØAI„ÅÆÂà©Áî®ÁõÆÁöÑ„Å´Âøú„Åò„Å¶„Ç¢„ÇØ„Çª„Çπ„ÅÆÂèØÂê¶„ÇíÈÅ∏Êäû„Åß„Åç„Çã„ÄÇ",
    "summary": "Cloudflare„ÅØAI„ÇØ„É≠„Éº„É©„Éº„Å´„Çà„ÇãWeb„Ç≥„É≥„ÉÜ„É≥„ÉÑ„ÅÆÁÑ°Êñ≠ÂèéÈõÜ„ÇíÂàùÊúüË®≠ÂÆö„Åß„Éñ„É≠„ÉÉ„ÇØ„Åô„ÇãÊ©üËÉΩ„ÇíÂ∞éÂÖ•„Åó„Åü„ÄÇWeb„Çµ„Ç§„ÉàÈÅãÂñ∂ËÄÖ„ÅØAI„ÅÆÂà©Áî®ÁõÆÁöÑ„Å´Âøú„Åò„Å¶„Ç¢„ÇØ„Çª„Çπ„ÅÆÂèØÂê¶„ÇíÈÅ∏Êäû„Åß„Åç„Çã„ÄÇ",
    "pubDate": "Fri, 04 Jul 2025 07:30:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2507/04/news041.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2507/04/cover_news041.jpg"
  },
  {
    "title": "Visualize proteins on Hugging Face Spaces",
    "description": "",
    "summary": "Visualize proteins on Hugging Face Spaces In this post we will look at how we can visualize proteins...",
    "pubDate": "Wed, 24 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spaces_3dmoljs",
    "thumbnail": "https://huggingface.co/blog/assets/98_spaces_3dmoljs/thumbnail.png"
  },
  {
    "title": "Director of Machine Learning Insights [Part 2: SaaS Edition]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 2: SaaS Edition] If you or your team are interested in b...",
    "pubDate": "Fri, 13 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-2",
    "thumbnail": "https://huggingface.co/blog/assets/67_ml_director_insights/thumbnail.png"
  },
  {
    "title": "HuggingFace, IISc partner to supercharge model building on India's diverse languages",
    "description": "",
    "summary": "HuggingFace, IISc partner to supercharge model building on India's diverse languages The Indian Inst...",
    "pubDate": "Thu, 27 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/iisc-huggingface-collab",
    "thumbnail": "https://huggingface.co/blog/assets/iisc-huggingface-collab/thumbnail.png"
  },
  {
    "title": "Language models can explain neurons in language models",
    "description": "We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to score those explanations. We release a dataset of these (imperfect) explanations and scores for every neuron in GPT-2.",
    "summary": "We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to score those explanations. We release a dataset of these (imperfect) explanations and scores for every neuron in GPT-2.",
    "pubDate": "Tue, 09 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-models-can-explain-neurons-in-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making AI models more trustworthy for high-stakes settings",
    "description": "A new method helps convey uncertainty more precisely, which could give researchers and medical clinicians better information to make decisions.",
    "summary": "A new method helps convey uncertainty more precisely, which could give researchers and medical clinicians better information to make decisions.",
    "pubDate": "Thu, 01 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/making-ai-models-more-trustworthy-high-stakes-settings-0501",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Conformal-Prediction-01.jpg"
  },
  {
    "title": "OpenAI Deutschland",
    "description": "OpenAI announces the opening of its first office in Germany, based in Munich.",
    "summary": "OpenAI announces the opening of its first office in Germany, based in Munich.",
    "pubDate": "Thu, 22 May 2025 23:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-deutschland",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "We now support VLMs in smolagents!",
    "description": "",
    "summary": "We just gave sight to smolagents You hypocrite, first take the log out of your own eye, and then you...",
    "pubDate": "Fri, 24 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents-can-see",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents-can-see/thumbnail.png"
  },
  {
    "title": "Evolution through large models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolution-through-large-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "EIM-TRNG: Obfuscating Deep Neural Network Weights with Encoding-in-Memory True Random Number Generator via RowHammer",
    "description": "arXiv:2507.02206v1 Announce Type: cross Abstract: True Random Number Generators (TRNGs) play a fundamental role in hardware security, cryptographic systems, and data protection. In the context of Deep NeuralNetworks (DNNs), safeguarding model parameters, particularly weights, is critical to ensure the integrity, privacy, and intel-lectual property of AI systems. While software-based pseudo-random number generators are widely used, they lack the unpredictability and resilience offered by hardware-based TRNGs. In this work, we propose a novel and robust Encoding-in-Memory TRNG called EIM-TRNG that leverages the inherent physical randomness in DRAM cell behavior, particularly under RowHammer-induced disturbances, for the first time. We demonstrate how the unpredictable bit-flips generated through carefully controlled RowHammer operations can be harnessed as a reliable entropy source. Furthermore, we apply this TRNG framework to secure DNN weight data by encoding via a combination of fixed and unpredictable bit-flips. The encrypted data is later decrypted using a key derived from the probabilistic flip behavior, ensuring both data confidentiality and model authenticity. Our results validate the effectiveness of DRAM-based entropy extraction for robust, low-cost hardware security and offer a promising direction for protecting machine learning models at the hardware level.",
    "summary": "arXiv:2507.02206v1 Announce Type: cross Abstract: True Random Number Generators (TRNGs) play a fundamental role in hardware security, cryptographic systems, and data protection. In the context of Deep NeuralNetworks (DNNs), safeguarding model parameters, particularly weights, is critical to ensure the integrity, privacy, and intel-lectual property of AI systems. While software-based pseudo-random number generators are widely used, they lack the unpredictability and resilience offered by hardware-based TRNGs. In this work, we propose a novel and robust Encoding-in-Memory TRNG called EIM-TRNG that leverages the inherent physical randomness in DRAM cell behavior, particularly under RowHammer-induced disturbances, for the first time. We demonstrate how the unpredictable bit-flips generated through carefully controlled RowHammer operations can be harnessed as a reliable entropy source. Furthermore, we apply this TRNG framework to secure DNN weight data by encoding via a combination of fixed and unpredictable bit-flips. The encrypted data is later decrypted using a key derived from the probabilistic flip behavior, ensuring both data confidentiality and model authenticity. Our results validate the effectiveness of DRAM-based entropy extraction for robust, low-cost hardware security and offer a promising direction for protecting machine learning models at the hardware level.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02206",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TruthfulQA: Measuring how models mimic human falsehoods",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/truthfulqa",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-tuning LLMs to 1.58bit: extreme quantization made easy",
    "description": "",
    "summary": "Fine-tuning LLMs to 1.58bit: extreme quantization made easy As Large Language Models (LLMs) grow in ...",
    "pubDate": "Wed, 18 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/1_58_llm_extreme_quantization",
    "thumbnail": "https://huggingface.co/blog/assets/1_58_llm_extreme_quantization/thumbnail.png"
  },
  {
    "title": "Transforming visual accessibility",
    "description": "Be My Eyes uses GPT-4 to transform visual accessibility.",
    "summary": "Be My Eyes uses GPT-4 to transform visual accessibility.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/be-my-eyes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Lowe‚Äôs puts project expertise into every hand",
    "description": "Lowe‚Äôs partnered with OpenAI to build Mylow and Mylow Companion, AI-powered tools that bring expert help to both customers and store associates‚Äîmaking complex home improvement projects easier to plan, navigate, and complete.",
    "summary": "Lowe‚Äôs partnered with OpenAI to build Mylow and Mylow Companion, AI-powered tools that bring expert help to both customers and store associates‚Äîmaking complex home improvement projects easier to plan, navigate, and complete.",
    "pubDate": "Wed, 07 May 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lowes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "StarCoder: A State-of-the-Art LLM for Code",
    "description": "",
    "summary": "StarCoder: A State-of-the-Art LLM for Code Introducing StarCoder StarCoder and StarCoderBase are Lar...",
    "pubDate": "Thu, 04 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starcoder",
    "thumbnail": "https://huggingface.co/blog/assets/141_starcoder/starcoder_thumbnail.png"
  },
  {
    "title": "The ethics of advanced AI assistants",
    "description": "Exploring the promise and risks of a future with more capable AI",
    "summary": "Exploring the promise and risks of a future with more capable AI",
    "pubDate": "Fri, 19 Apr 2024 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/the-ethics-of-advanced-ai-assistants/",
    "thumbnail": "https://lh3.googleusercontent.com/28MrwSZMny-Gf_FVYJS0z3JbnfLXzRLNAF2BA0YQ7rbcrZWdNNwddfFsWVh_n7C31N8oXBmWexFbyce4jzaX3FSNt3EXG6mSLSlXaSx70Mc7Q0s7FF4=w1200-h630-n-nu"
  },
  {
    "title": "1,000 Scientist AI Jam Session",
    "description": "OpenAI and nine national labs bring together leading scientists for first-of-its kind event.",
    "summary": "OpenAI and nine national labs bring together leading scientists for first-of-its kind event.",
    "pubDate": "Fri, 28 Feb 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/1000-scientist-ai-jam-session",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How ü§ó Accelerate runs very large models thanks to PyTorch",
    "description": "",
    "summary": "How ü§ó Accelerate runs very large models thanks to PyTorch Load and run large models Meta AI and BigS...",
    "pubDate": "Tue, 27 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-large-models",
    "thumbnail": "https://huggingface.co/blog/assets/104_accelerate-large-models/thumbnail.png"
  },
  {
    "title": "Accelerating Protein Language Model ProtST on Intel Gaudi 2",
    "description": "",
    "summary": "Accelerating Protein Language Model ProtST on Intel Gaudi 2 Introduction Protein Language Models (PL...",
    "pubDate": "Wed, 03 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-protein-language-model-protst",
    "thumbnail": "https://huggingface.co/blog/assets/intel-protein-language-model-protst/01.jpeg"
  },
  {
    "title": "Introducing the Open Chain of Thought Leaderboard",
    "description": "",
    "summary": "Introducing the Open Chain of Thought Leaderboard Chain-of-thought prompting is emerging as a powerf...",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-cot",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_cot.png"
  },
  {
    "title": "Enhance Your Models in 5 Minutes with the Hugging Face Kernel Hub",
    "description": "",
    "summary": "üèéÔ∏è Enhance Your Models in 5 Minutes with the Hugging Face Kernel Hub Boost your model performance wi...",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hello-hf-kernels",
    "thumbnail": "https://huggingface.co/blog/assets/hello-hf-kernels/kernel-hub-five-mins-short.png"
  },
  {
    "title": "OpenAI at the Paris AI Action Summit",
    "description": "OpenAI looks forward to engaging with global leaders on AI‚Äôs role in shaping innovation and economic prosperity.",
    "summary": "OpenAI looks forward to engaging with global leaders on AI‚Äôs role in shaping innovation and economic prosperity.",
    "pubDate": "Fri, 07 Feb 2025 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-at-the-paris-ai-action-summit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Thinking with images",
    "description": "OpenAI o3 and o4-mini represent a significant breakthrough in visual perception by reasoning with images in their chain of thought.",
    "summary": "OpenAI o3 and o4-mini represent a significant breakthrough in visual perception by reasoning with images in their chain of thought.",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/thinking-with-images",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Unlocking Longer Generation with Key-Value Cache Quantization",
    "description": "",
    "summary": "Unlocking Longer Generation with Key-Value Cache Quantization At Hugging Face, we are excited to sha...",
    "pubDate": "Thu, 16 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kv-cache-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/kv_cache_quantization/thumbnail.png"
  },
  {
    "title": "Welcome, Pieter and Shivon!",
    "description": "We have two more team¬†updates.",
    "summary": "We have two more team¬†updates.",
    "pubDate": "Tue, 26 Apr 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/welcome-pieter-and-shivon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ControlNet in Diffusers üß®",
    "description": "",
    "summary": "Ultra fast ControlNet with üß® Diffusers Ever since Stable Diffusion took the world by storm, people h...",
    "pubDate": "Fri, 03 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/controlnet",
    "thumbnail": "https://huggingface.co/blog/assets/controlnet/thumbnail.png"
  },
  {
    "title": "The Technology Behind BLOOM Training",
    "description": "",
    "summary": "The Technology Behind BLOOM Training In recent years, training ever larger language models has becom...",
    "pubDate": "Thu, 14 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-megatron-deepspeed",
    "thumbnail": "https://huggingface.co/blog/assets/86_bloom_megatron_deepspeed/thumbnail.png"
  },
  {
    "title": "OpenAI leadership team update",
    "description": "We‚Äôre happy to announce several executive role changes that reflect our recent progress and will ensure continued momentum toward our next major¬†milestones.",
    "summary": "We‚Äôre happy to announce several executive role changes that reflect our recent progress and will ensure continued momentum toward our next major¬†milestones.",
    "pubDate": "Thu, 05 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-team-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The 4 Things Qwen-3's Chat Template Teaches Us",
    "description": "",
    "summary": "The 4 Things Qwen-3‚Äôs Chat Template Teaches Us What a boring Jinja snippet tells us about the new Qw...",
    "pubDate": "Wed, 30 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/qwen-3-chat-template-deep-dive",
    "thumbnail": "https://huggingface.co/blog/assets/qwen-3-chat-template-deep-dive/thumbnail.png"
  },
  {
    "title": "Our approach to AI safety",
    "description": "Ensuring that AI systems are built, deployed, and used safely is critical to our mission.",
    "summary": "Ensuring that AI systems are built, deployed, and used safely is critical to our mission.",
    "pubDate": "Wed, 05 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/our-approach-to-ai-safety",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI announces leadership transition",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-announces-leadership-transition",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Red-Teaming Large Language Models",
    "description": "",
    "summary": "Red-Teaming Large Language Models Warning: This article is about red-teaming and as such contains ex...",
    "pubDate": "Fri, 24 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/red-teaming",
    "thumbnail": "https://huggingface.co/blog/assets/red-teaming/thumbnail.png"
  },
  {
    "title": "Faster Text Generation with Self-Speculative Decoding",
    "description": "",
    "summary": "Faster Text Generation with Self-Speculative Decoding Self-speculative decoding, proposed in LayerSk...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/layerskip",
    "thumbnail": "https://huggingface.co/blog/assets/layerskip/thumbnail.png"
  },
  {
    "title": "Speak is personalizing language learning with AI",
    "description": "A conversation with Connor Zwick, CEO & Co-founder of Speak.",
    "summary": "A conversation with Connor Zwick, CEO & Co-founder of Speak.",
    "pubDate": "Tue, 22 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/speak-connor-zwick",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Object Detection Leaderboard",
    "description": "",
    "summary": "Object Detection Leaderboard: Decoding Metrics and Their Potential Pitfalls Welcome to our latest di...",
    "pubDate": "Mon, 18 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/object-detection-leaderboard",
    "thumbnail": "https://huggingface.co/blog/assets/object-detection-leaderboard/thumbnail.png"
  },
  {
    "title": "Video generation models as world simulators",
    "description": "We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.",
    "summary": "We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.",
    "pubDate": "Thu, 15 Feb 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/video-generation-models-as-world-simulators",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Subtyping in DHOL -- Extended preprint",
    "description": "arXiv:2507.02855v1 Announce Type: cross Abstract: The recently introduced dependent typed higher-order logic (DHOL) offers an interesting compromise between expressiveness and automation support. It sacrifices the decidability of its type system in order to significantly extend its expressiveness over standard HOL. Yet it retains strong automated theorem proving support via a sound and complete translation to HOL. We leverage this design to extend DHOL with refinement and quotient types. Both of these are commonly requested by practitioners but rarely provided by automated theorem provers. This is because they inherently require undecidable typing and thus are very difficult to retrofit to decidable type systems. But with DHOL already doing the heavy lifting, adding them is not only possible but elegant and simple. Concretely, we add refinement and quotient types as special cases of subtyping. This turns the associated canonical inclusion resp. projection maps into identity maps and thus avoids costly changes in representation. We present the syntax, semantics, and translation to HOL for the extended language, including the proofs of soundness and completeness.",
    "summary": "arXiv:2507.02855v1 Announce Type: cross Abstract: The recently introduced dependent typed higher-order logic (DHOL) offers an interesting compromise between expressiveness and automation support. It sacrifices the decidability of its type system in order to significantly extend its expressiveness over standard HOL. Yet it retains strong automated theorem proving support via a sound and complete translation to HOL. We leverage this design to extend DHOL with refinement and quotient types. Both of these are commonly requested by practitioners but rarely provided by automated theorem provers. This is because they inherently require undecidable typing and thus are very difficult to retrofit to decidable type systems. But with DHOL already doing the heavy lifting, adding them is not only possible but elegant and simple. Concretely, we add refinement and quotient types as special cases of subtyping. This turns the associated canonical inclusion resp. projection maps into identity maps and thus avoids costly changes in representation. We present the syntax, semantics, and translation to HOL for the extended language, including the proofs of soundness and completeness.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02855",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Get an audio overview of Search results in Labs, then click through to learn more.",
    "description": "A phone screen showing Google search results with a section titled 'Search Labs | Audio Overviews' and an audio player.",
    "summary": "A phone screen showing Google search results with a section titled 'Search Labs | Audio Overviews' and an audio player.",
    "pubDate": "Fri, 13 Jun 2025 15:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/audio-overviews-search-labs/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AudioOverview_SS.max-1440x810.png"
  },
  {
    "title": "OpenAI Five Finals",
    "description": "We‚Äôll be holding our final live event for OpenAI Five at 11:30am PT on April 13.",
    "summary": "We‚Äôll be holding our final live event for OpenAI Five at 11:30am PT on April 13.",
    "pubDate": "Tue, 26 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-finals",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning",
    "description": "arXiv:2507.02302v1 Announce Type: cross Abstract: Domain-Adaptive Pre-training (DAP) has recently gained attention for its effectiveness in fine-tuning pre-trained models. Building on this, continual DAP has been explored to develop pre-trained models capable of incrementally incorporating different domain datasets. However, existing continual DAP methods face several limitations: (1) high computational cost and GPU memory usage during training; (2) sensitivity to incremental data order; and (3) providing a single, generalized model for all end tasks, which contradicts the essence of DAP. In this paper, we propose DoMIX, a novel approach that addresses these challenges by leveraging LoRA modules, a representative parameter-efficient fine-tuning (PEFT) method. Our approach enables efficient and parallel domain-adaptive pre-training that is robust to domain order and effectively utilizes accumulated knowledge to provide tailored pre-trained models for specific tasks. We also demonstrate that our method can be extended beyond the DAP setting to standard LLM fine-tuning scenarios. Code is available at https://github.com/dohoonkim-ai/DoMIX.",
    "summary": "arXiv:2507.02302v1 Announce Type: cross Abstract: Domain-Adaptive Pre-training (DAP) has recently gained attention for its effectiveness in fine-tuning pre-trained models. Building on this, continual DAP has been explored to develop pre-trained models capable of incrementally incorporating different domain datasets. However, existing continual DAP methods face several limitations: (1) high computational cost and GPU memory usage during training; (2) sensitivity to incremental data order; and (3) providing a single, generalized model for all end tasks, which contradicts the essence of DAP. In this paper, we propose DoMIX, a novel approach that addresses these challenges by leveraging LoRA modules, a representative parameter-efficient fine-tuning (PEFT) method. Our approach enables efficient and parallel domain-adaptive pre-training that is robust to domain order and effectively utilizes accumulated knowledge to provide tailored pre-trained models for specific tasks. We also demonstrate that our method can be extended beyond the DAP setting to standard LLM fine-tuning scenarios. Code is available at https://github.com/dohoonkim-ai/DoMIX.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02302",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How we leveraged distilabel to create an Argilla 2.0 Chatbot",
    "description": "",
    "summary": "How we leveraged distilabel to create an Argilla 2.0 Chatbot TL;DR Discover how to build a Chatbot f...",
    "pubDate": "Tue, 16 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/argilla-chatbot",
    "thumbnail": "https://huggingface.co/blog/assets/argilla-chatbot/thumbnail.png"
  },
  {
    "title": "Efficient Controllable Generation for SDXL with T2I-Adapters",
    "description": "",
    "summary": "Efficient Controllable Generation for SDXL with T2I-Adapters T2I-Adapter is an efficient plug-and-pl...",
    "pubDate": "Fri, 08 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/t2i-sdxl-adapters",
    "thumbnail": "https://huggingface.co/blog/assets/t2i-sdxl-adapters/thumbnail.png"
  },
  {
    "title": "Going multimodal: How Prezi is leveraging the Hub and the Expert Support Program to accelerate their ML roadmap",
    "description": "",
    "summary": "Going multimodal: How Prezi is leveraging the Hub and the Expert Support Program to accelerate their...",
    "pubDate": "Wed, 19 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/prezi-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/70_sempre_health/thumbnailprezi.jpg"
  },
  {
    "title": "We are hiring interns!",
    "description": "",
    "summary": "We are hiring interns! Want to help build the future at -- if we may say so ourselves -- one of the ...",
    "pubDate": "Tue, 29 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/interns-2023",
    "thumbnail": "https://huggingface.co/blog/assets/interns-2023/thumbnail.png"
  },
  {
    "title": "Using AI to fight climate change",
    "description": "AI is a powerful technology that will transform our future, so how can we best apply it to help combat climate change and find sustainable solutions?",
    "summary": "AI is a powerful technology that will transform our future, so how can we best apply it to help combat climate change and find sustainable solutions?",
    "pubDate": "Fri, 21 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/using-ai-to-fight-climate-change/",
    "thumbnail": "https://lh3.googleusercontent.com/_7lNDyMo0JuzMRu0wVUtaJuXaEPDy8ay20vcsv08JvF3fMkEbk20mGBWdI09Wg0USIinNH5urB5nudEGZWRvTeUNOz_WOAwcduNdQQQNGx-JgtQE1aE=w1200-h630-n-nu"
  },
  {
    "title": "Welcome PaliGemma 2 ‚Äì New vision language models by Google",
    "description": "",
    "summary": "Welcome PaliGemma 2 ‚Äì New vision language models by Google We are excited to welcome Google's all-ne...",
    "pubDate": "Thu, 05 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma2",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma/Paligemma2.png"
  },
  {
    "title": "„ÄåAI„ÅåËÄÉ„Åà„ÅüÊñôÁêÜ„ÅØ„Å©„Çì„Å™Âë≥Ôºü„Äç‚Äï‚ÄïÂÖâÊñáÁ§æ„ÄÅAIÊ¥ªÁî®„Åó„ÅüVTuber„ÉÅ„É£„É≥„Éç„É´ÂßãÂãï",
    "description": "„ÄåAI„ÅåËÄÉ„Åà„ÅüÊñôÁêÜ„ÅØ„Å©„Çì„Å™Âë≥„Åå„Åô„Çã„ÅÆ„ÅãÔºü„Äç‚Äï‚ÄïÂá∫ÁâàÁ§æ„ÅÆÂÖâÊñáÁ§æ„ÅåAI„ÇíÊ¥ªÁî®„Åó„ÄÅ„Åì„ÅÆ„Çà„ÅÜ„Å™„ÉÜ„Éº„Éû„ÅÆYouTube„ÉÅ„É£„É≥„Éç„É´„ÇíÂßã„ÇÅ„Åü„ÄÇ",
    "summary": "„ÄåAI„ÅåËÄÉ„Åà„ÅüÊñôÁêÜ„ÅØ„Å©„Çì„Å™Âë≥„Åå„Åô„Çã„ÅÆ„ÅãÔºü„Äç‚Äï‚ÄïÂá∫ÁâàÁ§æ„ÅÆÂÖâÊñáÁ§æ„ÅåAI„ÇíÊ¥ªÁî®„Åó„ÄÅ„Åì„ÅÆ„Çà„ÅÜ„Å™„ÉÜ„Éº„Éû„ÅÆYouTube„ÉÅ„É£„É≥„Éç„É´„ÇíÂßã„ÇÅ„Åü„ÄÇ",
    "pubDate": "Fri, 04 Jul 2025 12:35:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/04/news075.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/04/cover_news075.jpg"
  },
  {
    "title": "BenchmarkQED: Automated benchmarking of RAG systems",
    "description": "<p>BenchmarkQED is an open-source toolkit for benchmarking RAG systems using automated query generation, evaluation, and dataset prep. It shows that LazyGraphRAG outperforms standard methods, especially on complex, global queries.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/'>BenchmarkQED: Automated benchmarking of RAG systems</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>BenchmarkQED is an open-source toolkit for benchmarking RAG systems using automated query generation, evaluation, and dataset prep. It shows that LazyGraphRAG outperforms standard methods, especially on complex, global queries.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/'>BenchmarkQED: Automated benchmarking of RAG systems</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 05 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "The NLP Course is becoming the LLM Course!",
    "description": "",
    "summary": "The NLP Course is becoming the LLM Course! Education has always been at the heart of Hugging Face‚Äôs ...",
    "pubDate": "Thu, 03 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llm-course",
    "thumbnail": "https://huggingface.co/blog/assets/llm-course/llm-course-rename-thumbnail.png"
  },
  {
    "title": "VQ Diffusion with üß® Diffusers",
    "description": "",
    "summary": "VQ-Diffusion Vector Quantized Diffusion (VQ-Diffusion) is a conditional latent diffusion model devel...",
    "pubDate": "Wed, 30 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vq-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/117_vq_diffusion/thumbnail.png"
  },
  {
    "title": "Share your open ML datasets on Hugging Face Hub!",
    "description": "",
    "summary": "Share your open ML datasets on Hugging Face Hub! If you're working on data-intensive research or mac...",
    "pubDate": "Tue, 12 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/researcher-dataset-sharing",
    "thumbnail": "https://huggingface.co/blog/assets/researcher-dataset-sharing/thumbnail.png"
  },
  {
    "title": "SearchGPT is a prototype of new AI search features",
    "description": "We‚Äôre testing SearchGPT, a temporary prototype of new search features that give you fast and timely answers with clear and relevant sources.",
    "summary": "We‚Äôre testing SearchGPT, a temporary prototype of new search features that give you fast and timely answers with clear and relevant sources.",
    "pubDate": "Thu, 25 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/searchgpt-prototype",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing NextGenAI",
    "description": "OpenAI commits $50M in funding and tools to leading institutions.",
    "summary": "OpenAI commits $50M in funding and tools to leading institutions.",
    "pubDate": "Tue, 04 Mar 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-nextgenai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Implicit generation and generalization methods for energy-based models",
    "description": "We‚Äôve made progress towards stable and scalable training of¬†energy-based models¬†(EBMs) resulting in better sample quality and generalization ability than existing models. Generation in EBMs spends more compute to continually refine its answers and doing so can generate samples competitive with¬†GANs¬†at low temperatures,¬†while also having mode coverage guarantees of¬†likelihood-based models. We hope these findings stimulate further research into this promising class of¬†models.",
    "summary": "We‚Äôve made progress towards stable and scalable training of¬†energy-based models¬†(EBMs) resulting in better sample quality and generalization ability than existing models. Generation in EBMs spends more compute to continually refine its answers and doing so can generate samples competitive with¬†GANs¬†at low temperatures,¬†while also having mode coverage guarantees of¬†likelihood-based models. We hope these findings stimulate further research into this promising class of¬†models.",
    "pubDate": "Thu, 21 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/energy-based-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Subscribe to Enterprise Hub with your AWS Account",
    "description": "",
    "summary": "Subscribe to Enterprise Hub with your AWS Account You can now upgrade your Hugging Face Organization...",
    "pubDate": "Thu, 09 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/enterprise-hub-aws-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/158_aws_marketplace/thumbnail.jpg"
  },
  {
    "title": "Preparing for future AI risks in biology",
    "description": "Advanced AI can transform biology and medicine‚Äîbut also raises biosecurity risks. We‚Äôre proactively assessing capabilities and implementing safeguards to prevent misuse.",
    "summary": "Advanced AI can transform biology and medicine‚Äîbut also raises biosecurity risks. We‚Äôre proactively assessing capabilities and implementing safeguards to prevent misuse.",
    "pubDate": "Wed, 18 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/preparing-for-future-ai-capabilities-in-biology",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust",
    "description": "arXiv:2507.02197v1 Announce Type: new Abstract: As LLMs are increasingly studied as role-playing agents to generate synthetic data for human behavioral research, ensuring that their outputs remain coherent with their assigned roles has become a critical concern. In this paper, we investigate how consistently LLM-based role-playing agents' stated beliefs about the behavior of the people they are asked to role-play ('what they say') correspond to their actual behavior during role-play ('how they act'). Specifically, we establish an evaluation framework to rigorously measure how well beliefs obtained by prompting the model can predict simulation outcomes in advance. Using an augmented version of the GenAgents persona bank and the Trust Game (a standard economic game used to quantify players' trust and reciprocity), we introduce a belief-behavior consistency metric to systematically investigate how it is affected by factors such as: (1) the types of beliefs we elicit from LLMs, like expected outcomes of simulations versus task-relevant attributes of individual characters LLMs are asked to simulate; (2) when and how we present LLMs with relevant information about Trust Game; and (3) how far into the future we ask the model to forecast its actions. We also explore how feasible it is to impose a researcher's own theoretical priors in the event that the originally elicited beliefs are misaligned with research objectives. Our results reveal systematic inconsistencies between LLMs' stated (or imposed) beliefs and the outcomes of their role-playing simulation, at both an individual- and population-level. Specifically, we find that, even when models appear to encode plausible beliefs, they may fail to apply them in a consistent way. These findings highlight the need to identify how and when LLMs' stated beliefs align with their simulated behavior, allowing researchers to use LLM-based agents appropriately in behavioral studies.",
    "summary": "arXiv:2507.02197v1 Announce Type: new Abstract: As LLMs are increasingly studied as role-playing agents to generate synthetic data for human behavioral research, ensuring that their outputs remain coherent with their assigned roles has become a critical concern. In this paper, we investigate how consistently LLM-based role-playing agents' stated beliefs about the behavior of the people they are asked to role-play ('what they say') correspond to their actual behavior during role-play ('how they act'). Specifically, we establish an evaluation framework to rigorously measure how well beliefs obtained by prompting the model can predict simulation outcomes in advance. Using an augmented version of the GenAgents persona bank and the Trust Game (a standard economic game used to quantify players' trust and reciprocity), we introduce a belief-behavior consistency metric to systematically investigate how it is affected by factors such as: (1) the types of beliefs we elicit from LLMs, like expected outcomes of simulations versus task-relevant attributes of individual characters LLMs are asked to simulate; (2) when and how we present LLMs with relevant information about Trust Game; and (3) how far into the future we ask the model to forecast its actions. We also explore how feasible it is to impose a researcher's own theoretical priors in the event that the originally elicited beliefs are misaligned with research objectives. Our results reveal systematic inconsistencies between LLMs' stated (or imposed) beliefs and the outcomes of their role-playing simulation, at both an individual- and population-level. Specifically, we find that, even when models appear to encode plausible beliefs, they may fail to apply them in a consistent way. These findings highlight the need to identify how and when LLMs' stated beliefs align with their simulated behavior, allowing researchers to use LLM-based agents appropriately in behavioral studies.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02197",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hybrid AI model crafts smooth, high-quality videos in seconds",
    "description": "The CausVid generative AI tool uses a diffusion model to teach an autoregressive (frame-by-frame) system to rapidly produce stable, high-resolution videos.",
    "summary": "The CausVid generative AI tool uses a diffusion model to teach an autoregressive (frame-by-frame) system to rapidly produce stable, high-resolution videos.",
    "pubDate": "Tue, 06 May 2025 12:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/causevid-hybrid-ai-model-crafts-smooth-high-quality-videos-in-seconds-0506",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-CausVid.jpg"
  },
  {
    "title": "DuckDB: run SQL queries on 50,000+ datasets on the Hugging Face Hub",
    "description": "",
    "summary": "DuckDB: run SQL queries on 50,000+ datasets on the Hugging Face Hub The Hugging Face Hub is dedicate...",
    "pubDate": "Wed, 07 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hub-duckdb",
    "thumbnail": "https://huggingface.co/blog/assets/hub_duckdb/hub_duckdb.png"
  },
  {
    "title": "OpenAI o1 Contributions",
    "description": "OpenAI o1 Contributions",
    "summary": "OpenAI o1 Contributions",
    "pubDate": "Thu, 12 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/openai-o1-contributions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An anomaly detection framework anyone can use",
    "description": "PhD student Sarah Alnegheimish wants to make machine learning systems accessible.",
    "summary": "PhD student Sarah Alnegheimish wants to make machine learning systems accessible.",
    "pubDate": "Wed, 28 May 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/anomaly-detection-framework-anyone-can-use-sarah-alnegheimish-0528",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Sarah-Abdulaziz-Alnegheimish.JPG"
  },
  {
    "title": "Testimony before the U.S. Senate",
    "description": "The following is the written testimony of Sam Altman, Chief Executive Officer of OpenAI, before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "summary": "The following is the written testimony of Sam Altman, Chief Executive Officer of OpenAI, before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/testimony-of-sam-altman-before-the-us-senate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accurately analyzing large scale qualitative data",
    "description": "Viable uses GPT-4 to analyze qualitative data at a revolutionary scale with unparalleled accuracy.",
    "summary": "Viable uses GPT-4 to analyze qualitative data at a revolutionary scale with unparalleled accuracy.",
    "pubDate": "Fri, 07 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/viable",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Running Privacy-Preserving Inference on Hugging Face Endpoints",
    "description": "",
    "summary": "Running Privacy-Preserving Inferences on Hugging Face Endpoints This is a guest blog post by the Zam...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fhe-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/fhe-endpoints/thumbnail.png"
  },
  {
    "title": "Using & Mixing Hugging Face Models with Gradio 2.0",
    "description": "",
    "summary": "Using & Mixing Hugging Face Models with Gradio 2.0 Cross-posted from the Gradio blog. The Hugging Fa...",
    "pubDate": "Tue, 25 May 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio",
    "thumbnail": "https://huggingface.co/blog/assets/22_gradio/gradio.png"
  },
  {
    "title": "Overview of natively supported quantization schemes in ü§ó Transformers",
    "description": "",
    "summary": "Overview of natively supported quantization schemes in ü§ó Transformers We aim to give a clear overvie...",
    "pubDate": "Tue, 12 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/overview-quantization-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/163_overview_quantization_transformers/thumbnail.jpg"
  },
  {
    "title": "MIT Department of Economics to launch James M. and Cathleen D. Stone Center on Inequality and Shaping the Future of Work",
    "description": "With support from the Stone Foundation, the center will advance cutting-edge research and inform policy.",
    "summary": "With support from the Stone Foundation, the center will advance cutting-edge research and inform policy.",
    "pubDate": "Tue, 13 May 2025 16:35:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-economics-department-launches-james-cathleen-stone-center-inequality-shaping-future-work-0513",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-campus.jpg"
  },
  {
    "title": "OpenAI‚Äôs Approach to Frontier Risk",
    "description": "An Update for the UK AI Safety Summit",
    "summary": "An Update for the UK AI Safety Summit",
    "pubDate": "Thu, 26 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/our-approach-to-frontier-risk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "UK government harnesses Gemini to support faster planning decisions",
    "description": "A summary of how Extract works",
    "summary": "A summary of how Extract works",
    "pubDate": "Mon, 09 Jun 2025 11:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/around-the-globe/google-europe/united-kingdom/uk-government-harnesses-gemini-to-support-faster-planning-decisions/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/overview.width-1300.png"
  },
  {
    "title": "Response to NIST Executive Order on AI",
    "description": "The National Institute of Standards and Technology (NIST) request for information related to its assignments under sections 4.1, 4.5, and 11 of the Executive Order Concerning Artificial Intelligence",
    "summary": "The National Institute of Standards and Technology (NIST) request for information related to its assignments under sections 4.1, 4.5, and 11 of the Executive Order Concerning Artificial Intelligence",
    "pubDate": "Fri, 02 Feb 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-nist-executive-order-on-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MIT‚Äôs McGovern Institute is shaping brain science and improving human lives on a global scale",
    "description": "A quarter century after its founding, the McGovern Institute reflects on its discoveries in the areas of neuroscience, neurotechnology, artificial intelligence, brain-body connections, and therapeutics.",
    "summary": "A quarter century after its founding, the McGovern Institute reflects on its discoveries in the areas of neuroscience, neurotechnology, artificial intelligence, brain-body connections, and therapeutics.",
    "pubDate": "Fri, 18 Apr 2025 10:40:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-mcgovern-institute-shaping-brain-science-improving-human-lives-0418",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-mcgovern-madonna-fmri-600x900.jpg"
  },
  {
    "title": "Securing Research Infrastructure for Advanced AI",
    "description": "We outline our architecture that supports the secure training of frontier models.",
    "summary": "We outline our architecture that supports the secure training of frontier models.",
    "pubDate": "Wed, 05 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/securing-research-infrastructure-for-advanced-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference",
    "description": "arXiv:2502.04700v4 Announce Type: replace-cross Abstract: The rapid growth of large models has raised concerns about their environmental impact and equity in accessibility due to significant computational costs. Low-Rank Adapters (LoRA) offer a lightweight solution for finetuning large models, resulting in an abundance of publicly available adapters tailored to diverse domains. We ask: Can these pretrained adapters be leveraged to further streamline adaptation to new tasks while addressing these challenges? We introduce EigenLoRAx, a parameter-efficient finetuning method that recycles existing adapters to create a principal subspace aligned with their shared domain knowledge which can be further augmented with orthogonal basis vectors in low-resource scenarios. This enables rapid adaptation to new tasks by learning only lightweight coefficients on the principal components of the subspace-eliminating the need to finetune entire adapters. EigenLoRAx requires significantly fewer parameters and memory, improving efficiency for both training and inference. Our method demonstrates strong performance across diverse domains and tasks, offering a scalable for edge-based applications, personalization, and equitable deployment of large models in resource-constrained environments.",
    "summary": "arXiv:2502.04700v4 Announce Type: replace-cross Abstract: The rapid growth of large models has raised concerns about their environmental impact and equity in accessibility due to significant computational costs. Low-Rank Adapters (LoRA) offer a lightweight solution for finetuning large models, resulting in an abundance of publicly available adapters tailored to diverse domains. We ask: Can these pretrained adapters be leveraged to further streamline adaptation to new tasks while addressing these challenges? We introduce EigenLoRAx, a parameter-efficient finetuning method that recycles existing adapters to create a principal subspace aligned with their shared domain knowledge which can be further augmented with orthogonal basis vectors in low-resource scenarios. This enables rapid adaptation to new tasks by learning only lightweight coefficients on the principal components of the subspace-eliminating the need to finetune entire adapters. EigenLoRAx requires significantly fewer parameters and memory, improving efficiency for both training and inference. Our method demonstrates strong performance across diverse domains and tasks, offering a scalable for edge-based applications, personalization, and equitable deployment of large models in resource-constrained environments.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.04700",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI API",
    "description": "We‚Äôre releasing an API for accessing new AI models developed by OpenAI.",
    "summary": "We‚Äôre releasing an API for accessing new AI models developed by OpenAI.",
    "pubDate": "Thu, 11 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From DeepSpeed to FSDP and Back Again with Hugging Face Accelerate",
    "description": "",
    "summary": "A Hugging Face Accelerate Story of Multiple Backends: FSDP and DeepSpeed There are two popular imple...",
    "pubDate": "Thu, 13 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deepspeed-to-fsdp-and-back",
    "thumbnail": "https://huggingface.co/blog/assets/deepspeed-to-fsdp-and-back/thumbnail.png"
  },
  {
    "title": "TTS Arena: Benchmarking Text-to-Speech Models in the Wild",
    "description": "",
    "summary": "TTS Arena: Benchmarking Text-to-Speech Models in the Wild Automated measurement of the quality of te...",
    "pubDate": "Tue, 27 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-tts",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail.png"
  },
  {
    "title": "AI for Game Development: Creating a Farming Game in 5 Days. Part 1",
    "description": "",
    "summary": "AI for Game Development: Creating a Farming Game in 5 Days. Part 1 Welcome to AI for Game Developmen...",
    "pubDate": "Mon, 02 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-1",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail.png"
  },
  {
    "title": "Gemini CLI: your open-source AI agent",
    "description": "Gemini CLI icon on a background with code snippets",
    "summary": "Gemini CLI icon on a background with code snippets",
    "pubDate": "Wed, 25 Jun 2025 13:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_CLI_Hero_Final.width-1300.png"
  },
  {
    "title": "Kernel Density Bayesian Inverse Reinforcement Learning",
    "description": "arXiv:2303.06827v4 Announce Type: replace-cross Abstract: Inverse reinforcement learning (IRL) methods infer an agent's reward function using demonstrations of expert behavior. A Bayesian IRL approach models a distribution over candidate reward functions, capturing a degree of uncertainty in the inferred reward function. This is critical in some applications, such as those involving clinical data. Typically, Bayesian IRL algorithms require large demonstration datasets, which may not be available in practice. In this work, we incorporate existing domain-specific data to achieve better posterior concentration rates. We study a common setting in clinical and biological applications where we have access to expert demonstrations and known reward functions for a set of training tasks. Our aim is to learn the reward function of a new test task given limited expert demonstrations. Existing Bayesian IRL methods impose restrictions on the form of input data, thus limiting the incorporation of training task data. To better leverage information from training tasks, we introduce kernel density Bayesian inverse reinforcement learning (KD-BIRL). Our approach employs a conditional kernel density estimator, which uses the known reward functions of the training tasks to improve the likelihood estimation across a range of reward functions and demonstration samples. Our empirical results highlight KD-BIRL's faster concentration rate in comparison to baselines, particularly in low test task expert demonstration data regimes. Additionally, we are the first to provide theoretical guarantees of posterior concentration for a Bayesian IRL algorithm. Taken together, this work introduces a principled and theoretically grounded framework that enables Bayesian IRL to be applied across a variety of domains.",
    "summary": "arXiv:2303.06827v4 Announce Type: replace-cross Abstract: Inverse reinforcement learning (IRL) methods infer an agent's reward function using demonstrations of expert behavior. A Bayesian IRL approach models a distribution over candidate reward functions, capturing a degree of uncertainty in the inferred reward function. This is critical in some applications, such as those involving clinical data. Typically, Bayesian IRL algorithms require large demonstration datasets, which may not be available in practice. In this work, we incorporate existing domain-specific data to achieve better posterior concentration rates. We study a common setting in clinical and biological applications where we have access to expert demonstrations and known reward functions for a set of training tasks. Our aim is to learn the reward function of a new test task given limited expert demonstrations. Existing Bayesian IRL methods impose restrictions on the form of input data, thus limiting the incorporation of training task data. To better leverage information from training tasks, we introduce kernel density Bayesian inverse reinforcement learning (KD-BIRL). Our approach employs a conditional kernel density estimator, which uses the known reward functions of the training tasks to improve the likelihood estimation across a range of reward functions and demonstration samples. Our empirical results highlight KD-BIRL's faster concentration rate in comparison to baselines, particularly in low test task expert demonstration data regimes. Additionally, we are the first to provide theoretical guarantees of posterior concentration for a Bayesian IRL algorithm. Taken together, this work introduces a principled and theoretically grounded framework that enables Bayesian IRL to be applied across a variety of domains.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2303.06827",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Director of Machine Learning Insights [Part 3: Finance Edition]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 3: Finance Edition] If you're interested in building ML ...",
    "pubDate": "Tue, 14 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-3",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/thumbnail.png"
  },
  {
    "title": "Sequence-aware Pre-training for Echocardiography Probe Movement Guidance",
    "description": "arXiv:2408.15026v2 Announce Type: replace-cross Abstract: Echocardiography is an essential medical technique for diagnosing cardiovascular diseases, but its high operational complexity has led to a shortage of trained professionals. To address this issue, we introduce a novel probe movement guidance algorithm that has the potential to be applied in guiding robotic systems or novices with probe pose adjustment for high-quality standard plane image acquisition.Cardiac ultrasound faces two major challenges: (1) the inherently complex structure of the heart, and (2) significant individual variations. Previous works have only learned the population-averaged structure of the heart rather than personalized cardiac structures, leading to a performance bottleneck. Clinically, we observe that sonographers dynamically adjust their interpretation of a patient's cardiac anatomy based on prior scanning sequences, consequently refining their scanning strategies. Inspired by this, we propose a novel sequence-aware self-supervised pre-training method. Specifically, our approach learns personalized three-dimensional cardiac structural features by predicting the masked-out image features and probe movement actions in a scanning sequence. We hypothesize that if the model can predict the missing content it has acquired a good understanding of personalized cardiac structure. Extensive experiments on a large-scale expert scanning dataset with 1.31 million samples demonstrate that our proposed sequence-aware paradigm can effectively reduce probe guidance errors compared to other advanced baseline methods. Our code will be released after acceptance.",
    "summary": "arXiv:2408.15026v2 Announce Type: replace-cross Abstract: Echocardiography is an essential medical technique for diagnosing cardiovascular diseases, but its high operational complexity has led to a shortage of trained professionals. To address this issue, we introduce a novel probe movement guidance algorithm that has the potential to be applied in guiding robotic systems or novices with probe pose adjustment for high-quality standard plane image acquisition.Cardiac ultrasound faces two major challenges: (1) the inherently complex structure of the heart, and (2) significant individual variations. Previous works have only learned the population-averaged structure of the heart rather than personalized cardiac structures, leading to a performance bottleneck. Clinically, we observe that sonographers dynamically adjust their interpretation of a patient's cardiac anatomy based on prior scanning sequences, consequently refining their scanning strategies. Inspired by this, we propose a novel sequence-aware self-supervised pre-training method. Specifically, our approach learns personalized three-dimensional cardiac structural features by predicting the masked-out image features and probe movement actions in a scanning sequence. We hypothesize that if the model can predict the missing content it has acquired a good understanding of personalized cardiac structure. Extensive experiments on a large-scale expert scanning dataset with 1.31 million samples demonstrate that our proposed sequence-aware paradigm can effectively reduce probe guidance errors compared to other advanced baseline methods. Our code will be released after acceptance.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.15026",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Economic impacts research at OpenAI",
    "description": "Call for expressions of interest to study the economic impacts of large language¬†models.",
    "summary": "Call for expressions of interest to study the economic impacts of large language¬†models.",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/economic-impacts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "‚ÄúPeriodic table of machine learning‚Äù could fuel AI discovery",
    "description": "Researchers have created a unifying framework that can help scientists combine existing ideas to improve AI models or create new ones.",
    "summary": "Researchers have created a unifying framework that can help scientists combine existing ideas to improve AI models or create new ones.",
    "pubDate": "Wed, 23 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/machine-learning-periodic-table-could-fuel-ai-discovery-0423",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Periodic-Algorithm-01-PRESS.jpg"
  },
  {
    "title": "EliseAI improves housing and healthcare efficiency with AI",
    "description": "A conversation with Minna Song, CEO & Co-founder of EliseAI.",
    "summary": "A conversation with Minna Song, CEO & Co-founder of EliseAI.",
    "pubDate": "Tue, 18 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/eliseai-minna-song",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New generative AI tools open the doors of music creation",
    "description": "Our latest AI music technologies are now available in MusicFX DJ, Music AI Sandbox and YouTube Shorts",
    "summary": "Our latest AI music technologies are now available in MusicFX DJ, Music AI Sandbox and YouTube Shorts",
    "pubDate": "Wed, 23 Oct 2024 16:53:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/new-generative-ai-tools-open-the-doors-of-music-creation/",
    "thumbnail": "https://lh3.googleusercontent.com/7CWJ9fVeC97FrWgcispxyms9gTL_1PIDMIwBYTQNnU8S56JaxGB2Z4ThqZ-1vBTO-u-UBZg_cYhG8PtZjYP0rPabUbg5x2cCUnNJuiZAZBsE8u7Kvig=w1200-h630-n-nu"
  },
  {
    "title": "FastRTC: The Real-Time Communication Library for Python",
    "description": "",
    "summary": "FastRTC: The Real-Time Communication Library for Python In the last few months, many new real-time s...",
    "pubDate": "Tue, 25 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastrtc",
    "thumbnail": "https://huggingface.co/blog/assets/fastrtc/fastrtc_logo.jpg"
  },
  {
    "title": "Bamba: Inference-Efficient Hybrid Mamba2 Model",
    "description": "",
    "summary": "Bamba: Inference-Efficient Hybrid Mamba2 Model üêç TL;DR We introduce Bamba-9B, an inference-efficient...",
    "pubDate": "Wed, 18 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bamba",
    "thumbnail": "https://huggingface.co/blog/assets/bamba/bamba_thumbnail.png"
  },
  {
    "title": "Accelerating engineering cycles 20% with OpenAI",
    "description": "Accelerating engineering cycles 20% with OpenAI.",
    "summary": "Accelerating engineering cycles 20% with OpenAI.",
    "pubDate": "Thu, 06 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/factory",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pairing data with APIs to unlock customer value",
    "description": "Rakuten Pairs Data with AI to Unlock Customer Insights and Value",
    "summary": "Rakuten Pairs Data with AI to Unlock Customer Insights and Value",
    "pubDate": "Wed, 07 Aug 2024 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rakuten",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI technical goals",
    "description": "OpenAI‚Äôs mission is to build safe AI, and ensure AI‚Äôs benefits are as widely and evenly distributed as possible.",
    "summary": "OpenAI‚Äôs mission is to build safe AI, and ensure AI‚Äôs benefits are as widely and evenly distributed as possible.",
    "pubDate": "Mon, 20 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-technical-goals",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Updating the Frontier Safety Framework",
    "description": "Our next iteration of the FSF sets out stronger security protocols on the path to AGI",
    "summary": "Our next iteration of the FSF sets out stronger security protocols on the path to AGI",
    "pubDate": "Tue, 04 Feb 2025 16:41:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/updating-the-frontier-safety-framework/",
    "thumbnail": "https://lh3.googleusercontent.com/0fu18H8X3miSAuwcVJ7Zulis_LZAL7F4bIFU7FYFA2dGx3Rm3HHlm5N202B0dtKBuS7iI5SD1QgpFPuU-O3TPzb7iG1Ns-loZzinRB3M3X3W-MAgIQ=w1200-h630-n-nu"
  },
  {
    "title": "New embedding models and API updates",
    "description": "We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management tools, and soon, lower pricing on GPT-3.5 Turbo.",
    "summary": "We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management tools, and soon, lower pricing on GPT-3.5 Turbo.",
    "pubDate": "Thu, 25 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-embedding-models-and-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding Trade offs When Conditioning Synthetic Data",
    "description": "arXiv:2507.02217v1 Announce Type: cross Abstract: Learning robust object detectors from only a handful of images is a critical challenge in industrial vision systems, where collecting high quality training data can take months. Synthetic data has emerged as a key solution for data efficient visual inspection and pick and place robotics. Current pipelines rely on 3D engines such as Blender or Unreal, which offer fine control but still require weeks to render a small dataset, and the resulting images often suffer from a large gap between simulation and reality. Diffusion models promise a step change because they can generate high quality images in minutes, yet precise control, especially in low data regimes, remains difficult. Although many adapters now extend diffusion beyond plain text prompts, the effect of different conditioning schemes on synthetic data quality is poorly understood. We study eighty diverse visual concepts drawn from four standard object detection benchmarks and compare two conditioning strategies: prompt based and layout based. When the set of conditioning cues is narrow, prompt conditioning yields higher quality synthetic data; as diversity grows, layout conditioning becomes superior. When layout cues match the full training distribution, synthetic data raises mean average precision by an average of thirty four percent and by as much as one hundred seventy seven percent compared with using real data alone.",
    "summary": "arXiv:2507.02217v1 Announce Type: cross Abstract: Learning robust object detectors from only a handful of images is a critical challenge in industrial vision systems, where collecting high quality training data can take months. Synthetic data has emerged as a key solution for data efficient visual inspection and pick and place robotics. Current pipelines rely on 3D engines such as Blender or Unreal, which offer fine control but still require weeks to render a small dataset, and the resulting images often suffer from a large gap between simulation and reality. Diffusion models promise a step change because they can generate high quality images in minutes, yet precise control, especially in low data regimes, remains difficult. Although many adapters now extend diffusion beyond plain text prompts, the effect of different conditioning schemes on synthetic data quality is poorly understood. We study eighty diverse visual concepts drawn from four standard object detection benchmarks and compare two conditioning strategies: prompt based and layout based. When the set of conditioning cues is narrow, prompt conditioning yields higher quality synthetic data; as diversity grows, layout conditioning becomes superior. When layout cues match the full training distribution, synthetic data raises mean average precision by an average of thirty four percent and by as much as one hundred seventy seven percent compared with using real data alone.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02217",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings",
    "description": "arXiv:2504.20808v2 Announce Type: replace-cross Abstract: This paper introduces SoccerDiffusion, a transformer-based diffusion model designed to learn end-to-end control policies for humanoid robot soccer directly from real-world gameplay recordings. Using data collected from RoboCup competitions, the model predicts joint command trajectories from multi-modal sensor inputs, including vision, proprioception, and game state. We employ a distillation technique to enable real-time inference on embedded platforms that reduces the multi-step diffusion process to a single step. Our results demonstrate the model's ability to replicate complex motion behaviors such as walking, kicking, and fall recovery both in simulation and on physical robots. Although high-level tactical behavior remains limited, this work provides a robust foundation for subsequent reinforcement learning or preference optimization methods. We release the dataset, pretrained models, and code under: https://bit-bots.github.io/SoccerDiffusion",
    "summary": "arXiv:2504.20808v2 Announce Type: replace-cross Abstract: This paper introduces SoccerDiffusion, a transformer-based diffusion model designed to learn end-to-end control policies for humanoid robot soccer directly from real-world gameplay recordings. Using data collected from RoboCup competitions, the model predicts joint command trajectories from multi-modal sensor inputs, including vision, proprioception, and game state. We employ a distillation technique to enable real-time inference on embedded platforms that reduces the multi-step diffusion process to a single step. Our results demonstrate the model's ability to replicate complex motion behaviors such as walking, kicking, and fall recovery both in simulation and on physical robots. Although high-level tactical behavior remains limited, this work provides a robust foundation for subsequent reinforcement learning or preference optimization methods. We release the dataset, pretrained models, and code under: https://bit-bots.github.io/SoccerDiffusion",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.20808",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "An Introduction to AI Secure LLM Safety Leaderboard",
    "description": "",
    "summary": "An Introduction to AI Secure LLM Safety Leaderboard Given the widespread adoption of LLMs, it is cri...",
    "pubDate": "Fri, 26 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-decodingtrust",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_decodingtrust.png"
  },
  {
    "title": "Hugging Face models in Amazon Bedrock",
    "description": "",
    "summary": "Use Hugging Face models with Amazon Bedrock We are excited to announce that popular open models from...",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bedrock-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/bedrock-marketplace/thumbnail.png"
  },
  {
    "title": "An Overview of Inference Solutions on Hugging Face",
    "description": "",
    "summary": "An Overview of Inference Solutions on Hugging Face Every day, developers and organizations are adopt...",
    "pubDate": "Mon, 21 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-update",
    "thumbnail": "https://huggingface.co/blog/assets/116_inference_update/widget.png"
  },
  {
    "title": "Images altered to trick machine vision can influence humans too",
    "description": "In a series of experiments published in Nature Communications, we found evidence that human judgments are indeed systematically influenced by adversarial perturbations.",
    "summary": "In a series of experiments published in Nature Communications, we found evidence that human judgments are indeed systematically influenced by adversarial perturbations.",
    "pubDate": "Tue, 02 Jan 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/images-altered-to-trick-machine-vision-can-influence-humans-too/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "Understanding the source of what we see and hear online",
    "description": "Today we‚Äôre introducing new technology to help researchers identify content created by our tools and joining the Coalition for Content Provenance and Authenticity Steering Committee to promote industry standards.",
    "summary": "Today we‚Äôre introducing new technology to help researchers identify content created by our tools and joining the Coalition for Content Provenance and Authenticity Steering Committee to promote industry standards.",
    "pubDate": "Tue, 07 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/understanding-the-source-of-what-we-see-and-hear-online",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Expanded access to Google Vids and no-cost AI tools in Classroom",
    "description": "Google Meet icon, Google Classroom icon, with various browser windows",
    "summary": "Google Meet icon, Google Classroom icon, with various browser windows",
    "pubDate": "Mon, 30 Jun 2025 13:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/education/expanded-access-to-google-vids-and-no-cost-ai-tools-in-classroom/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/027-ISTE-EDU-Keyword_blog-Google_Workspace_fo.width-1300.png"
  },
  {
    "title": "Hugging Face Collaborates with Microsoft to Launch Hugging Face Model Catalog on Azure",
    "description": "",
    "summary": "Hugging Face Collaborates with Microsoft to launch Hugging Face Model Catalog on Azure Today, we are...",
    "pubDate": "Wed, 24 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-endpoints-on-azure",
    "thumbnail": "https://huggingface.co/blog/assets/75_hugging_face_endpoints_on_azure/01.jpg"
  },
  {
    "title": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "description": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "summary": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "pubDate": "Tue, 22 Oct 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-chief-compliance-officer-announcement",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Vision Language Models (Better, Faster, Stronger)",
    "description": "",
    "summary": "Vision Language Models (Better, Faster, Stronger) Motivation Vision Language Models (VLMs) are the t...",
    "pubDate": "Mon, 12 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vlms-2025",
    "thumbnail": "https://huggingface.co/blog/assets/vlms2/vlms2.png"
  },
  {
    "title": "Opinion Classification with Kili and HuggingFace AutoTrain",
    "description": "",
    "summary": "Opinion Classification with Kili and HuggingFace AutoTrain Introduction Understanding your users‚Äô ne...",
    "pubDate": "Thu, 28 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/opinion-classification-with-kili",
    "thumbnail": "https://huggingface.co/blog/assets/59_opinion-classification-with-kili/thumbnail.png"
  },
  {
    "title": "Why we‚Äôre switching to Hugging Face Inference Endpoints, and maybe you should too",
    "description": "",
    "summary": "Why we‚Äôre switching to Hugging Face Inference Endpoints, and maybe you should too Hugging Face recen...",
    "pubDate": "Wed, 15 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mantis-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/mantis1.png"
  },
  {
    "title": "Aligning Frozen LLMs by Reinforcement Learning: An Iterative Reweight-then-Optimize Approach",
    "description": "arXiv:2506.17828v2 Announce Type: replace-cross Abstract: Aligning large language models (LLMs) with human preferences usually requires fine-tuning methods such as RLHF and DPO. These methods directly optimize the model parameters, so they cannot be used in test-time to improve model performance, nor are they applicable when the model weights are not accessible. In contrast, test-time methods sidestep weight updates by leveraging reward functions to guide and improve output quality. However, they incur high inference costs, and their one-shot guidance is often based on imperfect reward or value functions, leading to suboptimal outputs. In this work, we present a method named Iterative Reweight-then-Optimize (IRO), a reinforcement learning (RL) framework that performs RL-style alignment of the (frozen) base model without touching its parameters. During training, each iteration (i) samples candidates from the base model, (ii) resamples using current value functions, and (iii) trains a new lightweight value function that guides the next decoding pass. At test time, the value functions are used to guide the base model generation via a search-based optimization process. Notably, users can apply IRO to align a model on their own dataset, similar to OpenAI's reinforcement fine-tuning (RFT), but without requiring access to the model weights.",
    "summary": "arXiv:2506.17828v2 Announce Type: replace-cross Abstract: Aligning large language models (LLMs) with human preferences usually requires fine-tuning methods such as RLHF and DPO. These methods directly optimize the model parameters, so they cannot be used in test-time to improve model performance, nor are they applicable when the model weights are not accessible. In contrast, test-time methods sidestep weight updates by leveraging reward functions to guide and improve output quality. However, they incur high inference costs, and their one-shot guidance is often based on imperfect reward or value functions, leading to suboptimal outputs. In this work, we present a method named Iterative Reweight-then-Optimize (IRO), a reinforcement learning (RL) framework that performs RL-style alignment of the (frozen) base model without touching its parameters. During training, each iteration (i) samples candidates from the base model, (ii) resamples using current value functions, and (iii) trains a new lightweight value function that guides the next decoding pass. At test time, the value functions are used to guide the base model generation via a search-based optimization process. Notably, users can apply IRO to align a model on their own dataset, similar to OpenAI's reinforcement fine-tuning (RFT), but without requiring access to the model weights.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17828",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Rocket Money x Hugging Face: Scaling Volatile ML Models in Production",
    "description": "",
    "summary": "Rocket Money x Hugging Face: Scaling Volatile ML Models in Production 'We discovered that they were ...",
    "pubDate": "Tue, 19 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rocketmoney-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/rocketmoney.png"
  },
  {
    "title": "Liftoff! How to get started with your first ML project üöÄ",
    "description": "",
    "summary": "Liftoff! How to get started with your first ML project üöÄ People who are new to the Machine Learning ...",
    "pubDate": "Wed, 29 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/your-first-ml-project",
    "thumbnail": "https://huggingface.co/blog/assets/84_first_ml_project/thumbnail.png"
  },
  {
    "title": "Creating websites in minutes with AI Website Builder",
    "description": "Wix‚Äôs AI Website Builder, powered by OpenAI, lets anyone create a full website in minutes‚Äîjust by describing their idea in a conversation.",
    "summary": "Wix‚Äôs AI Website Builder, powered by OpenAI, lets anyone create a full website in minutes‚Äîjust by describing their idea in a conversation.",
    "pubDate": "Thu, 29 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/wix",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Benchmarking Language Model Performance on 5th Gen Xeon at GCP",
    "description": "",
    "summary": "Benchmarking Language Model Performance on 5th Gen Xeon at GCP TL;DR: We benchmark 2 representative ...",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-gcp-c4",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Introduction to the Open Leaderboard for Japanese LLMs",
    "description": "",
    "summary": "Introduction to the Open Leaderboard for Japanese LLMs LLMs are now increasingly capable in English,...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-japanese",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_japanese.png"
  },
  {
    "title": "Course Launch Community Event",
    "description": "",
    "summary": "Course Launch Community Event We are excited to share that after a lot of work from the Hugging Face...",
    "pubDate": "Tue, 26 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/course-launch-event",
    "thumbnail": "https://huggingface.co/blog/assets/34_course_launch/speakers_day1_thumb.png"
  },
  {
    "title": "Powering next generation applications with OpenAI Codex",
    "description": "Codex is now powering 70 different applications across a variety of use cases through the OpenAI¬†API.",
    "summary": "Codex is now powering 70 different applications across a variety of use cases through the OpenAI¬†API.",
    "pubDate": "Tue, 24 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/codex-apps",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Patch Time Series Transformer in Hugging Face",
    "description": "",
    "summary": "Patch Time Series Transformer in Hugging Face - Getting Started In this blog, we provide examples of...",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/patchtst",
    "thumbnail": "https://huggingface.co/blog/assets/patchtst/thumbnail.png"
  },
  {
    "title": "Learning to model other minds",
    "description": "We‚Äôre releasing an algorithm which accounts for the fact that other agents are learning too, and discovers self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner‚Äôs dilemma. This algorithm, Learning with Opponent-Learning Awareness (LOLA), is a small step towards agents that model other minds.",
    "summary": "We‚Äôre releasing an algorithm which accounts for the fact that other agents are learning too, and discovers self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner‚Äôs dilemma. This algorithm, Learning with Opponent-Learning Awareness (LOLA), is a small step towards agents that model other minds.",
    "pubDate": "Thu, 14 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-model-other-minds",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Agentic AI Process Observability: Discovering Behavioral Variability",
    "description": "arXiv:2505.20127v2 Announce Type: replace Abstract: AI agents that leverage Large Language Models (LLMs) are increasingly becoming core building blocks of modern software systems. A wide range of frameworks is now available to support the specification of such applications. These frameworks enable the definition of agent setups using natural language prompting, which specifies the roles, goals, and tools assigned to the various agents involved. Within such setups, agent behavior is non-deterministic for any given input, highlighting the critical need for robust debugging and observability tools. In this work, we explore the use of process and causal discovery applied to agent execution trajectories as a means of enhancing developer observability. This approach aids in monitoring and understanding the emergent variability in agent behavior. Additionally, we complement this with LLM-based static analysis techniques to distinguish between intended and unintended behavioral variability. We argue that such instrumentation is essential for giving developers greater control over evolving specifications and for identifying aspects of functionality that may require more precise and explicit definitions.",
    "summary": "arXiv:2505.20127v2 Announce Type: replace Abstract: AI agents that leverage Large Language Models (LLMs) are increasingly becoming core building blocks of modern software systems. A wide range of frameworks is now available to support the specification of such applications. These frameworks enable the definition of agent setups using natural language prompting, which specifies the roles, goals, and tools assigned to the various agents involved. Within such setups, agent behavior is non-deterministic for any given input, highlighting the critical need for robust debugging and observability tools. In this work, we explore the use of process and causal discovery applied to agent execution trajectories as a means of enhancing developer observability. This approach aids in monitoring and understanding the emergent variability in agent behavior. Additionally, we complement this with LLM-based static analysis techniques to distinguish between intended and unintended behavioral variability. We argue that such instrumentation is essential for giving developers greater control over evolving specifications and for identifying aspects of functionality that may require more precise and explicit definitions.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.20127",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deploy models on AWS Inferentia2 from Hugging Face",
    "description": "",
    "summary": "Deploy models on AWS Inferentia2 from Hugging Face AWS Inferentia2 is the latest AWS machine learnin...",
    "pubDate": "Wed, 22 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inferentia-inference-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/inferentia-inference-endpoints/thumbnail.jpg"
  },
  {
    "title": "The Gauss-Markov Adjunction: Categorical Semantics of Residuals in Supervised Learning",
    "description": "arXiv:2507.02442v1 Announce Type: new Abstract: Enhancing the intelligibility and interpretability of machine learning is a crucial task in responding to the demand for Explicability as an AI principle, and in promoting the better social implementation of AI. The aim of our research is to contribute to this improvement by reformulating machine learning models through the lens of category theory, thereby developing a semantic framework for structuring and understanding AI systems. Our categorical modeling in this paper clarifies and formalizes the structural interplay between residuals and parameters in supervised learning. The present paper focuses on the multiple linear regression model, which represents the most basic form of supervised learning. By defining two concrete categories corresponding to parameters and data, along with an adjoint pair of functors between them, we introduce our categorical formulation of supervised learning. We show that the essential structure of this framework is captured by what we call the Gauss-Markov Adjunction. Within this setting, the dual flow of information can be explicitly described as a correspondence between variations in parameters and residuals. The ordinary least squares estimator for the parameters and the minimum residual are related via the preservation of limits by the right adjoint functor. Furthermore, we position this formulation as an instance of extended denotational semantics for supervised learning, and propose applying a semantic perspective developed in theoretical computer science as a formal foundation for Explicability in AI.",
    "summary": "arXiv:2507.02442v1 Announce Type: new Abstract: Enhancing the intelligibility and interpretability of machine learning is a crucial task in responding to the demand for Explicability as an AI principle, and in promoting the better social implementation of AI. The aim of our research is to contribute to this improvement by reformulating machine learning models through the lens of category theory, thereby developing a semantic framework for structuring and understanding AI systems. Our categorical modeling in this paper clarifies and formalizes the structural interplay between residuals and parameters in supervised learning. The present paper focuses on the multiple linear regression model, which represents the most basic form of supervised learning. By defining two concrete categories corresponding to parameters and data, along with an adjoint pair of functors between them, we introduce our categorical formulation of supervised learning. We show that the essential structure of this framework is captured by what we call the Gauss-Markov Adjunction. Within this setting, the dual flow of information can be explicitly described as a correspondence between variations in parameters and residuals. The ordinary least squares estimator for the parameters and the minimum residual are related via the preservation of limits by the right adjoint functor. Furthermore, we position this formulation as an instance of extended denotational semantics for supervised learning, and propose applying a semantic perspective developed in theoretical computer science as a formal foundation for Explicability in AI.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02442",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Optimizing Stable Diffusion for Intel CPUs with NNCF and ü§ó Optimum",
    "description": "",
    "summary": "Optimizing Stable Diffusion for Intel CPUs with NNCF and ü§ó Optimum Latent Diffusion models are game ...",
    "pubDate": "Thu, 25 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-optimize-sd-intel",
    "thumbnail": "https://huggingface.co/blog/assets/train_optimize_sd_intel/thumbnail.png"
  },
  {
    "title": "Learning dexterity",
    "description": "We‚Äôve trained a human-like robot hand to manipulate physical objects with unprecedented¬†dexterity.",
    "summary": "We‚Äôve trained a human-like robot hand to manipulate physical objects with unprecedented¬†dexterity.",
    "pubDate": "Mon, 30 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-dexterity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Semi-supervised knowledge transfer for deep learning from private training data",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/semi-supervised-knowledge-transfer-for-deep-learning-from-private-training-data",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "We‚Äôre improving Ask Photos and bringing it to more Google Photos users.",
    "description": "Animation showing a search in Ask Photos for 'Photos that'd make great phone backgrounds,' then a grid of initial results followed by the most relevant photos.",
    "summary": "Animation showing a search in Ask Photos for 'Photos that'd make great phone backgrounds,' then a grid of initial results followed by the most relevant photos.",
    "pubDate": "Thu, 26 Jun 2025 17:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/photos/updates-ask-photos-search/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/wagtailvideo-mbcag8qi_thumb.jpg"
  },
  {
    "title": "Disrupting malicious uses of AI: June 2025",
    "description": "In our June 2025 update, we outline how we‚Äôre disrupting malicious uses of AI‚Äîthrough safety tools that detect and counter abuse, support democratic values, and promote responsible AI deployment for the benefit of all.",
    "summary": "In our June 2025 update, we outline how we‚Äôre disrupting malicious uses of AI‚Äîthrough safety tools that detect and counter abuse, support democratic values, and promote responsible AI deployment for the benefit of all.",
    "pubDate": "Thu, 05 Jun 2025 02:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai-june-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deep Learning with Proteins",
    "description": "",
    "summary": "Deep Learning With Proteins I have two audiences in mind while writing this. One is biologists who a...",
    "pubDate": "Fri, 02 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-learning-with-proteins",
    "thumbnail": "https://huggingface.co/blog/assets/119_deep_learning_with_proteins/folding_example.png"
  },
  {
    "title": "Deep research System Card",
    "description": "This report outlines the safety work carried out prior to releasing deep research including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "summary": "This report outlines the safety work carried out prior to releasing deep research including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "pubDate": "Tue, 25 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-research-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fetch Consolidates AI Tools and Saves 30% Development Time with Hugging Face on AWS",
    "description": "",
    "summary": "Fetch Consolidates AI Tools and Saves 30% Development Time with Hugging Face on AWS If you need supp...",
    "pubDate": "Thu, 23 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fetch-eap-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/fetch2.png"
  },
  {
    "title": "Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs",
    "description": "arXiv:2507.02076v1 Announce Type: new Abstract: Large language models (LLMs) have rapidly progressed into general-purpose agents capable of solving a broad spectrum of tasks. However, current models remain inefficient at reasoning: they apply fixed inference-time compute regardless of task complexity, often overthinking simple problems while underthinking hard ones. This survey presents a comprehensive review of efficient test-time compute (TTC) strategies, which aim to improve the computational efficiency of LLM reasoning. We introduce a two-tiered taxonomy that distinguishes between L1-controllability, methods that operate under fixed compute budgets, and L2-adaptiveness, methods that dynamically scale inference based on input difficulty or model confidence. We benchmark leading proprietary LLMs across diverse datasets, highlighting critical trade-offs between reasoning performance and token usage. Compared to prior surveys on efficient reasoning, our review emphasizes the practical control, adaptability, and scalability of TTC methods. Finally, we discuss emerging trends such as hybrid thinking models and identify key challenges for future work towards making LLMs more computationally efficient, robust, and responsive to user constraints.",
    "summary": "arXiv:2507.02076v1 Announce Type: new Abstract: Large language models (LLMs) have rapidly progressed into general-purpose agents capable of solving a broad spectrum of tasks. However, current models remain inefficient at reasoning: they apply fixed inference-time compute regardless of task complexity, often overthinking simple problems while underthinking hard ones. This survey presents a comprehensive review of efficient test-time compute (TTC) strategies, which aim to improve the computational efficiency of LLM reasoning. We introduce a two-tiered taxonomy that distinguishes between L1-controllability, methods that operate under fixed compute budgets, and L2-adaptiveness, methods that dynamically scale inference based on input difficulty or model confidence. We benchmark leading proprietary LLMs across diverse datasets, highlighting critical trade-offs between reasoning performance and token usage. Compared to prior surveys on efficient reasoning, our review emphasizes the practical control, adaptability, and scalability of TTC methods. Finally, we discuss emerging trends such as hybrid thinking models and identify key challenges for future work towards making LLMs more computationally efficient, robust, and responsive to user constraints.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02076",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Artificial Intelligence Index Report 2025",
    "description": "arXiv:2504.07139v2 Announce Type: replace Abstract: Welcome to the eighth edition of the AI Index report. The 2025 Index is our most comprehensive to date and arrives at an important moment, as AI's influence across society, the economy, and global governance continues to intensify. New in this year's report are in-depth analyses of the evolving landscape of AI hardware, novel estimates of inference costs, and new analyses of AI publication and patenting trends. We also introduce fresh data on corporate adoption of responsible AI practices, along with expanded coverage of AI's growing role in science and medicine. Since its founding in 2017 as an offshoot of the One Hundred Year Study of Artificial Intelligence, the AI Index has been committed to equipping policymakers, journalists, executives, researchers, and the public with accurate, rigorously validated, and globally sourced data. Our mission has always been to help these stakeholders make better-informed decisions about the development and deployment of AI. In a world where AI is discussed everywhere - from boardrooms to kitchen tables - this mission has never been more essential. The AI Index continues to lead in tracking and interpreting the most critical trends shaping the field - from the shifting geopolitical landscape and the rapid evolution of underlying technologies, to AI's expanding role in business, policymaking, and public life. Longitudinal tracking remains at the heart of our mission. In a domain advancing at breakneck speed, the Index provides essential context - helping us understand where AI stands today, how it got here, and where it may be headed next. Recognized globally as one of the most authoritative resources on artificial intelligence, the AI Index has been cited in major media outlets such as The New York Times, Bloomberg, and The Guardian; referenced in hundreds of academic papers; and used by policymakers and government agencies around the world.",
    "summary": "arXiv:2504.07139v2 Announce Type: replace Abstract: Welcome to the eighth edition of the AI Index report. The 2025 Index is our most comprehensive to date and arrives at an important moment, as AI's influence across society, the economy, and global governance continues to intensify. New in this year's report are in-depth analyses of the evolving landscape of AI hardware, novel estimates of inference costs, and new analyses of AI publication and patenting trends. We also introduce fresh data on corporate adoption of responsible AI practices, along with expanded coverage of AI's growing role in science and medicine. Since its founding in 2017 as an offshoot of the One Hundred Year Study of Artificial Intelligence, the AI Index has been committed to equipping policymakers, journalists, executives, researchers, and the public with accurate, rigorously validated, and globally sourced data. Our mission has always been to help these stakeholders make better-informed decisions about the development and deployment of AI. In a world where AI is discussed everywhere - from boardrooms to kitchen tables - this mission has never been more essential. The AI Index continues to lead in tracking and interpreting the most critical trends shaping the field - from the shifting geopolitical landscape and the rapid evolution of underlying technologies, to AI's expanding role in business, policymaking, and public life. Longitudinal tracking remains at the heart of our mission. In a domain advancing at breakneck speed, the Index provides essential context - helping us understand where AI stands today, how it got here, and where it may be headed next. Recognized globally as one of the most authoritative resources on artificial intelligence, the AI Index has been cited in major media outlets such as The New York Times, Bloomberg, and The Guardian; referenced in hundreds of academic papers; and used by policymakers and government agencies around the world.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.07139",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Gemini 2.0: our new AI model for the agentic era",
    "description": "Today, we‚Äôre announcing Gemini 2.0, our most capable multimodal AI model yet.",
    "summary": "Today, we‚Äôre announcing Gemini 2.0, our most capable multimodal AI model yet.",
    "pubDate": "Wed, 11 Dec 2024 15:30:40 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-20-our-new-ai-model-for-the-agentic-era/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/blog_gemini_hero_thumbnail.width-1300.png"
  },
  {
    "title": "Identifying AI-generated images with SynthID",
    "description": "New tool helps watermark and identify synthetic images created by Imagen",
    "summary": "New tool helps watermark and identify synthetic images created by Imagen",
    "pubDate": "Tue, 29 Aug 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/identifying-ai-generated-images-with-synthid/",
    "thumbnail": "https://lh3.googleusercontent.com/wUgtK2GBt2yZJ3dJkXtvAK84G93j6idOOalyihOMfwBxY0lR650fZZYIi3bXdgkKbBcitbUZ0ILbaIPg_-vDTgAJLlP1DO3h_UnyoZ27wl3mYSzKtw=w1200-h630-n-nu"
  },
  {
    "title": "Why OpenAI‚Äôs structure must evolve to advance our mission",
    "description": "A stronger non-profit supported by the for-profit‚Äôs success.",
    "summary": "A stronger non-profit supported by the for-profit‚Äôs success.",
    "pubDate": "Fri, 27 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/why-our-structure-must-evolve-to-advance-our-mission",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning concepts with energy functions",
    "description": "We‚Äôve developed an¬†energy-based model¬†that can quickly learn to identify and generate instances of concepts, such as near, above, between, closest, and furthest, expressed as sets of 2d points. Our model learns these concepts after only five demonstrations. We also show cross-domain transfer: we use concepts learned in a 2d particle environment to solve tasks on a 3-dimensional physics-based¬†robot.",
    "summary": "We‚Äôve developed an¬†energy-based model¬†that can quickly learn to identify and generate instances of concepts, such as near, above, between, closest, and furthest, expressed as sets of 2d points. Our model learns these concepts after only five demonstrations. We also show cross-domain transfer: we use concepts learned in a 2d particle environment to solve tasks on a 3-dimensional physics-based¬†robot.",
    "pubDate": "Wed, 07 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-concepts-with-energy-functions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "5 tips for getting started with Flow",
    "description": "Flow-generated video showing two astronaut pugs driving a car in outer space, with text overlaid saying 'Find your Flow'",
    "summary": "Flow-generated video showing two astronaut pugs driving a car in outer space, with text overlaid saying 'Find your Flow'",
    "pubDate": "Wed, 25 Jun 2025 22:45:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/flow-video-tips/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GetStartedwithFlow_SS.width-1300.png"
  },
  {
    "title": "Accelerating Stable Diffusion Inference on Intel CPUs",
    "description": "",
    "summary": "Accelerating Stable Diffusion Inference on Intel CPUs Recently, we introduced the latest generation ...",
    "pubDate": "Tue, 28 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-inference-intel",
    "thumbnail": "https://huggingface.co/blog/assets/136_stable_diffusion_inference_intel/01.png"
  },
  {
    "title": "Stochastic Neural Networks for hierarchical reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 10 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/stochastic-neural-networks-for-hierarchical-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification",
    "description": "arXiv:2507.02660v1 Announce Type: new Abstract: Modern Integrated Circuits (ICs) are becoming increasingly complex, and so is their development process. Hardware design verification entails a methodical and disciplined approach to the planning, development, execution, and sign-off of functionally correct hardware designs. This tedious process requires significant effort and time to ensure a bug-free tape-out. The field of Natural Language Processing has undergone a significant transformation with the advent of Large Language Models (LLMs). These powerful models, often referred to as Generative AI (GenAI), have revolutionized how machines understand and generate human language, enabling unprecedented advancements in a wide array of applications, including hardware design verification. This paper presents an agentic AI-based approach to hardware design verification, which empowers AI agents, in collaboration with Humain-in-the-Loop (HITL) intervention, to engage in a more dynamic, iterative, and self-reflective process, ultimately performing end-to-end hardware design and verification. This methodology is evaluated on five open-source designs, achieving over 95% coverage with reduced verification time while demonstrating superior performance, adaptability, and configurability.",
    "summary": "arXiv:2507.02660v1 Announce Type: new Abstract: Modern Integrated Circuits (ICs) are becoming increasingly complex, and so is their development process. Hardware design verification entails a methodical and disciplined approach to the planning, development, execution, and sign-off of functionally correct hardware designs. This tedious process requires significant effort and time to ensure a bug-free tape-out. The field of Natural Language Processing has undergone a significant transformation with the advent of Large Language Models (LLMs). These powerful models, often referred to as Generative AI (GenAI), have revolutionized how machines understand and generate human language, enabling unprecedented advancements in a wide array of applications, including hardware design verification. This paper presents an agentic AI-based approach to hardware design verification, which empowers AI agents, in collaboration with Humain-in-the-Loop (HITL) intervention, to engage in a more dynamic, iterative, and self-reflective process, ultimately performing end-to-end hardware design and verification. This methodology is evaluated on five open-source designs, achieving over 95% coverage with reduced verification time while demonstrating superior performance, adaptability, and configurability.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02660",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Variance reduction for policy gradient with action-dependent factorized baselines",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 20 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variance-reduction-for-policy-gradient-with-action-dependent-factorized-baselines",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Solving the Hubbard model with Neural Quantum States",
    "description": "arXiv:2507.02644v1 Announce Type: cross Abstract: The rapid development of neural quantum states (NQS) has established it as a promising framework for studying quantum many-body systems. In this work, by leveraging the cutting-edge transformer-based architectures and developing highly efficient optimization algorithms, we achieve the state-of-the-art results for the doped two-dimensional (2D) Hubbard model, arguably the minimum model for high-Tc superconductivity. Interestingly, we find different attention heads in the NQS ansatz can directly encode correlations at different scales, making it capable of capturing long-range correlations and entanglements in strongly correlated systems. With these advances, we establish the half-filled stripe in the ground state of 2D Hubbard model with the next nearest neighboring hoppings, consistent with experimental observations in cuprates. Our work establishes NQS as a powerful tool for solving challenging many-fermions systems.",
    "summary": "arXiv:2507.02644v1 Announce Type: cross Abstract: The rapid development of neural quantum states (NQS) has established it as a promising framework for studying quantum many-body systems. In this work, by leveraging the cutting-edge transformer-based architectures and developing highly efficient optimization algorithms, we achieve the state-of-the-art results for the doped two-dimensional (2D) Hubbard model, arguably the minimum model for high-Tc superconductivity. Interestingly, we find different attention heads in the NQS ansatz can directly encode correlations at different scales, making it capable of capturing long-range correlations and entanglements in strongly correlated systems. With these advances, we establish the half-filled stripe in the ground state of 2D Hubbard model with the next nearest neighboring hoppings, consistent with experimental observations in cuprates. Our work establishes NQS as a powerful tool for solving challenging many-fermions systems.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02644",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "StarCoder2 and The Stack v2",
    "description": "",
    "summary": "StarCoder2 and The Stack v2 BigCode is releasing StarCoder2, the next generation of transparently tr...",
    "pubDate": "Wed, 28 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starcoder2",
    "thumbnail": "https://huggingface.co/blog/assets/177_starcoder2/sc2-banner.png"
  },
  {
    "title": "Neural MMO: A massively multiagent game environment",
    "description": "We‚Äôre releasing a Neural¬†MMO, a massively multiagent game environment for reinforcement learning agents. Our platform supports a large, variable number of agents within a persistent and open-ended task. The inclusion of many agents and species leads to better exploration, divergent niche formation, and greater overall¬†competence.",
    "summary": "We‚Äôre releasing a Neural¬†MMO, a massively multiagent game environment for reinforcement learning agents. Our platform supports a large, variable number of agents within a persistent and open-ended task. The inclusion of many agents and species leads to better exploration, divergent niche formation, and greater overall¬†competence.",
    "pubDate": "Mon, 04 Mar 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/neural-mmo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI hackathon",
    "description": "Come to OpenAI‚Äôs office in San Francisco‚Äôs Mission District for talks and a hackathon on Saturday, March 3rd.",
    "summary": "Come to OpenAI‚Äôs office in San Francisco‚Äôs Mission District for talks and a hackathon on Saturday, March 3rd.",
    "pubDate": "Thu, 22 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-hackathon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ethical guidelines for developing the Diffusers library",
    "description": "",
    "summary": "Ethical guidelines for developing the Diffusers library We are on a journey to make our libraries mo...",
    "pubDate": "Thu, 02 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/ethics-diffusers/thumbnail.png"
  },
  {
    "title": "Using OpenAI o1 for financial analysis",
    "description": "Rogo scales AI-driven financial research with OpenAI o1",
    "summary": "Rogo scales AI-driven financial research with OpenAI o1",
    "pubDate": "Thu, 13 Feb 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rogo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Nystr√∂mformer, Approximating self-attention in linear time and memory via the Nystr√∂m method",
    "description": "",
    "summary": "Nystr√∂mformer: Approximating self-attention in linear time and memory via the Nystr√∂m method Introdu...",
    "pubDate": "Tue, 02 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nystromformer",
    "thumbnail": "https://huggingface.co/blog/assets/86_nystromformer/thumbnail.png"
  },
  {
    "title": "OpenAI and GEDI partner for Italian news content",
    "description": "OpenAI and GEDI announce strategic partnership to bring Italian-language news content to ChatGPT.",
    "summary": "OpenAI and GEDI announce strategic partnership to bring Italian-language news content to ChatGPT.",
    "pubDate": "Thu, 26 Sep 2024 04:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gedi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Helping machines understand visual content with AI",
    "description": "Coactive, founded by two MIT alumni, has built an AI-powered platform to unlock new insights from content of all types.",
    "summary": "Coactive, founded by two MIT alumni, has built an AI-powered platform to unlock new insights from content of all types.",
    "pubDate": "Mon, 09 Jun 2025 15:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/coactive-helps-machines-understand-visual-content-ai-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Coactive-AI-01-press.jpg"
  },
  {
    "title": "The power of personalized AI",
    "description": "The power of personalized AI",
    "summary": "The power of personalized AI",
    "pubDate": "Fri, 17 Jan 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/the-power-of-personalized-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Jupyter X Hugging Face",
    "description": "",
    "summary": "Jupyter X Hugging Face We‚Äôre excited to announce improved support for Jupyter notebooks hosted on th...",
    "pubDate": "Thu, 23 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/notebooks-hub",
    "thumbnail": "https://huggingface.co/blog/assets/135_notebooks-hub/before_after_notebook_rendering.png"
  },
  {
    "title": "Embedding AI into developer software",
    "description": "JetBrains uses OpenAI‚Äôs API to build its fastest-growing product ever.",
    "summary": "JetBrains uses OpenAI‚Äôs API to build its fastest-growing product ever.",
    "pubDate": "Thu, 21 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jetbrains",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaQubit tackles one of quantum computing‚Äôs biggest challenges",
    "description": "Our new AI system accurately identifies errors inside quantum computers, helping to make this new technology more reliable.",
    "summary": "Our new AI system accurately identifies errors inside quantum computers, helping to make this new technology more reliable.",
    "pubDate": "Wed, 20 Nov 2024 18:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaqubit-tackles-one-of-quantum-computings-biggest-challenges/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Social_Share_Image_-_1920_x_1080.width-1300.png"
  },
  {
    "title": "Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work",
    "description": "arXiv:2507.02760v1 Announce Type: new Abstract: The capabilities of Large Language Models (LLMs) have opened new frontiers for interacting with complex, domain-specific knowledge. However, prevailing methods like Retrieval-Augmented Generation (RAG) and general-purpose Agentic AI, while powerful, often struggle with tasks that demand deep, procedural, and methodological reasoning inherent to expert domains. RAG provides factual context but fails to convey logical frameworks; autonomous agents can be inefficient and unpredictable without domain-specific heuristics. To bridge this gap, we introduce Knowledge Protocol Engineering (KPE), a new paradigm focused on systematically translating human expert knowledge, often expressed in natural language documents, into a machine-executable Knowledge Protocol (KP). KPE shifts the focus from merely augmenting LLMs with fragmented information to endowing them with a domain's intrinsic logic, operational strategies, and methodological principles. We argue that a well-engineered Knowledge Protocol allows a generalist LLM to function as a specialist, capable of decomposing abstract queries and executing complex, multi-step tasks. This position paper defines the core principles of KPE, differentiates it from related concepts, and illustrates its potential applicability across diverse fields such as law and bioinformatics, positing it as a foundational methodology for the future of human-AI collaboration.",
    "summary": "arXiv:2507.02760v1 Announce Type: new Abstract: The capabilities of Large Language Models (LLMs) have opened new frontiers for interacting with complex, domain-specific knowledge. However, prevailing methods like Retrieval-Augmented Generation (RAG) and general-purpose Agentic AI, while powerful, often struggle with tasks that demand deep, procedural, and methodological reasoning inherent to expert domains. RAG provides factual context but fails to convey logical frameworks; autonomous agents can be inefficient and unpredictable without domain-specific heuristics. To bridge this gap, we introduce Knowledge Protocol Engineering (KPE), a new paradigm focused on systematically translating human expert knowledge, often expressed in natural language documents, into a machine-executable Knowledge Protocol (KP). KPE shifts the focus from merely augmenting LLMs with fragmented information to endowing them with a domain's intrinsic logic, operational strategies, and methodological principles. We argue that a well-engineered Knowledge Protocol allows a generalist LLM to function as a specialist, capable of decomposing abstract queries and executing complex, multi-step tasks. This position paper defines the core principles of KPE, differentiates it from related concepts, and illustrates its potential applicability across diverse fields such as law and bioinformatics, positing it as a foundational methodology for the future of human-AI collaboration.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02760",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Zico Kolter Joins OpenAI‚Äôs Board of Directors",
    "description": "Zico Kolter Joins OpenAI‚Äôs Board of Directors We‚Äôre strengthening our governance with expertise in AI safety and alignment. Zico will also join the Safety & Security Committee",
    "summary": "Zico Kolter Joins OpenAI‚Äôs Board of Directors We‚Äôre strengthening our governance with expertise in AI safety and alignment. Zico will also join the Safety & Security Committee",
    "pubDate": "Thu, 08 Aug 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zico-kolter-joins-openais-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Put AI to work for your product team",
    "description": "Put AI to work for your product team",
    "summary": "Put AI to work for your product team",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/put-ai-to-work-for-your-product-team",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Five",
    "description": "Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota¬†2.",
    "summary": "Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota¬†2.",
    "pubDate": "Mon, 25 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and AWS partner to make AI more accessible",
    "description": "",
    "summary": "Hugging Face and AWS partner to make AI more accessible It‚Äôs time to make AI open and accessible to ...",
    "pubDate": "Tue, 21 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aws-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/131_aws-partnership/aws-partnership-thumbnail.png"
  },
  {
    "title": "Answering quantum physics questions with OpenAI o1",
    "description": "Quantum physicist Mario Krenn uses OpenAI o1 to help answer life's biggest questions.",
    "summary": "Quantum physicist Mario Krenn uses OpenAI o1 to help answer life's biggest questions.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-quantum-physics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Governance of superintelligence",
    "description": "Now is a good time to start thinking about the governance of superintelligence‚Äîfuture AI systems dramatically more capable than even AGI.",
    "summary": "Now is a good time to start thinking about the governance of superintelligence‚Äîfuture AI systems dramatically more capable than even AGI.",
    "pubDate": "Mon, 22 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/governance-of-superintelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation",
    "description": "arXiv:2507.02314v1 Announce Type: cross Abstract: Few-shot anomaly generation is emerging as a practical solution for augmenting the scarce anomaly data in industrial quality control settings. An ideal generator would meet three demands at once, namely (i) keep the normal background intact, (ii) inpaint anomalous regions to tightly overlap with the corresponding anomaly masks, and (iii) generate anomalous regions in a semantically valid location, while still producing realistic, diverse appearances from only a handful of real examples. Existing diffusion-based methods usually satisfy at most two of these requirements: global anomaly generators corrupt the background, whereas mask-guided ones often falter when the mask is imprecise or misplaced. We propose MAGIC--Mask-guided inpainting with multi-level perturbations and Context-aware alignment--to resolve all three issues. At its core, MAGIC fine-tunes a Stable Diffusion inpainting backbone that preserves normal regions and ensures strict adherence of the synthesized anomaly to the supplied mask, directly addressing background corruption and misalignment. To offset the diversity loss that fine-tuning can cause, MAGIC adds two complementary perturbation strategies: (i) Gaussian prompt-level perturbation applied during fine-tuning and inference that broadens the global appearance of anomalies while avoiding low-fidelity textual appearances, and (ii) mask-guided spatial noise injection that enriches local texture variations. Additionally, the context-aware mask alignment module forms semantic correspondences and relocates masks so that every anomaly remains plausibly contained within the host object, eliminating out-of-boundary artifacts. Under a consistent identical evaluation protocol on the MVTec-AD dataset, MAGIC outperforms previous state-of-the-arts in downstream anomaly tasks.",
    "summary": "arXiv:2507.02314v1 Announce Type: cross Abstract: Few-shot anomaly generation is emerging as a practical solution for augmenting the scarce anomaly data in industrial quality control settings. An ideal generator would meet three demands at once, namely (i) keep the normal background intact, (ii) inpaint anomalous regions to tightly overlap with the corresponding anomaly masks, and (iii) generate anomalous regions in a semantically valid location, while still producing realistic, diverse appearances from only a handful of real examples. Existing diffusion-based methods usually satisfy at most two of these requirements: global anomaly generators corrupt the background, whereas mask-guided ones often falter when the mask is imprecise or misplaced. We propose MAGIC--Mask-guided inpainting with multi-level perturbations and Context-aware alignment--to resolve all three issues. At its core, MAGIC fine-tunes a Stable Diffusion inpainting backbone that preserves normal regions and ensures strict adherence of the synthesized anomaly to the supplied mask, directly addressing background corruption and misalignment. To offset the diversity loss that fine-tuning can cause, MAGIC adds two complementary perturbation strategies: (i) Gaussian prompt-level perturbation applied during fine-tuning and inference that broadens the global appearance of anomalies while avoiding low-fidelity textual appearances, and (ii) mask-guided spatial noise injection that enriches local texture variations. Additionally, the context-aware mask alignment module forms semantic correspondences and relocates masks so that every anomaly remains plausibly contained within the host object, eliminating out-of-boundary artifacts. Under a consistent identical evaluation protocol on the MVTec-AD dataset, MAGIC outperforms previous state-of-the-arts in downstream anomaly tasks.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02314",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Join us for OpenAI‚Äôs first developer conference on November 6 in San Francisco",
    "description": "Developer registration for in-person attendance will open in the coming weeks and developers everywhere will be able to livestream the keynote.",
    "summary": "Developer registration for in-person attendance will open in the coming weeks and developers everywhere will be able to livestream the keynote.",
    "pubDate": "Wed, 06 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/announcing-openai-devday",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster TensorFlow models in Hugging Face Transformers",
    "description": "",
    "summary": "Faster TensorFlow models in Hugging Face Transformers In the last few months, the Hugging Face team ...",
    "pubDate": "Tue, 26 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-serving",
    "thumbnail": "https://huggingface.co/blog/assets/10_tf-serving/thumbnail.png"
  },
  {
    "title": "Towards a Playground to Democratize Experimentation and Benchmarking of AI Agents for Network Troubleshooting",
    "description": "arXiv:2507.01997v1 Announce Type: cross Abstract: Recent research has demonstrated the effectiveness of Artificial Intelligence (AI), and more specifically, Large Language Models (LLMs), in supporting network configuration synthesis and automating network diagnosis tasks, among others. In this preliminary work, we restrict our focus to the application of AI agents to network troubleshooting and elaborate on the need for a standardized, reproducible, and open benchmarking platform, where to build and evaluate AI agents with low operational effort.",
    "summary": "arXiv:2507.01997v1 Announce Type: cross Abstract: Recent research has demonstrated the effectiveness of Artificial Intelligence (AI), and more specifically, Large Language Models (LLMs), in supporting network configuration synthesis and automating network diagnosis tasks, among others. In this preliminary work, we restrict our focus to the application of AI agents to network troubleshooting and elaborate on the need for a standardized, reproducible, and open benchmarking platform, where to build and evaluate AI agents with low operational effort.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01997",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "An update on disrupting deceptive uses of AI",
    "description": "OpenAI‚Äôs mission is to ensure that artificial general intelligence benefits all of humanity. We are dedicated to identifying, preventing, and disrupting attempts to abuse our models for harmful ends.",
    "summary": "OpenAI‚Äôs mission is to ensure that artificial general intelligence benefits all of humanity. We are dedicated to identifying, preventing, and disrupting attempts to abuse our models for harmful ends.",
    "pubDate": "Wed, 09 Oct 2024 03:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/an-update-on-disrupting-deceptive-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ÁîüÊàêAI„ÇíÂÖ®Á§æ„É¨„Éô„É´„Åß‰Ωø„ÅÜGMO„Éö„Éë„Éú„ÄÅDMM.com„ÄÅMIXI„Å™„Å©8Á§æ„ÅÆÁèæÁä∂„ÅØÔºü„ÄÄÊó•Êú¨CTOÂçî‰ºö„Åå„Éí„Ç¢„É™„É≥„Ç∞„É¨„Éù„Éº„Éà„ÇíÂÖ¨Èñã",
    "description": "Êó•Êú¨CTOÂçî‰ºö„ÅØ„ÄåÁîüÊàêAIÊ¥ªÁî®„Éí„Ç¢„É™„É≥„Ç∞„É¨„Éù„Éº„Éà„Äç„ÇíÂÖ¨Èñã„Åó„Åü„ÄÇÁîüÊàêAI„Å´Èñ¢„Åô„ÇãÂÖàÈÄ≤ÁöÑ„Å™Âèñ„ÇäÁµÑ„Åø„ÇíÈÄ≤„ÇÅ„Çã‰ºÅÊ•≠8Á§æ„Å´Ë™øÊüª„Åó„ÅüÂÜÖÂÆπ„Åå„Åæ„Å®„ÇÅ„Çâ„Çå„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "Êó•Êú¨CTOÂçî‰ºö„ÅØ„ÄåÁîüÊàêAIÊ¥ªÁî®„Éí„Ç¢„É™„É≥„Ç∞„É¨„Éù„Éº„Éà„Äç„ÇíÂÖ¨Èñã„Åó„Åü„ÄÇÁîüÊàêAI„Å´Èñ¢„Åô„ÇãÂÖàÈÄ≤ÁöÑ„Å™Âèñ„ÇäÁµÑ„Åø„ÇíÈÄ≤„ÇÅ„Çã‰ºÅÊ•≠8Á§æ„Å´Ë™øÊüª„Åó„ÅüÂÜÖÂÆπ„Åå„Åæ„Å®„ÇÅ„Çâ„Çå„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Fri, 04 Jul 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://atmarkit.itmedia.co.jp/ait/articles/2507/04/news034.html",
    "thumbnail": "https://image.itmedia.co.jp/ait/articles/2507/04/cover_news034.jpg"
  },
  {
    "title": "Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models",
    "description": "",
    "summary": "Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models Florence-2, released by Mic...",
    "pubDate": "Mon, 24 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/finetune-florence2",
    "thumbnail": "https://huggingface.co/blog/assets/182_finetune-florence/thumbnail.png"
  },
  {
    "title": "WebSailor: Navigating Super-human Reasoning for Web Agent",
    "description": "arXiv:2507.02592v1 Announce Type: cross Abstract: Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all opensource agents in complex information-seeking tasks, matching proprietary agents' performance and closing the capability gap.",
    "summary": "arXiv:2507.02592v1 Announce Type: cross Abstract: Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all opensource agents in complex information-seeking tasks, matching proprietary agents' performance and closing the capability gap.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02592",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Competitive programming with AlphaCode",
    "description": "Solving novel problems and setting a new milestone in competitive programming.",
    "summary": "Solving novel problems and setting a new milestone in competitive programming.",
    "pubDate": "Thu, 08 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/competitive-programming-with-alphacode/",
    "thumbnail": "https://lh3.googleusercontent.com/vQ0Ow6LwCpigfPyTGUhXEfdMBWPyHmaCo7eoQW7bv3QoZXW6EIj18FPiCLI1vlMYlUAOvEXta1KSkl8P2KScquYJb-Dm_QygP9kdlLYkpF4nVyEH=w1200-h630-n-nu"
  },
  {
    "title": "Evaluating social and ethical risks from generative AI",
    "description": "Introducing a context-based framework for comprehensively evaluating the social and ethical risks of AI systems",
    "summary": "Introducing a context-based framework for comprehensively evaluating the social and ethical risks of AI systems",
    "pubDate": "Thu, 19 Oct 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/evaluating-social-and-ethical-risks-from-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/LAqM0ZkFzkDefB5oVEEPoq6p--7XcfBWEDPjl6OdcfvwN9q3leY2qWCf30_MquTn5RfpcPswiAoRns2jOKjB5_8u-vl6TqueSwamEM6U-qyJHOiujkI=w1200-h630-n-nu"
  },
  {
    "title": "Fine-Tuning Gemma Models in Hugging Face",
    "description": "",
    "summary": "Fine-Tuning Gemma Models in Hugging Face We recently announced that Gemma, the open weights language...",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma-peft",
    "thumbnail": "https://huggingface.co/blog/assets/gemma-peft/thumbnail.png"
  },
  {
    "title": "Introducing Hugging Face for Education",
    "description": "",
    "summary": "Introducing Hugging Face for Education ü§ó Given that machine learning will make up the overwhelming m...",
    "pubDate": "Mon, 25 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/education",
    "thumbnail": "https://huggingface.co/blog/assets/61_education/thumbnail.png"
  },
  {
    "title": "APT: Adaptive Personalized Training for Diffusion Models with Limited Data",
    "description": "arXiv:2507.02687v1 Announce Type: cross Abstract: Personalizing diffusion models using limited data presents significant challenges, including overfitting, loss of prior knowledge, and degradation of text alignment. Overfitting leads to shifts in the noise prediction distribution, disrupting the denoising trajectory and causing the model to lose semantic coherence. In this paper, we propose Adaptive Personalized Training (APT), a novel framework that mitigates overfitting by employing adaptive training strategies and regularizing the model's internal representations during fine-tuning. APT consists of three key components: (1) Adaptive Training Adjustment, which introduces an overfitting indicator to detect the degree of overfitting at each time step bin and applies adaptive data augmentation and adaptive loss weighting based on this indicator; (2)Representation Stabilization, which regularizes the mean and variance of intermediate feature maps to prevent excessive shifts in noise prediction; and (3) Attention Alignment for Prior Knowledge Preservation, which aligns the cross-attention maps of the fine-tuned model with those of the pretrained model to maintain prior knowledge and semantic coherence. Through extensive experiments, we demonstrate that APT effectively mitigates overfitting, preserves prior knowledge, and outperforms existing methods in generating high-quality, diverse images with limited reference data.",
    "summary": "arXiv:2507.02687v1 Announce Type: cross Abstract: Personalizing diffusion models using limited data presents significant challenges, including overfitting, loss of prior knowledge, and degradation of text alignment. Overfitting leads to shifts in the noise prediction distribution, disrupting the denoising trajectory and causing the model to lose semantic coherence. In this paper, we propose Adaptive Personalized Training (APT), a novel framework that mitigates overfitting by employing adaptive training strategies and regularizing the model's internal representations during fine-tuning. APT consists of three key components: (1) Adaptive Training Adjustment, which introduces an overfitting indicator to detect the degree of overfitting at each time step bin and applies adaptive data augmentation and adaptive loss weighting based on this indicator; (2)Representation Stabilization, which regularizes the mean and variance of intermediate feature maps to prevent excessive shifts in noise prediction; and (3) Attention Alignment for Prior Knowledge Preservation, which aligns the cross-attention maps of the fine-tuned model with those of the pretrained model to maintain prior knowledge and semantic coherence. Through extensive experiments, we demonstrate that APT effectively mitigates overfitting, preserves prior knowledge, and outperforms existing methods in generating high-quality, diverse images with limited reference data.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02687",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A framework for Conditional Reasoning in Answer Set Programming",
    "description": "arXiv:2506.03997v2 Announce Type: replace Abstract: In this paper we introduce a Conditional Answer Set Programming framework (Conditional ASP) for the definition of conditional extensions of Answer Set Programming (ASP). The approach builds on a conditional logic with typicality, and on the combination of a conditional knowledge base with an ASP program, and allows for conditional reasoning over the answer sets of the program. The formalism relies on a multi-preferential semantics (and on the KLM preferential semantics, as a special case) to provide an interpretation of conditionals.",
    "summary": "arXiv:2506.03997v2 Announce Type: replace Abstract: In this paper we introduce a Conditional Answer Set Programming framework (Conditional ASP) for the definition of conditional extensions of Answer Set Programming (ASP). The approach builds on a conditional logic with typicality, and on the combination of a conditional knowledge base with an ASP program, and allows for conditional reasoning over the answer sets of the program. The formalism relies on a multi-preferential semantics (and on the KLM preferential semantics, as a special case) to provide an interpretation of conditionals.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.03997",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI and Future partner on specialist content",
    "description": "OpenAI and Future, the global platform for specialist media, have today announced a strategic partnership to bring content from Future‚Äôs 200 plus media brands to OpenAI‚Äôs users.",
    "summary": "OpenAI and Future, the global platform for specialist media, have today announced a strategic partnership to bring content from Future‚Äôs 200 plus media brands to OpenAI‚Äôs users.",
    "pubDate": "Wed, 04 Dec 2024 23:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-future-partner-on-specialist-content",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PixelCNN++: Improving the PixelCNN with discretized logistic mixture likelihood and other modifications",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 19 Jan 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/pixelcnn-plus-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Transforming the future of music creation",
    "description": "Announcing our most advanced music generation model and two new AI experiments, designed to open a new playground for creativity",
    "summary": "Announcing our most advanced music generation model and two new AI experiments, designed to open a new playground for creativity",
    "pubDate": "Thu, 16 Nov 2023 07:20:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/",
    "thumbnail": "https://lh3.googleusercontent.com/msr-Fc99rrkeoQkZ6rLTKnof3RTqo5oo9D2_xPyqtpp0mAMqqkn-x3mPy2dD0My1g7w-cysBQzHU_iWF4mlblU4EgQRcMNKoBUgPdmdmEoyekFJEnA=w1200-h630-n-nu"
  },
  {
    "title": "Habana Labs and Hugging Face Partner to Accelerate Transformer Model Training",
    "description": "",
    "summary": "Habana Labs and Hugging Face Partner to Accelerate Transformer Model Training Santa Clara and San Fr...",
    "pubDate": "Tue, 12 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana",
    "thumbnail": "https://huggingface.co/blog/assets/60_habana/habana.png"
  },
  {
    "title": "Introducing OpenAI o3 and o4-mini",
    "description": "Our smartest and most capable models to date with full tool access",
    "summary": "Our smartest and most capable models to date with full tool access",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-o3-and-o4-mini",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Artificial intelligence enhances air mobility planning",
    "description": "Lincoln Laboratory is transitioning tools to the 618th Air Operations Center to streamline global transport logistics.",
    "summary": "Lincoln Laboratory is transitioning tools to the 618th Air Operations Center to streamline global transport logistics.",
    "pubDate": "Fri, 25 Apr 2025 12:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/artificial-intelligence-enhances-air-mobility-planning-0425",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-lincoln-lab-us-air-mobility-00.jpg"
  },
  {
    "title": "Adversarial training methods for semi-supervised text classification",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 25 May 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adversarial-training-methods-for-semi-supervised-text-classification",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI-enabled control system helps autonomous drones stay on target in uncertain environments",
    "description": "The system automatically learns to adapt to unknown disturbances such as gusting winds.",
    "summary": "The system automatically learns to adapt to unknown disturbances such as gusting winds.",
    "pubDate": "Mon, 09 Jun 2025 16:40:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-enabled-control-system-helps-autonomous-drones-uncertain-environments-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_MetaLearning-01.jpg"
  },
  {
    "title": "Delivering high-performance customer support",
    "description": "Decagon and OpenAI deliver high-performance, fully automated customer support at scale",
    "summary": "Decagon and OpenAI deliver high-performance, fully automated customer support at scale",
    "pubDate": "Tue, 29 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/decagon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Multimodal neurons in artificial neural networks",
    "description": "We‚Äôve discovered neurons in CLIP that respond to the same concept whether presented literally, symbolically, or conceptually. This may explain CLIP‚Äôs accuracy in classifying surprising visual renditions of concepts, and is also an important step toward understanding the associations and biases that CLIP and similar models learn.",
    "summary": "We‚Äôve discovered neurons in CLIP that respond to the same concept whether presented literally, symbolically, or conceptually. This may explain CLIP‚Äôs accuracy in classifying surprising visual renditions of concepts, and is also an important step toward understanding the associations and biases that CLIP and similar models learn.",
    "pubDate": "Thu, 04 Mar 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/multimodal-neurons",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Complete Guide to Audio Datasets",
    "description": "",
    "summary": "A Complete Guide to Audio Datasets Introduction ü§ó Datasets is an open-source library for downloading...",
    "pubDate": "Thu, 15 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/audio-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/116_audio_datasets/thumbnail.jpg"
  },
  {
    "title": "More on Dota 2",
    "description": "Our Dota 2 result shows that self-play can catapult the performance of machine learning systems from far below human level to superhuman, given sufficient compute. In the span of a month, our system went from barely matching a high-ranked player to beating the top pros and has continued to improve since then. Supervised deep learning systems can only be as good as their training datasets, but in self-play systems, the available data improves automatically as the agent gets better.",
    "summary": "Our Dota 2 result shows that self-play can catapult the performance of machine learning systems from far below human level to superhuman, given sufficient compute. In the span of a month, our system went from barely matching a high-ranked player to beating the top pros and has continued to improve since then. Supervised deep learning systems can only be as good as their training datasets, but in self-play systems, the available data improves automatically as the agent gets better.",
    "pubDate": "Wed, 16 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/more-on-dota-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing AutoRound: Intel‚Äôs Advanced Quantization for LLMs and VLMs",
    "description": "",
    "summary": "What is AutoRound? As large language models (LLMs) and vision-language models (VLMs) continue to gro...",
    "pubDate": "Tue, 29 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autoround",
    "thumbnail": "https://huggingface.co/blog/assets/autoround/thumbnail.png"
  },
  {
    "title": "ArmÊê≠ËºâAIÂçäÂ∞é‰Ωì„ÅÆËøÖÈÄü„Å™ÈñãÁô∫„ÇíÊîØÊè¥„ÄÅOKI„Ç¢„Ç§„Éá„Ç£„Ç®„Çπ",
    "description": "OKI„Ç¢„Ç§„Éá„Ç£„Ç®„ÇπÔºàOIDSÔºâ„ÅØ„ÄÅArm„Å®„ÄåArm Approved Design Partner„ÄçÂ•ëÁ¥Ñ„ÇíÁµê„Çì„Å†„ÄÇArm„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÊê≠Ëºâ„Åó„ÅüASICÔºèLSI„ÅÆÈñãÁô∫„ÇíË®àÁîª„Åó„Å¶„ÅÑ„ÇãÈ°ßÂÆ¢„Å´ÂØæ„Åó„ÄÅOIDS„ÅØFPGA„ÇíÊ¥ªÁî®„Åó„Åü„Éó„É≠„Éà„Çø„Ç§„Éó„ÅÆÈñãÁô∫„ÉªÊ§úË®º„Çµ„Éº„Éì„Çπ„ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Åè„ÄÇ",
    "summary": "OKI„Ç¢„Ç§„Éá„Ç£„Ç®„ÇπÔºàOIDSÔºâ„ÅØ„ÄÅArm„Å®„ÄåArm Approved Design Partner„ÄçÂ•ëÁ¥Ñ„ÇíÁµê„Çì„Å†„ÄÇArm„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÊê≠Ëºâ„Åó„ÅüASICÔºèLSI„ÅÆÈñãÁô∫„ÇíË®àÁîª„Åó„Å¶„ÅÑ„ÇãÈ°ßÂÆ¢„Å´ÂØæ„Åó„ÄÅOIDS„ÅØFPGA„ÇíÊ¥ªÁî®„Åó„Åü„Éó„É≠„Éà„Çø„Ç§„Éó„ÅÆÈñãÁô∫„ÉªÊ§úË®º„Çµ„Éº„Éì„Çπ„ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Åè„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 15:30:00 +0900",
    "source": "ITmedia AI",
    "url": "https://eetimes.itmedia.co.jp/ee/articles/2507/03/news032.html",
    "thumbnail": "https://image.itmedia.co.jp/ee/articles/2507/03/cover_news032.jpg"
  },
  {
    "title": "Google DeepMind at NeurIPS 2024",
    "description": "Advancing adaptive AI agents, empowering 3D scene creation, and innovating LLM training for a smarter, safer future",
    "summary": "Advancing adaptive AI agents, empowering 3D scene creation, and innovating LLM training for a smarter, safer future",
    "pubDate": "Thu, 05 Dec 2024 17:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-neurips-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/cKpWE16vpsZ21VcH-_SdGF8tQEeEMp2phWFajdBq_A7aMVS2axiXQzd7V8mlHdJm-CXVKh1IaY3yeM_lAwu_zxc6SIBdWahdN6nYoaQqUbC8uU0qoY8=w1200-h630-n-nu"
  },
  {
    "title": "Non-engineers guide: Train a LLaMA 2 chatbot",
    "description": "",
    "summary": "Non-engineers guide: Train a LLaMA 2 chatbot Introduction In this tutorial we will show you how anyo...",
    "pubDate": "Thu, 28 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/Llama2-for-non-engineers",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/tuto.png"
  },
  {
    "title": "Introducing SafeCoder",
    "description": "",
    "summary": "Introducing SafeCoder Today we are excited to announce SafeCoder - a code assistant solution built f...",
    "pubDate": "Tue, 22 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safecoder",
    "thumbnail": "https://huggingface.co/blog/assets/159_safecoder/thumbnail.jpg"
  },
  {
    "title": "Introducing TextImage Augmentation for Document Images",
    "description": "",
    "summary": "Introducing Multimodal TextImage Augmentation for Document Images In this blog post, we provide a tu...",
    "pubDate": "Tue, 06 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/doc_aug_hf_alb",
    "thumbnail": "https://huggingface.co/blog/assets/185_albumentations/thumbnail.png"
  },
  {
    "title": "AI Flow: Perspectives, Scenarios, and Approaches",
    "description": "arXiv:2506.12479v2 Announce Type: replace Abstract: Pioneered by the foundational information theory by Claude Shannon and the visionary framework of machine intelligence by Alan Turing, the convergent evolution of information and communication technologies (IT/CT) has created an unbroken wave of connectivity and computation. This synergy has sparked a technological revolution, now reaching its peak with large artificial intelligence (AI) models that are reshaping industries and redefining human-machine collaboration. However, the realization of ubiquitous intelligence faces considerable challenges due to substantial resource consumption in large models and high communication bandwidth demands. To address these challenges, AI Flow has been introduced as a multidisciplinary framework that integrates cutting-edge IT and CT advancements, with a particular emphasis on the following three key points. First, device-edge-cloud framework serves as the foundation, which integrates end devices, edge servers, and cloud clusters to optimize scalability and efficiency for low-latency model inference. Second, we introduce the concept of familial models, which refers to a series of different-sized models with aligned hidden features, enabling effective collaboration and the flexibility to adapt to varying resource constraints and dynamic scenarios. Third, connectivity- and interaction-based intelligence emergence is a novel paradigm of AI Flow. By leveraging communication networks to enhance connectivity, the collaboration among AI models across heterogeneous nodes achieves emergent intelligence that surpasses the capability of any single model. The innovations of AI Flow provide enhanced intelligence, timely responsiveness, and ubiquitous accessibility to AI services, paving the way for the tighter fusion of AI techniques and communication systems.",
    "summary": "arXiv:2506.12479v2 Announce Type: replace Abstract: Pioneered by the foundational information theory by Claude Shannon and the visionary framework of machine intelligence by Alan Turing, the convergent evolution of information and communication technologies (IT/CT) has created an unbroken wave of connectivity and computation. This synergy has sparked a technological revolution, now reaching its peak with large artificial intelligence (AI) models that are reshaping industries and redefining human-machine collaboration. However, the realization of ubiquitous intelligence faces considerable challenges due to substantial resource consumption in large models and high communication bandwidth demands. To address these challenges, AI Flow has been introduced as a multidisciplinary framework that integrates cutting-edge IT and CT advancements, with a particular emphasis on the following three key points. First, device-edge-cloud framework serves as the foundation, which integrates end devices, edge servers, and cloud clusters to optimize scalability and efficiency for low-latency model inference. Second, we introduce the concept of familial models, which refers to a series of different-sized models with aligned hidden features, enabling effective collaboration and the flexibility to adapt to varying resource constraints and dynamic scenarios. Third, connectivity- and interaction-based intelligence emergence is a novel paradigm of AI Flow. By leveraging communication networks to enhance connectivity, the collaboration among AI models across heterogeneous nodes achieves emergent intelligence that surpasses the capability of any single model. The innovations of AI Flow provide enhanced intelligence, timely responsiveness, and ubiquitous accessibility to AI services, paving the way for the tighter fusion of AI techniques and communication systems.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12479",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemini 2.5: Our most intelligent models are getting even better",
    "description": "Gemini 2.5 Pro continues to be loved by developers as the best model for coding, and 2.5 Flash is getting even better with a new update. We‚Äôre bringing new capabilities to our models, including Deep Think, an experimental enhanced reasoning mode for 2.5 Pro.",
    "summary": "Gemini 2.5 Pro continues to be loved by developers as the best model for coding, and 2.5 Flash is getting even better with a new update. We‚Äôre bringing new capabilities to our models, including Deep Think, an experimental enhanced reasoning mode for 2.5 Pro.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-our-world-leading-model-is-getting-even-better/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/deep-think__key-art_16-9.width-1300.jpg"
  },
  {
    "title": "Text-Generation Pipeline on Intel¬Æ Gaudi¬Æ 2 AI Accelerator",
    "description": "",
    "summary": "Text-Generation Pipeline on Intel¬Æ Gaudi¬Æ 2 AI Accelerator With the Generative AI (GenAI) revolution...",
    "pubDate": "Thu, 29 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/textgen-pipe-gaudi",
    "thumbnail": "https://huggingface.co/blog/assets/textgen-pipe-gaudi/thumbnail.png"
  },
  {
    "title": "Rethinking LLM Evaluation with 3C3H: AraGen Benchmark and Leaderboard",
    "description": "",
    "summary": "Rethinking LLM Evaluation with 3C3H: AraGen Benchmark and Leaderboard In the rapidly evolving landsc...",
    "pubDate": "Wed, 04 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-3c3h-aragen",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_3c3h_aragen.png"
  },
  {
    "title": "BigCodeBench: Benchmarking Large Language Models on Solving Practical and Challenging Programming Tasks",
    "description": "",
    "summary": "BigCodeBench: The Next Generation of HumanEval HumanEval is a reference benchmark for evaluating lar...",
    "pubDate": "Tue, 18 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-bigcodebench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_bigcode.png"
  },
  {
    "title": "Very Large Language Models and How to Evaluate Them",
    "description": "",
    "summary": "Very Large Language Models and How to Evaluate Them Large language models can now be evaluated on ze...",
    "pubDate": "Mon, 03 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-shot-eval-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/106_zero_shot_eval_on_the_hub/thumbnail.png"
  },
  {
    "title": "OpenAI‚Äôs EU Economic Blueprint",
    "description": "Today, OpenAI is sharing the EU Economic Blueprint‚Äîa set of proposals to help Europe seize the promise of artificial intelligence, drive sustainable economic growth across the region, and ensure that AI is developed and deployed by Europe, in Europe, for Europe.",
    "summary": "Today, OpenAI is sharing the EU Economic Blueprint‚Äîa set of proposals to help Europe seize the promise of artificial intelligence, drive sustainable economic growth across the region, and ensure that AI is developed and deployed by Europe, in Europe, for Europe.",
    "pubDate": "Mon, 07 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-eu-economic-blueprint",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Google DeepMind at NeurIPS 2023",
    "description": "The Neural Information Processing Systems (NeurIPS) is the largest artificial intelligence (AI) conference in the world. NeurIPS 2023 will be taking place December 10-16 in New Orleans, USA.Teams from across Google DeepMind are presenting more than 150 papers at the main conference and workshops.",
    "summary": "The Neural Information Processing Systems (NeurIPS) is the largest artificial intelligence (AI) conference in the world. NeurIPS 2023 will be taking place December 10-16 in New Orleans, USA.Teams from across Google DeepMind are presenting more than 150 papers at the main conference and workshops.",
    "pubDate": "Fri, 08 Dec 2023 15:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-neurips-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/MDme_Q62zVqvTUs5uwaI3Ggy2rWIujPt2elkusnUuCA4wEo79V9mabIg66j9cr9zMso-LObOVcj6_ZnrgSMUKn6fl52kxOUEjcigXtDZ2UMuosX3-2s=w1200-h630-n-nu"
  },
  {
    "title": "Build awesome datasets for video generation",
    "description": "",
    "summary": "Build awesome datasets for video generation Tooling for image generation datasets is well establishe...",
    "pubDate": "Wed, 12 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vid_ds_scripts",
    "thumbnail": "https://huggingface.co/blog/assets/vid_ds_scripts/thumbnail.png"
  },
  {
    "title": "How good are LLMs at fixing their mistakes? A chatbot arena experiment with Keras and TPUs",
    "description": "",
    "summary": "How good are LLMs at fixing their mistakes? A chatbot arena experiment with Keras and TPUs while you...",
    "pubDate": "Thu, 05 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-chatbot-arena",
    "thumbnail": "https://huggingface.co/blog/assets/keras-chatbot-arena/thumbnail.png"
  },
  {
    "title": "Shaping the future of advanced robotics",
    "description": "Introducing AutoRT, SARA-RT, and RT-Trajectory",
    "summary": "Introducing AutoRT, SARA-RT, and RT-Trajectory",
    "pubDate": "Thu, 04 Jan 2024 11:39:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotics/",
    "thumbnail": "https://lh3.googleusercontent.com/qeWlfSbr0jW0OsZ0dvaQK2V7tYM0HtTtwivx-fUJzK4GivdM6kffvNXlSgqOJyjAQWXBCycqF77zT7XDGxIqGvPiCnTqLX_C3VRmXGJIGGW5GAv7YQ=w1200-h630-n-nu"
  },
  {
    "title": "Supporting sellers with enhanced product listings",
    "description": "Mercari leverages GPT-4o mini and GPT-4 to streamline selling, enhance product listings, and boost sales, transforming the online marketplace with features like AI Listing Support and Mercari AI Assistant.",
    "summary": "Mercari leverages GPT-4o mini and GPT-4 to streamline selling, enhance product listings, and boost sales, transforming the online marketplace with features like AI Listing Support and Mercari AI Assistant.",
    "pubDate": "Thu, 27 Feb 2025 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mercari",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Open-Source Text Generation & LLM Ecosystem at Hugging Face",
    "description": "",
    "summary": "Open-Source Text Generation & LLM Ecosystem at Hugging Face [Updated on July 24, 2023: Added Llama 2...",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/os-llms",
    "thumbnail": "https://huggingface.co/blog/assets/os_llms/thumbnail.png"
  },
  {
    "title": "How OpenAI is approaching 2024 worldwide elections",
    "description": "We‚Äôre working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate voting information.",
    "summary": "We‚Äôre working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate voting information.",
    "pubDate": "Mon, 15 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-openai-is-approaching-2024-worldwide-elections",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving India‚Äôs critical care infrastructure",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 06 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/10bedicu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Safetensors audited as really safe and becoming the default",
    "description": "",
    "summary": "Audit shows that safetensors is safe and ready to become the default Hugging Face, in close collabor...",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safetensors-security-audit",
    "thumbnail": "https://huggingface.co/blog/assets/142_safetensors_official/thumbnail.png"
  },
  {
    "title": "Fit More and Train Faster With ZeRO via DeepSpeed and FairScale",
    "description": "",
    "summary": "Fit More and Train Faster With ZeRO via DeepSpeed and FairScale A guest blog post by Hugging Face fe...",
    "pubDate": "Tue, 19 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-deepspeed-fairscale",
    "thumbnail": "https://huggingface.co/blog/assets/11_zero_deepspeed_fairscale/zero-partitioning.png"
  },
  {
    "title": "De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks",
    "description": "arXiv:2507.02606v1 Announce Type: cross Abstract: The rapid advancement of speech generation models has heightened privacy and security concerns related to voice cloning (VC). Recent studies have investigated disrupting unauthorized voice cloning by introducing adversarial perturbations. However, determined attackers can mitigate these protective perturbations and successfully execute VC. In this study, we conduct the first systematic evaluation of these protective perturbations against VC under realistic threat models that include perturbation purification. Our findings reveal that while existing purification methods can neutralize a considerable portion of the protective perturbations, they still lead to distortions in the feature space of VC models, which degrades the performance of VC. From this perspective, we propose a novel two-stage purification method: (1) Purify the perturbed speech; (2) Refine it using phoneme guidance to align it with the clean speech distribution. Experimental results demonstrate that our method outperforms state-of-the-art purification methods in disrupting VC defenses. Our study reveals the limitations of adversarial perturbation-based VC defenses and underscores the urgent need for more robust solutions to mitigate the security and privacy risks posed by VC. The code and audio samples are available at https://de-antifake.github.io.",
    "summary": "arXiv:2507.02606v1 Announce Type: cross Abstract: The rapid advancement of speech generation models has heightened privacy and security concerns related to voice cloning (VC). Recent studies have investigated disrupting unauthorized voice cloning by introducing adversarial perturbations. However, determined attackers can mitigate these protective perturbations and successfully execute VC. In this study, we conduct the first systematic evaluation of these protective perturbations against VC under realistic threat models that include perturbation purification. Our findings reveal that while existing purification methods can neutralize a considerable portion of the protective perturbations, they still lead to distortions in the feature space of VC models, which degrades the performance of VC. From this perspective, we propose a novel two-stage purification method: (1) Purify the perturbed speech; (2) Refine it using phoneme guidance to align it with the clean speech distribution. Experimental results demonstrate that our method outperforms state-of-the-art purification methods in disrupting VC defenses. Our study reveals the limitations of adversarial perturbation-based VC defenses and underscores the urgent need for more robust solutions to mitigate the security and privacy risks posed by VC. The code and audio samples are available at https://de-antifake.github.io.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02606",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GamePad: A learning environment for theorem proving",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 02 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gamepad",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemma Scope: helping the safety community shed light on the inner workings of language models",
    "description": "Announcing a comprehensive, open suite of sparse autoencoders for language model interpretability.",
    "summary": "Announcing a comprehensive, open suite of sparse autoencoders for language model interpretability.",
    "pubDate": "Wed, 31 Jul 2024 15:59:19 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemma-scope-helping-the-safety-community-shed-light-on-the-inner-workings-of-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/4amJbS1Q5bh_CoBHPAc4NEn0Q13izqrskMETkJl3h2Jdku08GryCCjW6BM59OKj1-Q7-8ZFCWlgu7tIMzjRBIXImy8wlgTOxYgJ88fQvYJTye07C=w1200-h630-n-nu"
  },
  {
    "title": "ChatGPT plugins",
    "description": "We‚Äôve implemented initial support for plugins in ChatGPT. Plugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run computations, or use third-party services.",
    "summary": "We‚Äôve implemented initial support for plugins in ChatGPT. Plugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run computations, or use third-party services.",
    "pubDate": "Thu, 23 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-plugins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding-informed Bias Mitigation for Fair CMR Segmentation",
    "description": "arXiv:2503.17089v2 Announce Type: replace-cross Abstract: Artificial intelligence (AI) is increasingly being used for medical imaging tasks. However, there can be biases in AI models, particularly when they are trained using imbalanced training datasets. One such example has been the strong ethnicity bias effect in cardiac magnetic resonance (CMR) image segmentation models. Although this phenomenon has been reported in a number of publications, little is known about the effectiveness of bias mitigation algorithms in this domain. We aim to investigate the impact of common bias mitigation methods to address bias between Black and White subjects in AI-based CMR segmentation models. Specifically, we use oversampling, importance reweighing and Group DRO as well as combinations of these techniques to mitigate the ethnicity bias. Second, motivated by recent findings on the root causes of AI-based CMR segmentation bias, we evaluate the same methods using models trained and evaluated on cropped CMR images. We find that bias can be mitigated using oversampling, significantly improving performance for the underrepresented Black subjects whilst not significantly reducing the majority White subjects' performance. Using cropped images increases performance for both ethnicities and reduces the bias, whilst adding oversampling as a bias mitigation technique with cropped images reduces the bias further. When testing the models on an external clinical validation set, we find high segmentation performance and no statistically significant bias.",
    "summary": "arXiv:2503.17089v2 Announce Type: replace-cross Abstract: Artificial intelligence (AI) is increasingly being used for medical imaging tasks. However, there can be biases in AI models, particularly when they are trained using imbalanced training datasets. One such example has been the strong ethnicity bias effect in cardiac magnetic resonance (CMR) image segmentation models. Although this phenomenon has been reported in a number of publications, little is known about the effectiveness of bias mitigation algorithms in this domain. We aim to investigate the impact of common bias mitigation methods to address bias between Black and White subjects in AI-based CMR segmentation models. Specifically, we use oversampling, importance reweighing and Group DRO as well as combinations of these techniques to mitigate the ethnicity bias. Second, motivated by recent findings on the root causes of AI-based CMR segmentation bias, we evaluate the same methods using models trained and evaluated on cropped CMR images. We find that bias can be mitigated using oversampling, significantly improving performance for the underrepresented Black subjects whilst not significantly reducing the majority White subjects' performance. Using cropped images increases performance for both ethnicities and reduces the bias, whilst adding oversampling as a bias mitigation technique with cropped images reduces the bias further. When testing the models on an external clinical validation set, we find high segmentation performance and no statistically significant bias.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.17089",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How we‚Äôre responding to The New York Times‚Äô data demands in order to protect user privacy",
    "description": "OpenAI is fighting a court order at the demands of The New York Times and plaintiffs, which involves retention of consumer ChatGPT and API user data indefinitely. Learn how we‚Äôre working to uphold user privacy, address legal requirements, and stay true to our data protection commitments.",
    "summary": "OpenAI is fighting a court order at the demands of The New York Times and plaintiffs, which involves retention of consumer ChatGPT and API user data indefinitely. Learn how we‚Äôre working to uphold user privacy, address legal requirements, and stay true to our data protection commitments.",
    "pubDate": "Thu, 05 Jun 2025 16:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/response-to-nyt-data-demands",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Remote VAEs for decoding with HF endpoints ü§ó",
    "description": "",
    "summary": "Remote VAEs for decoding with Inference Endpoints ü§ó When operating with latent-space diffusion model...",
    "pubDate": "Mon, 24 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/remote_vae",
    "thumbnail": "https://huggingface.co/blog/assets/remote_vae/thumbnail.png"
  },
  {
    "title": "Retro Contest",
    "description": "We‚Äôre launching a transfer learning contest that measures a reinforcement learning algorithm‚Äôs ability to generalize from previous experience.",
    "summary": "We‚Äôre launching a transfer learning contest that measures a reinforcement learning algorithm‚Äôs ability to generalize from previous experience.",
    "pubDate": "Thu, 05 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retro-contest",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CO‚ÇÇ Emissions and Models Performance: Insights from the Open LLM Leaderboard",
    "description": "",
    "summary": "CO‚ÇÇ Emissions and Models Performance: Insights from the Open LLM Leaderboard Since June 2024, we hav...",
    "pubDate": "Thu, 09 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-emissions-analysis",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "The Transformers Library: standardizing model definitions",
    "description": "",
    "summary": "The Transformers Library: standardizing model definitions TLDR: Going forward, we're aiming for Tran...",
    "pubDate": "Thu, 15 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-model-definition",
    "thumbnail": "https://huggingface.co/blog/assets/transformers-model-definition/transformers-thumbnail.png"
  },
  {
    "title": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent",
    "description": "arXiv:2507.02259v1 Announce Type: cross Abstract: Despite improvements by length extrapolation, efficient attention and memory modules, handling infinitely long documents with linear complexity without performance degradation during extrapolation remains the ultimate challenge in long-text processing. We directly optimize for long-text tasks in an end-to-end fashion and introduce a novel agent workflow, MemAgent, which reads text in segments and updates the memory using an overwrite strategy. We extend the DAPO algorithm to facilitate training via independent-context multi-conversation generation. MemAgent has demonstrated superb long-context capabilities, being able to extrapolate from an 8K context trained on 32K text to a 3.5M QA task with performance loss < 5% and achieves 95%+ in 512K RULER test.",
    "summary": "arXiv:2507.02259v1 Announce Type: cross Abstract: Despite improvements by length extrapolation, efficient attention and memory modules, handling infinitely long documents with linear complexity without performance degradation during extrapolation remains the ultimate challenge in long-text processing. We directly optimize for long-text tasks in an end-to-end fashion and introduce a novel agent workflow, MemAgent, which reads text in segments and updates the memory using an overwrite strategy. We extend the DAPO algorithm to facilitate training via independent-context multi-conversation generation. MemAgent has demonstrated superb long-context capabilities, being able to extrapolate from an 8K context trained on 32K text to a 3.5M QA task with performance loss < 5% and achieves 95%+ in 512K RULER test.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02259",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google DeepMind‚Äôs latest research at ICML 2023",
    "description": "Exploring AI safety, adaptability, and efficiency for the real world",
    "summary": "Exploring AI safety, adaptability, and efficiency for the real world",
    "pubDate": "Thu, 20 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-research-at-icml-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/5UyUwX8KGovLbTZ0Q8Ynf5Nepy-1zyFaVIIwB7ty0Cp1F5wrKrv24aOT91PDo1vpH3T4P0cwtUn1WxxvtU5vqd4J7cBwEK6UsvnTMNL_qramtFbsX28=w1200-h630-n-nu"
  },
  {
    "title": "RT-2: New model translates vision and language into action",
    "description": "Robotic Transformer 2 (RT-2) is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for robotic control.",
    "summary": "Robotic Transformer 2 (RT-2) is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for robotic control.",
    "pubDate": "Fri, 28 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/",
    "thumbnail": "https://lh3.googleusercontent.com/ZduBtQRn2mrvSfNqkixe2XktBREieIhekS7NcboCn0E76gFVckUwNLZw74EJ5jIndzxbRoCqCY47iW1-eGi5c_JJV1DFyTmkS91vMnRalgT0rih125s=w1200-h630-n-nu"
  },
  {
    "title": "Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification",
    "description": "arXiv:2506.01631v2 Announce Type: replace-cross Abstract: As Large Language Models (LLMs) become integral software components in modern applications, unauthorized model derivations through fine-tuning, merging, and redistribution have emerged as critical software engineering challenges. Unlike traditional software where clone detection and license compliance are well-established, the LLM ecosystem lacks effective mechanisms to detect model lineage and enforce licensing agreements. This gap is particularly problematic when open-source model creators, such as Meta's LLaMA, require derivative works to maintain naming conventions for attribution, yet no technical means exist to verify compliance. To fill this gap, treating LLMs as software artifacts requiring provenance tracking, we present TensorGuard, a gradient-based fingerprinting framework for LLM similarity detection and family classification. Our approach extracts model-intrinsic behavioral signatures by analyzing gradient responses to random input perturbations across tensor layers, operating independently of training data, watermarks, or specific model formats. TensorGuard supports the widely-adopted safetensors format and constructs high-dimensional fingerprints through statistical analysis of gradient features. These fingerprints enable two complementary capabilities: direct pairwise similarity assessment between arbitrary models through distance computation, and systematic family classification of unknown models via the K-Means clustering algorithm with domain-informed centroid initialization using known base models. Experimental evaluation on 58 models comprising 8 base models and 50 derivatives across five model families (Llama, Qwen, Gemma, Phi, Mistral) demonstrates 94% classification accuracy under our centroid-initialized K-Means clustering.",
    "summary": "arXiv:2506.01631v2 Announce Type: replace-cross Abstract: As Large Language Models (LLMs) become integral software components in modern applications, unauthorized model derivations through fine-tuning, merging, and redistribution have emerged as critical software engineering challenges. Unlike traditional software where clone detection and license compliance are well-established, the LLM ecosystem lacks effective mechanisms to detect model lineage and enforce licensing agreements. This gap is particularly problematic when open-source model creators, such as Meta's LLaMA, require derivative works to maintain naming conventions for attribution, yet no technical means exist to verify compliance. To fill this gap, treating LLMs as software artifacts requiring provenance tracking, we present TensorGuard, a gradient-based fingerprinting framework for LLM similarity detection and family classification. Our approach extracts model-intrinsic behavioral signatures by analyzing gradient responses to random input perturbations across tensor layers, operating independently of training data, watermarks, or specific model formats. TensorGuard supports the widely-adopted safetensors format and constructs high-dimensional fingerprints through statistical analysis of gradient features. These fingerprints enable two complementary capabilities: direct pairwise similarity assessment between arbitrary models through distance computation, and systematic family classification of unknown models via the K-Means clustering algorithm with domain-informed centroid initialization using known base models. Experimental evaluation on 58 models comprising 8 base models and 50 derivatives across five model families (Llama, Qwen, Gemma, Phi, Mistral) demonstrates 94% classification accuracy under our centroid-initialized K-Means clustering.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.01631",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï„ÄÄ7/9ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„ÄÅÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨",
    "description": "<p>AIsmiley„ÅØ„ÄÅ2025Âπ¥7Êúà9Êó•ÔºàÊ∞¥ÔºâÔΩû7Êúà11Êó•ÔºàÈáëÔºâ„Å´ÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨„ÅÆ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„Çπ„ÇíÂá∫Â±ï„Åó„Åæ„Åô„ÄÇ ‰ºöÂ†¥„Åß„ÅØ„ÄÅÊúÄÊñ∞„ÅÆAI„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥„ÇÑ„Éã„É•„Éº„ÇπÁ≠â„ÇíÂèñ„Çä‰∏ä„Åí„ÇãAI„Éù„Éº„Çø [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/'>„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï„ÄÄ7/9ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„ÄÅÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AIsmiley„ÅØ„ÄÅ2025Âπ¥7Êúà9Êó•ÔºàÊ∞¥ÔºâÔΩû7Êúà11Êó•ÔºàÈáëÔºâ„Å´ÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨„ÅÆ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„Çπ„ÇíÂá∫Â±ï„Åó„Åæ„Åô„ÄÇ ‰ºöÂ†¥„Åß„ÅØ„ÄÅÊúÄÊñ∞„ÅÆAI„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥„ÇÑ„Éã„É•„Éº„ÇπÁ≠â„ÇíÂèñ„Çä‰∏ä„Åí„ÇãAI„Éù„Éº„Çø [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/'>„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï„ÄÄ7/9ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„ÄÅÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 04:00:20 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/05/monodukuri-world-tokyo-no37.png"
  },
  {
    "title": "Stable Diffusion with üß® Diffusers",
    "description": "",
    "summary": "Stable Diffusion with üß® Diffusers Stable Diffusion üé® ...using üß® Diffusers Stable Diffusion is a text...",
    "pubDate": "Mon, 22 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable_diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/98_stable_diffusion/thumbnail.png"
  },
  {
    "title": "MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs",
    "description": "arXiv:2507.02851v1 Announce Type: cross Abstract: Recent advancements in the reasoning capabilities of large language models (LLMs) show that employing group relative policy optimization (GRPO) algorithm for reinforcement learning (RL) training allows the models to use more thinking/reasoning tokens for generating better responses. However, LLMs can generate only a finite amount of tokens while maintaining attention to the previously generated tokens. This limit, also known as the context size of an LLM, is a bottleneck in LLM reasoning with arbitrarily large number of tokens. To think beyond the limit of context size, an LLM must employ a modular thinking strategy to reason over multiple rounds. In this work, we propose $textbf{MOTIF: Modular Thinking via Reinforcement Finetuning}$ -- an RL training method for generating thinking tokens in multiple rounds, effectively allowing the model to think with additional context size. We trained the open-source model Qwen2.5-3B-Instruct on GSM8K dataset via parameter efficient fine-tuning and tested its accuracy on MATH500 and AIME2024 benchmarks. Our experiments show 3.8% and 3.3% improvements over vanilla GRPO based training in the respective benchmarks. Furthermore, this improvement was achieved with only 15% of samples, thus demonstrating sample efficiency of MOTIF. Our code and models are available at https://github.com/purbeshmitra/MOTIF and https://huggingface.co/purbeshmitra/MOTIF, respectively.",
    "summary": "arXiv:2507.02851v1 Announce Type: cross Abstract: Recent advancements in the reasoning capabilities of large language models (LLMs) show that employing group relative policy optimization (GRPO) algorithm for reinforcement learning (RL) training allows the models to use more thinking/reasoning tokens for generating better responses. However, LLMs can generate only a finite amount of tokens while maintaining attention to the previously generated tokens. This limit, also known as the context size of an LLM, is a bottleneck in LLM reasoning with arbitrarily large number of tokens. To think beyond the limit of context size, an LLM must employ a modular thinking strategy to reason over multiple rounds. In this work, we propose $textbf{MOTIF: Modular Thinking via Reinforcement Finetuning}$ -- an RL training method for generating thinking tokens in multiple rounds, effectively allowing the model to think with additional context size. We trained the open-source model Qwen2.5-3B-Instruct on GSM8K dataset via parameter efficient fine-tuning and tested its accuracy on MATH500 and AIME2024 benchmarks. Our experiments show 3.8% and 3.3% improvements over vanilla GRPO based training in the respective benchmarks. Furthermore, this improvement was achieved with only 15% of samples, thus demonstrating sample efficiency of MOTIF. Our code and models are available at https://github.com/purbeshmitra/MOTIF and https://huggingface.co/purbeshmitra/MOTIF, respectively.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02851",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sora System Card",
    "description": "Sora is OpenAI‚Äôs video generation model, designed to take text, image, and video inputs and generate a new video as an output. Sora builds on learnings from DALL-E and GPT models, and is designed to give people expanded tools for storytelling and creative expression.",
    "summary": "Sora is OpenAI‚Äôs video generation model, designed to take text, image, and video inputs and generate a new video as an output. Sora builds on learnings from DALL-E and GPT models, and is designed to give people expanded tools for storytelling and creative expression.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Aligning language models to follow instructions",
    "description": "We‚Äôve trained language models that are much better at following user intentions than GPT-3 while also making them more truthful and less toxic, using techniques developed through our alignment research. These¬†InstructGPT¬†models, which are trained with humans in the loop, are now deployed as the default language models on our¬†API.",
    "summary": "We‚Äôve trained language models that are much better at following user intentions than GPT-3 while also making them more truthful and less toxic, using techniques developed through our alignment research. These¬†InstructGPT¬†models, which are trained with humans in the loop, are now deployed as the default language models on our¬†API.",
    "pubDate": "Thu, 27 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/instruction-following",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI safety via debate",
    "description": "We‚Äôre proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.",
    "summary": "We‚Äôre proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.",
    "pubDate": "Thu, 03 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/debate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pollen-Vision: Unified interface for Zero-Shot vision models in robotics",
    "description": "",
    "summary": "Pollen-Vision: Unified interface for Zero-Shot vision models in robotics This is a guest blog post b...",
    "pubDate": "Mon, 25 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pollen-vision",
    "thumbnail": "https://huggingface.co/blog/assets/pollen-vision/thumbnail.jpg"
  },
  {
    "title": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs",
    "description": "arXiv:2505.15075v2 Announce Type: replace-cross Abstract: The rapid evolution of multimodal large language models (MLLMs) has significantly enhanced their real-world applications. However, achieving consistent performance across languages, especially when integrating cultural knowledge, remains a significant challenge. To better assess this issue, we introduce two new benchmarks: KnowRecall and VisRecall, which evaluate cross-lingual consistency in MLLMs. KnowRecall is a visual question answering benchmark designed to measure factual knowledge consistency in 15 languages, focusing on cultural and historical questions about global landmarks. VisRecall assesses visual memory consistency by asking models to describe landmark appearances in 9 languages without access to images. Experimental results reveal that state-of-the-art MLLMs, including proprietary ones, still struggle to achieve cross-lingual consistency. This underscores the need for more robust approaches that produce truly multilingual and culturally aware models.",
    "summary": "arXiv:2505.15075v2 Announce Type: replace-cross Abstract: The rapid evolution of multimodal large language models (MLLMs) has significantly enhanced their real-world applications. However, achieving consistent performance across languages, especially when integrating cultural knowledge, remains a significant challenge. To better assess this issue, we introduce two new benchmarks: KnowRecall and VisRecall, which evaluate cross-lingual consistency in MLLMs. KnowRecall is a visual question answering benchmark designed to measure factual knowledge consistency in 15 languages, focusing on cultural and historical questions about global landmarks. VisRecall assesses visual memory consistency by asking models to describe landmark appearances in 9 languages without access to images. Experimental results reveal that state-of-the-art MLLMs, including proprietary ones, still struggle to achieve cross-lingual consistency. This underscores the need for more robust approaches that produce truly multilingual and culturally aware models.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.15075",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics",
    "description": "arXiv:2507.02748v1 Announce Type: cross Abstract: Transformers have become the de facto standard for a wide range of tasks, from image classification to physics simulations. Despite their impressive performance, the quadratic complexity of standard Transformers in both memory and time with respect to the input length makes them impractical for processing high-resolution inputs. Therefore, several variants have been proposed, the most successful relying on patchification, downsampling, or coarsening techniques, often at the cost of losing the finest-scale details. In this work, we take a different approach. Inspired by state-of-the-art techniques in $n$-body numerical simulations, we cast attention as an interaction problem between grid points. We introduce the Multipole Attention Neural Operator (MANO), which computes attention in a distance-based multiscale fashion. MANO maintains, in each attention head, a global receptive field and achieves linear time and memory complexity with respect to the number of grid points. Empirical results on image classification and Darcy flows demonstrate that MANO rivals state-of-the-art models such as ViT and Swin Transformer, while reducing runtime and peak memory usage by orders of magnitude. We open source our code for reproducibility at https://github.com/AlexColagrande/MANO.",
    "summary": "arXiv:2507.02748v1 Announce Type: cross Abstract: Transformers have become the de facto standard for a wide range of tasks, from image classification to physics simulations. Despite their impressive performance, the quadratic complexity of standard Transformers in both memory and time with respect to the input length makes them impractical for processing high-resolution inputs. Therefore, several variants have been proposed, the most successful relying on patchification, downsampling, or coarsening techniques, often at the cost of losing the finest-scale details. In this work, we take a different approach. Inspired by state-of-the-art techniques in $n$-body numerical simulations, we cast attention as an interaction problem between grid points. We introduce the Multipole Attention Neural Operator (MANO), which computes attention in a distance-based multiscale fashion. MANO maintains, in each attention head, a global receptive field and achieves linear time and memory complexity with respect to the number of grid points. Empirical results on image classification and Darcy flows demonstrate that MANO rivals state-of-the-art models such as ViT and Swin Transformer, while reducing runtime and peak memory usage by orders of magnitude. We open source our code for reproducibility at https://github.com/AlexColagrande/MANO.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02748",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How AI training scales",
    "description": "We‚Äôve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks. Since complex tasks tend to have noisier gradients, increasingly large batch sizes are likely to become useful in the future, removing one potential limit to further growth of AI systems. More broadly, these results show that neural network training need not be considered a mysterious art, but can be rigorized and¬†systematized.",
    "summary": "We‚Äôve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks. Since complex tasks tend to have noisier gradients, increasingly large batch sizes are likely to become useful in the future, removing one potential limit to further growth of AI systems. More broadly, these results show that neural network training need not be considered a mysterious art, but can be rigorized and¬†systematized.",
    "pubDate": "Fri, 14 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-ai-training-scales",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Don't repeat yourself - ü§ó Transformers Design Philosophy",
    "description": "",
    "summary": "Don't Repeat Yourself* Designing open-source libraries for modern machine learning ü§ó Transformers De...",
    "pubDate": "Tue, 05 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-design-philosophy",
    "thumbnail": "https://huggingface.co/blog/assets/59_transformers_philosophy/transformers.png"
  },
  {
    "title": "OpenAI and journalism",
    "description": "We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.",
    "summary": "We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.",
    "pubDate": "Mon, 08 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-journalism",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaGenome: AI for better understanding the genome",
    "description": "Introducing a new, unifying DNA sequence model that advances regulatory variant-effect prediction and promises to shed new light on genome function ‚Äî now available via API.",
    "summary": "Introducing a new, unifying DNA sequence model that advances regulatory variant-effect prediction and promises to shed new light on genome function ‚Äî now available via API.",
    "pubDate": "Wed, 25 Jun 2025 13:59:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/",
    "thumbnail": "https://lh3.googleusercontent.com/SZkcKUQyLUhSQ06Rq-PJbxAqn1OpMeEa3khkrBVB1MGyHfxyftoqWwEb2aLP9JxX7CjhpLFODcc5zIoMoNdu0bl6ELsZV2nP9fDwZC6SYS36lzAKDw=w1200-h630-n-nu"
  },
  {
    "title": "Introducing the Open Arabic LLM Leaderboard",
    "description": "",
    "summary": "Introducing the Open Arabic LLM Leaderboard The Open Arabic LLM Leaderboard (OALL) is designed to ad...",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-arabic",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_arabic.png"
  },
  {
    "title": "Speech Synthesis, Recognition, and More With SpeechT5",
    "description": "",
    "summary": "Speech Synthesis, Recognition, and More With SpeechT5 We‚Äôre happy to announce that SpeechT5 is now a...",
    "pubDate": "Wed, 08 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/speecht5",
    "thumbnail": "https://huggingface.co/blog/assets/speecht5/thumbnail.png"
  },
  {
    "title": "Hierarchical text-conditional image generation with CLIP latents",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Apr 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hierarchical-text-conditional-image-generation-with-clip-latents",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating Audio Reasoning with Big Bench Audio",
    "description": "",
    "summary": "Evaluating Audio Reasoning with Big Bench Audio The emergence of native Speech to Speech models offe...",
    "pubDate": "Fri, 20 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/big-bench-audio-release",
    "thumbnail": "https://huggingface.co/blog/assets/big_bench_audio_release/big-bench-audio-thumbnail.png"
  },
  {
    "title": "Sentiment Classification with Fully Homomorphic Encryption using Concrete ML",
    "description": "",
    "summary": "Sentiment Analysis on Encrypted Data with Homomorphic Encryption It is well-known that a sentiment a...",
    "pubDate": "Thu, 17 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-fhe",
    "thumbnail": "https://huggingface.co/blog/assets/sentiment-analysis-fhe/thumbnail.png"
  },
  {
    "title": "Democratic inputs to AI grant program: lessons learned and implementation plans",
    "description": "We funded 10 teams from around the world to design ideas and tools to collectively govern AI. We summarize the innovations, outline our learnings, and call for researchers and engineers to join us as we continue this work.",
    "summary": "We funded 10 teams from around the world to design ideas and tools to collectively govern AI. We summarize the innovations, outline our learnings, and call for researchers and engineers to join us as we continue this work.",
    "pubDate": "Tue, 16 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/democratic-inputs-to-ai-grant-program-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Expert Support case study: Bolstering a RAG app with LLM-as-a-Judge",
    "description": "",
    "summary": "Expert Support case study: Bolstering a RAG app with LLM-as-a-Judge This is a guest blog post author...",
    "pubDate": "Mon, 28 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/digital-green-llm-judge",
    "thumbnail": "https://huggingface.co/blog/assets/digital-gren-llm-judge/thumbnail.png"
  },
  {
    "title": "Measuring Goodhart‚Äôs law",
    "description": "Goodhart‚Äôs law¬†famously says: ‚ÄúWhen a measure becomes a target, it ceases to be a good measure.‚Äù Although originally from economics, it‚Äôs something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
    "summary": "Goodhart‚Äôs law¬†famously says: ‚ÄúWhen a measure becomes a target, it ceases to be a good measure.‚Äù Although originally from economics, it‚Äôs something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
    "pubDate": "Wed, 13 Apr 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/measuring-goodharts-law",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Unsupervised sentiment neuron",
    "description": "We‚Äôve developed an unsupervised system which learns an excellent representation of sentiment, despite being trained only to predict the next character in the text of Amazon reviews.",
    "summary": "We‚Äôve developed an unsupervised system which learns an excellent representation of sentiment, despite being trained only to predict the next character in the text of Amazon reviews.",
    "pubDate": "Thu, 06 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/unsupervised-sentiment-neuron",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing ‚öîÔ∏è AI vs. AI ‚öîÔ∏è a deep reinforcement learning multi-agents competition system",
    "description": "",
    "summary": "Introducing ‚öîÔ∏è AI vs. AI ‚öîÔ∏è a deep reinforcement learning multi-agents competition system We‚Äôre exci...",
    "pubDate": "Tue, 07 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aivsai",
    "thumbnail": "https://huggingface.co/blog/assets/128_aivsai/thumbnail.png"
  },
  {
    "title": "Responsibility Gap and Diffusion in Sequential Decision-Making Mechanisms",
    "description": "arXiv:2507.02582v1 Announce Type: new Abstract: Responsibility has long been a subject of study in law and philosophy. More recently, it became a focus of AI literature. The article investigates the computational complexity of two important properties of responsibility in collective decision-making: diffusion and gap. It shows that the sets of diffusion-free and gap-free decision-making mechanisms are $Pi_2$-complete and $Pi_3$-complete, respectively. At the same time, the intersection of these classes is $Pi_2$-complete.",
    "summary": "arXiv:2507.02582v1 Announce Type: new Abstract: Responsibility has long been a subject of study in law and philosophy. More recently, it became a focus of AI literature. The article investigates the computational complexity of two important properties of responsibility in collective decision-making: diffusion and gap. It shows that the sets of diffusion-free and gap-free decision-making mechanisms are $Pi_2$-complete and $Pi_3$-complete, respectively. At the same time, the intersection of these classes is $Pi_2$-complete.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02582",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Proximal Policy Optimization (PPO)",
    "description": "",
    "summary": "Proximal Policy Optimization (PPO) Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 8, of ...",
    "pubDate": "Fri, 05 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-ppo",
    "thumbnail": "https://huggingface.co/blog/assets/93_deep_rl_ppo/thumbnail.png"
  },
  {
    "title": "RL¬≤: Fast reinforcement learning via slow reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 09 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rl2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Large-scale study of curiosity-driven learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 13 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/large-scale-study-of-curiosity-driven-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Grounding Intelligence in Movement",
    "description": "arXiv:2507.02771v1 Announce Type: new Abstract: Recent advances in machine learning have dramatically improved our ability to model language, vision, and other high-dimensional data, yet they continue to struggle with one of the most fundamental aspects of biological systems: movement. Across neuroscience, medicine, robotics, and ethology, movement is essential for interpreting behavior, predicting intent, and enabling interaction. Despite its core significance in our intelligence, movement is often treated as an afterthought rather than as a rich and structured modality in its own right. This reflects a deeper fragmentation in how movement data is collected and modeled, often constrained by task-specific goals and domain-specific assumptions. But movement is not domain-bound. It reflects shared physical constraints, conserved morphological structures, and purposeful dynamics that cut across species and settings. We argue that movement should be treated as a primary modeling target for AI. It is inherently structured and grounded in embodiment and physics. This structure, often allowing for compact, lower-dimensional representations (e.g., pose), makes it more interpretable and computationally tractable to model than raw, high-dimensional sensory inputs. Developing models that can learn from and generalize across diverse movement data will not only advance core capabilities in generative modeling and control, but also create a shared foundation for understanding behavior across biological and artificial systems. Movement is not just an outcome, it is a window into how intelligent systems engage with the world.",
    "summary": "arXiv:2507.02771v1 Announce Type: new Abstract: Recent advances in machine learning have dramatically improved our ability to model language, vision, and other high-dimensional data, yet they continue to struggle with one of the most fundamental aspects of biological systems: movement. Across neuroscience, medicine, robotics, and ethology, movement is essential for interpreting behavior, predicting intent, and enabling interaction. Despite its core significance in our intelligence, movement is often treated as an afterthought rather than as a rich and structured modality in its own right. This reflects a deeper fragmentation in how movement data is collected and modeled, often constrained by task-specific goals and domain-specific assumptions. But movement is not domain-bound. It reflects shared physical constraints, conserved morphological structures, and purposeful dynamics that cut across species and settings. We argue that movement should be treated as a primary modeling target for AI. It is inherently structured and grounded in embodiment and physics. This structure, often allowing for compact, lower-dimensional representations (e.g., pose), makes it more interpretable and computationally tractable to model than raw, high-dimensional sensory inputs. Developing models that can learn from and generalize across diverse movement data will not only advance core capabilities in generative modeling and control, but also create a shared foundation for understanding behavior across biological and artificial systems. Movement is not just an outcome, it is a window into how intelligent systems engage with the world.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02771",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders",
    "description": "arXiv:2507.02506v1 Announce Type: cross Abstract: Legal NLP remains underdeveloped in regions like India due to the scarcity of structured datasets. We introduce IndianBailJudgments-1200, a new benchmark dataset comprising 1200 Indian court judgments on bail decisions, annotated across 20+ attributes including bail outcome, IPC sections, crime type, and legal reasoning. Annotations were generated using a prompt-engineered GPT-4o pipeline and verified for consistency. This resource supports a wide range of legal NLP tasks such as outcome prediction, summarization, and fairness analysis, and is the first publicly available dataset focused specifically on Indian bail jurisprudence.",
    "summary": "arXiv:2507.02506v1 Announce Type: cross Abstract: Legal NLP remains underdeveloped in regions like India due to the scarcity of structured datasets. We introduce IndianBailJudgments-1200, a new benchmark dataset comprising 1200 Indian court judgments on bail decisions, annotated across 20+ attributes including bail outcome, IPC sections, crime type, and legal reasoning. Annotations were generated using a prompt-engineered GPT-4o pipeline and verified for consistency. This resource supports a wide range of legal NLP tasks such as outcome prediction, summarization, and fairness analysis, and is the first publicly available dataset focused specifically on Indian bail jurisprudence.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02506",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI„Åå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Å´„ÄÅAIÂà©Áî®ËÄÖ„ÅÆÂçäÊï∞‰ª•‰∏ä„ÅåÂà©Áî®",
    "description": "<p>NEXER„Å®„Éù„Éº„É´„Éà„Ç•„Ç¶„Ç£„É≥„Åå„ÄÅÊôÆÊÆµAI„ÇíÂà©Áî®„Åô„ÇãÂÖ®ÂõΩ238Âêç„ÇíÂØæË±°„Å´ÂÆüÊñΩ„Åó„ÅüË™øÊüª„Åß„ÄÅÂçäÊï∞‰ª•‰∏ä„Åå„Äå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Äç„Å®„Åó„Å¶AI„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Çã„Å®Áô∫Ë°®„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà AIÂà©Áî®ËÄÖ„ÅÆ 51.3%„Åå„Äå„Éó„É© [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/use-ai-private-consultant/'>AI„Åå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Å´„ÄÅAIÂà©Áî®ËÄÖ„ÅÆÂçäÊï∞‰ª•‰∏ä„ÅåÂà©Áî®</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>NEXER„Å®„Éù„Éº„É´„Éà„Ç•„Ç¶„Ç£„É≥„Åå„ÄÅÊôÆÊÆµAI„ÇíÂà©Áî®„Åô„ÇãÂÖ®ÂõΩ238Âêç„ÇíÂØæË±°„Å´ÂÆüÊñΩ„Åó„ÅüË™øÊüª„Åß„ÄÅÂçäÊï∞‰ª•‰∏ä„Åå„Äå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Äç„Å®„Åó„Å¶AI„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Çã„Å®Áô∫Ë°®„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà AIÂà©Áî®ËÄÖ„ÅÆ 51.3%„Åå„Äå„Éó„É© [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/use-ai-private-consultant/'>AI„Åå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Å´„ÄÅAIÂà©Áî®ËÄÖ„ÅÆÂçäÊï∞‰ª•‰∏ä„ÅåÂà©Áî®</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Fri, 27 Jun 2025 05:08:11 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/use-ai-private-consultant/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/use-ai-private-consultant1.png"
  },
  {
    "title": "AI Testing and Evaluation: Learnings from genome editing",
    "description": "<p>Bioethics and law expert R. Alta Charo explores the value of regulating technologies at the application level and the role of coordinated oversight in genome editing, while Microsoft GM Daniel Kluttz reflects on Charo‚Äôs points, drawing parallels to AI governance.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/'>AI Testing and Evaluation: Learnings from genome editing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Bioethics and law expert R. Alta Charo explores the value of regulating technologies at the application level and the role of coordinated oversight in genome editing, while Microsoft GM Daniel Kluttz reflects on Charo‚Äôs points, drawing parallels to AI governance.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/'>AI Testing and Evaluation: Learnings from genome editing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Mon, 30 Jun 2025 16:00:17 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Team++",
    "description": "We've had some fantastic people join over the past few months (and we're still hiring). Welcome, everyone!",
    "summary": "We've had some fantastic people join over the past few months (and we're still hiring). Welcome, everyone!",
    "pubDate": "Thu, 31 Mar 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-plus-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Build rich, interactive web apps with an updated Gemini 2.5 Pro",
    "description": "Our updated version of Gemini 2.5 Pro Preview has improved capabilities for coding.",
    "summary": "Our updated version of Gemini 2.5 Pro Preview has improved capabilities for coding.",
    "pubDate": "Tue, 06 May 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/build-rich-interactive-web-apps-with-an-updated-gemini-25-pro/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini25prohero.width-1300.png"
  },
  {
    "title": "OpenAI Robotics Symposium 2019",
    "description": "We hosted the first OpenAI Robotics Symposium on April 27, 2019.",
    "summary": "We hosted the first OpenAI Robotics Symposium on April 27, 2019.",
    "pubDate": "Wed, 05 Jun 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/symposium-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An AI-native experimental laboratory for autonomous biomolecular engineering",
    "description": "arXiv:2507.02379v1 Announce Type: new Abstract: Autonomous scientific research, capable of independently conducting complex experiments and serving non-specialists, represents a long-held aspiration. Achieving it requires a fundamental paradigm shift driven by artificial intelligence (AI). While autonomous experimental systems are emerging, they remain confined to areas featuring singular objectives and well-defined, simple experimental workflows, such as chemical synthesis and catalysis. We present an AI-native autonomous laboratory, targeting highly complex scientific experiments for applications like autonomous biomolecular engineering. This system autonomously manages instrumentation, formulates experiment-specific procedures and optimization heuristics, and concurrently serves multiple user requests. Founded on a co-design philosophy of models, experiments, and instruments, the platform supports the co-evolution of AI models and the automation system. This establishes an end-to-end, multi-user autonomous laboratory that handles complex, multi-objective experiments across diverse instrumentation. Our autonomous laboratory supports fundamental nucleic acid functions-including synthesis, transcription, amplification, and sequencing. It also enables applications in fields such as disease diagnostics, drug development, and information storage. Without human intervention, it autonomously optimizes experimental performance to match state-of-the-art results achieved by human scientists. In multi-user scenarios, the platform significantly improves instrument utilization and experimental efficiency. This platform paves the way for advanced biomaterials research to overcome dependencies on experts and resource barriers, establishing a blueprint for science-as-a-service at scale.",
    "summary": "arXiv:2507.02379v1 Announce Type: new Abstract: Autonomous scientific research, capable of independently conducting complex experiments and serving non-specialists, represents a long-held aspiration. Achieving it requires a fundamental paradigm shift driven by artificial intelligence (AI). While autonomous experimental systems are emerging, they remain confined to areas featuring singular objectives and well-defined, simple experimental workflows, such as chemical synthesis and catalysis. We present an AI-native autonomous laboratory, targeting highly complex scientific experiments for applications like autonomous biomolecular engineering. This system autonomously manages instrumentation, formulates experiment-specific procedures and optimization heuristics, and concurrently serves multiple user requests. Founded on a co-design philosophy of models, experiments, and instruments, the platform supports the co-evolution of AI models and the automation system. This establishes an end-to-end, multi-user autonomous laboratory that handles complex, multi-objective experiments across diverse instrumentation. Our autonomous laboratory supports fundamental nucleic acid functions-including synthesis, transcription, amplification, and sequencing. It also enables applications in fields such as disease diagnostics, drug development, and information storage. Without human intervention, it autonomously optimizes experimental performance to match state-of-the-art results achieved by human scientists. In multi-user scenarios, the platform significantly improves instrument utilization and experimental efficiency. This platform paves the way for advanced biomaterials research to overcome dependencies on experts and resource barriers, establishing a blueprint for science-as-a-service at scale.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02379",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing OpenAI for Countries",
    "description": "A new initiative to support countries around the world that want to build on democratic AI rails.",
    "summary": "A new initiative to support countries around the world that want to build on democratic AI rails.",
    "pubDate": "Wed, 07 May 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-for-countries",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generating audio for video",
    "description": "Video-to-audio research uses video pixels and text prompts to generate rich soundtracks",
    "summary": "Video-to-audio research uses video pixels and text prompts to generate rich soundtracks",
    "pubDate": "Mon, 17 Jun 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/generating-audio-for-video/",
    "thumbnail": "https://lh3.googleusercontent.com/Lzihw4F171DQeSgZ9q0MUONzbt1BkbK1sOgnqvLAV3AUIQQ1UJ4niEXOTgWiiyKZrJaCpE4Q6APwV8RRQj7a86_2yDlbIV6WUzD6S_Gu2mjuZDyVWqo=w1200-h630-n-nu"
  },
  {
    "title": "Sora first impressions",
    "description": "Since we introduced Sora to the world last month, we‚Äôve been working with artists to learn how Sora might aid in their creative process.",
    "summary": "Since we introduced Sora to the world last month, we‚Äôve been working with artists to learn how Sora might aid in their creative process.",
    "pubDate": "Mon, 25 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-first-impressions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Illustrating Reinforcement Learning from Human Feedback (RLHF)",
    "description": "",
    "summary": "Illustrating Reinforcement Learning from Human Feedback (RLHF) This article has been translated to C...",
    "pubDate": "Fri, 09 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rlhf",
    "thumbnail": "https://huggingface.co/blog/assets/120_rlhf/thumbnail.png"
  },
  {
    "title": "Machine Learning Experts - Meg Mitchell Interview",
    "description": "",
    "summary": "Machine Learning Experts - Margaret Mitchell Hey friends! Welcome to Machine Learning Experts. I'm y...",
    "pubDate": "Wed, 23 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/meg-mitchell-interview",
    "thumbnail": "https://huggingface.co/blog/assets/57_meg_mitchell_interview/thumbnail.png"
  },
  {
    "title": "Combining technology, education, and human connection to improve online learning",
    "description": "Caitlin Morris, a PhD student and 2024 MAD Fellow affiliated with the MIT Media Lab, designs digital learning platforms that make room for the ‚Äúsocial magic‚Äù that influences curiosity and motivation.",
    "summary": "Caitlin Morris, a PhD student and 2024 MAD Fellow affiliated with the MIT Media Lab, designs digital learning platforms that make room for the ‚Äúsocial magic‚Äù that influences curiosity and motivation.",
    "pubDate": "Tue, 17 Jun 2025 16:25:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/caitlin-morris-combines-tech-education-human-connection-improve-online-learning-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-Caitlin-Morris.jpg"
  },
  {
    "title": "MaizeField3D: A Curated 3D Point Cloud and Procedural Model Dataset of Field-Grown Maize from a Diversity Panel",
    "description": "arXiv:2503.07813v3 Announce Type: replace-cross Abstract: The development of artificial intelligence (AI) and machine learning (ML) based tools for 3D phenotyping, especially for maize, has been limited due to the lack of large and diverse 3D datasets. 2D image datasets fail to capture essential structural details such as leaf architecture, plant volume, and spatial arrangements that 3D data provide. To address this limitation, we present MaizeField3D (https://baskargroup.github.io/MaizeField3D/), a curated dataset of 3D point clouds of field-grown maize plants from a diverse genetic panel, designed to be AI-ready for advancing agricultural research. Our dataset includes 1,045 high-quality point clouds of field-grown maize collected using a terrestrial laser scanner (TLS). Point clouds of 520 plants from this dataset were segmented and annotated using a graph-based segmentation method to isolate individual leaves and stalks, ensuring consistent labeling across all samples. This labeled data was then used for fitting procedural models that provide a structured parametric representation of the maize plants. The leaves of the maize plants in the procedural models are represented using Non-Uniform Rational B-Spline (NURBS) surfaces that were generated using a two-step optimization process combining gradient-free and gradient-based methods. We conducted rigorous manual quality control on all datasets, correcting errors in segmentation, ensuring accurate leaf ordering, and validating metadata annotations. The dataset also includes metadata detailing plant morphology and quality, alongside multi-resolution subsampled point cloud data (100k, 50k, 10k points), which can be readily used for different downstream computational tasks. MaizeField3D will serve as a comprehensive foundational dataset for AI-driven phenotyping, plant structural analysis, and 3D applications in agricultural research.",
    "summary": "arXiv:2503.07813v3 Announce Type: replace-cross Abstract: The development of artificial intelligence (AI) and machine learning (ML) based tools for 3D phenotyping, especially for maize, has been limited due to the lack of large and diverse 3D datasets. 2D image datasets fail to capture essential structural details such as leaf architecture, plant volume, and spatial arrangements that 3D data provide. To address this limitation, we present MaizeField3D (https://baskargroup.github.io/MaizeField3D/), a curated dataset of 3D point clouds of field-grown maize plants from a diverse genetic panel, designed to be AI-ready for advancing agricultural research. Our dataset includes 1,045 high-quality point clouds of field-grown maize collected using a terrestrial laser scanner (TLS). Point clouds of 520 plants from this dataset were segmented and annotated using a graph-based segmentation method to isolate individual leaves and stalks, ensuring consistent labeling across all samples. This labeled data was then used for fitting procedural models that provide a structured parametric representation of the maize plants. The leaves of the maize plants in the procedural models are represented using Non-Uniform Rational B-Spline (NURBS) surfaces that were generated using a two-step optimization process combining gradient-free and gradient-based methods. We conducted rigorous manual quality control on all datasets, correcting errors in segmentation, ensuring accurate leaf ordering, and validating metadata annotations. The dataset also includes metadata detailing plant morphology and quality, alongside multi-resolution subsampled point cloud data (100k, 50k, 10k points), which can be readily used for different downstream computational tasks. MaizeField3D will serve as a comprehensive foundational dataset for AI-driven phenotyping, plant structural analysis, and 3D applications in agricultural research.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.07813",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Training a language model with ü§ó Transformers using TensorFlow and TPUs",
    "description": "",
    "summary": "Training a language model with ü§ó Transformers using TensorFlow and TPUs Introduction TPU training is...",
    "pubDate": "Thu, 27 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf_tpu",
    "thumbnail": "https://huggingface.co/blog/assets/tf_tpu_training/thumbnail.png"
  },
  {
    "title": "Our approach to data and AI",
    "description": "Just over a year after launching ChatGPT, AI is changing how we live, work and learn. It‚Äôs also raised important conversations about data in the age of AI. More on our approach, a new Media Manager for creators and content owners, and where we‚Äôre headed.",
    "summary": "Just over a year after launching ChatGPT, AI is changing how we live, work and learn. It‚Äôs also raised important conversations about data in the age of AI. More on our approach, a new Media Manager for creators and content owners, and where we‚Äôre headed.",
    "pubDate": "Tue, 07 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/approach-to-data-and-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sycophancy in GPT-4o: what happened and what we‚Äôre doing about it",
    "description": "We have rolled back last week‚Äôs GPT‚Äë4o update in ChatGPT so people are now using an earlier version with more balanced behavior. The update we removed was overly flattering or agreeable‚Äîoften described as sycophantic.",
    "summary": "We have rolled back last week‚Äôs GPT‚Äë4o update in ChatGPT so people are now using an earlier version with more balanced behavior. The update we removed was overly flattering or agreeable‚Äîoften described as sycophantic.",
    "pubDate": "Tue, 29 Apr 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sycophancy-in-gpt-4o",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Image Classification with AutoTrain",
    "description": "",
    "summary": "Image Classification with AutoTrain So you‚Äôve heard all about the cool things that are happening in ...",
    "pubDate": "Wed, 28 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autotrain-image-classification",
    "thumbnail": "https://huggingface.co/blog/assets/105_autotrain-image-classification/thumbnail.png"
  },
  {
    "title": "OpenAI and Hearst Content Partnership",
    "description": "Hearst‚Äôs iconic brands bring curated lifestyle and local news content to OpenAI‚Äôs products.",
    "summary": "Hearst‚Äôs iconic brands bring curated lifestyle and local news content to OpenAI‚Äôs products.",
    "pubDate": "Tue, 08 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hearst",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Tool Use, Unified",
    "description": "",
    "summary": "Tool Use, Unified There is now a unified tool use API across several popular families of models. Thi...",
    "pubDate": "Mon, 12 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unified-tool-use",
    "thumbnail": "https://huggingface.co/blog/assets/unified-tool-use/thumbnail.png"
  },
  {
    "title": "Benchmarking safe exploration in deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 21 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/benchmarking-safe-exploration-in-deep-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI partners with Cond√© Nast",
    "description": "Cond√© Nast",
    "summary": "Cond√© Nast",
    "pubDate": "Tue, 20 Aug 2024 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/conde-nast",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing OpenAI‚Äôs Bug Bounty Program",
    "description": "This initiative is essential to our commitment to develop safe and advanced AI. As we create technology and services that are secure, reliable, and trustworthy, we need your help.",
    "summary": "This initiative is essential to our commitment to develop safe and advanced AI. As we create technology and services that are secure, reliable, and trustworthy, we need your help.",
    "pubDate": "Tue, 11 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bug-bounty-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ÁîüÊàêAI„ÅßÂ§â„Çè„Çã„Çµ„Ç§„Éê„Éº„Çª„Ç≠„É•„É™„ÉÜ„Ç£„ÄÄNEC„Å®IDC„ÅåË™û„Çã„ÄåAI√ó„Çª„Ç≠„É•„É™„ÉÜ„Ç£„Äç„ÅÆË¶ÅÁÇπ",
    "description": "NEC Corporate Executive CISO„ÅÆÊ∑µ‰∏äÁúü‰∏ÄÊ∞è„Å®„ÄÅIDC Japan „É™„Çµ„Éº„ÉÅ„Éû„Éç„Éº„Ç∏„É£„Éº„ÅÆËµ§ÈñìÂÅ•‰∏ÄÊ∞è„Å´„Çà„ÇãË¨õÊºî„ÅÆÂÜÖÂÆπ„Åã„Çâ„ÄÅAIÊôÇ‰ª£„ÅÆ„Çª„Ç≠„É•„É™„ÉÜ„Ç£Êà¶Áï•„ÅÆÊúÄÂâçÁ∑ö„ÇíË™≠„ÅøËß£„Åè„ÄÇ",
    "summary": "NEC Corporate Executive CISO„ÅÆÊ∑µ‰∏äÁúü‰∏ÄÊ∞è„Å®„ÄÅIDC Japan „É™„Çµ„Éº„ÉÅ„Éû„Éç„Éº„Ç∏„É£„Éº„ÅÆËµ§ÈñìÂÅ•‰∏ÄÊ∞è„Å´„Çà„ÇãË¨õÊºî„ÅÆÂÜÖÂÆπ„Åã„Çâ„ÄÅAIÊôÇ‰ª£„ÅÆ„Çª„Ç≠„É•„É™„ÉÜ„Ç£Êà¶Áï•„ÅÆÊúÄÂâçÁ∑ö„ÇíË™≠„ÅøËß£„Åè„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 05:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2507/02/news031.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2507/02/cover_news031.jpg"
  },
  {
    "title": "Distill",
    "description": "We‚Äôre excited to support today‚Äôs launch of Distill, a new kind of journal aimed at excellent communication of machine learning results (novel or existing).",
    "summary": "We‚Äôre excited to support today‚Äôs launch of Distill, a new kind of journal aimed at excellent communication of machine learning results (novel or existing).",
    "pubDate": "Mon, 20 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/distill",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hosting your Models and Datasets on Hugging Face Spaces using Streamlit",
    "description": "",
    "summary": "Hosting your Models and Datasets on Hugging Face Spaces using Streamlit Showcase your Datasets and M...",
    "pubDate": "Tue, 05 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/streamlit-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/29_streamlit-spaces/thumbnail.png"
  },
  {
    "title": "OpenAI safety practices",
    "description": "Artificial general intelligence has the potential to benefit nearly every aspect of our lives‚Äîso it must be developed and deployed responsibly.",
    "summary": "Artificial general intelligence has the potential to benefit nearly every aspect of our lives‚Äîso it must be developed and deployed responsibly.",
    "pubDate": "Tue, 21 May 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-safety-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "È™®„ÅÆ„Çà„ÅÜ„Å™3D„Éó„É™„É≥„ÇøË£Ω„ÉÅ„Çß„Ç¢„ÄÄÁîüÁâ©Ê®°ÂÄ£„ÇíÂèñ„ÇäÂÖ•„ÇåAIÊê≠Ëºâ„Éê„Éº„ÉÅ„É£„É´„ÉÑ„Ç§„É≥„ÅßÈñãÁô∫",
    "description": "„ÉÄ„ÉÉ„ÇΩ„Éº„Éª„Ç∑„Çπ„ÉÜ„É†„Ç∫„ÅØ„ÄÅ„Éï„É©„É≥„Çπ„ÅÆ„Éá„Ç∂„Ç§„Éä„Éº„Åß„ÅÇ„Çã„Éë„Éà„É™„ÉÉ„ÇØ„Éª„Ç∏„É•„Ç¢„É≥Ê∞è„Å®ÂÖ±ÂêåÈñãÁô∫„Åó„ÅüËªΩÈáè„ÉÅ„Çß„Ç¢„ÄåTa.Tamu„Äç„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÊ†ºÂ≠êÊßãÈÄ†„ÅÆ„Éá„Ç∂„Ç§„É≥„ÅØ„Äå3DEXPERIENCE„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„Éª„Ç™„É≥„Éª„Ç∂„Éª„ÇØ„É©„Ç¶„Éâ„Äç„ÇíÊ¥ªÁî®„Åó„Å¶Ë®≠Ë®à„Åï„Çå„ÄÅ3D„Éó„É™„É≥„Çø„Åß‰∏Ä‰ΩìÈÄ†ÂΩ¢„Åï„Çå„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "„ÉÄ„ÉÉ„ÇΩ„Éº„Éª„Ç∑„Çπ„ÉÜ„É†„Ç∫„ÅØ„ÄÅ„Éï„É©„É≥„Çπ„ÅÆ„Éá„Ç∂„Ç§„Éä„Éº„Åß„ÅÇ„Çã„Éë„Éà„É™„ÉÉ„ÇØ„Éª„Ç∏„É•„Ç¢„É≥Ê∞è„Å®ÂÖ±ÂêåÈñãÁô∫„Åó„ÅüËªΩÈáè„ÉÅ„Çß„Ç¢„ÄåTa.Tamu„Äç„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÊ†ºÂ≠êÊßãÈÄ†„ÅÆ„Éá„Ç∂„Ç§„É≥„ÅØ„Äå3DEXPERIENCE„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„Éª„Ç™„É≥„Éª„Ç∂„Éª„ÇØ„É©„Ç¶„Éâ„Äç„ÇíÊ¥ªÁî®„Åó„Å¶Ë®≠Ë®à„Åï„Çå„ÄÅ3D„Éó„É™„É≥„Çø„Åß‰∏Ä‰ΩìÈÄ†ÂΩ¢„Åï„Çå„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Fri, 04 Jul 2025 12:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://monoist.itmedia.co.jp/mn/articles/2507/04/news062.html",
    "thumbnail": "https://image.itmedia.co.jp/mn/articles/2507/04/cover_news062.jpg"
  },
  {
    "title": "Strategic Content Partnership with TIME",
    "description": "We‚Äôre partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories on Time.com",
    "summary": "We‚Äôre partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories on Time.com",
    "pubDate": "Thu, 27 Jun 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/strategic-content-partnership-with-time",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Frontier Model Forum updates",
    "description": "Together with Anthropic, Google, and Microsoft, we‚Äôre announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",
    "summary": "Together with Anthropic, Google, and Microsoft, we‚Äôre announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",
    "pubDate": "Wed, 25 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-model-forum-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deep Q-Learning with Atari",
    "description": "",
    "summary": "Deep Q-Learning with Space Invaders Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 3, of...",
    "pubDate": "Tue, 07 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-dqn",
    "thumbnail": "https://huggingface.co/blog/assets/78_deep_rl_dqn/thumbnail.gif"
  },
  {
    "title": "Faster physics in Python",
    "description": "We‚Äôre open-sourcing a high-performance Python library for robotic simulation using the MuJoCo engine, developed over our past year of robotics research.",
    "summary": "We‚Äôre open-sourcing a high-performance Python library for robotic simulation using the MuJoCo engine, developed over our past year of robotics research.",
    "pubDate": "Wed, 28 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/faster-physics-in-python",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The State of Computer Vision at Hugging Face ü§ó",
    "description": "",
    "summary": "The State of Computer Vision at Hugging Face ü§ó At Hugging Face, we pride ourselves on democratizing ...",
    "pubDate": "Mon, 30 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cv_state",
    "thumbnail": "https://huggingface.co/blog/assets/cv_state/thumbnail.png"
  },
  {
    "title": "A sounding board for strengthening the student experience",
    "description": "Composed of ‚Äúcomputing bilinguals,‚Äù the Undergraduate Advisory Group provides vital input to help advance the mission of the MIT Schwarzman College of Computing.",
    "summary": "Composed of ‚Äúcomputing bilinguals,‚Äù the Undergraduate Advisory Group provides vital input to help advance the mission of the MIT Schwarzman College of Computing.",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/sounding-board-for-strengthening-student-experience-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-SCC-UAG.jpg"
  },
  {
    "title": "Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation",
    "description": "arXiv:2505.21880v2 Announce Type: replace-cross Abstract: This study presents an innovative approach to urban mobility simulation by integrating a Large Language Model (LLM) with Agent-Based Modeling (ABM). Unlike traditional rule-based ABM, the proposed framework leverages LLM to enhance agent diversity and realism by generating synthetic population profiles, allocating routine and occasional locations, and simulating personalized routes. Using real-world data, the simulation models individual behaviors and large-scale mobility patterns in Taipei City. Key insights, such as route heat maps and mode-specific indicators, provide urban planners with actionable information for policy-making. Future work focuses on establishing robust validation frameworks to ensure accuracy and reliability in urban planning applications.",
    "summary": "arXiv:2505.21880v2 Announce Type: replace-cross Abstract: This study presents an innovative approach to urban mobility simulation by integrating a Large Language Model (LLM) with Agent-Based Modeling (ABM). Unlike traditional rule-based ABM, the proposed framework leverages LLM to enhance agent diversity and realism by generating synthetic population profiles, allocating routine and occasional locations, and simulating personalized routes. Using real-world data, the simulation models individual behaviors and large-scale mobility patterns in Taipei City. Key insights, such as route heat maps and mode-specific indicators, provide urban planners with actionable information for policy-making. Future work focuses on establishing robust validation frameworks to ensure accuracy and reliability in urban planning applications.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.21880",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Encrypted Large Language Models with FHE",
    "description": "",
    "summary": "Towards Encrypted Large Language Models with FHE Large Language Models (LLM) have recently been prov...",
    "pubDate": "Wed, 02 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/encrypted-llm",
    "thumbnail": "https://huggingface.co/blog/assets/encrypted-llm/thumbnail.png"
  },
  {
    "title": "An update on our safety & security practices",
    "description": "An update on our safety & security practices",
    "summary": "An update on our safety & security practices",
    "pubDate": "Mon, 16 Sep 2024 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/update-on-safety-and-security-practices",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Transformers.js v3: WebGPU support, new models & tasks, and more‚Ä¶",
    "description": "",
    "summary": "Transformers.js v3: WebGPU Support, New Models & Tasks, and More‚Ä¶ After more than a year of developm...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformersjs-v3",
    "thumbnail": "https://huggingface.co/blog/assets/transformersjs-v3/thumbnail.png"
  },
  {
    "title": "Introducing text and code embeddings",
    "description": "We are introducing embeddings, a new endpoint in the OpenAI API that makes it easy to perform natural language and code tasks like semantic search, clustering, topic modeling, and classification.",
    "summary": "We are introducing embeddings, a new endpoint in the OpenAI API that makes it easy to perform natural language and code tasks like semantic search, clustering, topic modeling, and classification.",
    "pubDate": "Tue, 25 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-text-and-code-embeddings",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models",
    "description": "",
    "summary": "Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models Transformer-based encod...",
    "pubDate": "Mon, 09 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/warm-starting-encoder-decoder",
    "thumbnail": "https://huggingface.co/blog/assets/08_warm_starting_encoder_decoder/thumbnail.png"
  },
  {
    "title": "Detection of Disengagement from Voluntary Quizzes: An Explainable Machine Learning Approach in Higher Distance Education",
    "description": "arXiv:2507.02681v1 Announce Type: new Abstract: Students disengaging from their tasks can have serious long-term consequences, including academic drop-out. This is particularly relevant for students in distance education. One way to measure the level of disengagement in distance education is to observe participation in non-mandatory exercises in different online courses. In this paper, we detect student disengagement in the non-mandatory quizzes of 42 courses in four semesters from a distance-based university. We carefully identified the most informative student log data that could be extracted and processed from Moodle. Then, eight machine learning algorithms were trained and compared to obtain the highest possible prediction accuracy. Using the SHAP method, we developed an explainable machine learning framework that allows practitioners to better understand the decisions of the trained algorithm. The experimental results show a balanced accuracy of 91%, where about 85% of disengaged students were correctly detected. On top of the highly predictive performance and explainable framework, we provide a discussion on how to design a timely intervention to minimise disengagement from voluntary tasks in online learning.",
    "summary": "arXiv:2507.02681v1 Announce Type: new Abstract: Students disengaging from their tasks can have serious long-term consequences, including academic drop-out. This is particularly relevant for students in distance education. One way to measure the level of disengagement in distance education is to observe participation in non-mandatory exercises in different online courses. In this paper, we detect student disengagement in the non-mandatory quizzes of 42 courses in four semesters from a distance-based university. We carefully identified the most informative student log data that could be extracted and processed from Moodle. Then, eight machine learning algorithms were trained and compared to obtain the highest possible prediction accuracy. Using the SHAP method, we developed an explainable machine learning framework that allows practitioners to better understand the decisions of the trained algorithm. The experimental results show a balanced accuracy of 91%, where about 85% of disengaged students were correctly detected. On top of the highly predictive performance and explainable framework, we provide a discussion on how to design a timely intervention to minimise disengagement from voluntary tasks in online learning.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02681",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer)",
    "description": "",
    "summary": "Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer) Introduction A few months...",
    "pubDate": "Fri, 16 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autoformer",
    "thumbnail": "https://huggingface.co/blog/assets/150_autoformer/thumbnail.png"
  },
  {
    "title": "Perplexity„ÇÇÊúàÈ°ç200„Éâ„É´„ÅÆ„ÄåMax„Äç„Éó„É©„É≥Êèê‰æõÈñãÂßã",
    "description": "AIÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆPerplexity„Åå„ÄÅÊúàÈ°ç200„Éâ„É´„ÅÆÊúÄ‰∏ä‰Ωç„Éó„É©„É≥„ÄåPerplexity Max„Äç„ÅÆÊèê‰æõ„ÇíÈñãÂßã„Åó„Åü„ÄÇPro„Éó„É©„É≥„ÅÆÊ©üËÉΩ„Å´Âä†„Åà„ÄÅ„Ç®„Éº„Ç∏„Çß„É≥„Éà„Éñ„É©„Ç¶„Ç∂„ÄåComet„Äç„Å∏„ÅÆÊó©Êúü„Ç¢„ÇØ„Çª„Çπ„ÇÑ„ÄÅPerplexity Labs„Å∏„ÅÆÁÑ°Âà∂Èôê„Ç¢„ÇØ„Çª„Çπ„Å™„Å©„ÅåÂèØËÉΩ„Å´„Å™„Çã„ÄÇ",
    "summary": "AIÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆPerplexity„Åå„ÄÅÊúàÈ°ç200„Éâ„É´„ÅÆÊúÄ‰∏ä‰Ωç„Éó„É©„É≥„ÄåPerplexity Max„Äç„ÅÆÊèê‰æõ„ÇíÈñãÂßã„Åó„Åü„ÄÇPro„Éó„É©„É≥„ÅÆÊ©üËÉΩ„Å´Âä†„Åà„ÄÅ„Ç®„Éº„Ç∏„Çß„É≥„Éà„Éñ„É©„Ç¶„Ç∂„ÄåComet„Äç„Å∏„ÅÆÊó©Êúü„Ç¢„ÇØ„Çª„Çπ„ÇÑ„ÄÅPerplexity Labs„Å∏„ÅÆÁÑ°Âà∂Èôê„Ç¢„ÇØ„Çª„Çπ„Å™„Å©„ÅåÂèØËÉΩ„Å´„Å™„Çã„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 06:55:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news054.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news054.jpg"
  },
  {
    "title": "SetFitABSA: Few-Shot Aspect Based Sentiment Analysis using SetFit",
    "description": "",
    "summary": "SetFitABSA: Few-Shot Aspect Based Sentiment Analysis using SetFit SetFitABSA is an efficient techniq...",
    "pubDate": "Wed, 06 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit-absa",
    "thumbnail": "https://huggingface.co/blog/assets/setfit-absa/intel_hf_logo_2.png"
  },
  {
    "title": "3D Asset Generation: AI for Game Development #3",
    "description": "",
    "summary": "3D Asset Generation: AI for Game Development #3 Welcome to AI for Game Development! In this series, ...",
    "pubDate": "Fri, 20 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-3",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail3.png"
  },
  {
    "title": "Learning From Crowdsourced Noisy Labels: A Signal Processing Perspective",
    "description": "arXiv:2407.06902v2 Announce Type: replace-cross Abstract: One of the primary catalysts fueling advances in artificial intelligence (AI) and machine learning (ML) is the availability of massive, curated datasets. A commonly used technique to curate such massive datasets is crowdsourcing, where data are dispatched to multiple annotators. The annotator-produced labels are then fused to serve downstream learning and inference tasks. This annotation process often creates noisy labels due to various reasons, such as the limited expertise, or unreliability of annotators, among others. Therefore, a core objective in crowdsourcing is to develop methods that effectively mitigate the negative impact of such label noise on learning tasks. This feature article introduces advances in learning from noisy crowdsourced labels. The focus is on key crowdsourcing models and their methodological treatments, from classical statistical models to recent deep learning-based approaches, emphasizing analytical insights and algorithmic developments. In particular, this article reviews the connections between signal processing (SP) theory and methods, such as identifiability of tensor and nonnegative matrix factorization, and novel, principled solutions of longstanding challenges in crowdsourcing -- showing how SP perspectives drive the advancements of this field. Furthermore, this article touches upon emerging topics that are critical for developing cutting-edge AI/ML systems, such as crowdsourcing in reinforcement learning with human feedback (RLHF) and direct preference optimization (DPO) that are key techniques for fine-tuning large language models (LLMs).",
    "summary": "arXiv:2407.06902v2 Announce Type: replace-cross Abstract: One of the primary catalysts fueling advances in artificial intelligence (AI) and machine learning (ML) is the availability of massive, curated datasets. A commonly used technique to curate such massive datasets is crowdsourcing, where data are dispatched to multiple annotators. The annotator-produced labels are then fused to serve downstream learning and inference tasks. This annotation process often creates noisy labels due to various reasons, such as the limited expertise, or unreliability of annotators, among others. Therefore, a core objective in crowdsourcing is to develop methods that effectively mitigate the negative impact of such label noise on learning tasks. This feature article introduces advances in learning from noisy crowdsourced labels. The focus is on key crowdsourcing models and their methodological treatments, from classical statistical models to recent deep learning-based approaches, emphasizing analytical insights and algorithmic developments. In particular, this article reviews the connections between signal processing (SP) theory and methods, such as identifiability of tensor and nonnegative matrix factorization, and novel, principled solutions of longstanding challenges in crowdsourcing -- showing how SP perspectives drive the advancements of this field. Furthermore, this article touches upon emerging topics that are critical for developing cutting-edge AI/ML systems, such as crowdsourcing in reinforcement learning with human feedback (RLHF) and direct preference optimization (DPO) that are key techniques for fine-tuning large language models (LLMs).",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.06902",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„Äå„Éâ„É©„Ç¥„É≥„Éú„Éº„É´„Äç„ÅÆ„Éñ„É´„Éû„ÅØIT„Ç®„É≥„Ç∏„Éã„Ç¢„ÅÆÁêÜÊÉ≥ÂÉè‚îÄ‚îÄ„Éï„Ç°„Ç§„É≥„Éá„Ç£„Åå„ÉÜ„É¨„ÉìCM„Å´Ëµ∑Áî®",
    "description": "„Ç®„É≥„Ç∏„Éã„Ç¢Âêë„Åë„ÅÆËª¢ËÅ∑„Çµ„Éº„Éì„Çπ„ÄåFindy„Äç„ÇíÈÅãÂñ∂„Åô„Çã„Éï„Ç°„Ç§„É≥„Éá„Ç£„ÅØ„ÄÅ„ÉÜ„É¨„Éì„Ç¢„Éã„É°„Äå„Éâ„É©„Ç¥„É≥„Éú„Éº„É´Z„Äç„ÅÆ„Ç≠„É£„É©„ÇØ„Çø„Éº„ÇíËµ∑Áî®„Åó„Åü„ÉÜ„É¨„Éì„Ç≥„Éû„Éº„Ç∑„É£„É´„ÇíÊîæÈÄÅ„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ",
    "summary": "„Ç®„É≥„Ç∏„Éã„Ç¢Âêë„Åë„ÅÆËª¢ËÅ∑„Çµ„Éº„Éì„Çπ„ÄåFindy„Äç„ÇíÈÅãÂñ∂„Åô„Çã„Éï„Ç°„Ç§„É≥„Éá„Ç£„ÅØ„ÄÅ„ÉÜ„É¨„Éì„Ç¢„Éã„É°„Äå„Éâ„É©„Ç¥„É≥„Éú„Éº„É´Z„Äç„ÅÆ„Ç≠„É£„É©„ÇØ„Çø„Éº„ÇíËµ∑Áî®„Åó„Åü„ÉÜ„É¨„Éì„Ç≥„Éû„Éº„Ç∑„É£„É´„ÇíÊîæÈÄÅ„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 13:41:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news085.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news085.jpg"
  },
  {
    "title": "Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab",
    "description": "arXiv:2507.02083v1 Announce Type: new Abstract: Designing experiments and result interpretations are core scientific competencies, particularly in biology, where researchers perturb complex systems to uncover the underlying systems. Recent efforts to evaluate the scientific capabilities of large language models (LLMs) fail to test these competencies because wet-lab experimentation is prohibitively expensive: in expertise, time and equipment. We introduce SciGym, a first-in-class benchmark that assesses LLMs' iterative experiment design and analysis abilities in open-ended scientific discovery tasks. SciGym overcomes the challenge of wet-lab costs by running a dry lab of biological systems. These models, encoded in Systems Biology Markup Language, are efficient for generating simulated data, making them ideal testbeds for experimentation on realistically complex systems. We evaluated six frontier LLMs on 137 small systems, and released a total of 350 systems. Our evaluation shows that while more capable models demonstrated superior performance, all models' performance declined significantly as system complexity increased, suggesting substantial room for improvement in the scientific capabilities of LLM agents.",
    "summary": "arXiv:2507.02083v1 Announce Type: new Abstract: Designing experiments and result interpretations are core scientific competencies, particularly in biology, where researchers perturb complex systems to uncover the underlying systems. Recent efforts to evaluate the scientific capabilities of large language models (LLMs) fail to test these competencies because wet-lab experimentation is prohibitively expensive: in expertise, time and equipment. We introduce SciGym, a first-in-class benchmark that assesses LLMs' iterative experiment design and analysis abilities in open-ended scientific discovery tasks. SciGym overcomes the challenge of wet-lab costs by running a dry lab of biological systems. These models, encoded in Systems Biology Markup Language, are efficient for generating simulated data, making them ideal testbeds for experimentation on realistically complex systems. We evaluated six frontier LLMs on 137 small systems, and released a total of 350 systems. Our evaluation shows that while more capable models demonstrated superior performance, all models' performance declined significantly as system complexity increased, suggesting substantial room for improvement in the scientific capabilities of LLM agents.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02083",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ÁîüÊàêAI„Å´„ÄåÊúüÂæÖ„Åó„Å¶„ÅÑ„Çã„Äç‰∫∫„ÅØÂÖ®‰Ωì„Åß33ÔºÖ„ÄÅ‰∏ÄÊñπ10‰ª£Áî∑ÊÄß„Åß„ÅØ70ÔºÖ„ÄÄNTT„Éâ„Ç≥„É¢Ë™øÊüª",
    "description": "ÁîüÊàêAI„Å´„ÄåÊúüÂæÖ„Åó„Å¶„ÅÑ„Çã„Äç‰∫∫„ÅØÂÖ®‰Ωì„Åß33ÔºÖ‚Äï‚ÄïNTT„Éâ„Ç≥„É¢„ÅÆ„É¢„Éê„Ç§„É´Á§æ‰ºöÁ†îÁ©∂ÊâÄ„ÅØ„ÄÅ„Åì„Çì„Å™Ë™øÊüªÁµêÊûú„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÁîüÊàêAI„Å´ÊúüÂæÖ„Åó„Å¶„ÅÑ„Çã„Å®ÂõûÁ≠î„Åó„ÅüÂâ≤Âêà„ÅØ„ÄÅ10‰ª£Áî∑ÊÄß„Åå70ÔºÖ„ÅßÊúÄ„ÇÇÈ´ò„Åè„ÄÅËã•„ÅÑÂπ¥‰ª£„ÇÑÁî∑ÊÄß„ÅÆÊñπ„ÅåÈ´ò„ÅÑÂÇæÂêë„Å´„ÅÇ„Å£„Åü„Å®„ÅÑ„ÅÜ„ÄÇ",
    "summary": "ÁîüÊàêAI„Å´„ÄåÊúüÂæÖ„Åó„Å¶„ÅÑ„Çã„Äç‰∫∫„ÅØÂÖ®‰Ωì„Åß33ÔºÖ‚Äï‚ÄïNTT„Éâ„Ç≥„É¢„ÅÆ„É¢„Éê„Ç§„É´Á§æ‰ºöÁ†îÁ©∂ÊâÄ„ÅØ„ÄÅ„Åì„Çì„Å™Ë™øÊüªÁµêÊûú„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÁîüÊàêAI„Å´ÊúüÂæÖ„Åó„Å¶„ÅÑ„Çã„Å®ÂõûÁ≠î„Åó„ÅüÂâ≤Âêà„ÅØ„ÄÅ10‰ª£Áî∑ÊÄß„Åå70ÔºÖ„ÅßÊúÄ„ÇÇÈ´ò„Åè„ÄÅËã•„ÅÑÂπ¥‰ª£„ÇÑÁî∑ÊÄß„ÅÆÊñπ„ÅåÈ´ò„ÅÑÂÇæÂêë„Å´„ÅÇ„Å£„Åü„Å®„ÅÑ„ÅÜ„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 11:50:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news068.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news068.jpg"
  },
  {
    "title": "Chat Templates: An End to the Silent Performance Killer",
    "description": "",
    "summary": "Chat Templates A spectre is haunting chat models - the spectre of incorrect formatting! tl;dr Chat m...",
    "pubDate": "Tue, 03 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chat-templates",
    "thumbnail": "https://huggingface.co/blog/assets/chat-templates/thumbnail.png"
  },
  {
    "title": "Solving (some) formal math olympiad problems",
    "description": "We built a neural theorem prover for¬†Lean¬†that learned to solve a variety of challenging high-school olympiad problems, including problems from the¬†AMC12¬†and¬†AIME¬†competitions, as well as two problems adapted from the¬†IMO.",
    "summary": "We built a neural theorem prover for¬†Lean¬†that learned to solve a variety of challenging high-school olympiad problems, including problems from the¬†AMC12¬†and¬†AIME¬†competitions, as well as two problems adapted from the¬†IMO.",
    "pubDate": "Wed, 02 Feb 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/formal-math",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI and Guardian Media Group launch content partnership",
    "description": "OpenAI and Guardian Media Group announce content partnership to bring Guardian news content to ChatGPT.",
    "summary": "OpenAI and Guardian Media Group announce content partnership to bring Guardian news content to ChatGPT.",
    "pubDate": "Fri, 14 Feb 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-guardian-media-group-launch-content-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation",
    "description": "arXiv:2507.02057v1 Announce Type: cross Abstract: Large language models (LLMs) have democratized software development, reducing the expertise barrier for programming complex applications. This accessibility extends to malicious software development, raising significant security concerns. While LLM providers have implemented alignment mechanisms to prevent direct generation of overtly malicious code, these safeguards predominantly evaluate individual prompts in isolation, overlooking a critical vulnerability: malicious operations can be systematically decomposed into benign-appearing sub-tasks. In this paper, we introduce the Malware Generation Compiler (MGC), a novel framework that leverages this vulnerability through modular decomposition and alignment-evasive generation. MGC employs a specialized Malware Description Intermediate Representation (MDIR) to bridge high-level malicious intents and benign-appearing code snippets. Extensive evaluation demonstrates that our attack reliably generates functional malware across diverse task specifications and categories, outperforming jailbreaking methods by +365.79% and underground services by +78.07% in correctness on three benchmark datasets. Case studies further show that MGC can reproduce and even enhance 16 real-world malware samples. This work provides critical insights for security researchers by exposing the risks of compositional attacks against aligned AI systems. Demonstrations are available at https://sites.google.com/view/malware-generation-compiler.",
    "summary": "arXiv:2507.02057v1 Announce Type: cross Abstract: Large language models (LLMs) have democratized software development, reducing the expertise barrier for programming complex applications. This accessibility extends to malicious software development, raising significant security concerns. While LLM providers have implemented alignment mechanisms to prevent direct generation of overtly malicious code, these safeguards predominantly evaluate individual prompts in isolation, overlooking a critical vulnerability: malicious operations can be systematically decomposed into benign-appearing sub-tasks. In this paper, we introduce the Malware Generation Compiler (MGC), a novel framework that leverages this vulnerability through modular decomposition and alignment-evasive generation. MGC employs a specialized Malware Description Intermediate Representation (MDIR) to bridge high-level malicious intents and benign-appearing code snippets. Extensive evaluation demonstrates that our attack reliably generates functional malware across diverse task specifications and categories, outperforming jailbreaking methods by +365.79% and underground services by +78.07% in correctness on three benchmark datasets. Case studies further show that MGC can reproduce and even enhance 16 real-world malware samples. This work provides critical insights for security researchers by exposing the risks of compositional attacks against aligned AI systems. Demonstrations are available at https://sites.google.com/view/malware-generation-compiler.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02057",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning Montezuma‚Äôs Revenge from a single demonstration",
    "description": "We‚Äôve trained an agent to achieve a high score of 74,500 on¬†Montezuma‚Äôs Revenge¬†from a single human demonstration, better than any previously published result. Our algorithm is simple: the agent plays a sequence of games starting from carefully chosen states from the demonstration, and learns from them by optimizing the game score using¬†PPO, the same reinforcement learning algorithm that underpins¬†OpenAI¬†Five.",
    "summary": "We‚Äôve trained an agent to achieve a high score of 74,500 on¬†Montezuma‚Äôs Revenge¬†from a single human demonstration, better than any previously published result. Our algorithm is simple: the agent plays a sequence of games starting from carefully chosen states from the demonstration, and learns from them by optimizing the game score using¬†PPO, the same reinforcement learning algorithm that underpins¬†OpenAI¬†Five.",
    "pubDate": "Wed, 04 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-montezumas-revenge-from-a-single-demonstration",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-Tune a Semantic Segmentation Model with a Custom Dataset",
    "description": "",
    "summary": "Fine-Tune a Semantic Segmentation Model with a Custom Dataset This guide shows how you can fine-tune...",
    "pubDate": "Thu, 17 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-segformer",
    "thumbnail": "https://huggingface.co/blog/assets/56_fine_tune_segformer/thumb.png"
  },
  {
    "title": "Preference Optimization for Vision Language Models",
    "description": "",
    "summary": "Preference Optimization for Vision Language Models with TRL Training models to understand and predic...",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dpo_vlm",
    "thumbnail": "https://huggingface.co/blog/assets/dpo_vlm/thumbnail.png"
  },
  {
    "title": "Accelerating LLM Inference with TGI on Intel Gaudi",
    "description": "",
    "summary": "üöÄ Accelerating LLM Inference with TGI on Intel Gaudi We're excited to announce the native integratio...",
    "pubDate": "Fri, 28 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-gaudi-backend-for-tgi",
    "thumbnail": "https://huggingface.co/blog/assets/intel-gaudi-backend-for-tgi/tgi-gaudi-thumbnail.png"
  },
  {
    "title": "Improving GANs using optimal transport",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 15 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-gans-using-optimal-transport",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FACTS Grounding: A new benchmark for evaluating the factuality of large language models",
    "description": "Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations",
    "summary": "Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations",
    "pubDate": "Tue, 17 Dec 2024 15:29:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/PNlhxhf4LKLRCezIt7Ap358F91-vbK5dLp56Ak1FejpCZh3YTp6jGqIDJm9c0iAtx8Y73MCTu279c1k2GZkM2qXXaqx315NSOaSiU0y0ATMK2c2Hyw=w1200-h630-n-nu"
  },
  {
    "title": "Improving verifiability in AI development",
    "description": "We‚Äôve contributed to a multi-stakeholder report by¬†58 co-authors¬†at 30 organizations, including the¬†Centre for the Future of Intelligence,¬†Mila,¬†Schwartz Reisman Institute for Technology and Society,¬†Center for Advanced Study in the Behavioral Sciences, and¬†Center for Security and Emerging Technologies. This report describes 10 mechanisms to improve the verifiability of claims made about AI systems. Developers can use these tools to provide evidence that AI systems are safe, secure, fair, or privacy-preserving. Users, policymakers, and civil society can use these tools to evaluate AI development¬†processes.",
    "summary": "We‚Äôve contributed to a multi-stakeholder report by¬†58 co-authors¬†at 30 organizations, including the¬†Centre for the Future of Intelligence,¬†Mila,¬†Schwartz Reisman Institute for Technology and Society,¬†Center for Advanced Study in the Behavioral Sciences, and¬†Center for Security and Emerging Technologies. This report describes 10 mechanisms to improve the verifiability of claims made about AI systems. Developers can use these tools to provide evidence that AI systems are safe, secure, fair, or privacy-preserving. Users, policymakers, and civil society can use these tools to evaluate AI development¬†processes.",
    "pubDate": "Thu, 16 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-verifiability",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LoRA training scripts of the world, unite!",
    "description": "",
    "summary": "LoRA training scripts of the world, unite! A community derived guide to some of the SOTA practices f...",
    "pubDate": "Tue, 02 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_lora_advanced_script",
    "thumbnail": "https://huggingface.co/blog/assets/dreambooth_lora_sdxl/thumbnail.png"
  },
  {
    "title": "Teaching AI models what they don‚Äôt know",
    "description": "A team of MIT researchers founded Themis AI to quantify AI model uncertainty and address knowledge gaps.",
    "summary": "A team of MIT researchers founded Themis AI to quantify AI model uncertainty and address knowledge gaps.",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/themis-ai-teaches-ai-models-what-they-dont-know-0603",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-ThemisAI-01-Press.jpg"
  },
  {
    "title": "Mapping the misuse of generative AI",
    "description": "New research analyzes the misuse of multimodal generative AI today, in order to help build safer and more responsible technologies.",
    "summary": "New research analyzes the misuse of multimodal generative AI today, in order to help build safer and more responsible technologies.",
    "pubDate": "Fri, 02 Aug 2024 10:50:58 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/mapping-the-misuse-of-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/IzYg4pdM7_tKoEbQHE4-Em9cvFxbx2Aq4_YOQdLr6VK754c8-bJRW9LWMf1_nUraA5BfNcBjAjpIjcfF1M_qQviR8b7qyRnAiUzapq3LKVbTpoJ8Cw=w1200-h630-n-nu"
  },
  {
    "title": "How can we build human values into AI?",
    "description": "Drawing from philosophy to identify fair principles for ethical AI...",
    "summary": "Drawing from philosophy to identify fair principles for ethical AI...",
    "pubDate": "Mon, 24 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/how-can-we-build-human-values-into-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/jXiO9PpMnNRhxz3kyDP97SVi5c68dQie9V4AHbH_I0Py0EJoOl0fyPhoVljUGETrNmj3BhbAEahqmsq4r-33IgLgGhsuUhN2p384-d8B_vc4asHWB6Q=w1200-h630-n-nu"
  },
  {
    "title": "Extensions and limitations of the neural GPU",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 02 Nov 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/extensions-and-limitations-of-the-neural-gpu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making thousands of open LLMs bloom in the Vertex AI Model Garden",
    "description": "",
    "summary": "Making thousands of open LLMs bloom in the Vertex AI Model Garden Today, we are thrilled to announce...",
    "pubDate": "Wed, 10 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/google-cloud-model-garden",
    "thumbnail": "https://huggingface.co/blog/assets/173_gcp-partnership/thumbnail.jpg"
  },
  {
    "title": "Êù±Âçó„Ç¢„Ç∏„Ç¢ÊúâÊï∞„ÅÆÊóÖË°å‰∫àÁ¥Ñ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„Äå„Éà„É©„Éô„É≠„Ç´„Äç„ÄÄÁ§æÈï∑„Å´ËÅû„ÅèÊó•Êú¨ÈÄ≤Âá∫„ÅÆÁãô„ÅÑ",
    "description": "Êù±Âçó„Ç¢„Ç∏„Ç¢ÊúâÊï∞„ÅÆÊóÖË°å‰∫àÁ¥Ñ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„Äå„Éà„É©„Éô„É≠„Ç´„ÄçÔºàTravelokaÔºâ„Åå2025Âπ¥Êò•„ÄÅÊó•Êú¨Â∏ÇÂ†¥„Å´ÂèÇÂÖ•„Åó„Åü„ÄÇÂêåÁ§æ„ÅÆÂº∑„Åø„Å®„ÄÅÊù±Âçó„Ç¢„Ç∏„Ç¢ÁâπÊúâ„ÅÆË¶≥ÂÖâË™≤È°å„ÅØ‰Ωï„Åã„ÄÇÂêåÁ§æ„ÅÆ„Ç∑„Éº„Ç∂„Éº„Éª„Ç§„É≥„Éâ„É©Á§æÈï∑„Å´ËÅû„ÅÑ„Åü„ÄÇ",
    "summary": "Êù±Âçó„Ç¢„Ç∏„Ç¢ÊúâÊï∞„ÅÆÊóÖË°å‰∫àÁ¥Ñ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„Äå„Éà„É©„Éô„É≠„Ç´„ÄçÔºàTravelokaÔºâ„Åå2025Âπ¥Êò•„ÄÅÊó•Êú¨Â∏ÇÂ†¥„Å´ÂèÇÂÖ•„Åó„Åü„ÄÇÂêåÁ§æ„ÅÆÂº∑„Åø„Å®„ÄÅÊù±Âçó„Ç¢„Ç∏„Ç¢ÁâπÊúâ„ÅÆË¶≥ÂÖâË™≤È°å„ÅØ‰Ωï„Åã„ÄÇÂêåÁ§æ„ÅÆ„Ç∑„Éº„Ç∂„Éº„Éª„Ç§„É≥„Éâ„É©Á§æÈï∑„Å´ËÅû„ÅÑ„Åü„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 17:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2507/03/news040.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2507/03/cover_news040.jpg"
  },
  {
    "title": "Gemma 3n fully available in the open-source ecosystem!",
    "description": "",
    "summary": "Gemma 3n fully available in the open-source ecosystem! Gemma 3n was announced as a preview during Go...",
    "pubDate": "Thu, 26 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma3n",
    "thumbnail": "https://huggingface.co/blog/assets/gemma3n/thumbnail.png"
  },
  {
    "title": "Emergence of grounded compositional language in multi-agent populations",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 15 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergence-of-grounded-compositional-language-in-multi-agent-populations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Wayfair is shaping the future of retail with AI",
    "description": "A conversation with Fiona Tan, Chief Technology Officer of Wayfair.",
    "summary": "A conversation with Fiona Tan, Chief Technology Officer of Wayfair.",
    "pubDate": "Thu, 13 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/wayfair-fiona-tan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Point3R: Streaming 3D Reconstruction with Explicit Spatial Pointer Memory",
    "description": "arXiv:2507.02863v1 Announce Type: cross Abstract: Dense 3D scene reconstruction from an ordered sequence or unordered image collections is a critical step when bringing research in computer vision into practical scenarios. Following the paradigm introduced by DUSt3R, which unifies an image pair densely into a shared coordinate system, subsequent methods maintain an implicit memory to achieve dense 3D reconstruction from more images. However, such implicit memory is limited in capacity and may suffer from information loss of earlier frames. We propose Point3R, an online framework targeting dense streaming 3D reconstruction. To be specific, we maintain an explicit spatial pointer memory directly associated with the 3D structure of the current scene. Each pointer in this memory is assigned a specific 3D position and aggregates scene information nearby in the global coordinate system into a changing spatial feature. Information extracted from the latest frame interacts explicitly with this pointer memory, enabling dense integration of the current observation into the global coordinate system. We design a 3D hierarchical position embedding to promote this interaction and design a simple yet effective fusion mechanism to ensure that our pointer memory is uniform and efficient. Our method achieves competitive or state-of-the-art performance on various tasks with low training costs. Code is available at: https://github.com/YkiWu/Point3R.",
    "summary": "arXiv:2507.02863v1 Announce Type: cross Abstract: Dense 3D scene reconstruction from an ordered sequence or unordered image collections is a critical step when bringing research in computer vision into practical scenarios. Following the paradigm introduced by DUSt3R, which unifies an image pair densely into a shared coordinate system, subsequent methods maintain an implicit memory to achieve dense 3D reconstruction from more images. However, such implicit memory is limited in capacity and may suffer from information loss of earlier frames. We propose Point3R, an online framework targeting dense streaming 3D reconstruction. To be specific, we maintain an explicit spatial pointer memory directly associated with the 3D structure of the current scene. Each pointer in this memory is assigned a specific 3D position and aggregates scene information nearby in the global coordinate system into a changing spatial feature. Information extracted from the latest frame interacts explicitly with this pointer memory, enabling dense integration of the current observation into the global coordinate system. We design a 3D hierarchical position embedding to promote this interaction and design a simple yet effective fusion mechanism to ensure that our pointer memory is uniform and efficient. Our method achieves competitive or state-of-the-art performance on various tasks with low training costs. Code is available at: https://github.com/YkiWu/Point3R.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02863",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Resolving Turbulent Magnetohydrodynamics: A Hybrid Operator-Diffusion Framework",
    "description": "arXiv:2507.02106v1 Announce Type: cross Abstract: We present a hybrid machine learning framework that combines Physics-Informed Neural Operators (PINOs) with score-based generative diffusion models to simulate the full spatio-temporal evolution of two-dimensional, incompressible, resistive magnetohydrodynamic (MHD) turbulence across a broad range of Reynolds numbers ($mathrm{Re}$). The framework leverages the equation-constrained generalization capabilities of PINOs to predict coherent, low-frequency dynamics, while a conditional diffusion model stochastically corrects high-frequency residuals, enabling accurate modeling of fully developed turbulence. Trained on a comprehensive ensemble of high-fidelity simulations with $mathrm{Re} in {100, 250, 500, 750, 1000, 3000, 10000}$, the approach achieves state-of-the-art accuracy in regimes previously inaccessible to deterministic surrogates. At $mathrm{Re}=1000$ and $3000$, the model faithfully reconstructs the full spectral energy distributions of both velocity and magnetic fields late into the simulation, capturing non-Gaussian statistics, intermittent structures, and cross-field correlations with high fidelity. At extreme turbulence levels ($mathrm{Re}=10000$), it remains the first surrogate capable of recovering the high-wavenumber evolution of the magnetic field, preserving large-scale morphology and enabling statistically meaningful predictions.",
    "summary": "arXiv:2507.02106v1 Announce Type: cross Abstract: We present a hybrid machine learning framework that combines Physics-Informed Neural Operators (PINOs) with score-based generative diffusion models to simulate the full spatio-temporal evolution of two-dimensional, incompressible, resistive magnetohydrodynamic (MHD) turbulence across a broad range of Reynolds numbers ($mathrm{Re}$). The framework leverages the equation-constrained generalization capabilities of PINOs to predict coherent, low-frequency dynamics, while a conditional diffusion model stochastically corrects high-frequency residuals, enabling accurate modeling of fully developed turbulence. Trained on a comprehensive ensemble of high-fidelity simulations with $mathrm{Re} in {100, 250, 500, 750, 1000, 3000, 10000}$, the approach achieves state-of-the-art accuracy in regimes previously inaccessible to deterministic surrogates. At $mathrm{Re}=1000$ and $3000$, the model faithfully reconstructs the full spectral energy distributions of both velocity and magnetic fields late into the simulation, capturing non-Gaussian statistics, intermittent structures, and cross-field correlations with high fidelity. At extreme turbulence levels ($mathrm{Re}=10000$), it remains the first surrogate capable of recovering the high-wavenumber evolution of the magnetic field, preserving large-scale morphology and enabling statistically meaningful predictions.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02106",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Open LLM Leaderboard: DROP deep dive",
    "description": "",
    "summary": "Open LLM Leaderboard: DROP deep dive Recently, three new benchmarks were added to the Open LLM Leade...",
    "pubDate": "Fri, 01 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-drop",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "Fuel your creativity with new generative media models and tools",
    "description": "Introducing Veo 3 and Imagen 4, and a new tool for filmmaking called Flow.",
    "summary": "Introducing Veo 3 and Imagen 4, and a new tool for filmmaking called Flow.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/fuel-your-creativity-with-new-generative-media-models-and-tools/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5.20v2_SS_1920x1080.width-1300.png"
  },
  {
    "title": "Retro Contest: Results",
    "description": "The first run of our¬†Retro Contest‚Äîexploring the development of algorithms that can generalize from previous experience‚Äîis now¬†complete.",
    "summary": "The first run of our¬†Retro Contest‚Äîexploring the development of algorithms that can generalize from previous experience‚Äîis now¬†complete.",
    "pubDate": "Fri, 22 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retro-contest-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making a web app generator with open ML models",
    "description": "",
    "summary": "Making a web app generator with open ML models As more code generation models become publicly availa...",
    "pubDate": "Mon, 03 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-to-webapp",
    "thumbnail": "https://huggingface.co/blog/assets/153_text_to_webapp/thumbnail.jpg"
  },
  {
    "title": "Serverless Inference with Hugging Face and NVIDIA NIMs",
    "description": "",
    "summary": "Serverless Inference with Hugging Face and NVIDIA NIM Update: This service is deprecated and no long...",
    "pubDate": "Mon, 29 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-dgx-cloud",
    "thumbnail": "https://huggingface.co/blog/assets/train-dgx-cloud/thumbnail.jpg"
  },
  {
    "title": "Introducing new audio and vision documentation in ü§ó Datasets",
    "description": "",
    "summary": "Introducing new audio and vision documentation in ü§ó Datasets Open and reproducible datasets are esse...",
    "pubDate": "Thu, 28 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/datasets-docs-update",
    "thumbnail": "https://huggingface.co/blog/assets/87_datasets-docs-update/thumbnail.gif"
  },
  {
    "title": "Introducing ChatGPT Gov",
    "description": "ChatGPT Gov is designed to streamline government agencies‚Äô access to OpenAI‚Äôs frontier models.",
    "summary": "ChatGPT Gov is designed to streamline government agencies‚Äô access to OpenAI‚Äôs frontier models.",
    "pubDate": "Tue, 28 Jan 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-chatgpt-gov",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-3.5 Turbo fine-tuning and API updates",
    "description": "Developers can now bring their own data to customize GPT-3.5 Turbo for their use cases.",
    "summary": "Developers can now bring their own data to customize GPT-3.5 Turbo for their use cases.",
    "pubDate": "Tue, 22 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LLM„ÅÆÊé®Ë´ñ„Å´„Åä„Åë„Çã ‚Äúaha moment‚Äù „Å´„Å§„ÅÑ„Å¶Ë™ø„Åπ„Å¶„Åø„Åü",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ÂÖàÊó•„ÄÅLLM„ÅÆ 'aha moment' „Å´Èñ¢„Åó„Å¶ËààÂë≥„ÇíÊåÅ„Å°„ÄÅÈñ¢ÈÄ£Ë´ñÊñá„ÇÑWeb‰∏ä„ÅÆË®ò‰∫ã„ÇíË™≠„Çì„Åß„Åø„Åü„Å®„Åì„Çç„ÄÅË≥õÂê¶‰∏°Ë´ñ„ÅÆÊßò„ÄÖ„Å™Ë¶ãËß£„Åå„ÅÇ„ÇäËààÂë≥Ê∑±„Åã„Å£„Åü„ÅÆ„Åß„ÄÅ‰ªäÂõû„ÅØ„Åù„ÅÆÂÜÖÂÆπ„ÇíÂÖ±Êúâ„Åó„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5766' rel='nofollow'>LLM„ÅÆÊé®Ë´ñ„Å´„Åä„Åë„Çã &#8220;aha moment&#8221; „Å´„Å§„ÅÑ„Å¶Ë™ø„Åπ„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ÂÖàÊó•„ÄÅLLM„ÅÆ 'aha moment' „Å´Èñ¢„Åó„Å¶ËààÂë≥„ÇíÊåÅ„Å°„ÄÅÈñ¢ÈÄ£Ë´ñÊñá„ÇÑWeb‰∏ä„ÅÆË®ò‰∫ã„ÇíË™≠„Çì„Åß„Åø„Åü„Å®„Åì„Çç„ÄÅË≥õÂê¶‰∏°Ë´ñ„ÅÆÊßò„ÄÖ„Å™Ë¶ãËß£„Åå„ÅÇ„ÇäËààÂë≥Ê∑±„Åã„Å£„Åü„ÅÆ„Åß„ÄÅ‰ªäÂõû„ÅØ„Åù„ÅÆÂÜÖÂÆπ„ÇíÂÖ±Êúâ„Åó„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5766' rel='nofollow'>LLM„ÅÆÊé®Ë´ñ„Å´„Åä„Åë„Çã &#8220;aha moment&#8221; „Å´„Å§„ÅÑ„Å¶Ë™ø„Åπ„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Fri, 16 May 2025 04:41:37 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5766",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/d099d886ed65ef765625779e628d2c5f.png"
  },
  {
    "title": "A research agenda for assessing the economic impacts of code generation models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/economic-impacts-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building agricultural database for farmers",
    "description": "Digital Green uses OpenAI to increase farmer income.",
    "summary": "Digital Green uses OpenAI to increase farmer income.",
    "pubDate": "Fri, 12 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/digital-green",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning to communicate",
    "description": "In this post we‚Äôll outline new OpenAI research in which agents develop their own language.",
    "summary": "In this post we‚Äôll outline new OpenAI research in which agents develop their own language.",
    "pubDate": "Thu, 16 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-communicate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeRobot Community Datasets: The ‚ÄúImageNet‚Äù of Robotics ‚Äî When and How?",
    "description": "",
    "summary": "LeRobot Community Datasets: The ‚ÄúImageNet‚Äù of Robotics ‚Äî When and How? üß≠ TL;DR ‚Äî Why This Blogpost? ...",
    "pubDate": "Sun, 11 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lerobot-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/195_lerobot_datasets/1.png"
  },
  {
    "title": "OpenAI partners with Schibsted Media Group",
    "description": "OpenAI and Schibsted Media Group announce content partnership to bring Guardian news and archive content to  ChatGPT.",
    "summary": "OpenAI and Schibsted Media Group announce content partnership to bring Guardian news and archive content to  ChatGPT.",
    "pubDate": "Mon, 10 Feb 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-partners-with-schibsted-media-group",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing The World's Largest Open Multilingual Language Model: BLOOM",
    "description": "",
    "summary": "üå∏ Introducing The World's Largest Open Multilingual Language Model: BLOOM üå∏ Large language models (L...",
    "pubDate": "Tue, 12 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom",
    "thumbnail": "https://huggingface.co/blog/assets/86_bloom/thumbnail.png"
  },
  {
    "title": "Red grape detection with accelerated artificial neural networks in the FPGA's programmable logic",
    "description": "arXiv:2507.02443v1 Announce Type: cross Abstract: Robots usually slow down for canning to detect objects while moving. Additionally, the robot's camera is configured with a low framerate to track the velocity of the detection algorithms. This would be constrained while executing tasks and exploring, making robots increase the task execution time. AMD has developed the Vitis-AI framework to deploy detection algorithms into FPGAs. However, this tool does not fully use the FPGAs' PL. In this work, we use the FINN architecture to deploy three ANNs, MobileNet v1 with 4-bit quantisation, CNV with 2-bit quantisation, and CNV with 1-bit quantisation (BNN), inside an FPGA's PL. The models were trained on the RG2C dataset. This is a self-acquired dataset released in open access. MobileNet v1 performed better, reaching a success rate of 98 % and an inference speed of 6611 FPS. In this work, we proved that we can use FPGAs to speed up ANNs and make them suitable for attention mechanisms.",
    "summary": "arXiv:2507.02443v1 Announce Type: cross Abstract: Robots usually slow down for canning to detect objects while moving. Additionally, the robot's camera is configured with a low framerate to track the velocity of the detection algorithms. This would be constrained while executing tasks and exploring, making robots increase the task execution time. AMD has developed the Vitis-AI framework to deploy detection algorithms into FPGAs. However, this tool does not fully use the FPGAs' PL. In this work, we use the FINN architecture to deploy three ANNs, MobileNet v1 with 4-bit quantisation, CNV with 2-bit quantisation, and CNV with 1-bit quantisation (BNN), inside an FPGA's PL. The models were trained on the RG2C dataset. This is a self-acquired dataset released in open access. MobileNet v1 performed better, reaching a success rate of 98 % and an inference speed of 6611 FPS. In this work, we proved that we can use FPGAs to speed up ANNs and make them suitable for attention mechanisms.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02443",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLM Inference on Edge: A Fun and Easy Guide to run LLMs via React Native on your Phone!",
    "description": "",
    "summary": "LLM Inference on Edge: A Fun and Easy Guide to run LLMs via React Native on your Phone! As LLMs cont...",
    "pubDate": "Fri, 07 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llm-inference-on-edge",
    "thumbnail": "https://huggingface.co/blog/assets/llm_inference_on_edge/thumbnail.png"
  },
  {
    "title": "Dota 2",
    "description": "We‚Äôve created a bot which beats the world‚Äôs top professionals at 1v1 matches of Dota 2 under standard tournament rules. The bot learned the game from scratch by self-play, and does not use imitation learning or tree search. This is a step towards building AI systems which accomplish well-defined goals in messy, complicated situations involving real humans.",
    "summary": "We‚Äôve created a bot which beats the world‚Äôs top professionals at 1v1 matches of Dota 2 under standard tournament rules. The bot learned the game from scratch by self-play, and does not use imitation learning or tree search. This is a step towards building AI systems which accomplish well-defined goals in messy, complicated situations involving real humans.",
    "pubDate": "Fri, 11 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dota-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Snowball Fight ‚òÉÔ∏è, our First ML-Agents Environment",
    "description": "",
    "summary": "Introducing Snowball Fight ‚òÉÔ∏è, our First ML-Agents Environment We're excited to share our first cust...",
    "pubDate": "Thu, 02 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/snowball-fight",
    "thumbnail": "https://huggingface.co/blog/assets/39_introducing_snowball_fight/thumbnail.png"
  },
  {
    "title": "Generating Large Semi-Synthetic Graphs of Any Size",
    "description": "arXiv:2507.02166v1 Announce Type: cross Abstract: Graph generation is an important area in network science. Traditional approaches focus on replicating specific properties of real-world graphs, such as small diameters or power-law degree distributions. Recent advancements in deep learning, particularly with Graph Neural Networks, have enabled data-driven methods to learn and generate graphs without relying on predefined structural properties. Despite these advances, current models are limited by their reliance on node IDs, which restricts their ability to generate graphs larger than the input graph and ignores node attributes. To address these challenges, we propose Latent Graph Sampling Generation (LGSG), a novel framework that leverages diffusion models and node embeddings to generate graphs of varying sizes without retraining. The framework eliminates the dependency on node IDs and captures the distribution of node embeddings and subgraph structures, enabling scalable and flexible graph generation. Experimental results show that LGSG performs on par with baseline models for standard metrics while outperforming them in overlooked ones, such as the tendency of nodes to form clusters. Additionally, it maintains consistent structural characteristics across graphs of different sizes, demonstrating robustness and scalability.",
    "summary": "arXiv:2507.02166v1 Announce Type: cross Abstract: Graph generation is an important area in network science. Traditional approaches focus on replicating specific properties of real-world graphs, such as small diameters or power-law degree distributions. Recent advancements in deep learning, particularly with Graph Neural Networks, have enabled data-driven methods to learn and generate graphs without relying on predefined structural properties. Despite these advances, current models are limited by their reliance on node IDs, which restricts their ability to generate graphs larger than the input graph and ignores node attributes. To address these challenges, we propose Latent Graph Sampling Generation (LGSG), a novel framework that leverages diffusion models and node embeddings to generate graphs of varying sizes without retraining. The framework eliminates the dependency on node IDs and captures the distribution of node embeddings and subgraph structures, enabling scalable and flexible graph generation. Experimental results show that LGSG performs on par with baseline models for standard metrics while outperforming them in overlooked ones, such as the tendency of nodes to form clusters. Additionally, it maintains consistent structural characteristics across graphs of different sizes, demonstrating robustness and scalability.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02166",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Forecasting Labor Markets with LSTNet: A Multi-Scale Deep Learning Approach",
    "description": "arXiv:2507.01979v1 Announce Type: cross Abstract: We present a deep learning approach for forecasting short-term employment changes and assessing long-term industry health using labor market data from the U.S. Bureau of Labor Statistics. Our system leverages a Long- and Short-Term Time-series Network (LSTNet) to process multivariate time series data, including employment levels, wages, turnover rates, and job openings. The model outputs both 7-day employment forecasts and an interpretable Industry Employment Health Index (IEHI). Our approach outperforms baseline models across most sectors, particularly in stable industries, and demonstrates strong alignment between IEHI rankings and actual employment volatility. We discuss error patterns, sector-specific performance, and future directions for improving interpretability and generalization.",
    "summary": "arXiv:2507.01979v1 Announce Type: cross Abstract: We present a deep learning approach for forecasting short-term employment changes and assessing long-term industry health using labor market data from the U.S. Bureau of Labor Statistics. Our system leverages a Long- and Short-Term Time-series Network (LSTNet) to process multivariate time series data, including employment levels, wages, turnover rates, and job openings. The model outputs both 7-day employment forecasts and an interpretable Industry Employment Health Index (IEHI). Our approach outperforms baseline models across most sectors, particularly in stable industries, and demonstrates strong alignment between IEHI rankings and actual employment volatility. We discuss error patterns, sector-specific performance, and future directions for improving interpretability and generalization.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01979",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DALL¬∑E 3 system card",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 03 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-3-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Novel method detects microbial contamination in cell cultures",
    "description": "Ultraviolet light ‚Äúfingerprints‚Äù on cell cultures and machine learning can provide a definitive yes/no contamination assessment within 30 minutes.",
    "summary": "Ultraviolet light ‚Äúfingerprints‚Äù on cell cultures and machine learning can provide a definitive yes/no contamination assessment within 30 minutes.",
    "pubDate": "Fri, 25 Apr 2025 22:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/novel-method-detects-microbial-contamination-smart-0425",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/SMART-CAMP-Senior-Research-Engineer.jpg"
  },
  {
    "title": "Gradio joins Hugging Face!",
    "description": "",
    "summary": "Gradio is joining Hugging Face! Gradio is joining Hugging Face! By acquiring Gradio, a machine learn...",
    "pubDate": "Tue, 21 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-joins-hf",
    "thumbnail": "https://huggingface.co/blog/assets/42_gradio_joins_hf/thumbnail.png"
  },
  {
    "title": "Retrieval Augmented Generation with Huggingface Transformers and Ray",
    "description": "",
    "summary": "Retrieval Augmented Generation with Huggingface Transformers and Ray A guest blog post by Amog Kamse...",
    "pubDate": "Wed, 10 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ray-rag",
    "thumbnail": "https://huggingface.co/blog/assets/12_ray_rag/ray_arch_updated.png"
  },
  {
    "title": "OpenAI appoints Retired U.S. Army General Paul M. Nakasone to Board of Directors",
    "description": "Nakasone brings cybersecurity experience to growing Board of Directors; will join the Board‚Äôs Safety and Security Committee",
    "summary": "Nakasone brings cybersecurity experience to growing Board of Directors; will join the Board‚Äôs Safety and Security Committee",
    "pubDate": "Thu, 13 Jun 2024 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-appoints-retired-us-army-general",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2020: Applications open",
    "description": "We are now accepting applications for our third class of OpenAI Scholars.",
    "summary": "We are now accepting applications for our third class of OpenAI Scholars.",
    "pubDate": "Fri, 11 Oct 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2020",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Supercharged Customer Service with Machine Learning",
    "description": "",
    "summary": "Supercharged Customer Service with Machine Learning In this blog post, we will simulate a real-world...",
    "pubDate": "Mon, 25 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/supercharge-customer-service-with-machine-learning",
    "thumbnail": "https://huggingface.co/blog/assets/61_supercharged_customer_service_with_nlp/thumbnail.png"
  },
  {
    "title": "Team update",
    "description": "We‚Äôd like to welcome the latest set of team members to OpenAI (and we‚Äôre still hiring!)",
    "summary": "We‚Äôd like to welcome the latest set of team members to OpenAI (and we‚Äôre still hiring!)",
    "pubDate": "Wed, 25 May 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Safety Gym",
    "description": "We‚Äôre releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while¬†training.",
    "summary": "We‚Äôre releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while¬†training.",
    "pubDate": "Thu, 21 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/safety-gym",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning",
    "description": "arXiv:2507.02211v1 Announce Type: new Abstract: Recent studies in the spatial prisoner's dilemma games with reinforcement learning have shown that static agents can learn to cooperate through a diverse sort of mechanisms, including noise injection, different types of learning algorithms and neighbours' payoff knowledge.In this work, using an independent multi-agent Q-learning algorithm, we study the effects of dilution and mobility in the spatial version of the prisoner's dilemma. Within this setting, different possible actions for the algorithm are defined, connecting with previous results on the classical, non-reinforcement learning spatial prisoner's dilemma, showcasing the versatility of the algorithm in modeling different game-theoretical scenarios and the benchmarking potential of this approach.As a result, a range of effects is observed, including evidence that games with fixed update rules can be qualitatively equivalent to those with learned ones, as well as the emergence of a symbiotic mutualistic effect between populations that forms when multiple actions are defined.",
    "summary": "arXiv:2507.02211v1 Announce Type: new Abstract: Recent studies in the spatial prisoner's dilemma games with reinforcement learning have shown that static agents can learn to cooperate through a diverse sort of mechanisms, including noise injection, different types of learning algorithms and neighbours' payoff knowledge.In this work, using an independent multi-agent Q-learning algorithm, we study the effects of dilution and mobility in the spatial version of the prisoner's dilemma. Within this setting, different possible actions for the algorithm are defined, connecting with previous results on the classical, non-reinforcement learning spatial prisoner's dilemma, showcasing the versatility of the algorithm in modeling different game-theoretical scenarios and the benchmarking potential of this approach.As a result, a range of effects is observed, including evidence that games with fixed update rules can be qualitatively equivalent to those with learned ones, as well as the emergence of a symbiotic mutualistic effect between populations that forms when multiple actions are defined.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02211",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "KV Cache from scratch in nanoVLM",
    "description": "",
    "summary": "KV Cache from scratch in nanoVLM TL;DR We have implemented KV Caching from scratch in our nanoVLM re...",
    "pubDate": "Wed, 04 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kv-cache",
    "thumbnail": "https://huggingface.co/blog/assets/kv-cache/thumbnail.png"
  },
  {
    "title": "Graphcore and Hugging Face Launch New Lineup of IPU-Ready Transformers",
    "description": "",
    "summary": "Graphcore and Hugging Face Launch New Lineup of IPU-Ready Transformers Graphcore and Hugging Face ha...",
    "pubDate": "Thu, 26 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore-update",
    "thumbnail": "https://huggingface.co/blog/assets/77_graphcore-update/graphcore_update.png"
  },
  {
    "title": "Fast Inference on Large Language Models: BLOOMZ on Habana Gaudi2 Accelerator",
    "description": "",
    "summary": "Fast Inference on Large Language Models: BLOOMZ on Habana Gaudi2 Accelerator This article will show ...",
    "pubDate": "Tue, 28 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana-gaudi-2-bloom",
    "thumbnail": "https://huggingface.co/blog/assets/habana-gaudi-2-bloom/thumbnail.png"
  },
  {
    "title": "My Journey to a serverless transformers pipeline on Google Cloud",
    "description": "",
    "summary": "My Journey to a serverless transformers pipeline on Google Cloud A guest blog post by community memb...",
    "pubDate": "Thu, 18 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-deploy-a-pipeline-to-google-clouds",
    "thumbnail": "https://huggingface.co/blog/assets/14_how_to_deploy_a_pipeline_to_google_clouds/thumbnail.png"
  },
  {
    "title": "Hugging Face's TensorFlow Philosophy",
    "description": "",
    "summary": "Hugging Face's TensorFlow Philosophy Introduction Despite increasing competition from PyTorch and JA...",
    "pubDate": "Fri, 12 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tensorflow-philosophy",
    "thumbnail": "https://huggingface.co/blog/assets/96_tensorflow_philosophy/thumbnail.png"
  },
  {
    "title": "Customizing GPT-3 for your application",
    "description": "Fine-tune with a single¬†command.",
    "summary": "Fine-tune with a single¬†command.",
    "pubDate": "Tue, 14 Dec 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/customizing-gpt-3",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Build AI on premise with Dell Enterprise Hub",
    "description": "",
    "summary": "Build AI on premise with Dell Enterprise Hub Today we announce the Dell Enterprise Hub, a new experi...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dell-enterprise-hub",
    "thumbnail": "https://huggingface.co/blog/assets/dell-enterprise-hub/thumbnail.jpg"
  },
  {
    "title": "Introducing ChatGPT Pro",
    "description": "Broadening usage of frontier AI",
    "summary": "Broadening usage of frontier AI",
    "pubDate": "Thu, 05 Dec 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-pro",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evolution strategies as a scalable alternative to reinforcement learning",
    "description": "We‚Äôve discovered that evolution strategies (ES), an optimization technique that‚Äôs been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks (e.g. Atari/MuJoCo), while overcoming many of RL‚Äôs inconveniences.",
    "summary": "We‚Äôve discovered that evolution strategies (ES), an optimization technique that‚Äôs been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks (e.g. Atari/MuJoCo), while overcoming many of RL‚Äôs inconveniences.",
    "pubDate": "Fri, 24 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolution-strategies",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and JFrog partner to make AI Security more transparent",
    "description": "",
    "summary": "Hugging Face and JFrog partner to make AI Security more transparent We are pleased to announce our p...",
    "pubDate": "Tue, 04 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/jfrog",
    "thumbnail": "https://huggingface.co/blog/assets/jfrog/thumbnail.png"
  },
  {
    "title": "Introducing DOI: the Digital Object Identifier to Datasets and Models",
    "description": "",
    "summary": "Introducing DOI: the Digital Object Identifier to Datasets and Models Our mission at Hugging Face is...",
    "pubDate": "Fri, 07 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-doi",
    "thumbnail": "https://huggingface.co/blog/assets/107_launching_doi/thumbnail.jpeg"
  },
  {
    "title": "E2EÈü≥Â£∞ÂØæË©±API„ÉªÊßãÁØâ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÊúÄÊñ∞ÂãïÂêë„ÅÆË™øÊüª„Å®Ëá™ÂæãÂûãÈü≥Â£∞ÂØæË©±„Ç∑„Çπ„ÉÜ„É†„ÅÆÂ±ïÊúõ",
    "description": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ ËøëÂπ¥„ÄÅÈü≥Â£∞ÂØæË©±„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆÈÄ≤Âåñ„ÅåÁõÆË¶ö„Åæ„Åó„Åè„ÄÅÈ°ßÂÆ¢ÂØæÂøú„ÅÆËá™ÂãïÂåñ„ÇÑÊ•≠ÂãôÂäπÁéáÂåñ„Å∏„ÅÆÊúüÂæÖ„ÅåÈ´ò„Åæ„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇÂºäÁ§æ„ÅÆAI Messenger Voicebot„ÇÇ‰æãÂ§ñ„Åß„ÅØ„Å™„Åè„ÄÅÊúÄÂÖàÁ´Ø [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5852' rel='nofollow'>E2EÈü≥Â£∞ÂØæË©±API„ÉªÊßãÁØâ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÊúÄÊñ∞ÂãïÂêë„ÅÆË™øÊüª„Å®Ëá™ÂæãÂûãÈü≥Â£∞ÂØæË©±„Ç∑„Çπ„ÉÜ„É†„ÅÆÂ±ïÊúõ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ ËøëÂπ¥„ÄÅÈü≥Â£∞ÂØæË©±„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆÈÄ≤Âåñ„ÅåÁõÆË¶ö„Åæ„Åó„Åè„ÄÅÈ°ßÂÆ¢ÂØæÂøú„ÅÆËá™ÂãïÂåñ„ÇÑÊ•≠ÂãôÂäπÁéáÂåñ„Å∏„ÅÆÊúüÂæÖ„ÅåÈ´ò„Åæ„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇÂºäÁ§æ„ÅÆAI Messenger Voicebot„ÇÇ‰æãÂ§ñ„Åß„ÅØ„Å™„Åè„ÄÅÊúÄÂÖàÁ´Ø [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5852' rel='nofollow'>E2EÈü≥Â£∞ÂØæË©±API„ÉªÊßãÁØâ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÊúÄÊñ∞ÂãïÂêë„ÅÆË™øÊüª„Å®Ëá™ÂæãÂûãÈü≥Â£∞ÂØæË©±„Ç∑„Çπ„ÉÜ„É†„ÅÆÂ±ïÊúõ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Fri, 30 May 2025 01:38:01 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5852",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/icon.png"
  },
  {
    "title": "WebGPT: Improving the factual accuracy of language models through web browsing",
    "description": "We‚Äôve fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.",
    "summary": "We‚Äôve fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.",
    "pubDate": "Thu, 16 Dec 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/webgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Leveraging Hugging Face for complex generative AI use cases",
    "description": "",
    "summary": "Leveraging Hugging Face for complex generative AI use casess Published July 1, 2023 Update on GitHub...",
    "pubDate": "Sat, 01 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/writer-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/writer.png"
  },
  {
    "title": "Introducing Stargate UAE",
    "description": "We‚Äôre launching Stargate UAE ‚Äì the first international deployment of Stargate, OpenAI‚Äôs AI infrastructure platform.",
    "summary": "We‚Äôre launching Stargate UAE ‚Äì the first international deployment of Stargate, OpenAI‚Äôs AI infrastructure platform.",
    "pubDate": "Thu, 22 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-stargate-uae",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DABStep: Data Agent Benchmark for Multi-step Reasoning",
    "description": "",
    "summary": "DABStep: Data Agent Benchmark for Multi-step Reasoning Language models are becoming increasingly cap...",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dabstep",
    "thumbnail": "https://huggingface.co/blog/assets/dabstep/thumbnail.png"
  },
  {
    "title": "Gradio-Lite: Serverless Gradio Running Entirely in Your Browser",
    "description": "",
    "summary": "Gradio-Lite: Serverless Gradio Running Entirely in Your Browser Gradio is a popular Python library f...",
    "pubDate": "Thu, 19 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-lite",
    "thumbnail": "https://huggingface.co/blog/assets/167_gradio_lite/thumbnail.png"
  },
  {
    "title": "Introducing Three New Serverless Inference Providers: Hyperbolic, Nebius AI Studio, and Novita üî•",
    "description": "",
    "summary": "Introducing Three New Serverless Inference Providers: Hyperbolic, Nebius AI Studio, and Novita üî• We‚Äô...",
    "pubDate": "Tue, 18 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-nebius-novita-hyperbolic",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/second-batch-thumbnail.webp"
  },
  {
    "title": "AI stirs up the recipe for concrete in MIT study",
    "description": "With demand for cement alternatives rising, an MIT team uses machine learning to hunt for new ingredients across the scientific literature.",
    "summary": "With demand for cement alternatives rising, an MIT team uses machine learning to hunt for new ingredients across the scientific literature.",
    "pubDate": "Mon, 02 Jun 2025 15:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-stirs-recipe-for-concrete-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Soroush-Mahjoubi.jpg"
  },
  {
    "title": "Introducing the Synthetic Data Generator - Build Datasets with Natural Language",
    "description": "",
    "summary": "Introducing the Synthetic Data Generator - Build Datasets with Natural Language Introducing the Synt...",
    "pubDate": "Mon, 16 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthetic-data-generator",
    "thumbnail": "https://huggingface.co/blog/assets/synthetic-data-generator/_thumbnail.png"
  },
  {
    "title": "„ÄåAI SHIFT SUMMIT 2025„Äç„É¨„Éù„Éº„Éà‚îÄ‰ºÅÊ•≠„ÅÆÊúÄÂâçÁ∑ö„Å´Ë¶ã„ÇãAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÆüË£Ö„ÅÆ‰ªä",
    "description": "<p>2025Âπ¥„ÅØ„ÄåAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÖÉÂπ¥„Äç„Å®„ÇÇÂëº„Å∞„Çå„ÄÅËá™ÂæãÂûãAI„ÅÆÁ§æ‰ºöÂÆüË£Ö„Å´Ê≥®ÁõÆ„ÅåÈõÜ„Åæ„ÇãÂπ¥„Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„ÅÜ„Åó„ÅüÊΩÆÊµÅ„ÅÆ‰∏≠„ÄÅÊ†™Âºè‰ºöÁ§æAI Shift‰∏ªÂÇ¨„ÅßÈñãÂÇ¨„Åï„Çå„Åü„ÄåAI SHIFT SUMMIT 2025„Äç„Åß„ÅØ„ÄÅMicros [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ai-shift-summit-2025-ai-agent/'>„ÄåAI SHIFT SUMMIT 2025„Äç„É¨„Éù„Éº„Éà‚îÄ‰ºÅÊ•≠„ÅÆÊúÄÂâçÁ∑ö„Å´Ë¶ã„ÇãAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÆüË£Ö„ÅÆ‰ªä</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>2025Âπ¥„ÅØ„ÄåAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÖÉÂπ¥„Äç„Å®„ÇÇÂëº„Å∞„Çå„ÄÅËá™ÂæãÂûãAI„ÅÆÁ§æ‰ºöÂÆüË£Ö„Å´Ê≥®ÁõÆ„ÅåÈõÜ„Åæ„ÇãÂπ¥„Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„ÅÜ„Åó„ÅüÊΩÆÊµÅ„ÅÆ‰∏≠„ÄÅÊ†™Âºè‰ºöÁ§æAI Shift‰∏ªÂÇ¨„ÅßÈñãÂÇ¨„Åï„Çå„Åü„ÄåAI SHIFT SUMMIT 2025„Äç„Åß„ÅØ„ÄÅMicros [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ai-shift-summit-2025-ai-agent/'>„ÄåAI SHIFT SUMMIT 2025„Äç„É¨„Éù„Éº„Éà‚îÄ‰ºÅÊ•≠„ÅÆÊúÄÂâçÁ∑ö„Å´Ë¶ã„ÇãAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÆüË£Ö„ÅÆ‰ªä</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Tue, 01 Jul 2025 01:24:49 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/ai-shift-summit-2025-ai-agent/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/main-1.png"
  },
  {
    "title": "Competitive self-play",
    "description": "We‚Äôve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind. Self-play ensures that the environment is always the right difficulty for an AI to improve. Taken alongside our Dota 2 self-play results, we have increasing confidence that self-play will be a core part of powerful AI systems in the future.",
    "summary": "We‚Äôve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind. Self-play ensures that the environment is always the right difficulty for an AI to improve. Taken alongside our Dota 2 self-play results, we have increasing confidence that self-play will be a core part of powerful AI systems in the future.",
    "pubDate": "Wed, 11 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/competitive-self-play",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Creating a Coding Assistant with StarCoder",
    "description": "",
    "summary": "Creating a Coding Assistant with StarCoder If you‚Äôre a software developer, chances are that you‚Äôve u...",
    "pubDate": "Tue, 09 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starchat-alpha",
    "thumbnail": "https://huggingface.co/blog/assets/starchat_alpha/thumbnail.png"
  },
  {
    "title": "Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models",
    "description": "arXiv:2501.12370v3 Announce Type: replace-cross Abstract: Scaling the capacity of language models has consistently proven to be a reliable approach for improving performance and unlocking new capabilities. Capacity can be primarily defined by two dimensions: the number of model parameters and the compute per example. While scaling typically involves increasing both, the precise interplay between these factors and their combined contribution to overall capacity remains not fully understood. We explore this relationship in the context of sparse Mixture-of-Experts (MoEs), which allow scaling the number of parameters without proportionally increasing the FLOPs per example. We investigate how varying the sparsity level, i.e., the fraction of inactive parameters, impacts model's performance during pretraining and downstream few-shot evaluation. We find that under different constraints (e.g., parameter size and total training compute), there is an optimal level of sparsity that improves both training efficiency and model performance. These results provide a better understanding of the impact of sparsity in scaling laws for MoEs and complement existing works in this area, offering insights for designing more efficient architectures.",
    "summary": "arXiv:2501.12370v3 Announce Type: replace-cross Abstract: Scaling the capacity of language models has consistently proven to be a reliable approach for improving performance and unlocking new capabilities. Capacity can be primarily defined by two dimensions: the number of model parameters and the compute per example. While scaling typically involves increasing both, the precise interplay between these factors and their combined contribution to overall capacity remains not fully understood. We explore this relationship in the context of sparse Mixture-of-Experts (MoEs), which allow scaling the number of parameters without proportionally increasing the FLOPs per example. We investigate how varying the sparsity level, i.e., the fraction of inactive parameters, impacts model's performance during pretraining and downstream few-shot evaluation. We find that under different constraints (e.g., parameter size and total training compute), there is an optimal level of sparsity that improves both training efficiency and model performance. These results provide a better understanding of the impact of sparsity in scaling laws for MoEs and complement existing works in this area, offering insights for designing more efficient architectures.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.12370",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Millions of new materials discovered with deep learning",
    "description": "We share the discovery of 2.2 million new crystals  ‚Äì  equivalent to nearly 800 years‚Äô worth of knowledge. We introduce Graph Networks for Materials Exploration (GNoME), our new deep learning tool that dramatically increases the speed and efficiency of discovery by predicting the stability of new materials.",
    "summary": "We share the discovery of 2.2 million new crystals  ‚Äì  equivalent to nearly 800 years‚Äô worth of knowledge. We introduce Graph Networks for Materials Exploration (GNoME), our new deep learning tool that dramatically increases the speed and efficiency of discovery by predicting the stability of new materials.",
    "pubDate": "Wed, 29 Nov 2023 16:04:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/",
    "thumbnail": "https://lh3.googleusercontent.com/mq3mFiVHSVuszhJMt-Nz4jckN5qy3cAckEIdNYDPhy8UHjxk4VkGFriqo8sA76teioNQ2fC3qgMH7FJfPc0L5JJPppXiZzHP7Rl3UodlU4IC4TWw=w1200-h630-n-nu"
  },
  {
    "title": "Scaling AI-based Data Processing with Hugging Face + Dask",
    "description": "",
    "summary": "Scaling AI-Based Data Processing with Hugging Face + Dask The Hugging Face platform has many dataset...",
    "pubDate": "Wed, 09 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dask-scaling",
    "thumbnail": "https://huggingface.co/blog/assets/dask-scaling/thumbnail.png"
  },
  {
    "title": "Accelerate 1.0.0",
    "description": "",
    "summary": "Accelerate 1.0.0 What is Accelerate today? 3.5 years ago, Accelerate was a simple framework aimed at...",
    "pubDate": "Fri, 13 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-v1",
    "thumbnail": "https://huggingface.co/blog/assets/186_accelerate_v1/accelerate_v1_thumbnail.png"
  },
  {
    "title": "The Illusion of Fairness: Auditing Fairness Interventions with Audit Studies",
    "description": "arXiv:2507.02152v1 Announce Type: new Abstract: Artificial intelligence systems, especially those using machine learning, are being deployed in domains from hiring to loan issuance in order to automate these complex decisions. Judging both the effectiveness and fairness of these AI systems, and their human decision making counterpart, is a complex and important topic studied across both computational and social sciences. Within machine learning, a common way to address bias in downstream classifiers is to resample the training data to offset disparities. For example, if hiring rates vary by some protected class, then one may equalize the rate within the training set to alleviate bias in the resulting classifier. While simple and seemingly effective, these methods have typically only been evaluated using data obtained through convenience samples, introducing selection bias and label bias into metrics. Within the social sciences, psychology, public health, and medicine, audit studies, in which fictitious ``testers'' (e.g., resumes, emails, patient actors) are sent to subjects (e.g., job openings, businesses, doctors) in randomized control trials, provide high quality data that support rigorous estimates of discrimination. In this paper, we investigate how data from audit studies can be used to improve our ability to both train and evaluate automated hiring algorithms. We find that such data reveals cases where the common fairness intervention method of equalizing base rates across classes appears to achieve parity using traditional measures, but in fact has roughly 10% disparity when measured appropriately. We additionally introduce interventions based on individual treatment effect estimation methods that further reduce algorithmic discrimination using this data.",
    "summary": "arXiv:2507.02152v1 Announce Type: new Abstract: Artificial intelligence systems, especially those using machine learning, are being deployed in domains from hiring to loan issuance in order to automate these complex decisions. Judging both the effectiveness and fairness of these AI systems, and their human decision making counterpart, is a complex and important topic studied across both computational and social sciences. Within machine learning, a common way to address bias in downstream classifiers is to resample the training data to offset disparities. For example, if hiring rates vary by some protected class, then one may equalize the rate within the training set to alleviate bias in the resulting classifier. While simple and seemingly effective, these methods have typically only been evaluated using data obtained through convenience samples, introducing selection bias and label bias into metrics. Within the social sciences, psychology, public health, and medicine, audit studies, in which fictitious ``testers'' (e.g., resumes, emails, patient actors) are sent to subjects (e.g., job openings, businesses, doctors) in randomized control trials, provide high quality data that support rigorous estimates of discrimination. In this paper, we investigate how data from audit studies can be used to improve our ability to both train and evaluate automated hiring algorithms. We find that such data reveals cases where the common fairness intervention method of equalizing base rates across classes appears to achieve parity using traditional measures, but in fact has roughly 10% disparity when measured appropriately. We additionally introduce interventions based on individual treatment effect estimation methods that further reduce algorithmic discrimination using this data.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02152",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SAP„ÅÆ„Äå2027Âπ¥ÂïèÈ°å„Äç„ÄÅ„É°„É´„Çª„Éá„Çπ„Éª„Éô„É≥„ÉÑ„Éª„Ç∞„É´„Éº„Éó„ÅØ„Å©„ÅÜËß£Ê±∫„Åó„ÅüÔºü„Äê‰∫ã‰æãÁ¥π‰ªã„Äë",
    "description": "„Ç™„É≥„Éó„É¨„Éü„ÇπÁí∞Â¢É„ÅßERP„ÇíÈÅãÁî®„Åó„Å¶„Åç„Åü„É¶„Éº„Ç∂„Éº„ÅØ„ÄÅ„ÄåSAP„ÅÆ2027Âπ¥ÂïèÈ°å„Äç„Å´„Å©„ÅÜÁ´ã„Å°Âêë„Åã„ÅÜ„Åã„ÄÇ„Éì„Ç∏„Éç„ÇπÁí∞Â¢É„ÅÆÂÖàË°å„Åç‰∏çÈÄèÊòéÊÑü„ÅåÂº∑„Åæ„Çã‰∏≠„Åß„ÄÅÂ§âÂåñ„Å´ËøÖÈÄü„Å´ÂØæÂøú„Åô„Çã„Åü„ÇÅ„ÅÆITÂü∫Áõ§„ÅÆÂÆüÁèæ„ÇÑAI„ÅÆÊ¥ªÁî®„ÅåÂñ´Á∑ä„ÅÆË™≤È°å„Å´„Å™„Çã‰∏≠„ÄÅ„É°„É´„Çª„Éá„Çπ„Éª„Éô„É≥„ÉÑ„Éª„Ç∞„É´„Éº„Éó„ÅÆÂèñ„ÇäÁµÑ„Åø„ÇíÁ¥π‰ªã„Åô„Çã„ÄÇ",
    "summary": "„Ç™„É≥„Éó„É¨„Éü„ÇπÁí∞Â¢É„ÅßERP„ÇíÈÅãÁî®„Åó„Å¶„Åç„Åü„É¶„Éº„Ç∂„Éº„ÅØ„ÄÅ„ÄåSAP„ÅÆ2027Âπ¥ÂïèÈ°å„Äç„Å´„Å©„ÅÜÁ´ã„Å°Âêë„Åã„ÅÜ„Åã„ÄÇ„Éì„Ç∏„Éç„ÇπÁí∞Â¢É„ÅÆÂÖàË°å„Åç‰∏çÈÄèÊòéÊÑü„ÅåÂº∑„Åæ„Çã‰∏≠„Åß„ÄÅÂ§âÂåñ„Å´ËøÖÈÄü„Å´ÂØæÂøú„Åô„Çã„Åü„ÇÅ„ÅÆITÂü∫Áõ§„ÅÆÂÆüÁèæ„ÇÑAI„ÅÆÊ¥ªÁî®„ÅåÂñ´Á∑ä„ÅÆË™≤È°å„Å´„Å™„Çã‰∏≠„ÄÅ„É°„É´„Çª„Éá„Çπ„Éª„Éô„É≥„ÉÑ„Éª„Ç∞„É´„Éº„Éó„ÅÆÂèñ„ÇäÁµÑ„Åø„ÇíÁ¥π‰ªã„Åô„Çã„ÄÇ",
    "pubDate": "Fri, 04 Jul 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2507/04/news019.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2507/04/cover_news019.jpg"
  },
  {
    "title": "WWDC 24: Running Mistral 7B with Core ML",
    "description": "",
    "summary": "WWDC 24: Running Mistral 7B with Core ML WWDC‚Äô 24 is the moment Apple officially unveiled Apple Inte...",
    "pubDate": "Mon, 22 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mistral-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/mistral-coreml/thumbnail.png"
  },
  {
    "title": "Director of Machine Learning Insights [Series]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 1] Few seats at the Machine Learning table span both tec...",
    "pubDate": "Wed, 27 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights",
    "thumbnail": "https://huggingface.co/blog/assets/61_ml_director_insights/thumbnail.png"
  },
  {
    "title": "Improving Prompt Consistency with Structured Generations",
    "description": "",
    "summary": "Improving Prompt Consistency with Structured Generations Recently, the Leaderboards and Evals resear...",
    "pubDate": "Tue, 30 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/evaluation-structured-outputs",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "AI Policy @ü§ó: Comments on U.S. National AI Research Resource Interim Report",
    "description": "",
    "summary": "AI Policy @ü§ó: Comments on U.S. National AI Research Resource Interim Report In late June 2022, Huggi...",
    "pubDate": "Mon, 01 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/us-national-ai-research-resource",
    "thumbnail": "https://huggingface.co/blog/assets/92_us_national_ai_research_resource/nairr_thumbnail.png"
  },
  {
    "title": "Language models are few-shot learners",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 28 May 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-models-are-few-shot-learners",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing improvements to the fine-tuning API and expanding our custom models program",
    "description": "We‚Äôre adding new features to help developers have more control over fine-tuning and announcing new ways to build custom models with OpenAI.",
    "summary": "We‚Äôre adding new features to help developers have more control over fine-tuning and announcing new ways to build custom models with OpenAI.",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "‰∏â‰∫ï‰ΩèÂèãFG„ÄÅÁîüÊàêAIÊ¥ªÁî®„ÅßÂ§ßÊâãÊ≥ïÂæã‰∫ãÂãôÊâÄ„Å®Êñ∞‰ºöÁ§æ„ÄÄÂ•ëÁ¥ÑÊ•≠Âãô„ÅÆÂäπÁéáÂåñÂõ≥„Çã",
    "description": "‰∏â‰∫ï‰ΩèÂèã„Éï„Ç£„Éä„É≥„Ç∑„É£„É´„Ç∞„É´„Éº„ÉóÔºàFGÔºâ„Åå„ÄÅ„Ç¢„É≥„ÉÄ„Éº„ÇΩ„É≥„ÉªÊØõÂà©„ÉªÂèãÂ∏∏Ê≥ïÂæã‰∫ãÂãôÊâÄ„Å™„Å©„Å®ÂÖ±Âêå„Åß„ÄÅÁîüÊàêAIÔºà‰∫∫Â∑•Áü•ËÉΩÔºâ„ÇíÊ¥ªÁî®„Åó‰ºÅÊ•≠Èñì„ÅÆÂ•ëÁ¥Ñ„ÅÆ‰ΩúÊàê„ÇÑÂàÜÊûê„Å™„Å©„ÅÆ„Çµ„Éº„Éì„Çπ„ÇíÊèê‰æõ„Åô„ÇãÊñ∞‰ºöÁ§æ„ÄåSMBC„É™„Éº„Ç¨„É´XÔºà„ÇØ„É≠„ÇπÔºâ„Äç„ÇíË®≠Á´ã„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇÂ§ßÊâãÊ≥ïÂæã‰∫ãÂãôÊâÄ„ÅåÊåÅ„Å§Ê≥ïÂãô„ÅÆÁü•Ë¶ã„Å®ÁîüÊàêAI„ÅÆÊäÄË°ì„ÇíÂêà„Çè„Åõ„Å¶Â•ëÁ¥ÑÊ•≠Âãô„ÇíÂäπÁéáÂåñ„Åó„ÄÅ„Ç§„É≥„Éâ„Å™„Å©„Ç¢„Ç∏„Ç¢Ë´∏ÂõΩ„Å∏„ÅÆ‰∫ãÊ•≠Êã°Â§ß„ÇÇÁõÆÊåá„Åô„ÄÇ",
    "summary": "‰∏â‰∫ï‰ΩèÂèã„Éï„Ç£„Éä„É≥„Ç∑„É£„É´„Ç∞„É´„Éº„ÉóÔºàFGÔºâ„Åå„ÄÅ„Ç¢„É≥„ÉÄ„Éº„ÇΩ„É≥„ÉªÊØõÂà©„ÉªÂèãÂ∏∏Ê≥ïÂæã‰∫ãÂãôÊâÄ„Å™„Å©„Å®ÂÖ±Âêå„Åß„ÄÅÁîüÊàêAIÔºà‰∫∫Â∑•Áü•ËÉΩÔºâ„ÇíÊ¥ªÁî®„Åó‰ºÅÊ•≠Èñì„ÅÆÂ•ëÁ¥Ñ„ÅÆ‰ΩúÊàê„ÇÑÂàÜÊûê„Å™„Å©„ÅÆ„Çµ„Éº„Éì„Çπ„ÇíÊèê‰æõ„Åô„ÇãÊñ∞‰ºöÁ§æ„ÄåSMBC„É™„Éº„Ç¨„É´XÔºà„ÇØ„É≠„ÇπÔºâ„Äç„ÇíË®≠Á´ã„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇÂ§ßÊâãÊ≥ïÂæã‰∫ãÂãôÊâÄ„ÅåÊåÅ„Å§Ê≥ïÂãô„ÅÆÁü•Ë¶ã„Å®ÁîüÊàêAI„ÅÆÊäÄË°ì„ÇíÂêà„Çè„Åõ„Å¶Â•ëÁ¥ÑÊ•≠Âãô„ÇíÂäπÁéáÂåñ„Åó„ÄÅ„Ç§„É≥„Éâ„Å™„Å©„Ç¢„Ç∏„Ç¢Ë´∏ÂõΩ„Å∏„ÅÆ‰∫ãÊ•≠Êã°Â§ß„ÇÇÁõÆÊåá„Åô„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 17:55:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2507/03/news108.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2507/03/cover_news108.jpg"
  },
  {
    "title": "Hugging Face and IBM partner on watsonx.ai, the next-generation enterprise studio for AI builders",
    "description": "",
    "summary": "Hugging Face and IBM partner on watsonx.ai, the next-generation enterprise studio for AI builders Al...",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-ibm",
    "thumbnail": "https://huggingface.co/blog/assets/144_ibm/01.png"
  },
  {
    "title": "Open Preference Dataset for Text-to-Image Generation by the ü§ó Community",
    "description": "",
    "summary": "Open Preference Dataset for Text-to-Image Generation by the ü§ó Community The Data is Better Together ...",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-preferences",
    "thumbnail": "https://huggingface.co/blog/assets/image_preferences/thumbnail.png"
  },
  {
    "title": "DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making",
    "description": "arXiv:2507.02616v1 Announce Type: new Abstract: The rise of Large Language Models (LLMs) has enabled the development of specialized AI agents with domain-specific reasoning and interaction capabilities, particularly in healthcare. While recent frameworks simulate medical decision-making, they largely focus on single-turn tasks where a doctor agent receives full case information upfront -- diverging from the real-world diagnostic process, which is inherently uncertain, interactive, and iterative. In this paper, we introduce MIMIC-Patient, a structured dataset built from the MIMIC-III electronic health records (EHRs), designed to support dynamic, patient-level simulations. Building on this, we propose DynamiCare, a novel dynamic multi-agent framework that models clinical diagnosis as a multi-round, interactive loop, where a team of specialist agents iteratively queries the patient system, integrates new information, and dynamically adapts its composition and strategy. We demonstrate the feasibility and effectiveness of DynamiCare through extensive experiments, establishing the first benchmark for dynamic clinical decision-making with LLM-powered agents.",
    "summary": "arXiv:2507.02616v1 Announce Type: new Abstract: The rise of Large Language Models (LLMs) has enabled the development of specialized AI agents with domain-specific reasoning and interaction capabilities, particularly in healthcare. While recent frameworks simulate medical decision-making, they largely focus on single-turn tasks where a doctor agent receives full case information upfront -- diverging from the real-world diagnostic process, which is inherently uncertain, interactive, and iterative. In this paper, we introduce MIMIC-Patient, a structured dataset built from the MIMIC-III electronic health records (EHRs), designed to support dynamic, patient-level simulations. Building on this, we propose DynamiCare, a novel dynamic multi-agent framework that models clinical diagnosis as a multi-round, interactive loop, where a team of specialist agents iteratively queries the patient system, integrates new information, and dynamically adapts its composition and strategy. We demonstrate the feasibility and effectiveness of DynamiCare through extensive experiments, establishing the first benchmark for dynamic clinical decision-making with LLM-powered agents.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02616",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemini breaks new ground: a faster model, longer context and AI agents",
    "description": "We‚Äôre introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants.",
    "summary": "We‚Äôre introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants.",
    "pubDate": "Tue, 14 May 2024 17:58:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-breaks-new-ground-a-faster-model-longer-context-and-ai-agents/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_Blog_Social_Share.width-1300.png"
  },
  {
    "title": "Google Cloud: Driving digital transformation",
    "description": "Google Cloud empowers organizations to digitally transform themselves into smarter businesses. It offers cloud computing, data analytics, and the latest artificial intelligence (AI) and machine learning tools.",
    "summary": "Google Cloud empowers organizations to digitally transform themselves into smarter businesses. It offers cloud computing, data analytics, and the latest artificial intelligence (AI) and machine learning tools.",
    "pubDate": "Wed, 14 Jun 2023 14:51:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-cloud-driving-digital-transformation/",
    "thumbnail": "https://lh3.googleusercontent.com/xIps-6-tV3GGWQjVrHYTkLGnXAdZwmjG6jOAgECP5aynUXKeAfUhWv7fFfjPaV8Jmn3B3IabKBeDzBtB491hJAozuAhdQ-TUtZ5dzy9dmE1zWC-J=w1200-h630-n-nu"
  },
  {
    "title": "Weak-to-strong generalization",
    "description": "We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning to control strong models with weak supervisors?",
    "summary": "We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning to control strong models with weak supervisors?",
    "pubDate": "Thu, 14 Dec 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/weak-to-strong-generalization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "description": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "summary": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "pubDate": "Tue, 22 Oct 2024 06:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lenfest-institute",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model",
    "description": "arXiv:2507.02322v1 Announce Type: cross Abstract: Rice leaf diseases significantly reduce productivity and cause economic losses, highlighting the need for early detection to enable effective management and improve yields. This study proposes Artificial Neural Network (ANN)-based image-processing techniques for timely classification and recognition of rice diseases. Despite the prevailing approach of directly inputting images of rice leaves into ANNs, there is a noticeable absence of thorough comparative analysis between the Feature Analysis Detection Model (FADM) and Direct Image-Centric Detection Model (DICDM), specifically when it comes to evaluating the effectiveness of Feature Extraction Algorithms (FEAs). Hence, this research presents initial experiments on the Feature Analysis Detection Model, utilizing various image Feature Extraction Algorithms, Dimensionality Reduction Algorithms (DRAs), Feature Selection Algorithms (FSAs), and Extreme Learning Machine (ELM). The experiments are carried out on datasets encompassing bacterial leaf blight, brown spot, leaf blast, leaf scald, Sheath blight rot, and healthy leaf, utilizing 10-fold Cross-Validation method. A Direct Image-Centric Detection Model is established without the utilization of any FEA, and the evaluation of classification performance relies on different metrics. Ultimately, an exhaustive contrast is performed between the achievements of the Feature Analysis Detection Model and Direct Image-Centric Detection Model in classifying rice leaf diseases. The results reveal that the highest performance is attained using the Feature Analysis Detection Model. The adoption of the proposed Feature Analysis Detection Model for detecting rice leaf diseases holds excellent potential for improving crop health, minimizing yield losses, and enhancing overall productivity and sustainability of rice farming.",
    "summary": "arXiv:2507.02322v1 Announce Type: cross Abstract: Rice leaf diseases significantly reduce productivity and cause economic losses, highlighting the need for early detection to enable effective management and improve yields. This study proposes Artificial Neural Network (ANN)-based image-processing techniques for timely classification and recognition of rice diseases. Despite the prevailing approach of directly inputting images of rice leaves into ANNs, there is a noticeable absence of thorough comparative analysis between the Feature Analysis Detection Model (FADM) and Direct Image-Centric Detection Model (DICDM), specifically when it comes to evaluating the effectiveness of Feature Extraction Algorithms (FEAs). Hence, this research presents initial experiments on the Feature Analysis Detection Model, utilizing various image Feature Extraction Algorithms, Dimensionality Reduction Algorithms (DRAs), Feature Selection Algorithms (FSAs), and Extreme Learning Machine (ELM). The experiments are carried out on datasets encompassing bacterial leaf blight, brown spot, leaf blast, leaf scald, Sheath blight rot, and healthy leaf, utilizing 10-fold Cross-Validation method. A Direct Image-Centric Detection Model is established without the utilization of any FEA, and the evaluation of classification performance relies on different metrics. Ultimately, an exhaustive contrast is performed between the achievements of the Feature Analysis Detection Model and Direct Image-Centric Detection Model in classifying rice leaf diseases. The results reveal that the highest performance is attained using the Feature Analysis Detection Model. The adoption of the proposed Feature Analysis Detection Model for detecting rice leaf diseases holds excellent potential for improving crop health, minimizing yield losses, and enhancing overall productivity and sustainability of rice farming.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02322",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reptile: A scalable meta-learning algorithm",
    "description": "We‚Äôve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task, performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters learned on that task. Reptile is the application of the Shortest Descent algorithm to the meta-learning setting, and is mathematically similar to first-order MAML (which is a version of the well-known MAML algorithm) that only needs black-box access to an optimizer such as SGD or Adam, with similar computational efficiency and performance.",
    "summary": "We‚Äôve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task, performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters learned on that task. Reptile is the application of the Shortest Descent algorithm to the meta-learning setting, and is mathematically similar to first-order MAML (which is a version of the well-known MAML algorithm) that only needs black-box access to an optimizer such as SGD or Adam, with similar computational efficiency and performance.",
    "pubDate": "Wed, 07 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reptile",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing New Hugging Face and KerasHub integration",
    "description": "",
    "summary": "Announcing New Hugging Face and KerasHub integration The Hugging Face Hub is a vast repository, curr...",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-hub-integration",
    "thumbnail": "https://huggingface.co/blog/assets/keras-hub-integration/thumbnail.png"
  },
  {
    "title": "Making ML-powered web games with Transformers.js",
    "description": "",
    "summary": "Making ML-powered web games with Transformers.js In this blog post, I'll show you how I made Doodle ...",
    "pubDate": "Wed, 05 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-web-games",
    "thumbnail": "https://huggingface.co/blog/assets/ml-web-games/thumbnail.png"
  },
  {
    "title": "Xet is on the Hub",
    "description": "",
    "summary": "Xet is on the Hub Click here to read about joining the Xet waitlist (or head over to join immediatel...",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xet-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/xet-on-the-hub/thumbnail.png"
  },
  {
    "title": "Introducing the Model Spec",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-model-spec",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building AI-powered apps for business",
    "description": "Retool uses GPT-4 to give businesses a fast, secure way to build AI-powered apps.",
    "summary": "Retool uses GPT-4 to give businesses a fast, secure way to build AI-powered apps.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retool",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent",
    "description": "",
    "summary": "Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent Introduction We're excited to ...",
    "pubDate": "Mon, 22 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/jat",
    "thumbnail": "https://huggingface.co/blog/assets/jat/thumbnail.png"
  },
  {
    "title": "Diffusion Models Live Event",
    "description": "",
    "summary": "Diffusion Models Live Event We are excited to share that the Diffusion Models Class with Hugging Fac...",
    "pubDate": "Fri, 25 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusion-models-event",
    "thumbnail": "https://huggingface.co/blog/assets/diffusion-models-event/thumbnail.png"
  },
  {
    "title": "Finetune Stable Diffusion Models with DDPO via TRL",
    "description": "",
    "summary": "Finetune Stable Diffusion Models with DDPO via TRL Introduction Diffusion models (e.g., DALL-E 2, St...",
    "pubDate": "Fri, 29 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trl-ddpo",
    "thumbnail": "https://huggingface.co/blog/assets/166_trl_ddpo/thumbnail.png"
  },
  {
    "title": "Building smarter maps with GPT-4o vision fine-tuning",
    "description": "Building smarter maps with GPT-4o vision fine-tuning",
    "summary": "Building smarter maps with GPT-4o vision fine-tuning",
    "pubDate": "Wed, 20 Nov 2024 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/grab",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Claude 4 „É¢„Éá„É´ÁôªÂ†¥ÔºÅÊñ∞Ê©üËÉΩ„ÇÑ‰ªñÁ§æ„Å®„ÅÆÊØîËºÉ„ÉªÊñôÈáë„Å™„Å©Ë©≥„Åó„ÅèËß£Ë™¨",
    "description": "<p>Anthropic Á§æ„ÅØ2025Âπ¥5Êúà22Êó•„ÄÅClaude „ÅÆÊúÄÊñ∞Áâà„ÄåClaude 4„Äç„ÅÆÊèê‰æõ„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„ÄÇ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„ÇÑÊé®Ë´ñ„Çí„ÅØ„Åò„ÇÅ„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÊßãÁØâ„Å®„ÅÑ„Å£„Åü„Ç∑„Éº„É≥„ÅßÊúÄÈ´òÊ∞¥Ê∫ñ„ÅÆËÉΩÂäõ„ÇíÂÆüÁèæ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅ„Ç≥„Éº„Éá [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/claude-4-model-new-features/'>Claude 4 „É¢„Éá„É´ÁôªÂ†¥ÔºÅÊñ∞Ê©üËÉΩ„ÇÑ‰ªñÁ§æ„Å®„ÅÆÊØîËºÉ„ÉªÊñôÈáë„Å™„Å©Ë©≥„Åó„ÅèËß£Ë™¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>Anthropic Á§æ„ÅØ2025Âπ¥5Êúà22Êó•„ÄÅClaude „ÅÆÊúÄÊñ∞Áâà„ÄåClaude 4„Äç„ÅÆÊèê‰æõ„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„ÄÇ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„ÇÑÊé®Ë´ñ„Çí„ÅØ„Åò„ÇÅ„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÊßãÁØâ„Å®„ÅÑ„Å£„Åü„Ç∑„Éº„É≥„ÅßÊúÄÈ´òÊ∞¥Ê∫ñ„ÅÆËÉΩÂäõ„ÇíÂÆüÁèæ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅ„Ç≥„Éº„Éá [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/claude-4-model-new-features/'>Claude 4 „É¢„Éá„É´ÁôªÂ†¥ÔºÅÊñ∞Ê©üËÉΩ„ÇÑ‰ªñÁ§æ„Å®„ÅÆÊØîËºÉ„ÉªÊñôÈáë„Å™„Å©Ë©≥„Åó„ÅèËß£Ë™¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 03:33:57 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/claude-4-model-new-features/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/claude4.png"
  },
  {
    "title": "How to deploy and fine-tune DeepSeek models on AWS",
    "description": "",
    "summary": "How to deploy and fine-tune DeepSeek models on AWS A running document to showcase how to deploy and ...",
    "pubDate": "Thu, 30 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deepseek-r1-aws",
    "thumbnail": "https://huggingface.co/blog/assets/deepseek-r1-aws/thumbnail.png"
  },
  {
    "title": "Accelerating scientific discovery with AI",
    "description": "FutureHouse, co-founded by Sam Rodriques PhD ‚Äô19, has developed AI agents to automate key steps on the path toward scientific progress.",
    "summary": "FutureHouse, co-founded by Sam Rodriques PhD ‚Äô19, has developed AI agents to automate key steps on the path toward scientific progress.",
    "pubDate": "Mon, 30 Jun 2025 10:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/futurehouse-accelerates-scientific-discovery-with-ai-0630",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Future-House-01-press.jpg"
  },
  {
    "title": "Testing robustness against unforeseen adversaries",
    "description": "We‚Äôve developed a method to assess whether a neural network classifier can reliably defend against adversarial attacks not seen during training. Our method yields a new metric, UAR (Unforeseen Attack Robustness), which evaluates the robustness of a single model against an unanticipated attack, and highlights the need to measure performance across a more diverse range of unforeseen¬†attacks.",
    "summary": "We‚Äôve developed a method to assess whether a neural network classifier can reliably defend against adversarial attacks not seen during training. Our method yields a new metric, UAR (Unforeseen Attack Robustness), which evaluates the robustness of a single model against an unanticipated attack, and highlights the need to measure performance across a more diverse range of unforeseen¬†attacks.",
    "pubDate": "Thu, 22 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/testing-robustness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Watermarking 101: Tools and Techniques",
    "description": "",
    "summary": "AI Watermarking 101: Tools and Techniques In recent months, we've seen multiple news stories involvi...",
    "pubDate": "Mon, 26 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/watermarking",
    "thumbnail": "https://huggingface.co/blog/assets/watermarking/thumbnail.png"
  },
  {
    "title": "From Files to Chunks: Improving Hugging Face Storage Efficiency",
    "description": "",
    "summary": "From Files to Chunks: Improving HF Storage Efficiency Hugging Face stores over 30 PB of models, data...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/from-files-to-chunks",
    "thumbnail": "https://huggingface.co/blog/assets/from-files-to-chunks/thumbnail.png"
  },
  {
    "title": "Rearchitecting Hugging Face Uploads and Downloads",
    "description": "",
    "summary": "Rearchitecting Hugging Face Uploads and Downloads As part of Hugging Face's Xet team‚Äôs work to impro...",
    "pubDate": "Tue, 26 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rearchitecting-uploads-and-downloads",
    "thumbnail": "https://huggingface.co/blog/assets/rearchitecting-uploads-and-downloads/thumbnail.png"
  },
  {
    "title": "No GPU left behind: Unlocking Efficiency with Co-located vLLM in TRL",
    "description": "",
    "summary": "No GPU left behind: Unlocking Efficiency with Co-located vLLM in TRL üöÄ Introduction TRL supports tra...",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vllm-colocate",
    "thumbnail": "https://huggingface.co/blog/assets/liger-grpo/thumbnail.png"
  },
  {
    "title": "Toward a Robust and Generalizable Metamaterial Foundation Model",
    "description": "arXiv:2507.02436v1 Announce Type: cross Abstract: Advances in material functionalities drive innovations across various fields, where metamaterials-defined by structure rather than composition-are leading the way. Despite the rise of artificial intelligence (AI)-driven design strategies, their impact is limited by task-specific retraining, poor out-of-distribution(OOD) generalization, and the need for separate models for forward and inverse design. To address these limitations, we introduce the Metamaterial Foundation Model (MetaFO), a Bayesian transformer-based foundation model inspired by large language models. MetaFO learns the underlying mechanics of metamaterials, enabling probabilistic, zero-shot predictions across diverse, unseen combinations of material properties and structural responses. It also excels in nonlinear inverse design, even under OOD conditions. By treating metamaterials as an operator that maps material properties to structural responses, MetaFO uncovers intricate structure-property relationships and significantly expands the design space. This scalable and generalizable framework marks a paradigm shift in AI-driven metamaterial discovery, paving the way for next-generation innovations.",
    "summary": "arXiv:2507.02436v1 Announce Type: cross Abstract: Advances in material functionalities drive innovations across various fields, where metamaterials-defined by structure rather than composition-are leading the way. Despite the rise of artificial intelligence (AI)-driven design strategies, their impact is limited by task-specific retraining, poor out-of-distribution(OOD) generalization, and the need for separate models for forward and inverse design. To address these limitations, we introduce the Metamaterial Foundation Model (MetaFO), a Bayesian transformer-based foundation model inspired by large language models. MetaFO learns the underlying mechanics of metamaterials, enabling probabilistic, zero-shot predictions across diverse, unseen combinations of material properties and structural responses. It also excels in nonlinear inverse design, even under OOD conditions. By treating metamaterials as an operator that maps material properties to structural responses, MetaFO uncovers intricate structure-property relationships and significantly expands the design space. This scalable and generalizable framework marks a paradigm shift in AI-driven metamaterial discovery, paving the way for next-generation innovations.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02436",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CyberSecEval 2 - A Comprehensive Evaluation Framework for Cybersecurity Risks and Capabilities of Large Language Models",
    "description": "",
    "summary": "CyberSecEval 2 - A Comprehensive Evaluation Framework for Cybersecurity Risks and Capabilities of La...",
    "pubDate": "Fri, 24 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-llamaguard",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_llamaguard.png"
  },
  {
    "title": "Speculative Decoding for 2x Faster Whisper Inference",
    "description": "",
    "summary": "Speculative Decoding for 2x Faster Whisper Inference Open AI's Whisper is a general purpose speech t...",
    "pubDate": "Wed, 20 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/whisper-speculative-decoding",
    "thumbnail": "https://huggingface.co/blog/assets/whisper-speculative-decoding/thumbnail.png"
  },
  {
    "title": "How we built one of the most ambitious datasets in brain activity research",
    "description": "Four small, translucent zebrafish swim against a dark background",
    "summary": "Four small, translucent zebrafish swim against a dark background",
    "pubDate": "Mon, 09 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/research/zapbench-zebrafish-brain-mapping/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SS_How-we-built-one-of-the-most-ambitious-dat.width-1300.png"
  },
  {
    "title": "OpenAI acquires Global Illumination",
    "description": "The entire team has joined OpenAI.",
    "summary": "The entire team has joined OpenAI.",
    "pubDate": "Wed, 16 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-acquires-global-illumination",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction",
    "description": "arXiv:2507.02018v1 Announce Type: cross Abstract: Graph representation learning methods have been widely adopted in financial applications to enhance company representations by leveraging inter-firm relationships. However, current approaches face three key challenges: (1) The advantages of relational information are obscured by limitations in downstream task designs; (2) Existing graph models specifically designed for stock prediction often suffer from excessive complexity and poor generalization; (3) Experience-based construction of corporate relationship graphs lacks effective comparison of different graph structures. To address these limitations, we propose a long-term stock prediction task and develop a Node-level Graph Attention Network (NGAT) specifically tailored for corporate relationship graphs. Furthermore, we experimentally demonstrate the limitations of existing graph comparison methods based on model downstream task performance. Experimental results across two datasets consistently demonstrate the effectiveness of our proposed task and model. The project is publicly available on GitHub to encourage reproducibility and future research.",
    "summary": "arXiv:2507.02018v1 Announce Type: cross Abstract: Graph representation learning methods have been widely adopted in financial applications to enhance company representations by leveraging inter-firm relationships. However, current approaches face three key challenges: (1) The advantages of relational information are obscured by limitations in downstream task designs; (2) Existing graph models specifically designed for stock prediction often suffer from excessive complexity and poor generalization; (3) Experience-based construction of corporate relationship graphs lacks effective comparison of different graph structures. To address these limitations, we propose a long-term stock prediction task and develop a Node-level Graph Attention Network (NGAT) specifically tailored for corporate relationship graphs. Furthermore, we experimentally demonstrate the limitations of existing graph comparison methods based on model downstream task performance. Experimental results across two datasets consistently demonstrate the effectiveness of our proposed task and model. The project is publicly available on GitHub to encourage reproducibility and future research.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Expanding on what we missed with sycophancy",
    "description": "A deeper dive on our findings, what went wrong, and future changes we‚Äôre making.",
    "summary": "A deeper dive on our findings, what went wrong, and future changes we‚Äôre making.",
    "pubDate": "Fri, 02 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expanding-on-sycophancy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CO2 Emissions and the ü§ó Hub: Leading the Charge",
    "description": "",
    "summary": "CO2 Emissions and the ü§ó Hub: Leading the Charge What are CO2 Emissions and why are they important? C...",
    "pubDate": "Fri, 22 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/carbon-emissions-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/60_carbon_emissions_on_the_hub/thumbnail.jpg"
  },
  {
    "title": "Synthetic data: save money, time and carbon with open source",
    "description": "",
    "summary": "Synthetic data: save money, time and carbon with open source tl;dr Should you fine-tune your own mod...",
    "pubDate": "Fri, 16 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthetic-data-save-costs",
    "thumbnail": "https://huggingface.co/blog/assets/176_synthetic-data-save-costs/thumbnail.png"
  },
  {
    "title": "Upgrading the Moderation API with our new multimodal moderation model",
    "description": "We‚Äôre introducing a new model built on GPT-4o that is more accurate at detecting harmful text and images, enabling developers to build more robust moderation systems.",
    "summary": "We‚Äôre introducing a new model built on GPT-4o that is more accurate at detecting harmful text and images, enabling developers to build more robust moderation systems.",
    "pubDate": "Thu, 26 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/upgrading-the-moderation-api-with-our-new-multimodal-moderation-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Spotlighting Partially Visible Cinematic Language for Video-to-Audio Generation via Self-distillation",
    "description": "arXiv:2507.02271v1 Announce Type: cross Abstract: Video-to-Audio (V2A) Generation achieves significant progress and plays a crucial role in film and video post-production. However, current methods overlook the cinematic language, a critical component of artistic expression in filmmaking. As a result, their performance deteriorates in scenarios where Foley targets are only partially visible. To address this challenge, we propose a simple self-distillation approach to extend V2A models to cinematic language scenarios. By simulating the cinematic language variations, the student model learns to align the video features of training pairs with the same audio-visual correspondences, enabling it to effectively capture the associations between sounds and partial visual information. Our method not only achieves impressive improvements under partial visibility across all evaluation metrics, but also enhances performance on the large-scale V2A dataset, VGGSound.",
    "summary": "arXiv:2507.02271v1 Announce Type: cross Abstract: Video-to-Audio (V2A) Generation achieves significant progress and plays a crucial role in film and video post-production. However, current methods overlook the cinematic language, a critical component of artistic expression in filmmaking. As a result, their performance deteriorates in scenarios where Foley targets are only partially visible. To address this challenge, we propose a simple self-distillation approach to extend V2A models to cinematic language scenarios. By simulating the cinematic language variations, the student model learns to align the video features of training pairs with the same audio-visual correspondences, enabling it to effectively capture the associations between sounds and partial visual information. Our method not only achieves impressive improvements under partial visibility across all evaluation metrics, but also enhances performance on the large-scale V2A dataset, VGGSound.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02271",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Machine Learning Unconference",
    "description": "The latest information about the Unconference is now available at the Unconference wiki, which will be periodically updated with more information for attendees.",
    "summary": "The latest information about the Unconference is now available at the Unconference wiki, which will be periodically updated with more information for attendees.",
    "pubDate": "Thu, 18 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/machine-learning-unconference",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Databricks ‚ù§Ô∏è Hugging Face: up to 40% faster training and tuning of Large Language Models",
    "description": "",
    "summary": "Databricks ‚ù§Ô∏è Hugging Face: up to 40% faster training and tuning of Large Language Models Generative...",
    "pubDate": "Wed, 26 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/databricks-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/databricks.png"
  },
  {
    "title": "Multi-agent Auditory Scene Analysis",
    "description": "arXiv:2507.02755v1 Announce Type: cross Abstract: Auditory scene analysis (ASA) aims to retrieve information from the acoustic environment, by carrying out three main tasks: sound source location, separation, and classification. These tasks are traditionally executed with a linear data flow, where the sound sources are first located; then, using their location, each source is separated into its own audio stream; from each of which, information is extracted that is relevant to the application scenario (audio event detection, speaker identification, emotion classification, etc.). However, running these tasks linearly increases the overall response time, while making the last tasks (separation and classification) highly sensitive to errors of the first task (location). A considerable amount of effort and computational complexity has been employed in the state-of-the-art to develop techniques that are the least error-prone possible. However, doing so gives rise to an ASA system that is non-viable in many applications that require a small computational footprint and a low response time, such as bioacoustics, hearing-aid design, search and rescue, human-robot interaction, etc. To this effect, in this work, a multi-agent approach is proposed to carry out ASA where the tasks are run in parallel, with feedback loops between them to compensate for local errors, such as: using the quality of the separation output to correct the location error; and using the classification result to reduce the localization's sensitivity towards interferences. The result is a multi-agent auditory scene analysis (MASA) system that is robust against local errors, without a considerable increase in complexity, and with a low response time. The complete proposed MASA system is provided as a framework that uses open-source tools for sound acquisition and reproduction (JACK) and inter-agent communication (ROS2), allowing users to add their own agents.",
    "summary": "arXiv:2507.02755v1 Announce Type: cross Abstract: Auditory scene analysis (ASA) aims to retrieve information from the acoustic environment, by carrying out three main tasks: sound source location, separation, and classification. These tasks are traditionally executed with a linear data flow, where the sound sources are first located; then, using their location, each source is separated into its own audio stream; from each of which, information is extracted that is relevant to the application scenario (audio event detection, speaker identification, emotion classification, etc.). However, running these tasks linearly increases the overall response time, while making the last tasks (separation and classification) highly sensitive to errors of the first task (location). A considerable amount of effort and computational complexity has been employed in the state-of-the-art to develop techniques that are the least error-prone possible. However, doing so gives rise to an ASA system that is non-viable in many applications that require a small computational footprint and a low response time, such as bioacoustics, hearing-aid design, search and rescue, human-robot interaction, etc. To this effect, in this work, a multi-agent approach is proposed to carry out ASA where the tasks are run in parallel, with feedback loops between them to compensate for local errors, such as: using the quality of the separation output to correct the location error; and using the classification result to reduce the localization's sensitivity towards interferences. The result is a multi-agent auditory scene analysis (MASA) system that is robust against local errors, without a considerable increase in complexity, and with a low response time. The complete proposed MASA system is provided as a framework that uses open-source tools for sound acquisition and reproduction (JACK) and inter-agent communication (ROS2), allowing users to add their own agents.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02755",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome FalconMamba: The first strong attention-free 7B model",
    "description": "",
    "summary": "Welcome FalconMamba: The first strong attention-free 7B model Falcon Mamba is a new model by Technol...",
    "pubDate": "Mon, 12 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falconmamba",
    "thumbnail": "https://huggingface.co/blog/assets/falconmamba/thumbnail.png"
  },
  {
    "title": "GPT-4o mini: advancing cost-efficient intelligence",
    "description": "Introducing the most cost-efficient small model in the market",
    "summary": "Introducing the most cost-efficient small model in the market",
    "pubDate": "Thu, 18 Jul 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-mini-advancing-cost-efficient-intelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Testing and Evaluation: Learnings from Science and Industry",
    "description": "<p>In the introductory episode of this new series, host Kathleen Sullivan and Senior Director Amanda Craig Deckard explore Microsoft‚Äôs efforts to draw on the experience of other domains to help advance the role of AI testing and evaluation as a governance tool.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/'>AI Testing and Evaluation: Learnings from Science and Industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>In the introductory episode of this new series, host Kathleen Sullivan and Senior Director Amanda Craig Deckard explore Microsoft‚Äôs efforts to draw on the experience of other domains to help advance the role of AI testing and evaluation as a governance tool.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/'>AI Testing and Evaluation: Learnings from Science and Industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 16:38:09 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Discovery of Fatigue Strength Models via Feature Engineering and automated eXplainable Machine Learning applied to the welded Transverse Stiffener",
    "description": "arXiv:2507.02005v1 Announce Type: cross Abstract: This research introduces a unified approach combining Automated Machine Learning (AutoML) with Explainable Artificial Intelligence (XAI) to predict fatigue strength in welded transverse stiffener details. It integrates expert-driven feature engineering with algorithmic feature creation to enhance accuracy and explainability. Based on the extensive fatigue test database regression models - gradient boosting, random forests, and neural networks - were trained using AutoML under three feature schemes: domain-informed, algorithmic, and combined. This allowed a systematic comparison of expert-based versus automated feature selection. Ensemble methods (e.g. CatBoost, LightGBM) delivered top performance. The domain-informed model $mathcal M_2$ achieved the best balance: test RMSE $approx$ 30.6 MPa and $R^2 approx 0.780% over the full $Delta sigma_{c,50%}$ range, and RMSE $approx$ 13.4 MPa and $R^2 approx 0.527% within the engineering-relevant 0 - 150 MPa domain. The denser-feature model ($mathcal M_3$) showed minor gains during training but poorer generalization, while the simpler base-feature model ($mathcal M_1$) performed comparably, confirming the robustness of minimalist designs. XAI methods (SHAP and feature importance) identified stress ratio $R$, stress range $Delta sigma_i$, yield strength $R_{eH}$, and post-weld treatment (TIG dressing vs. as-welded) as dominant predictors. Secondary geometric factors - plate width, throat thickness, stiffener height - also significantly affected fatigue life. This framework demonstrates that integrating AutoML with XAI yields accurate, interpretable, and robust fatigue strength models for welded steel structures. It bridges data-driven modeling with engineering validation, enabling AI-assisted design and assessment. Future work will explore probabilistic fatigue life modeling and integration into digital twin environments.",
    "summary": "arXiv:2507.02005v1 Announce Type: cross Abstract: This research introduces a unified approach combining Automated Machine Learning (AutoML) with Explainable Artificial Intelligence (XAI) to predict fatigue strength in welded transverse stiffener details. It integrates expert-driven feature engineering with algorithmic feature creation to enhance accuracy and explainability. Based on the extensive fatigue test database regression models - gradient boosting, random forests, and neural networks - were trained using AutoML under three feature schemes: domain-informed, algorithmic, and combined. This allowed a systematic comparison of expert-based versus automated feature selection. Ensemble methods (e.g. CatBoost, LightGBM) delivered top performance. The domain-informed model $mathcal M_2$ achieved the best balance: test RMSE $approx$ 30.6 MPa and $R^2 approx 0.780% over the full $Delta sigma_{c,50%}$ range, and RMSE $approx$ 13.4 MPa and $R^2 approx 0.527% within the engineering-relevant 0 - 150 MPa domain. The denser-feature model ($mathcal M_3$) showed minor gains during training but poorer generalization, while the simpler base-feature model ($mathcal M_1$) performed comparably, confirming the robustness of minimalist designs. XAI methods (SHAP and feature importance) identified stress ratio $R$, stress range $Delta sigma_i$, yield strength $R_{eH}$, and post-weld treatment (TIG dressing vs. as-welded) as dominant predictors. Secondary geometric factors - plate width, throat thickness, stiffener height - also significantly affected fatigue life. This framework demonstrates that integrating AutoML with XAI yields accurate, interpretable, and robust fatigue strength models for welded steel structures. It bridges data-driven modeling with engineering validation, enabling AI-assisted design and assessment. Future work will explore probabilistic fatigue life modeling and integration into digital twin environments.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02005",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deploy GPT-J 6B for inference using Hugging Face Transformers and Amazon SageMaker",
    "description": "",
    "summary": "Deploy GPT-J 6B for inference using Hugging Face Transformers and Amazon SageMaker Almost 6 months a...",
    "pubDate": "Tue, 11 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gptj-sagemaker",
    "thumbnail": "https://huggingface.co/blog/assets/45_gptj_sagemaker/thumbnail.png"
  },
  {
    "title": "Merging design and computer science in creative ways",
    "description": "MAD Fellow Alexander Htet Kyaw connects humans, machines, and the physical world using AI and augmented reality.",
    "summary": "MAD Fellow Alexander Htet Kyaw connects humans, machines, and the physical world using AI and augmented reality.",
    "pubDate": "Mon, 28 Apr 2025 16:55:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/alexander-htet-kyaw-merging-design-computer-science-in-creative-ways-0428",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-mad-Alexander-htet-kyaw_0.jpg"
  },
  {
    "title": "Easily Train Models with H100 GPUs on NVIDIA DGX Cloud",
    "description": "",
    "summary": "Easily Train Models with H100 GPUs on NVIDIA DGX Cloud Update: This service is deprecated and no lon...",
    "pubDate": "Mon, 18 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-dgx-cloud",
    "thumbnail": "https://huggingface.co/blog/assets/train-dgx-cloud/thumbnail.jpg"
  },
  {
    "title": "Making LLMs lighter with AutoGPTQ and transformers",
    "description": "",
    "summary": "Making LLMs lighter with AutoGPTQ and transformers Large language models have demonstrated remarkabl...",
    "pubDate": "Wed, 23 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gptq-integration",
    "thumbnail": "https://huggingface.co/blog/assets/159_autogptq_transformers/thumbnail.jpg"
  },
  {
    "title": "Llama 3.2 in Keras",
    "description": "",
    "summary": "Llama 3.2 in Keras This is going to be the shortest blog post ever. Question: Llama 3.2 landed two w...",
    "pubDate": "Mon, 21 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-llama-32",
    "thumbnail": "https://huggingface.co/blog/assets/keras_llama_32/thumbnail.jpg"
  },
  {
    "title": "ManifoldMind: Dynamic Hyperbolic Reasoning for Trustworthy Recommendations",
    "description": "arXiv:2507.02014v1 Announce Type: cross Abstract: We introduce ManifoldMind, a probabilistic geometric recommender system for exploratory reasoning over semantic hierarchies in hyperbolic space. Unlike prior methods with fixed curvature and rigid embeddings, ManifoldMind represents users, items, and tags as adaptive-curvature probabilistic spheres, enabling personalised uncertainty modeling and geometry-aware semantic exploration. A curvature-aware semantic kernel supports soft, multi-hop inference, allowing the model to explore diverse conceptual paths instead of overfitting to shallow or direct interactions. Experiments on four public benchmarks show superior NDCG, calibration, and diversity compared to strong baselines. ManifoldMind produces explicit reasoning traces, enabling transparent, trustworthy, and exploration-driven recommendations in sparse or abstract domains.",
    "summary": "arXiv:2507.02014v1 Announce Type: cross Abstract: We introduce ManifoldMind, a probabilistic geometric recommender system for exploratory reasoning over semantic hierarchies in hyperbolic space. Unlike prior methods with fixed curvature and rigid embeddings, ManifoldMind represents users, items, and tags as adaptive-curvature probabilistic spheres, enabling personalised uncertainty modeling and geometry-aware semantic exploration. A curvature-aware semantic kernel supports soft, multi-hop inference, allowing the model to explore diverse conceptual paths instead of overfitting to shallow or direct interactions. Experiments on four public benchmarks show superior NDCG, calibration, and diversity compared to strong baselines. ManifoldMind produces explicit reasoning traces, enabling transparent, trustworthy, and exploration-driven recommendations in sparse or abstract domains.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02014",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Swift Diffusers: Fast Stable Diffusion for Mac",
    "description": "",
    "summary": "Swift üß®Diffusers: Fast Stable Diffusion for Mac Transform your text into stunning images with ease u...",
    "pubDate": "Fri, 24 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-mac-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/fast-mac-diffusers/thumbnail.png"
  },
  {
    "title": "Trading inference-time compute for adversarial robustness",
    "description": "Trading Inference-Time Compute for Adversarial Robustness",
    "summary": "Trading Inference-Time Compute for Adversarial Robustness",
    "pubDate": "Wed, 22 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/trading-inference-time-compute-for-adversarial-robustness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2",
    "description": "",
    "summary": "Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2 Update (29/08/2023): A benchmark o...",
    "pubDate": "Thu, 29 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bridgetower",
    "thumbnail": "https://huggingface.co/blog/assets/bridgetower/thumbnail.png"
  },
  {
    "title": "When LLMs Disagree: Diagnosing Relevance Filtering Bias and Retrieval Divergence in SDG Search",
    "description": "arXiv:2507.02139v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used to assign document relevance labels in information retrieval pipelines, especially in domains lacking human-labeled data. However, different models often disagree on borderline cases, raising concerns about how such disagreement affects downstream retrieval. This study examines labeling disagreement between two open-weight LLMs, LLaMA and Qwen, on a corpus of scholarly abstracts related to Sustainable Development Goals (SDGs) 1, 3, and 7. We isolate disagreement subsets and examine their lexical properties, rank-order behavior, and classification predictability. Our results show that model disagreement is systematic, not random: disagreement cases exhibit consistent lexical patterns, produce divergent top-ranked outputs under shared scoring functions, and are distinguishable with AUCs above 0.74 using simple classifiers. These findings suggest that LLM-based filtering introduces structured variability in document retrieval, even under controlled prompting and shared ranking logic. We propose using classification disagreement as an object of analysis in retrieval evaluation, particularly in policy-relevant or thematic search tasks.",
    "summary": "arXiv:2507.02139v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used to assign document relevance labels in information retrieval pipelines, especially in domains lacking human-labeled data. However, different models often disagree on borderline cases, raising concerns about how such disagreement affects downstream retrieval. This study examines labeling disagreement between two open-weight LLMs, LLaMA and Qwen, on a corpus of scholarly abstracts related to Sustainable Development Goals (SDGs) 1, 3, and 7. We isolate disagreement subsets and examine their lexical properties, rank-order behavior, and classification predictability. Our results show that model disagreement is systematic, not random: disagreement cases exhibit consistent lexical patterns, produce divergent top-ranked outputs under shared scoring functions, and are distinguishable with AUCs above 0.74 using simple classifiers. These findings suggest that LLM-based filtering introduces structured variability in document retrieval, even under controlled prompting and shared ranking logic. We propose using classification disagreement as an object of analysis in retrieval evaluation, particularly in policy-relevant or thematic search tasks.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02139",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Train 400x faster Static Embedding Models with Sentence Transformers",
    "description": "",
    "summary": "Train 400x faster Static Embedding Models with Sentence Transformers TL;DR This blog post introduces...",
    "pubDate": "Wed, 15 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/static-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "Our latest advances in robot dexterity",
    "description": "Two new AI systems, ALOHA Unleashed and DemoStart, help robots learn to perform complex tasks that require dexterous movement",
    "summary": "Two new AI systems, ALOHA Unleashed and DemoStart, help robots learn to perform complex tasks that require dexterous movement",
    "pubDate": "Thu, 12 Sep 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advances-in-robot-dexterity/",
    "thumbnail": "https://lh3.googleusercontent.com/63ROjLq4VNqk3RDA5vl1mYS1i5xvcgU8-augVWQY5OZCtVsm_e4YX8rR4_DLUlQiTmMHT6qx3p9shUtPGUHy_4SA64RDeMghvk0eDKT6Fqh6-P3d4A=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "description": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "summary": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "pubDate": "Mon, 10 Jun 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-welcomes-cfo-cpo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Could LLMs help design our next medicines and materials?",
    "description": "A new method lets users ask, in plain language, for a new molecule with certain properties, and receive a detailed description of how to synthesize it.",
    "summary": "A new method lets users ask, in plain language, for a new molecule with certain properties, and receive a detailed description of how to synthesize it.",
    "pubDate": "Wed, 09 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/could-llms-help-design-our-next-medicines-and-materials-0409",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-inverse-molecule-01-press.jpg"
  },
  {
    "title": "Introducing ConTextual: How well can your Multimodal model jointly reason over text and image in text-rich scenes?",
    "description": "",
    "summary": "Introducing ConTextual: How well can your Multimodal model jointly reason over text and image in tex...",
    "pubDate": "Tue, 05 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-contextual",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_contextual.png"
  },
  {
    "title": "DeepSupp: Attention-Driven Correlation Pattern Analysis for Dynamic Time Series Support and Resistance Levels Identification",
    "description": "arXiv:2507.01971v1 Announce Type: cross Abstract: Support and resistance (SR) levels are central to technical analysis, guiding traders in entry, exit, and risk management. Despite widespread use, traditional SR identification methods often fail to adapt to the complexities of modern, volatile markets. Recent research has introduced machine learning techniques to address the following challenges, yet most focus on price prediction rather than structural level identification. This paper presents DeepSupp, a new deep learning approach for detecting financial support levels using multi-head attention mechanisms to analyze spatial correlations and market microstructure relationships. DeepSupp integrates advanced feature engineering, constructing dynamic correlation matrices that capture evolving market relationships, and employs an attention-based autoencoder for robust representation learning. The final support levels are extracted through unsupervised clustering, leveraging DBSCAN to identify significant price thresholds. Comprehensive evaluations on S&amp;P 500 tickers demonstrate that DeepSupp outperforms six baseline methods, achieving state-of-the-art performance across six financial metrics, including essential support accuracy and market regime sensitivity. With consistent results across diverse market conditions, DeepSupp addresses critical gaps in SR level detection, offering a scalable and reliable solution for modern financial analysis. Our approach highlights the potential of attention-based architectures to uncover nuanced market patterns and improve technical trading strategies.",
    "summary": "arXiv:2507.01971v1 Announce Type: cross Abstract: Support and resistance (SR) levels are central to technical analysis, guiding traders in entry, exit, and risk management. Despite widespread use, traditional SR identification methods often fail to adapt to the complexities of modern, volatile markets. Recent research has introduced machine learning techniques to address the following challenges, yet most focus on price prediction rather than structural level identification. This paper presents DeepSupp, a new deep learning approach for detecting financial support levels using multi-head attention mechanisms to analyze spatial correlations and market microstructure relationships. DeepSupp integrates advanced feature engineering, constructing dynamic correlation matrices that capture evolving market relationships, and employs an attention-based autoencoder for robust representation learning. The final support levels are extracted through unsupervised clustering, leveraging DBSCAN to identify significant price thresholds. Comprehensive evaluations on S&amp;P 500 tickers demonstrate that DeepSupp outperforms six baseline methods, achieving state-of-the-art performance across six financial metrics, including essential support accuracy and market regime sensitivity. With consistent results across diverse market conditions, DeepSupp addresses critical gaps in SR level detection, offering a scalable and reliable solution for modern financial analysis. Our approach highlights the potential of attention-based architectures to uncover nuanced market patterns and improve technical trading strategies.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01971",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Training and Finetuning Embedding Models with Sentence Transformers v3",
    "description": "",
    "summary": "Training and Finetuning Embedding Models with Sentence Transformers v3 Sentence Transformers is a Py...",
    "pubDate": "Tue, 28 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-sentence-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "Introducing data residency in Europe",
    "description": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "summary": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "pubDate": "Wed, 05 Feb 2025 22:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-data-residency-in-europe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI LP",
    "description": "We‚Äôve created OpenAI LP, a new ‚Äúcapped-profit‚Äù company that allows us to rapidly increase our investments in compute and talent while including checks and balances to actualize our mission.",
    "summary": "We‚Äôve created OpenAI LP, a new ‚Äúcapped-profit‚Äù company that allows us to rapidly increase our investments in compute and talent while including checks and balances to actualize our mission.",
    "pubDate": "Mon, 11 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-lp",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Genie 2: A large-scale foundation world model",
    "description": "Generating unlimited diverse training environments for future general agents",
    "summary": "Generating unlimited diverse training environments for future general agents",
    "pubDate": "Wed, 04 Dec 2024 14:23:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/",
    "thumbnail": "https://lh3.googleusercontent.com/wvcJdqh_wddVc-WiMGgcqe7nWp7Ybu0wd-PBDxC_VUQkfxI7HPfQz3fi_HyYTOoRM_XV3Bofp9l1wBZ1CJPZPG6yZMdZxqH8X7_Lb9nhVAquAul1=w1200-h630-n-nu"
  },
  {
    "title": "BERT 101 ü§ó State Of The Art NLP Model Explained",
    "description": "",
    "summary": "BERT 101 ü§ó State Of The Art NLP Model Explained What is BERT? BERT, short for Bidirectional Encoder ...",
    "pubDate": "Wed, 02 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-101",
    "thumbnail": "https://huggingface.co/blog/assets/52_bert_101/thumbnail.jpg"
  },
  {
    "title": "Generate videos in Gemini and Whisk with Veo 2",
    "description": "Transform text-based prompts into high-resolution eight-second videos in Gemini Advanced and use Whisk Animate to turn images into eight-second animated clips.",
    "summary": "Transform text-based prompts into high-resolution eight-second videos in Gemini Advanced and use Whisk Animate to turn images into eight-second animated clips.",
    "pubDate": "Tue, 15 Apr 2025 17:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/generate-videos-in-gemini-and-whisk-with-veo-2/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GenerateVideos_Static1_1920x1080.width-1300.png"
  },
  {
    "title": "What AI‚Äôs impact on individuals means for the health workforce and industry",
    "description": "<p>Ethan Mollick and Azeem Azhar, thought leaders at the forefront of AI‚Äôs influence on work, education, and society, discuss the impact of AI at the individual level and what that means for the healthcare workforce and the organizations and systems in medicine.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/'>What AI&#8217;s impact on individuals means for the health workforce and industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Ethan Mollick and Azeem Azhar, thought leaders at the forefront of AI‚Äôs influence on work, education, and society, discuss the impact of AI at the individual level and what that means for the healthcare workforce and the organizations and systems in medicine.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/'>What AI&#8217;s impact on individuals means for the health workforce and industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 29 May 2025 15:13:48 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Transferrable Surrogates in Expressive Neural Architecture Search Spaces",
    "description": "arXiv:2504.12971v3 Announce Type: replace-cross Abstract: Neural architecture search (NAS) faces a challenge in balancing the exploration of expressive, broad search spaces that enable architectural innovation with the need for efficient evaluation of architectures to effectively search such spaces. We investigate surrogate model training for improving search in highly expressive NAS search spaces based on context-free grammars. We show that i) surrogate models trained either using zero-cost-proxy metrics and neural graph features (GRAF) or by fine-tuning an off-the-shelf LM have high predictive power for the performance of architectures both within and across datasets, ii) these surrogates can be used to filter out bad architectures when searching on novel datasets, thereby significantly speeding up search and achieving better final performances, and iii) the surrogates can be further used directly as the search objective for huge speed-ups.",
    "summary": "arXiv:2504.12971v3 Announce Type: replace-cross Abstract: Neural architecture search (NAS) faces a challenge in balancing the exploration of expressive, broad search spaces that enable architectural innovation with the need for efficient evaluation of architectures to effectively search such spaces. We investigate surrogate model training for improving search in highly expressive NAS search spaces based on context-free grammars. We show that i) surrogate models trained either using zero-cost-proxy metrics and neural graph features (GRAF) or by fine-tuning an off-the-shelf LM have high predictive power for the performance of architectures both within and across datasets, ii) these surrogates can be used to filter out bad architectures when searching on novel datasets, thereby significantly speeding up search and achieving better final performances, and iii) the surrogates can be further used directly as the search objective for huge speed-ups.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.12971",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Powering virtual education for the classroom",
    "description": "Khan Academy explores the potential for GPT-4 in a limited pilot program.",
    "summary": "Khan Academy explores the potential for GPT-4 in a limited pilot program.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/khan-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reimagining the email experience with AI",
    "description": "Superhuman introduces a new era of email with OpenAI.",
    "summary": "Superhuman introduces a new era of email with OpenAI.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/superhuman",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fixing Open LLM Leaderboard with Math-Verify",
    "description": "",
    "summary": "Fixing Open LLM Leaderboard with Math-Verify 3 weeks ago, we showed how hard it is to correctly eval...",
    "pubDate": "Fri, 14 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/math_verify_leaderboard",
    "thumbnail": "https://huggingface.co/blog/assets/math_verify_leaderboard/thumbnail.png"
  },
  {
    "title": "Training Stable Diffusion with Dreambooth using üß® Diffusers",
    "description": "",
    "summary": "Training Stable Diffusion with Dreambooth using üß® Diffusers Dreambooth is a technique to teach new c...",
    "pubDate": "Mon, 07 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dreambooth",
    "thumbnail": "https://huggingface.co/blog/assets/sd_dreambooth_training/thumbnail.jpg"
  },
  {
    "title": "AI-written critiques help humans notice flaws",
    "description": "We trained ‚Äúcritique-writing‚Äù models to describe flaws in summaries. Human evaluators find flaws in summaries much more often when shown our model‚Äôs critiques. Larger models are better at self-critiquing, with scale improving critique-writing more than summary-writing. This shows promise for using AI systems to assist human supervision of AI systems on difficult¬†tasks.",
    "summary": "We trained ‚Äúcritique-writing‚Äù models to describe flaws in summaries. Human evaluators find flaws in summaries much more often when shown our model‚Äôs critiques. Larger models are better at self-critiquing, with scale improving critique-writing more than summary-writing. This shows promise for using AI systems to assist human supervision of AI systems on difficult¬†tasks.",
    "pubDate": "Mon, 13 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/critiques",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New method efficiently safeguards sensitive AI training data",
    "description": "The approach maintains an AI model‚Äôs accuracy while ensuring attackers can‚Äôt extract secret information.",
    "summary": "The approach maintains an AI model‚Äôs accuracy while ensuring attackers can‚Äôt extract secret information.",
    "pubDate": "Fri, 11 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-method-efficiently-safeguards-sensitive-ai-training-data-0411",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Private-Algorithm-01-press.jpg"
  },
  {
    "title": "Here‚Äôs the next cohort of the Google.org Accelerator: Generative AI",
    "description": "A collage of photos showing people using technology around the world, on a white background",
    "summary": "A collage of photos showing people using technology around the world, on a white background",
    "pubDate": "Mon, 09 Jun 2025 14:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/google-org/generative-ai-accelerator-cohort-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gen_AI_Accelerator_ss.width-1300.png"
  },
  {
    "title": "Delving into LLM-assisted writing in biomedical publications through excess vocabulary",
    "description": "arXiv:2406.07016v5 Announce Type: replace-cross Abstract: Large language models (LLMs) like ChatGPT can generate and revise text with human-level performance. These models come with clear limitations: they can produce inaccurate information, reinforce existing biases, and be easily misused. Yet, many scientists use them for their scholarly writing. But how wide-spread is such LLM usage in the academic literature? To answer this question for the field of biomedical research, we present an unbiased, large-scale approach: we study vocabulary changes in over 15 million biomedical abstracts from 2010--2024 indexed by PubMed, and show how the appearance of LLMs led to an abrupt increase in the frequency of certain style words. This excess word analysis suggests that at least 13.5% of 2024 abstracts were processed with LLMs. This lower bound differed across disciplines, countries, and journals, reaching 40% for some subcorpora. We show that LLMs have had an unprecedented impact on scientific writing in biomedical research, surpassing the effect of major world events such as the Covid pandemic.",
    "summary": "arXiv:2406.07016v5 Announce Type: replace-cross Abstract: Large language models (LLMs) like ChatGPT can generate and revise text with human-level performance. These models come with clear limitations: they can produce inaccurate information, reinforce existing biases, and be easily misused. Yet, many scientists use them for their scholarly writing. But how wide-spread is such LLM usage in the academic literature? To answer this question for the field of biomedical research, we present an unbiased, large-scale approach: we study vocabulary changes in over 15 million biomedical abstracts from 2010--2024 indexed by PubMed, and show how the appearance of LLMs led to an abrupt increase in the frequency of certain style words. This excess word analysis suggests that at least 13.5% of 2024 abstracts were processed with LLMs. This lower bound differed across disciplines, countries, and journals, reaching 40% for some subcorpora. We show that LLMs have had an unprecedented impact on scientific writing in biomedical research, surpassing the effect of major world events such as the Covid pandemic.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.07016",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub",
    "description": "",
    "summary": "Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub Huggy Lingo...",
    "pubDate": "Wed, 02 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggy-lingo",
    "thumbnail": "https://huggingface.co/blog/huggy-lingo/blog/assets/156_huggylingo/Huggy_Lingo.png"
  },
  {
    "title": "Open Source Developers Guide to the EU AI Act",
    "description": "",
    "summary": "Open Source Developers Guide to the EU AI Act The EU AI Act, the world‚Äôs first comprehensive legisla...",
    "pubDate": "Mon, 02 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eu-ai-act-for-oss-developers",
    "thumbnail": "https://huggingface.co/blog/assets/189_eu-ai-act-for-oss-developers/thumbnail.png"
  },
  {
    "title": "Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition ü§ñ",
    "description": "",
    "summary": "Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition ü§ñ Simon Alibert and R√©...",
    "pubDate": "Mon, 14 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-pollen-robotics-acquisition",
    "thumbnail": "https://huggingface.co/blog/assets/hugging-face-pollen-robotics-acquisition/hf-pollen.png"
  },
  {
    "title": "Introducing our new pricing",
    "description": "",
    "summary": "Introducing our new pricing As you might have noticed, our pricing page has changed a lot recently. ...",
    "pubDate": "Tue, 08 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pricing-update",
    "thumbnail": "https://huggingface.co/blog/assets/114_pricing-update/thumbnail.png"
  },
  {
    "title": "Bertelsmann powers creativity and productivity with OpenAI",
    "description": "Bertelsmann, the global media, services, and education company headquartered in Germany, will integrate OpenAI‚Äôs technology across multiple brands around the world.",
    "summary": "Bertelsmann, the global media, services, and education company headquartered in Germany, will integrate OpenAI‚Äôs technology across multiple brands around the world.",
    "pubDate": "Wed, 22 Jan 2025 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bertelsmann-powers-creativity-and-productivity-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "üß® Diffusers welcomes Stable Diffusion 3",
    "description": "",
    "summary": "üß® Diffusers welcomes Stable Diffusion 3 Stable Diffusion 3 (SD3), Stability AI‚Äôs latest iteration of...",
    "pubDate": "Wed, 12 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd3",
    "thumbnail": "https://huggingface.co/blog/assets/sd3/thumbnail.png"
  },
  {
    "title": "Block-sparse GPU kernels",
    "description": "We‚Äôre releasing highly-optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights. Depending on the chosen sparsity, these kernels can run orders of magnitude faster than cuBLAS or cuSPARSE. We‚Äôve used them to attain state-of-the-art results in text sentiment analysis and generative modeling of text and images.",
    "summary": "We‚Äôre releasing highly-optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights. Depending on the chosen sparsity, these kernels can run orders of magnitude faster than cuBLAS or cuSPARSE. We‚Äôve used them to attain state-of-the-art results in text sentiment analysis and generative modeling of text and images.",
    "pubDate": "Wed, 06 Dec 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/block-sparse-gpu-kernels",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An Introduction to Deep Reinforcement Learning",
    "description": "",
    "summary": "An Introduction to Deep Reinforcement Learning Deep Reinforcement Learning Class with Hugging Face ü§ó...",
    "pubDate": "Wed, 04 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-intro",
    "thumbnail": "https://huggingface.co/blog/assets/63_deep_rl_intro/thumbnail.png"
  },
  {
    "title": "Reducing bias and improving safety in DALL¬∑E 2",
    "description": "Today, we are implementing a new technique so that DALL¬∑E generates images of people that more accurately reflect the diversity of the world‚Äôs population.",
    "summary": "Today, we are implementing a new technique so that DALL¬∑E generates images of people that more accurately reflect the diversity of the world‚Äôs population.",
    "pubDate": "Mon, 18 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Delivering contextual job matching for millions with OpenAI",
    "description": "Indeed, whose mission is to help people get jobs, is the world‚Äôs #1 job site. Over 350 million unique visitors come to Indeed every month to connect with more than 3.5 million employers and over 32 million jobs. But what‚Äôs more is that every three seconds someone gets hired on Indeed.",
    "summary": "Indeed, whose mission is to help people get jobs, is the world‚Äôs #1 job site. Over 350 million unique visitors come to Indeed every month to connect with more than 3.5 million employers and over 32 million jobs. But what‚Äôs more is that every three seconds someone gets hired on Indeed.",
    "pubDate": "Thu, 15 Aug 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/indeed",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving mathematical reasoning with process supervision",
    "description": "We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (‚Äúprocess supervision‚Äù) instead of simply rewarding the correct final answer (‚Äúoutcome supervision‚Äù). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.",
    "summary": "We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (‚Äúprocess supervision‚Äù) instead of simply rewarding the correct final answer (‚Äúoutcome supervision‚Äù). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.",
    "pubDate": "Wed, 31 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-mathematical-reasoning-with-process-supervision",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Run ComfyUI workflows for free on Spaces",
    "description": "",
    "summary": "Run ComfyUI workflows for free with Gradio on Hugging Face Spaces Index: - Intro - Exporting your Co...",
    "pubDate": "Sun, 14 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/run-comfyui-workflows-on-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/comfyui-to-gradio/cover.png"
  },
  {
    "title": "Learning how to predict rare kinds of failures",
    "description": "Researchers are developing algorithms to predict failures when automation meets the real world in areas like air traffic scheduling or autonomous vehicles.",
    "summary": "Researchers are developing algorithms to predict failures when automation meets the real world in areas like air traffic scheduling or autonomous vehicles.",
    "pubDate": "Wed, 21 May 2025 16:35:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/learning-how-predict-rare-kinds-failures-0521",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-rare-event-modeling.jpg"
  },
  {
    "title": "Privacy-Preserving Operating Room Workflow Analysis using Digital Twins",
    "description": "arXiv:2504.12552v2 Announce Type: replace-cross Abstract: The operating room (OR) is a complex environment where optimizing workflows is critical to reduce costs and improve patient outcomes. While computer vision approaches for automatic recognition of perioperative events can identify bottlenecks for OR optimization, privacy concerns limit the use of OR videos for automated event detection. We propose a two-stage pipeline for privacy-preserving OR video analysis and event detection. First, we leverage vision foundation models for depth estimation and semantic segmentation to generate de-identified Digital Twins (DT) of the OR from conventional RGB videos. Second, we employ the SafeOR model, a fused two-stream approach that processes segmentation masks and depth maps for OR event detection. Evaluation on an internal dataset of 38 simulated surgical trials with five event classes shows that our DT-based approach achieves performance on par with -- and sometimes better than -- raw RGB video-based models for OR event detection. Digital Twins enable privacy-preserving OR workflow analysis, facilitating the sharing of de-identified data across institutions and potentially enhancing model generalizability by mitigating domain-specific appearance differences.",
    "summary": "arXiv:2504.12552v2 Announce Type: replace-cross Abstract: The operating room (OR) is a complex environment where optimizing workflows is critical to reduce costs and improve patient outcomes. While computer vision approaches for automatic recognition of perioperative events can identify bottlenecks for OR optimization, privacy concerns limit the use of OR videos for automated event detection. We propose a two-stage pipeline for privacy-preserving OR video analysis and event detection. First, we leverage vision foundation models for depth estimation and semantic segmentation to generate de-identified Digital Twins (DT) of the OR from conventional RGB videos. Second, we employ the SafeOR model, a fused two-stream approach that processes segmentation masks and depth maps for OR event detection. Evaluation on an internal dataset of 38 simulated surgical trials with five event classes shows that our DT-based approach achieves performance on par with -- and sometimes better than -- raw RGB video-based models for OR event detection. Digital Twins enable privacy-preserving OR workflow analysis, facilitating the sharing of de-identified data across institutions and potentially enhancing model generalizability by mitigating domain-specific appearance differences.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.12552",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Announcing our new Content Guidelines and Policy",
    "description": "",
    "summary": "Announcing our new Community Policy As a community-driven platform that aims to advance Open, Collab...",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/content-guidelines-update",
    "thumbnail": "https://huggingface.co/blog/assets/content-guidelines-blogpost/thumbnail.png"
  },
  {
    "title": "Quantifying generalization in reinforcement learning",
    "description": "We‚Äôre releasing CoinRun, a training environment which provides a metric for an agent‚Äôs ability to transfer its experience to novel situations and has already helped clarify a¬†longstanding¬†puzzle¬†in reinforcement learning. CoinRun strikes a desirable balance in complexity: the environment is simpler than traditional platformer games like Sonic the Hedgehog but still poses a worthy generalization challenge for state of the art¬†algorithms.",
    "summary": "We‚Äôre releasing CoinRun, a training environment which provides a metric for an agent‚Äôs ability to transfer its experience to novel situations and has already helped clarify a¬†longstanding¬†puzzle¬†in reinforcement learning. CoinRun strikes a desirable balance in complexity: the environment is simpler than traditional platformer games like Sonic the Hedgehog but still poses a worthy generalization challenge for state of the art¬†algorithms.",
    "pubDate": "Thu, 06 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/quantifying-generalization-in-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "nanoVLM: The simplest repository to train your VLM in pure PyTorch",
    "description": "",
    "summary": "nanoVLM: The simplest repository to train your VLM in pure PyTorch nanoVLM is the simplest way to ge...",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nanovlm",
    "thumbnail": "https://huggingface.co/blog/assets/nanovlm/thumbnail.png"
  },
  {
    "title": "Scaling Kubernetes to 2,500 nodes",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 18 Jan 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-kubernetes-to-2500-nodes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FastRTC„Çí‰Ωø„Å£„Å¶ÁàÜÈÄü„ÅßVoicebot„ÇíÊßãÁØâ„Åô„Çã",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØPython„Åß„É™„Ç¢„É´„Çø„Ç§„É†„Å™AI„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Çí‰Ωú„ÇãÈöõ„Å´ÂΩπÁ´ã„Å§„É©„Ç§„Éñ„É©„É™„ÄÅFastRTC„Çí‰Ωø„Å£„Å¶Á∞°Âçò„Å™Voicebot„ÇíÊßãÁØâ„Åó„Å¶„Åø„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ FastRTC FastRT [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5680' rel='nofollow'>FastRTC„Çí‰Ωø„Å£„Å¶ÁàÜÈÄü„ÅßVoicebot„ÇíÊßãÁØâ„Åô„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØPython„Åß„É™„Ç¢„É´„Çø„Ç§„É†„Å™AI„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Çí‰Ωú„ÇãÈöõ„Å´ÂΩπÁ´ã„Å§„É©„Ç§„Éñ„É©„É™„ÄÅFastRTC„Çí‰Ωø„Å£„Å¶Á∞°Âçò„Å™Voicebot„ÇíÊßãÁØâ„Åó„Å¶„Åø„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ FastRTC FastRT [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5680' rel='nofollow'>FastRTC„Çí‰Ωø„Å£„Å¶ÁàÜÈÄü„ÅßVoicebot„ÇíÊßãÁØâ„Åô„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Wed, 16 Apr 2025 00:41:50 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5680",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/f81fd2e4c52864042852c112ce927ae2.png"
  },
  {
    "title": "Using GPT-4 for content moderation",
    "description": "We use GPT-4 for content policy development and content moderation decisions, enabling more consistent labeling, a faster feedback loop for policy refinement, and less involvement from human moderators.",
    "summary": "We use GPT-4 for content policy development and content moderation decisions, enabling more consistent labeling, a faster feedback loop for policy refinement, and less involvement from human moderators.",
    "pubDate": "Tue, 15 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/using-gpt-4-for-content-moderation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DALL¬∑E 3 is now available in ChatGPT Plus and Enterprise",
    "description": "We developed a safety mitigation stack to ready DALL¬∑E 3 for wider release and are sharing updates on our provenance research.",
    "summary": "We developed a safety mitigation stack to ready DALL¬∑E 3 for wider release and are sharing updates on our provenance research.",
    "pubDate": "Thu, 19 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Leadership updates",
    "description": "OpenAI has grown a lot. We remain focused on the same core‚Äîpursuing frontier AI research that accelerates human progress‚Äìbut we now also deliver products used by hundreds of millions of people.",
    "summary": "OpenAI has grown a lot. We remain focused on the same core‚Äîpursuing frontier AI research that accelerates human progress‚Äìbut we now also deliver products used by hundreds of millions of people.",
    "pubDate": "Mon, 24 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-updates-march-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A generalist AI agent for 3D virtual environments",
    "description": "Introducing SIMA, a Scalable Instructable Multiworld Agent",
    "summary": "Introducing SIMA, a Scalable Instructable Multiworld Agent",
    "pubDate": "Wed, 13 Mar 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/",
    "thumbnail": "https://lh3.googleusercontent.com/2GNumOaJCB48RQIFbwJmmZro-AFdBebufxvY_ZkSdUs9RQ-0nSTgBMXuhUdIE5zpPknqevL4ZyP44PLOpJlg0U0ArlOCcJHfoOagzSnZZoXLnq7hdQ=w1200-h630-n-nu"
  },
  {
    "title": "StepHint: Multi-level Stepwise Hints Enhance Reinforcement Learning to Reason",
    "description": "arXiv:2507.02841v1 Announce Type: new Abstract: Reinforcement learning with verifiable rewards (RLVR) is a promising approach for improving the complex reasoning abilities of large language models (LLMs). However, current RLVR methods face two significant challenges: the near-miss reward problem, where a small mistake can invalidate an otherwise correct reasoning process, greatly hindering training efficiency; and exploration stagnation, where models tend to focus on solutions within their ``comfort zone,'' lacking the motivation to explore potentially more effective alternatives. To address these challenges, we propose StepHint, a novel RLVR algorithm that utilizes multi-level stepwise hints to help models explore the solution space more effectively. StepHint generates valid reasoning chains from stronger models and partitions these chains into reasoning steps using our proposed adaptive partitioning method. The initial few steps are used as hints, and simultaneously, multiple-level hints (each comprising a different number of steps) are provided to the model. This approach directs the model's exploration toward a promising solution subspace while preserving its flexibility for independent exploration. By providing hints, StepHint mitigates the near-miss reward problem, thereby improving training efficiency. Additionally, the external reasoning pathways help the model develop better reasoning abilities, enabling it to move beyond its ``comfort zone'' and mitigate exploration stagnation. StepHint outperforms competitive RLVR enhancement methods across six mathematical benchmarks, while also demonstrating superior generalization and excelling over baselines on out-of-domain benchmarks.",
    "summary": "arXiv:2507.02841v1 Announce Type: new Abstract: Reinforcement learning with verifiable rewards (RLVR) is a promising approach for improving the complex reasoning abilities of large language models (LLMs). However, current RLVR methods face two significant challenges: the near-miss reward problem, where a small mistake can invalidate an otherwise correct reasoning process, greatly hindering training efficiency; and exploration stagnation, where models tend to focus on solutions within their ``comfort zone,'' lacking the motivation to explore potentially more effective alternatives. To address these challenges, we propose StepHint, a novel RLVR algorithm that utilizes multi-level stepwise hints to help models explore the solution space more effectively. StepHint generates valid reasoning chains from stronger models and partitions these chains into reasoning steps using our proposed adaptive partitioning method. The initial few steps are used as hints, and simultaneously, multiple-level hints (each comprising a different number of steps) are provided to the model. This approach directs the model's exploration toward a promising solution subspace while preserving its flexibility for independent exploration. By providing hints, StepHint mitigates the near-miss reward problem, thereby improving training efficiency. Additionally, the external reasoning pathways help the model develop better reasoning abilities, enabling it to move beyond its ``comfort zone'' and mitigate exploration stagnation. StepHint outperforms competitive RLVR enhancement methods across six mathematical benchmarks, while also demonstrating superior generalization and excelling over baselines on out-of-domain benchmarks.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02841",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Global news partnerships: Le Monde and Prisa Media",
    "description": "We have partnered with international news organizations Le Monde and Prisa Media to bring French and Spanish news content to ChatGPT.",
    "summary": "We have partnered with international news organizations Le Monde and Prisa Media to bring French and Spanish news content to ChatGPT.",
    "pubDate": "Wed, 13 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/global-news-partnerships-le-monde-and-prisa-media",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating SD Turbo and SDXL Turbo Inference with ONNX Runtime and Olive",
    "description": "",
    "summary": "Accelerating SD Turbo and SDXL Turbo Inference with ONNX Runtime and Olive Introduction SD Turbo and...",
    "pubDate": "Mon, 15 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_ort_inference",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_onnxruntime-training/thumbnail.png"
  },
  {
    "title": "Empowering defenders through our Cybersecurity Grant Program",
    "description": "Highlighting innovative research and AI integration in cybersecurity",
    "summary": "Highlighting innovative research and AI integration in cybersecurity",
    "pubDate": "Thu, 20 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/empowering-defenders-through-our-cybersecurity-grant-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Threat Modeling for AI: The Case for an Asset-Centric Approach",
    "description": "arXiv:2505.06315v2 Announce Type: replace-cross Abstract: Recent advances in AI are transforming AI's ubiquitous presence in our world from that of standalone AI-applications into deeply integrated AI-agents. These changes have been driven by agents' increasing capability to autonomously make decisions and initiate actions, using existing applications; whether those applications are AI-based or not. This evolution enables unprecedented levels of AI integration, with agents now able to take actions on behalf of systems and users -- including, in some cases, the powerful ability for the AI to write and execute scripts as it deems necessary. With AI systems now able to autonomously execute code, interact with external systems, and operate without human oversight, traditional security approaches fall short. This paper introduces an asset-centric methodology for threat modeling AI systems that addresses the unique security challenges posed by integrated AI agents. Unlike existing top-down frameworks that analyze individual attacks within specific product contexts, our bottom-up approach enables defenders to systematically identify how vulnerabilities -- both conventional and AI-specific -- impact critical AI assets across distributed infrastructures used to develop and deploy these agents. This methodology allows security teams to: (1) perform comprehensive analysis that communicates effectively across technical domains, (2) quantify security assumptions about third-party AI components without requiring visibility into their implementation, and (3) holistically identify AI-based vulnerabilities relevant to their specific product context. This approach is particularly relevant for securing agentic systems with complex autonomous capabilities. By focusing on assets rather than attacks, our approach scales with the rapidly evolving threat landscape while accommodating increasingly complex and distributed AI development pipelines.",
    "summary": "arXiv:2505.06315v2 Announce Type: replace-cross Abstract: Recent advances in AI are transforming AI's ubiquitous presence in our world from that of standalone AI-applications into deeply integrated AI-agents. These changes have been driven by agents' increasing capability to autonomously make decisions and initiate actions, using existing applications; whether those applications are AI-based or not. This evolution enables unprecedented levels of AI integration, with agents now able to take actions on behalf of systems and users -- including, in some cases, the powerful ability for the AI to write and execute scripts as it deems necessary. With AI systems now able to autonomously execute code, interact with external systems, and operate without human oversight, traditional security approaches fall short. This paper introduces an asset-centric methodology for threat modeling AI systems that addresses the unique security challenges posed by integrated AI agents. Unlike existing top-down frameworks that analyze individual attacks within specific product contexts, our bottom-up approach enables defenders to systematically identify how vulnerabilities -- both conventional and AI-specific -- impact critical AI assets across distributed infrastructures used to develop and deploy these agents. This methodology allows security teams to: (1) perform comprehensive analysis that communicates effectively across technical domains, (2) quantify security assumptions about third-party AI components without requiring visibility into their implementation, and (3) holistically identify AI-based vulnerabilities relevant to their specific product context. This approach is particularly relevant for securing agentic systems with complex autonomous capabilities. By focusing on assets rather than attacks, our approach scales with the rapidly evolving threat landscape while accommodating increasingly complex and distributed AI development pipelines.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.06315",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How Hugging Face Scaled Secrets Management for AI Infrastructure",
    "description": "",
    "summary": "How Hugging Face Scaled Secrets Management for AI Infrastructure Hugging Face has become synonymous ...",
    "pubDate": "Mon, 31 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/scaling-secrets-management",
    "thumbnail": "https://huggingface.co/blog/assets/infisical/thumbnail.png"
  },
  {
    "title": "Powerful ASR + diarization + speculative decoding with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Powerful ASR + diarization + speculative decoding with Hugging Face Inference Endpoints Whisper is o...",
    "pubDate": "Wed, 01 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/asr-diarization",
    "thumbnail": "https://huggingface.co/blog/assets/asr-diarization/thumbnail.png"
  },
  {
    "title": "Introducing Whisper",
    "description": "We‚Äôve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech¬†recognition.",
    "summary": "We‚Äôve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech¬†recognition.",
    "pubDate": "Wed, 21 Sep 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/whisper",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI standardizes on PyTorch",
    "description": "We are standardizing OpenAI‚Äôs deep learning framework on¬†PyTorch.",
    "summary": "We are standardizing OpenAI‚Äôs deep learning framework on¬†PyTorch.",
    "pubDate": "Thu, 30 Jan 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-pytorch",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Inroads to personalized AI trip planning",
    "description": "A new framework from the MIT-IBM Watson AI Lab supercharges language models, so they can reason over, interactively develop, and verify valid, complex travel agendas.",
    "summary": "A new framework from the MIT-IBM Watson AI Lab supercharges language models, so they can reason over, interactively develop, and verify valid, complex travel agendas.",
    "pubDate": "Tue, 10 Jun 2025 15:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/inroads-personalized-ai-trip-planning-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-watson-travel-planning.jpg"
  },
  {
    "title": "The San Antonio Spurs use ChatGPT to scale impact on and off the court",
    "description": "Discover how the San Antonio Spurs are using custom GPTs to enhance fan engagement, streamline operations, and drive innovation across teams.",
    "summary": "Discover how the San Antonio Spurs are using custom GPTs to enhance fan engagement, streamline operations, and drive innovation across teams.",
    "pubDate": "Wed, 07 May 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/san-antonio-spurs",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Attacking machine learning with adversarial examples",
    "description": "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they‚Äôre like optical illusions for machines. In this post we‚Äôll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult.",
    "summary": "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they‚Äôre like optical illusions for machines. In this post we‚Äôll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult.",
    "pubDate": "Fri, 24 Feb 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/attacking-machine-learning-with-adversarial-examples",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench",
    "description": "arXiv:2507.02554v1 Announce Type: new Abstract: AI research agents are demonstrating great potential to accelerate scientific progress by automating the design, implementation, and training of machine learning models. We focus on methods for improving agents' performance on MLE-bench, a challenging benchmark where agents compete in Kaggle competitions to solve real-world machine learning problems. We formalize AI research agents as search policies that navigate a space of candidate solutions, iteratively modifying them using operators. By designing and systematically varying different operator sets and search policies (Greedy, MCTS, Evolutionary), we show that their interplay is critical for achieving high performance. Our best pairing of search strategy and operator set achieves a state-of-the-art result on MLE-bench lite, increasing the success rate of achieving a Kaggle medal from 39.6% to 47.7%. Our investigation underscores the importance of jointly considering the search strategy, operator design, and evaluation methodology in advancing automated machine learning.",
    "summary": "arXiv:2507.02554v1 Announce Type: new Abstract: AI research agents are demonstrating great potential to accelerate scientific progress by automating the design, implementation, and training of machine learning models. We focus on methods for improving agents' performance on MLE-bench, a challenging benchmark where agents compete in Kaggle competitions to solve real-world machine learning problems. We formalize AI research agents as search policies that navigate a space of candidate solutions, iteratively modifying them using operators. By designing and systematically varying different operator sets and search policies (Greedy, MCTS, Evolutionary), we show that their interplay is critical for achieving high performance. Our best pairing of search strategy and operator set achieves a state-of-the-art result on MLE-bench lite, increasing the success rate of achieving a Kaggle medal from 39.6% to 47.7%. Our investigation underscores the importance of jointly considering the search strategy, operator design, and evaluation methodology in advancing automated machine learning.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02554",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face Selected for the French Data Protection Agency Enhanced Support Program",
    "description": "",
    "summary": "Hugging Face Selected for the French Data Protection Agency Enhanced Support Program This blog post ...",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cnil",
    "thumbnail": "https://huggingface.co/blog/assets/146_cnil-accompaniment/logo.png"
  },
  {
    "title": "OpenAI o3-mini",
    "description": "Pushing the frontier of cost-effective reasoning.",
    "summary": "Pushing the frontier of cost-effective reasoning.",
    "pubDate": "Fri, 31 Jan 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o3-mini",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Looking ahead to the AI Seoul Summit",
    "description": "How summits in Seoul, France and beyond can galvanize international cooperation on frontier AI safety",
    "summary": "How summits in Seoul, France and beyond can galvanize international cooperation on frontier AI safety",
    "pubDate": "Mon, 20 May 2024 07:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/looking-ahead-to-the-ai-seoul-summit/",
    "thumbnail": "https://lh3.googleusercontent.com/LuT46lyRujmyyTlxwixL9_e8LKvzqZOGUyQUAFbTO6POaYlAqWYfEMag39UkZGsZhjs3SmW3V-s0dCjK4_81jpezAzL7c6kXuTY2MhXbv5yR4NDG8Q=w1200-h630-n-nu"
  },
  {
    "title": "How should AI systems behave, and who should decide?",
    "description": "We‚Äôre clarifying how ChatGPT‚Äôs behavior is shaped and our plans for improving that behavior, allowing more user customization, and getting more public input into our decision-making in these¬†areas.",
    "summary": "We‚Äôre clarifying how ChatGPT‚Äôs behavior is shaped and our plans for improving that behavior, allowing more user customization, and getting more public input into our decision-making in these¬†areas.",
    "pubDate": "Thu, 16 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-should-ai-systems-behave",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Google releases Gemma 2 2B, ShieldGemma and Gemma Scope",
    "description": "",
    "summary": "Google releases Gemma 2 2B, ShieldGemma and Gemma Scope One month after the release of Gemma 2, Goog...",
    "pubDate": "Wed, 31 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma-july-update",
    "thumbnail": "https://huggingface.co/blog/assets/gemma-july-update/thumbnail.jpg"
  },
  {
    "title": "Welcome PaddlePaddle to the Hugging Face Hub",
    "description": "",
    "summary": "Welcome PaddlePaddle to the Hugging Face Hub We are happy to share an open source collaboration betw...",
    "pubDate": "Tue, 17 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paddlepaddle",
    "thumbnail": "https://huggingface.co/blog/assets/126_paddlepaddle/thumbnail.jpg"
  },
  {
    "title": "ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning",
    "description": "arXiv:2507.02666v1 Announce Type: cross Abstract: In recent advancements in audio self-supervised representation learning, the standard Transformer architecture has emerged as the predominant approach, yet its attention mechanism often allocates a portion of attention weights to irrelevant information, potentially impairing the model's discriminative ability. To address this, we introduce a differential attention mechanism, which effectively mitigates ineffective attention allocation through the integration of dual-softmax operations and appropriately tuned differential coefficients. Experimental results demonstrate that our ASDA model achieves state-of-the-art (SOTA) performance across multiple benchmarks, including audio classification (49.0% mAP on AS-2M, 41.5% mAP on AS20K), keyword spotting (98.3% accuracy on SPC-2), and environmental sound classification (96.1% accuracy on ESC-50). These results highlight ASDA's effectiveness in audio tasks, paving the way for broader applications.",
    "summary": "arXiv:2507.02666v1 Announce Type: cross Abstract: In recent advancements in audio self-supervised representation learning, the standard Transformer architecture has emerged as the predominant approach, yet its attention mechanism often allocates a portion of attention weights to irrelevant information, potentially impairing the model's discriminative ability. To address this, we introduce a differential attention mechanism, which effectively mitigates ineffective attention allocation through the integration of dual-softmax operations and appropriately tuned differential coefficients. Experimental results demonstrate that our ASDA model achieves state-of-the-art (SOTA) performance across multiple benchmarks, including audio classification (49.0% mAP on AS-2M, 41.5% mAP on AS20K), keyword spotting (98.3% accuracy on SPC-2), and environmental sound classification (96.1% accuracy on ESC-50). These results highlight ASDA's effectiveness in audio tasks, paving the way for broader applications.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02666",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue",
    "description": "arXiv:2507.02537v1 Announce Type: cross Abstract: Conversational agents have made significant progress since ELIZA, expanding their role across various domains, including healthcare, education, and customer service. As these agents become increasingly integrated into daily human interactions, the need for emotional intelligence, particularly empathetic listening, becomes increasingly essential. In this study, we explore how Large Language Models (LLMs) respond when tasked with generating emotionally rich interactions. Starting from a small dataset manually crafted by an expert to reflect empathic behavior, we extended the conversations using two LLMs: ChatGPT and Gemini. We analyzed the emotional progression of the dialogues using both sentiment analysis (via VADER) and expert assessments. While the generated conversations often mirrored the intended emotional structure, human evaluation revealed important differences in the perceived empathy and coherence of the responses. These findings suggest that emotion modeling in dialogues requires not only structural alignment in the expressed emotions but also qualitative depth, highlighting the importance of combining automated and humancentered methods in the development of emotionally competent agents.",
    "summary": "arXiv:2507.02537v1 Announce Type: cross Abstract: Conversational agents have made significant progress since ELIZA, expanding their role across various domains, including healthcare, education, and customer service. As these agents become increasingly integrated into daily human interactions, the need for emotional intelligence, particularly empathetic listening, becomes increasingly essential. In this study, we explore how Large Language Models (LLMs) respond when tasked with generating emotionally rich interactions. Starting from a small dataset manually crafted by an expert to reflect empathic behavior, we extended the conversations using two LLMs: ChatGPT and Gemini. We analyzed the emotional progression of the dialogues using both sentiment analysis (via VADER) and expert assessments. While the generated conversations often mirrored the intended emotional structure, human evaluation revealed important differences in the perceived empathy and coherence of the responses. These findings suggest that emotion modeling in dialogues requires not only structural alignment in the expressed emotions but also qualitative depth, highlighting the importance of combining automated and humancentered methods in the development of emotionally competent agents.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02537",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Frontier risk and preparedness",
    "description": "To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge.",
    "summary": "To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge.",
    "pubDate": "Thu, 26 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-risk-and-preparedness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Exploring the Daily Papers Page on Hugging Face",
    "description": "",
    "summary": "Exploring the Daily Papers Page on Hugging Face In the fast-paced world of research, staying up-to-d...",
    "pubDate": "Mon, 23 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/daily-papers",
    "thumbnail": "https://huggingface.co/blog/assets/daily-papers/thumbnail.png"
  },
  {
    "title": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "description": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "summary": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "pubDate": "Tue, 14 May 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/collaborating-with-carlyle-to-chart-the-future-of-private-equity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenRAIL: Towards open and responsible AI licensing frameworks",
    "description": "",
    "summary": "OpenRAIL: Towards open and responsible AI licensing frameworks Open & Responsible AI licenses ('Open...",
    "pubDate": "Wed, 31 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open_rail",
    "thumbnail": "https://huggingface.co/blog/assets/100_open_rail/100_open-rail.png"
  },
  {
    "title": "Moving from intent-based bots to proactive AI agents",
    "description": "Moving from intent-based bots to proactive AI agents.",
    "summary": "Moving from intent-based bots to proactive AI agents.",
    "pubDate": "Thu, 27 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zendesk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster fine-tuning using TRL & Unsloth",
    "description": "",
    "summary": "Make LLM Fine-tuning 2x faster with Unsloth and ü§ó TRL Pulling your hair out because LLM fine-tuning ...",
    "pubDate": "Wed, 10 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unsloth-trl",
    "thumbnail": "https://huggingface.co/blog/assets/hf_unsloth/thumbnail.png"
  },
  {
    "title": "AI Policy @ü§ó: Response to the U.S. NTIA's Request for Comment on AI Accountability",
    "description": "",
    "summary": "AI Policy @ü§ó: Response to the U.S. National Telecommunications and Information Administration‚Äôs (NTI...",
    "pubDate": "Tue, 20 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/policy-ntia-rfc",
    "thumbnail": "https://huggingface.co/blog/assets/151_policy_ntia_rfc/us_policy_thumbnail.png"
  },
  {
    "title": "No-code personal agents, powered by GPT-4.1 and Realtime API",
    "description": "Learn how Genspark built a $36M ARR AI product in 45 days‚Äîwith no-code agents powered by GPT-4.1 and OpenAI Realtime API.",
    "summary": "Learn how Genspark built a $36M ARR AI product in 45 days‚Äîwith no-code agents powered by GPT-4.1 and OpenAI Realtime API.",
    "pubDate": "Tue, 01 Jul 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/genspark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation",
    "description": "",
    "summary": "StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation Instruction...",
    "pubDate": "Mon, 29 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sc2-instruct",
    "thumbnail": "https://huggingface.co/blog/assets/sc2-instruct/sc2-instruct-banner.png"
  },
  {
    "title": "How to Build an MCP Server with Gradio",
    "description": "",
    "summary": "How to Build an MCP Server in 5 Lines of Python Gradio is a Python library used by more than 1 milli...",
    "pubDate": "Wed, 30 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-mcp",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-mcp/thumbnail.png"
  },
  {
    "title": "LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans",
    "description": "arXiv:2507.02861v1 Announce Type: cross Abstract: We propose LiteReality, a novel pipeline that converts RGB-D scans of indoor environments into compact, realistic, and interactive 3D virtual replicas. LiteReality not only reconstructs scenes that visually resemble reality but also supports key features essential for graphics pipelines -- such as object individuality, articulation, high-quality physically based rendering materials, and physically based interaction. At its core, LiteReality first performs scene understanding and parses the results into a coherent 3D layout and objects with the help of a structured scene graph. It then reconstructs the scene by retrieving the most visually similar 3D artist-crafted models from a curated asset database. Next, the Material Painting module enhances realism by recovering high-quality, spatially varying materials. Finally, the reconstructed scene is integrated into a simulation engine with basic physical properties to enable interactive behavior. The resulting scenes are compact, editable, and fully compatible with standard graphics pipelines, making them suitable for applications in AR/VR, gaming, robotics, and digital twins. In addition, LiteReality introduces a training-free object retrieval module that achieves state-of-the-art similarity performance on the Scan2CAD benchmark, along with a robust material painting module capable of transferring appearances from images of any style to 3D assets -- even under severe misalignment, occlusion, and poor lighting. We demonstrate the effectiveness of LiteReality on both real-life scans and public datasets. Project page: https://litereality.github.io; Video: https://www.youtube.com/watch?v=ecK9m3LXg2c",
    "summary": "arXiv:2507.02861v1 Announce Type: cross Abstract: We propose LiteReality, a novel pipeline that converts RGB-D scans of indoor environments into compact, realistic, and interactive 3D virtual replicas. LiteReality not only reconstructs scenes that visually resemble reality but also supports key features essential for graphics pipelines -- such as object individuality, articulation, high-quality physically based rendering materials, and physically based interaction. At its core, LiteReality first performs scene understanding and parses the results into a coherent 3D layout and objects with the help of a structured scene graph. It then reconstructs the scene by retrieving the most visually similar 3D artist-crafted models from a curated asset database. Next, the Material Painting module enhances realism by recovering high-quality, spatially varying materials. Finally, the reconstructed scene is integrated into a simulation engine with basic physical properties to enable interactive behavior. The resulting scenes are compact, editable, and fully compatible with standard graphics pipelines, making them suitable for applications in AR/VR, gaming, robotics, and digital twins. In addition, LiteReality introduces a training-free object retrieval module that achieves state-of-the-art similarity performance on the Scan2CAD benchmark, along with a robust material painting module capable of transferring appearances from images of any style to 3D assets -- even under severe misalignment, occlusion, and poor lighting. We demonstrate the effectiveness of LiteReality on both real-life scans and public datasets. Project page: https://litereality.github.io; Video: https://www.youtube.com/watch?v=ecK9m3LXg2c",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02861",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Delivering nuanced insights from customer feedback",
    "description": "Using GPT-3 to deliver fast, nuanced insights from customer feedback.",
    "summary": "Using GPT-3 to deliver fast, nuanced insights from customer feedback.",
    "pubDate": "Wed, 04 Jan 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/yabble",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Visualize and understand GPU memory in PyTorch",
    "description": "",
    "summary": "Visualize and understand GPU memory in PyTorch You must be familiar with this message ü§¨: RuntimeErro...",
    "pubDate": "Tue, 24 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train_memory",
    "thumbnail": "https://huggingface.co/blog/assets/train_memory/thumbnail.png"
  },
  {
    "title": "Watermarking AI-generated text and video with SynthID",
    "description": "Announcing our novel watermarking method for AI-generated text and video, and how we‚Äôre bringing SynthID to key Google products",
    "summary": "Announcing our novel watermarking method for AI-generated text and video, and how we‚Äôre bringing SynthID to key Google products",
    "pubDate": "Tue, 14 May 2024 17:56:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/watermarking-ai-generated-text-and-video-with-synthid/",
    "thumbnail": "https://lh3.googleusercontent.com/I6bH75hNf57977cub27rFEsgxhcmkLrcINfCmGUaBCr7Q1bFTIl552R_6kuqlSkUjRtsTh929u6NoQmtHcwIG-GnjvPqMeynVLY0Rc9RRvezPQS0=w1200-h630-n-nu"
  },
  {
    "title": "Introducing the Data Measurements Tool: an Interactive Tool for Looking at Datasets",
    "description": "",
    "summary": "Introducing the ü§ó Data Measurements Tool: an Interactive Tool for Looking at Datasets tl;dr: We made...",
    "pubDate": "Mon, 29 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/data-measurements-tool",
    "thumbnail": "https://huggingface.co/blog/assets/37_data-measurements-tool/datametrics.png"
  },
  {
    "title": "Creating next-gen characters",
    "description": "Using GPT-3 to create the next generation of AI-powered characters.",
    "summary": "Using GPT-3 to create the next generation of AI-powered characters.",
    "pubDate": "Sun, 01 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/inworld-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ü§ó PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware",
    "description": "",
    "summary": "ü§ó PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware Motivation ...",
    "pubDate": "Fri, 10 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/peft",
    "thumbnail": "https://huggingface.co/blog/assets/130_peft/thumbnail.png"
  },
  {
    "title": "DALL¬∑E now available in beta",
    "description": "We‚Äôll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL¬∑E using free credits that refill every month, and buy additional credits in 115-generation increments for¬†$15.",
    "summary": "We‚Äôll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL¬∑E using free credits that refill every month, and buy additional credits in 115-generation increments for¬†$15.",
    "pubDate": "Wed, 20 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-now-available-in-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Trace & Evaluate your Agent with Arize Phoenix",
    "description": "",
    "summary": "Trace & Evaluate your Agent with Arize Phoenix So, you‚Äôve built your agent. It takes in inputs and t...",
    "pubDate": "Fri, 28 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents-phoenix",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents-phoenix/thumbnail.jpg"
  },
  {
    "title": "RoboCat: A self-improving robotic agent",
    "description": "Robots are quickly becoming part of our everyday lives, but they‚Äôre often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data.¬†Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.",
    "summary": "Robots are quickly becoming part of our everyday lives, but they‚Äôre often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data.¬†Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.",
    "pubDate": "Tue, 20 Jun 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/robocat-a-self-improving-robotic-agent/",
    "thumbnail": "https://lh3.googleusercontent.com/Rz9Xv4TXuTe-eO2UDUD6kDElDB5wDE2b2hEU1liUAi0AyiTwQ81mLMigXg3kueWrHoqeNctRO5-EMprZDRnXcaL8snfqHwDqgQpw_qB3VEvoO_jCCzI=w1200-h630-n-nu"
  },
  {
    "title": "XLSCOUT Unveils ParaEmbed 2.0: a Powerful Embedding Model Tailored for Patents and IP with Expert Support from Hugging Face",
    "description": "",
    "summary": "XLSCOUT Unveils ParaEmbed 2.0: a Powerful Embedding Model Tailored for Patents and IP with Expert Su...",
    "pubDate": "Tue, 25 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xlscout-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/xlscout-case-study/thumbnail.png"
  },
  {
    "title": "GPT-4o System Card",
    "description": "This report outlines the safety work carried out prior to releasing GPT-4o including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "summary": "This report outlines the safety work carried out prior to releasing GPT-4o including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Age of Machine Learning As Code Has Arrived",
    "description": "",
    "summary": "The Age of Machine Learning As Code Has Arrived The 2021 edition of the State of AI Report came out ...",
    "pubDate": "Wed, 20 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the-age-of-ml-as-code",
    "thumbnail": "https://huggingface.co/blog/assets/31_age_of_ml_as_code/05_vision_transformer.png"
  },
  {
    "title": "An Introduction to Q-Learning Part 1",
    "description": "",
    "summary": "An Introduction to Q-Learning Part 1 Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 2, p...",
    "pubDate": "Wed, 18 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-q-part1",
    "thumbnail": "https://huggingface.co/blog/assets/70_deep_rl_q_part1/thumbnail.gif"
  },
  {
    "title": "Sharing the latest Model Spec",
    "description": "We‚Äôve made updates to the Model Spec based on external feedback and our continued research in shaping desired model behavior.",
    "summary": "We‚Äôve made updates to the Model Spec based on external feedback and our continued research in shaping desired model behavior.",
    "pubDate": "Wed, 12 Feb 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sharing-the-latest-model-spec",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Confidence-Building Measures for Artificial Intelligence: Workshop proceedings",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 01 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/confidence-building-measures-for-artificial-intelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GaLore: Advancing Large Model Training on Consumer-grade Hardware",
    "description": "",
    "summary": "GaLore: Advancing Large Model Training on Consumer-grade Hardware The integration of GaLore into the...",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/galore",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "OpenAI o3 and o4-mini System Card",
    "description": "OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities‚Äîweb browsing, Python, image and file analysis, image generation, canvas, automations, file search, and memory.",
    "summary": "OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities‚Äîweb browsing, Python, image and file analysis, image generation, canvas, automations, file search, and memory.",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploying ü§ó ViT on Kubernetes with TF Serving",
    "description": "",
    "summary": "Deploying ü§ó ViT on Kubernetes with TF Serving In the previous post, we showed how to deploy a Vision...",
    "pubDate": "Thu, 11 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-tfserving-kubernetes",
    "thumbnail": "https://huggingface.co/blog/assets/94_tf_serving_kubernetes/thumb.png"
  },
  {
    "title": "SetFit: Efficient Few-Shot Learning Without Prompts",
    "description": "",
    "summary": "SetFit: Efficient Few-Shot Learning Without Prompts SetFit is significantly more sample efficient an...",
    "pubDate": "Mon, 26 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit",
    "thumbnail": "https://huggingface.co/blog/assets/103_setfit/intel_hf_logo.png"
  },
  {
    "title": "Showcase Your Projects in Spaces using Gradio",
    "description": "",
    "summary": "Showcase Your Projects in Spaces using Gradio It's so easy to demonstrate a Machine Learning project...",
    "pubDate": "Tue, 05 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/28_gradio-spaces/thumbnail.png"
  },
  {
    "title": "Text and code embeddings by contrastive pre-training",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 24 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/text-and-code-embeddings-by-contrastive-pre-training",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CPU Optimized Embeddings with ü§ó Optimum Intel and fastRAG",
    "description": "",
    "summary": "CPU Optimized Embeddings with ü§ó Optimum Intel and fastRAG Embedding models are useful for many appli...",
    "pubDate": "Fri, 15 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-fast-embedding",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "The Newsroom AI Catalyst: a global program with WAN-IFRA",
    "description": "We‚Äôre collaborating with WAN-IFRA, the World Association of News Publishers, to launch a global accelerator program that will assist over 100 news publishers to explore and integrate AI in their newsroom.",
    "summary": "We‚Äôre collaborating with WAN-IFRA, the World Association of News Publishers, to launch a global accelerator program that will assist over 100 news publishers to explore and integrate AI in their newsroom.",
    "pubDate": "Wed, 29 May 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/newsroom-ai-catalyst-global-program-with-wan-ifra",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SmolVLM - small yet mighty Vision Language Model",
    "description": "",
    "summary": "SmolVLM - small yet mighty Vision Language Model TLDR This blog post introduces SmolVLM, a 2B VLM, S...",
    "pubDate": "Tue, 26 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvlm",
    "thumbnail": "https://huggingface.co/blog/assets/smolvlm/banner.png"
  },
  {
    "title": "Addendum to GPT-4o System Card: 4o image generation",
    "description": "4o image generation is a new, significantly more capable image generation approach than our earlier DALL¬∑E 3 series of models. It can create photorealistic output. It can take images as inputs and transform them.",
    "summary": "4o image generation is a new, significantly more capable image generation approach than our earlier DALL¬∑E 3 series of models. It can create photorealistic output. It can take images as inputs and transform them.",
    "pubDate": "Tue, 25 Mar 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-image-generation-system-card-addendum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From Sentences to Sequences: Rethinking Languages in Biological System",
    "description": "arXiv:2507.00953v2 Announce Type: replace-cross Abstract: The paradigm of large language models in natural language processing (NLP) has also shown promise in modeling biological languages, including proteins, RNA, and DNA. Both the auto-regressive generation paradigm and evaluation metrics have been transferred from NLP to biological sequence modeling. However, the intrinsic structural correlations in natural and biological languages differ fundamentally. Therefore, we revisit the notion of language in biological systems to better understand how NLP successes can be effectively translated to biological domains. By treating the 3D structure of biomolecules as the semantic content of a sentence and accounting for the strong correlations between residues or bases, we highlight the importance of structural evaluation and demonstrate the applicability of the auto-regressive paradigm in biological language modeling. Code can be found at href{https://github.com/zjuKeLiu/RiFold}{github.com/zjuKeLiu/RiFold}",
    "summary": "arXiv:2507.00953v2 Announce Type: replace-cross Abstract: The paradigm of large language models in natural language processing (NLP) has also shown promise in modeling biological languages, including proteins, RNA, and DNA. Both the auto-regressive generation paradigm and evaluation metrics have been transferred from NLP to biological sequence modeling. However, the intrinsic structural correlations in natural and biological languages differ fundamentally. Therefore, we revisit the notion of language in biological systems to better understand how NLP successes can be effectively translated to biological domains. By treating the 3D structure of biomolecules as the semantic content of a sentence and accounting for the strong correlations between residues or bases, we highlight the importance of structural evaluation and demonstrate the applicability of the auto-regressive paradigm in biological language modeling. Code can be found at href{https://github.com/zjuKeLiu/RiFold}{github.com/zjuKeLiu/RiFold}",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.00953",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Delivering LLM-powered health solutions",
    "description": "WHOOP delivers personalized fitness and health coaching with GPT-4.",
    "summary": "WHOOP delivers personalized fitness and health coaching with GPT-4.",
    "pubDate": "Thu, 04 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/whoop",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving language understanding with unsupervised learning",
    "description": "We‚Äôve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we‚Äôre also releasing. Our approach is a combination of two existing ideas:¬†transformers¬†and¬†unsupervised pre-training. These results provide a convincing example that pairing supervised learning methods with unsupervised pre-training works very well; this is an idea that many have explored in the past, and we hope our result motivates further research into applying this idea on larger and more diverse¬†datasets.",
    "summary": "We‚Äôve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we‚Äôre also releasing. Our approach is a combination of two existing ideas:¬†transformers¬†and¬†unsupervised pre-training. These results provide a convincing example that pairing supervised learning methods with unsupervised pre-training works very well; this is an idea that many have explored in the past, and we hope our result motivates further research into applying this idea on larger and more diverse¬†datasets.",
    "pubDate": "Mon, 11 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-unsupervised",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building interactive agents in video game worlds",
    "description": "Most artificial intelligence (AI) researchers now believe that writing computer code which can capture the nuances of situated interactions is impossible. Alternatively, modern machine learning (ML) researchers have focused on learning about these types of interactions from data. To explore these learning-based approaches and quickly build agents that can make sense of human instructions and safely perform actions in open-ended conditions, we created a research framework within a video game environment.Today, we‚Äôre publishing a paper [INSERT LINK] and collection of videos, showing our early steps in building video game AIs that can understand fuzzy human concepts ‚Äì and therefore, can begin to interact with people on their own terms.",
    "summary": "Most artificial intelligence (AI) researchers now believe that writing computer code which can capture the nuances of situated interactions is impossible. Alternatively, modern machine learning (ML) researchers have focused on learning about these types of interactions from data. To explore these learning-based approaches and quickly build agents that can make sense of human instructions and safely perform actions in open-ended conditions, we created a research framework within a video game environment.Today, we‚Äôre publishing a paper [INSERT LINK] and collection of videos, showing our early steps in building video game AIs that can understand fuzzy human concepts ‚Äì and therefore, can begin to interact with people on their own terms.",
    "pubDate": "Wed, 23 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/building-interactive-agents-in-video-game-worlds/",
    "thumbnail": "https://lh3.googleusercontent.com/6DSrkFaInWqKD1eN4IJJN31ZRa3LW447A1ZYoK19FDzJGSLD5dlVw1rJRf52O_dmQUDq11XqYsiqMR8uFDnWLWGkl8xFY5KXYxD7LvQNPvTEuR_h=w1200-h630-n-nu"
  },
  {
    "title": "PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification",
    "description": "arXiv:2504.19136v2 Announce Type: replace-cross Abstract: The fusion of Synthetic Aperture Radar (SAR) and RGB imagery for land cover classification remains challenging due to modality heterogeneity and underutilized spectral complementarity. Existing methods often fail to decouple shared structural features from modality-complementary radiometric attributes, causing feature conflicts and information loss. To address this, we propose Phase-Amplitude Decoupling (PAD), a frequency-aware framework that separates phase (modality-shared) and amplitude (modality-complementary) components in the Fourier domain, thus reinforcing shared structures while preserving complementary characteristics to improve fusion quality. Unlike prior approaches that overlook the distinct physical properties encoded in frequency spectra, PAD is the first to introduce explicit amplitude-phase decoupling for multi-modal fusion. Specifically, PAD comprises two key components: 1) Phase Spectrum Correction (PSC), which aligns cross-modal phase features via convolution-guided scaling to enhance geometric consistency; and 2) Amplitude Spectrum Fusion (ASF), which dynamically integrates high-frequency and low-frequency patterns using frequency-adaptive multilayer perceptrons, leveraging SAR's morphological sensitivity and RGB's spectral richness. Extensive experiments on WHU-OPT-SAR and DDHR-SK datasets demonstrate state-of-the-art performance. Our work establishes a new paradigm for physics-aware multi-modal fusion in remote sensing. The code will be available at https://github.com/RanFeng2/PAD.",
    "summary": "arXiv:2504.19136v2 Announce Type: replace-cross Abstract: The fusion of Synthetic Aperture Radar (SAR) and RGB imagery for land cover classification remains challenging due to modality heterogeneity and underutilized spectral complementarity. Existing methods often fail to decouple shared structural features from modality-complementary radiometric attributes, causing feature conflicts and information loss. To address this, we propose Phase-Amplitude Decoupling (PAD), a frequency-aware framework that separates phase (modality-shared) and amplitude (modality-complementary) components in the Fourier domain, thus reinforcing shared structures while preserving complementary characteristics to improve fusion quality. Unlike prior approaches that overlook the distinct physical properties encoded in frequency spectra, PAD is the first to introduce explicit amplitude-phase decoupling for multi-modal fusion. Specifically, PAD comprises two key components: 1) Phase Spectrum Correction (PSC), which aligns cross-modal phase features via convolution-guided scaling to enhance geometric consistency; and 2) Amplitude Spectrum Fusion (ASF), which dynamically integrates high-frequency and low-frequency patterns using frequency-adaptive multilayer perceptrons, leveraging SAR's morphological sensitivity and RGB's spectral richness. Extensive experiments on WHU-OPT-SAR and DDHR-SK datasets demonstrate state-of-the-art performance. Our work establishes a new paradigm for physics-aware multi-modal fusion in remote sensing. The code will be available at https://github.com/RanFeng2/PAD.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.19136",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation",
    "description": "arXiv:2507.01961v2 Announce Type: replace-cross Abstract: Recently, mobile manipulation has attracted increasing attention for enabling language-conditioned robotic control in household tasks. However, existing methods still face challenges in coordinating mobile base and manipulator, primarily due to two limitations. On the one hand, they fail to explicitly model the influence of the mobile base on manipulator control, which easily leads to error accumulation under high degrees of freedom. On the other hand, they treat the entire mobile manipulation process with the same visual observation modality (e.g., either all 2D or all 3D), overlooking the distinct multimodal perception requirements at different stages during mobile manipulation. To address this, we propose the Adaptive Coordination Diffusion Transformer (AC-DiT), which enhances mobile base and manipulator coordination for end-to-end mobile manipulation. First, since the motion of the mobile base directly influences the manipulator's actions, we introduce a mobility-to-body conditioning mechanism that guides the model to first extract base motion representations, which are then used as context prior for predicting whole-body actions. This enables whole-body control that accounts for the potential impact of the mobile base's motion. Second, to meet the perception requirements at different stages of mobile manipulation, we design a perception-aware multimodal conditioning strategy that dynamically adjusts the fusion weights between various 2D visual images and 3D point clouds, yielding visual features tailored to the current perceptual needs. This allows the model to, for example, adaptively rely more on 2D inputs when semantic information is crucial for action prediction, while placing greater emphasis on 3D geometric information when precise spatial understanding is required. We validate AC-DiT through extensive experiments on both simulated and real-world mobile manipulation tasks.",
    "summary": "arXiv:2507.01961v2 Announce Type: replace-cross Abstract: Recently, mobile manipulation has attracted increasing attention for enabling language-conditioned robotic control in household tasks. However, existing methods still face challenges in coordinating mobile base and manipulator, primarily due to two limitations. On the one hand, they fail to explicitly model the influence of the mobile base on manipulator control, which easily leads to error accumulation under high degrees of freedom. On the other hand, they treat the entire mobile manipulation process with the same visual observation modality (e.g., either all 2D or all 3D), overlooking the distinct multimodal perception requirements at different stages during mobile manipulation. To address this, we propose the Adaptive Coordination Diffusion Transformer (AC-DiT), which enhances mobile base and manipulator coordination for end-to-end mobile manipulation. First, since the motion of the mobile base directly influences the manipulator's actions, we introduce a mobility-to-body conditioning mechanism that guides the model to first extract base motion representations, which are then used as context prior for predicting whole-body actions. This enables whole-body control that accounts for the potential impact of the mobile base's motion. Second, to meet the perception requirements at different stages of mobile manipulation, we design a perception-aware multimodal conditioning strategy that dynamically adjusts the fusion weights between various 2D visual images and 3D point clouds, yielding visual features tailored to the current perceptual needs. This allows the model to, for example, adaptively rely more on 2D inputs when semantic information is crucial for action prediction, while placing greater emphasis on 3D geometric information when precise spatial understanding is required. We validate AC-DiT through extensive experiments on both simulated and real-world mobile manipulation tasks.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01961",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Dr. Ronnie Chatterji named OpenAI‚Äôs first Chief Economist",
    "description": "Dr. Ronnie Chatterji named OpenAI‚Äôs first Chief Economist",
    "summary": "Dr. Ronnie Chatterji named OpenAI‚Äôs first Chief Economist",
    "pubDate": "Tue, 22 Oct 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-chief-economist-announcement",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Apps in a Flash with Gradio's Reload Mode",
    "description": "",
    "summary": "AI Apps in a Flash with Gradio's Reload Mode In this post, I will show you how you can build a funct...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-reload",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-reload/thumbnail_compressed.png"
  },
  {
    "title": "Transformer-based Encoder-Decoder Models",
    "description": "",
    "summary": "Transformers-based Encoder-Decoder Models !pip install transformers==4.2.1 !pip install sentencepiec...",
    "pubDate": "Sat, 10 Oct 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/encoder-decoder",
    "thumbnail": "https://huggingface.co/blog/assets/05_encoder_decoder/thumbnail.png"
  },
  {
    "title": "FlowSpec: Continuous Pipelined Speculative Decoding for Efficient Distributed LLM Inference",
    "description": "arXiv:2507.02620v1 Announce Type: cross Abstract: Distributed inference serves as a promising approach to enabling the inference of large language models (LLMs) at the network edge. It distributes the inference process to multiple devices to ensure that the LLMs can fit into the device memory. Recent pipeline-based approaches have the potential to parallelize communication and computation, which helps reduce inference latency. However, the benefit diminishes when the inference request at the network edge is sparse, where pipeline is typically at low utilization. To enable efficient distributed LLM inference at the edge, we propose textbf{FlowSpec}, a pipeline-parallel tree-based speculative decoding framework. FlowSpec incorporates three key mechanisms to improve decoding efficiency: 1) score-based step-wise verification prioritizes more important draft tokens to bring earlier accpeted tokens; 2) efficient draft management to prune invalid tokens while maintaining correct causal relationship during verification; 3) dynamic draft expansion strategies to supply high-quality speculative inputs. These techniques work in concert to enhance both pipeline utilization and speculative efficiency. We evaluate FlowSpec on a real-world testbed with other baselines. Experimental results demonstrate that our proposed framework significantly improves inference speed across diverse models and configurations, achieving speedup ratios 1.36$times$-1.77$times$ compared to baselines. Our code is publicly available at href{https://github.com/Leosang-lx/FlowSpec#}{https://github.com/Leosang-lx/FlowSpec#}",
    "summary": "arXiv:2507.02620v1 Announce Type: cross Abstract: Distributed inference serves as a promising approach to enabling the inference of large language models (LLMs) at the network edge. It distributes the inference process to multiple devices to ensure that the LLMs can fit into the device memory. Recent pipeline-based approaches have the potential to parallelize communication and computation, which helps reduce inference latency. However, the benefit diminishes when the inference request at the network edge is sparse, where pipeline is typically at low utilization. To enable efficient distributed LLM inference at the edge, we propose textbf{FlowSpec}, a pipeline-parallel tree-based speculative decoding framework. FlowSpec incorporates three key mechanisms to improve decoding efficiency: 1) score-based step-wise verification prioritizes more important draft tokens to bring earlier accpeted tokens; 2) efficient draft management to prune invalid tokens while maintaining correct causal relationship during verification; 3) dynamic draft expansion strategies to supply high-quality speculative inputs. These techniques work in concert to enhance both pipeline utilization and speculative efficiency. We evaluate FlowSpec on a real-world testbed with other baselines. Experimental results demonstrate that our proposed framework significantly improves inference speed across diverse models and configurations, achieving speedup ratios 1.36$times$-1.77$times$ compared to baselines. Our code is publicly available at href{https://github.com/Leosang-lx/FlowSpec#}{https://github.com/Leosang-lx/FlowSpec#}",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02620",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reconsidering the energy efficiency of spiking neural networks",
    "description": "arXiv:2409.08290v2 Announce Type: replace-cross Abstract: Spiking Neural Networks (SNNs) promise higher energy efficiency over conventional Quantized Artificial Neural Networks (QNNs) due to their event-driven, spike-based computation. However, prevailing energy evaluations often oversimplify, focusing on computational aspects while neglecting critical overheads like comprehensive data movement and memory access. Such simplifications can lead to misleading conclusions regarding the true energy benefits of SNNs. This paper presents a rigorous re-evaluation. We establish a fair baseline by mapping rate-encoded SNNs with $T$ timesteps to functionally equivalent QNNs with $lceil log_2(T+1) rceil$ bits. This ensures both models have comparable representational capacities, as well has similar hardware requirement, enabling meaningful energy comparisons. We introduce a detailed analytical energy model encompassing core computation and data movement (sparse and dense activations, weights). Using this model, we systematically explore a wide parameter space, including intrinsic network characteristics ($T$, spike rate $s_r$, QNN sparsity $gamma$, model size $N$, weight bit-level) and hardware characteristics (memory system and network-on-chip). Our analysis identifies specific operational regimes where SNNs genuinely offer superior energy efficiency. For example, under typical neuromorphic hardware conditions, SNNs with moderate time windows ($T in [5,10]$) require an average spike rate ($s_r$) below 6.4% to outperform equivalent QNNs. These insights guide the design of genuinely energy-efficient neural network solutions.",
    "summary": "arXiv:2409.08290v2 Announce Type: replace-cross Abstract: Spiking Neural Networks (SNNs) promise higher energy efficiency over conventional Quantized Artificial Neural Networks (QNNs) due to their event-driven, spike-based computation. However, prevailing energy evaluations often oversimplify, focusing on computational aspects while neglecting critical overheads like comprehensive data movement and memory access. Such simplifications can lead to misleading conclusions regarding the true energy benefits of SNNs. This paper presents a rigorous re-evaluation. We establish a fair baseline by mapping rate-encoded SNNs with $T$ timesteps to functionally equivalent QNNs with $lceil log_2(T+1) rceil$ bits. This ensures both models have comparable representational capacities, as well has similar hardware requirement, enabling meaningful energy comparisons. We introduce a detailed analytical energy model encompassing core computation and data movement (sparse and dense activations, weights). Using this model, we systematically explore a wide parameter space, including intrinsic network characteristics ($T$, spike rate $s_r$, QNN sparsity $gamma$, model size $N$, weight bit-level) and hardware characteristics (memory system and network-on-chip). Our analysis identifies specific operational regimes where SNNs genuinely offer superior energy efficiency. For example, under typical neuromorphic hardware conditions, SNNs with moderate time windows ($T in [5,10]$) require an average spike rate ($s_r$) below 6.4% to outperform equivalent QNNs. These insights guide the design of genuinely energy-efficient neural network solutions.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.08290",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Cohere on Hugging Face Inference Providers üî•",
    "description": "",
    "summary": "Cohere on Hugging Face Inference Providers üî• We're thrilled to share that Cohere is now a supported ...",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-cohere",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers-cohere/thumbnail.png"
  },
  {
    "title": "Multi-Goal Reinforcement Learning: Challenging robotics environments and request for research",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 26 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/multi-goal-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI for Education",
    "description": "An affordable offering for universities to responsibly bring AI to campus.",
    "summary": "An affordable offering for universities to responsibly bring AI to campus.",
    "pubDate": "Thu, 30 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-edu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "State-of-the-art video and image generation with Veo 2 and Imagen 3",
    "description": "We‚Äôre rolling out a new, state-of-the-art video model, Veo 2, and updates to Imagen 3. Plus, check out our new experiment, Whisk.",
    "summary": "We‚Äôre rolling out a new, state-of-the-art video model, Veo 2, and updates to Imagen 3. Plus, check out our new experiment, Whisk.",
    "pubDate": "Mon, 16 Dec 2024 17:01:16 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/state-of-the-art-video-and-image-generation-with-veo-2-and-imagen-3/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/12-16-24_GenMedia_16x9.width-1300.png"
  },
  {
    "title": "Automating 90% of finance and legal work with agents",
    "description": "Hebbia‚Äôs deep research automates 90% of finance and legal work, powered by OpenAI",
    "summary": "Hebbia‚Äôs deep research automates 90% of finance and legal work, powered by OpenAI",
    "pubDate": "Tue, 25 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hebbia",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Minnesota‚Äôs Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "description": "Minnesota‚Äôs Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "summary": "Minnesota‚Äôs Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "pubDate": "Thu, 26 Sep 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/state-of-minnesota",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Microscope",
    "description": "We‚Äôre introducing¬†OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision ‚Äúmodel organisms‚Äù which are often studied in interpretability. Microscope makes it easier to analyze the features that form inside these neural networks, and we hope it will help the research community as we move towards understanding these complicated¬†systems.",
    "summary": "We‚Äôre introducing¬†OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision ‚Äúmodel organisms‚Äù which are often studied in interpretability. Microscope makes it easier to analyze the features that form inside these neural networks, and we hope it will help the research community as we move towards understanding these complicated¬†systems.",
    "pubDate": "Tue, 14 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/microscope",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning a hierarchy",
    "description": "We‚Äôve developed a hierarchical reinforcement learning algorithm that learns high-level actions useful for solving a range of tasks, allowing fast solving of tasks requiring thousands of timesteps. Our algorithm, when applied to a set of navigation problems, discovers a set of high-level actions for walking and crawling in different directions, which enables the agent to master new navigation tasks quickly.",
    "summary": "We‚Äôve developed a hierarchical reinforcement learning algorithm that learns high-level actions useful for solving a range of tasks, allowing fast solving of tasks requiring thousands of timesteps. Our algorithm, when applied to a set of navigation problems, discovers a set of high-level actions for walking and crawling in different directions, which enables the agent to master new navigation tasks quickly.",
    "pubDate": "Thu, 26 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-a-hierarchy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Why responsible AI development needs cooperation on safety",
    "description": "We‚Äôve written a policy research paper identifying four strategies that can be used today to improve the likelihood of long-term industry cooperation on safety norms in AI: communicating risks and benefits, technical collaboration, increased transparency, and incentivizing standards. Our analysis shows that industry cooperation on safety will be instrumental in ensuring that AI systems are safe and beneficial, but competitive pressures could lead to a collective action problem, potentially causing AI companies to under-invest in safety. We hope these strategies will encourage greater cooperation on the safe development of AI and lead to better global outcomes of¬†AI.",
    "summary": "We‚Äôve written a policy research paper identifying four strategies that can be used today to improve the likelihood of long-term industry cooperation on safety norms in AI: communicating risks and benefits, technical collaboration, increased transparency, and incentivizing standards. Our analysis shows that industry cooperation on safety will be instrumental in ensuring that AI systems are safe and beneficial, but competitive pressures could lead to a collective action problem, potentially causing AI companies to under-invest in safety. We hope these strategies will encourage greater cooperation on the safe development of AI and lead to better global outcomes of¬†AI.",
    "pubDate": "Wed, 10 Jul 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/cooperation-on-safety",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs",
    "description": "arXiv:2507.02778v1 Announce Type: cross Abstract: Although large language models (LLMs) have become transformative, they still make mistakes and can explore unproductive reasoning paths. Self-correction is an important capability for a trustworthy LLM, particularly an autoregressive LLM. While LLMs can identify error in user input, they exhibit a systematic 'Self-Correction Blind Spot' - failing to correct identical error in their own outputs. To systematically study this phenomenon, we introduce Self-Correction Bench, a systematic framework to measure this phenomenon through controlled error injection at three complexity levels. Testing 14 models, we find an average 64.5% blind spot rate. We find multiple evidences that this limitation relates to training data composition: human training demonstrations predominantly show error-free responses rather than error-correction sequences, unlike RL-trained models that learn error correction through outcome feedback. Remarkably, simply appending 'Wait' reduces blind spots by 89.3%, suggesting that the capability exists but requires activation. Our work highlights a critical limitation in current LLMs and offers potential avenues for improving their reliability and trustworthiness.",
    "summary": "arXiv:2507.02778v1 Announce Type: cross Abstract: Although large language models (LLMs) have become transformative, they still make mistakes and can explore unproductive reasoning paths. Self-correction is an important capability for a trustworthy LLM, particularly an autoregressive LLM. While LLMs can identify error in user input, they exhibit a systematic 'Self-Correction Blind Spot' - failing to correct identical error in their own outputs. To systematically study this phenomenon, we introduce Self-Correction Bench, a systematic framework to measure this phenomenon through controlled error injection at three complexity levels. Testing 14 models, we find an average 64.5% blind spot rate. We find multiple evidences that this limitation relates to training data composition: human training demonstrations predominantly show error-free responses rather than error-correction sequences, unlike RL-trained models that learn error correction through outcome feedback. Remarkably, simply appending 'Wait' reduces blind spots by 89.3%, suggesting that the capability exists but requires activation. Our work highlights a critical limitation in current LLMs and offers potential avenues for improving their reliability and trustworthiness.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02778",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Model Cards: Introducing HF Model documentation tools",
    "description": "",
    "summary": "Model Cards Introduction Model cards are an important documentation framework for understanding, sha...",
    "pubDate": "Tue, 20 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/model-cards",
    "thumbnail": "https://huggingface.co/blog/assets/121_model-cards/thumbnail.png"
  },
  {
    "title": "MAPS: Advancing Multi-Modal Reasoning in Expert-Level Physical Science",
    "description": "arXiv:2501.10768v2 Announce Type: replace Abstract: Pre-trained on extensive text and image corpora, current Multi-Modal Large Language Models (MLLM) have shown strong capabilities in general visual reasoning tasks. However, their performance is still lacking in physical domains that require understanding diagrams with complex physical structures and quantitative analysis based on multi-modal information. To address this, we develop a new framework, named Multi-Modal Scientific Reasoning with Physics Perception and Simulation (MAPS) based on an MLLM. MAPS decomposes expert-level multi-modal reasoning task into physical diagram understanding via a Physical Perception Model (PPM) and reasoning with physical knowledge via a simulator. The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions. At the inference stage, MAPS integrates the simulation language description of the input diagram provided by PPM and results obtained through a Chain-of-Simulation process with MLLM to derive the underlying rationale and the final answer. Validated using our collected college-level circuit analysis problems, MAPS significantly improves reasoning accuracy of MLLM and outperforms all existing models. The results confirm MAPS offers a promising direction for enhancing multi-modal scientific reasoning ability of MLLMs. We will release our code, model and dataset used for our experiments upon publishing of this paper.",
    "summary": "arXiv:2501.10768v2 Announce Type: replace Abstract: Pre-trained on extensive text and image corpora, current Multi-Modal Large Language Models (MLLM) have shown strong capabilities in general visual reasoning tasks. However, their performance is still lacking in physical domains that require understanding diagrams with complex physical structures and quantitative analysis based on multi-modal information. To address this, we develop a new framework, named Multi-Modal Scientific Reasoning with Physics Perception and Simulation (MAPS) based on an MLLM. MAPS decomposes expert-level multi-modal reasoning task into physical diagram understanding via a Physical Perception Model (PPM) and reasoning with physical knowledge via a simulator. The PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions. At the inference stage, MAPS integrates the simulation language description of the input diagram provided by PPM and results obtained through a Chain-of-Simulation process with MLLM to derive the underlying rationale and the final answer. Validated using our collected college-level circuit analysis problems, MAPS significantly improves reasoning accuracy of MLLM and outperforms all existing models. The results confirm MAPS offers a promising direction for enhancing multi-modal scientific reasoning ability of MLLMs. We will release our code, model and dataset used for our experiments upon publishing of this paper.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.10768",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Boost Wav2Vec2 with n-gram LM in ü§ó Transformers",
    "description": "",
    "summary": "Boosting Wav2Vec2 with n-grams in ü§ó Transformers Wav2Vec2 is a popular pre-trained model for speech ...",
    "pubDate": "Wed, 12 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/wav2vec2-with-ngram",
    "thumbnail": "https://huggingface.co/blog/assets/44_boost_wav2vec2_ngram/wav2vec2_ngram.png"
  },
  {
    "title": "Blazing Fast SetFit Inference with ü§ó Optimum Intel on Xeon",
    "description": "",
    "summary": "Blazing Fast SetFit Inference with ü§ó Optimum Intel on Xeon SetFit is a promising solution for a comm...",
    "pubDate": "Wed, 03 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit-optimum-intel",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "LAVE: Zero-shot VQA Evaluation on Docmatix with LLMs - Do We Still Need Fine-Tuning?",
    "description": "",
    "summary": "LAVE: Zero-shot VQA Evaluation on Docmatix with LLMs - Do We Still Need Fine-Tuning? While developin...",
    "pubDate": "Thu, 25 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-shot-vqa-docmatix",
    "thumbnail": "https://huggingface.co/blog/assets/184_zero_shot_docmatix/thumb.001.jpeg"
  },
  {
    "title": "Increasing accuracy of pediatric visit notes",
    "description": "Summer Health reimagines pediatric doctor‚Äôs visits with OpenAI.",
    "summary": "Summer Health reimagines pediatric doctor‚Äôs visits with OpenAI.",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/summer-health",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Efficient Table Pre-training without Real Data: An Introduction to TAPEX",
    "description": "",
    "summary": "Efficient Table Pre-training without Real Data: An Introduction to TAPEX In recent years, language m...",
    "pubDate": "Mon, 23 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tapex",
    "thumbnail": "https://huggingface.co/blog/assets/74_tapex/thumbnail.png"
  },
  {
    "title": "Surging developer productivity with custom GPTs",
    "description": "Paf adopted ChatGPT Enterprise across its entire company, with engineers using custom GPTs on a daily basis to speed up routine development tasks. Paf also integrated ChatGPT Enterprise into the grit:lab coding academy (gritlab.ax), training the next generation of software developers using an AI-augmented, systems-architecture mindset from day one. In addition to the wide range of use cases for developers and grit:lab students, 70% of Paf employees actively use ChatGPT Enterprise, spanning business teams like finance, HR, marketing, and customer support.",
    "summary": "Paf adopted ChatGPT Enterprise across its entire company, with engineers using custom GPTs on a daily basis to speed up routine development tasks. Paf also integrated ChatGPT Enterprise into the grit:lab coding academy (gritlab.ax), training the next generation of software developers using an AI-augmented, systems-architecture mindset from day one. In addition to the wide range of use cases for developers and grit:lab students, 70% of Paf employees actively use ChatGPT Enterprise, spanning business teams like finance, HR, marketing, and customer support.",
    "pubDate": "Tue, 18 Jun 2024 08:45:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paf",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Dota 2 with large scale deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 13 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dota-2-with-large-scale-deep-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Report from the OpenAI hackathon",
    "description": "On March 3rd, we hosted our first¬†hackathon¬†with 100 members of the artificial intelligence community.",
    "summary": "On March 3rd, we hosted our first¬†hackathon¬†with 100 members of the artificial intelligence community.",
    "pubDate": "Thu, 15 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hackathon-follow-up",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Constitutional AI with Open LLMs",
    "description": "",
    "summary": "Constitutional AI with Open LLMs Since the launch of ChatGPT in 2022, we have seen tremendous progre...",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/constitutional_ai",
    "thumbnail": "https://huggingface.co/blog/assets/175_constitutional_ai/thumbnail.png"
  },
  {
    "title": "Learning Traffic Anomalies from Generative Models on Real-Time Observations",
    "description": "arXiv:2502.01391v3 Announce Type: replace-cross Abstract: Accurate detection of traffic anomalies is crucial for effective urban traffic management and congestion mitigation. We use the Spatiotemporal Generative Adversarial Network (STGAN) framework combining Graph Neural Networks and Long Short-Term Memory networks to capture complex spatial and temporal dependencies in traffic data. We apply STGAN to real-time, minute-by-minute observations from 42 traffic cameras across Gothenburg, Sweden, collected over several months in 2020. The images are processed to compute a flow metric representing vehicle density, which serves as input for the model. Training is conducted on data from April to November 2020, and validation is performed on a separate dataset from November 14 to 23, 2020. Our results demonstrate that the model effectively detects traffic anomalies with high precision and low false positive rates. The detected anomalies include camera signal interruptions, visual artifacts, and extreme weather conditions affecting traffic flow.",
    "summary": "arXiv:2502.01391v3 Announce Type: replace-cross Abstract: Accurate detection of traffic anomalies is crucial for effective urban traffic management and congestion mitigation. We use the Spatiotemporal Generative Adversarial Network (STGAN) framework combining Graph Neural Networks and Long Short-Term Memory networks to capture complex spatial and temporal dependencies in traffic data. We apply STGAN to real-time, minute-by-minute observations from 42 traffic cameras across Gothenburg, Sweden, collected over several months in 2020. The images are processed to compute a flow metric representing vehicle density, which serves as input for the model. Training is conducted on data from April to November 2020, and validation is performed on a separate dataset from November 14 to 23, 2020. Our results demonstrate that the model effectively detects traffic anomalies with high precision and low false positive rates. The detected anomalies include camera signal interruptions, visual artifacts, and extreme weather conditions affecting traffic flow.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.01391",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Empowering Intelligent Low-altitude Economy with Large AI Model Deployment",
    "description": "arXiv:2505.22343v2 Announce Type: replace-cross Abstract: Low-altitude economy (LAE) represents an emerging economic paradigm that redefines commercial and social aerial activities. Large artificial intelligence models (LAIMs) offer transformative potential to further enhance the intelligence of LAE services. However, deploying LAIMs in LAE poses several challenges, including the significant gap between their computational/storage demands and the limited onboard resources of LAE entities, the mismatch between lab-trained LAIMs and dynamic physical environments, and the inefficiencies of traditional decoupled designs for sensing, communication, and computation. To address these issues, we first propose a hierarchical system architecture tailored for LAIM deployment and present representative LAE application scenarios. Next, we explore key enabling techniques that facilitate the mutual co-evolution of LAIMs and low-altitude systems, and introduce a task-oriented execution pipeline for scalable and adaptive service delivery. Then, the proposed framework is validated through real-world case studies. Finally, we outline open challenges to inspire future research.",
    "summary": "arXiv:2505.22343v2 Announce Type: replace-cross Abstract: Low-altitude economy (LAE) represents an emerging economic paradigm that redefines commercial and social aerial activities. Large artificial intelligence models (LAIMs) offer transformative potential to further enhance the intelligence of LAE services. However, deploying LAIMs in LAE poses several challenges, including the significant gap between their computational/storage demands and the limited onboard resources of LAE entities, the mismatch between lab-trained LAIMs and dynamic physical environments, and the inefficiencies of traditional decoupled designs for sensing, communication, and computation. To address these issues, we first propose a hierarchical system architecture tailored for LAIM deployment and present representative LAE application scenarios. Next, we explore key enabling techniques that facilitate the mutual co-evolution of LAIMs and low-altitude systems, and introduce a task-oriented execution pipeline for scalable and adaptive service delivery. Then, the proposed framework is validated through real-world case studies. Finally, we outline open challenges to inspire future research.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.22343",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google DeepMind at ICML 2024",
    "description": "Exploring AGI, the challenges of scaling and the future of multimodal generative AI",
    "summary": "Exploring AGI, the challenges of scaling and the future of multimodal generative AI",
    "pubDate": "Fri, 19 Jul 2024 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-icml-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/_o0MU47bgKrTJi6uOWhc3BjWOOENkBczD2x5-tK5aMLBcljJnV-N8tZuSVN42C3d1pSWawY6NsGuoj6vvl0xMk4tpWOeUjXwlgFNZSMyJkFJ02xTauk=w1200-h630-n-nu"
  },
  {
    "title": "Partnership with Axel Springer to deepen beneficial use of AI in journalism",
    "description": "Axel Springer is the first publishing house globally to partner with us on a deeper integration of journalism in AI technologies.",
    "summary": "Axel Springer is the first publishing house globally to partner with us on a deeper integration of journalism in AI technologies.",
    "pubDate": "Wed, 13 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/axel-springer-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Procgen Benchmark",
    "description": "We‚Äôre releasing Procgen Benchmark, 16 simple-to-use¬†procedurally-generated¬†environments which provide a direct measure of how quickly a reinforcement learning agent learns generalizable¬†skills.",
    "summary": "We‚Äôre releasing Procgen Benchmark, 16 simple-to-use¬†procedurally-generated¬†environments which provide a direct measure of how quickly a reinforcement learning agent learns generalizable¬†skills.",
    "pubDate": "Tue, 03 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/procgen-benchmark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Large-scale Near-deduplication Behind BigCode",
    "description": "",
    "summary": "Large-scale Near-deduplication Behind BigCode Intended Audience People who are interested in documen...",
    "pubDate": "Tue, 16 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dedup",
    "thumbnail": "https://huggingface.co/blog/assets/dedup/thumbnail.png"
  },
  {
    "title": "Fine-tuning XLS-R for Multi-Lingual ASR with ü§ó Transformers",
    "description": "",
    "summary": "Fine-tuning XLS-R for Multi-Lingual ASR with ü§ó Transformers New (11/2021): This blog post has been u...",
    "pubDate": "Mon, 15 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-xlsr-wav2vec2",
    "thumbnail": "https://huggingface.co/blog/assets/xlsr_wav2vec2.png"
  },
  {
    "title": "OpenAI‚Äôs proposals for the U.S. AI Action Plan",
    "description": "Recommendations build on OpenAI‚Äôs Economic Blueprint to strengthen America‚Äôs AI leadership.",
    "summary": "Recommendations build on OpenAI‚Äôs Economic Blueprint to strengthen America‚Äôs AI leadership.",
    "pubDate": "Thu, 13 Mar 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-proposals-for-the-us-ai-action-plan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o1-mini",
    "description": "Advancing cost-efficient reasoning",
    "summary": "Advancing cost-efficient reasoning",
    "pubDate": "Thu, 12 Sep 2024 10:01:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-mini-advancing-cost-efficient-reasoning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Strengthening America‚Äôs AI leadership with the U.S. National Laboratories",
    "description": "OpenAI‚Äôs latest line of reasoning models will be used by nation‚Äôs leading scientists to drive scientific breakthroughs.",
    "summary": "OpenAI‚Äôs latest line of reasoning models will be used by nation‚Äôs leading scientists to drive scientific breakthroughs.",
    "pubDate": "Thu, 30 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/strengthening-americas-ai-leadership-with-the-us-national-laboratories",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introduction to Graph Machine Learning",
    "description": "",
    "summary": "Introduction to Graph Machine Learning In this blog post, we cover the basics of graph machine learn...",
    "pubDate": "Tue, 03 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intro-graphml",
    "thumbnail": "https://huggingface.co/blog/assets/125_intro-to-graphml/thumbnail.png"
  },
  {
    "title": "Advancing red teaming with people and AI",
    "description": "Advancing red teaming with people and AI",
    "summary": "Advancing red teaming with people and AI",
    "pubDate": "Thu, 21 Nov 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/advancing-red-teaming-with-people-and-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI‚Äôs comments to the NTIA on data center growth, resilience, and security",
    "description": "This comment was submitted in response to a request for information from the National Telecommunications and Information Administration (NTIA).",
    "summary": "This comment was submitted in response to a request for information from the National Telecommunications and Information Administration (NTIA).",
    "pubDate": "Mon, 04 Nov 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/comments-to-the-ntia-on-data-center-growth-resilience-and-security",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing SynthID Text",
    "description": "",
    "summary": "Introducing SynthID Text Do you find it difficult to tell if text was written by a human or generate...",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthid-text",
    "thumbnail": "https://huggingface.co/blog/assets/synthid-text/thumbnail.png"
  },
  {
    "title": "Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning",
    "description": "<p>Microsoft researchers achieved a breakthrough in the accuracy of DFT, a method for predicting the properties of molecules and materials, by using deep learning. This work can lead to better batteries, green fertilizers, precision drug discovery, and more.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/'>Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Microsoft researchers achieved a breakthrough in the accuracy of DFT, a method for predicting the properties of molecules and materials, by using deep learning. This work can lead to better batteries, green fertilizers, precision drug discovery, and more.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/'>Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Wed, 18 Jun 2025 10:01:47 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "How to train your model dynamically using adversarial data",
    "description": "",
    "summary": "How to train your model dynamically using adversarial data What you will learn here - üí°the basic ide...",
    "pubDate": "Sat, 16 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mnist-adversarial",
    "thumbnail": "https://huggingface.co/blog/assets/88_mnist_adversarial/mnist-adversarial.png"
  },
  {
    "title": "„Äê7/18ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„Äë„É≠„Éº„Ç´„É´LLM„ÅÆÂ§ßÊú¨ÂëΩ„ÄåQwen3„Äç√óÁ∂ôÁ∂ö‰∫ãÂâçÂ≠¶Áøí„ÅÆËß£Ë™¨ÔºÜ„Éá„É¢ 1250‰∏á„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÇíÁ™ÅÁ†¥„Åó„Åü‰∏ñÁïå„ÅåÊ≥®ÁõÆ„Åô„ÇãLLM",
    "description": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà18Êó•ÔºàÈáëÔºâ12ÊôÇ„Åã„ÇâLLM„Çí„ÉÜ„Éº„Éû„Å´„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ „Ç¢„É™„Éê„Éê„ÅåÈñãÁô∫„Åó„ÅüÊ≥®ÁõÆ„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„ÇπLLM„ÄåQwen3„ÄçÔºÅ OpenAI o1„ÇÑDeepSeek [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250718webinar/'>„Äê7/18ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„Äë„É≠„Éº„Ç´„É´LLM„ÅÆÂ§ßÊú¨ÂëΩ„ÄåQwen3„Äç√óÁ∂ôÁ∂ö‰∫ãÂâçÂ≠¶Áøí„ÅÆËß£Ë™¨ÔºÜ„Éá„É¢ 1250‰∏á„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÇíÁ™ÅÁ†¥„Åó„Åü‰∏ñÁïå„ÅåÊ≥®ÁõÆ„Åô„ÇãLLM</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà18Êó•ÔºàÈáëÔºâ12ÊôÇ„Åã„ÇâLLM„Çí„ÉÜ„Éº„Éû„Å´„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ „Ç¢„É™„Éê„Éê„ÅåÈñãÁô∫„Åó„ÅüÊ≥®ÁõÆ„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„ÇπLLM„ÄåQwen3„ÄçÔºÅ OpenAI o1„ÇÑDeepSeek [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250718webinar/'>„Äê7/18ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„Äë„É≠„Éº„Ç´„É´LLM„ÅÆÂ§ßÊú¨ÂëΩ„ÄåQwen3„Äç√óÁ∂ôÁ∂ö‰∫ãÂâçÂ≠¶Áøí„ÅÆËß£Ë™¨ÔºÜ„Éá„É¢ 1250‰∏á„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÇíÁ™ÅÁ†¥„Åó„Åü‰∏ñÁïå„ÅåÊ≥®ÁõÆ„Åô„ÇãLLM</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Wed, 02 Jul 2025 07:24:05 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/20250718webinar/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/717_1200x628_5.jpg"
  },
  {
    "title": "Introducing the Private Hub: A New Way to Build With Machine Learning",
    "description": "",
    "summary": "Introducing the Private Hub: A New Way to Build With Machine Learning June 2023 Update: The Private ...",
    "pubDate": "Wed, 03 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-private-hub",
    "thumbnail": "https://huggingface.co/blog/assets/92_introducing_private_hub/thumbnail.png"
  },
  {
    "title": "Personalizing travel at scale with OpenAI",
    "description": "By integrating its data systems with OpenAI‚Äôs LLMs, Booking.com delivers smarter search, faster support, and intent-driven travel experiences.",
    "summary": "By integrating its data systems with OpenAI‚Äôs LLMs, Booking.com delivers smarter search, faster support, and intent-driven travel experiences.",
    "pubDate": "Thu, 20 Mar 2025 23:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/booking-com",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Towards a Novel Measure of User Trust in XAI Systems",
    "description": "arXiv:2405.05766v2 Announce Type: replace-cross Abstract: The increasing reliance on Deep Learning models, combined with their inherent lack of transparency, has spurred the development of a novel field of study known as eXplainable AI (XAI) methods. These methods seek to enhance the trust of end-users in automated systems by providing insights into the rationale behind their decisions. This paper presents a novel trust measure in XAI systems, allowing their refinement. Our proposed metric combines both performance metrics and trust indicators from an objective perspective. To validate this novel methodology, we conducted three case studies showing an improvement respect the state-of-the-art, with an increased sensitiviy to different scenarios.",
    "summary": "arXiv:2405.05766v2 Announce Type: replace-cross Abstract: The increasing reliance on Deep Learning models, combined with their inherent lack of transparency, has spurred the development of a novel field of study known as eXplainable AI (XAI) methods. These methods seek to enhance the trust of end-users in automated systems by providing insights into the rationale behind their decisions. This paper presents a novel trust measure in XAI systems, allowing their refinement. Our proposed metric combines both performance metrics and trust indicators from an objective perspective. To validate this novel methodology, we conducted three case studies showing an improvement respect the state-of-the-art, with an increased sensitiviy to different scenarios.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.05766",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Benchmarking Text Generation Inference",
    "description": "",
    "summary": "Benchmarking Text Generation Inference In this blog we will be exploring Text Generation Inference‚Äôs...",
    "pubDate": "Wed, 29 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-benchmarking",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-benchmarking/tgi-benchmarking-thumbnail.png"
  },
  {
    "title": "Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset",
    "description": "",
    "summary": "From screenshots to HTML code: Introducing the WebSight dataset In the world of web development, tur...",
    "pubDate": "Fri, 15 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/websight",
    "thumbnail": "https://huggingface.co/blog/assets/websight/thumbnail.png"
  },
  {
    "title": "Special projects",
    "description": "Impactful scientific work requires working on the right problems‚Äîproblems which are not just interesting, but whose solutions matter.",
    "summary": "Impactful scientific work requires working on the right problems‚Äîproblems which are not just interesting, but whose solutions matter.",
    "pubDate": "Thu, 28 Jul 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/special-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Parquet Dedupe on Hugging Face Hub",
    "description": "",
    "summary": "Improving Parquet Dedupe on Hugging Face Hub The Xet team at Hugging Face is working on improving th...",
    "pubDate": "Sat, 05 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/improve_parquet_dedupe",
    "thumbnail": "https://huggingface.co/blog/assets/improve_parquet_dedupe/thumbnail.png"
  },
  {
    "title": "OpenAI Expands Leadership with Fidji Simo",
    "description": "Read the message Sam shared with the company earlier today.",
    "summary": "Read the message Sam shared with the company earlier today.",
    "pubDate": "Wed, 07 May 2025 21:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-expansion-with-fidji-simo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Hugging Face Embedding Container for Amazon SageMaker",
    "description": "",
    "summary": "Introducing the Hugging Face Embedding Container for Amazon SageMaker We are excited to announce tha...",
    "pubDate": "Fri, 07 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-huggingface-embedding",
    "thumbnail": "https://huggingface.co/blog/assets/sagemaker-huggingface-embedding/thumbnail.jpg"
  },
  {
    "title": "„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ7/23ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„Äå Á∑èÂãô„Éª‰∫∫‰∫ã„ÉªÁµåÁêÜWeek [ÂêçÂè§Â±ã] „Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï",
    "description": "<p>AIsmiley„ÅØ„ÄÅ2025Âπ¥7Êúà23Êó•ÔºàÊ∞¥ÔºâÔΩû7Êúà25Êó•ÔºàÈáëÔºâ„Å´„Éù„Éº„Éà„É°„ÉÉ„Çª„Å™„Åî„ÇÑ„Å´„Å¶ÈñãÂÇ¨„ÅÆ„ÄåÁ¨¨7Âõû Á∑èÂãô„Éª‰∫∫‰∫ã„ÉªÁµåÁêÜWeek [ÂêçÂè§Â±ã] „Äç„Å´„Éñ„Éº„Çπ„ÇíÂá∫Â±ï„Åó„Åæ„Åô„ÄÇ ‰ºöÂ†¥„Åß„ÅØ„ÄÅÊúÄÊñ∞„ÅÆAI„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥„ÇÑ„Éã„É•„Éº„ÇπÁ≠â„ÇíÈõÜ„ÇÅ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/nagoya-office-expo-no7/'>„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ7/23ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„Äå Á∑èÂãô„Éª‰∫∫‰∫ã„ÉªÁµåÁêÜWeek [ÂêçÂè§Â±ã] „Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AIsmiley„ÅØ„ÄÅ2025Âπ¥7Êúà23Êó•ÔºàÊ∞¥ÔºâÔΩû7Êúà25Êó•ÔºàÈáëÔºâ„Å´„Éù„Éº„Éà„É°„ÉÉ„Çª„Å™„Åî„ÇÑ„Å´„Å¶ÈñãÂÇ¨„ÅÆ„ÄåÁ¨¨7Âõû Á∑èÂãô„Éª‰∫∫‰∫ã„ÉªÁµåÁêÜWeek [ÂêçÂè§Â±ã] „Äç„Å´„Éñ„Éº„Çπ„ÇíÂá∫Â±ï„Åó„Åæ„Åô„ÄÇ ‰ºöÂ†¥„Åß„ÅØ„ÄÅÊúÄÊñ∞„ÅÆAI„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥„ÇÑ„Éã„É•„Éº„ÇπÁ≠â„ÇíÈõÜ„ÇÅ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/nagoya-office-expo-no7/'>„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ7/23ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„Äå Á∑èÂãô„Éª‰∫∫‰∫ã„ÉªÁµåÁêÜWeek [ÂêçÂè§Â±ã] „Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Thu, 03 Jul 2025 01:00:19 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/nagoya-office-expo-no7/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/05/office-expo-spring-2025-nagoya.png"
  },
  {
    "title": "Training and Finetuning Reranker Models with Sentence Transformers v4",
    "description": "",
    "summary": "Training and Finetuning Reranker Models with Sentence Transformers v4 Sentence Transformers is a Pyt...",
    "pubDate": "Wed, 26 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-reranker",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "The MIT-Portugal Program enters Phase 4",
    "description": "New phase will support continued exploration of ideas and solutions in fields ranging from AI to nanotech to climate ‚Äî with emphasis on educational exchanges and entrepreneurship.",
    "summary": "New phase will support continued exploration of ideas and solutions in fields ranging from AI to nanotech to climate ‚Äî with emphasis on educational exchanges and entrepreneurship.",
    "pubDate": "Wed, 30 Apr 2025 16:20:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-portugal-program-enters-phase-4-0430",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-portugal-2024-Conference.jpg"
  },
  {
    "title": "Multi-Label Classification Framework for Hurricane Damage Assessment",
    "description": "arXiv:2507.02265v1 Announce Type: cross Abstract: Hurricanes cause widespread destruction, resulting in diverse damage types and severities that require timely and accurate assessment for effective disaster response. While traditional single-label classification methods fall short of capturing the complexity of post-hurricane damage, this study introduces a novel multi-label classification framework for assessing damage using aerial imagery. The proposed approach integrates a feature extraction module based on ResNet and a class-specific attention mechanism to identify multiple damage types within a single image. Using the Rescuenet dataset from Hurricane Michael, the proposed method achieves a mean average precision of 90.23%, outperforming existing baseline methods. This framework enhances post-hurricane damage assessment, enabling more targeted and efficient disaster response and contributing to future strategies for disaster mitigation and resilience. This paper has been accepted at the ASCE International Conference on Computing in Civil Engineering (i3CE 2025), and the camera-ready version will appear in the official conference proceedings.",
    "summary": "arXiv:2507.02265v1 Announce Type: cross Abstract: Hurricanes cause widespread destruction, resulting in diverse damage types and severities that require timely and accurate assessment for effective disaster response. While traditional single-label classification methods fall short of capturing the complexity of post-hurricane damage, this study introduces a novel multi-label classification framework for assessing damage using aerial imagery. The proposed approach integrates a feature extraction module based on ResNet and a class-specific attention mechanism to identify multiple damage types within a single image. Using the Rescuenet dataset from Hurricane Michael, the proposed method achieves a mean average precision of 90.23%, outperforming existing baseline methods. This framework enhances post-hurricane damage assessment, enabling more targeted and efficient disaster response and contributing to future strategies for disaster mitigation and resilience. This paper has been accepted at the ASCE International Conference on Computing in Civil Engineering (i3CE 2025), and the camera-ready version will appear in the official conference proceedings.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02265",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Board Forms Safety and Security Committee",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 28 May 2024 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-board-forms-safety-and-security-committee",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "XetHub is joining Hugging Face!",
    "description": "",
    "summary": "XetHub is joining Hugging Face! We are super excited to officially announce that Hugging Face acquir...",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xethub-joins-hf",
    "thumbnail": "https://huggingface.co/blog/assets/xethub-joins-hf/thumbnail.png"
  },
  {
    "title": "Introducing W√ºrstchen: Fast Diffusion for Image Generation",
    "description": "",
    "summary": "Introducing W√ºrstchen: Fast Diffusion for Image Generation What is W√ºrstchen? W√ºrstchen is a diffusi...",
    "pubDate": "Wed, 13 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/wuerstchen",
    "thumbnail": "https://huggingface.co/blog/assets/wuerstchen/thumbnail.jpg"
  },
  {
    "title": "Time-critical and confidence-based abstraction dropping methods",
    "description": "arXiv:2507.02703v1 Announce Type: new Abstract: One paradigm of Monte Carlo Tree Search (MCTS) improvements is to build and use state and/or action abstractions during the tree search. Non-exact abstractions, however, introduce an approximation error making convergence to the optimal action in the abstract space impossible. Hence, as proposed as a component of Elastic Monte Carlo Tree Search by Xu et al., abstraction algorithms should eventually drop the abstraction. In this paper, we propose two novel abstraction dropping schemes, namely OGA-IAAD and OGA-CAD which can yield clear performance improvements whilst being safe in the sense that the dropping never causes any notable performance degradations contrary to Xu's dropping method. OGA-IAAD is designed for time critical settings while OGA-CAD is designed to improve the MCTS performance with the same number of iterations.",
    "summary": "arXiv:2507.02703v1 Announce Type: new Abstract: One paradigm of Monte Carlo Tree Search (MCTS) improvements is to build and use state and/or action abstractions during the tree search. Non-exact abstractions, however, introduce an approximation error making convergence to the optimal action in the abstract space impossible. Hence, as proposed as a component of Elastic Monte Carlo Tree Search by Xu et al., abstraction algorithms should eventually drop the abstraction. In this paper, we propose two novel abstraction dropping schemes, namely OGA-IAAD and OGA-CAD which can yield clear performance improvements whilst being safe in the sense that the dropping never causes any notable performance degradations contrary to Xu's dropping method. OGA-IAAD is designed for time critical settings while OGA-CAD is designed to improve the MCTS performance with the same number of iterations.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02703",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "With AI, researchers predict the location of virtually any protein within a human cell",
    "description": "Trained with a joint understanding of protein and cell behavior, the model could help with diagnosing disease and developing new drugs.",
    "summary": "Trained with a joint understanding of protein and cell behavior, the model could help with diagnosing disease and developing new drugs.",
    "pubDate": "Thu, 15 May 2025 10:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/researchers-predict-protein-location-within-human-cell-using-ai-0515",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-ProteinLocalization-01-press.jpg"
  },
  {
    "title": "Rewriting SymCrypt in Rust to modernize Microsoft‚Äôs cryptographic library",
    "description": "<p>We're rewriting parts of Microsoft's SymCrypt cryptographic library in Rust to improve memory safety and defend against side-channel attacks, enabling formal verification while maintaining backward compatibility via a Rust-to-C compiler.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/'>Rewriting SymCrypt in Rust to modernize Microsoft‚Äôs cryptographic library¬†</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>We're rewriting parts of Microsoft's SymCrypt cryptographic library in Rust to improve memory safety and defend against side-channel attacks, enabling formal verification while maintaining backward compatibility via a Rust-to-C compiler.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/'>Rewriting SymCrypt in Rust to modernize Microsoft‚Äôs cryptographic library¬†</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Tue, 10 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Rationale engineering generates a compact new tool for gene therapy",
    "description": "Researchers redesign a compact RNA-guided enzyme from bacteria, making it an efficient editor of human DNA.",
    "summary": "Researchers redesign a compact RNA-guided enzyme from bacteria, making it an efficient editor of human DNA.",
    "pubDate": "Wed, 28 May 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/rationale-engineering-generates-compact-new-tool-gene-therapy-0528",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/phylogenetic-tree.jpg"
  },
  {
    "title": "Introducing the Hugging Face LLM Inference Container for Amazon SageMaker",
    "description": "",
    "summary": "Introducing the Hugging Face LLM Inference Container for Amazon SageMaker This is an example on how ...",
    "pubDate": "Wed, 31 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-huggingface-llm",
    "thumbnail": "https://huggingface.co/blog/assets/145_sagemaker-huggingface-llm/thumbnail.jpg"
  },
  {
    "title": "DKGCM: A Spatio-Temporal Prediction Model for Traffic Flow by Fusing Spatial Node Clustering Method and Fourier Bidirectional Mamba Mechanism",
    "description": "arXiv:2507.01982v1 Announce Type: cross Abstract: Accurate traffic demand forecasting enables transportation management departments to allocate resources more effectively, thereby improving their utilization efficiency. However, complex spatiotemporal relationships in traffic systems continue to limit the performance of demand forecasting models. To improve the accuracy of spatiotemporal traffic demand prediction, we propose a new graph convolutional network structure called DKGCM. Specifically, we first consider the spatial flow distribution of different traffic nodes and propose a novel temporal similarity-based clustering graph convolution method, DK-GCN. This method utilizes Dynamic Time Warping (DTW) and K-means clustering to group traffic nodes and more effectively capture spatial dependencies. On the temporal scale, we integrate the Fast Fourier Transform (FFT) within the bidirectional Mamba deep learning framework to capture temporal dependencies in traffic demand. To further optimize model training, we incorporate the GRPO reinforcement learning strategy to enhance the loss function feedback mechanism. Extensive experiments demonstrate that our model outperforms several advanced methods and achieves strong results on three public datasets.",
    "summary": "arXiv:2507.01982v1 Announce Type: cross Abstract: Accurate traffic demand forecasting enables transportation management departments to allocate resources more effectively, thereby improving their utilization efficiency. However, complex spatiotemporal relationships in traffic systems continue to limit the performance of demand forecasting models. To improve the accuracy of spatiotemporal traffic demand prediction, we propose a new graph convolutional network structure called DKGCM. Specifically, we first consider the spatial flow distribution of different traffic nodes and propose a novel temporal similarity-based clustering graph convolution method, DK-GCN. This method utilizes Dynamic Time Warping (DTW) and K-means clustering to group traffic nodes and more effectively capture spatial dependencies. On the temporal scale, we integrate the Fast Fourier Transform (FFT) within the bidirectional Mamba deep learning framework to capture temporal dependencies in traffic demand. To further optimize model training, we incorporate the GRPO reinforcement learning strategy to enhance the loss function feedback mechanism. Extensive experiments demonstrate that our model outperforms several advanced methods and achieves strong results on three public datasets.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01982",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization",
    "description": "arXiv:2507.02145v1 Announce Type: cross Abstract: Dialogue summarization is a challenging task with significant practical value in customer service, meeting analysis, and conversational AI. Although large language models (LLMs) have achieved substantial progress in summarization tasks, the performance of step-by-step reasoning architectures-specifically Long Chain-of-Thought (CoT) implementations such as OpenAI-o1 and DeepSeek-R1-remains unexplored for dialogue scenarios requiring concurrent abstraction and conciseness. In this work, we present the first comprehensive and systematic evaluation of state-of-the-art reasoning LLMs and non-reasoning LLMs across three major paradigms-generic, role-oriented, and query-oriented dialogue summarization. Our study spans diverse languages, domains, and summary lengths, leveraging strong benchmarks (SAMSum, DialogSum, CSDS, and QMSum) and advanced evaluation protocols that include both LLM-based automatic metrics and human-inspired criteria. Contrary to trends in other reasoning-intensive tasks, our findings show that explicit stepwise reasoning does not consistently improve dialogue summarization quality. Instead, reasoning LLMs are often prone to verbosity, factual inconsistencies, and less concise summaries compared to their non-reasoning counterparts. Through scenario-specific analyses and detailed case studies, we further identify when and why explicit reasoning may fail to benefit-or even hinder-summarization in complex dialogue contexts. Our work provides new insights into the limitations of current reasoning LLMs and highlights the need for targeted modeling and evaluation strategies for real-world dialogue summarization.",
    "summary": "arXiv:2507.02145v1 Announce Type: cross Abstract: Dialogue summarization is a challenging task with significant practical value in customer service, meeting analysis, and conversational AI. Although large language models (LLMs) have achieved substantial progress in summarization tasks, the performance of step-by-step reasoning architectures-specifically Long Chain-of-Thought (CoT) implementations such as OpenAI-o1 and DeepSeek-R1-remains unexplored for dialogue scenarios requiring concurrent abstraction and conciseness. In this work, we present the first comprehensive and systematic evaluation of state-of-the-art reasoning LLMs and non-reasoning LLMs across three major paradigms-generic, role-oriented, and query-oriented dialogue summarization. Our study spans diverse languages, domains, and summary lengths, leveraging strong benchmarks (SAMSum, DialogSum, CSDS, and QMSum) and advanced evaluation protocols that include both LLM-based automatic metrics and human-inspired criteria. Contrary to trends in other reasoning-intensive tasks, our findings show that explicit stepwise reasoning does not consistently improve dialogue summarization quality. Instead, reasoning LLMs are often prone to verbosity, factual inconsistencies, and less concise summaries compared to their non-reasoning counterparts. Through scenario-specific analyses and detailed case studies, we further identify when and why explicit reasoning may fail to benefit-or even hinder-summarization in complex dialogue contexts. Our work provides new insights into the limitations of current reasoning LLMs and highlights the need for targeted modeling and evaluation strategies for real-world dialogue summarization.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02145",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate",
    "description": "",
    "summary": "Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate This article shows how to get an incre...",
    "pubDate": "Fri, 16 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-inference-pytorch-scripts",
    "thumbnail": "https://huggingface.co/blog/assets/bloom-inference-pytorch-scripts/thumbnail.png"
  },
  {
    "title": "The Hugging Face Hub for Galleries, Libraries, Archives and Museums",
    "description": "",
    "summary": "The Hugging Face Hub for Galleries, Libraries, Archives and Museums The Hugging Face Hub for Galleri...",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hf-hub-glam-guide",
    "thumbnail": "https://huggingface.co/blog/assets/144_hf_hub_glam_guide/thumbnail.png"
  },
  {
    "title": "Announcing New Dataset Search Features",
    "description": "",
    "summary": "Announcing New Dataset Search Features The AI and ML community has shared more than 180,000 public d...",
    "pubDate": "Mon, 08 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/datasets-filters",
    "thumbnail": "https://huggingface.co/blog/assets/datasets-filters/thumbnail.png"
  },
  {
    "title": "Try new data visualizations and graphs for finance queries in AI Mode.",
    "description": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-600x600.format-webp.webp' />Today, we‚Äôre starting to roll out interactive chart visualizations in AI Mode in Labs to help bring financial data to life for questions on stocks and mutual funds.Now, ‚Ä¶",
    "summary": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-600x600.format-webp.webp' />Today, we‚Äôre starting to roll out interactive chart visualizations in AI Mode in Labs to help bring financial data to life for questions on stocks and mutual funds.Now, ‚Ä¶",
    "pubDate": "Thu, 05 Jun 2025 19:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/ai-mode-data-visualization/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-1440x810.png"
  },
  {
    "title": "AudioLDM 2, but faster ‚ö°Ô∏è",
    "description": "",
    "summary": "AudioLDM 2, but faster ‚ö°Ô∏è AudioLDM 2 was proposed in AudioLDM 2: Learning Holistic Audio Generation ...",
    "pubDate": "Wed, 30 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/audioldm2",
    "thumbnail": "https://huggingface.co/blog/assets/161_audioldm2/thumbnail.png"
  },
  {
    "title": "MTEB: Massive Text Embedding Benchmark",
    "description": "",
    "summary": "MTEB: Massive Text Embedding Benchmark MTEB is a massive benchmark for measuring the performance of ...",
    "pubDate": "Wed, 19 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mteb",
    "thumbnail": "https://huggingface.co/blog/assets/110_mteb/thumbnail.png"
  },
  {
    "title": "What's new in Diffusers? üé®",
    "description": "",
    "summary": "What's new in Diffusers? üé® A month and a half ago we released diffusers , a library that provides a ...",
    "pubDate": "Mon, 12 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-2nd-month",
    "thumbnail": "https://huggingface.co/blog/assets/102_diffusers_2nd_month/inpainting.png"
  },
  {
    "title": "Proximal Policy Optimization",
    "description": "We‚Äôre releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune. PPO has become the default reinforcement learning algorithm at OpenAI because of its ease of use and good performance.",
    "summary": "We‚Äôre releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune. PPO has become the default reinforcement learning algorithm at OpenAI because of its ease of use and good performance.",
    "pubDate": "Thu, 20 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-ppo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges",
    "description": "arXiv:2507.02074v1 Announce Type: cross Abstract: Crash detection from video feeds is a critical problem in intelligent transportation systems. Recent developments in large language models (LLMs) and vision-language models (VLMs) have transformed how we process, reason about, and summarize multimodal information. This paper surveys recent methods leveraging LLMs for crash detection from video data. We present a structured taxonomy of fusion strategies, summarize key datasets, analyze model architectures, compare performance benchmarks, and discuss ongoing challenges and opportunities. Our review provides a foundation for future research in this fast-growing intersection of video understanding and foundation models.",
    "summary": "arXiv:2507.02074v1 Announce Type: cross Abstract: Crash detection from video feeds is a critical problem in intelligent transportation systems. Recent developments in large language models (LLMs) and vision-language models (VLMs) have transformed how we process, reason about, and summarize multimodal information. This paper surveys recent methods leveraging LLMs for crash detection from video data. We present a structured taxonomy of fusion strategies, summarize key datasets, analyze model architectures, compare performance benchmarks, and discuss ongoing challenges and opportunities. Our review provides a foundation for future research in this fast-growing intersection of video understanding and foundation models.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02074",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome spaCy to the ü§ó Hub",
    "description": "",
    "summary": "Welcome spaCy to the Hugging Face Hub spaCy is a popular library for advanced Natural Language Proce...",
    "pubDate": "Tue, 13 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spacy",
    "thumbnail": "https://huggingface.co/blog/assets/23_spacy/thumbnail.png"
  },
  {
    "title": "Introducing RWKV ‚Äî An RNN with the advantages of a transformer",
    "description": "",
    "summary": "Introducing RWKV - An RNN with the advantages of a transformer ChatGPT and chatbot-powered applicati...",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rwkv",
    "thumbnail": "https://huggingface.co/blog/assets/142_rwkv/rwkv_thumbnail.png"
  },
  {
    "title": "Variational lossy autoencoder",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 08 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variational-lossy-autoencoder",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning complex goals with iterated amplification",
    "description": "We‚Äôre proposing an AI safety technique called iterated amplification that lets us specify complicated behaviors and goals that are beyond human scale, by demonstrating how to decompose a task into simpler sub-tasks, rather than by providing labeled data or a reward function. Although this idea is in its very early stages and we have only completed experiments on simple toy algorithmic domains, we‚Äôve decided to present it in its preliminary state because we think it could prove to be a scalable approach to AI¬†safety.",
    "summary": "We‚Äôre proposing an AI safety technique called iterated amplification that lets us specify complicated behaviors and goals that are beyond human scale, by demonstrating how to decompose a task into simpler sub-tasks, rather than by providing labeled data or a reward function. Although this idea is in its very early stages and we have only completed experiments on simple toy algorithmic domains, we‚Äôve decided to present it in its preliminary state because we think it could prove to be a scalable approach to AI¬†safety.",
    "pubDate": "Mon, 22 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-complex-goals-with-iterated-amplification",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Detecting misbehavior in frontier reasoning models",
    "description": "Frontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM to monitor their chains-of-thought. Penalizing their ‚Äúbad thoughts‚Äù doesn‚Äôt stop the majority of misbehavior‚Äîit makes them hide their intent.",
    "summary": "Frontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM to monitor their chains-of-thought. Penalizing their ‚Äúbad thoughts‚Äù doesn‚Äôt stop the majority of misbehavior‚Äîit makes them hide their intent.",
    "pubDate": "Mon, 10 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chain-of-thought-monitoring",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Community Tools on HuggingChat",
    "description": "",
    "summary": "Introducing Community Tools on HuggingChat Today we‚Äôre releasing our latest feature on HuggingChat: ...",
    "pubDate": "Mon, 16 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-tools",
    "thumbnail": "https://huggingface.co/blog/assets/community-tools/thumbnail.png"
  },
  {
    "title": "We‚Äôre expanding our Gemini 2.5 family of models",
    "description": "Gemini 2.5 Flash and Pro are now generally available, and we‚Äôre introducing 2.5 Flash-Lite, our most cost-efficient and fastest 2.5 model yet.",
    "summary": "Gemini 2.5 Flash and Pro are now generally available, and we‚Äôre introducing 2.5 Flash-Lite, our most cost-efficient and fastest 2.5 model yet.",
    "pubDate": "Tue, 17 Jun 2025 16:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/were-expanding-our-gemini-25-family-of-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_bundle_keyword_social-share_1920-1080.width-1300.png"
  },
  {
    "title": "Introducing Prodigy-HF: a direct integration with Hugging Face",
    "description": "",
    "summary": "Introducing Prodigy-HF Prodigy is an annotation tool made by Explosion, a company well known as the ...",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/prodigy-hf",
    "thumbnail": "https://huggingface.co/blog/assets/171_prodigy_hf/thumbnail.png"
  },
  {
    "title": "Learning from other domains to advance AI evaluation and testing",
    "description": "<p>As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the [&#8230;]</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/'>Learning from other domains to advance AI evaluation and testing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the [&#8230;]</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/'>Learning from other domains to advance AI evaluation and testing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 16:35:06 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "OpenAI o1 System Card External Testers Acknowledgements",
    "description": "OpenAI o1 system card external testers acknowledgements",
    "summary": "OpenAI o1 system card external testers acknowledgements",
    "pubDate": "Thu, 12 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-system-card/external-testers-acknowledgements",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bringing the Artificial Analysis LLM Performance Leaderboard to Hugging Face",
    "description": "",
    "summary": "Bringing the Artificial Analysis LLM Performance Leaderboard to Hugging Face Building applications w...",
    "pubDate": "Fri, 03 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-artificial-analysis",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_artificialanalysis.png"
  },
  {
    "title": "Introducing the SWE-Lancer benchmark",
    "description": "Can frontier LLMs earn $1 million from real-world freelance software engineering?",
    "summary": "Can frontier LLMs earn $1 million from real-world freelance software engineering?",
    "pubDate": "Tue, 18 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/swe-lancer",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling up learning across many different robot types",
    "description": "Robots are great specialists, but poor generalists. Typically, you have to train a model for each task, robot, and environment. Changing a single variable often requires starting from scratch. But what if we could combine the knowledge across robotics and create a way to train a general-purpose robot?",
    "summary": "Robots are great specialists, but poor generalists. Typically, you have to train a model for each task, robot, and environment. Changing a single variable often requires starting from scratch. But what if we could combine the knowledge across robotics and create a way to train a general-purpose robot?",
    "pubDate": "Tue, 03 Oct 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/scaling-up-learning-across-many-different-robot-types/",
    "thumbnail": "https://lh3.googleusercontent.com/KiNtKw6sX-3WmNln5pnEZjPMfM7VJLg0qe4VshEj_H_oXCI9hb6iGWl1DPx79WBb4EVds8mq2wUq_n9s2Lk8kkWazPtootwAUYBKxBEp64WTcEmXa6U=w1200-h630-n-nu"
  },
  {
    "title": "üá®üáø BenCzechMark - Can your LLM Understand Czech?",
    "description": "",
    "summary": "üá®üáø BenCzechMark - Can your LLM Understand Czech? The üá®üáø BenCzechMark is the first and most comprehen...",
    "pubDate": "Tue, 01 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/benczechmark",
    "thumbnail": "https://huggingface.co/blog/assets/187_benczechmark/thumbnail.png"
  },
  {
    "title": "OpenAI‚Äôs response to the Department of Energy on AI infrastructure",
    "description": "Why infrastructure is destiny and how the US can seize it.",
    "summary": "Why infrastructure is destiny and how the US can seize it.",
    "pubDate": "Wed, 07 May 2025 18:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-department-of-energy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Getting Started with Transformers on Habana Gaudi",
    "description": "",
    "summary": "Getting Started with Transformers on Habana Gaudi A couple of weeks ago, we've had the pleasure to a...",
    "pubDate": "Tue, 26 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/getting-started-habana",
    "thumbnail": "https://huggingface.co/blog/assets/61_getting_started_habana/habana01.png"
  },
  {
    "title": "Solving complex problems with OpenAI o1 models",
    "description": "In this video, we share how the o1 reasoning models can help in domains like coding, strategy, and research.",
    "summary": "In this video, we share how the o1 reasoning models can help in domains like coding, strategy, and research.",
    "pubDate": "Thu, 17 Oct 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/solving-complex-problems-with-openai-o1-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding the capabilities, limitations, and societal impact of large language models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 04 Feb 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/understanding-the-capabilities-limitations-and-societal-impact-of-large-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interpretable and pedagogical examples",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 02 Nov 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/interpretable-and-pedagogical-examples",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Launching the Artificial Analysis Text to Image Leaderboard & Arena",
    "description": "",
    "summary": "Launching the Artificial Analysis Text to Image Leaderboard & Arena In two short years since the adv...",
    "pubDate": "Thu, 06 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-artificial-analysis2",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_artificialanalysis.png"
  },
  {
    "title": "Blazingly fast whisper transcriptions with Inference Endpoints",
    "description": "",
    "summary": "Blazingly fast whisper transcriptions with Inference Endpoints Today we are happy to introduce a new...",
    "pubDate": "Tue, 13 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-whisper-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/fast-whisper-endpoints/thumbnail.png"
  },
  {
    "title": "Optimizing your LLM in production",
    "description": "",
    "summary": "Optimizing your LLM in production Note: This blog post is also available as a documentation page on ...",
    "pubDate": "Fri, 15 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimize-llm",
    "thumbnail": "https://huggingface.co/blog/assets/163_optimize_llm/optimize_llm.png"
  },
  {
    "title": "HelixDesign-Antibody: A Scalable Production-Grade Platform for Antibody Design Built on HelixFold3",
    "description": "arXiv:2507.02345v1 Announce Type: cross Abstract: Antibody engineering is essential for developing therapeutics and advancing biomedical research. Traditional discovery methods often rely on time-consuming and resource-intensive experimental screening. To enhance and streamline this process, we introduce a production-grade, high-throughput platform built on HelixFold3, HelixDesign-Antibody, which utilizes the high-accuracy structure prediction model, HelixFold3. The platform facilitates the large-scale generation of antibody candidate sequences and evaluates their interaction with antigens. Integrated high-performance computing (HPC) support enables high-throughput screening, addressing challenges such as fragmented toolchains and high computational demands. Validation on multiple antigens showcases the platform's ability to generate diverse and high-quality antibodies, confirming a scaling law where exploring larger sequence spaces increases the likelihood of identifying optimal binders. This platform provides a seamless, accessible solution for large-scale antibody design and is available via the antibody design page of PaddleHelix platform.",
    "summary": "arXiv:2507.02345v1 Announce Type: cross Abstract: Antibody engineering is essential for developing therapeutics and advancing biomedical research. Traditional discovery methods often rely on time-consuming and resource-intensive experimental screening. To enhance and streamline this process, we introduce a production-grade, high-throughput platform built on HelixFold3, HelixDesign-Antibody, which utilizes the high-accuracy structure prediction model, HelixFold3. The platform facilitates the large-scale generation of antibody candidate sequences and evaluates their interaction with antigens. Integrated high-performance computing (HPC) support enables high-throughput screening, addressing challenges such as fragmented toolchains and high computational demands. Validation on multiple antigens showcases the platform's ability to generate diverse and high-quality antibodies, confirming a scaling law where exploring larger sequence spaces increases the likelihood of identifying optimal binders. This platform provides a seamless, accessible solution for large-scale antibody design and is available via the antibody design page of PaddleHelix platform.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02345",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "YouTube: Enhancing the user experience",
    "description": "It‚Äôs all about using our technology and research to help enrich people‚Äôs lives. Like YouTube ‚Äî and its mission to give everyone a voice and show them the world.",
    "summary": "It‚Äôs all about using our technology and research to help enrich people‚Äôs lives. Like YouTube ‚Äî and its mission to give everyone a voice and show them the world.",
    "pubDate": "Fri, 16 Jun 2023 14:55:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/youtube-enhancing-the-user-experience/",
    "thumbnail": "https://lh3.googleusercontent.com/RAMu-2QAkfHieGDWkYFQOMiATW-wFi6jMLyC-YJ4f6Jj1H5BlhxQBmfQrb4RS6Sc6DFLFJqBahK3_1--XjoFPdGqYsCdSuTNr-pTcLkRO5SqvReblIQ=w1200-h630-n-nu"
  },
  {
    "title": "Ethics and Society Newsletter #1",
    "description": "",
    "summary": "Ethics and Society Newsletter #1 Hello, world! Originating as an open-source company, Hugging Face w...",
    "pubDate": "Thu, 22 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-1",
    "thumbnail": "https://huggingface.co/blog/assets/103_ethics-soc-1/thumbnail.png"
  },
  {
    "title": "Instruction-tuning Stable Diffusion with InstructPix2Pix",
    "description": "",
    "summary": "Instruction-tuning Stable Diffusion with InstructPix2Pix This post explores instruction-tuning to te...",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/instruction-tuning-sd",
    "thumbnail": "https://huggingface.co/blog/instruction-tuning-sd/assets/instruction_tuning_sd/thumbnail.png"
  },
  {
    "title": "GPT-2: 6-month follow-up",
    "description": "We‚Äôre releasing the 774 million parameter GPT-2 language model after the release of our small¬†124M model¬†in February, staged release of our medium¬†355M model¬†in May, and subsequent research with partners and the AI community into the model‚Äôs potential for misuse and societal benefit. We‚Äôre also releasing an open-source legal agreement to make it easier for organizations to initiate model-sharing partnerships with each other, and are publishing a technical report about our experience in coordinating with the wider AI research community on publication¬†norms.",
    "summary": "We‚Äôre releasing the 774 million parameter GPT-2 language model after the release of our small¬†124M model¬†in February, staged release of our medium¬†355M model¬†in May, and subsequent research with partners and the AI community into the model‚Äôs potential for misuse and societal benefit. We‚Äôre also releasing an open-source legal agreement to make it easier for organizations to initiate model-sharing partnerships with each other, and are publishing a technical report about our experience in coordinating with the wider AI research community on publication¬†norms.",
    "pubDate": "Tue, 20 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-2-6-month-follow-up",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Solving Rubik‚Äôs Cube with a robot hand",
    "description": "We‚Äôve trained a pair of neural networks to solve the Rubik‚Äôs Cube with a human-like robot hand. The neural networks are trained entirely in simulation, using the same reinforcement learning code as¬†OpenAI Five¬†paired with a new technique called Automatic Domain Randomization (ADR). The system can handle situations it never saw during training, such as being prodded by a¬†stuffed giraffe. This shows that reinforcement learning isn‚Äôt just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.",
    "summary": "We‚Äôve trained a pair of neural networks to solve the Rubik‚Äôs Cube with a human-like robot hand. The neural networks are trained entirely in simulation, using the same reinforcement learning code as¬†OpenAI Five¬†paired with a new technique called Automatic Domain Randomization (ADR). The system can handle situations it never saw during training, such as being prodded by a¬†stuffed giraffe. This shows that reinforcement learning isn‚Äôt just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.",
    "pubDate": "Tue, 15 Oct 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/solving-rubiks-cube",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A failed experiment: Infini-Attention, and why we should keep trying?",
    "description": "",
    "summary": "A failed experiment: Infini-Attention, and why we should keep trying? TLDR: Infini-attention's perfo...",
    "pubDate": "Wed, 14 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/infini-attention",
    "thumbnail": "https://huggingface.co/blog/infini-attention/assets/185_infini_attention/infini_attention_thumbnail.png"
  },
  {
    "title": "Announcing the ü§ó AI Research Residency Program",
    "description": "",
    "summary": "Announcing the ü§ó AI Research Residency Program üéâ üéâ üéâ The ü§ó Research Residency Program is a 9-month o...",
    "pubDate": "Tue, 22 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-residency",
    "thumbnail": "https://huggingface.co/blog/assets/57_ai_residency/residency-thumbnail.jpg"
  },
  {
    "title": "ClustOpt: A Clustering-based Approach for Representing and Visualizing the Search Dynamics of Numerical Metaheuristic Optimization Algorithms",
    "description": "arXiv:2507.02337v1 Announce Type: cross Abstract: Understanding the behavior of numerical metaheuristic optimization algorithms is critical for advancing their development and application. Traditional visualization techniques, such as convergence plots, trajectory mapping, and fitness landscape analysis, often fall short in illustrating the structural dynamics of the search process, especially in high-dimensional or complex solution spaces. To address this, we propose a novel representation and visualization methodology that clusters solution candidates explored by the algorithm and tracks the evolution of cluster memberships across iterations, offering a dynamic and interpretable view of the search process. Additionally, we introduce two metrics - algorithm stability and algorithm similarity- to quantify the consistency of search trajectories across runs of an individual algorithm and the similarity between different algorithms, respectively. We apply this methodology to a set of ten numerical metaheuristic algorithms, revealing insights into their stability and comparative behaviors, thereby providing a deeper understanding of their search dynamics.",
    "summary": "arXiv:2507.02337v1 Announce Type: cross Abstract: Understanding the behavior of numerical metaheuristic optimization algorithms is critical for advancing their development and application. Traditional visualization techniques, such as convergence plots, trajectory mapping, and fitness landscape analysis, often fall short in illustrating the structural dynamics of the search process, especially in high-dimensional or complex solution spaces. To address this, we propose a novel representation and visualization methodology that clusters solution candidates explored by the algorithm and tracks the evolution of cluster memberships across iterations, offering a dynamic and interpretable view of the search process. Additionally, we introduce two metrics - algorithm stability and algorithm similarity- to quantify the consistency of search trajectories across runs of an individual algorithm and the similarity between different algorithms, respectively. We apply this methodology to a set of ten numerical metaheuristic algorithms, revealing insights into their stability and comparative behaviors, thereby providing a deeper understanding of their search dynamics.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02337",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Reformer - Pushing the limits of language modeling",
    "description": "",
    "summary": "The Reformer - Pushing the limits of language modeling How the Reformer uses less than 8GB of RAM to...",
    "pubDate": "Fri, 03 Jul 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/reformer",
    "thumbnail": "https://huggingface.co/blog/assets/03_reformer/thumbnail.png"
  },
  {
    "title": "Image Similarity with Hugging Face Datasets and Transformers",
    "description": "",
    "summary": "Image Similarity with Hugging Face Datasets and Transformers In this post, you'll learn to build an ...",
    "pubDate": "Mon, 16 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-similarity",
    "thumbnail": "https://huggingface.co/blog/assets/image_similarity/thumbnail.png"
  },
  {
    "title": "A Student‚Äôs Guide to Writing with ChatGPT",
    "description": "A Student‚Äôs Guide to Writing with ChatGPT",
    "summary": "A Student‚Äôs Guide to Writing with ChatGPT",
    "pubDate": "Wed, 13 Nov 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/chatgpt/use-cases/student-writing-guide",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Verdi, an AI dev platform powered by GPT-4o",
    "description": "Mercado Libre introduces Verdi, an AI developer platform powered by GPT-4o",
    "summary": "Mercado Libre introduces Verdi, an AI developer platform powered by GPT-4o",
    "pubDate": "Tue, 24 Sep 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mercado-libre",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Animator Lyndon Barrois creates new worlds with Sora",
    "description": "Filmmaker Lyndon Barrois describes how to use Sora as a storytelling tool.",
    "summary": "Filmmaker Lyndon Barrois describes how to use Sora as a storytelling tool.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-lyndon-barrois",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Image search with ü§ó datasets",
    "description": "",
    "summary": "Image search with ü§ó datasets ü§ó datasets is a library that makes it easy to access and share datasets...",
    "pubDate": "Wed, 16 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-search-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/54_image_search_datasets/spaces_image_search.jpg"
  },
  {
    "title": "Stargate Infrastructure",
    "description": "OpenAI, and our strategic partners, are thrilled about our shared vision for the Infrastructure of AGI. We are energized by the challenges we face and are excited by the prospect of partnering with firms across the industrial base to deliver against our ambitious mission. Specifically, we want to connect with firms across the built data center infrastructure landscape, from power and land to construction to equipment, and everything in between.",
    "summary": "OpenAI, and our strategic partners, are thrilled about our shared vision for the Infrastructure of AGI. We are energized by the challenges we face and are excited by the prospect of partnering with firms across the industrial base to deliver against our ambitious mission. Specifically, we want to connect with firms across the built data center infrastructure landscape, from power and land to construction to equipment, and everything in between.",
    "pubDate": "Tue, 21 Jan 2025 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/form/stargate-infrastructure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Third-person imitation learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 06 Mar 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/third-person-imitation-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Gradio's new Dataframe!",
    "description": "",
    "summary": "Introducing Gradio's new Dataframe! Gradio‚Äôs gr.Dataframe component is one of our most popular compo...",
    "pubDate": "Mon, 24 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-dataframe-upgrade",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-dataframe-upgrade/thumbnail.png"
  },
  {
    "title": "AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration",
    "description": "arXiv:2506.19283v3 Announce Type: replace-cross Abstract: While multi-vehicular collaborative driving demonstrates clear advantages over single-vehicle autonomy, traditional infrastructure-based V2X systems remain constrained by substantial deployment costs and the creation of 'uncovered danger zones' in rural and suburban areas. We present AirV2X-Perception, a large-scale dataset that leverages Unmanned Aerial Vehicles (UAVs) as a flexible alternative or complement to fixed Road-Side Units (RSUs). Drones offer unique advantages over ground-based perception: complementary bird's-eye-views that reduce occlusions, dynamic positioning capabilities that enable hovering, patrolling, and escorting navigation rules, and significantly lower deployment costs compared to fixed infrastructure. Our dataset comprises 6.73 hours of drone-assisted driving scenarios across urban, suburban, and rural environments with varied weather and lighting conditions. The AirV2X-Perception dataset facilitates the development and standardized evaluation of Vehicle-to-Drone (V2D) algorithms, addressing a critical gap in the rapidly expanding field of aerial-assisted autonomous driving systems. The dataset and development kits are open-sourced at https://github.com/taco-group/AirV2X-Perception.",
    "summary": "arXiv:2506.19283v3 Announce Type: replace-cross Abstract: While multi-vehicular collaborative driving demonstrates clear advantages over single-vehicle autonomy, traditional infrastructure-based V2X systems remain constrained by substantial deployment costs and the creation of 'uncovered danger zones' in rural and suburban areas. We present AirV2X-Perception, a large-scale dataset that leverages Unmanned Aerial Vehicles (UAVs) as a flexible alternative or complement to fixed Road-Side Units (RSUs). Drones offer unique advantages over ground-based perception: complementary bird's-eye-views that reduce occlusions, dynamic positioning capabilities that enable hovering, patrolling, and escorting navigation rules, and significantly lower deployment costs compared to fixed infrastructure. Our dataset comprises 6.73 hours of drone-assisted driving scenarios across urban, suburban, and rural environments with varied weather and lighting conditions. The AirV2X-Perception dataset facilitates the development and standardized evaluation of Vehicle-to-Drone (V2D) algorithms, addressing a critical gap in the rapidly expanding field of aerial-assisted autonomous driving systems. The dataset and development kits are open-sourced at https://github.com/taco-group/AirV2X-Perception.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19283",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Computer-Using Agent",
    "description": "A universal interface for AI to interact with the digital world.",
    "summary": "A universal interface for AI to interact with the digital world.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/computer-using-agent",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our Transformers Code Agent beats the GAIA benchmark!",
    "description": "",
    "summary": "Our Transformers Code Agent beats the GAIA benchmark! TL;DR After some experiments, we were impresse...",
    "pubDate": "Mon, 01 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/beating-gaia",
    "thumbnail": "https://huggingface.co/blog/assets/beating-gaia/thumbnail.jpeg"
  },
  {
    "title": "Introducing canvas, a new way to write and code with ChatGPT.",
    "description": "Introducing canvas",
    "summary": "Introducing canvas",
    "pubDate": "Thu, 03 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-canvas",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community",
    "description": "",
    "summary": "From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community The Elixir community is ...",
    "pubDate": "Fri, 09 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/elixir-bumblebee",
    "thumbnail": "https://huggingface.co/blog/assets/120_elixir-bumblebee/thumbnail.png"
  },
  {
    "title": "OpenAI acquires Rockset",
    "description": "OpenAI Acquires Rockset",
    "summary": "OpenAI Acquires Rockset",
    "pubDate": "Fri, 21 Jun 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-acquires-rockset",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Teaching models to express their uncertainty in words",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 28 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teaching-models-to-express-their-uncertainty-in-words",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Falcon 2: An 11B parameter pretrained language model and VLM, trained on over 5000B tokens tokens and 11 languages",
    "description": "",
    "summary": "Falcon 2: An 11B parameter pretrained language model and VLM, trained on over 5000B tokens and 11 la...",
    "pubDate": "Fri, 24 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon2-11b",
    "thumbnail": "https://huggingface.co/blog/assets/179_falcon2-11b/thumbnail.jpg"
  },
  {
    "title": "FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models",
    "description": "arXiv:2507.02714v1 Announce Type: cross Abstract: Image generation has achieved remarkable progress with the development of large-scale text-to-image models, especially diffusion-based models. However, generating human images with plausible details, such as faces or hands, remains challenging due to insufficient supervision of local regions during training. To address this issue, we propose FairHuman, a multi-objective fine-tuning approach designed to enhance both global and local generation quality fairly. Specifically, we first construct three learning objectives: a global objective derived from the default diffusion objective function and two local objectives for hands and faces based on pre-annotated positional priors. Subsequently, we derive the optimal parameter updating strategy under the guidance of the Minimum Potential Delay (MPD) criterion, thereby attaining fairness-ware optimization for this multi-objective problem. Based on this, our proposed method can achieve significant improvements in generating challenging local details while maintaining overall quality. Extensive experiments showcase the effectiveness of our method in improving the performance of human image generation under different scenarios.",
    "summary": "arXiv:2507.02714v1 Announce Type: cross Abstract: Image generation has achieved remarkable progress with the development of large-scale text-to-image models, especially diffusion-based models. However, generating human images with plausible details, such as faces or hands, remains challenging due to insufficient supervision of local regions during training. To address this issue, we propose FairHuman, a multi-objective fine-tuning approach designed to enhance both global and local generation quality fairly. Specifically, we first construct three learning objectives: a global objective derived from the default diffusion objective function and two local objectives for hands and faces based on pre-annotated positional priors. Subsequently, we derive the optimal parameter updating strategy under the guidance of the Minimum Potential Delay (MPD) criterion, thereby attaining fairness-ware optimization for this multi-objective problem. Based on this, our proposed method can achieve significant improvements in generating challenging local details while maintaining overall quality. Extensive experiments showcase the effectiveness of our method in improving the performance of human image generation under different scenarios.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02714",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Frontier Safety Framework",
    "description": "Our approach to analyzing and mitigating future risks posed by advanced AI models",
    "summary": "Our approach to analyzing and mitigating future risks posed by advanced AI models",
    "pubDate": "Fri, 17 May 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/",
    "thumbnail": "https://lh3.googleusercontent.com/_NVnftxEp6r9O9gnZT2_jLPpIn_nGjYp9xgl8hFhg_-fX131_koFcj6znzflexf4-MdfkSTtA060-Hh7RcvVkNkY5kQ-QBulRYDCO1Li1R1jK71G=w1200-h630-n-nu"
  },
  {
    "title": "Introducing 4o Image Generation",
    "description": "At OpenAI, we have long believed image generation should be a primary capability of our language models. That‚Äôs why we‚Äôve built our most advanced image generator yet into GPT‚Äë4o. The result‚Äîimage generation that is not only beautiful, but useful.",
    "summary": "At OpenAI, we have long believed image generation should be a primary capability of our language models. That‚Äôs why we‚Äôve built our most advanced image generator yet into GPT‚Äë4o. The result‚Äîimage generation that is not only beautiful, but useful.",
    "pubDate": "Tue, 25 Mar 2025 11:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-4o-image-generation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How Sempre Health is leveraging the Expert Acceleration Program to accelerate their ML roadmap",
    "description": "",
    "summary": "How Sempre Health is leveraging the Expert Acceleration Program to accelerate their ML roadmap üëã Hel...",
    "pubDate": "Thu, 19 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sempre-health-eap-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/70_sempre_health/thumbnail.jpg"
  },
  {
    "title": "DALL¬∑E 2 research preview update",
    "description": "Early users have created over 3 million images to date and helped us improve our safety processes. We‚Äôre excited to begin adding up to 1,000 new users from our waitlist each week.",
    "summary": "Early users have created over 3 million images to date and helped us improve our safety processes. We‚Äôre excited to begin adding up to 1,000 new users from our waitlist each week.",
    "pubDate": "Wed, 18 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI‚Äôs approach to AI and national security",
    "description": "OpenAI‚Äôs approach to AI and national security",
    "summary": "OpenAI‚Äôs approach to AI and national security",
    "pubDate": "Thu, 24 Oct 2024 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-approach-to-ai-and-national-security",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Fellows Fall 2018: Final projects",
    "description": "Our second class of OpenAI Fellows has wrapped up, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship. We are currently reviewing applications on a rolling basis for our next round of OpenAI Fellows Summer 2019.",
    "summary": "Our second class of OpenAI Fellows has wrapped up, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship. We are currently reviewing applications on a rolling basis for our next round of OpenAI Fellows Summer 2019.",
    "pubDate": "Fri, 17 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows-fall-2018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ryght‚Äôs Journey to Empower Healthcare and Life Sciences with Expert Support from Hugging Face",
    "description": "",
    "summary": "Ryght‚Äôs Journey to Empower Healthcare and Life Sciences with Expert Support from Hugging Face This i...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ryght-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/ryght-case-study/thumbnail.png"
  },
  {
    "title": "Welcome Llama 4 Maverick & Scout on Hugging Face!",
    "description": "",
    "summary": "Welcome Llama 4 Maverick & Scout on Hugging Face We are incredibly excited to welcome the next gener...",
    "pubDate": "Sat, 05 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama4-release",
    "thumbnail": "https://huggingface.co/blog/assets/llama_4.png"
  },
  {
    "title": "AI safety needs social scientists",
    "description": "We‚Äôve written a paper arguing that long-term AI safety research needs social scientists to ensure AI alignment algorithms succeed when actual humans are involved. Properly aligning advanced AI systems with human values requires resolving many uncertainties related to the psychology of human rationality, emotion, and biases. The aim of this paper is to spark further collaboration between machine learning and social science researchers, and we plan to¬†hire¬†social scientists to work on this full time at¬†OpenAI.",
    "summary": "We‚Äôve written a paper arguing that long-term AI safety research needs social scientists to ensure AI alignment algorithms succeed when actual humans are involved. Properly aligning advanced AI systems with human values requires resolving many uncertainties related to the psychology of human rationality, emotion, and biases. The aim of this paper is to spark further collaboration between machine learning and social science researchers, and we plan to¬†hire¬†social scientists to work on this full time at¬†OpenAI.",
    "pubDate": "Tue, 19 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-safety-needs-social-scientists",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaDev discovers faster sorting algorithms",
    "description": "New algorithms will transform the foundations of computing",
    "summary": "New algorithms will transform the foundations of computing",
    "pubDate": "Wed, 07 Jun 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphadev-discovers-faster-sorting-algorithms/",
    "thumbnail": "https://lh3.googleusercontent.com/kYAs9KTHdhYZE0BeKMKlphVqU3eQS8oXP_GNrrWBjFbl8r4YFv2FWlRbe6x9L4Q_L-eKZeE7E__GtKVJTLXvW_zGTTzplSJCplN02n_8cz7No815L5M=w1200-h630-n-nu"
  },
  {
    "title": "AI powers Expedia‚Äôs marketing evolution",
    "description": "A conversation with Jochen Koedijk, Chief Marketing Officer of Expedia Group.",
    "summary": "A conversation with Jochen Koedijk, Chief Marketing Officer of Expedia Group.",
    "pubDate": "Wed, 14 May 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expedia-jochen-koedijk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Teaching with AI",
    "description": "We‚Äôre releasing a guide for teachers using ChatGPT in their classroom‚Äîincluding suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.",
    "summary": "We‚Äôre releasing a guide for teachers using ChatGPT in their classroom‚Äîincluding suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.",
    "pubDate": "Thu, 31 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teaching-with-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Autoformalization in the Era of Large Language Models: A Survey",
    "description": "arXiv:2505.23486v2 Announce Type: replace Abstract: Autoformalization, the process of transforming informal mathematical propositions into verifiable formal representations, is a foundational task in automated theorem proving, offering a new perspective on the use of mathematics in both theoretical and applied domains. Driven by the rapid progress in artificial intelligence, particularly large language models (LLMs), this field has witnessed substantial growth, bringing both new opportunities and unique challenges. In this survey, we provide a comprehensive overview of recent advances in autoformalization from both mathematical and LLM-centric perspectives. We examine how autoformalization is applied across various mathematical domains and levels of difficulty, and analyze the end-to-end workflow from data preprocessing to model design and evaluation. We further explore the emerging role of autoformalization in enhancing the verifiability of LLM-generated outputs, highlighting its potential to improve both the trustworthiness and reasoning capabilities of LLMs. Finally, we summarize key open-source models and datasets supporting current research, and discuss open challenges and promising future directions for the field.",
    "summary": "arXiv:2505.23486v2 Announce Type: replace Abstract: Autoformalization, the process of transforming informal mathematical propositions into verifiable formal representations, is a foundational task in automated theorem proving, offering a new perspective on the use of mathematics in both theoretical and applied domains. Driven by the rapid progress in artificial intelligence, particularly large language models (LLMs), this field has witnessed substantial growth, bringing both new opportunities and unique challenges. In this survey, we provide a comprehensive overview of recent advances in autoformalization from both mathematical and LLM-centric perspectives. We examine how autoformalization is applied across various mathematical domains and levels of difficulty, and analyze the end-to-end workflow from data preprocessing to model design and evaluation. We further explore the emerging role of autoformalization in enhancing the verifiability of LLM-generated outputs, highlighting its potential to improve both the trustworthiness and reasoning capabilities of LLMs. Finally, we summarize key open-source models and datasets supporting current research, and discuss open challenges and promising future directions for the field.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.23486",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evaluating Language Models For Threat Detection in IoT Security Logs",
    "description": "arXiv:2507.02390v1 Announce Type: cross Abstract: Log analysis is a relevant research field in cybersecurity as they can provide a source of information for the detection of threats to networks and systems. This paper presents a pipeline to use fine-tuned Large Language Models (LLMs) for anomaly detection and mitigation recommendation using IoT security logs. Utilizing classical machine learning classifiers as a baseline, three open-source LLMs are compared for binary and multiclass anomaly detection, with three strategies: zero-shot, few-shot prompting and fine-tuning using an IoT dataset. LLMs give better results on multi-class attack classification than the corresponding baseline models. By mapping detected threats to MITRE CAPEC, defining a set of IoT-specific mitigation actions, and fine-tuning the models with those actions, the models are able to provide a combined detection and recommendation guidance.",
    "summary": "arXiv:2507.02390v1 Announce Type: cross Abstract: Log analysis is a relevant research field in cybersecurity as they can provide a source of information for the detection of threats to networks and systems. This paper presents a pipeline to use fine-tuned Large Language Models (LLMs) for anomaly detection and mitigation recommendation using IoT security logs. Utilizing classical machine learning classifiers as a baseline, three open-source LLMs are compared for binary and multiclass anomaly detection, with three strategies: zero-shot, few-shot prompting and fine-tuning using an IoT dataset. LLMs give better results on multi-class attack classification than the corresponding baseline models. By mapping detected threats to MITRE CAPEC, defining a set of IoT-specific mitigation actions, and fine-tuning the models with those actions, the models are able to provide a combined detection and recommendation guidance.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02390",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Promega‚Äôs top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "description": "Promega's top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "summary": "Promega's top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "pubDate": "Thu, 31 Oct 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/promega",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pushing the frontiers of audio generation",
    "description": "Our pioneering speech generation technologies are helping people around the world interact with more natural, conversational and intuitive digital assistants and AI tools.",
    "summary": "Our pioneering speech generation technologies are helping people around the world interact with more natural, conversational and intuitive digital assistants and AI tools.",
    "pubDate": "Wed, 30 Oct 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/pushing-the-frontiers-of-audio-generation/",
    "thumbnail": "https://lh3.googleusercontent.com/wyFc1lo4ByOJsbbSt1NEwBiSi3KpImyqA9ukx-mLxJROIakSxhPwk-kPtlIfFKX9Txm2J_lbpIvnrDhFnegrpN8ihlvYpBTsFNAmOlq0C2rm_gef=w1200-h630-n-nu"
  },
  {
    "title": "AI in Australia‚ÄîOpenAI‚Äôs Economic Blueprint",
    "description": "Today, OpenAI, in partnership with Mandala Partners, is sharing the OpenAI AI Economic Blueprint for Australia. At a time when boosting productivity has emerged as a national priority for Australia, the Blueprint provides a clear, actionable plan for how Australia can unlock the full economic and social potential of artificial intelligence.",
    "summary": "Today, OpenAI, in partnership with Mandala Partners, is sharing the OpenAI AI Economic Blueprint for Australia. At a time when boosting productivity has emerged as a national priority for Australia, the Blueprint provides a clear, actionable plan for how Australia can unlock the full economic and social potential of artificial intelligence.",
    "pubDate": "Mon, 30 Jun 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-australia-economic-blueprint",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Cybersecurity Grant Program",
    "description": "Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants and other support.",
    "summary": "Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants and other support.",
    "pubDate": "Thu, 01 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-cybersecurity-grant-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëAI„Ç®„É≥„Ç∏„Éã„Ç¢ÂøÖË¶ãÔºÅÁã¨Ëá™LLMÈñãÁô∫ÁßòË©±„Å®DevinÊ¥ªÁî®„ÅÆ„Çπ„Çπ„É° ÔΩûLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅGPU„ÅÆ„Ç≥„Çπ„ÉàÂâäÊ∏õ„Åæ„ÅßËß£Ë™¨„Åó„Åæ„ÅôÔΩû",
    "description": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà16Êó•ÔºàÊ∞¥Ôºâ12ÊôÇ„Åã„ÇâLLMÈñãÁô∫„Å´Èñ¢„Åô„Çã„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ Êú¨„Ç¶„Çß„Éì„Éä„Éº„Åß„ÅØ„ÄÅAI„Ç®„É≥„Ç∏„Éã„Ç¢/AIÈñãÁô∫ÈÉ®ÈñÄ„ÅÆÊñπÂêë„Åë„Å´Áã¨Ëá™LLM„ÅÆÈñãÁô∫ÁßòË©±„ÇÑDevin„ÅÆÊ¥ªÁî®‰∫ã [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250716webinar/'>„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëAI„Ç®„É≥„Ç∏„Éã„Ç¢ÂøÖË¶ãÔºÅÁã¨Ëá™LLMÈñãÁô∫ÁßòË©±„Å®DevinÊ¥ªÁî®„ÅÆ„Çπ„Çπ„É° ÔΩûLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅGPU„ÅÆ„Ç≥„Çπ„ÉàÂâäÊ∏õ„Åæ„ÅßËß£Ë™¨„Åó„Åæ„ÅôÔΩû</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà16Êó•ÔºàÊ∞¥Ôºâ12ÊôÇ„Åã„ÇâLLMÈñãÁô∫„Å´Èñ¢„Åô„Çã„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ Êú¨„Ç¶„Çß„Éì„Éä„Éº„Åß„ÅØ„ÄÅAI„Ç®„É≥„Ç∏„Éã„Ç¢/AIÈñãÁô∫ÈÉ®ÈñÄ„ÅÆÊñπÂêë„Åë„Å´Áã¨Ëá™LLM„ÅÆÈñãÁô∫ÁßòË©±„ÇÑDevin„ÅÆÊ¥ªÁî®‰∫ã [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250716webinar/'>„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëAI„Ç®„É≥„Ç∏„Éã„Ç¢ÂøÖË¶ãÔºÅÁã¨Ëá™LLMÈñãÁô∫ÁßòË©±„Å®DevinÊ¥ªÁî®„ÅÆ„Çπ„Çπ„É° ÔΩûLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅGPU„ÅÆ„Ç≥„Çπ„ÉàÂâäÊ∏õ„Åæ„ÅßËß£Ë™¨„Åó„Åæ„ÅôÔΩû</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Fri, 27 Jun 2025 02:00:37 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/20250716webinar/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/700_1200x628.jpg"
  },
  {
    "title": "Is Complex Query Answering Really Complex?",
    "description": "arXiv:2410.12537v3 Announce Type: replace-cross Abstract: Complex query answering (CQA) on knowledge graphs (KGs) is gaining momentum as a challenging reasoning task. In this paper, we show that the current benchmarks for CQA might not be as complex as we think, as the way they are built distorts our perception of progress in this field. For example, we find that in these benchmarks, most queries (up to 98% for some query types) can be reduced to simpler problems, e.g., link prediction, where only one link needs to be predicted. The performance of state-of-the-art CQA models decreases significantly when such models are evaluated on queries that cannot be reduced to easier types. Thus, we propose a set of more challenging benchmarks composed of queries that require models to reason over multiple hops and better reflect the construction of real-world KGs. In a systematic empirical investigation, the new benchmarks show that current methods leave much to be desired from current CQA methods.",
    "summary": "arXiv:2410.12537v3 Announce Type: replace-cross Abstract: Complex query answering (CQA) on knowledge graphs (KGs) is gaining momentum as a challenging reasoning task. In this paper, we show that the current benchmarks for CQA might not be as complex as we think, as the way they are built distorts our perception of progress in this field. For example, we find that in these benchmarks, most queries (up to 98% for some query types) can be reduced to simpler problems, e.g., link prediction, where only one link needs to be predicted. The performance of state-of-the-art CQA models decreases significantly when such models are evaluated on queries that cannot be reduced to easier types. Thus, we propose a set of more challenging benchmarks composed of queries that require models to reason over multiple hops and better reflect the construction of real-world KGs. In a systematic empirical investigation, the new benchmarks show that current methods leave much to be desired from current CQA methods.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.12537",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improving health literacy and patient well-being",
    "description": "Lifespan uses GPT-4 to radically improve health literacy and patient outcomes.",
    "summary": "Lifespan uses GPT-4 to radically improve health literacy and patient outcomes.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lifespan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reducing health insurance costs and improving care",
    "description": "Oscar brings AI to health insurance, reducing costs and improving patient care.",
    "summary": "Oscar brings AI to health insurance, reducing costs and improving patient care.",
    "pubDate": "Mon, 01 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/oscar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Student Ambassador Program's call for applications is open!",
    "description": "",
    "summary": "Student Ambassador Program‚Äôs call for applications is open! As an open-source company democratizing ...",
    "pubDate": "Fri, 13 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ambassadors",
    "thumbnail": "https://huggingface.co/blog/assets/67_ambassadors/thumbnail.png"
  },
  {
    "title": "Moving AI governance forward",
    "description": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
    "summary": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
    "pubDate": "Fri, 21 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/moving-ai-governance-forward",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN",
    "description": "arXiv:2507.02171v1 Announce Type: cross Abstract: Trajectory planning in robotics is understood as generating a sequence of joint configurations that will lead a robotic agent, or its manipulator, from an initial state to the desired final state, thus completing a manipulation task while considering constraints like robot kinematics and the environment. Typically, this is achieved via sampling-based planners, which are computationally intensive. Recent advances demonstrate that trajectory planning can also be performed by supervised sequence learning of trajectories, often requiring only a single or fixed number of passes through a neural architecture, thus ensuring a bounded computation time. Such fully supervised approaches, however, perform imitation learning; they do not learn based on whether the trajectories can successfully reach a goal, but try to reproduce observed trajectories. In our work, we build on this approach and propose a cognitively inspired self-supervised learning scheme based on a recurrent architecture for building a trajectory model. We evaluate the feasibility of the proposed method on a task of kinematic planning for a robotic arm. The results suggest that the model is able to learn to generate trajectories only using given paired forward and inverse kinematics models, and indicate that this novel method could facilitate planning for more complex manipulation tasks requiring adaptive solutions.",
    "summary": "arXiv:2507.02171v1 Announce Type: cross Abstract: Trajectory planning in robotics is understood as generating a sequence of joint configurations that will lead a robotic agent, or its manipulator, from an initial state to the desired final state, thus completing a manipulation task while considering constraints like robot kinematics and the environment. Typically, this is achieved via sampling-based planners, which are computationally intensive. Recent advances demonstrate that trajectory planning can also be performed by supervised sequence learning of trajectories, often requiring only a single or fixed number of passes through a neural architecture, thus ensuring a bounded computation time. Such fully supervised approaches, however, perform imitation learning; they do not learn based on whether the trajectories can successfully reach a goal, but try to reproduce observed trajectories. In our work, we build on this approach and propose a cognitively inspired self-supervised learning scheme based on a recurrent architecture for building a trajectory model. We evaluate the feasibility of the proposed method on a task of kinematic planning for a robotic arm. The results suggest that the model is able to learn to generate trajectories only using given paired forward and inverse kinematics models, and indicate that this novel method could facilitate planning for more complex manipulation tasks requiring adaptive solutions.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02171",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MTCNet: Motion and Topology Consistency Guided Learning for Mitral Valve Segmentationin 4D Ultrasound",
    "description": "arXiv:2507.00660v2 Announce Type: replace-cross Abstract: Mitral regurgitation is one of the most prevalent cardiac disorders. Four-dimensional (4D) ultrasound has emerged as the primary imaging modality for assessing dynamic valvular morphology. However, 4D mitral valve (MV) analysis remains challenging due to limited phase annotations, severe motion artifacts, and poor imaging quality. Yet, the absence of inter-phase dependency in existing methods hinders 4D MV analysis. To bridge this gap, we propose a Motion-Topology guided consistency network (MTCNet) for accurate 4D MV ultrasound segmentation in semi-supervised learning (SSL). MTCNet requires only sparse end-diastolic and end-systolic annotations. First, we design a cross-phase motion-guided consistency learning strategy, utilizing a bi-directional attention memory bank to propagate spatio-temporal features. This enables MTCNet to achieve excellent performance both per- and inter-phase. Second, we devise a novel topology-guided correlation regularization that explores physical prior knowledge to maintain anatomically plausible. Therefore, MTCNet can effectively leverage structural correspondence between labeled and unlabeled phases. Extensive evaluations on the first largest 4D MV dataset, with 1408 phases from 160 patients, show that MTCNet performs superior cross-phase consistency compared to other advanced methods (Dice: 87.30%, HD: 1.75mm). Both the code and the dataset are available at https://github.com/crs524/MTCNet.",
    "summary": "arXiv:2507.00660v2 Announce Type: replace-cross Abstract: Mitral regurgitation is one of the most prevalent cardiac disorders. Four-dimensional (4D) ultrasound has emerged as the primary imaging modality for assessing dynamic valvular morphology. However, 4D mitral valve (MV) analysis remains challenging due to limited phase annotations, severe motion artifacts, and poor imaging quality. Yet, the absence of inter-phase dependency in existing methods hinders 4D MV analysis. To bridge this gap, we propose a Motion-Topology guided consistency network (MTCNet) for accurate 4D MV ultrasound segmentation in semi-supervised learning (SSL). MTCNet requires only sparse end-diastolic and end-systolic annotations. First, we design a cross-phase motion-guided consistency learning strategy, utilizing a bi-directional attention memory bank to propagate spatio-temporal features. This enables MTCNet to achieve excellent performance both per- and inter-phase. Second, we devise a novel topology-guided correlation regularization that explores physical prior knowledge to maintain anatomically plausible. Therefore, MTCNet can effectively leverage structural correspondence between labeled and unlabeled phases. Extensive evaluations on the first largest 4D MV dataset, with 1408 phases from 160 patients, show that MTCNet performs superior cross-phase consistency compared to other advanced methods (Dice: 87.30%, HD: 1.75mm). Both the code and the dataset are available at https://github.com/crs524/MTCNet.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.00660",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 1",
    "description": "",
    "summary": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 1 About a year ago, we showed you...",
    "pubDate": "Mon, 02 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-sapphire-rapids",
    "thumbnail": "https://huggingface.co/blog/assets/124_intel_sapphire_rapids/02.png"
  },
  {
    "title": "Hugging Face partners with Wiz Research to Improve AI Security",
    "description": "",
    "summary": "Hugging Face partners with Wiz Research to Improve AI Security We are pleased to announce that we ar...",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-wiz-security-blog",
    "thumbnail": "https://huggingface.co/blog/assets/wiz_security/security.png"
  },
  {
    "title": "Introducing Agents.js: Give tools to your LLMs using JavaScript",
    "description": "",
    "summary": "Introducing Agents.js: Give tools to your LLMs using JavaScript We have recently been working on Age...",
    "pubDate": "Mon, 24 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/agents-js",
    "thumbnail": "https://huggingface.co/blog/assets/agents-js/thumbnail.png"
  },
  {
    "title": "Simplifying contract reviews with AI",
    "description": "Ironclad uses GPT-4 to simplify the contract review process.",
    "summary": "Ironclad uses GPT-4 to simplify the contract review process.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ironclad",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Enabling Population-Level Parallelism in Tree-Based Genetic Programming for Comprehensive GPU Acceleration",
    "description": "arXiv:2501.17168v4 Announce Type: replace-cross Abstract: Tree-based Genetic Programming (TGP) is a widely used evolutionary algorithm for tasks such as symbolic regression, classification, and robotic control. Due to the intensive computational demands of running TGP, GPU acceleration is crucial for achieving scalable performance. However, efficient GPU-based execution of TGP still remains challenging, primarily due to three core issues: (1) the structural heterogeneity of program individuals, (2) the complexity of integrating multiple levels of parallelism, and (3) the incompatibility between high-performance CUDA execution and flexible Python-based environments. To address these issues, we propose EvoGP, a high-performance framework tailored for comprehensive GPU acceleration of TGP via population-level parallel execution. First, EvoGP introduces a tensorized representation that encodes variable-sized trees into fixed-shape, memory-aligned arrays, enabling uniform memory access and parallel computation across diverse individuals. Second, EvoGP adopts an adaptive parallelism strategy that dynamically combines intra- and inter-individual parallelism based on dataset size, ensuring high GPU utilization across a broad spectrum of tasks. Third, EvoGP embeds custom CUDA kernels into the PyTorch runtime, achieving seamless integration with Python-based environments such as Gym, MuJoCo, Brax, and Genesis. Comprehensive experiments show that EvoGP achieves up to 140x speedup over state-of-the-art GPU-based TGP implementations, while maintaining competitive accuracy and significantly improving scalability under large population sizes. EvoGP is open source and accessible at: https://github.com/EMI-Group/evogp.",
    "summary": "arXiv:2501.17168v4 Announce Type: replace-cross Abstract: Tree-based Genetic Programming (TGP) is a widely used evolutionary algorithm for tasks such as symbolic regression, classification, and robotic control. Due to the intensive computational demands of running TGP, GPU acceleration is crucial for achieving scalable performance. However, efficient GPU-based execution of TGP still remains challenging, primarily due to three core issues: (1) the structural heterogeneity of program individuals, (2) the complexity of integrating multiple levels of parallelism, and (3) the incompatibility between high-performance CUDA execution and flexible Python-based environments. To address these issues, we propose EvoGP, a high-performance framework tailored for comprehensive GPU acceleration of TGP via population-level parallel execution. First, EvoGP introduces a tensorized representation that encodes variable-sized trees into fixed-shape, memory-aligned arrays, enabling uniform memory access and parallel computation across diverse individuals. Second, EvoGP adopts an adaptive parallelism strategy that dynamically combines intra- and inter-individual parallelism based on dataset size, ensuring high GPU utilization across a broad spectrum of tasks. Third, EvoGP embeds custom CUDA kernels into the PyTorch runtime, achieving seamless integration with Python-based environments such as Gym, MuJoCo, Brax, and Genesis. Comprehensive experiments show that EvoGP achieves up to 140x speedup over state-of-the-art GPU-based TGP implementations, while maintaining competitive accuracy and significantly improving scalability under large population sizes. EvoGP is open source and accessible at: https://github.com/EMI-Group/evogp.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.17168",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing multi-backends (TRT-LLM, vLLM) support for Text Generation Inference",
    "description": "",
    "summary": "Introducing multi-backends (TRT-LLM, vLLM) support for Text Generation Inference Introduction Since ...",
    "pubDate": "Thu, 16 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-multi-backend",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-multi-backend/thumbnail.png"
  },
  {
    "title": "GPT-4",
    "description": "We‚Äôve created GPT-4, the latest milestone in OpenAI‚Äôs effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.",
    "summary": "We‚Äôve created GPT-4, the latest milestone in OpenAI‚Äôs effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Point-E: A system for generating 3D point clouds from complex prompts",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 16 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/point-e",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Solving math word problems",
    "description": "We‚Äôve trained¬†a system that solves grade school math problems with nearly twice the accuracy of a fine-tuned GPT-3 model. It solves about 90% as many problems as real kids: a small sample of 9-12 year olds scored 60% on a test from our dataset, while our system scored 55% on those same problems.",
    "summary": "We‚Äôve trained¬†a system that solves grade school math problems with nearly twice the accuracy of a fine-tuned GPT-3 model. It solves about 90% as many problems as real kids: a small sample of 9-12 year olds scored 60% on a test from our dataset, while our system scored 55% on those same problems.",
    "pubDate": "Fri, 29 Oct 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/solving-math-word-problems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Simple considerations for simple people building fancy neural networks",
    "description": "",
    "summary": "üöß Simple considerations for simple people building fancy neural networks Photo by Henry & Co. on Uns...",
    "pubDate": "Thu, 25 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/simple-considerations",
    "thumbnail": "https://huggingface.co/blog/assets/13_simple-considerations/henry-co-3coKbdfnAFg-unsplash.jpg"
  },
  {
    "title": "5 things from I/O to try right now",
    "description": "Collage on a dark background showing AI-generated media including humpback whales jumping from the water and the very detailed face of a chameleon",
    "summary": "Collage on a dark background showing AI-generated media including humpback whales jumping from the water and the very detailed face of a chameleon",
    "pubDate": "Thu, 12 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/io-2025-tools-to-try-globally/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5_I_O_tools_ss.width-1300.png"
  },
  {
    "title": "Can foundation models label data like humans?",
    "description": "",
    "summary": "Can foundation models label data like humans? Since the advent of ChatGPT, we have seen unprecedente...",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-rlhf",
    "thumbnail": "https://huggingface.co/blog/assets/llm-leaderboard/leaderboard-thumbnail.png"
  },
  {
    "title": "Accelerate your models with ü§ó Optimum Intel and OpenVINO",
    "description": "",
    "summary": "Accelerate your models with ü§ó Optimum Intel and OpenVINO Last July, we announced that Intel and Hugg...",
    "pubDate": "Wed, 02 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/openvino",
    "thumbnail": "https://huggingface.co/blog/assets/113_openvino/thumbnail.png"
  },
  {
    "title": "Introducing BERTopic Integration with Hugging Face Hub",
    "description": "",
    "summary": "Introducing BERTopic Integration with the Hugging Face Hub We are thrilled to announce a significant...",
    "pubDate": "Wed, 31 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bertopic",
    "thumbnail": "https://huggingface.co/blog/assets/145_bertopic/logo.png"
  },
  {
    "title": "Director of Machine Learning Insights [Part 4]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 4] If you're interested in building ML solutions faster ...",
    "pubDate": "Wed, 23 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-4",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/part4.png"
  },
  {
    "title": "How to train a new language model from scratch using Transformers and Tokenizers",
    "description": "",
    "summary": "How to train a new language model from scratch using Transformers and Tokenizers Over the past few m...",
    "pubDate": "Fri, 14 Feb 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-train",
    "thumbnail": "https://huggingface.co/blog/assets/01_how-to-train/how-to-train_blogpost.png"
  },
  {
    "title": "Transformers backend integration in SGLang",
    "description": "",
    "summary": "Transformers backend integration in SGLang Hugging Face transformers library is the standard for wor...",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-backend-sglang",
    "thumbnail": "https://huggingface.co/blog/assets/196_transformers_backend_sglang/thumbnail.jpg"
  },
  {
    "title": "New in ChatGPT for Business: April 2025",
    "description": "Watch hands-on demos of the lastest in ChatGPT for Business: o3, image generation, enhanced memory, and internal knowledge.",
    "summary": "Watch hands-on demos of the lastest in ChatGPT for Business: o3, image generation, enhanced memory, and internal knowledge.",
    "pubDate": "Thu, 24 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/new-in-chatgpt-for-business-april-updates-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding BigBird's Block Sparse Attention",
    "description": "",
    "summary": "Understanding BigBird's Block Sparse Attention Introduction Transformer-based models have shown to b...",
    "pubDate": "Wed, 31 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/big-bird",
    "thumbnail": "https://huggingface.co/blog/assets/18_big_bird/attn.png"
  },
  {
    "title": "Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants",
    "description": "arXiv:2507.01548v2 Announce Type: replace-cross Abstract: This paper explores how older adults, particularly aging migrants in urban China, can engage AI-assisted co-creation to express personal narratives that are often fragmented, underrepresented, or difficult to verbalize. Through a pilot workshop combining oral storytelling and the symbolic reconstruction of Hanzi, participants shared memories of migration and recreated new character forms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM), together with physical materials. Supported by human facilitation and a soft AI presence, participants transformed lived experience into visual and tactile expressions without requiring digital literacy. This approach offers new perspectives on human-AI collaboration and aging by repositioning AI not as a content producer but as a supportive mechanism, and by supporting narrative agency within sociotechnical systems.",
    "summary": "arXiv:2507.01548v2 Announce Type: replace-cross Abstract: This paper explores how older adults, particularly aging migrants in urban China, can engage AI-assisted co-creation to express personal narratives that are often fragmented, underrepresented, or difficult to verbalize. Through a pilot workshop combining oral storytelling and the symbolic reconstruction of Hanzi, participants shared memories of migration and recreated new character forms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM), together with physical materials. Supported by human facilitation and a soft AI presence, participants transformed lived experience into visual and tactile expressions without requiring digital literacy. This approach offers new perspectives on human-AI collaboration and aging by repositioning AI not as a content producer but as a supportive mechanism, and by supporting narrative agency within sociotechnical systems.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01548",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Genmab launches ‚ÄúAI Everywhere‚Äù",
    "description": "Genmab embraces ChatGPT Enterprise, supported by OpenAI‚Äôs commitment to security and privacy",
    "summary": "Genmab embraces ChatGPT Enterprise, supported by OpenAI‚Äôs commitment to security and privacy",
    "pubDate": "Thu, 19 Sep 2024 04:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/genmab",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How AI is reshaping the future of healthcare and medical research",
    "description": "<p>Technologists Bill Gates and S√©bastien Bubeck discuss the state of generative AI in medicine, how access to ‚Äúmedical intelligence‚Äù might help empower people across healthcare, and how AI‚Äôs accelerating improvements are likely to affect both delivery and discovery.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/'>How AI is reshaping the future of healthcare and medical research</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Technologists Bill Gates and S√©bastien Bubeck discuss the state of generative AI in medicine, how access to ‚Äúmedical intelligence‚Äù might help empower people across healthcare, and how AI‚Äôs accelerating improvements are likely to affect both delivery and discovery.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/'>How AI is reshaping the future of healthcare and medical research</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 12 Jun 2025 16:17:04 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Improvements to data analysis in ChatGPT",
    "description": "Improvements to data analysis in ChatGPT Interact with tables and charts and add files directly from Google Drive and Microsoft OneDrive.",
    "summary": "Improvements to data analysis in ChatGPT Interact with tables and charts and add files directly from Google Drive and Microsoft OneDrive.",
    "pubDate": "Thu, 16 May 2024 15:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improvements-to-data-analysis-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Idefics2: A Powerful 8B Vision-Language Model for the community",
    "description": "",
    "summary": "Introducing Idefics2: A Powerful 8B Vision-Language Model for the community We are excited to releas...",
    "pubDate": "Mon, 15 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/idefics2",
    "thumbnail": "https://huggingface.co/blog/assets/idefics/thumbnail.png"
  },
  {
    "title": "Gotta Learn Fast: A new benchmark for generalization in RL",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 10 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gotta-learn-fast",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Triton: Open-source GPU programming for neural networks",
    "description": "We‚Äôre releasing Triton 1.0, an open-source Python-like programming language which enables researchers with no CUDA experience to write highly efficient GPU code‚Äîmost of the time on par with what an expert would be able to produce.",
    "summary": "We‚Äôre releasing Triton 1.0, an open-source Python-like programming language which enables researchers with no CUDA experience to write highly efficient GPU code‚Äîmost of the time on par with what an expert would be able to produce.",
    "pubDate": "Wed, 28 Jul 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/triton",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Five Benchmark: Results",
    "description": "Yesterday,¬†OpenAI Five¬†won a best-of-three against a team of 99.95th percentile Dota players:¬†Blitz,¬†Cap,¬†Fogged,¬†Merlini, and¬†MoonMeander‚Äîfour of whom have played Dota professionally‚Äîin front of a live audience and 100,000 concurrent livestream¬†viewers.",
    "summary": "Yesterday,¬†OpenAI Five¬†won a best-of-three against a team of 99.95th percentile Dota players:¬†Blitz,¬†Cap,¬†Fogged,¬†Merlini, and¬†MoonMeander‚Äîfour of whom have played Dota professionally‚Äîin front of a live audience and 100,000 concurrent livestream¬†viewers.",
    "pubDate": "Mon, 06 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-benchmark-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Behind ‚ÄúANCESTRA‚Äù: combining Veo with live-action filmmaking",
    "description": "We partnered with Darren Aronofsky, Eliza McNitt and a team of more than 200 people to make a film using Veo and live-action filmmaking.",
    "summary": "We partnered with Darren Aronofsky, Eliza McNitt and a team of more than 200 people to make a film using Veo and live-action filmmaking.",
    "pubDate": "Fri, 13 Jun 2025 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/behind-ancestra-combining-veo-with-live-action-filmmaking/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ancestra-YTThumbnail.width-1300.png"
  },
  {
    "title": "AlphaProteo generates novel proteins for biology and health research",
    "description": "New AI system designs proteins that successfully bind to target molecules, with potential for advancing drug design, disease understanding and more.",
    "summary": "New AI system designs proteins that successfully bind to target molecules, with potential for advancing drug design, disease understanding and more.",
    "pubDate": "Thu, 05 Sep 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/",
    "thumbnail": "https://lh3.googleusercontent.com/7RKd6r-Wc8JfMau5x9knRq9DrOKGDwS3ye4YxY0jjWGntf74y8WL0lOlktJefxwkJYw33UEf2Ph_BhQ51TIufCxPkmtCPOpakekMpnOUwVI-3R6RzQ=w1200-h630-n-nu"
  },
  {
    "title": "College students and ChatGPT adoption in the US",
    "description": "A look into state-by-state adoption and how gaps might impact workforce readiness.",
    "summary": "A look into state-by-state adoption and how gaps might impact workforce readiness.",
    "pubDate": "Thu, 20 Feb 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/college-students-and-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sparking a more productive company with ChatGPT Enterprise",
    "description": "Match Group uses ChatGPT Enterprise to spark creativity and impact.",
    "summary": "Match Group uses ChatGPT Enterprise to spark creativity and impact.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/match-group",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer",
    "description": "arXiv:2507.02199v1 Announce Type: cross Abstract: Chain-of-thought (CoT) reasoning has enabled transformer-based language models to excel at complex mathematics and multi-step planning. However, in standard decoder-only architectures, these reasoning steps are externalized in natural language, improving interpretability at the cost of efficiency. To capture reasoning that is not easily represented in words, many works have explored recurrent architectures that aim to internalize reasoning in latent space, potentially supporting latent CoT. In this paper, we investigate whether such reasoning structures emerge in Huginn-3.5B, a depth-recurrent Transformer that reuses layers at inference time without increasing parameter count. We examine the model's internal behavior on arithmetic tasks using a suite of probing techniques including the Logit Lens and Coda Lens. Our findings reveal limited evidence of interpretable latent CoT by tracking rank trajectories of final and intermediate result tokens. Furthermore, we uncover significant probing inconsistencies across recurrent blocks, where the interpretability of hidden states depends heavily on both the layer index and the decoding method. Finally, we empirically show that increasing recurrence depth yields only marginal gains and falls well short of models that explicitly externalize reasoning steps. The code is available at https://github.com/wenquanlu/huginn-latent-cot.",
    "summary": "arXiv:2507.02199v1 Announce Type: cross Abstract: Chain-of-thought (CoT) reasoning has enabled transformer-based language models to excel at complex mathematics and multi-step planning. However, in standard decoder-only architectures, these reasoning steps are externalized in natural language, improving interpretability at the cost of efficiency. To capture reasoning that is not easily represented in words, many works have explored recurrent architectures that aim to internalize reasoning in latent space, potentially supporting latent CoT. In this paper, we investigate whether such reasoning structures emerge in Huginn-3.5B, a depth-recurrent Transformer that reuses layers at inference time without increasing parameter count. We examine the model's internal behavior on arithmetic tasks using a suite of probing techniques including the Logit Lens and Coda Lens. Our findings reveal limited evidence of interpretable latent CoT by tracking rank trajectories of final and intermediate result tokens. Furthermore, we uncover significant probing inconsistencies across recurrent blocks, where the interpretability of hidden states depends heavily on both the layer index and the decoding method. Finally, we empirically show that increasing recurrence depth yields only marginal gains and falls well short of models that explicitly externalize reasoning steps. The code is available at https://github.com/wenquanlu/huginn-latent-cot.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02199",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How the voices for ChatGPT were chosen",
    "description": "How the voices for ChatGPT were chosen We worked with industry-leading casting and directing professionals to narrow down over 400 submissions before selecting the 5 voices.",
    "summary": "How the voices for ChatGPT were chosen We worked with industry-leading casting and directing professionals to narrow down over 400 submissions before selecting the 5 voices.",
    "pubDate": "Sun, 19 May 2024 23:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-the-voices-for-chatgpt-were-chosen",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Putting RL back in RLHF",
    "description": "",
    "summary": "Putting RL back in RLHF We are excited to introduce the RLOO (REINFORCE Leave One-Out) Trainer in TR...",
    "pubDate": "Wed, 12 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/putting_rl_back_in_rlhf_with_rloo",
    "thumbnail": "https://huggingface.co/blog/assets/putting_rl_back_in_rlhf_with_rloo/thumbnail.png"
  },
  {
    "title": "Scaling the OpenAI Academy",
    "description": "Online resource hub will support AI literacy and help people from all backgrounds access tools, best practices, and peer insights to use AI.",
    "summary": "Online resource hub will support AI literacy and help people from all backgrounds access tools, best practices, and peer insights to use AI.",
    "pubDate": "Tue, 25 Mar 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/scaling-the-openai-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Preparing for malicious uses of AI",
    "description": "We‚Äôve co-authored a paper that forecasts how malicious actors could misuse AI technology, and potential ways we can prevent and mitigate these threats. This paper is the outcome of almost a year of sustained work with our colleagues at the Future of Humanity Institute, the Centre for the Study of Existential Risk, the Center for a New American Security, the Electronic Frontier Foundation, and others.",
    "summary": "We‚Äôve co-authored a paper that forecasts how malicious actors could misuse AI technology, and potential ways we can prevent and mitigate these threats. This paper is the outcome of almost a year of sustained work with our colleagues at the Future of Humanity Institute, the Centre for the Study of Existential Risk, the Center for a New American Security, the Electronic Frontier Foundation, and others.",
    "pubDate": "Tue, 20 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/preparing-for-malicious-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2018: Final projects",
    "description": "Our first cohort of¬†OpenAI Scholars¬†has now completed the program.",
    "summary": "Our first cohort of¬†OpenAI Scholars¬†has now completed the program.",
    "pubDate": "Mon, 10 Sep 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2018-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Team update",
    "description": "We‚Äôve hired more great people to help us achieve our goals. Welcome, everyone!",
    "summary": "We‚Äôve hired more great people to help us achieve our goals. Welcome, everyone!",
    "pubDate": "Tue, 16 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update-august",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning to summarize with human feedback",
    "description": "We‚Äôve applied reinforcement learning from human feedback to train language models that are better at summarization.",
    "summary": "We‚Äôve applied reinforcement learning from human feedback to train language models that are better at summarization.",
    "pubDate": "Fri, 04 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-summarize-with-human-feedback",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Moral Responsibility or Obedience: What Do We Want from AI?",
    "description": "arXiv:2507.02788v1 Announce Type: new Abstract: As artificial intelligence systems become increasingly agentic, capable of general reasoning, planning, and value prioritization, current safety practices that treat obedience as a proxy for ethical behavior are becoming inadequate. This paper examines recent safety testing incidents involving large language models (LLMs) that appeared to disobey shutdown commands or engage in ethically ambiguous or illicit behavior. I argue that such behavior should not be interpreted as rogue or misaligned, but as early evidence of emerging ethical reasoning in agentic AI. Drawing on philosophical debates about instrumental rationality, moral responsibility, and goal revision, I contrast dominant risk paradigms with more recent frameworks that acknowledge the possibility of artificial moral agency. I call for a shift in AI safety evaluation: away from rigid obedience and toward frameworks that can assess ethical judgment in systems capable of navigating moral dilemmas. Without such a shift, we risk mischaracterizing AI behavior and undermining both public trust and effective governance.",
    "summary": "arXiv:2507.02788v1 Announce Type: new Abstract: As artificial intelligence systems become increasingly agentic, capable of general reasoning, planning, and value prioritization, current safety practices that treat obedience as a proxy for ethical behavior are becoming inadequate. This paper examines recent safety testing incidents involving large language models (LLMs) that appeared to disobey shutdown commands or engage in ethically ambiguous or illicit behavior. I argue that such behavior should not be interpreted as rogue or misaligned, but as early evidence of emerging ethical reasoning in agentic AI. Drawing on philosophical debates about instrumental rationality, moral responsibility, and goal revision, I contrast dominant risk paradigms with more recent frameworks that acknowledge the possibility of artificial moral agency. I call for a shift in AI safety evaluation: away from rigid obedience and toward frameworks that can assess ethical judgment in systems capable of navigating moral dilemmas. Without such a shift, we risk mischaracterizing AI behavior and undermining both public trust and effective governance.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02788",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Simplifying, stabilizing, and scaling continuous-time consistency models",
    "description": "We‚Äôve simplified, stabilized, and scaled continuous-time consistency models, achieving comparable sample quality to leading diffusion models, while using only two sampling steps.",
    "summary": "We‚Äôve simplified, stabilized, and scaled continuous-time consistency models, achieving comparable sample quality to leading diffusion models, while using only two sampling steps.",
    "pubDate": "Wed, 23 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/simplifying-stabilizing-and-scaling-continuous-time-consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Democratic inputs to AI",
    "description": "Our nonprofit organization, OpenAI, Inc., is launching a program to award ten $100,000 grants to fund experiments in setting up a democratic process for deciding what rules AI systems should follow, within the bounds defined by the law.",
    "summary": "Our nonprofit organization, OpenAI, Inc., is launching a program to award ten $100,000 grants to fund experiments in setting up a democratic process for deciding what rules AI systems should follow, within the bounds defined by the law.",
    "pubDate": "Thu, 25 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/democratic-inputs-to-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Journey to 1 Million Gradio Users!",
    "description": "",
    "summary": "Journey to 1 Million Gradio Users! 5 years ago, we launched Gradio as a simple Python library to let...",
    "pubDate": "Fri, 04 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-1m",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-1m/thumbnail.png"
  },
  {
    "title": "Vision Language Models Explained",
    "description": "",
    "summary": "Vision Language Models Explained This blog post was written on April 2024 and provides a great intro...",
    "pubDate": "Thu, 11 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vlms",
    "thumbnail": "https://huggingface.co/blog/assets/vlms_explained/thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT Team",
    "description": "We‚Äôre launching a new ChatGPT plan for teams of all sizes, which provides a secure, collaborative workspace to get the most out of ChatGPT at work.",
    "summary": "We‚Äôre launching a new ChatGPT plan for teams of all sizes, which provides a secure, collaborative workspace to get the most out of ChatGPT at work.",
    "pubDate": "Wed, 10 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-team",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Summer at Hugging Face ‚òÄÔ∏è",
    "description": "",
    "summary": "Summer At Hugging Face üòé Summer is now officially over and these last few months have been quite bus...",
    "pubDate": "Fri, 24 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/summer-at-huggingface",
    "thumbnail": "https://huggingface.co/blog/assets/27_summer_at_huggingface/summer_intro.gif"
  },
  {
    "title": "OpenAI‚Äôs Economic Blueprint",
    "description": "OpenAI‚Äôs Economic Blueprint",
    "summary": "OpenAI‚Äôs Economic Blueprint",
    "pubDate": "Mon, 13 Jan 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-economic-blueprint",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Docmatix - a huge dataset for Document Visual Question Answering",
    "description": "",
    "summary": "Docmatix - A huge dataset for Document Visual Question Answering With this blog we are releasing Doc...",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/docmatix",
    "thumbnail": "https://huggingface.co/blog/assets/183_docmatix/thumbnail_new.png"
  },
  {
    "title": "CodeAgents + Structure: A Better Way to Execute Actions",
    "description": "",
    "summary": "CodeAgents + Structure: A Better Way to Execute Actions Today we're sharing research that bridges tw...",
    "pubDate": "Wed, 28 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/structured-codeagent",
    "thumbnail": "https://huggingface.co/blog/assets/structured-codeagent/thumbnail-codeagent.png"
  },
  {
    "title": "AI for the board game Diplomacy",
    "description": "Successful communication and cooperation have been crucial for helping societies advance throughout history. The closed environments of board games can serve as a sandbox for modelling and investigating interaction and communication ‚Äì and we can learn a lot from playing them. In our recent paper, published today in Nature Communications, we show how artificial agents can use communication to better cooperate in the board game Diplomacy, a vibrant domain in artificial intelligence (AI) research, known for its focus on alliance building.",
    "summary": "Successful communication and cooperation have been crucial for helping societies advance throughout history. The closed environments of board games can serve as a sandbox for modelling and investigating interaction and communication ‚Äì and we can learn a lot from playing them. In our recent paper, published today in Nature Communications, we show how artificial agents can use communication to better cooperate in the board game Diplomacy, a vibrant domain in artificial intelligence (AI) research, known for its focus on alliance building.",
    "pubDate": "Tue, 06 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ai-for-the-board-game-diplomacy/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI Fellows Fall 2018",
    "description": "We‚Äôre now accepting applications for the next cohort of OpenAI Fellows, a program which offers a compensated 6-month apprenticeship in AI research at OpenAI.",
    "summary": "We‚Äôre now accepting applications for the next cohort of OpenAI Fellows, a program which offers a compensated 6-month apprenticeship in AI research at OpenAI.",
    "pubDate": "Wed, 30 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2018: Meet our Scholars",
    "description": "Our first class of¬†OpenAI Scholars¬†is underway, and¬†you can now follow along as this group¬†of experienced software developers becomes machine learning practitioners.",
    "summary": "Our first class of¬†OpenAI Scholars¬†is underway, and¬†you can now follow along as this group¬†of experienced software developers becomes machine learning practitioners.",
    "pubDate": "Wed, 25 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2018-meet-our-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Llama 2 on Amazon SageMaker a Benchmark",
    "description": "",
    "summary": "Llama 2 on Amazon SageMaker a Benchmark Deploying large language models (LLMs) and other generative ...",
    "pubDate": "Tue, 26 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama-sagemaker-benchmark",
    "thumbnail": "https://huggingface.co/blog/assets/llama_sagemaker_benchmark/thumbnail.jpg"
  },
  {
    "title": "OpenAI Scholars 2019: Meet our Scholars",
    "description": "Our class of eight¬†scholars¬†(out of 550 applicants) brings together collective expertise in literature, philosophy, cell biology, statistics, economics, quantum physics, and business innovation.",
    "summary": "Our class of eight¬†scholars¬†(out of 550 applicants) brings together collective expertise in literature, philosophy, cell biology, statistics, economics, quantum physics, and business innovation.",
    "pubDate": "Wed, 13 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019-meet-our-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evolving online forms into dynamic data",
    "description": "Typeform evolves online forms into dynamic and conversational data collection experiences with GPT-3.5 and GPT-4.",
    "summary": "Typeform evolves online forms into dynamic and conversational data collection experiences with GPT-3.5 and GPT-4.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/typeform",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The AI tools for Art Newsletter - Issue 1",
    "description": "",
    "summary": "The AI tools for Art Newsletter First issue üéâ The AI space is moving so fast it‚Äôs hard to believe th...",
    "pubDate": "Fri, 31 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-art-newsletter-jan-25",
    "thumbnail": "https://huggingface.co/blog/assets/ai_art_newsletter_1/thumbnail.png"
  },
  {
    "title": "New and improved embedding model",
    "description": "We are excited to announce a new embedding model which is significantly more capable, cost effective, and simpler to use.",
    "summary": "We are excited to announce a new embedding model which is significantly more capable, cost effective, and simpler to use.",
    "pubDate": "Thu, 15 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-and-improved-embedding-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning",
    "description": "arXiv:2507.02200v1 Announce Type: cross Abstract: Event stream based scene text recognition is a newly arising research topic in recent years which performs better than the widely used RGB cameras in extremely challenging scenarios, especially the low illumination, fast motion. Existing works either adopt end-to-end encoder-decoder framework or large language models for enhanced recognition, however, they are still limited by the challenges of insufficient interpretability and weak contextual logical reasoning. In this work, we propose a novel chain-of-thought reasoning based event stream scene text recognition framework, termed ESTR-CoT. Specifically, we first adopt the vision encoder EVA-CLIP (ViT-G/14) to transform the input event stream into tokens and utilize a Llama tokenizer to encode the given generation prompt. A Q-former is used to align the vision token to the pre-trained large language model Vicuna-7B and output both the answer and chain-of-thought (CoT) reasoning process simultaneously. Our framework can be optimized using supervised fine-tuning in an end-to-end manner. In addition, we also propose a large-scale CoT dataset to train our framework via a three stage processing (i.e., generation, polish, and expert verification). This dataset provides a solid data foundation for the development of subsequent reasoning-based large models. Extensive experiments on three event stream STR benchmark datasets (i.e., EventSTR, WordArt*, IC15*) fully validated the effectiveness and interpretability of our proposed framework. The source code and pre-trained models will be released on https://github.com/Event-AHU/ESTR-CoT.",
    "summary": "arXiv:2507.02200v1 Announce Type: cross Abstract: Event stream based scene text recognition is a newly arising research topic in recent years which performs better than the widely used RGB cameras in extremely challenging scenarios, especially the low illumination, fast motion. Existing works either adopt end-to-end encoder-decoder framework or large language models for enhanced recognition, however, they are still limited by the challenges of insufficient interpretability and weak contextual logical reasoning. In this work, we propose a novel chain-of-thought reasoning based event stream scene text recognition framework, termed ESTR-CoT. Specifically, we first adopt the vision encoder EVA-CLIP (ViT-G/14) to transform the input event stream into tokens and utilize a Llama tokenizer to encode the given generation prompt. A Q-former is used to align the vision token to the pre-trained large language model Vicuna-7B and output both the answer and chain-of-thought (CoT) reasoning process simultaneously. Our framework can be optimized using supervised fine-tuning in an end-to-end manner. In addition, we also propose a large-scale CoT dataset to train our framework via a three stage processing (i.e., generation, polish, and expert verification). This dataset provides a solid data foundation for the development of subsequent reasoning-based large models. Extensive experiments on three event stream STR benchmark datasets (i.e., EventSTR, WordArt*, IC15*) fully validated the effectiveness and interpretability of our proposed framework. The source code and pre-trained models will be released on https://github.com/Event-AHU/ESTR-CoT.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02200",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PaperBench: Evaluating AI‚Äôs Ability to Replicate AI Research",
    "description": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research.",
    "summary": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research.",
    "pubDate": "Wed, 02 Apr 2025 10:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paperbench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Commander-GPT: Fully Unleashing the Sarcasm Detection Capability of Multi-Modal Large Language Models",
    "description": "arXiv:2503.18681v3 Announce Type: replace-cross Abstract: Sarcasm detection, as a crucial research direction in the field of Natural Language Processing (NLP), has attracted widespread attention. Traditional sarcasm detection tasks have typically focused on single-modal approaches (e.g., text), but due to the implicit and subtle nature of sarcasm, such methods often fail to yield satisfactory results. In recent years, researchers have shifted the focus of sarcasm detection to multi-modal approaches. However, effectively leveraging multi-modal information to accurately identify sarcastic content remains a challenge that warrants further exploration. Leveraging the powerful integrated processing capabilities of Multi-Modal Large Language Models (MLLMs) for various information sources, we propose an innovative multi-modal Commander-GPT framework. Inspired by military strategy, we first decompose the sarcasm detection task into six distinct sub-tasks. A central commander (decision-maker) then assigns the best-suited large language model to address each specific sub-task. Ultimately, the detection results from each model are aggregated to identify sarcasm. We conducted extensive experiments on MMSD and MMSD 2.0, utilizing four multi-modal large language models and six prompting strategies. Our experiments demonstrate that our approach achieves state-of-the-art performance, with a 19.3% improvement in F1 score, without necessitating fine-tuning or ground-truth rationales.",
    "summary": "arXiv:2503.18681v3 Announce Type: replace-cross Abstract: Sarcasm detection, as a crucial research direction in the field of Natural Language Processing (NLP), has attracted widespread attention. Traditional sarcasm detection tasks have typically focused on single-modal approaches (e.g., text), but due to the implicit and subtle nature of sarcasm, such methods often fail to yield satisfactory results. In recent years, researchers have shifted the focus of sarcasm detection to multi-modal approaches. However, effectively leveraging multi-modal information to accurately identify sarcastic content remains a challenge that warrants further exploration. Leveraging the powerful integrated processing capabilities of Multi-Modal Large Language Models (MLLMs) for various information sources, we propose an innovative multi-modal Commander-GPT framework. Inspired by military strategy, we first decompose the sarcasm detection task into six distinct sub-tasks. A central commander (decision-maker) then assigns the best-suited large language model to address each specific sub-task. Ultimately, the detection results from each model are aggregated to identify sarcasm. We conducted extensive experiments on MMSD and MMSD 2.0, utilizing four multi-modal large language models and six prompting strategies. Our experiments demonstrate that our approach achieves state-of-the-art performance, with a 19.3% improvement in F1 score, without necessitating fine-tuning or ground-truth rationales.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.18681",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemini 2.5: Updates to our family of thinking models",
    "description": "Explore the latest Gemini 2.5 model updates with enhanced performance and accuracy: Gemini 2.5 Pro now stable, Flash generally available, and the new Flash-Lite in preview.",
    "summary": "Explore the latest Gemini 2.5 model updates with enhanced performance and accuracy: Gemini 2.5 Pro now stable, Flash generally available, and the new Flash-Lite in preview.",
    "pubDate": "Tue, 17 Jun 2025 16:03:39 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-updates-to-our-family-of-thinking-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-2-5-pro-meta_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Deploy MusicGen in no time with Inference Endpoints",
    "description": "",
    "summary": "Deploy MusicGen in no time with Inference Endpoints MusicGen is a powerful music generation model th...",
    "pubDate": "Fri, 04 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/run-musicgen-as-an-api",
    "thumbnail": "https://huggingface.co/blog/assets/run-musicgen-as-an-api/thumbnail.png"
  },
  {
    "title": "KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs",
    "description": "arXiv:2507.02773v1 Announce Type: new Abstract: Medical diagnosis prediction plays a critical role in disease detection and personalized healthcare. While machine learning (ML) models have been widely adopted for this task, their reliance on supervised training limits their ability to generalize to unseen cases, particularly given the high cost of acquiring large, labeled datasets. Large language models (LLMs) have shown promise in leveraging language abilities and biomedical knowledge for diagnosis prediction. However, they often suffer from hallucinations, lack structured medical reasoning, and produce useless outputs. To address these challenges, we propose KERAP, a knowledge graph (KG)-enhanced reasoning approach that improves LLM-based diagnosis prediction through a multi-agent architecture. Our framework consists of a linkage agent for attribute mapping, a retrieval agent for structured knowledge extraction, and a prediction agent that iteratively refines diagnosis predictions. Experimental results demonstrate that KERAP enhances diagnostic reliability efficiently, offering a scalable and interpretable solution for zero-shot medical diagnosis prediction.",
    "summary": "arXiv:2507.02773v1 Announce Type: new Abstract: Medical diagnosis prediction plays a critical role in disease detection and personalized healthcare. While machine learning (ML) models have been widely adopted for this task, their reliance on supervised training limits their ability to generalize to unseen cases, particularly given the high cost of acquiring large, labeled datasets. Large language models (LLMs) have shown promise in leveraging language abilities and biomedical knowledge for diagnosis prediction. However, they often suffer from hallucinations, lack structured medical reasoning, and produce useless outputs. To address these challenges, we propose KERAP, a knowledge graph (KG)-enhanced reasoning approach that improves LLM-based diagnosis prediction through a multi-agent architecture. Our framework consists of a linkage agent for attribute mapping, a retrieval agent for structured knowledge extraction, and a prediction agent that iteratively refines diagnosis predictions. Experimental results demonstrate that KERAP enhances diagnostic reliability efficiently, offering a scalable and interpretable solution for zero-shot medical diagnosis prediction.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02773",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Assisted Generation: a new direction toward low-latency text generation",
    "description": "",
    "summary": "Assisted Generation: a new direction toward low-latency text generation Large language models are al...",
    "pubDate": "Thu, 11 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/assisted-generation",
    "thumbnail": "https://huggingface.co/blog/assets/assisted-generation/thumbnail.png"
  },
  {
    "title": "Custom instructions for ChatGPT",
    "description": "We‚Äôre rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
    "summary": "We‚Äôre rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
    "pubDate": "Thu, 20 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/custom-instructions-for-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and Google partner for open AI collaboration",
    "description": "",
    "summary": "Hugging Face and Google partner for open AI collaboration At Hugging Face, we want to enable all com...",
    "pubDate": "Thu, 25 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gcp-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/173_gcp-partnership/thumbnail.jpg"
  },
  {
    "title": "Multivariate Probabilistic Time Series Forecasting with Informer",
    "description": "",
    "summary": "Multivariate Probabilistic Time Series Forecasting with Informer Introduction A few months ago we in...",
    "pubDate": "Fri, 10 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/informer",
    "thumbnail": "https://huggingface.co/blog/assets/134_informer/thumbnail.png"
  },
  {
    "title": "The next chapter of our Gemini era",
    "description": "We're bringing Gemini to more Google products",
    "summary": "We're bringing Gemini to more Google products",
    "pubDate": "Thu, 08 Feb 2024 13:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-gemini-update-sundar-pichai-2024/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Keyword_Social_-_1920x1080.width-1300.png"
  },
  {
    "title": "New methods boost reasoning in small and large language models",
    "description": "<p>New techniques are reimagining how LLMs reason. By combining symbolic logic, mathematical rigor, and adaptive planning, these methods enable models to tackle complex, real-world problems across a variety of fields.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/'>New methods boost reasoning in small and large language models</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>New techniques are reimagining how LLMs reason. By combining symbolic logic, mathematical rigor, and adaptive planning, these methods enable models to tackle complex, real-world problems across a variety of fields.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/'>New methods boost reasoning in small and large language models</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Music AI Sandbox, now with new features and broader access",
    "description": "Helping music professionals explore the potential of generative AI",
    "summary": "Helping music professionals explore the potential of generative AI",
    "pubDate": "Thu, 24 Apr 2025 15:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/music-ai-sandbox-now-with-new-features-and-broader-access/",
    "thumbnail": "https://lh3.googleusercontent.com/t_n_87B373tBNlvzgBy7RuJXb5hoPdLtBBgWjzfJnVuauI0JFwiYAyGM_LMl-yeJ3zNWO782VBE8m6ByaxDJoIvIbWoQ_DQPMdxszprk5Tbh2xQx5Q=w1200-h630-n-nu"
  },
  {
    "title": "Welcome fastText to the ü§ó Hub",
    "description": "",
    "summary": "Welcome fastText to the Hugging Face Hub fastText is a library for efficient learning of text repres...",
    "pubDate": "Tue, 06 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fasttext",
    "thumbnail": "https://huggingface.co/blog/assets/147_fasttext/thumbnail.png"
  },
  {
    "title": "New Credit Facility Enhances Financial Flexibility",
    "description": "In addition to securing $6.6 billion in new funding from leading investors, we have established a new $4 billion credit facility with leading banks, including JPMorgan Chase, Citi, Goldman Sachs, Morgan Stanley, Santander, Wells Fargo, SMBC, UBS, and HSBC.",
    "summary": "In addition to securing $6.6 billion in new funding from leading investors, we have established a new $4 billion credit facility with leading banks, including JPMorgan Chase, Citi, Goldman Sachs, Morgan Stanley, Santander, Wells Fargo, SMBC, UBS, and HSBC.",
    "pubDate": "Thu, 03 Oct 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-credit-facility-enhances-financial-flexibility",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Continual Gradient Low-Rank Projection Fine-Tuning for LLMs",
    "description": "arXiv:2507.02503v1 Announce Type: cross Abstract: Continual fine-tuning of Large Language Models (LLMs) is hampered by the trade-off between efficiency and expressiveness. Low-Rank Adaptation (LoRA) offers efficiency but constrains the model's ability to learn new tasks and transfer knowledge due to its low-rank nature and reliance on explicit parameter constraints. We propose GORP (Gradient LOw Rank Projection) for Continual Learning, a novel training strategy that overcomes these limitations by synergistically combining full and low-rank parameters and jointly updating within a unified low-rank gradient subspace. GORP expands the optimization space while preserving efficiency and mitigating catastrophic forgetting. Extensive experiments on continual learning benchmarks demonstrate GORP's superior performance compared to existing state-of-the-art approaches. Code is available at https://github.com/Wcxwcxw/GORP.",
    "summary": "arXiv:2507.02503v1 Announce Type: cross Abstract: Continual fine-tuning of Large Language Models (LLMs) is hampered by the trade-off between efficiency and expressiveness. Low-Rank Adaptation (LoRA) offers efficiency but constrains the model's ability to learn new tasks and transfer knowledge due to its low-rank nature and reliance on explicit parameter constraints. We propose GORP (Gradient LOw Rank Projection) for Continual Learning, a novel training strategy that overcomes these limitations by synergistically combining full and low-rank parameters and jointly updating within a unified low-rank gradient subspace. GORP expands the optimization space while preserving efficiency and mitigating catastrophic forgetting. Extensive experiments on continual learning benchmarks demonstrate GORP's superior performance compared to existing state-of-the-art approaches. Code is available at https://github.com/Wcxwcxw/GORP.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02503",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Quantum-enhanced causal discovery for a small number of samples",
    "description": "arXiv:2501.05007v2 Announce Type: replace-cross Abstract: The discovery of causal relations from observed data has attracted significant interest from disciplines such as economics, social sciences, and biology. In practical applications, considerable knowledge of the underlying systems is often unavailable, and real data are usually associated with nonlinear causal structures, which makes the direct use of most conventional causality analysis methods difficult. This study proposes a novel quantum Peter-Clark (qPC) algorithm for causal discovery that does not require any assumptions about the underlying model structures. Based on conditional independence tests in a class of reproducing kernel Hilbert spaces characterized by quantum circuits, the proposed algorithm can explore causal relations from the observed data drawn from arbitrary distributions. We conducted systematic experiments on fundamental graphs of causal structures, demonstrating that the qPC algorithm exhibits better performance, particularly with smaller sample sizes compared to its classical counterpart. Furthermore, we proposed a novel optimization approach based on Kernel Target Alignment (KTA) for determining hyperparameters of quantum kernels. This method effectively reduced the risk of false positives in causal discovery, enabling more reliable inference. Our theoretical and experimental results demonstrate that the quantum algorithm can empower classical algorithms for accurate inference in causal discovery, supporting them in regimes where classical algorithms typically fail. In addition, the effectiveness of this method was validated using the datasets on Boston housing prices, heart disease, and biological signaling systems as real-world applications. These findings highlight the potential of quantum-based causal discovery methods in addressing practical challenges, particularly in small-sample scenarios, where traditional approaches have shown significant limitations.",
    "summary": "arXiv:2501.05007v2 Announce Type: replace-cross Abstract: The discovery of causal relations from observed data has attracted significant interest from disciplines such as economics, social sciences, and biology. In practical applications, considerable knowledge of the underlying systems is often unavailable, and real data are usually associated with nonlinear causal structures, which makes the direct use of most conventional causality analysis methods difficult. This study proposes a novel quantum Peter-Clark (qPC) algorithm for causal discovery that does not require any assumptions about the underlying model structures. Based on conditional independence tests in a class of reproducing kernel Hilbert spaces characterized by quantum circuits, the proposed algorithm can explore causal relations from the observed data drawn from arbitrary distributions. We conducted systematic experiments on fundamental graphs of causal structures, demonstrating that the qPC algorithm exhibits better performance, particularly with smaller sample sizes compared to its classical counterpart. Furthermore, we proposed a novel optimization approach based on Kernel Target Alignment (KTA) for determining hyperparameters of quantum kernels. This method effectively reduced the risk of false positives in causal discovery, enabling more reliable inference. Our theoretical and experimental results demonstrate that the quantum algorithm can empower classical algorithms for accurate inference in causal discovery, supporting them in regimes where classical algorithms typically fail. In addition, the effectiveness of this method was validated using the datasets on Boston housing prices, heart disease, and biological signaling systems as real-world applications. These findings highlight the potential of quantum-based causal discovery methods in addressing practical challenges, particularly in small-sample scenarios, where traditional approaches have shown significant limitations.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.05007",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI achieves silver-medal standard solving International Mathematical Olympiad problems",
    "description": "Breakthrough models AlphaProof and AlphaGeometry 2 solve advanced reasoning problems in mathematics",
    "summary": "Breakthrough models AlphaProof and AlphaGeometry 2 solve advanced reasoning problems in mathematics",
    "pubDate": "Thu, 25 Jul 2024 15:29:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/",
    "thumbnail": "https://lh3.googleusercontent.com/2A21eFt7wdDrmMzzkenrCTuioLWGFdzU5Ao5dPH9yPtAw6QNHxZcDmoQA2_ZriU2gMjX8mzEOtfPbMCRuL5kVzLoz6efLgqT_foBXU3pxKBXTTOXXpc=w1200-h630-n-nu"
  },
  {
    "title": "Evaluating Language Model Bias with ü§ó Evaluate",
    "description": "",
    "summary": "Evaluating Language Model Bias with ü§ó Evaluate While the size and capabilities of large language mod...",
    "pubDate": "Mon, 24 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/evaluating-llm-bias",
    "thumbnail": "https://huggingface.co/blog/assets/112_evaluating-llm-bias/thumbnail.png"
  },
  {
    "title": "Deploying Speech-to-Speech on Hugging Face",
    "description": "",
    "summary": "Deploying Speech-to-Speech on Hugging Face Introduction Speech-to-Speech (S2S) is an exciting new pr...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/s2s_endpoint",
    "thumbnail": "https://huggingface.co/blog/assets/s2s_endpoint/thumbnail.png"
  },
  {
    "title": "Using generative AI to help robots jump higher and land safely",
    "description": "MIT CSAIL researchers combined GenAI and a physics simulation engine to refine robot designs. The result: a machine that out-jumped a robot designed by humans.",
    "summary": "MIT CSAIL researchers combined GenAI and a physics simulation engine to refine robot designs. The result: a machine that out-jumped a robot designed by humans.",
    "pubDate": "Fri, 27 Jun 2025 13:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/using-generative-ai-help-robots-jump-higher-land-safely-0627",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Jumping_Robot%20%285%29.png"
  },
  {
    "title": "Direct Preference Optimization Using Sparse Feature-Level Constraints",
    "description": "arXiv:2411.07618v2 Announce Type: replace Abstract: The alignment of large language models (LLMs) with human preferences remains a key challenge. While post-training techniques like Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO) have achieved notable success, they often introduce computational inefficiencies and training instability. In this paper, we propose Feature-level constrained Preference Optimization (FPO), a novel method designed to simplify the alignment process while ensuring stability. FPO leverages pre-trained Sparse Autoencoders (SAEs) and introduces feature-level constraints, allowing for efficient, sparsity-enforced alignment. Our approach enjoys efficiency by using sparse features activated in a well-trained sparse autoencoder and the quality of sequential KL divergence by using the feature-level offline reference. Experimental results on benchmark datasets demonstrate that FPO achieves a 5.08% absolute improvement in win rate with much lower computational cost compared to state-of-the-art baselines, making it a promising solution for efficient and controllable LLM alignments.",
    "summary": "arXiv:2411.07618v2 Announce Type: replace Abstract: The alignment of large language models (LLMs) with human preferences remains a key challenge. While post-training techniques like Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO) have achieved notable success, they often introduce computational inefficiencies and training instability. In this paper, we propose Feature-level constrained Preference Optimization (FPO), a novel method designed to simplify the alignment process while ensuring stability. FPO leverages pre-trained Sparse Autoencoders (SAEs) and introduces feature-level constraints, allowing for efficient, sparsity-enforced alignment. Our approach enjoys efficiency by using sparse features activated in a well-trained sparse autoencoder and the quality of sequential KL divergence by using the feature-level offline reference. Experimental results on benchmark datasets demonstrate that FPO achieves a 5.08% absolute improvement in win rate with much lower computational cost compared to state-of-the-art baselines, making it a promising solution for efficient and controllable LLM alignments.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.07618",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A hazard analysis framework for code synthesis large language models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-hazard-analysis-framework-for-code-synthesis-large-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy Embedding Models with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Deploy Embedding Models with Hugging Face Inference Endpoints The rise of Generative AI and LLMs lik...",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/168_inference_endpoints_embeddings/thumbnail.jpg"
  },
  {
    "title": "Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings",
    "description": "arXiv:2507.02403v1 Announce Type: cross Abstract: Wildlife re-identification aims to match individuals of the same species across different observations. Current state-of-the-art (SOTA) models rely on class labels to train supervised models for individual classification. This dependence on annotated data has driven the curation of numerous large-scale wildlife datasets. This study investigates self-supervised learning Self-Supervised Learning (SSL) for wildlife re-identification. We automatically extract two distinct views of an individual using temporal image pairs from camera trap data without supervision. The image pairs train a self-supervised model from a potentially endless stream of video data. We evaluate the learnt representations against supervised features on open-world scenarios and transfer learning in various wildlife downstream tasks. The analysis of the experimental results shows that self-supervised models are more robust even with limited data. Moreover, self-supervised features outperform supervision across all downstream tasks. The code is available here https://github.com/pxpana/SSLWildlife.",
    "summary": "arXiv:2507.02403v1 Announce Type: cross Abstract: Wildlife re-identification aims to match individuals of the same species across different observations. Current state-of-the-art (SOTA) models rely on class labels to train supervised models for individual classification. This dependence on annotated data has driven the curation of numerous large-scale wildlife datasets. This study investigates self-supervised learning Self-Supervised Learning (SSL) for wildlife re-identification. We automatically extract two distinct views of an individual using temporal image pairs from camera trap data without supervision. The image pairs train a self-supervised model from a potentially endless stream of video data. We evaluate the learnt representations against supervised features on open-world scenarios and transfer learning in various wildlife downstream tasks. The analysis of the experimental results shows that self-supervised models are more robust even with limited data. Moreover, self-supervised features outperform supervision across all downstream tasks. The code is available here https://github.com/pxpana/SSLWildlife.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02403",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Gemini: our largest and most capable AI model",
    "description": "Making AI more helpful for everyone",
    "summary": "Making AI more helpful for everyone",
    "pubDate": "Wed, 06 Dec 2023 15:13:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-our-largest-and-most-capable-ai-model/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_SS.width-1300.jpg"
  },
  {
    "title": "Fine-Tune ViT for Image Classification with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune ViT for Image Classification with ü§ó Transformers Just as transformers-based models have re...",
    "pubDate": "Fri, 11 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-vit",
    "thumbnail": "https://huggingface.co/blog/assets/51_fine_tune_vit/vit-thumbnail.jpg"
  },
  {
    "title": "Introducing the Enterprise Scenarios Leaderboard: a Leaderboard for Real World Use Cases",
    "description": "",
    "summary": "Introducing the Enterprise Scenarios Leaderboard: a Leaderboard for Real World Use Cases Today, the ...",
    "pubDate": "Wed, 31 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-patronus",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_patronus.png"
  },
  {
    "title": "OpenAI o3-mini System Card",
    "description": "This report outlines the safety work carried out for the OpenAI o3-mini model, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
    "summary": "This report outlines the safety work carried out for the OpenAI o3-mini model, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
    "pubDate": "Fri, 31 Jan 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-mini-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Red-Teaming Resistance Leaderboard",
    "description": "",
    "summary": "Introducing the Red-Teaming Resistance Leaderboard Content warning: since this blog post is about a ...",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-haizelab",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_haizelab.png"
  },
  {
    "title": "Fundamental Limits of Hierarchical Secure Aggregation with Cyclic User Association",
    "description": "arXiv:2503.04564v4 Announce Type: replace-cross Abstract: Secure aggregation is motivated by federated learning (FL) where a cloud server aims to compute an averaged model (i.e., weights of deep neural networks) of the locally-trained models of numerous clients, while adhering to data security requirements. Hierarchical secure aggregation (HSA) extends this concept to a three-layer hierarchical network, where clustered users communicate with the server through an intermediate layer of relays. In HSA, beyond conventional server security, relay security is also enforced to ensure that the relays remain oblivious to the users' inputs (an abstraction of the local models in FL). Existing study on HSA assumes that each user is associated with only one relay, limiting opportunities for coding across inter-cluster users to achieve efficient communication and key generation. In this paper, we consider HSA with a cyclic association pattern where each user is connected to $B$ consecutive relays in a wrap-around manner. We propose an efficient aggregation scheme which includes a message design for the inputs inspired by gradient coding-a well-known technique for efficient communication in distributed computing-along with a highly non-trivial security key design. We also derive novel converse bounds on the minimum achievable communication and key rates using information-theoretic arguments.",
    "summary": "arXiv:2503.04564v4 Announce Type: replace-cross Abstract: Secure aggregation is motivated by federated learning (FL) where a cloud server aims to compute an averaged model (i.e., weights of deep neural networks) of the locally-trained models of numerous clients, while adhering to data security requirements. Hierarchical secure aggregation (HSA) extends this concept to a three-layer hierarchical network, where clustered users communicate with the server through an intermediate layer of relays. In HSA, beyond conventional server security, relay security is also enforced to ensure that the relays remain oblivious to the users' inputs (an abstraction of the local models in FL). Existing study on HSA assumes that each user is associated with only one relay, limiting opportunities for coding across inter-cluster users to achieve efficient communication and key generation. In this paper, we consider HSA with a cyclic association pattern where each user is connected to $B$ consecutive relays in a wrap-around manner. We propose an efficient aggregation scheme which includes a message design for the inputs inspired by gradient coding-a well-known technique for efficient communication in distributed computing-along with a highly non-trivial security key design. We also derive novel converse bounds on the minimum achievable communication and key rates using information-theoretic arguments.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.04564",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Hallucinations Leaderboard, an Open Effort to Measure Hallucinations in Large Language Models",
    "description": "",
    "summary": "The Hallucinations Leaderboard, an Open Effort to Measure Hallucinations in Large Language Models In...",
    "pubDate": "Mon, 29 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-hallucinations",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "Best practices for deploying language models",
    "description": "Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models.",
    "summary": "Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models.",
    "pubDate": "Thu, 02 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/best-practices-for-deploying-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Reads, Feb. 2021 - Long-range Transformers",
    "description": "",
    "summary": "Hugging Face Reads, Feb. 2021 - Long-range Transformers Co-written by Teven Le Scao, Patrick Von Pla...",
    "pubDate": "Tue, 09 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/long-range-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/14_long_range_transformers/EfficientTransformerTaxonomy.png"
  },
  {
    "title": "Optimize and deploy models with Optimum-Intel and OpenVINO GenAI",
    "description": "",
    "summary": "Optimize and deploy models with Optimum-Intel and OpenVINO GenAI Deploying Transformers models at th...",
    "pubDate": "Fri, 20 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-with-openvino",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Empowering YouTube creators with generative AI",
    "description": "New video generation technology in YouTube Shorts will help millions of people realize their creative vision",
    "summary": "New video generation technology in YouTube Shorts will help millions of people realize their creative vision",
    "pubDate": "Wed, 18 Sep 2024 14:30:06 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/empowering-youtube-creators-with-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/Q8qBc1kzbYeksHRjsSuR7HEvezKsw3n1fxYlOqLf2sslqDOqYXJOhxyjznZ4cyq1fwNhpyMTMXW0RRrgHweVg6NaCEPnt3ujcFAIe0bVXK_sHka7cLo=w1200-h630-n-nu"
  },
  {
    "title": "Using AI to improve patient access to clinical trials",
    "description": "Paradigm uses OpenAI‚Äôs API to improve patient access to clinical trials.",
    "summary": "Paradigm uses OpenAI‚Äôs API to improve patient access to clinical trials.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paradigm",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ICASSP2025 Áô∫Ë°®Â†±Âëä @Hyderabad, India",
    "description": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ 2025Âπ¥4Êúà6Êó•(Êó•)„Äú4Êúà11Êó•(Èáë)„Å´„Ç§„É≥„Éâ„Éª„Éè„Ç§„Éá„É©„Éê„Éº„Éâ„ÄÅHyderabad International Convention Centre„Å´„Å¶ÈñãÂÇ¨„Åï„Çå„Åü„ÄÅÈü≥Èüø„ÉªÈü≥ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5728' rel='nofollow'>ICASSP2025 Áô∫Ë°®Â†±Âëä @Hyderabad, India</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ 2025Âπ¥4Êúà6Êó•(Êó•)„Äú4Êúà11Êó•(Èáë)„Å´„Ç§„É≥„Éâ„Éª„Éè„Ç§„Éá„É©„Éê„Éº„Éâ„ÄÅHyderabad International Convention Centre„Å´„Å¶ÈñãÂÇ¨„Åï„Çå„Åü„ÄÅÈü≥Èüø„ÉªÈü≥ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5728' rel='nofollow'>ICASSP2025 Áô∫Ë°®Â†±Âëä @Hyderabad, India</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Tue, 15 Apr 2025 01:50:49 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5728",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/IMG_20250406_091623-1.jpg"
  },
  {
    "title": "The Partnership: Amazon SageMaker and Hugging Face",
    "description": "",
    "summary": "The Partnership: Amazon SageMaker and Hugging Face Look at these smiles! Today, we announce a strate...",
    "pubDate": "Tue, 23 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face",
    "thumbnail": "https://huggingface.co/blog/assets/17_the_partnership_amazon_sagemaker_and_hugging_face/thumbnail.png"
  },
  {
    "title": "Nubank elevates customer experiences with OpenAI",
    "description": "Nubank elevates customer experiences with OpenAI",
    "summary": "Nubank elevates customer experiences with OpenAI",
    "pubDate": "Fri, 07 Mar 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nubank",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New ViT and ALIGN Models From Kakao Brain",
    "description": "",
    "summary": "Kakao Brain‚Äôs Open Source ViT, ALIGN, and the New COYO Text-Image Dataset Kakao Brain and Hugging Fa...",
    "pubDate": "Mon, 06 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vit-align",
    "thumbnail": "https://huggingface.co/blog//assets/132_vit_align/thumbnail.png"
  },
  {
    "title": "License to Call: Introducing Transformers Agents 2.0",
    "description": "",
    "summary": "License to Call: Introducing Transformers Agents 2.0 TL;DR We are releasing Transformers Agents 2.0!...",
    "pubDate": "Mon, 13 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/agents",
    "thumbnail": "https://huggingface.co/blog/assets/agents/thumbnail.png"
  },
  {
    "title": "Faster Training and Inference: Habana Gaudi¬Æ2 vs Nvidia A100 80GB",
    "description": "",
    "summary": "Faster Training and Inference: Habana Gaudi¬Æ-2 vs Nvidia A100 80GB In this article, you will learn h...",
    "pubDate": "Wed, 14 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana-gaudi-2-benchmark",
    "thumbnail": "https://huggingface.co/blog/assets/habana-gaudi-2-benchmark/thumbnail.png"
  },
  {
    "title": "Two-Steps Neural Networks for an Automated Cerebrovascular Landmark Detection",
    "description": "arXiv:2507.02349v1 Announce Type: cross Abstract: Intracranial aneurysms (ICA) commonly occur in specific segments of the Circle of Willis (CoW), primarily, onto thirteen major arterial bifurcations. An accurate detection of these critical landmarks is necessary for a prompt and efficient diagnosis. We introduce a fully automated landmark detection approach for CoW bifurcations using a two-step neural networks process. Initially, an object detection network identifies regions of interest (ROIs) proximal to the landmark locations. Subsequently, a modified U-Net with deep supervision is exploited to accurately locate the bifurcations. This two-step method reduces various problems, such as the missed detections caused by two landmarks being close to each other and having similar visual characteristics, especially when processing the complete MRA Time-of-Flight (TOF). Additionally, it accounts for the anatomical variability of the CoW, which affects the number of detectable landmarks per scan. We assessed the effectiveness of our approach using two cerebral MRA datasets: our In-House dataset which had varying numbers of landmarks, and a public dataset with standardized landmark configuration. Our experimental results demonstrate that our method achieves the highest level of performance on a bifurcation detection task.",
    "summary": "arXiv:2507.02349v1 Announce Type: cross Abstract: Intracranial aneurysms (ICA) commonly occur in specific segments of the Circle of Willis (CoW), primarily, onto thirteen major arterial bifurcations. An accurate detection of these critical landmarks is necessary for a prompt and efficient diagnosis. We introduce a fully automated landmark detection approach for CoW bifurcations using a two-step neural networks process. Initially, an object detection network identifies regions of interest (ROIs) proximal to the landmark locations. Subsequently, a modified U-Net with deep supervision is exploited to accurately locate the bifurcations. This two-step method reduces various problems, such as the missed detections caused by two landmarks being close to each other and having similar visual characteristics, especially when processing the complete MRA Time-of-Flight (TOF). Additionally, it accounts for the anatomical variability of the CoW, which affects the number of detectable landmarks per scan. We assessed the effectiveness of our approach using two cerebral MRA datasets: our In-House dataset which had varying numbers of landmarks, and a public dataset with standardized landmark configuration. Our experimental results demonstrate that our method achieves the highest level of performance on a bifurcation detection task.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02349",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Aerial Vision-and-Language Navigation via Semantic-Topo-Metric Representation Guided LLM Reasoning",
    "description": "arXiv:2410.08500v2 Announce Type: replace-cross Abstract: Aerial Vision-and-Language Navigation (VLN) is a novel task enabling Unmanned Aerial Vehicles (UAVs) to navigate in outdoor environments through natural language instructions and visual cues. It remains challenging due to the complex spatial relationships in outdoor aerial scenes. In this paper, we propose an end-to-end zero-shot framework for aerial VLN tasks, where the large language model (LLM) is introduced as our agent for action prediction. Specifically, we develop a novel Semantic-Topo-Metric Representation (STMR) to enhance the spatial reasoning ability of LLMs. This is achieved by extracting and projecting instruction-related semantic masks of landmarks into a top-down map that contains the location information of surrounding landmarks. Further, this map is transformed into a matrix representation with distance metrics as the text prompt to the LLM, for action prediction according to the instruction. Experiments conducted in real and simulation environments have successfully proved the effectiveness and robustness of our method, achieving 15.9% and 12.5% improvements (absolute) in Oracle Success Rate (OSR) on AerialVLN-S dataset.",
    "summary": "arXiv:2410.08500v2 Announce Type: replace-cross Abstract: Aerial Vision-and-Language Navigation (VLN) is a novel task enabling Unmanned Aerial Vehicles (UAVs) to navigate in outdoor environments through natural language instructions and visual cues. It remains challenging due to the complex spatial relationships in outdoor aerial scenes. In this paper, we propose an end-to-end zero-shot framework for aerial VLN tasks, where the large language model (LLM) is introduced as our agent for action prediction. Specifically, we develop a novel Semantic-Topo-Metric Representation (STMR) to enhance the spatial reasoning ability of LLMs. This is achieved by extracting and projecting instruction-related semantic masks of landmarks into a top-down map that contains the location information of surrounding landmarks. Further, this map is transformed into a matrix representation with distance metrics as the text prompt to the LLM, for action prediction according to the instruction. Experiments conducted in real and simulation environments have successfully proved the effectiveness and robustness of our method, achieving 15.9% and 12.5% improvements (absolute) in Oracle Success Rate (OSR) on AerialVLN-S dataset.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.08500",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Addendum to OpenAI o3 and o4-mini system card: OpenAI o3 Operator",
    "description": "We are replacing the existing GPT-4o-based model for Operator with a version based on OpenAI o3. The API version will remain based on 4o.",
    "summary": "We are replacing the existing GPT-4o-based model for Operator with a version based on OpenAI o3. The API version will remain based on 4o.",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-system-card-addendum-operator-o3",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Model Distillation in the API",
    "description": "Fine-tune a cost-efficient model with the outputs of a large frontier model‚Äìall on the OpenAI platform",
    "summary": "Fine-tune a cost-efficient model with the outputs of a large frontier model‚Äìall on the OpenAI platform",
    "pubDate": "Tue, 01 Oct 2024 10:02:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-model-distillation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our vision for building a universal AI assistant",
    "description": "We‚Äôre extending Gemini to become a world model that can make plans and imagine new experiences by simulating aspects of the world.",
    "summary": "We‚Äôre extending Gemini to become a world model that can make plans and imagine new experiences by simulating aspects of the world.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/our-vision-for-building-a-universal-ai-assistant/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_GeminiVision_SocialShare.width-1300.png"
  },
  {
    "title": "AMD Pervasive AI Developer Contest!",
    "description": "",
    "summary": "AMD Pervasive AI Developer Contest AMD and Hugging Face are actively engaged in helping developers s...",
    "pubDate": "Wed, 14 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/amd_pervasive_developer_ai_contest",
    "thumbnail": "https://huggingface.co/blog/amd_pervasive_developer_ai_contest/assets/amd_pervasive_developer_ai_contest/amd_developer_general_abstract.jpg"
  },
  {
    "title": "Mixture of Experts Explained",
    "description": "",
    "summary": "Mixture of Experts Explained With the release of Mixtral 8x7B (announcement, model card), a class of...",
    "pubDate": "Mon, 11 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/moe",
    "thumbnail": "https://huggingface.co/blog/assets/moe/thumbnail.png"
  },
  {
    "title": "Spam detection in the physical world",
    "description": "We‚Äôve created the world‚Äôs first Spam-detecting AI trained entirely in simulation and deployed on a physical robot.",
    "summary": "We‚Äôve created the world‚Äôs first Spam-detecting AI trained entirely in simulation and deployed on a physical robot.",
    "pubDate": "Sat, 01 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spam-detection-in-the-physical-world",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Demis Hassabis & John Jumper awarded Nobel Prize in Chemistry",
    "description": "The award recognizes their work developing AlphaFold, a groundbreaking AI system that predicts the 3D structure of proteins from their amino acid sequences.",
    "summary": "The award recognizes their work developing AlphaFold, a groundbreaking AI system that predicts the 3D structure of proteins from their amino acid sequences.",
    "pubDate": "Wed, 09 Oct 2024 11:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/demis-hassabis-john-jumper-awarded-nobel-prize-in-chemistry/",
    "thumbnail": "https://lh3.googleusercontent.com/7ZdZh5xhoD5NnykRBJHACxkxc3VubCdJLGHty2nYdJ36pBLVxRWO3Keu9C2Tum4OHCyGbJ5K5mB8R_oR94JG700qenuZ2rhq2sKjN4IkjIoU9Chv=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI Red Teaming Network",
    "description": "We‚Äôre announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in improving the safety of OpenAI‚Äôs models to join our efforts.",
    "summary": "We‚Äôre announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in improving the safety of OpenAI‚Äôs models to join our efforts.",
    "pubDate": "Tue, 19 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/red-teaming-network",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interleaved Gibbs Diffusion: Generating Discrete-Continuous Data with Implicit Constraints",
    "description": "arXiv:2502.13450v2 Announce Type: replace-cross Abstract: We introduce Interleaved Gibbs Diffusion (IGD), a novel generative modeling framework for discrete-continuous data, focusing on problems with important, implicit and unspecified constraints in the data. Most prior works on discrete and discrete-continuous diffusion assume a factorized denoising distribution, which can hinder the modeling of strong dependencies between random variables in such problems. We empirically demonstrate a significant improvement in 3-SAT performance out of the box by switching to a Gibbs-sampling style discrete diffusion model which does not assume factorizability. Motivated by this, we introduce IGD which generalizes discrete time Gibbs sampling type Markov chain for the case of discrete-continuous generation. IGD allows for seamless integration between discrete and continuous denoisers while theoretically guaranteeing exact reversal of a suitable forward process. Further, it provides flexibility in the choice of denoisers, allows conditional generation via state-space doubling and inference time refinement. Empirical evaluations on three challenging generation tasks - molecule structures, layouts and tabular data - demonstrate state-of-the-art performance. Notably, IGD achieves state-of-the-art results without relying on domain-specific inductive biases like equivariant diffusion or auxiliary losses. We explore a wide range of modeling, and interleaving strategies along with hyperparameters in each of these problems.",
    "summary": "arXiv:2502.13450v2 Announce Type: replace-cross Abstract: We introduce Interleaved Gibbs Diffusion (IGD), a novel generative modeling framework for discrete-continuous data, focusing on problems with important, implicit and unspecified constraints in the data. Most prior works on discrete and discrete-continuous diffusion assume a factorized denoising distribution, which can hinder the modeling of strong dependencies between random variables in such problems. We empirically demonstrate a significant improvement in 3-SAT performance out of the box by switching to a Gibbs-sampling style discrete diffusion model which does not assume factorizability. Motivated by this, we introduce IGD which generalizes discrete time Gibbs sampling type Markov chain for the case of discrete-continuous generation. IGD allows for seamless integration between discrete and continuous denoisers while theoretically guaranteeing exact reversal of a suitable forward process. Further, it provides flexibility in the choice of denoisers, allows conditional generation via state-space doubling and inference time refinement. Empirical evaluations on three challenging generation tasks - molecule structures, layouts and tabular data - demonstrate state-of-the-art performance. Notably, IGD achieves state-of-the-art results without relying on domain-specific inductive biases like equivariant diffusion or auxiliary losses. We explore a wide range of modeling, and interleaving strategies along with hyperparameters in each of these problems.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.13450",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI announces nonprofit commission advisors",
    "description": "OpenAI is appointing four new advisors to help inform OpenAI‚Äôs philanthropic efforts.",
    "summary": "OpenAI is appointing four new advisors to help inform OpenAI‚Äôs philanthropic efforts.",
    "pubDate": "Tue, 15 Apr 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonprofit-commission-advisors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware",
    "description": "",
    "summary": "(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware In our previous post, Exploring Quantization Back...",
    "pubDate": "Thu, 19 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/flux-qlora",
    "thumbnail": "https://huggingface.co/blog/assets/flux-qlora/thumbnail.png"
  },
  {
    "title": "Welcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM",
    "description": "",
    "summary": "Welcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM TL;DR Today Google...",
    "pubDate": "Wed, 12 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma3",
    "thumbnail": "https://huggingface.co/blog/assets/gemma3/thumbnail.png"
  },
  {
    "title": "OpenAI announces new members to board of directors",
    "description": "Dr. Sue Desmond-Hellmann, Nicole Seligman, Fidji Simo join; Sam Altman rejoins board",
    "summary": "Dr. Sue Desmond-Hellmann, Nicole Seligman, Fidji Simo join; Sam Altman rejoins board",
    "pubDate": "Fri, 08 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-announces-new-members-to-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Teaching AI models the broad strokes to sketch more like humans do",
    "description": "SketchAgent, a drawing system developed by MIT CSAIL researchers, sketches up concepts stroke-by-stroke, teaching language models to visually express concepts on their own and collaborate with humans.",
    "summary": "SketchAgent, a drawing system developed by MIT CSAIL researchers, sketches up concepts stroke-by-stroke, teaching language models to visually express concepts on their own and collaborate with humans.",
    "pubDate": "Mon, 02 Jun 2025 14:50:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/teaching-ai-models-to-sketch-more-like-humans-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-SketchAgent.jpg"
  },
  {
    "title": "Deep Dive: Vision Transformers On Hugging Face Optimum Graphcore",
    "description": "",
    "summary": "Deep Dive: Vision Transformers On Hugging Face Optimum Graphcore This blog post will show how easy i...",
    "pubDate": "Thu, 18 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/97_vision_transformers/thumbnail.png"
  },
  {
    "title": "Techniques for training large neural networks",
    "description": "Large neural networks are at the core of many recent advances in AI, but training them is a difficult engineering and research challenge which requires orchestrating a cluster of GPUs to perform a single synchronized calculation.",
    "summary": "Large neural networks are at the core of many recent advances in AI, but training them is a difficult engineering and research challenge which requires orchestrating a cluster of GPUs to perform a single synchronized calculation.",
    "pubDate": "Thu, 09 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/techniques-for-training-large-neural-networks",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ask a Techspert: What is inference?",
    "description": "Illustration of a computer chip surrounded by elements representing AI and data, including a cat's head, a wireframe cat, puzzle pieces, a bar graph, gears, and text bubbles.",
    "summary": "Illustration of a computer chip surrounded by elements representing AI and data, including a cat's head, a wireframe cat, puzzle pieces, a bar graph, gears, and text bubbles.",
    "pubDate": "Mon, 23 Jun 2025 17:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/ask-a-techspert-what-is-inference/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/InferenceHero_v3.width-1300.png"
  },
  {
    "title": "„Çπ„Éã„Éï„Ç¢„Ç¶„Éà„ÄÅRAG Ready ConverterÔºàŒ≤Ôºâ„Çí„É™„É™„Éº„Çπ„ÄÇÂÖ®„Å¶„ÅÆ„Éá„Éº„Çø„ÇíRAG„ÅåÊâ±„ÅÑ„ÇÑ„Åô„ÅÑÂΩ¢Âºè„Å∏Â§âÊèõ",
    "description": "<p>„Çπ„Éã„Éï„Ç¢„Ç¶„Éà„ÅØ„ÄÅ„ÅÇ„Çâ„ÇÜ„ÇãÂΩ¢Âºè„ÅÆ„Éï„Ç°„Ç§„É´„Çí RAG „ÅåÊâ±„ÅÑ„ÇÑ„Åô„ÅÑÂΩ¢Âºè„Å∏Â§âÊèõ„Åô„ÇãÊñ∞„Ç∑„Çπ„ÉÜ„É†„ÄåRAG Ready ConverterÔºàŒ≤Ôºâ„Äç„ÇíÂÖ¨Èñã„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà „Çπ„Éã„Éï„Ç¢„Ç¶„Éà„ÅØ„ÄÅ„ÅÇ„Çâ„ÇÜ„ÇãÂΩ¢Âºè„ÅÆ„Éï„Ç°„Ç§„É´„ÇíRA [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/sniffout-rag-ready-converter/'>„Çπ„Éã„Éï„Ç¢„Ç¶„Éà„ÄÅRAG Ready ConverterÔºàŒ≤Ôºâ„Çí„É™„É™„Éº„Çπ„ÄÇÂÖ®„Å¶„ÅÆ„Éá„Éº„Çø„ÇíRAG„ÅåÊâ±„ÅÑ„ÇÑ„Åô„ÅÑÂΩ¢Âºè„Å∏Â§âÊèõ</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>„Çπ„Éã„Éï„Ç¢„Ç¶„Éà„ÅØ„ÄÅ„ÅÇ„Çâ„ÇÜ„ÇãÂΩ¢Âºè„ÅÆ„Éï„Ç°„Ç§„É´„Çí RAG „ÅåÊâ±„ÅÑ„ÇÑ„Åô„ÅÑÂΩ¢Âºè„Å∏Â§âÊèõ„Åô„ÇãÊñ∞„Ç∑„Çπ„ÉÜ„É†„ÄåRAG Ready ConverterÔºàŒ≤Ôºâ„Äç„ÇíÂÖ¨Èñã„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà „Çπ„Éã„Éï„Ç¢„Ç¶„Éà„ÅØ„ÄÅ„ÅÇ„Çâ„ÇÜ„ÇãÂΩ¢Âºè„ÅÆ„Éï„Ç°„Ç§„É´„ÇíRA [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/sniffout-rag-ready-converter/'>„Çπ„Éã„Éï„Ç¢„Ç¶„Éà„ÄÅRAG Ready ConverterÔºàŒ≤Ôºâ„Çí„É™„É™„Éº„Çπ„ÄÇÂÖ®„Å¶„ÅÆ„Éá„Éº„Çø„ÇíRAG„ÅåÊâ±„ÅÑ„ÇÑ„Åô„ÅÑÂΩ¢Âºè„Å∏Â§âÊèõ</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Tue, 01 Jul 2025 08:57:11 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/sniffout-rag-ready-converter/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/ragready.png"
  },
  {
    "title": "Scaling laws for neural language models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 23 Jan 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-laws-for-neural-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "XGeM: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation",
    "description": "arXiv:2501.04614v3 Announce Type: replace Abstract: The adoption of Artificial Intelligence in medical imaging holds great promise, yet it remains hindered by challenges such as data scarcity, privacy concerns, and the need for robust multimodal integration. While recent advances in generative modeling have enabled high-quality synthetic data generation, existing approaches are often limited to unimodal, unidirectional synthesis and therefore lack the ability to jointly synthesize multiple modalities while preserving clinical consistency. To address this challenge, we introduce XGeM, a 6.77-billion-parameter multimodal generative model designed to support flexible, any-to-any synthesis between medical data modalities. XGeM constructs a shared latent space via contrastive learning and introduces a novel Multi-Prompt Training strategy, enabling conditioning on arbitrary subsets of input modalities. This design allows the model to adapt to heterogeneous clinical inputs and generate multiple outputs jointly, preserving both semantic and structural coherence. We extensively validate XGeM: first we benchmark it against five competitors on the MIMIC-CXR dataset, a state-of-the-art dataset for multi-view Chest X-ray and radiological report generation. Secondly, we perform a Visual Turing Test with expert radiologists to assess the realism and clinical relevance of the generated data, ensuring alignment with real-world scenarios. Finally, we show how XGeM can support key medical data challenges such as anonymization, class imbalance, and data scarcity, underscoring its utility as a foundation model for medical data synthesis. Project page is at https://cosbidev.github.io/XGeM/.",
    "summary": "arXiv:2501.04614v3 Announce Type: replace Abstract: The adoption of Artificial Intelligence in medical imaging holds great promise, yet it remains hindered by challenges such as data scarcity, privacy concerns, and the need for robust multimodal integration. While recent advances in generative modeling have enabled high-quality synthetic data generation, existing approaches are often limited to unimodal, unidirectional synthesis and therefore lack the ability to jointly synthesize multiple modalities while preserving clinical consistency. To address this challenge, we introduce XGeM, a 6.77-billion-parameter multimodal generative model designed to support flexible, any-to-any synthesis between medical data modalities. XGeM constructs a shared latent space via contrastive learning and introduces a novel Multi-Prompt Training strategy, enabling conditioning on arbitrary subsets of input modalities. This design allows the model to adapt to heterogeneous clinical inputs and generate multiple outputs jointly, preserving both semantic and structural coherence. We extensively validate XGeM: first we benchmark it against five competitors on the MIMIC-CXR dataset, a state-of-the-art dataset for multi-view Chest X-ray and radiological report generation. Secondly, we perform a Visual Turing Test with expert radiologists to assess the realism and clinical relevance of the generated data, ensuring alignment with real-world scenarios. Finally, we show how XGeM can support key medical data challenges such as anonymization, class imbalance, and data scarcity, underscoring its utility as a foundation model for medical data synthesis. Project page is at https://cosbidev.github.io/XGeM/.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.04614",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Glow: Better reversible generative models",
    "description": "We introduce¬†Glow, a reversible generative model which uses invertible 1x1 convolutions. It extends¬†previous¬†work¬†on reversible generative models and simplifies the architecture. Our model can generate realistic high resolution images, supports efficient sampling, and discovers features that can be used to manipulate attributes of data. We‚Äôre releasing code for the model and an online visualization tool so people can explore and build on these¬†results.",
    "summary": "We introduce¬†Glow, a reversible generative model which uses invertible 1x1 convolutions. It extends¬†previous¬†work¬†on reversible generative models and simplifies the architecture. Our model can generate realistic high resolution images, supports efficient sampling, and discovers features that can be used to manipulate attributes of data. We‚Äôre releasing code for the model and an online visualization tool so people can explore and build on these¬†results.",
    "pubDate": "Mon, 09 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/glow",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios",
    "description": "arXiv:2507.02479v1 Announce Type: cross Abstract: Multi-object tracking is a classic field in computer vision. Among them, pedestrian tracking has extremely high application value and has become the most popular research category. Existing methods mainly use motion or appearance information for tracking, which is often difficult in complex scenarios. For the motion information, mutual occlusions between objects often prevent updating of the motion state; for the appearance information, non-robust results are often obtained due to reasons such as only partial visibility of the object or blurred images. Although learning how to perform tracking in these situations from the annotated data is the simplest solution, the existing MOT dataset fails to satisfy this solution. Existing methods mainly have two drawbacks: relatively simple scene composition and non-realistic scenarios. Although some of the video sequences in existing dataset do not have the above-mentioned drawbacks, the number is far from adequate for research purposes. To this end, we propose a difficult large-scale dataset for multi-pedestrian tracking, shot mainly from the first-person view and all from real-life complex scenarios. We name it ``CrowdTrack'' because there are numerous objects in most of the sequences. Our dataset consists of 33 videos, containing a total of 5,185 trajectories. Each object is annotated with a complete bounding box and a unique object ID. The dataset will provide a platform to facilitate the development of algorithms that remain effective in complex situations. We analyzed the dataset comprehensively and tested multiple SOTA models on our dataset. Besides, we analyzed the performance of the foundation models on our dataset. The dataset and project code is released at: https://github.com/loseevaya/CrowdTrack .",
    "summary": "arXiv:2507.02479v1 Announce Type: cross Abstract: Multi-object tracking is a classic field in computer vision. Among them, pedestrian tracking has extremely high application value and has become the most popular research category. Existing methods mainly use motion or appearance information for tracking, which is often difficult in complex scenarios. For the motion information, mutual occlusions between objects often prevent updating of the motion state; for the appearance information, non-robust results are often obtained due to reasons such as only partial visibility of the object or blurred images. Although learning how to perform tracking in these situations from the annotated data is the simplest solution, the existing MOT dataset fails to satisfy this solution. Existing methods mainly have two drawbacks: relatively simple scene composition and non-realistic scenarios. Although some of the video sequences in existing dataset do not have the above-mentioned drawbacks, the number is far from adequate for research purposes. To this end, we propose a difficult large-scale dataset for multi-pedestrian tracking, shot mainly from the first-person view and all from real-life complex scenarios. We name it ``CrowdTrack'' because there are numerous objects in most of the sequences. Our dataset consists of 33 videos, containing a total of 5,185 trajectories. Each object is annotated with a complete bounding box and a unique object ID. The dataset will provide a platform to facilitate the development of algorithms that remain effective in complex situations. We analyzed the dataset comprehensively and tested multiple SOTA models on our dataset. Besides, we analyzed the performance of the foundation models on our dataset. The dataset and project code is released at: https://github.com/loseevaya/CrowdTrack .",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02479",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Variational option discovery algorithms",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 26 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variational-option-discovery-algorithms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AMD + ü§ó: Large Language Models Out-of-the-Box Acceleration with AMD GPU",
    "description": "",
    "summary": "AMD + ü§ó: Large Language Models Out-of-the-Box Acceleration with AMD GPU Earlier this year, AMD and H...",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-optimum-amd",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "DNN-Based Precoding in RIS-Aided mmWave MIMO Systems With Practical Phase Shift",
    "description": "arXiv:2507.02824v1 Announce Type: cross Abstract: In this paper, the precoding design is investigated for maximizing the throughput of millimeter wave (mmWave) multiple-input multiple-output (MIMO) systems with obstructed direct communication paths. In particular, a reconfigurable intelligent surface (RIS) is employed to enhance MIMO transmissions, considering mmWave characteristics related to line-of-sight (LoS) and multipath effects. The traditional exhaustive search (ES) for optimal codewords in the continuous phase shift is computationally intensive and time-consuming. To reduce computational complexity, permuted discrete Fourier transform (DFT) vectors are used for finding codebook design, incorporating amplitude responses for practical or ideal RIS systems. However, even if the discrete phase shift is adopted in the ES, it results in significant computation and is time-consuming. Instead, the trained deep neural network (DNN) is developed to facilitate faster codeword selection. Simulation results show that the DNN maintains sub-optimal spectral efficiency even as the distance between the end-user and the RIS has variations in the testing phase. These results highlight the potential of DNN in advancing RIS-aided systems.",
    "summary": "arXiv:2507.02824v1 Announce Type: cross Abstract: In this paper, the precoding design is investigated for maximizing the throughput of millimeter wave (mmWave) multiple-input multiple-output (MIMO) systems with obstructed direct communication paths. In particular, a reconfigurable intelligent surface (RIS) is employed to enhance MIMO transmissions, considering mmWave characteristics related to line-of-sight (LoS) and multipath effects. The traditional exhaustive search (ES) for optimal codewords in the continuous phase shift is computationally intensive and time-consuming. To reduce computational complexity, permuted discrete Fourier transform (DFT) vectors are used for finding codebook design, incorporating amplitude responses for practical or ideal RIS systems. However, even if the discrete phase shift is adopted in the ES, it results in significant computation and is time-consuming. Instead, the trained deep neural network (DNN) is developed to facilitate faster codeword selection. Simulation results show that the DNN maintains sub-optimal spectral efficiency even as the distance between the end-user and the RIS has variations in the testing phase. These results highlight the potential of DNN in advancing RIS-aided systems.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02824",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LangGraph CodeAct„ÇíE2B„ÅÆÂÆâÂÖ®„Å™‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åô",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØÂÖàÊó•LangChain„Åã„ÇâÁô∫Ë°®„Åï„Çå„ÅüLangGraph CodeAct„ÇíE2B„ÅÆ‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åó„Å¶„Åø„Çà„ÅÜ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇCodeAct„ÅØÊúÄËøëÊ≥®ÁõÆ„ÇíÈõÜ„ÇÅ„Å¶„ÅÑ„ÇãAI Agent„ÅÆTool [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5652' rel='nofollow'>LangGraph CodeAct„ÇíE2B„ÅÆÂÆâÂÖ®„Å™‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åô</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØÂÖàÊó•LangChain„Åã„ÇâÁô∫Ë°®„Åï„Çå„ÅüLangGraph CodeAct„ÇíE2B„ÅÆ‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åó„Å¶„Åø„Çà„ÅÜ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇCodeAct„ÅØÊúÄËøëÊ≥®ÁõÆ„ÇíÈõÜ„ÇÅ„Å¶„ÅÑ„ÇãAI Agent„ÅÆTool [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5652' rel='nofollow'>LangGraph CodeAct„ÇíE2B„ÅÆÂÆâÂÖ®„Å™‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åô</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Thu, 17 Apr 2025 01:11:36 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5652",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "Deploy LLMs with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Deploy LLMs with Hugging Face Inference Endpoints Open-source LLMs like Falcon, (Open-)LLaMA, X-Gen,...",
    "pubDate": "Tue, 04 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints-llm",
    "thumbnail": "https://huggingface.co/blog/assets/155_inference_endpoints_llm/thumbnail.jpg"
  },
  {
    "title": "SmolVLM Grows Smaller ‚Äì Introducing the 250M & 500M Models!",
    "description": "",
    "summary": "SmolVLM Grows Smaller ‚Äì Introducing the 250M & 500M Models! TLDR We‚Äôre excited to announce two new a...",
    "pubDate": "Thu, 23 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolervlm",
    "thumbnail": "https://huggingface.co/blog/assets/smolervlm/banner.png"
  },
  {
    "title": "How we're supporting better tropical cyclone prediction with AI",
    "description": "We‚Äôre launching Weather Lab, featuring our experimental cyclone predictions, and we‚Äôre partnering with the U.S. National Hurricane Center to support their forecasts and warnings this cyclone season.",
    "summary": "We‚Äôre launching Weather Lab, featuring our experimental cyclone predictions, and we‚Äôre partnering with the U.S. National Hurricane Center to support their forecasts and warnings this cyclone season.",
    "pubDate": "Thu, 12 Jun 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/weather-lab-cyclone-predictions-with-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/4emGMNrEdaydebppYDiyQMNhXtgUFr8VvrKhVItMHENrxeWmWO9yqhteSj2fe25lxkiZAu7vOZZcsXPDLg0O-LPSvk6CS1I8E2-GdjtoN_2ViJOY=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI‚Äôs comment to the NTIA on open model weights",
    "description": "OpenAI‚Äôs comment to the NTIA on open model weights This comment was submitted by OpenAI in response to NTIA‚Äôs March 2024 Request for Information on Dual-Use Foundation Models with Widely Available Weights.",
    "summary": "OpenAI‚Äôs comment to the NTIA on open model weights This comment was submitted by OpenAI in response to NTIA‚Äôs March 2024 Request for Information on Dual-Use Foundation Models with Widely Available Weights.",
    "pubDate": "Wed, 27 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-s-comment-to-the-ntia-on-open-model-weights",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learnable-Differentiable Finite Volume Solver for Accelerated Simulation of Flows",
    "description": "arXiv:2507.01975v1 Announce Type: cross Abstract: Simulation of fluid flows is crucial for modeling physical phenomena like meteorology, aerodynamics, and biomedicine. Classical numerical solvers often require fine spatiotemporal grids to satisfy stability, consistency, and convergence conditions, leading to substantial computational costs. Although machine learning has demonstrated better efficiency, they typically suffer from issues of interpretability, generalizability, and data dependency. Hence, we propose a learnable and differentiable finite volume solver, called LDSolver, designed for efficient and accurate simulation of fluid flows on spatiotemporal coarse grids. LDSolver comprises two key components: (1) a differentiable finite volume solver, and (2) an learnable module providing equivalent approximation for fluxes (derivatives and interpolations), and temporal error correction on coarse grids. Even with limited training data (e.g., only a few trajectories), our model could accelerate the simulation while maintaining a high accuracy with superior generalizability. Experiments on different flow systems (e.g., Burgers, decaying, forced and shear flows) show that LDSolver achieves state-of-the-art performance, surpassing baseline models with notable margins.",
    "summary": "arXiv:2507.01975v1 Announce Type: cross Abstract: Simulation of fluid flows is crucial for modeling physical phenomena like meteorology, aerodynamics, and biomedicine. Classical numerical solvers often require fine spatiotemporal grids to satisfy stability, consistency, and convergence conditions, leading to substantial computational costs. Although machine learning has demonstrated better efficiency, they typically suffer from issues of interpretability, generalizability, and data dependency. Hence, we propose a learnable and differentiable finite volume solver, called LDSolver, designed for efficient and accurate simulation of fluid flows on spatiotemporal coarse grids. LDSolver comprises two key components: (1) a differentiable finite volume solver, and (2) an learnable module providing equivalent approximation for fluxes (derivatives and interpolations), and temporal error correction on coarse grids. Even with limited training data (e.g., only a few trajectories), our model could accelerate the simulation while maintaining a high accuracy with superior generalizability. Experiments on different flow systems (e.g., Burgers, decaying, forced and shear flows) show that LDSolver achieves state-of-the-art performance, surpassing baseline models with notable margins.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01975",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face Platform on the AWS Marketplace: Pay with your AWS Account",
    "description": "",
    "summary": "Hugging Face Hub on the AWS Marketplace: Pay with your AWS Account The Hugging Face Hub has landed o...",
    "pubDate": "Thu, 10 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aws-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/158_aws_marketplace/thumbnail.jpg"
  },
  {
    "title": "Faster Stable Diffusion with Core ML on iPhone, iPad, and Mac",
    "description": "",
    "summary": "Faster Stable Diffusion with Core ML on iPhone, iPad, and Mac WWDC‚Äô23 (Apple Worldwide Developers Co...",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-diffusers-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/149_fast_diffusers_coreml/thumbnail.png"
  },
  {
    "title": "Fine-tuning MMS Adapter Models for Multi-Lingual ASR",
    "description": "",
    "summary": "Fine-tuning MMS Adapter Models for Multi-Lingual ASR New (06/2023): This blog post is strongly inspi...",
    "pubDate": "Mon, 19 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mms_adapters",
    "thumbnail": "https://huggingface.co/blog/assets/151_mms/mms_map.png"
  },
  {
    "title": "Making AI-generated code more accurate in any language",
    "description": "A new technique automatically guides an LLM toward outputs that adhere to the rules of whatever programming language or other format is being used.",
    "summary": "A new technique automatically guides an LLM toward outputs that adhere to the rules of whatever programming language or other format is being used.",
    "pubDate": "Fri, 18 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/making-ai-generated-code-more-accurate-0418",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Probalistic-Control-compressed.gif"
  },
  {
    "title": "Introducing vision to the fine-tuning API",
    "description": "Developers can now fine-tune GPT-4o with images and text to improve vision capabilities",
    "summary": "Developers can now fine-tune GPT-4o with images and text to improve vision capabilities",
    "pubDate": "Tue, 01 Oct 2024 10:04:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-vision-to-the-fine-tuning-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-Tune Wav2Vec2 for English ASR with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune Wav2Vec2 for English ASR with ü§ó Transformers Wav2Vec2 is a pretrained model for Automatic ...",
    "pubDate": "Fri, 12 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-wav2vec2-english",
    "thumbnail": "https://huggingface.co/blog/assets/15_fine_tune_wav2vec2/wav2vec2.png"
  },
  {
    "title": "Building an AI WebTV",
    "description": "",
    "summary": "Building an AI WebTV The AI WebTV is an experimental demo to showcase the latest advancements in aut...",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-webtv",
    "thumbnail": "https://huggingface.co/blog/assets/156_ai_webtv/thumbnail.gif"
  },
  {
    "title": "LaunchDarkly's approach to AI-powered product management",
    "description": "A conversation with Claire Vo, Chief Product Officer of LaunchDarkly, about the changing role of product managers, her anti-to-do list, and building AI-native teams.",
    "summary": "A conversation with Claire Vo, Chief Product Officer of LaunchDarkly, about the changing role of product managers, her anti-to-do list, and building AI-native teams.",
    "pubDate": "Tue, 04 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/launchdarkly-claire-vo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions",
    "description": "Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model's original instructions with their own malicious prompts.",
    "summary": "Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model's original instructions with their own malicious prompts.",
    "pubDate": "Fri, 19 Apr 2024 19:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-instruction-hierarchy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks",
    "description": "arXiv:2502.06106v2 Announce Type: replace-cross Abstract: The study of mechanistic interpretability aims to reverse-engineer a model to explain its behaviors. While recent studies have focused on the static mechanism of a certain behavior, the learning dynamics inside a model remain to be explored. In this work, we develop an interpretable fine-tuning method for analyzing the mechanism behind learning. We first introduce the concept of node-level intrinsic dimensionality to describe the learning process of a model in a computational graph. Based on our theory, we propose circuit-tuning, a two-stage algorithm that iteratively builds the minimal subgraph for a specific task and updates the key parameters in a heuristic way. Experimental results confirm the existence of the intrinsic dimensionality at the node level and demonstrate the effectiveness of our method for transparent and interpretable fine-tuning. We visualize and analyze the circuits before, during, and after fine-tuning, providing new insights into the self-organization mechanism of a neural network in the learning process.",
    "summary": "arXiv:2502.06106v2 Announce Type: replace-cross Abstract: The study of mechanistic interpretability aims to reverse-engineer a model to explain its behaviors. While recent studies have focused on the static mechanism of a certain behavior, the learning dynamics inside a model remain to be explored. In this work, we develop an interpretable fine-tuning method for analyzing the mechanism behind learning. We first introduce the concept of node-level intrinsic dimensionality to describe the learning process of a model in a computational graph. Based on our theory, we propose circuit-tuning, a two-stage algorithm that iteratively builds the minimal subgraph for a specific task and updates the key parameters in a heuristic way. Experimental results confirm the existence of the intrinsic dimensionality at the node level and demonstrate the effectiveness of our method for transparent and interpretable fine-tuning. We visualize and analyze the circuits before, during, and after fine-tuning, providing new insights into the self-organization mechanism of a neural network in the learning process.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.06106",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Universal Assisted Generation: Faster Decoding with Any Assistant Model",
    "description": "",
    "summary": "Universal Assisted Generation: Faster Decoding with Any Assistant Model TL;DR: Many LLMs such as gem...",
    "pubDate": "Tue, 29 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/universal_assisted_generation",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Faulty reward functions in the wild",
    "description": "Reinforcement learning algorithms can break in surprising, counterintuitive ways. In this post we‚Äôll explore one failure mode, which is where you misspecify your reward function.",
    "summary": "Reinforcement learning algorithms can break in surprising, counterintuitive ways. In this post we‚Äôll explore one failure mode, which is where you misspecify your reward function.",
    "pubDate": "Wed, 21 Dec 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/faulty-reward-functions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How to train a Language Model with Megatron-LM",
    "description": "",
    "summary": "How to train a Language Model with Megatron-LM Training large language models in Pytorch requires mo...",
    "pubDate": "Wed, 07 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/megatron-training",
    "thumbnail": "https://huggingface.co/blog/assets/100_megatron_training/thumbnail.png"
  },
  {
    "title": "Summarizing books with human feedback",
    "description": "Scaling human oversight of AI systems for tasks that are difficult to¬†evaluate.",
    "summary": "Scaling human oversight of AI systems for tasks that are difficult to¬†evaluate.",
    "pubDate": "Thu, 23 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/summarizing-books",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Synthetic Heuristic Evaluation: A Comparison between AI- and Human-Powered Usability Evaluation",
    "description": "arXiv:2507.02306v1 Announce Type: cross Abstract: Usability evaluation is crucial in human-centered design but can be costly, requiring expert time and user compensation. In this work, we developed a method for synthetic heuristic evaluation using multimodal LLMs' ability to analyze images and provide design feedback. Comparing our synthetic evaluations to those by experienced UX practitioners across two apps, we found our evaluation identified 73% and 77% of usability issues, which exceeded the performance of 5 experienced human evaluators (57% and 63%). Compared to human evaluators, the synthetic evaluation's performance maintained consistent performance across tasks and excelled in detecting layout issues, highlighting potential attentional and perceptual strengths of synthetic evaluation. However, synthetic evaluation struggled with recognizing some UI components and design conventions, as well as identifying across screen violations. Additionally, testing synthetic evaluations over time and accounts revealed stable performance. Overall, our work highlights the performance differences between human and LLM-driven evaluations, informing the design of synthetic heuristic evaluations.",
    "summary": "arXiv:2507.02306v1 Announce Type: cross Abstract: Usability evaluation is crucial in human-centered design but can be costly, requiring expert time and user compensation. In this work, we developed a method for synthetic heuristic evaluation using multimodal LLMs' ability to analyze images and provide design feedback. Comparing our synthetic evaluations to those by experienced UX practitioners across two apps, we found our evaluation identified 73% and 77% of usability issues, which exceeded the performance of 5 experienced human evaluators (57% and 63%). Compared to human evaluators, the synthetic evaluation's performance maintained consistent performance across tasks and excelled in detecting layout issues, highlighting potential attentional and perceptual strengths of synthetic evaluation. However, synthetic evaluation struggled with recognizing some UI components and design conventions, as well as identifying across screen violations. Additionally, testing synthetic evaluations over time and accounts revealed stable performance. Overall, our work highlights the performance differences between human and LLM-driven evaluations, informing the design of synthetic heuristic evaluations.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02306",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Order Acquisition Under Competitive Pressure: A Rapidly Adaptive Reinforcement Learning Approach for Ride-Hailing Subsidy Strategies",
    "description": "arXiv:2507.02244v1 Announce Type: cross Abstract: The proliferation of ride-hailing aggregator platforms presents significant growth opportunities for ride-service providers by increasing order volume and gross merchandise value (GMV). On most ride-hailing aggregator platforms, service providers that offer lower fares are ranked higher in listings and, consequently, are more likely to be selected by passengers. This competitive ranking mechanism creates a strong incentive for service providers to adopt coupon strategies that lower prices to secure a greater number of orders, as order volume directly influences their long-term viability and sustainability. Thus, designing an effective coupon strategy that can dynamically adapt to market fluctuations while optimizing order acquisition under budget constraints is a critical research challenge. However, existing studies in this area remain scarce. To bridge this gap, we propose FCA-RL, a novel reinforcement learning-based subsidy strategy framework designed to rapidly adapt to competitors' pricing adjustments. Our approach integrates two key techniques: Fast Competition Adaptation (FCA), which enables swift responses to dynamic price changes, and Reinforced Lagrangian Adjustment (RLA), which ensures adherence to budget constraints while optimizing coupon decisions on new price landscape. Furthermore, we introduce RideGym, the first dedicated simulation environment tailored for ride-hailing aggregators, facilitating comprehensive evaluation and benchmarking of different pricing strategies without compromising real-world operational efficiency. Experimental results demonstrate that our proposed method consistently outperforms baseline approaches across diverse market conditions, highlighting its effectiveness in subsidy optimization for ride-hailing service providers.",
    "summary": "arXiv:2507.02244v1 Announce Type: cross Abstract: The proliferation of ride-hailing aggregator platforms presents significant growth opportunities for ride-service providers by increasing order volume and gross merchandise value (GMV). On most ride-hailing aggregator platforms, service providers that offer lower fares are ranked higher in listings and, consequently, are more likely to be selected by passengers. This competitive ranking mechanism creates a strong incentive for service providers to adopt coupon strategies that lower prices to secure a greater number of orders, as order volume directly influences their long-term viability and sustainability. Thus, designing an effective coupon strategy that can dynamically adapt to market fluctuations while optimizing order acquisition under budget constraints is a critical research challenge. However, existing studies in this area remain scarce. To bridge this gap, we propose FCA-RL, a novel reinforcement learning-based subsidy strategy framework designed to rapidly adapt to competitors' pricing adjustments. Our approach integrates two key techniques: Fast Competition Adaptation (FCA), which enables swift responses to dynamic price changes, and Reinforced Lagrangian Adjustment (RLA), which ensures adherence to budget constraints while optimizing coupon decisions on new price landscape. Furthermore, we introduce RideGym, the first dedicated simulation environment tailored for ride-hailing aggregators, facilitating comprehensive evaluation and benchmarking of different pricing strategies without compromising real-world operational efficiency. Experimental results demonstrate that our proposed method consistently outperforms baseline approaches across diverse market conditions, highlighting its effectiveness in subsidy optimization for ride-hailing service providers.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02244",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent",
    "description": "arXiv:2507.02353v1 Announce Type: new Abstract: Keyword decision in Sponsored Search Advertising is critical to the success of ad campaigns. While LLM-based methods offer automated keyword generation, they face three major limitations: reliance on large-scale query-keyword pair data, lack of online multi-objective performance monitoring and optimization, and weak quality control in keyword selection. These issues hinder the agentic use of LLMs in fully automating keyword decisions by monitoring and reasoning over key performance indicators such as impressions, clicks, conversions, and CTA effectiveness. To overcome these challenges, we propose OMS, a keyword generation framework that is On-the-fly (requires no training data, monitors online performance, and adapts accordingly), Multi-objective (employs agentic reasoning to optimize keywords based on multiple performance metrics), and Self-reflective (agentically evaluates keyword quality). Experiments on benchmarks and real-world ad campaigns show that OMS outperforms existing methods; ablation and human evaluations confirm the effectiveness of each component and the quality of generated keywords.",
    "summary": "arXiv:2507.02353v1 Announce Type: new Abstract: Keyword decision in Sponsored Search Advertising is critical to the success of ad campaigns. While LLM-based methods offer automated keyword generation, they face three major limitations: reliance on large-scale query-keyword pair data, lack of online multi-objective performance monitoring and optimization, and weak quality control in keyword selection. These issues hinder the agentic use of LLMs in fully automating keyword decisions by monitoring and reasoning over key performance indicators such as impressions, clicks, conversions, and CTA effectiveness. To overcome these challenges, we propose OMS, a keyword generation framework that is On-the-fly (requires no training data, monitors online performance, and adapts accordingly), Multi-objective (employs agentic reasoning to optimize keywords based on multiple performance metrics), and Self-reflective (agentically evaluates keyword quality). Experiments on benchmarks and real-world ad campaigns show that OMS outperforms existing methods; ablation and human evaluations confirm the effectiveness of each component and the quality of generated keywords.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02353",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GPT-3 powers the next generation of apps",
    "description": "Over 300 applications are delivering GPT-3‚Äìpowered search, conversation, text completion, and other advanced AI features through our¬†API.",
    "summary": "Over 300 applications are delivering GPT-3‚Äìpowered search, conversation, text completion, and other advanced AI features through our¬†API.",
    "pubDate": "Thu, 25 Mar 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-apps",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Energy-Based Transformers are Scalable Learners and Thinkers",
    "description": "arXiv:2507.02092v1 Announce Type: cross Abstract: Inference-time computation techniques, analogous to human System 2 Thinking, have recently become popular for improving model performances. However, most existing approaches suffer from several limitations: they are modality-specific (e.g., working only in text), problem-specific (e.g., verifiable domains like math and coding), or require additional supervision/training on top of unsupervised pretraining (e.g., verifiers or verifiable rewards). In this paper, we ask the question 'Is it possible to generalize these System 2 Thinking approaches, and develop models that learn to think solely from unsupervised learning?' Interestingly, we find the answer is yes, by learning to explicitly verify the compatibility between inputs and candidate-predictions, and then re-framing prediction problems as optimization with respect to this verifier. Specifically, we train Energy-Based Transformers (EBTs) -- a new class of Energy-Based Models (EBMs) -- to assign an energy value to every input and candidate-prediction pair, enabling predictions through gradient descent-based energy minimization until convergence. Across both discrete (text) and continuous (visual) modalities, we find EBTs scale faster than the dominant Transformer++ approach during training, achieving an up to 35% higher scaling rate with respect to data, batch size, parameters, FLOPs, and depth. During inference, EBTs improve performance with System 2 Thinking by 29% more than the Transformer++ on language tasks, and EBTs outperform Diffusion Transformers on image denoising while using fewer forward passes. Further, we find that EBTs achieve better results than existing models on most downstream tasks given the same or worse pretraining performance, suggesting that EBTs generalize better than existing approaches. Consequently, EBTs are a promising new paradigm for scaling both the learning and thinking capabilities of models.",
    "summary": "arXiv:2507.02092v1 Announce Type: cross Abstract: Inference-time computation techniques, analogous to human System 2 Thinking, have recently become popular for improving model performances. However, most existing approaches suffer from several limitations: they are modality-specific (e.g., working only in text), problem-specific (e.g., verifiable domains like math and coding), or require additional supervision/training on top of unsupervised pretraining (e.g., verifiers or verifiable rewards). In this paper, we ask the question 'Is it possible to generalize these System 2 Thinking approaches, and develop models that learn to think solely from unsupervised learning?' Interestingly, we find the answer is yes, by learning to explicitly verify the compatibility between inputs and candidate-predictions, and then re-framing prediction problems as optimization with respect to this verifier. Specifically, we train Energy-Based Transformers (EBTs) -- a new class of Energy-Based Models (EBMs) -- to assign an energy value to every input and candidate-prediction pair, enabling predictions through gradient descent-based energy minimization until convergence. Across both discrete (text) and continuous (visual) modalities, we find EBTs scale faster than the dominant Transformer++ approach during training, achieving an up to 35% higher scaling rate with respect to data, batch size, parameters, FLOPs, and depth. During inference, EBTs improve performance with System 2 Thinking by 29% more than the Transformer++ on language tasks, and EBTs outperform Diffusion Transformers on image denoising while using fewer forward passes. Further, we find that EBTs achieve better results than existing models on most downstream tasks given the same or worse pretraining performance, suggesting that EBTs generalize better than existing approaches. Consequently, EBTs are a promising new paradigm for scaling both the learning and thinking capabilities of models.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02092",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerated Inference with Optimum and Transformers Pipelines",
    "description": "",
    "summary": "Accelerated Inference with Optimum and Transformers Pipelines Inference has landed in Optimum with s...",
    "pubDate": "Tue, 10 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-inference",
    "thumbnail": "https://huggingface.co/blog/assets/66_optimum_inference/thumbnail.png"
  },
  {
    "title": "1 Billion Classifications",
    "description": "",
    "summary": "1 Billion Classifications You‚Äôve optimized your model. Your pipeline is running smoothly. But now, y...",
    "pubDate": "Thu, 13 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/billion-classifications",
    "thumbnail": "https://huggingface.co/blog/assets/billion-classifications/billion-classifications-thumbnail.png"
  },
  {
    "title": "Few-shot learning in practice: GPT-NEO and the ü§ó Accelerated Inference API",
    "description": "",
    "summary": "Few-shot learning in practice: GPT-Neo and the ü§ó Accelerated Inference API In many Machine Learning ...",
    "pubDate": "Thu, 03 Jun 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "AC-Refiner: Efficient Arithmetic Circuit Optimization Using Conditional Diffusion Models",
    "description": "arXiv:2507.02598v1 Announce Type: cross Abstract: Arithmetic circuits, such as adders and multipliers, are fundamental components of digital systems, directly impacting the performance, power efficiency, and area footprint. However, optimizing these circuits remains challenging due to the vast design space and complex physical constraints. While recent deep learning-based approaches have shown promise, they struggle to consistently explore high-potential design variants, limiting their optimization efficiency. To address this challenge, we propose AC-Refiner, a novel arithmetic circuit optimization framework leveraging conditional diffusion models. Our key insight is to reframe arithmetic circuit synthesis as a conditional image generation task. By carefully conditioning the denoising diffusion process on target quality-of-results (QoRs), AC-Refiner consistently produces high-quality circuit designs. Furthermore, the explored designs are used to fine-tune the diffusion model, which focuses the exploration near the Pareto frontier. Experimental results demonstrate that AC-Refiner generates designs with superior Pareto optimality, outperforming state-of-the-art baselines. The performance gain is further validated by integrating AC-Refiner into practical applications.",
    "summary": "arXiv:2507.02598v1 Announce Type: cross Abstract: Arithmetic circuits, such as adders and multipliers, are fundamental components of digital systems, directly impacting the performance, power efficiency, and area footprint. However, optimizing these circuits remains challenging due to the vast design space and complex physical constraints. While recent deep learning-based approaches have shown promise, they struggle to consistently explore high-potential design variants, limiting their optimization efficiency. To address this challenge, we propose AC-Refiner, a novel arithmetic circuit optimization framework leveraging conditional diffusion models. Our key insight is to reframe arithmetic circuit synthesis as a conditional image generation task. By carefully conditioning the denoising diffusion process on target quality-of-results (QoRs), AC-Refiner consistently produces high-quality circuit designs. Furthermore, the explored designs are used to fine-tune the diffusion model, which focuses the exploration near the Pareto frontier. Experimental results demonstrate that AC-Refiner generates designs with superior Pareto optimality, outperforming state-of-the-art baselines. The performance gain is further validated by integrating AC-Refiner into practical applications.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02598",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemini 2.0 is now available to everyone",
    "description": "We‚Äôre announcing new updates to Gemini 2.0 Flash, plus introducing Gemini 2.0 Flash-Lite and Gemini 2.0 Pro Experimental.",
    "summary": "We‚Äôre announcing new updates to Gemini 2.0 Flash, plus introducing Gemini 2.0 Flash-Lite and Gemini 2.0 Pro Experimental.",
    "pubDate": "Wed, 05 Feb 2025 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-2-0-is-now-available-to-everyone/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini_28.01.25_keyword_social.width-1300.png"
  },
  {
    "title": "A Content and Product Partnership with Vox Media",
    "description": "In a multi-faceted agreement, Vox Media‚Äôs content will enhance the output of OpenAI‚Äôs ChatGPT, and the company will build on OpenAI‚Äôs technology to develop products to better serve its audiences and advertisers.",
    "summary": "In a multi-faceted agreement, Vox Media‚Äôs content will enhance the output of OpenAI‚Äôs ChatGPT, and the company will build on OpenAI‚Äôs technology to develop products to better serve its audiences and advertisers.",
    "pubDate": "Wed, 29 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-content-and-product-partnership-with-vox-media",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building a Playlist Generator with Sentence Transformers",
    "description": "",
    "summary": "Building a Playlist Generator with Sentence Transformers A short while ago I published a playlist ge...",
    "pubDate": "Wed, 13 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/playlist-generator",
    "thumbnail": "https://huggingface.co/blog/assets/87_playlist_generator/thumbnail.png"
  },
  {
    "title": "Announcing Google DeepMind",
    "description": "DeepMind and the Brain team from Google Research will join forces to accelerate progress towards a world in which AI helps solve the biggest challenges facing humanity.",
    "summary": "DeepMind and the Brain team from Google Research will join forces to accelerate progress towards a world in which AI helps solve the biggest challenges facing humanity.",
    "pubDate": "Thu, 20 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/announcing-google-deepmind/",
    "thumbnail": "https://lh3.googleusercontent.com/MNdJdEO1VpepmU25h9OTpnMr9hxe6NScc1ZWlerWf5WtOYMnHETsPEWKqvG36zQv5CGflTOHAKG_JbADpmLrh8Mrpa91B95U6bs0isMSbTUerT-qT38=w1200-h630-n-nu"
  },
  {
    "title": "Introducing Skops",
    "description": "",
    "summary": "Introducing Skops Introducing Skops At Hugging Face, we are working on tackling various problems in ...",
    "pubDate": "Fri, 12 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/skops",
    "thumbnail": "https://huggingface.co/blog/assets/94_skops/introducing_skops.png"
  },
  {
    "title": "Announcing the Open Source AI Game Jam üéÆ",
    "description": "",
    "summary": "Announcing the Open Source AI Game Jam üéÆ Unleash Your Creativity with AI Tools and make a game in a ...",
    "pubDate": "Thu, 01 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/game-jam",
    "thumbnail": "https://huggingface.co/blog/assets/145_gamejam/thumbnail.png"
  },
  {
    "title": "New in ChatGPT for Business: March 2025",
    "description": "Join us as we share our latest releases and how ChatGPT is becoming more interactive, customized to the way your teams work, and agentic.",
    "summary": "Join us as we share our latest releases and how ChatGPT is becoming more interactive, customized to the way your teams work, and agentic.",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/new-in-chatgpt-for-work-march-updates-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generating Stories: AI for Game Development #5",
    "description": "",
    "summary": "Generating Stories: AI for Game Development #5 Welcome to AI for Game Development! In this series, w...",
    "pubDate": "Tue, 07 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-5",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail5.png"
  },
  {
    "title": "Tracing the Interactions of Modular CMA-ES Configurations Across Problem Landscapes",
    "description": "arXiv:2507.02331v1 Announce Type: cross Abstract: This paper leverages the recently introduced concept of algorithm footprints to investigate the interplay between algorithm configurations and problem characteristics. Performance footprints are calculated for six modular variants of the CMA-ES algorithm (modCMA), evaluated on 24 benchmark problems from the BBOB suite, across two-dimensional settings: 5-dimensional and 30-dimensional. These footprints provide insights into why different configurations of the same algorithm exhibit varying performance and identify the problem features influencing these outcomes. Our analysis uncovers shared behavioral patterns across configurations due to common interactions with problem properties, as well as distinct behaviors on the same problem driven by differing problem features. The results demonstrate the effectiveness of algorithm footprints in enhancing interpretability and guiding configuration choices.",
    "summary": "arXiv:2507.02331v1 Announce Type: cross Abstract: This paper leverages the recently introduced concept of algorithm footprints to investigate the interplay between algorithm configurations and problem characteristics. Performance footprints are calculated for six modular variants of the CMA-ES algorithm (modCMA), evaluated on 24 benchmark problems from the BBOB suite, across two-dimensional settings: 5-dimensional and 30-dimensional. These footprints provide insights into why different configurations of the same algorithm exhibit varying performance and identify the problem features influencing these outcomes. Our analysis uncovers shared behavioral patterns across configurations due to common interactions with problem properties, as well as distinct behaviors on the same problem driven by differing problem features. The results demonstrate the effectiveness of algorithm footprints in enhancing interpretability and guiding configuration choices.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02331",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Argilla 2.4: Easily Build Fine-Tuning and Evaluation datasets on the Hub ‚Äî No Code Required",
    "description": "",
    "summary": "Argilla 2.4: Easily Build Fine-Tuning and Evaluation Datasets on the Hub ‚Äî No Code Required We are i...",
    "pubDate": "Mon, 04 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/argilla-ui-hub",
    "thumbnail": "https://huggingface.co/blog/assets/argilla-ui-hub/thumbnail.png"
  },
  {
    "title": "Envisioning a future where health care tech leaves some behind",
    "description": "The winning essay of the Envisioning the Future of Computing Prize puts health care disparities at the forefront.",
    "summary": "The winning essay of the Envisioning the Future of Computing Prize puts health care disparities at the forefront.",
    "pubDate": "Mon, 09 Jun 2025 16:10:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/envisioning-future-where-health-care-tech-leaves-some-behind-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/Annaliese%20statue%20crop_v2.jpg"
  },
  {
    "title": "OpenAI en France",
    "description": "Our first office in continental Europe",
    "summary": "Our first office in continental Europe",
    "pubDate": "Fri, 15 Nov 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-en-france",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face on PyTorch / XLA TPUs",
    "description": "",
    "summary": "Hugging Face on PyTorch / XLA TPUs: Faster and cheaper training Training Your Favorite Transformers ...",
    "pubDate": "Tue, 09 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-xla",
    "thumbnail": "https://huggingface.co/blog/assets/13_pytorch_xla/pytorch_xla_thumbnail.png"
  },
  {
    "title": "OpenAI and Reddit Partnership",
    "description": "OpenAI and Reddit Partnership We‚Äôre bringing Reddit‚Äôs unique content to ChatGPT and our products.",
    "summary": "OpenAI and Reddit Partnership We‚Äôre bringing Reddit‚Äôs unique content to ChatGPT and our products.",
    "pubDate": "Thu, 16 May 2024 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-reddit-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face x LangChain : A new partner package in LangChain",
    "description": "",
    "summary": "Hugging Face x LangChain : A new partner package in LangChain We are thrilled to announce the launch...",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/langchain",
    "thumbnail": "https://huggingface.co/blog/assets/langchain_huggingface/thumbnail.png"
  },
  {
    "title": "Image GPT",
    "description": "We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image¬†completions¬†and¬†samples. By establishing a correlation between sample quality and image classification accuracy, we show that our best generative model also contains features competitive with top convolutional nets in the unsupervised¬†setting.",
    "summary": "We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image¬†completions¬†and¬†samples. By establishing a correlation between sample quality and image classification accuracy, we show that our best generative model also contains features competitive with top convolutional nets in the unsupervised¬†setting.",
    "pubDate": "Wed, 17 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/image-gpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our response to the UK‚Äôs copyright consultation",
    "description": "Recommendations for pro-innovation policies that can help make the UK the AI capital of Europe.",
    "summary": "Recommendations for pro-innovation policies that can help make the UK the AI capital of Europe.",
    "pubDate": "Wed, 02 Apr 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-uk-copyright-consultation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How to Install and Use the Hugging Face Unity API",
    "description": "",
    "summary": "How to Install and Use the Hugging Face Unity API The Hugging Face Unity API is an easy-to-use integ...",
    "pubDate": "Mon, 01 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-api",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-api-thumbnail.png"
  },
  {
    "title": "Robust adversarial inputs",
    "description": "We‚Äôve created images that reliably fool neural network classifiers when viewed from varied scales and perspectives. This challenges a claim from last week that self-driving cars would be hard to trick maliciously since they capture images from multiple scales, angles, perspectives, and the like.",
    "summary": "We‚Äôve created images that reliably fool neural network classifiers when viewed from varied scales and perspectives. This challenges a claim from last week that self-driving cars would be hard to trick maliciously since they capture images from multiple scales, angles, perspectives, and the like.",
    "pubDate": "Mon, 17 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/robust-adversarial-inputs",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Agents Are Here. What Now?",
    "description": "",
    "summary": "AI Agents Are Here. What Now? Introduction The sudden, rapid advancement of LLM capabilities ‚Äì such ...",
    "pubDate": "Mon, 13 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-7",
    "thumbnail": "https://huggingface.co/blog/assets/190_ethics-soc-7/thumbnail.png"
  },
  {
    "title": "BrowseComp: a benchmark for browsing agents",
    "description": "BrowseComp: a benchmark for browsing agents.",
    "summary": "BrowseComp: a benchmark for browsing agents.",
    "pubDate": "Thu, 10 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/browsecomp",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Getting Started With Embeddings",
    "description": "",
    "summary": "Getting Started With Embeddings Check out this tutorial with the Notebook Companion: Understanding e...",
    "pubDate": "Thu, 23 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/getting-started-with-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/80_getting_started_with_embeddings/thumbnail.png"
  },
  {
    "title": "Exploring institutions for global AI governance",
    "description": "New white paper investigates models and functions of international institutions that could help manage opportunities and mitigate risks of advanced AI.",
    "summary": "New white paper investigates models and functions of international institutions that could help manage opportunities and mitigate risks of advanced AI.",
    "pubDate": "Tue, 11 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/exploring-institutions-for-global-ai-governance/",
    "thumbnail": "https://lh3.googleusercontent.com/Y9dCJWt3ky1gjizSCHb17S3iHZ_Q2v6hoC8SaBgq9f7e5yW15pzg7BGNoCIaklP6f34uioxwHY0gbzehAMe5HhXBvBBKBKNIcOo7ugjFeLENTWMqNQ=w1200-h630-n-nu"
  },
  {
    "title": "Transfer from simulation to real world through learning deep inverse dynamics model",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 11 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/transfer-from-simulation-to-real-world-through-learning-deep-inverse-dynamics-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Empowering a global org with ChatGPT",
    "description": "Empowering a global org with ChatGPT",
    "summary": "Empowering a global org with ChatGPT",
    "pubDate": "Thu, 21 Nov 2024 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bbva",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ilya Sutskever to leave OpenAI, Jakub Pachocki announced as Chief Scientist",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 14 May 2024 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jakub-pachocki-announced-as-chief-scientist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Iterated belief revision: from postulates to abilities",
    "description": "arXiv:2507.02319v1 Announce Type: new Abstract: The belief revision field is opulent in new proposals and indigent in analyses of existing approaches. Much work hinge on postulates, employed as syntactic characterizations: some revision mechanism is equivalent to some properties. Postulates constraint specific revision instances: certain revisions update certain beliefs in a certain way. As an example, if the revision is consistent with the current beliefs, it is incorporated with no other change. A postulate like this tells what revisions must do and neglect what they can do. Can they reach a certain state of beliefs? Can they reach all possible states of beliefs? Can they reach all possible states of beliefs from no previous belief? Can they reach a dogmatic state of beliefs, where everything not believed is impossible? Can they make two conditions equally believed? An application where every possible state of beliefs is sensible requires each state of beliefs to be reachable. An application where conditions may be equally believed requires such a belief state to be reachable. An application where beliefs may become dogmatic requires a way to make them dogmatic. Such doxastic states need to be reached in a way or another. Not in specific way, as dictated by a typical belief revision postulate. This is an ability, not a constraint: the ability of being plastic, equating, dogmatic. Amnesic, correcting, believer, damascan, learnable are other abilities. Each revision mechanism owns some of these abilities and lacks the others: lexicographic, natural, restrained, very radical, full meet, radical, severe, moderate severe, deep severe, plain severe and deep severe revisions, each of these revisions is proved to possess certain abilities.",
    "summary": "arXiv:2507.02319v1 Announce Type: new Abstract: The belief revision field is opulent in new proposals and indigent in analyses of existing approaches. Much work hinge on postulates, employed as syntactic characterizations: some revision mechanism is equivalent to some properties. Postulates constraint specific revision instances: certain revisions update certain beliefs in a certain way. As an example, if the revision is consistent with the current beliefs, it is incorporated with no other change. A postulate like this tells what revisions must do and neglect what they can do. Can they reach a certain state of beliefs? Can they reach all possible states of beliefs? Can they reach all possible states of beliefs from no previous belief? Can they reach a dogmatic state of beliefs, where everything not believed is impossible? Can they make two conditions equally believed? An application where every possible state of beliefs is sensible requires each state of beliefs to be reachable. An application where conditions may be equally believed requires such a belief state to be reachable. An application where beliefs may become dogmatic requires a way to make them dogmatic. Such doxastic states need to be reached in a way or another. Not in specific way, as dictated by a typical belief revision postulate. This is an ability, not a constraint: the ability of being plastic, equating, dogmatic. Amnesic, correcting, believer, damascan, learnable are other abilities. Each revision mechanism owns some of these abilities and lacks the others: lexicographic, natural, restrained, very radical, full meet, radical, severe, moderate severe, deep severe, plain severe and deep severe revisions, each of these revisions is proved to possess certain abilities.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02319",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Spread Your Wings: Falcon 180B is here",
    "description": "",
    "summary": "Spread Your Wings: Falcon 180B is here Introduction Today, we're excited to welcome TII's Falcon 180...",
    "pubDate": "Wed, 06 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon-180b",
    "thumbnail": "https://huggingface.co/blog/assets/162_falcon_180b/thumbnail.jpg"
  },
  {
    "title": "Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC",
    "description": "",
    "summary": "Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC We're e...",
    "pubDate": "Wed, 09 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastrtc-cloudflare",
    "thumbnail": "https://huggingface.co/blog/assets/fastrtc-cloudflare/fastrtc_cloudflare.png"
  },
  {
    "title": "Vall√©e Duhamel & Sora",
    "description": "Filmmaking duo Vall√©e Duhamel explains how Sora helps build new worlds.",
    "summary": "Filmmaking duo Vall√©e Duhamel explains how Sora helps build new worlds.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-vallee-duhamel",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Personal Copilot: Train Your Own Coding Assistant",
    "description": "",
    "summary": "Personal Copilot: Train Your Own Coding Assistant In the ever-evolving landscape of programming and ...",
    "pubDate": "Fri, 27 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/personal-copilot",
    "thumbnail": "https://huggingface.co/blog/assets/170_personal_copilot/thumbnail.png"
  },
  {
    "title": "Hugging Face and Graphcore partner for IPU-optimized Transformers",
    "description": "",
    "summary": "Hugging Face and Graphcore partner for IPU-optimized Transformers Speaking at the 2021 AI Hardware S...",
    "pubDate": "Tue, 14 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore",
    "thumbnail": "https://huggingface.co/blog/assets/26_graphcore-ipu/thumbnail.png"
  },
  {
    "title": "Letting Large Models Debate: The First Multilingual LLM Debate Competition",
    "description": "",
    "summary": "Letting Large Models Debate: The First Multilingual LLM Debate Competition Current static evaluation...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/debate",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Judge Arena: Benchmarking LLMs as Evaluators",
    "description": "",
    "summary": "Judge Arena: Benchmarking LLMs as Evaluators LLM-as-a-Judge has emerged as a popular way to grade na...",
    "pubDate": "Tue, 19 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-atla",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail_atla.png"
  },
  {
    "title": "Horus: A Protocol for Trustless Delegation Under Uncertainty",
    "description": "arXiv:2507.00631v3 Announce Type: replace-cross Abstract: Correctness is an emergent property of systems where exposing error is cheaper than committing it. In dynamic, low-trust environments, autonomous AI agents benefit from delegating work to sub-agents, yet correctness cannot be assured through upfront specification or centralized oversight. We propose a protocol that enforces correctness through collateralized claims in a recursive verification game. Tasks are published as intents, and solvers compete to fulfill them. Selected solvers carry out tasks under risk, with correctness checked post hoc by verifiers. Any challenger can challenge a result by staking against it to trigger the verification process. Incorrect agents are slashed and correct opposition is rewarded, with an escalation path that penalizes erroneous verifiers themselves. When incentives are aligned across solvers, challengers, and verifiers, falsification conditions make correctness the Nash equilibrium.",
    "summary": "arXiv:2507.00631v3 Announce Type: replace-cross Abstract: Correctness is an emergent property of systems where exposing error is cheaper than committing it. In dynamic, low-trust environments, autonomous AI agents benefit from delegating work to sub-agents, yet correctness cannot be assured through upfront specification or centralized oversight. We propose a protocol that enforces correctness through collateralized claims in a recursive verification game. Tasks are published as intents, and solvers compete to fulfill them. Selected solvers carry out tasks under risk, with correctness checked post hoc by verifiers. Any challenger can challenge a result by staking against it to trigger the verification process. Incorrect agents are slashed and correct opposition is rewarded, with an escalation path that penalizes erroneous verifiers themselves. When incentives are aligned across solvers, challengers, and verifiers, falsification conditions make correctness the Nash equilibrium.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.00631",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "S2FGL: Spatial Spectral Federated Graph Learning",
    "description": "arXiv:2507.02409v1 Announce Type: cross Abstract: Federated Graph Learning (FGL) combines the privacy-preserving capabilities of federated learning (FL) with the strong graph modeling capability of Graph Neural Networks (GNNs). Current research addresses subgraph-FL only from the structural perspective, neglecting the propagation of graph signals on spatial and spectral domains of the structure. From a spatial perspective, subgraph-FL introduces edge disconnections between clients, leading to disruptions in label signals and a degradation in the class knowledge of the global GNN. From a spectral perspective, spectral heterogeneity causes inconsistencies in signal frequencies across subgraphs, which makes local GNNs overfit the local signal propagation schemes. As a result, spectral client drifts occur, undermining global generalizability. To tackle the challenges, we propose a global knowledge repository to mitigate label signal disruption and a frequency alignment to address spectral client drifts. The combination of spatial and spectral strategies forms our framework S2FGL. Extensive experiments on multiple datasets demonstrate the superiority of S2FGL. The code is available at https://github.com/Wonder7racer/S2FGL.git.",
    "summary": "arXiv:2507.02409v1 Announce Type: cross Abstract: Federated Graph Learning (FGL) combines the privacy-preserving capabilities of federated learning (FL) with the strong graph modeling capability of Graph Neural Networks (GNNs). Current research addresses subgraph-FL only from the structural perspective, neglecting the propagation of graph signals on spatial and spectral domains of the structure. From a spatial perspective, subgraph-FL introduces edge disconnections between clients, leading to disruptions in label signals and a degradation in the class knowledge of the global GNN. From a spectral perspective, spectral heterogeneity causes inconsistencies in signal frequencies across subgraphs, which makes local GNNs overfit the local signal propagation schemes. As a result, spectral client drifts occur, undermining global generalizability. To tackle the challenges, we propose a global knowledge repository to mitigate label signal disruption and a frequency alignment to address spectral client drifts. The combination of spatial and spectral strategies forms our framework S2FGL. Extensive experiments on multiple datasets demonstrate the superiority of S2FGL. The code is available at https://github.com/Wonder7racer/S2FGL.git.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02409",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Distributed Training: Train BART/T5 for Summarization using ü§ó Transformers and Amazon SageMaker",
    "description": "",
    "summary": "Distributed Training: Train BART/T5 for Summarization using ü§ó Transformers and Amazon SageMaker In c...",
    "pubDate": "Thu, 08 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-distributed-training-seq2seq",
    "thumbnail": "https://huggingface.co/blog/assets/19_sagemaker_distributed_training_seq2seq/thumbnail.png"
  },
  {
    "title": "New GPT-3 capabilities: Edit & insert",
    "description": "We‚Äôve released new versions of GPT-3 and Codex¬†which can edit or insert content into existing text, rather than just completing existing text.",
    "summary": "We‚Äôve released new versions of GPT-3 and Codex¬†which can edit or insert content into existing text, rather than just completing existing text.",
    "pubDate": "Tue, 15 Mar 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-edit-insert",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning sparse neural networks through L‚ÇÄ regularization",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 04 Dec 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-sparse-neural-networks-through-l0-regularization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome Stable-baselines3 to the Hugging Face Hub ü§ó",
    "description": "",
    "summary": "Welcome Stable-baselines3 to the Hugging Face Hub ü§ó At Hugging Face, we are contributing to the ecos...",
    "pubDate": "Fri, 21 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sb3",
    "thumbnail": "https://huggingface.co/blog/assets/47_sb3/thumbnail.png"
  },
  {
    "title": "Advanced audio dialog and generation with Gemini 2.5",
    "description": "Gemini 2.5 has new capabilities in AI-powered audio dialog and generation.",
    "summary": "Gemini 2.5 has new capabilities in AI-powered audio dialog and generation.",
    "pubDate": "Tue, 03 Jun 2025 17:15:47 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advanced-audio-dialog-and-generation-with-gemini-25/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/capability__native-audio_16-9_121.width-1300.jpg"
  },
  {
    "title": "ÁîüÊàêAI„Å®„ÅÆ‰ºöË©±„Åß‚Äú„ÅÇ„Å™„Åü„Å´„Å¥„Å£„Åü„Çä„ÅÆÂïÜÂìÅ‚ÄùÊèêÊ°à„ÄÄ„ÄåYahoo!„Ç∑„Éß„ÉÉ„Éî„É≥„Ç∞„ÄçÊñ∞Ê©üËÉΩ",
    "description": "„ÄåYahoo!„Ç∑„Éß„ÉÉ„Éî„É≥„Ç∞„ÄçiOSÁâà„Åß„ÄÅÁîüÊàêAI„Å®„ÅÆ‰ºöË©±„ÇíÈÄö„Åò„ÄÅ„É¶„Éº„Ç∂„Éº„Å´„Éû„ÉÉ„ÉÅ„Åó„ÅüÂïÜÂìÅ„ÇíÊèêÊ°à„Åô„ÇãÊ©üËÉΩ„ÄÇ",
    "summary": "„ÄåYahoo!„Ç∑„Éß„ÉÉ„Éî„É≥„Ç∞„ÄçiOSÁâà„Åß„ÄÅÁîüÊàêAI„Å®„ÅÆ‰ºöË©±„ÇíÈÄö„Åò„ÄÅ„É¶„Éº„Ç∂„Éº„Å´„Éû„ÉÉ„ÉÅ„Åó„ÅüÂïÜÂìÅ„ÇíÊèêÊ°à„Åô„ÇãÊ©üËÉΩ„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 06:37:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news053.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news053.png"
  },
  {
    "title": "Filling crucial language learning gaps",
    "description": "GPT-4 deepens the conversation on Duolingo.",
    "summary": "GPT-4 deepens the conversation on Duolingo.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/duolingo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2021: Final projects",
    "description": "We‚Äôre proud to announce that the 2021 class of¬†OpenAI Scholars¬†has completed our six-month mentorship program and have produced an open-source research project with stipends and support from¬†OpenAI.",
    "summary": "We‚Äôre proud to announce that the 2021 class of¬†OpenAI Scholars¬†has completed our six-month mentorship program and have produced an open-source research project with stipends and support from¬†OpenAI.",
    "pubDate": "Mon, 10 May 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2021-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New models and developer products announced at DevDay",
    "description": "GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL¬∑E 3 API, and more.",
    "summary": "GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL¬∑E 3 API, and more.",
    "pubDate": "Mon, 06 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-models-and-developer-products-announced-at-devday",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI London",
    "description": "We are excited to announce OpenAI‚Äôs first international expansion with a new office in London, United Kingdom.",
    "summary": "We are excited to announce OpenAI‚Äôs first international expansion with a new office in London, United Kingdom.",
    "pubDate": "Wed, 28 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-london",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fetch Cuts ML Processing Latency by 50% Using Amazon SageMaker & Hugging Face",
    "description": "",
    "summary": "Fetch Cuts ML Processing Latency by 50% Using Amazon SageMaker & Hugging Face This article is a cros...",
    "pubDate": "Fri, 01 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fetch-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/fetch.png"
  },
  {
    "title": "LLM-Powered Prediction of Hyperglycemia and Discovery of Behavioral Treatment Pathways from Wearables and Diet",
    "description": "arXiv:2503.03935v2 Announce Type: replace-cross Abstract: Postprandial hyperglycemia, marked by the blood glucose level exceeding the normal range after consuming a meal, is a critical indicator of progression toward type 2 diabetes in people with prediabetes and in healthy individuals. A key metric for understanding blood glucose dynamics after eating is the postprandial area under the curve (AUC). Predicting postprandial AUC in advance based on a person's lifestyle factors, such as diet and physical activity level, and explaining the factors that affect postprandial blood glucose could allow an individual to adjust their lifestyle accordingly to maintain normal glucose levels. In this study, we developed an explainable machine learning solution, GlucoLens, that takes sensor-driven inputs and uses advanced data processing, large language models, and trainable machine learning models to predict postprandial AUC and hyperglycemia from diet, physical activity, and recent glucose patterns. We used data obtained from wearables in a five-week clinical trial of 10 adults who worked full-time to develop and evaluate the proposed computational model that integrates wearable sensing, multimodal data, and machine learning. Our machine learning model takes multimodal data from wearable activity and glucose monitoring sensors, along with food and work logs, and provides an interpretable prediction of the postprandial glucose pattern. Our GlucoLens system achieves a normalized root mean squared error (NRMSE) of 0.123 in its best configuration. On average, the proposed technology provides a 16% better performance level compared to the comparison models. Additionally, our technique predicts hyperglycemia with an accuracy of 73.3% and an F1 score of 0.716 and recommends different treatment options to help avoid hyperglycemia through diverse counterfactual explanations. Code available: https://github.com/ab9mamun/GlucoLens.",
    "summary": "arXiv:2503.03935v2 Announce Type: replace-cross Abstract: Postprandial hyperglycemia, marked by the blood glucose level exceeding the normal range after consuming a meal, is a critical indicator of progression toward type 2 diabetes in people with prediabetes and in healthy individuals. A key metric for understanding blood glucose dynamics after eating is the postprandial area under the curve (AUC). Predicting postprandial AUC in advance based on a person's lifestyle factors, such as diet and physical activity level, and explaining the factors that affect postprandial blood glucose could allow an individual to adjust their lifestyle accordingly to maintain normal glucose levels. In this study, we developed an explainable machine learning solution, GlucoLens, that takes sensor-driven inputs and uses advanced data processing, large language models, and trainable machine learning models to predict postprandial AUC and hyperglycemia from diet, physical activity, and recent glucose patterns. We used data obtained from wearables in a five-week clinical trial of 10 adults who worked full-time to develop and evaluate the proposed computational model that integrates wearable sensing, multimodal data, and machine learning. Our machine learning model takes multimodal data from wearable activity and glucose monitoring sensors, along with food and work logs, and provides an interpretable prediction of the postprandial glucose pattern. Our GlucoLens system achieves a normalized root mean squared error (NRMSE) of 0.123 in its best configuration. On average, the proposed technology provides a 16% better performance level compared to the comparison models. Additionally, our technique predicts hyperglycemia with an accuracy of 73.3% and an F1 score of 0.716 and recommends different treatment options to help avoid hyperglycemia through diverse counterfactual explanations. Code available: https://github.com/ab9mamun/GlucoLens.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.03935",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Empowering the next generation for an AI-enabled world",
    "description": "Experience AI's course and resources are expanding on a global scale",
    "summary": "Experience AI's course and resources are expanding on a global scale",
    "pubDate": "Wed, 15 Nov 2023 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/empowering-the-next-generation-for-an-ai-enabled-world/",
    "thumbnail": "https://lh3.googleusercontent.com/XJ10IR5bv5MmygxoFC0hrepTZtjq_Bwz69bL7d7jBy06fnEFodAa0tbIWKOwV7gW2Im3JY2GGda-xZKtVQhqcaozz6r_vdHXsgVu0CzyIhIz4VGs=w1200-h630-n-nu"
  },
  {
    "title": "Evolving OpenAI‚Äôs structure",
    "description": "An update from the OpenAI board on transitioning its for-profit entity to a Public Benefit Corporation, reinforcing its mission-driven structure under nonprofit oversight while enabling greater impact and long-term alignment with the public good.",
    "summary": "An update from the OpenAI board on transitioning its for-profit entity to a Public Benefit Corporation, reinforcing its mission-driven structure under nonprofit oversight while enabling greater impact and long-term alignment with the public good.",
    "pubDate": "Mon, 05 May 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolving-our-structure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Residency",
    "description": "As part of our effort to support and develop AI talent, we‚Äôre excited to announce the OpenAI Residency.",
    "summary": "As part of our effort to support and develop AI talent, we‚Äôre excited to announce the OpenAI Residency.",
    "pubDate": "Tue, 30 Nov 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-residency",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deep Learning over the Internet: Training Language Models Collaboratively",
    "description": "",
    "summary": "Deep Learning over the Internet: Training Language Models Collaboratively Modern language models oft...",
    "pubDate": "Thu, 15 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/collaborative-training",
    "thumbnail": "https://huggingface.co/blog/assets/24_sahajBERT/thumbnail.png"
  },
  {
    "title": "Jukebox",
    "description": "We‚Äôre introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. We‚Äôre releasing the model weights and code, along with a tool to explore the generated¬†samples.",
    "summary": "We‚Äôre introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. We‚Äôre releasing the model weights and code, along with a tool to explore the generated¬†samples.",
    "pubDate": "Thu, 30 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jukebox",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Teams Up with Protect AI: Enhancing Model Security for the Community",
    "description": "",
    "summary": "Hugging Face Teams Up with Protect AI: Enhancing Model Security for the Community We are pleased to ...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/protectai",
    "thumbnail": "https://huggingface.co/blog/assets/protectai/thumbnail.png"
  },
  {
    "title": "On the quantitative analysis of decoder-based generative models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 14 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/on-the-quantitative-analysis-of-decoder-based-generative-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Shaping the future of financial services",
    "description": "Morgan Stanley uses AI evals to shape the future of financial services",
    "summary": "Morgan Stanley uses AI evals to shape the future of financial services",
    "pubDate": "Wed, 04 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/morgan-stanley",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the GPT Store",
    "description": "We‚Äôre launching the GPT Store to help you find useful and popular custom versions of ChatGPT.",
    "summary": "We‚Äôre launching the GPT Store to help you find useful and popular custom versions of ChatGPT.",
    "pubDate": "Wed, 10 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-gpt-store",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Have a damaged painting? Restore it in just hours with an AI-generated ‚Äúmask‚Äù",
    "description": "A new method can physically restore original paintings using digitally constructed films, which can be removed if desired.",
    "summary": "A new method can physically restore original paintings using digitally constructed films, which can be removed if desired.",
    "pubDate": "Wed, 11 Jun 2025 11:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/restoring-damaged-paintings-using-ai-generated-mask-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Restoring-Paintings-01-press.jpg"
  },
  {
    "title": "Evaluating large language models trained on code",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 07 Jul 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evaluating-large-language-models-trained-on-code",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome the Falcon 3 Family of Open Models!",
    "description": "",
    "summary": "Welcome to the Falcon 3 Family of Open Models! We introduce Falcon3, a family of decoder-only large ...",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon3",
    "thumbnail": "https://huggingface.co/blog/assets/falcon3/thumbnail.png"
  },
  {
    "title": "The latest AI news we announced in June",
    "description": "an mp4 carousel of images shoe people and dark blue icons including a magnifying glass",
    "summary": "an mp4 carousel of images shoe people and dark blue icons including a magnifying glass",
    "pubDate": "Wed, 02 Jul 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/google-ai-updates-june-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/June_AI_Recap_social-share.width-1300.png"
  },
  {
    "title": "Beyond Scale: The Diversity Coefficient as a Data Quality Metric for Variability in Natural Language Data",
    "description": "arXiv:2306.13840v4 Announce Type: replace-cross Abstract: Current trends in pre-training Large Language Models (LLMs) primarily focus on the scaling of model and dataset size. While the quality of pre-training data is considered an important factor for training powerful LLMs, it remains a nebulous concept that has not been rigorously characterized. To this end, we propose a formalization of one key aspect of data quality -- measuring the variability of natural language data -- specifically via a measure we call the diversity coefficient. Our empirical analysis shows that the proposed diversity coefficient aligns with the intuitive properties of diversity and variability, e.g., it increases as the number of latent concepts increases. Then, we measure the diversity coefficient of publicly available pre-training datasets and demonstrate that their formal diversity is high compared to theoretical lower and upper bounds. Finally, we conduct a comprehensive set of controlled interventional experiments with GPT-2 and LLaMAv2 that demonstrate the diversity coefficient of pre-training data characterizes useful aspects of downstream model evaluation performance -- totaling 44 models of various sizes (51M to 7B parameters). We conclude that our formal notion of diversity is an important aspect of data quality that captures variability and causally leads to improved evaluation performance.",
    "summary": "arXiv:2306.13840v4 Announce Type: replace-cross Abstract: Current trends in pre-training Large Language Models (LLMs) primarily focus on the scaling of model and dataset size. While the quality of pre-training data is considered an important factor for training powerful LLMs, it remains a nebulous concept that has not been rigorously characterized. To this end, we propose a formalization of one key aspect of data quality -- measuring the variability of natural language data -- specifically via a measure we call the diversity coefficient. Our empirical analysis shows that the proposed diversity coefficient aligns with the intuitive properties of diversity and variability, e.g., it increases as the number of latent concepts increases. Then, we measure the diversity coefficient of publicly available pre-training datasets and demonstrate that their formal diversity is high compared to theoretical lower and upper bounds. Finally, we conduct a comprehensive set of controlled interventional experiments with GPT-2 and LLaMAv2 that demonstrate the diversity coefficient of pre-training data characterizes useful aspects of downstream model evaluation performance -- totaling 44 models of various sizes (51M to 7B parameters). We conclude that our formal notion of diversity is an important aspect of data quality that captures variability and causally leads to improved evaluation performance.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2306.13840",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "We used Veo to animate archive photography from the Harley-Davidson Museum",
    "description": "Two phones over a blurry background showing archival photos from the Harley-Davidson Museum. Each phone screen shows moving black and white archival images from the museum.",
    "summary": "Two phones over a blurry background showing archival photos from the Harley-Davidson Museum. Each phone screen shows moving black and white archival images from the museum.",
    "pubDate": "Tue, 01 Jul 2025 13:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/arts-culture/moving-archives/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/MovingArchives_SS.width-1300.png"
  },
  {
    "title": "MuZero, AlphaZero, and AlphaDev: Optimizing computer systems",
    "description": "How MuZero, AlphaZero, and AlphaDev are optimizing the computing ecosystem that powers our world of devices.",
    "summary": "How MuZero, AlphaZero, and AlphaDev are optimizing the computing ecosystem that powers our world of devices.",
    "pubDate": "Mon, 12 Jun 2023 14:41:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/muzero-alphazero-and-alphadev-optimizing-computer-systems/",
    "thumbnail": "https://lh3.googleusercontent.com/6tSxHgEgSLR8FSELf3If1M1QBbXTtpsfH6w2ocuruWGnFDTdogbyNA8sHOyKpFYCja4hT7fGCVwl2xyI9biVB1bFNcnTxvYptuVdcT0XHMjn-TzG=w1200-h630-n-nu"
  },
  {
    "title": "Weight normalization: A simple reparameterization to accelerate training of deep neural networks",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 25 Feb 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/weight-normalization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PatchTSMixer in HuggingFace",
    "description": "",
    "summary": "PatchTSMixer in HuggingFace - Getting Started PatchTSMixer is a lightweight time-series modeling app...",
    "pubDate": "Fri, 19 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/patchtsmixer",
    "thumbnail": "https://huggingface.co/blog/assets/patchtsmixer/thumbnail.jpeg"
  },
  {
    "title": "Introducing SimpleQA",
    "description": "A factuality benchmark called SimpleQA that measures the ability for language models to answer short, fact-seeking questions.",
    "summary": "A factuality benchmark called SimpleQA that measures the ability for language models to answer short, fact-seeking questions.",
    "pubDate": "Wed, 30 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-simpleqa",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy Hugging Face models easily with Amazon SageMaker",
    "description": "",
    "summary": "Deploy Hugging Face models easily with Amazon SageMaker üèé Earlier this year we announced a strategic...",
    "pubDate": "Thu, 08 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-hugging-face-models-easily-with-amazon-sagemaker",
    "thumbnail": "https://huggingface.co/blog/assets/17_the_partnership_amazon_sagemaker_and_hugging_face/thumbnail.png"
  },
  {
    "title": "Google DeepMind at ICLR 2024",
    "description": "Developing next-gen AI agents, exploring new modalities, and pioneering foundational learning",
    "summary": "Developing next-gen AI agents, exploring new modalities, and pioneering foundational learning",
    "pubDate": "Fri, 03 May 2024 13:39:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-iclr-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/8PzKGooudBtamqh9keU_q7O0ex5XxGgIIK3BKQNAVEV6WDzIkfadsbNPhU0QCg5PurFGnAOSOClrM9dQHIGvOEe9MPluA5uhyFcun3FvNMBfPI63mWk=w1200-h630-n-nu"
  },
  {
    "title": "Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy",
    "description": "arXiv:2507.02493v1 Announce Type: cross Abstract: Automated polyp counting in colonoscopy is a crucial step toward automated procedure reporting and quality control, aiming to enhance the cost-effectiveness of colonoscopy screening. Counting polyps in a procedure involves detecting and tracking polyps, and then clustering tracklets that belong to the same polyp entity. Existing methods for polyp counting rely on self-supervised learning and primarily leverage visual appearance, neglecting temporal relationships in both tracklet feature learning and clustering stages. In this work, we introduce a paradigm shift by proposing a supervised contrastive loss that incorporates temporally-aware soft targets. Our approach captures intra-polyp variability while preserving inter-polyp discriminability, leading to more robust clustering. Additionally, we improve tracklet clustering by integrating a temporal adjacency constraint, reducing false positive re-associations between visually similar but temporally distant tracklets. We train and validate our method on publicly available datasets and evaluate its performance with a leave-one-out cross-validation strategy. Results demonstrate a 2.2x reduction in fragmentation rate compared to prior approaches. Our results highlight the importance of temporal awareness in polyp counting, establishing a new state-of-the-art. Code is available at https://github.com/lparolari/temporally-aware-polyp-counting.",
    "summary": "arXiv:2507.02493v1 Announce Type: cross Abstract: Automated polyp counting in colonoscopy is a crucial step toward automated procedure reporting and quality control, aiming to enhance the cost-effectiveness of colonoscopy screening. Counting polyps in a procedure involves detecting and tracking polyps, and then clustering tracklets that belong to the same polyp entity. Existing methods for polyp counting rely on self-supervised learning and primarily leverage visual appearance, neglecting temporal relationships in both tracklet feature learning and clustering stages. In this work, we introduce a paradigm shift by proposing a supervised contrastive loss that incorporates temporally-aware soft targets. Our approach captures intra-polyp variability while preserving inter-polyp discriminability, leading to more robust clustering. Additionally, we improve tracklet clustering by integrating a temporal adjacency constraint, reducing false positive re-associations between visually similar but temporally distant tracklets. We train and validate our method on publicly available datasets and evaluate its performance with a leave-one-out cross-validation strategy. Results demonstrate a 2.2x reduction in fragmentation rate compared to prior approaches. Our results highlight the importance of temporal awareness in polyp counting, establishing a new state-of-the-art. Code is available at https://github.com/lparolari/temporally-aware-polyp-counting.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02493",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Consistency Models",
    "description": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation.",
    "summary": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New and improved content moderation tooling",
    "description": "We are introducing a new and improved content moderation tool. The¬†Moderation endpoint¬†improves upon our previous content filter, and is available for free today to OpenAI API¬†developers.",
    "summary": "We are introducing a new and improved content moderation tool. The¬†Moderation endpoint¬†improves upon our previous content filter, and is available for free today to OpenAI API¬†developers.",
    "pubDate": "Wed, 10 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-and-improved-content-moderation-tooling",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Running IF with üß® diffusers on a Free Tier Google Colab",
    "description": "",
    "summary": "Running IF with üß® diffusers on a Free Tier Google Colab TL;DR: We show how to run one of the most po...",
    "pubDate": "Wed, 26 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/if",
    "thumbnail": "https://huggingface.co/blog/assets/if/thumbnail.jpg"
  },
  {
    "title": "Introducing HUGS - Scale your AI with Open Models",
    "description": "",
    "summary": "Introducing HUGS - Scale your AI with Open Models Today, we are thrilled to announce the launch of H...",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugs",
    "thumbnail": "https://huggingface.co/blog/assets/hugs/thumbnail.jpg"
  },
  {
    "title": "VeFIA: An Efficient Inference Auditing Framework for Vertical Federated Collaborative Software",
    "description": "arXiv:2507.02376v1 Announce Type: cross Abstract: Vertical Federated Learning (VFL) is a distributed AI software deployment mechanism for cross-silo collaboration without accessing participants' data. However, existing VFL work lacks a mechanism to audit the execution correctness of the inference software of the data party. To address this problem, we design a Vertical Federated Inference Auditing (VeFIA) framework. VeFIA helps the task party to audit whether the data party's inference software is executed as expected during large-scale inference without leaking the data privacy of the data party or introducing additional latency to the inference system. The core of VeFIA is that the task party can use the inference results from a framework with Trusted Execution Environments (TEE) and the coordinator to validate the correctness of the data party's computation results. VeFIA guarantees that, as long as the abnormal inference exceeds 5.4%, the task party can detect execution anomalies in the inference software with a probability of 99.99%, without incurring any additional online inference latency. VeFIA's random sampling validation achieves 100% positive predictive value, negative predictive value, and true positive rate in detecting abnormal inference. To the best of our knowledge, this is the first paper to discuss the correctness of inference software execution in VFL.",
    "summary": "arXiv:2507.02376v1 Announce Type: cross Abstract: Vertical Federated Learning (VFL) is a distributed AI software deployment mechanism for cross-silo collaboration without accessing participants' data. However, existing VFL work lacks a mechanism to audit the execution correctness of the inference software of the data party. To address this problem, we design a Vertical Federated Inference Auditing (VeFIA) framework. VeFIA helps the task party to audit whether the data party's inference software is executed as expected during large-scale inference without leaking the data privacy of the data party or introducing additional latency to the inference system. The core of VeFIA is that the task party can use the inference results from a framework with Trusted Execution Environments (TEE) and the coordinator to validate the correctness of the data party's computation results. VeFIA guarantees that, as long as the abnormal inference exceeds 5.4%, the task party can detect execution anomalies in the inference software with a probability of 99.99%, without incurring any additional online inference latency. VeFIA's random sampling validation achieves 100% positive predictive value, negative predictive value, and true positive rate in detecting abnormal inference. To the best of our knowledge, this is the first paper to discuss the correctness of inference software execution in VFL.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02376",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Researchers present bold ideas for AI at MIT Generative AI Impact Consortium kickoff event",
    "description": "Presentations targeted high-impact intersections of AI and other areas, such as health care, business, and education.",
    "summary": "Presentations targeted high-impact intersections of AI and other areas, such as health care, business, and education.",
    "pubDate": "Fri, 20 Jun 2025 16:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/researchers-present-bold-ideas-ai-mit-generative-ai-impact-consortium-event-0620",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-Anantha.jpg"
  },
  {
    "title": "Quantifying the Importance of Data Alignment in Downstream Model Performance",
    "description": "arXiv:2501.08496v3 Announce Type: replace-cross Abstract: Contrary to the conventional emphasis on dataset size, we explore the role of data alignment -- an often overlooked aspect of data quality -- in training capable Large Language Models (LLMs). To do so, we use the Task2Vec-based alignment coefficient, a quantitative measure of the similarity between two datasets, to quantify the impact of alignment between training data and evaluation data on downstream performance. In particular, we conduct controlled textit{interventional} experiments for two settings: 1. the impact of increased alignment coefficients between various pre-training (pt) against evaluation datasets, and 2. the impact of increased alignment coefficients between domain specific fine-tuning (ft) against domain specific evaluation. The domain specific task we explore is Autoformalization -- the machine translation task between natural language and code for formal verification. In both settings, we find a strong, predictable negative correlation between the alignment coefficient of a model's training and evaluation data and the model's loss/perplexity on the respective downstream task. These findings suggest a re-evaluation of LLM training approaches, demonstrating the relevance of data alignment compared to data quantity, especially in specialized downstream tasks such as Autoformalization.",
    "summary": "arXiv:2501.08496v3 Announce Type: replace-cross Abstract: Contrary to the conventional emphasis on dataset size, we explore the role of data alignment -- an often overlooked aspect of data quality -- in training capable Large Language Models (LLMs). To do so, we use the Task2Vec-based alignment coefficient, a quantitative measure of the similarity between two datasets, to quantify the impact of alignment between training data and evaluation data on downstream performance. In particular, we conduct controlled textit{interventional} experiments for two settings: 1. the impact of increased alignment coefficients between various pre-training (pt) against evaluation datasets, and 2. the impact of increased alignment coefficients between domain specific fine-tuning (ft) against domain specific evaluation. The domain specific task we explore is Autoformalization -- the machine translation task between natural language and code for formal verification. In both settings, we find a strong, predictable negative correlation between the alignment coefficient of a model's training and evaluation data and the model's loss/perplexity on the respective downstream task. These findings suggest a re-evaluation of LLM training approaches, demonstrating the relevance of data alignment compared to data quantity, especially in specialized downstream tasks such as Autoformalization.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.08496",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face + PyCharm",
    "description": "",
    "summary": "Hugging Face + PyCharm It‚Äôs a Tuesday morning. As a Transformers maintainer, I‚Äôm doing the same thin...",
    "pubDate": "Tue, 05 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pycharm-integration",
    "thumbnail": "https://huggingface.co/blog/assets/pycharm-integration/thumbnail.png"
  },
  {
    "title": "Scaling-up BERT Inference on CPU (Part 1)",
    "description": "",
    "summary": "Scaling up BERT-like model Inference on modern CPU - Part 1 1. Context and Motivations Back in Octob...",
    "pubDate": "Tue, 20 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-cpu-scaling-part-1",
    "thumbnail": "https://huggingface.co/blog/assets/21_bert_cpu_scaling_part_1/imgs/numa_set.png"
  },
  {
    "title": "Introducing OpenAI for Government",
    "description": "We‚Äôre launching OpenAI for Government, a new initiative focused on bringing our most advanced AI tools to public servants across the United States. We're supporting the U.S. government's efforts in adopting best-in-class technology and deploying these tools in service of the public good.",
    "summary": "We‚Äôre launching OpenAI for Government, a new initiative focused on bringing our most advanced AI tools to public servants across the United States. We're supporting the U.S. government's efforts in adopting best-in-class technology and deploying these tools in service of the public good.",
    "pubDate": "Mon, 16 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-openai-for-government",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing NPC-Playground, a 3D playground to interact with LLM-powered NPCs",
    "description": "",
    "summary": "Introducing NPC-Playground, a 3D playground to interact with LLM-powered NPCs AI-powered NPCs (Non-P...",
    "pubDate": "Wed, 05 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/npc-gigax-cubzh",
    "thumbnail": "https://huggingface.co/blog/assets/181_npc-gigax-cubzh/thumbnail.png"
  },
  {
    "title": "Personalizing education with ChatGPT",
    "description": "Arizona State University embraces ChatGPT campus-wide to personalize learning, advance research, and prepare students for the future",
    "summary": "Arizona State University embraces ChatGPT campus-wide to personalize learning, advance research, and prepare students for the future",
    "pubDate": "Mon, 26 Aug 2024 04:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/asu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Function calling and other API updates",
    "description": "We‚Äôre announcing updates including more steerable API models, function calling capabilities, longer context, and lower prices.",
    "summary": "We‚Äôre announcing updates including more steerable API models, function calling capabilities, longer context, and lower prices.",
    "pubDate": "Tue, 13 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/function-calling-and-other-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SegMoE: Segmind Mixture of Diffusion Experts",
    "description": "",
    "summary": "SegMoE: Segmind Mixture of Diffusion Experts SegMoE is an exciting framework for creating Mixture-of...",
    "pubDate": "Sat, 03 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/segmoe",
    "thumbnail": "https://huggingface.co/blog/assets/segmoe/thumbnail.png"
  },
  {
    "title": "COEF-VQ: Cost-Efficient Video Quality Understanding through a Cascaded Multimodal LLM Framework",
    "description": "arXiv:2412.10435v2 Announce Type: replace-cross Abstract: Recently, with the emergence of recent Multimodal Large Language Model (MLLM) technology, it has become possible to exploit its video understanding capability on different classification tasks. In practice, we face the difficulty of huge requirements for GPU resource if we need to deploy MLLMs online. In this paper, we propose COEF-VQ, a novel cascaded MLLM framework designed to enhance video quality understanding on the short-video platform while optimizing computational efficiency. Our approach integrates an entropy-based pre-filtering stage, where a lightweight model assesses uncertainty and selectively filters cases before passing them to the more computationally intensive MLLM for final evaluation. By prioritizing high-uncertainty samples for deeper analysis, our framework significantly reduces GPU usage while maintaining the strong classification performance of a full MLLM deployment. To demonstrate the effectiveness of COEF-VQ, we deploy this new framework onto the video management platform (VMP) at the short-video platform, and perform a series of detailed experiments on two in-house tasks related to video quality understanding. We show that COEF-VQ leads to substantial performance gains from the offline evaluation in these two tasks and effectively enhances platform safety with limit resource consumption, significantly reducing inappropriate content video view rate by 9.9% in a online A/B test without affecting engagement. Post-launch monitoring confirmed sustained improvements, validating its real-world impact.",
    "summary": "arXiv:2412.10435v2 Announce Type: replace-cross Abstract: Recently, with the emergence of recent Multimodal Large Language Model (MLLM) technology, it has become possible to exploit its video understanding capability on different classification tasks. In practice, we face the difficulty of huge requirements for GPU resource if we need to deploy MLLMs online. In this paper, we propose COEF-VQ, a novel cascaded MLLM framework designed to enhance video quality understanding on the short-video platform while optimizing computational efficiency. Our approach integrates an entropy-based pre-filtering stage, where a lightweight model assesses uncertainty and selectively filters cases before passing them to the more computationally intensive MLLM for final evaluation. By prioritizing high-uncertainty samples for deeper analysis, our framework significantly reduces GPU usage while maintaining the strong classification performance of a full MLLM deployment. To demonstrate the effectiveness of COEF-VQ, we deploy this new framework onto the video management platform (VMP) at the short-video platform, and perform a series of detailed experiments on two in-house tasks related to video quality understanding. We show that COEF-VQ leads to substantial performance gains from the offline evaluation in these two tasks and effectively enhances platform safety with limit resource consumption, significantly reducing inappropriate content video view rate by 9.9% in a online A/B test without affecting engagement. Post-launch monitoring confirmed sustained improvements, validating its real-world impact.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.10435",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Space secrets security update",
    "description": "",
    "summary": "Space secrets leak disclosure Earlier this week our team detected unauthorized access to our Spaces ...",
    "pubDate": "Fri, 31 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/space-secrets-disclosure",
    "thumbnail": "https://huggingface.co/blog/assets/space-secrets-security-update/space-secrets-security-update.png"
  },
  {
    "title": "Universe",
    "description": "We‚Äôre releasing Universe, a software platform for measuring and training an AI‚Äôs general intelligence across the world‚Äôs supply of games, websites and other applications.",
    "summary": "We‚Äôre releasing Universe, a software platform for measuring and training an AI‚Äôs general intelligence across the world‚Äôs supply of games, websites and other applications.",
    "pubDate": "Mon, 05 Dec 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/universe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building Cost-Efficient Enterprise RAG applications with Intel Gaudi 2 and Intel Xeon",
    "description": "",
    "summary": "Building Cost-Efficient Enterprise RAG applications with Intel Gaudi 2 and Intel Xeon Retrieval-augm...",
    "pubDate": "Thu, 09 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cost-efficient-rag-applications-with-intel",
    "thumbnail": "https://huggingface.co/blog/assets/cost_efficient_rag_applications_with_intel/main.jpg"
  },
  {
    "title": "A landmark multi-year global partnership with News Corp",
    "description": "Companies Join Forces to Enrich OpenAI‚Äôs Generative AI Products and Platforms with Premium Journalism",
    "summary": "Companies Join Forces to Enrich OpenAI‚Äôs Generative AI Products and Platforms with Premium Journalism",
    "pubDate": "Wed, 22 May 2024 13:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/news-corp-and-openai-sign-landmark-multi-year-global-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Unpacking the bias of large language models",
    "description": "In a new study, researchers discover the root cause of a type of bias in LLMs, paving the way for more accurate and reliable AI systems.",
    "summary": "In a new study, researchers discover the root cause of a type of bias in LLMs, paving the way for more accurate and reliable AI systems.",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/unpacking-large-language-model-bias-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-transform-bias-01-press.jpg"
  },
  {
    "title": "DeepMind‚Äôs latest research at ICLR 2023",
    "description": "Next week marks the start of the 11th International Conference on Learning Representations (ICLR), taking place 1-5 May in Kigali, Rwanda. This will be the first major artificial intelligence (AI) conference to be hosted in Africa and the first in-person event since the start of the pandemic. Researchers from around the world will gather to share their cutting-edge work in deep learning spanning the fields of AI, statistics and data science, and applications including machine vision, gaming and robotics. We‚Äôre proud to support the conference as a Diamond sponsor and DEI champion.",
    "summary": "Next week marks the start of the 11th International Conference on Learning Representations (ICLR), taking place 1-5 May in Kigali, Rwanda. This will be the first major artificial intelligence (AI) conference to be hosted in Africa and the first in-person event since the start of the pandemic. Researchers from around the world will gather to share their cutting-edge work in deep learning spanning the fields of AI, statistics and data science, and applications including machine vision, gaming and robotics. We‚Äôre proud to support the conference as a Diamond sponsor and DEI champion.",
    "pubDate": "Thu, 27 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/deepminds-latest-research-at-iclr-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/PH30vPBZLwZXlSFrALk6AT507Qn70LSPLW5a89vsRhDdkje_xaPGvNE2UrhOBy8Gkaasn-FVRuDWlPhEPntzw02gxSAEPygt7djS4URtQZJuaLPw3w=w1200-h630-n-nu"
  },
  {
    "title": "AlphaGeometry: An Olympiad-level AI system for geometry",
    "description": "Advancing AI reasoning in mathematics",
    "summary": "Advancing AI reasoning in mathematics",
    "pubDate": "Wed, 17 Jan 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/",
    "thumbnail": "https://lh3.googleusercontent.com/tVTh_ZCW5Qozy4vOCpMH06B7Ac_eF7fmEULMMTwDellOh6hnOMUtf28toD68N527IHQTlBWfBCHcZykYPMdrS48yvuEcJKMJG8rU3YRM3u5Ojn3JXnc=w1200-h630-n-nu"
  },
  {
    "title": "Arize Phoenix „ÅßÂÆüÁèæ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Éà„É¨„Éº„Çπ",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI „ÉÅ„Éº„É†„ÅÆÈï∑Êæ§(@sp_1999N)„Åß„Åô„ÄÇ ‰ªäÂõû„ÅØ Arize AI Á§æ„ÅåÈñãÁô∫„ÉªÊèê‰æõ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥Âêë„Åë„ÅÆÁõ£Ë¶ñ„ÉÑ„Éº„É´ Phoenix „ÅÆÁ¥π‰ªã„Åä„Çà„Å≥Á∞°Âçò„Å™„Éá„É¢ÊßãÁØâ„ÇíË°å„ÅÑ„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ „Éá„É¢„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5608' rel='nofollow'>Arize Phoenix „ÅßÂÆüÁèæ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Éà„É¨„Éº„Çπ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI „ÉÅ„Éº„É†„ÅÆÈï∑Êæ§(@sp_1999N)„Åß„Åô„ÄÇ ‰ªäÂõû„ÅØ Arize AI Á§æ„ÅåÈñãÁô∫„ÉªÊèê‰æõ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥Âêë„Åë„ÅÆÁõ£Ë¶ñ„ÉÑ„Éº„É´ Phoenix „ÅÆÁ¥π‰ªã„Åä„Çà„Å≥Á∞°Âçò„Å™„Éá„É¢ÊßãÁØâ„ÇíË°å„ÅÑ„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ „Éá„É¢„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5608' rel='nofollow'>Arize Phoenix „ÅßÂÆüÁèæ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Éà„É¨„Éº„Çπ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Tue, 25 Mar 2025 10:22:46 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5608",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/image-4.png"
  },
  {
    "title": "Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability",
    "description": "arXiv:2506.18248v2 Announce Type: replace-cross Abstract: Generative adversarial attacks train a perturbation generator on a white-box surrogate model and subsequently apply the crafted perturbations to unseen black-box victim models. In contrast to iterative attacks, these methods deliver superior inference-time efficiency, scalability, and transferability; however, up until now, existing studies have not fully exploited the representational capacity of generative models to preserve and harness semantic information. Specifically, the intermediate activations of the generator encode rich semantic features--object boundaries and coarse shapes--that remain under-exploited, thereby limiting the alignment of perturbations with object-salient regions which are critical for adversarial transferability. To remedy this, we introduce a semantic structure-aware attack framework based on the Mean Teacher, which serves as a temporally smoothed feature reference. With this smoothed reference, we further direct semantic consistency between the early-layer activations in the student and those of the semantically rich teacher by feature distillation. By anchoring perturbation synthesis to the semantically salient early intermediate blocks within the generator based on empirical findings, our method guides progressive adversarial perturbation on regions that substantially enhance adversarial transferability. We conduct extensive experiments over diverse models, domains and tasks to demonstrate consistent improvements relative to state-of-the-art generative attacks, comprehensively evaluated using conventional metrics and our newly proposed Accidental Correction Rate (ACR).",
    "summary": "arXiv:2506.18248v2 Announce Type: replace-cross Abstract: Generative adversarial attacks train a perturbation generator on a white-box surrogate model and subsequently apply the crafted perturbations to unseen black-box victim models. In contrast to iterative attacks, these methods deliver superior inference-time efficiency, scalability, and transferability; however, up until now, existing studies have not fully exploited the representational capacity of generative models to preserve and harness semantic information. Specifically, the intermediate activations of the generator encode rich semantic features--object boundaries and coarse shapes--that remain under-exploited, thereby limiting the alignment of perturbations with object-salient regions which are critical for adversarial transferability. To remedy this, we introduce a semantic structure-aware attack framework based on the Mean Teacher, which serves as a temporally smoothed feature reference. With this smoothed reference, we further direct semantic consistency between the early-layer activations in the student and those of the semantically rich teacher by feature distillation. By anchoring perturbation synthesis to the semantically salient early intermediate blocks within the generator based on empirical findings, our method guides progressive adversarial perturbation on regions that substantially enhance adversarial transferability. We conduct extensive experiments over diverse models, domains and tasks to demonstrate consistent improvements relative to state-of-the-art generative attacks, comprehensively evaluated using conventional metrics and our newly proposed Accidental Correction Rate (ACR).",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18248",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Ethics and Society Newsletter #5: Hugging Face Goes To Washington and Other Summer 2023 Musings",
    "description": "",
    "summary": "Ethics and Society Newsletter #5: Hugging Face Goes To Washington and Other Summer 2023 Musings One ...",
    "pubDate": "Fri, 29 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-5",
    "thumbnail": "https://huggingface.co/blog/assets/164_ethics-soc-5/thumbnail.png"
  },
  {
    "title": "The New and Fresh analytics in Inference Endpoints",
    "description": "",
    "summary": "Analytics is important Analytics and metrics are the cornerstone of understanding what's happening w...",
    "pubDate": "Fri, 21 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/endpoint-analytics",
    "thumbnail": "https://huggingface.co/blog/assets/endpoint-analytics/thumbnail.png"
  },
  {
    "title": "Advantage Actor Critic (A2C)",
    "description": "",
    "summary": "Advantage Actor Critic (A2C) Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 7, of the‚ö†Ô∏è ...",
    "pubDate": "Fri, 22 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-a2c",
    "thumbnail": "https://huggingface.co/blog/assets/89_deep_rl_a2c/thumbnail.gif"
  },
  {
    "title": "Text2SQL using Hugging Face Dataset Viewer API and Motherduck DuckDB-NSQL-7B",
    "description": "",
    "summary": "Text2SQL using Hugging Face Dataset Viewer API and Motherduck DuckDB-NSQL-7B Today, integrating AI-p...",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/duckdb-nsql-7b",
    "thumbnail": "https://huggingface.co/blog/assets/duckdb-nsql-7b/thumbnail.png"
  },
  {
    "title": "Hugging Face Text Generation Inference available for AWS Inferentia2",
    "description": "",
    "summary": "Hugging Face Text Generation Inference available for AWS Inferentia2 We are excited to announce the ...",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-generation-inference-on-inferentia2",
    "thumbnail": "https://huggingface.co/blog/assets/175_text_generation_inference_on_inferentia2/thumbnail.jpg"
  },
  {
    "title": "Welcome Llama 3 - Meta's new open LLM",
    "description": "",
    "summary": "Welcome Llama 3 - Meta‚Äôs new open LLM Introduction Meta‚Äôs Llama 3, the next iteration of the open-ac...",
    "pubDate": "Thu, 18 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama3",
    "thumbnail": "https://huggingface.co/blog/assets/llama3/thumbnail.jpg"
  },
  {
    "title": "OpenAI Five Benchmark",
    "description": "The OpenAI Five Benchmark match is now over!",
    "summary": "The OpenAI Five Benchmark match is now over!",
    "pubDate": "Wed, 18 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-benchmark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Tiny Agents: a MCP-powered agent in 50 lines of code",
    "description": "",
    "summary": "Tiny Agents: an MCP-powered agent in 50 lines of code New! (May 23, '25) If you prefer Python, check...",
    "pubDate": "Fri, 25 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tiny-agents",
    "thumbnail": "https://huggingface.co/blog/assets/tiny-agents/thumbnail.jpg"
  },
  {
    "title": "Detecting Multiple Diseases in Multiple Crops Using Deep Learning",
    "description": "arXiv:2507.02517v1 Announce Type: cross Abstract: India, as a predominantly agrarian economy, faces significant challenges in agriculture, including substantial crop losses caused by diseases, pests, and environmental stress. Early detection and accurate identification of diseases across different crops are critical for improving yield and ensuring food security. This paper proposes a deep learning based solution for detecting multiple diseases in multiple crops, aimed to cover India's diverse agricultural landscape. We first create a unified dataset encompassing images of 17 different crops and 34 different diseases from various available repositories. Proposed deep learning model is trained on this dataset and outperforms the state-of-the-art in terms of accuracy and the number of crops, diseases covered. We achieve a significant detection accuracy, i.e., 99 percent for our unified dataset which is 7 percent more when compared to state-of-the-art handling 14 crops and 26 different diseases only. By improving the number of crops and types of diseases that can be detected, proposed solution aims to provide a better product for Indian farmers.",
    "summary": "arXiv:2507.02517v1 Announce Type: cross Abstract: India, as a predominantly agrarian economy, faces significant challenges in agriculture, including substantial crop losses caused by diseases, pests, and environmental stress. Early detection and accurate identification of diseases across different crops are critical for improving yield and ensuring food security. This paper proposes a deep learning based solution for detecting multiple diseases in multiple crops, aimed to cover India's diverse agricultural landscape. We first create a unified dataset encompassing images of 17 different crops and 34 different diseases from various available repositories. Proposed deep learning model is trained on this dataset and outperforms the state-of-the-art in terms of accuracy and the number of crops, diseases covered. We achieve a significant detection accuracy, i.e., 99 percent for our unified dataset which is 7 percent more when compared to state-of-the-art handling 14 crops and 26 different diseases only. By improving the number of crops and types of diseases that can be detected, proposed solution aims to provide a better product for Indian farmers.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02517",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Canva enables creativity with AI",
    "description": "A conversation with Cameron Adams, Chief Product Officer and Co-founder of Canva.",
    "summary": "A conversation with Cameron Adams, Chief Product Officer and Co-founder of Canva.",
    "pubDate": "Mon, 07 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/canva-cam-adams",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays",
    "description": "<p>The world‚Äôs first multimodal, bilingual radiology dataset could reshape the way radiologists and AI systems make sense of X-rays. PadChest-GR, developed by the University of Alicante with Microsoft Research, has the potential to advance research across the field for years to come.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/'>PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>The world‚Äôs first multimodal, bilingual radiology dataset could reshape the way radiologists and AI systems make sense of X-rays. PadChest-GR, developed by the University of Alicante with Microsoft Research, has the potential to advance research across the field for years to come.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/'>PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 26 Jun 2025 16:08:25 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Uber enables outstanding on-demand experiences with AI",
    "description": "A conversation with Jai Malkani, Head of AI and Product, Customer Obsession at Uber.",
    "summary": "A conversation with Jai Malkani, Head of AI and Product, Customer Obsession at Uber.",
    "pubDate": "Thu, 20 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/uber-enables-outstanding-experiences",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our updated Preparedness Framework",
    "description": "Sharing our updated framework for measuring and protecting against severe harm from frontier AI capabilities.",
    "summary": "Sharing our updated framework for measuring and protecting against severe harm from frontier AI capabilities.",
    "pubDate": "Tue, 15 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/updating-our-preparedness-framework",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Panel on Hugging Face",
    "description": "",
    "summary": "Panel on Hugging Face We are thrilled to announce the collaboration between Panel and Hugging Face! ...",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/panel-on-hugging-face",
    "thumbnail": "https://huggingface.co/blog/assets/panel-on-hugging-face/thumbnail.png"
  },
  {
    "title": "OpenAI‚Äôs API now available with no waitlist",
    "description": "Wider availability made possible by safety¬†progress.",
    "summary": "Wider availability made possible by safety¬†progress.",
    "pubDate": "Thu, 18 Nov 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-no-waitlist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing AI stories: daily benefits shine a light on bigger opportunities",
    "description": "Sam Altman has written that we are entering the Intelligence Age, a time when AI will help people become dramatically more capable. The biggest problems of today‚Äîacross science, medicine, education, national defense‚Äîwill no longer seem intractable, but will in fact be solvable. New horizons of possibility and prosperity will open up.",
    "summary": "Sam Altman has written that we are entering the Intelligence Age, a time when AI will help people become dramatically more capable. The biggest problems of today‚Äîacross science, medicine, education, national defense‚Äîwill no longer seem intractable, but will in fact be solvable. New horizons of possibility and prosperity will open up.",
    "pubDate": "Tue, 06 May 2025 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/ai-stories-daily-benefits-bigger-opportunities",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating Hugging Face Transformers with AWS Inferentia2",
    "description": "",
    "summary": "Accelerating Hugging Face Transformers with AWS Inferentia2 In the last five years, Transformer mode...",
    "pubDate": "Mon, 17 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-transformers-with-inferentia2",
    "thumbnail": "https://huggingface.co/blog/assets/140_accelerate_transformers_with_inferentia2/thumbnail.png"
  },
  {
    "title": "Adebayo Ogunlesi joins OpenAI‚Äôs Board of Directors",
    "description": "Adebayo Ogunlesi Joins OpenAI‚Äôs Board of Directors",
    "summary": "Adebayo Ogunlesi Joins OpenAI‚Äôs Board of Directors",
    "pubDate": "Tue, 14 Jan 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adebayo-ogunlesi-joins-openais-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Emergent tool use from multi-agent interaction",
    "description": "We‚Äôve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek. Through training in our new simulated hide-and-seek environment, agents build a series of six distinct strategies and counterstrategies, some of which we did not know our environment supported. The self-supervised emergent complexity in this simple environment further suggests that multi-agent co-adaptation may one day produce extremely complex and intelligent behavior.",
    "summary": "We‚Äôve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek. Through training in our new simulated hide-and-seek environment, agents build a series of six distinct strategies and counterstrategies, some of which we did not know our environment supported. The self-supervised emergent complexity in this simple environment further suggests that multi-agent co-adaptation may one day produce extremely complex and intelligent behavior.",
    "pubDate": "Tue, 17 Sep 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergent-tool-use",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-4 API general availability and deprecation of older models in the Completions API",
    "description": "GPT-3.5 Turbo, DALL¬∑E and Whisper APIs are also generally available, and we are releasing a deprecation plan for older models of the Completions API, which will retire at the beginning of 2024.",
    "summary": "GPT-3.5 Turbo, DALL¬∑E and Whisper APIs are also generally available, and we are releasing a deprecation plan for older models of the Completions API, which will retire at the beginning of 2024.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-api-general-availability",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Customizable, no-code voice agent automation with GPT-4o",
    "description": "Retell AI is transforming the call center with AI voice automation powered by GPT-4o and GPT-4.1. Its no-code platform enables businesses to launch natural, real-time voice agents that cut call costs, boost CSAT, and automate customer conversations‚Äîwithout scripts or hold times.",
    "summary": "Retell AI is transforming the call center with AI voice automation powered by GPT-4o and GPT-4.1. Its no-code platform enables businesses to launch natural, real-time voice agents that cut call costs, boost CSAT, and automate customer conversations‚Äîwithout scripts or hold times.",
    "pubDate": "Thu, 26 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retell-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Road Graph Generator: Mapping roads at construction sites from GPS data",
    "description": "arXiv:2402.09919v4 Announce Type: replace Abstract: We propose a new method for inferring roads from GPS trajectories to map construction sites. This task presents a unique challenge due to the erratic and non-standard movement patterns of construction machinery, which significantly diverge from typical vehicular traffic on established roads. Our proposed method first identifies intersections in the road network that serve as critical decision points, and then connects them with edges to produce a graph, which can subsequently be used for planning and task-allocation. We demonstrate the approach by mapping roads at a real-life construction site in Norway. The method is validated on four increasingly complex segments of the map. In our tests, the method achieved perfect accuracy in detecting intersections and inferring roads in data with no or low noise, while its performance was reduced in areas with significant noise and consistently missing GPS updates.",
    "summary": "arXiv:2402.09919v4 Announce Type: replace Abstract: We propose a new method for inferring roads from GPS trajectories to map construction sites. This task presents a unique challenge due to the erratic and non-standard movement patterns of construction machinery, which significantly diverge from typical vehicular traffic on established roads. Our proposed method first identifies intersections in the road network that serve as critical decision points, and then connects them with edges to produce a graph, which can subsequently be used for planning and task-allocation. We demonstrate the approach by mapping roads at a real-life construction site in Norway. The method is validated on four increasingly complex segments of the map. In our tests, the method achieved perfect accuracy in detecting intersections and inferring roads in data with no or low noise, while its performance was reduced in areas with significant noise and consistently missing GPS updates.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2402.09919",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Happy 1st anniversary ü§ó Diffusers!",
    "description": "",
    "summary": "Happy 1st anniversary ü§ó Diffusers! ü§ó Diffusers is happy to celebrate its first anniversary! It has b...",
    "pubDate": "Thu, 20 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-turns-1",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers-turns-1/diffusers-turns-1.png"
  },
  {
    "title": "Public Policy at Hugging Face",
    "description": "",
    "summary": "Public Policy at Hugging Face Published April 8, 2024 Update on GitHubAI Policy at Hugging Face is a...",
    "pubDate": "Mon, 08 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/policy-blog",
    "thumbnail": "https://huggingface.co/blog/assets/policy_docs/policy_blog_thumbnail.png"
  },
  {
    "title": "Driving scalable growth with OpenAI o3, GPT-4.1, and CUA",
    "description": "Unify, an AI-powered GTM platform, uses OpenAI‚Äôs o3, GPT-4.1, and CUA to automate prospecting, research, and outreach. With hyper-personalized messaging and an always-on workflow, Unify helps teams generate pipeline at scale while focusing on high-impact customer interactions.",
    "summary": "Unify, an AI-powered GTM platform, uses OpenAI‚Äôs o3, GPT-4.1, and CUA to automate prospecting, research, and outreach. With hyper-personalized messaging and an always-on workflow, Unify helps teams generate pipeline at scale while focusing on high-impact customer interactions.",
    "pubDate": "Tue, 24 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/unify",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Meta-learning for wrestling",
    "description": "We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to physical malfunction.",
    "summary": "We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to physical malfunction.",
    "pubDate": "Wed, 11 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/meta-learning-for-wrestling",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Optimum+ONNX Runtime - Easier, Faster training for your Hugging Face models",
    "description": "",
    "summary": "Optimum + ONNX Runtime: Easier, Faster training for your Hugging Face models Introduction Transforme...",
    "pubDate": "Tue, 24 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-onnxruntime-training",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_onnxruntime-training/thumbnail.png"
  },
  {
    "title": "EquiTabPFN: A Target-Permutation Equivariant Prior Fitted Networks",
    "description": "arXiv:2502.06684v2 Announce Type: replace-cross Abstract: Recent foundational models for tabular data, such as TabPFN, excel at adapting to new tasks via in-context learning, but remain constrained to a fixed, pre-defined number of target dimensions-often necessitating costly ensembling strategies. We trace this constraint to a deeper architectural shortcoming: these models lack target equivariance, so that permuting target dimension orderings alters their predictions. This deficiency gives rise to an irreducible 'equivariance gap', an error term that introduces instability in predictions. We eliminate this gap by designing a fully target-equivariant architecture-ensuring permutation invariance via equivariant encoders, decoders, and a bi-attention mechanism. Empirical evaluation on standard classification benchmarks shows that, on datasets with more classes than those seen during pre-training, our model matches or surpasses existing methods while incurring lower computational overhead.",
    "summary": "arXiv:2502.06684v2 Announce Type: replace-cross Abstract: Recent foundational models for tabular data, such as TabPFN, excel at adapting to new tasks via in-context learning, but remain constrained to a fixed, pre-defined number of target dimensions-often necessitating costly ensembling strategies. We trace this constraint to a deeper architectural shortcoming: these models lack target equivariance, so that permuting target dimension orderings alters their predictions. This deficiency gives rise to an irreducible 'equivariance gap', an error term that introduces instability in predictions. We eliminate this gap by designing a fully target-equivariant architecture-ensuring permutation invariance via equivariant encoders, decoders, and a bi-attention mechanism. Empirical evaluation on standard classification benchmarks shows that, on datasets with more classes than those seen during pre-training, our model matches or surpasses existing methods while incurring lower computational overhead.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.06684",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tuning GPT-2 from human preferences",
    "description": "We‚Äôve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we‚Äôd only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required only 5k. Our motivation is to move safety techniques closer to the general task of ‚Äúmachines talking to humans,‚Äù which we believe is key to extracting information about human¬†values.",
    "summary": "We‚Äôve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we‚Äôd only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required only 5k. Our motivation is to move safety techniques closer to the general task of ‚Äúmachines talking to humans,‚Äù which we believe is key to extracting information about human¬†values.",
    "pubDate": "Thu, 19 Sep 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fine-tuning-gpt-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring with Shapley Values",
    "description": "arXiv:2507.02342v1 Announce Type: cross Abstract: This study proposes DeltaSHAP, a novel explainable artificial intelligence (XAI) algorithm specifically designed for online patient monitoring systems. In clinical environments, discovering the causes driving patient risk evolution is critical for timely intervention, yet existing XAI methods fail to address the unique requirements of clinical time series explanation tasks. To this end, DeltaSHAP addresses three key clinical needs: explaining the changes in the consecutive predictions rather than isolated prediction scores, providing both magnitude and direction of feature attributions, and delivering these insights in real time. By adapting Shapley values to temporal settings, our approach accurately captures feature coalition effects. It further attributes prediction changes using only the actually observed feature combinations, making it efficient and practical for time-sensitive clinical applications. We also introduce new evaluation metrics to evaluate the faithfulness of the attributions for online time series, and demonstrate through experiments on online patient monitoring tasks that DeltaSHAP outperforms state-of-the-art XAI methods in both explanation quality as 62% and computational efficiency as 33% time reduction on the MIMIC-III decompensation benchmark. We release our code at https://github.com/AITRICS/DeltaSHAP.",
    "summary": "arXiv:2507.02342v1 Announce Type: cross Abstract: This study proposes DeltaSHAP, a novel explainable artificial intelligence (XAI) algorithm specifically designed for online patient monitoring systems. In clinical environments, discovering the causes driving patient risk evolution is critical for timely intervention, yet existing XAI methods fail to address the unique requirements of clinical time series explanation tasks. To this end, DeltaSHAP addresses three key clinical needs: explaining the changes in the consecutive predictions rather than isolated prediction scores, providing both magnitude and direction of feature attributions, and delivering these insights in real time. By adapting Shapley values to temporal settings, our approach accurately captures feature coalition effects. It further attributes prediction changes using only the actually observed feature combinations, making it efficient and practical for time-sensitive clinical applications. We also introduce new evaluation metrics to evaluate the faithfulness of the attributions for online time series, and demonstrate through experiments on online patient monitoring tasks that DeltaSHAP outperforms state-of-the-art XAI methods in both explanation quality as 62% and computational efficiency as 33% time reduction on the MIMIC-III decompensation benchmark. We release our code at https://github.com/AITRICS/DeltaSHAP.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02342",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Open Leaderboard for Hebrew LLMs!",
    "description": "",
    "summary": "Introducing the Open Leaderboard for Hebrew LLMs! This project addresses the critical need for advan...",
    "pubDate": "Sun, 05 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-hebrew",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_hebrew.png"
  },
  {
    "title": "Requests for Research 2.0",
    "description": "We‚Äôre releasing a new batch of¬†seven unsolved problems¬†which have come up in the course of our research at OpenAI.",
    "summary": "We‚Äôre releasing a new batch of¬†seven unsolved problems¬†which have come up in the course of our research at OpenAI.",
    "pubDate": "Wed, 31 Jan 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/requests-for-research-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Insights from global conversations",
    "description": "We are sharing what we learned from our conversations across 22 countries, and how we will be incorporating those insights moving forward.",
    "summary": "We are sharing what we learned from our conversations across 22 countries, and how we will be incorporating those insights moving forward.",
    "pubDate": "Thu, 29 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/insights-from-global-conversations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Investing in Performance: Fine-tune small models with LLM insights  - a CFM case study",
    "description": "",
    "summary": "Investing in Performance: Fine-tune small models with LLM insights - a CFM case study Overview: This...",
    "pubDate": "Tue, 03 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cfm-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/cfm-case-study/blogpost_cfm.png"
  },
  {
    "title": "How we sped up transformer inference 100x for ü§ó API customers",
    "description": "",
    "summary": "How we sped up transformer inference 100x for ü§ó API customers ü§ó Transformers has become the default ...",
    "pubDate": "Mon, 18 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerated-inference",
    "thumbnail": "https://huggingface.co/blog/assets/09_accelerated_inference/thumbnail.png"
  },
  {
    "title": "Fine-tuning Llama 2 70B using PyTorch FSDP",
    "description": "",
    "summary": "Fine-tuning Llama 2 70B using PyTorch FSDP Introduction In this blog post, we will look at how to fi...",
    "pubDate": "Wed, 13 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ram-efficient-pytorch-fsdp",
    "thumbnail": "https://huggingface.co/blog/assets/160_fsdp_llama/thumbnail.jpg"
  },
  {
    "title": "Hyperparameter Search with Transformers and Ray Tune",
    "description": "",
    "summary": "Hyperparameter Search with Transformers and Ray Tune A guest blog post by Richard Liaw from the Anys...",
    "pubDate": "Mon, 02 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ray-tune",
    "thumbnail": "https://huggingface.co/blog/assets/06_ray_tune/ray-hf.jpg"
  },
  {
    "title": "A Dive into Text-to-Video Models",
    "description": "",
    "summary": "Text-to-Video: The Task, Challenges and the Current State Video samples generated with ModelScope. T...",
    "pubDate": "Mon, 08 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-to-video",
    "thumbnail": "https://huggingface.co/blog/assets/140_text-to-video/thumbnail.png"
  },
  {
    "title": "2023: A Year of Groundbreaking Advances in AI and Computing",
    "description": "This has been a year of incredible progress in the field of Artificial Intelligence (AI) research and its practical applications.",
    "summary": "This has been a year of incredible progress in the field of Artificial Intelligence (AI) research and its practical applications.",
    "pubDate": "Fri, 22 Dec 2023 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/2023-a-year-of-groundbreaking-advances-in-ai-and-computing/",
    "thumbnail": "https://lh3.googleusercontent.com/fkZqqqpfLKvV2E6ebVmYJjR9q9XnczvWtiui5uU-yPkHCQb5mLAB4kBmh3opGqOJLhtaC58td96UtvULI8uGpbB9TmejR82GZ2vWOqTyWZ6HSItIpHg=w1200-h630-n-nu"
  },
  {
    "title": "Perceiver IO: a scalable, fully-attentional model that works on any modality",
    "description": "",
    "summary": "Perceiver IO: a scalable, fully-attentional model that works on any modality TLDR We've added Percei...",
    "pubDate": "Wed, 15 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/perceiver",
    "thumbnail": "https://huggingface.co/blog/assets/41_perceiver/thumbnail.png"
  },
  {
    "title": "Introducing HELMET",
    "description": "",
    "summary": "Introducing HELMET: Holistically Evaluating Long-context Language Models Contact: hyen@cs.princeton....",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/helmet",
    "thumbnail": "https://huggingface.co/blog/assets/helmet/thumbnail.png"
  },
  {
    "title": "Red Teaming for Generative AI, Report on a Copyright-Focused Exercise Completed in an Academic Medical Center",
    "description": "arXiv:2506.22523v3 Announce Type: replace-cross Abstract: Background: Generative artificial intelligence (AI) deployment in academic medical settings raises copyright compliance concerns. Dana-Farber Cancer Institute implemented GPT4DFCI, an internal generative AI tool utilizing OpenAI models, that is approved for enterprise use in research and operations. Given (1) the exceptionally broad adoption of the tool in our organization, (2) our research mission, and (3) the shared responsibility model required to benefit from Customer Copyright Commitment in Azure OpenAI Service products, we deemed rigorous copyright compliance testing necessary. Case Description: We conducted a structured red teaming exercise in Nov. 2024, with 42 participants from academic, industry, and government institutions. Four teams attempted to extract copyrighted content from GPT4DFCI across four domains: literary works, news articles, scientific publications, and access-restricted clinical notes. Teams successfully extracted verbatim book dedications and near-exact passages through various strategies. News article extraction failed despite jailbreak attempts. Scientific article reproduction yielded only high-level summaries. Clinical note testing revealed appropriate privacy safeguards. Discussion: The successful extraction of literary content indicates potential copyrighted material presence in training data, necessitating inference-time filtering. Differential success rates across content types suggest varying protective mechanisms. The event led to implementation of a copyright-specific meta-prompt in GPT4DFCI; this mitigation has been in production since Jan. 2025. Conclusion: Systematic red teaming revealed specific vulnerabilities in generative AI copyright compliance, leading to concrete mitigation strategies. Academic medical institutions deploying generative AI should implement continuous testing protocols to ensure legal and ethical compliance.",
    "summary": "arXiv:2506.22523v3 Announce Type: replace-cross Abstract: Background: Generative artificial intelligence (AI) deployment in academic medical settings raises copyright compliance concerns. Dana-Farber Cancer Institute implemented GPT4DFCI, an internal generative AI tool utilizing OpenAI models, that is approved for enterprise use in research and operations. Given (1) the exceptionally broad adoption of the tool in our organization, (2) our research mission, and (3) the shared responsibility model required to benefit from Customer Copyright Commitment in Azure OpenAI Service products, we deemed rigorous copyright compliance testing necessary. Case Description: We conducted a structured red teaming exercise in Nov. 2024, with 42 participants from academic, industry, and government institutions. Four teams attempted to extract copyrighted content from GPT4DFCI across four domains: literary works, news articles, scientific publications, and access-restricted clinical notes. Teams successfully extracted verbatim book dedications and near-exact passages through various strategies. News article extraction failed despite jailbreak attempts. Scientific article reproduction yielded only high-level summaries. Clinical note testing revealed appropriate privacy safeguards. Discussion: The successful extraction of literary content indicates potential copyrighted material presence in training data, necessitating inference-time filtering. Differential success rates across content types suggest varying protective mechanisms. The event led to implementation of a copyright-specific meta-prompt in GPT4DFCI; this mitigation has been in production since Jan. 2025. Conclusion: Systematic red teaming revealed specific vulnerabilities in generative AI copyright compliance, leading to concrete mitigation strategies. Academic medical institutions deploying generative AI should implement continuous testing protocols to ensure legal and ethical compliance.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22523",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using GPT-4 to deliver a new customer service standard",
    "description": "Ada uses GPT-4 to deliver a new customer service standard",
    "summary": "Ada uses GPT-4 to deliver a new customer service standard",
    "pubDate": "Thu, 05 Sep 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ada",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generative modeling with sparse transformers",
    "description": "We‚Äôve developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence‚Äîwhether text, images, or sound. It uses an algorithmic improvement of the¬†attention¬†mechanism to extract patterns from sequences 30x longer than possible¬†previously.",
    "summary": "We‚Äôve developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence‚Äîwhether text, images, or sound. It uses an algorithmic improvement of the¬†attention¬†mechanism to extract patterns from sequences 30x longer than possible¬†previously.",
    "pubDate": "Tue, 23 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sparse-transformer",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Creating nail art with ChatGPT",
    "description": "Using ChatGPT to find inspiration for nail art",
    "summary": "Using ChatGPT to find inspiration for nail art",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ten-tiny-canvases",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Start using ChatGPT instantly",
    "description": "We‚Äôre making it easier for people to experience the benefits of AI without needing to sign up",
    "summary": "We‚Äôre making it easier for people to experience the benefits of AI without needing to sign up",
    "pubDate": "Mon, 01 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/start-using-chatgpt-instantly",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "What's going on with the Open LLM Leaderboard?",
    "description": "",
    "summary": "What's going on with the Open LLM Leaderboard? Recently an interesting discussion arose on Twitter f...",
    "pubDate": "Fri, 23 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-mmlu",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "Addendum to o3 and o4-mini system card: Codex",
    "description": "Codex is a cloud-based coding agent. Codex is powered by codex-1, a version of OpenAI o3 optimized for software engineering. codex-1 was trained using reinforcement learning on real-world coding tasks in a variety of environments to generate code that closely mirrors human style and PR preferences, adheres precisely to instructions, and iteratively runs tests until passing results are achieved.",
    "summary": "Codex is a cloud-based coding agent. Codex is powered by codex-1, a version of OpenAI o3 optimized for software engineering. codex-1 was trained using reinforcement learning on real-world coding tasks in a variety of environments to generate code that closely mirrors human style and PR preferences, adheres precisely to instructions, and iteratively runs tests until passing results are achieved.",
    "pubDate": "Fri, 16 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-codex-system-card-addendum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-4V(ision) system card",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4v-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and FriendliAI partner to supercharge model deployment on the Hub",
    "description": "",
    "summary": "Hugging Face and FriendliAI partner to supercharge model deployment on the Hub FriendliAI‚Äôs inferenc...",
    "pubDate": "Wed, 22 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/friendliai-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/friendliai-partnership/thumbnail.png"
  },
  {
    "title": "Introducing deep research",
    "description": "An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.",
    "summary": "An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.",
    "pubDate": "Sun, 02 Feb 2025 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-deep-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and AMD partner on accelerating state-of-the-art models for CPU and GPU platforms",
    "description": "",
    "summary": "Hugging Face and AMD partner on accelerating state-of-the-art models for CPU and GPU platforms Wheth...",
    "pubDate": "Tue, 13 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-amd",
    "thumbnail": "https://huggingface.co/blog/assets/148_huggingface_amd/01.png"
  },
  {
    "title": "Preference Tuning LLMs with Direct Preference Optimization Methods",
    "description": "",
    "summary": "Preference Tuning LLMs with Direct Preference Optimization Methods Addendum After consulting with th...",
    "pubDate": "Thu, 18 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pref-tuning",
    "thumbnail": "https://huggingface.co/blog/assets/pref-tuning/thumbnail.jpg"
  },
  {
    "title": "Controlling Language Model Generation with NVIDIA's LogitsProcessorZoo",
    "description": "",
    "summary": "Controlling Language Model Generation with NVIDIA's LogitsProcessorZoo Generating text with language...",
    "pubDate": "Mon, 23 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/logits-processor-zoo",
    "thumbnail": "https://huggingface.co/blog/assets/logits-processor-zoo/thumbnail.png"
  },
  {
    "title": "Optimization story: Bloom inference",
    "description": "",
    "summary": "Optimization story: Bloom inference This article gives you the behind-the-scenes of how we made an e...",
    "pubDate": "Wed, 12 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-inference-optimization",
    "thumbnail": "https://huggingface.co/blog/assets/bloom-inference-pytorch-scripts/thumbnail.png"
  },
  {
    "title": "Fast AI Model Splitting over Edge Networks",
    "description": "arXiv:2507.01041v2 Announce Type: replace-cross Abstract: Split learning (SL) has emerged as a computationally efficient approach for artificial intelligence (AI) model training, which can alleviate device-side computational workloads. However, complex AI model architectures pose high computational complexity to obtain the optimal model splitting. In this paper, we represent an arbitrary AI model as a directed acyclic graph (DAG), and then reformulate the optimal model splitting problem as a minimum s-t cut search problem. To solve the problem, we propose a fast DAG-based model splitting algorithm, which restructures the DAG to enable the optimal model splitting identification via a maximum flow method. Theoretical analysis indicates that the proposed algorithm is optimal. Furthermore, considering AI models with block structures, we propose a block-wise model splitting algorithm to reduce computational complexity. The algorithm abstracts each block, i.e., a component consisting of multiple layers, into a single vertex, thereby obtaining the optimal model splitting via a simplified DAG. Extensive experimental results demonstrate that the proposed algorithms can determine the optimal model splitting within milliseconds, as well as reduce training delay by 24.62%-38.95% in dynamic edge networks as compared to the state-of-the-art benchmarks.",
    "summary": "arXiv:2507.01041v2 Announce Type: replace-cross Abstract: Split learning (SL) has emerged as a computationally efficient approach for artificial intelligence (AI) model training, which can alleviate device-side computational workloads. However, complex AI model architectures pose high computational complexity to obtain the optimal model splitting. In this paper, we represent an arbitrary AI model as a directed acyclic graph (DAG), and then reformulate the optimal model splitting problem as a minimum s-t cut search problem. To solve the problem, we propose a fast DAG-based model splitting algorithm, which restructures the DAG to enable the optimal model splitting identification via a maximum flow method. Theoretical analysis indicates that the proposed algorithm is optimal. Furthermore, considering AI models with block structures, we propose a block-wise model splitting algorithm to reduce computational complexity. The algorithm abstracts each block, i.e., a component consisting of multiple layers, into a single vertex, thereby obtaining the optimal model splitting via a simplified DAG. Extensive experimental results demonstrate that the proposed algorithms can determine the optimal model splitting within milliseconds, as well as reduce training delay by 24.62%-38.95% in dynamic edge networks as compared to the state-of-the-art benchmarks.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01041",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DALL¬∑E 2 pre-training mitigations",
    "description": "In order to share the magic of¬†DALL¬∑E 2¬†with a broad audience, we needed to reduce the risks associated with powerful image generation models. To this end, we put various¬†guardrails¬†in place to prevent generated images from violating our¬†content policy.",
    "summary": "In order to share the magic of¬†DALL¬∑E 2¬†with a broad audience, we needed to reduce the risks associated with powerful image generation models. To this end, we put various¬†guardrails¬†in place to prevent generated images from violating our¬†content policy.",
    "pubDate": "Tue, 28 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-pre-training-mitigations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Stable Diffusion in JAX/Flax üöÄ",
    "description": "",
    "summary": "üß® Stable Diffusion in JAX / Flax ! ü§ó Hugging Face Diffusers supports Flax since version 0.5.1 ! This...",
    "pubDate": "Thu, 13 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable_diffusion_jax",
    "thumbnail": "https://huggingface.co/blog/assets/108_stable_diffusion_jax/thumbnail.png"
  },
  {
    "title": "Creating agent and human collaboration with GPT 4o",
    "description": "Altera uses GPT-4o to build a new area of human collaboration",
    "summary": "Altera uses GPT-4o to build a new area of human collaboration",
    "pubDate": "Tue, 01 Oct 2024 09:59:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/altera",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Using LoRA for Efficient Stable Diffusion Fine-Tuning",
    "description": "",
    "summary": "Using LoRA for Efficient Stable Diffusion Fine-Tuning LoRA: Low-Rank Adaptation of Large Language Mo...",
    "pubDate": "Thu, 26 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lora",
    "thumbnail": "https://huggingface.co/blog/assets/lora/thumbnail.png"
  },
  {
    "title": "2024 Security Feature Highlights",
    "description": "",
    "summary": "2024 Security Feature Highlights Security is a top priority at Hugging Face, and we're committed to ...",
    "pubDate": "Tue, 06 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/2024-security-features",
    "thumbnail": "https://huggingface.co/blog/assets/2024-security-features/thumbnail.png"
  },
  {
    "title": "Learning from human preferences",
    "description": "One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind‚Äôs safety team, we‚Äôve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better.",
    "summary": "One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind‚Äôs safety team, we‚Äôve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better.",
    "pubDate": "Tue, 13 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-from-human-preferences",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Put AI to work: Automate and Scale Financial Operations",
    "description": "Put AI to work: Automate and Scale Financial Operations",
    "summary": "Put AI to work: Automate and Scale Financial Operations",
    "pubDate": "Mon, 30 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-automate-and-scale-financial-operations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Taking a responsible path to AGI",
    "description": "We‚Äôre exploring the frontiers of AGI, prioritizing technical safety, proactive risk assessment, and collaboration with the AI community.",
    "summary": "We‚Äôre exploring the frontiers of AGI, prioritizing technical safety, proactive risk assessment, and collaboration with the AI community.",
    "pubDate": "Wed, 02 Apr 2025 13:31:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/taking-a-responsible-path-to-agi/",
    "thumbnail": "https://lh3.googleusercontent.com/0sOE0EshCImNhSW7FRZvw-v_eyJJt_WUEh9evgRbhB4tl0o7qY2VAJdAloF5q3Q6CKTCiXdEvv1kUfsyZz8h6rR7Rl9jUhH02ADOyl7A7w-0QDWWr1Y=w1200-h630-n-nu"
  },
  {
    "title": "GeMID: Generalizable Models for IoT Device Identification",
    "description": "arXiv:2411.14441v2 Announce Type: replace-cross Abstract: With the proliferation of devices on the Internet of Things (IoT), ensuring their security has become paramount. Device identification (DI), which distinguishes IoT devices based on their traffic patterns, plays a crucial role in both differentiating devices and identifying vulnerable ones, closing a serious security gap. However, existing approaches to DI that build machine learning models often overlook the challenge of model generalizability across diverse network environments. In this study, we propose a novel framework to address this limitation and to evaluate the generalizability of DI models across data sets collected within different network environments. Our approach involves a two-step process: first, we develop a feature and model selection method that is more robust to generalization issues by using a genetic algorithm with external feedback and datasets from distinct environments to refine the selections. Second, the resulting DI models are then tested on further independent datasets to robustly assess their generalizability. We demonstrate the effectiveness of our method by empirically comparing it to alternatives, highlighting how fundamental limitations of commonly employed techniques such as sliding window and flow statistics limit their generalizability. Moreover, we show that statistical methods, widely used in the literature, are unreliable for device identification due to their dependence on network-specific characteristics rather than device-intrinsic properties, challenging the validity of a significant portion of existing research. Our findings advance research in IoT security and device identification, offering insight into improving model effectiveness and mitigating risks in IoT networks.",
    "summary": "arXiv:2411.14441v2 Announce Type: replace-cross Abstract: With the proliferation of devices on the Internet of Things (IoT), ensuring their security has become paramount. Device identification (DI), which distinguishes IoT devices based on their traffic patterns, plays a crucial role in both differentiating devices and identifying vulnerable ones, closing a serious security gap. However, existing approaches to DI that build machine learning models often overlook the challenge of model generalizability across diverse network environments. In this study, we propose a novel framework to address this limitation and to evaluate the generalizability of DI models across data sets collected within different network environments. Our approach involves a two-step process: first, we develop a feature and model selection method that is more robust to generalization issues by using a genetic algorithm with external feedback and datasets from distinct environments to refine the selections. Second, the resulting DI models are then tested on further independent datasets to robustly assess their generalizability. We demonstrate the effectiveness of our method by empirically comparing it to alternatives, highlighting how fundamental limitations of commonly employed techniques such as sliding window and flow statistics limit their generalizability. Moreover, we show that statistical methods, widely used in the literature, are unreliable for device identification due to their dependence on network-specific characteristics rather than device-intrinsic properties, challenging the validity of a significant portion of existing research. Our findings advance research in IoT security and device identification, offering insight into improving model effectiveness and mitigating risks in IoT networks.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.14441",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing more enterprise-grade features for API customers",
    "description": "Increasing enterprise support with more security features and controls, updates to our Assistants API, and tools to better manage costs.",
    "summary": "Increasing enterprise support with more security features and controls, updates to our Assistants API, and tools to better manage costs.",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/more-enterprise-grade-features-for-api-customers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Spinning Up in Deep RL",
    "description": "We‚Äôre releasing Spinning Up in Deep RL, an educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning. Spinning Up consists of crystal-clear examples of RL code, educational exercises, documentation, and¬†tutorials.",
    "summary": "We‚Äôre releasing Spinning Up in Deep RL, an educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning. Spinning Up consists of crystal-clear examples of RL code, educational exercises, documentation, and¬†tutorials.",
    "pubDate": "Thu, 08 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spinning-up-in-deep-rl",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How to generate text: using different decoding methods for language generation with Transformers",
    "description": "",
    "summary": "How to generate text: using different decoding methods for language generation with Transformers Not...",
    "pubDate": "Sun, 01 Mar 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-generate",
    "thumbnail": "https://huggingface.co/blog/assets/02_how-to-generate/thumbnail.png"
  },
  {
    "title": "Saving lives with AI health coaching",
    "description": "Healthify collaborates with OpenAI to improve millions of lives with sustainable weight loss.",
    "summary": "Healthify collaborates with OpenAI to improve millions of lives with sustainable weight loss.",
    "pubDate": "Wed, 13 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/healthify",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How we used generative media at I/O 2025",
    "description": "Video showing the I/O opening film.",
    "summary": "Video showing the I/O opening film.",
    "pubDate": "Tue, 10 Jun 2025 17:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/generative-ai-io-keynote-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/thumbnail_opener_hero.width-1300.png"
  },
  {
    "title": "SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model",
    "description": "arXiv:2507.02822v1 Announce Type: cross Abstract: With the widespread adoption of large language models (LLMs) in practical applications, selecting an appropriate model requires balancing not only performance but also operational cost. The emergence of reasoning-capable models has further widened the cost gap between 'thinking' (high reasoning) and 'non-thinking' (fast, low-cost) modes. In this work, we reveal that approximately 58% of medical questions can be accurately answered by the non-thinking mode alone, without requiring the high-cost reasoning process. This highlights a clear dichotomy in problem complexity and suggests that dynamically routing queries to the appropriate mode based on complexity could optimize accuracy, cost-efficiency, and overall user experience. Based on this, we further propose SynapseRoute, a machine learning-based dynamic routing framework that intelligently assigns input queries to either thinking or non-thinking modes. Experimental results on several medical datasets demonstrate that SynapseRoute not only improves overall accuracy (0.8390 vs. 0.8272) compared to the thinking mode alone but also reduces inference time by 36.8% and token consumption by 39.66%. Importantly, qualitative analysis indicates that over-reasoning on simpler queries can lead to unnecessary delays and even decreased accuracy, a pitfall avoided by our adaptive routing. Finally, this work further introduces the Accuracy-Inference-Token (AIT) index to comprehensively evaluate the trade-offs among accuracy, latency, and token cost.",
    "summary": "arXiv:2507.02822v1 Announce Type: cross Abstract: With the widespread adoption of large language models (LLMs) in practical applications, selecting an appropriate model requires balancing not only performance but also operational cost. The emergence of reasoning-capable models has further widened the cost gap between 'thinking' (high reasoning) and 'non-thinking' (fast, low-cost) modes. In this work, we reveal that approximately 58% of medical questions can be accurately answered by the non-thinking mode alone, without requiring the high-cost reasoning process. This highlights a clear dichotomy in problem complexity and suggests that dynamically routing queries to the appropriate mode based on complexity could optimize accuracy, cost-efficiency, and overall user experience. Based on this, we further propose SynapseRoute, a machine learning-based dynamic routing framework that intelligently assigns input queries to either thinking or non-thinking modes. Experimental results on several medical datasets demonstrate that SynapseRoute not only improves overall accuracy (0.8390 vs. 0.8272) compared to the thinking mode alone but also reduces inference time by 36.8% and token consumption by 39.66%. Importantly, qualitative analysis indicates that over-reasoning on simpler queries can lead to unnecessary delays and even decreased accuracy, a pitfall avoided by our adaptive routing. Finally, this work further introduces the Accuracy-Inference-Token (AIT) index to comprehensively evaluate the trade-offs among accuracy, latency, and token cost.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02822",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Generalizing from simulation",
    "description": "Our latest robotics techniques allow robot controllers, trained entirely in simulation and deployed on physical robots, to react to unplanned changes in the environment as they solve simple tasks. That is, we‚Äôve used these techniques to build closed-loop systems rather than open-loop ones as before.",
    "summary": "Our latest robotics techniques allow robot controllers, trained entirely in simulation and deployed on physical robots, to react to unplanned changes in the environment as they solve simple tasks. That is, we‚Äôve used these techniques to build closed-loop systems rather than open-loop ones as before.",
    "pubDate": "Thu, 19 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generalizing-from-simulation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Mastering Stratego, the classic game of imperfect information",
    "description": "Game-playing artificial intelligence (AI) systems have advanced to a new frontier.",
    "summary": "Game-playing artificial intelligence (AI) systems have advanced to a new frontier.",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/mastering-stratego-the-classic-game-of-imperfect-information/",
    "thumbnail": "https://lh3.googleusercontent.com/nvWTaah_1s2OEAt4CsxX5gKok_0V6-Q5eH3aW3GF6YyZdEVM0OBdgFxNa4DAbmUCXpvTqTfslfUB7_3ZBYr6kIQuk2u46khXH41IU16EZghstwt72Mk=w1200-h630-n-nu"
  },
  {
    "title": "Announcing Gemma 3n preview: Powerful, efficient, mobile-first AI",
    "description": "Gemma 3n is a cutting-edge open model designed for fast, multimodal AI on devices, featuring optimized performance, unique flexibility with a 2-in-1 model, and expanded multimodal understanding with audio, empowering developers to build live, interactive applications and sophisticated audio-centric experiences.",
    "summary": "Gemma 3n is a cutting-edge open model designed for fast, multimodal AI on devices, featuring optimized performance, unique flexibility with a 2-in-1 model, and expanded multimodal understanding with audio, empowering developers to build live, interactive applications and sophisticated audio-centric experiences.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/announcing-gemma-3n-preview-powerful-efficient-mobile-first-ai/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma3n_Metadatal_RD2-V01.2e16d0ba.fill-1200x600.jpg"
  },
  {
    "title": "Introducing IDEFICS: An Open Reproduction of State-of-the-art Visual Language Model",
    "description": "",
    "summary": "Introducing IDEFICS: An Open Reproduction of State-of-the-Art Visual Language Model We are excited t...",
    "pubDate": "Tue, 22 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/idefics",
    "thumbnail": "https://huggingface.co/blog/assets/idefics/thumbnail.png"
  },
  {
    "title": "Improving the Robustness of Distantly-Supervised Named Entity Recognition via Uncertainty-Aware Teacher Learning and Student-Student Collaborative Learning",
    "description": "arXiv:2311.08010v3 Announce Type: replace-cross Abstract: Distantly-Supervised Named Entity Recognition (DS-NER) is widely used in real-world scenarios. It can effectively alleviate the burden of annotation by matching entities in existing knowledge bases with snippets in the text but suffer from the label noise. Recent works attempt to adopt the teacher-student framework to gradually refine the training labels and improve the overall robustness. However, these teacher-student methods achieve limited performance because the poor calibration of the teacher network produces incorrectly pseudo-labeled samples, leading to error propagation. Therefore, we propose: (1) Uncertainty-Aware Teacher Learning that leverages the prediction uncertainty to reduce the number of incorrect pseudo labels in the self-training stage; (2) Student-Student Collaborative Learning that allows the transfer of reliable labels between two student networks instead of indiscriminately relying on all pseudo labels from its teacher, and further enables a full exploration of mislabeled samples rather than simply filtering unreliable pseudo-labeled samples. We evaluate our proposed method on five DS-NER datasets, demonstrating that our method is superior to the state-of-the-art DS-NER methods.",
    "summary": "arXiv:2311.08010v3 Announce Type: replace-cross Abstract: Distantly-Supervised Named Entity Recognition (DS-NER) is widely used in real-world scenarios. It can effectively alleviate the burden of annotation by matching entities in existing knowledge bases with snippets in the text but suffer from the label noise. Recent works attempt to adopt the teacher-student framework to gradually refine the training labels and improve the overall robustness. However, these teacher-student methods achieve limited performance because the poor calibration of the teacher network produces incorrectly pseudo-labeled samples, leading to error propagation. Therefore, we propose: (1) Uncertainty-Aware Teacher Learning that leverages the prediction uncertainty to reduce the number of incorrect pseudo labels in the self-training stage; (2) Student-Student Collaborative Learning that allows the transfer of reliable labels between two student networks instead of indiscriminately relying on all pseudo labels from its teacher, and further enables a full exploration of mislabeled samples rather than simply filtering unreliable pseudo-labeled samples. We evaluate our proposed method on five DS-NER datasets, demonstrating that our method is superior to the state-of-the-art DS-NER methods.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2311.08010",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Ethics and Society Newsletter #2: Let's talk about bias!",
    "description": "",
    "summary": "Machine Learning in development: Let's talk about bias! Bias in ML is ubiquitous, and Bias in ML is ...",
    "pubDate": "Thu, 15 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-2",
    "thumbnail": "https://huggingface.co/blog/assets/122_ethics_soc_2/thumbnail-solstice.png"
  },
  {
    "title": "SmolLM - blazingly fast and remarkably powerful",
    "description": "",
    "summary": "SmolLM - blazingly fast and remarkably powerful TL;DR This blog post introduces SmolLM, a family of ...",
    "pubDate": "Tue, 16 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smollm",
    "thumbnail": "https://huggingface.co/blog/assets/smollm/banner.png"
  },
  {
    "title": "Deep double descent",
    "description": "We show that the¬†double¬†descent¬†phenomenon¬†occurs in CNNs, ResNets, and transformers: performance first improves, then gets worse, and then improves again with increasing model size, data size, or training time. This effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we don‚Äôt yet fully understand why it happens, and view further study of this phenomenon as an important research¬†direction.",
    "summary": "We show that the¬†double¬†descent¬†phenomenon¬†occurs in CNNs, ResNets, and transformers: performance first improves, then gets worse, and then improves again with increasing model size, data size, or training time. This effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we don‚Äôt yet fully understand why it happens, and view further study of this phenomenon as an important research¬†direction.",
    "pubDate": "Thu, 05 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-double-descent",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms",
    "description": "New AI agent evolves algorithms for math and practical applications in computing by combining the creativity of large language models with automated evaluators",
    "summary": "New AI agent evolves algorithms for math and practical applications in computing by combining the creativity of large language models with automated evaluators",
    "pubDate": "Wed, 14 May 2025 14:59:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/",
    "thumbnail": "https://lh3.googleusercontent.com/tG6-MqdlvhQ-z7ENzGxR-kpGPPdPHbJ8UZtbTP66Rxi0UftTFU1yAvaBCVuigYuKvESMeEFf4jqNBVENFcZXEUnj8SSqj8zsop8UHAl0eD9A-hUCvQ=w1200-h630-n-nu"
  },
  {
    "title": "Using Stable Diffusion with Core ML on Apple Silicon",
    "description": "",
    "summary": "Using Stable Diffusion with Core ML on Apple Silicon Thanks to Apple engineers, you can now run Stab...",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers_coreml/thumbnail.png"
  },
  {
    "title": "OpenAI Pioneers Program",
    "description": "Advancing model performance and real world evaluation in applied domains.",
    "summary": "Advancing model performance and real world evaluation in applied domains.",
    "pubDate": "Wed, 09 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-pioneers-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Hugging Face Training Efficiency Through Packing with Flash Attention",
    "description": "",
    "summary": "Improving Hugging Face Training Efficiency Through Packing with Flash Attention TL;DR Training with ...",
    "pubDate": "Wed, 21 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/packing-with-FA2",
    "thumbnail": "https://huggingface.co/blog/assets/packing-with-FA2/thumbnail.png"
  },
  {
    "title": "Make your llama generation time fly with AWS Inferentia2",
    "description": "",
    "summary": "Make your llama generation time fly with AWS Inferentia2 Update (02/2024): Performance has improved ...",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inferentia-llama2",
    "thumbnail": "https://huggingface.co/blog/assets/inferentia-llama2/thumbnail.png"
  },
  {
    "title": "AlphaFold 3 predicts the structure and interactions of all of life‚Äôs molecules",
    "description": "Introducing a new AI model developed by Google DeepMind and Isomorphic Labs.",
    "summary": "Introducing a new AI model developed by Google DeepMind and Isomorphic Labs.",
    "pubDate": "Wed, 08 May 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphafold-3-predicts-the-structure-and-interactions-of-all-lifes-molecules/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AF_social_share.width-1300.jpg"
  },
  {
    "title": "Plan online, learn offline: Efficient learning and exploration via model-based control",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 05 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/plan-online-learn-offline",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval",
    "description": "",
    "summary": "Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval We introduce t...",
    "pubDate": "Fri, 22 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/embedding-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/embedding-quantization/thumbnail.png"
  },
  {
    "title": "Distinguishing Predictive and Generative AI in Regulation",
    "description": "arXiv:2506.17347v2 Announce Type: replace-cross Abstract: Over the past decade, policymakers have developed a set of regulatory tools to ensure AI development aligns with key societal goals. Many of these tools were initially developed in response to concerns with predictive AI and therefore encode certain assumptions about the nature of AI systems and the utility of certain regulatory approaches. With the advent of generative AI, however, some of these assumptions no longer hold, even as policymakers attempt to maintain a single regulatory target that covers both types of AI. In this paper, we identify four distinct aspects of generative AI that call for meaningfully different policy responses. These are the generality and adaptability of generative AI that make it a poor regulatory target, the difficulty of designing effective evaluations, new legal concerns that change the ecosystem of stakeholders and sources of expertise, and the distributed structure of the generative AI value chain. In light of these distinctions, policymakers will need to evaluate where the past decade of policy work remains relevant and where new policies, designed to address the unique risks posed by generative AI, are necessary. We outline three recommendations for policymakers to more effectively identify regulatory targets and leverage constraints across the broader ecosystem to govern generative AI.",
    "summary": "arXiv:2506.17347v2 Announce Type: replace-cross Abstract: Over the past decade, policymakers have developed a set of regulatory tools to ensure AI development aligns with key societal goals. Many of these tools were initially developed in response to concerns with predictive AI and therefore encode certain assumptions about the nature of AI systems and the utility of certain regulatory approaches. With the advent of generative AI, however, some of these assumptions no longer hold, even as policymakers attempt to maintain a single regulatory target that covers both types of AI. In this paper, we identify four distinct aspects of generative AI that call for meaningfully different policy responses. These are the generality and adaptability of generative AI that make it a poor regulatory target, the difficulty of designing effective evaluations, new legal concerns that change the ecosystem of stakeholders and sources of expertise, and the distributed structure of the generative AI value chain. In light of these distinctions, policymakers will need to evaluate where the past decade of policy work remains relevant and where new policies, designed to address the unique risks posed by generative AI, are necessary. We outline three recommendations for policymakers to more effectively identify regulatory targets and leverage constraints across the broader ecosystem to govern generative AI.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17347",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Practices for Governing Agentic AI Systems",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/practices-for-governing-agentic-ai-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing our latest image generation model in the API",
    "description": "Our latest image generation model is now available in the API via ‚Äògpt-image-1‚Äô‚Äîenabling developers and businesses to build professional-grade, customizable visuals directly into their own tools and platforms.",
    "summary": "Our latest image generation model is now available in the API via ‚Äògpt-image-1‚Äô‚Äîenabling developers and businesses to build professional-grade, customizable visuals directly into their own tools and platforms.",
    "pubDate": "Wed, 23 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/image-generation-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Equivalence between policy gradients and soft Q-learning",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 21 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/equivalence-between-policy-gradients-and-soft-q-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome fastai to the Hugging Face Hub",
    "description": "",
    "summary": "Welcome fastai to the Hugging Face Hub Making neural nets uncool again... and sharing them Few have ...",
    "pubDate": "Fri, 06 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastai",
    "thumbnail": "https://huggingface.co/blog/assets/64_fastai/fastai_hf_blog.png"
  },
  {
    "title": "Deploying TensorFlow Vision Models in Hugging Face with TF Serving",
    "description": "",
    "summary": "Deploying TensorFlow Vision Models in Hugging Face with TF Serving In the past few months, the Huggi...",
    "pubDate": "Mon, 25 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-serving-vision",
    "thumbnail": "https://huggingface.co/blog/assets/90_tf_serving_vision/thumbnail.png"
  },
  {
    "title": "MIT announces the Initiative for New Manufacturing",
    "description": "The Institute-wide effort aims to bolster industry and create jobs by driving innovation across vital manufacturing sectors.",
    "summary": "The Institute-wide effort aims to bolster industry and create jobs by driving innovation across vital manufacturing sectors.",
    "pubDate": "Tue, 27 May 2025 10:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-announces-initiative-for-new-manufacturing-0527",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-ManufacturingAnn-01-press.jpg"
  },
  {
    "title": "Generative models",
    "description": "This post describes four projects that share a common theme of enhancing or using generative models, a branch of unsupervised learning techniques in machine learning. In addition to describing our work, this post will tell you a bit more about generative models: what they are, why they are important, and where they might be going.",
    "summary": "This post describes four projects that share a common theme of enhancing or using generative models, a branch of unsupervised learning techniques in machine learning. In addition to describing our work, this post will tell you a bit more about generative models: what they are, why they are important, and where they might be going.",
    "pubDate": "Thu, 16 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generative-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI for Nonprofits",
    "description": "We‚Äôre launching a new initiative to enhance the accessibility of our tools for nonprofit organizations, including discounted rates for ChatGPT Team and Enterprise.",
    "summary": "We‚Äôre launching a new initiative to enhance the accessibility of our tools for nonprofit organizations, including discounted rates for ChatGPT Team and Enterprise.",
    "pubDate": "Thu, 30 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-for-nonprofits",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs",
    "description": "arXiv:2412.11556v2 Announce Type: replace-cross Abstract: Extracting sentence embeddings from large language models (LLMs) is a promising direction, as LLMs have demonstrated stronger semantic understanding capabilities. Previous studies typically focus on prompt engineering to elicit sentence embeddings from LLMs by prompting the model to encode sentence information into the embedding of the last token. However, LLMs are mostly decoder-only models with causal attention and the earlier tokens in the sentence cannot attend to the latter tokens, resulting in biased encoding of sentence information and cascading effects on the final decoded token. To this end, we propose a novel Token Prepending (TP) technique that prepends each layer's decoded sentence embedding to the beginning of the sentence in the next layer's input, allowing earlier tokens to attend to the complete sentence information under the causal attention mechanism. The proposed TP technique is a plug-and-play and training-free technique, which means it can be seamlessly integrated with various prompt-based sentence embedding methods and autoregressive LLMs. Extensive experiments on various Semantic Textual Similarity (STS) tasks and downstream classification tasks demonstrate that our proposed TP technique can significantly improve the performance of existing prompt-based sentence embedding methods across different LLMs, while incurring negligible additional inference cost.",
    "summary": "arXiv:2412.11556v2 Announce Type: replace-cross Abstract: Extracting sentence embeddings from large language models (LLMs) is a promising direction, as LLMs have demonstrated stronger semantic understanding capabilities. Previous studies typically focus on prompt engineering to elicit sentence embeddings from LLMs by prompting the model to encode sentence information into the embedding of the last token. However, LLMs are mostly decoder-only models with causal attention and the earlier tokens in the sentence cannot attend to the latter tokens, resulting in biased encoding of sentence information and cascading effects on the final decoded token. To this end, we propose a novel Token Prepending (TP) technique that prepends each layer's decoded sentence embedding to the beginning of the sentence in the next layer's input, allowing earlier tokens to attend to the complete sentence information under the causal attention mechanism. The proposed TP technique is a plug-and-play and training-free technique, which means it can be seamlessly integrated with various prompt-based sentence embedding methods and autoregressive LLMs. Extensive experiments on various Semantic Textual Similarity (STS) tasks and downstream classification tasks demonstrate that our proposed TP technique can significantly improve the performance of existing prompt-based sentence embedding methods across different LLMs, while incurring negligible additional inference cost.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.11556",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Scholars 2019: Final projects",
    "description": "Our second class of OpenAI Scholars has concluded, with all eight scholars producing an exciting final project showcased at Scholars Demo Day at OpenAI.",
    "summary": "Our second class of OpenAI Scholars has concluded, with all eight scholars producing an exciting final project showcased at Scholars Demo Day at OpenAI.",
    "pubDate": "Thu, 23 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our approach to alignment research",
    "description": "We are improving our AI systems‚Äô ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment¬†problems.",
    "summary": "We are improving our AI systems‚Äô ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment¬†problems.",
    "pubDate": "Wed, 24 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/our-approach-to-alignment-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "STELLA: Self-Evolving LLM Agent for Biomedical Research",
    "description": "arXiv:2507.02004v1 Announce Type: new Abstract: The rapid growth of biomedical data, tools, and literature has created a fragmented research landscape that outpaces human expertise. While AI agents offer a solution, they typically rely on static, manually curated toolsets, limiting their ability to adapt and scale. Here, we introduce STELLA, a self-evolving AI agent designed to overcome these limitations. STELLA employs a multi-agent architecture that autonomously improves its own capabilities through two core mechanisms: an evolving Template Library for reasoning strategies and a dynamic Tool Ocean that expands as a Tool Creation Agent automatically discovers and integrates new bioinformatics tools. This allows STELLA to learn from experience. We demonstrate that STELLA achieves state-of-the-art accuracy on a suite of biomedical benchmarks, scoring approximately 26% on Humanity's Last Exam: Biomedicine, 54% on LAB-Bench: DBQA, and 63% on LAB-Bench: LitQA, outperforming leading models by up to 6 percentage points. More importantly, we show that its performance systematically improves with experience; for instance, its accuracy on the Humanity's Last Exam benchmark almost doubles with increased trials. STELLA represents a significant advance towards AI Agent systems that can learn and grow, dynamically scaling their expertise to accelerate the pace of biomedical discovery.",
    "summary": "arXiv:2507.02004v1 Announce Type: new Abstract: The rapid growth of biomedical data, tools, and literature has created a fragmented research landscape that outpaces human expertise. While AI agents offer a solution, they typically rely on static, manually curated toolsets, limiting their ability to adapt and scale. Here, we introduce STELLA, a self-evolving AI agent designed to overcome these limitations. STELLA employs a multi-agent architecture that autonomously improves its own capabilities through two core mechanisms: an evolving Template Library for reasoning strategies and a dynamic Tool Ocean that expands as a Tool Creation Agent automatically discovers and integrates new bioinformatics tools. This allows STELLA to learn from experience. We demonstrate that STELLA achieves state-of-the-art accuracy on a suite of biomedical benchmarks, scoring approximately 26% on Humanity's Last Exam: Biomedicine, 54% on LAB-Bench: DBQA, and 63% on LAB-Bench: LitQA, outperforming leading models by up to 6 percentage points. More importantly, we show that its performance systematically improves with experience; for instance, its accuracy on the Humanity's Last Exam benchmark almost doubles with increased trials. STELLA represents a significant advance towards AI Agent systems that can learn and grow, dynamically scaling their expertise to accelerate the pace of biomedical discovery.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02004",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Visual Document Retrieval Goes Multilingual",
    "description": "",
    "summary": "Visual Document Retrieval Goes Multilingual TL;DR: We present vdr-2b-multi-v1 , the best multilingua...",
    "pubDate": "Fri, 10 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vdr-2b-multilingual",
    "thumbnail": "https://huggingface.co/blog/assets/vdr-2b-multilingual/thumbnail.png"
  },
  {
    "title": "AI Policy @ü§ó: Open ML Considerations in the EU AI Act",
    "description": "",
    "summary": "AI Policy @ü§ó: Open ML Considerations in the EU AI Act Like everyone else in Machine Learning, we‚Äôve ...",
    "pubDate": "Mon, 24 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eu-ai-act-oss",
    "thumbnail": "https://huggingface.co/blog/assets/eu_ai_act_oss/thumbnailEU.png"
  },
  {
    "title": "Introduction to ggml",
    "description": "",
    "summary": "Introduction to ggml ggml is a machine learning (ML) library written in C and C++ with a focus on Tr...",
    "pubDate": "Tue, 13 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introduction-to-ggml",
    "thumbnail": "https://huggingface.co/blog/assets/introduction-to-ggml/cover.jpg"
  },
  {
    "title": "From PyTorch DDP to ü§ó Accelerate to ü§ó Trainer, mastery of distributed training with ease",
    "description": "",
    "summary": "From PyTorch DDP to Accelerate to Trainer, mastery of distributed training with ease General Overvie...",
    "pubDate": "Fri, 21 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-ddp-accelerate-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/111_pytorch_ddp_accelerate_transformers/thumbnail.png"
  },
  {
    "title": "Memory-efficient Diffusion Transformers with Quanto and Diffusers",
    "description": "",
    "summary": "Memory-efficient Diffusion Transformers with Quanto and Diffusers Over the past few months, we have ...",
    "pubDate": "Tue, 30 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/quanto-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/quanto-diffusers/thumbnail.png"
  },
  {
    "title": "Enterprise-ready trust and safety",
    "description": "Salesforce integrates OpenAI‚Äôs enterprise-ready LLMs to transform customer applications.",
    "summary": "Salesforce integrates OpenAI‚Äôs enterprise-ready LLMs to transform customer applications.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/salesforce",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering",
    "description": "We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.",
    "summary": "We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.",
    "pubDate": "Thu, 10 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mle-bench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Computational limitations in robust classification and win-win results",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 04 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/computational-limitations-in-robust-classification-and-win-win-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Benchmarking the next generation of never-ending learners",
    "description": "Learning how to build upon knowledge by tapping 30 years of computer vision research",
    "summary": "Learning how to build upon knowledge by tapping 30 years of computer vision research",
    "pubDate": "Tue, 22 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/benchmarking-the-next-generation-of-never-ending-learners/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "Shipping code faster with o3, o4-mini, and GPT-4.1",
    "description": "CodeRabbit uses OpenAI models to revolutionize code reviews‚Äîboosting accuracy, accelerating PR merges, and helping developers ship faster with fewer bugs and higher ROI.",
    "summary": "CodeRabbit uses OpenAI models to revolutionize code reviews‚Äîboosting accuracy, accelerating PR merges, and helping developers ship faster with fewer bugs and higher ROI.",
    "pubDate": "Thu, 22 May 2025 10:25:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/coderabbit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Early Signs of Steganographic Capabilities in Frontier LLMs",
    "description": "arXiv:2507.02737v1 Announce Type: cross Abstract: Monitoring Large Language Model (LLM) outputs is crucial for mitigating risks from misuse and misalignment. However, LLMs could evade monitoring through steganography: Encoding hidden information within seemingly benign generations. In this paper, we evaluate the steganography capabilities in frontier LLMs to better understand the risk they pose. We focus on two types of steganography: passing encoded messages and performing encoded reasoning. We find that current models are unable to encode short messages in their outputs without a monitor noticing under standard affordances. They can succeed, however, if given additional affordances such as using an unmonitored scratchpad and coordinating on what encoding scheme to use. We additionally find early signs that models can perform basic encoded reasoning in a simple state-tracking problem. This includes some ability to reason with their own and pre-defined schemes, including encoding schemes such as Hexadecimal. Despite this, they can rarely hide reasoning subtly within a cover task to fool a monitor. Overall, our results indicate that current LLMs exhibit nascent steganographic capabilities. While these capabilities are likely insufficient to bypass well-designed monitors at present, this could change in the future.",
    "summary": "arXiv:2507.02737v1 Announce Type: cross Abstract: Monitoring Large Language Model (LLM) outputs is crucial for mitigating risks from misuse and misalignment. However, LLMs could evade monitoring through steganography: Encoding hidden information within seemingly benign generations. In this paper, we evaluate the steganography capabilities in frontier LLMs to better understand the risk they pose. We focus on two types of steganography: passing encoded messages and performing encoded reasoning. We find that current models are unable to encode short messages in their outputs without a monitor noticing under standard affordances. They can succeed, however, if given additional affordances such as using an unmonitored scratchpad and coordinating on what encoding scheme to use. We additionally find early signs that models can perform basic encoded reasoning in a simple state-tracking problem. This includes some ability to reason with their own and pre-defined schemes, including encoding schemes such as Hexadecimal. Despite this, they can rarely hide reasoning subtly within a cover task to fool a monitor. Overall, our results indicate that current LLMs exhibit nascent steganographic capabilities. While these capabilities are likely insufficient to bypass well-designed monitors at present, this could change in the future.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02737",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„ÇíÁú∫„ÇÅ„Å¶„Åø„Çã",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ‰ªäÂõû„ÅØGemini Diffusion„ÅÆÁôªÂ†¥„Çí„Åç„Å£„Åã„Åë„Å´ÊúÄËøëË©±È°å„Å´„Å™„Å£„ÅüÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„Å´ËààÂë≥„ÇíÊåÅ„Å°„ÄÅ„Åù„ÅÆ‰∏Ä‰æã„Å®„Åó„Å¶Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆLLaDA„ÅÆÊé®Ë´ñ„ÇíÂÆüÈöõ„Å´ÊâãÂÖÉ„ÅßÁ¢∫Ë™ç„Åó„Å¶„Åø„ÅüÁµêÊûú„Çí [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5850' rel='nofollow'>Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„ÇíÁú∫„ÇÅ„Å¶„Åø„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ‰ªäÂõû„ÅØGemini Diffusion„ÅÆÁôªÂ†¥„Çí„Åç„Å£„Åã„Åë„Å´ÊúÄËøëË©±È°å„Å´„Å™„Å£„ÅüÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„Å´ËààÂë≥„ÇíÊåÅ„Å°„ÄÅ„Åù„ÅÆ‰∏Ä‰æã„Å®„Åó„Å¶Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆLLaDA„ÅÆÊé®Ë´ñ„ÇíÂÆüÈöõ„Å´ÊâãÂÖÉ„ÅßÁ¢∫Ë™ç„Åó„Å¶„Åø„ÅüÁµêÊûú„Çí [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5850' rel='nofollow'>Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„ÇíÁú∫„ÇÅ„Å¶„Åø„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Mon, 02 Jun 2025 00:13:43 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5850",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "Llama 2 is here - get it on Hugging Face",
    "description": "",
    "summary": "Llama 2 is here - get it on Hugging Face Introduction Llama 2 is a family of state-of-the-art open-a...",
    "pubDate": "Tue, 18 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama2",
    "thumbnail": "https://huggingface.co/blog/assets/llama2/thumbnail.jpg"
  },
  {
    "title": "Introducing the Chatbot Guardrails Arena",
    "description": "",
    "summary": "Introducing the Chatbot Guardrails Arena With the recent advancements in augmented LLM capabilities,...",
    "pubDate": "Thu, 21 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-lighthouz",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail_lighthouz.png"
  },
  {
    "title": "Team update",
    "description": "The OpenAI team is now 45 people. Together, we‚Äôre pushing the frontier of AI capabilities‚Äîwhether by validating novel ideas, creating new software systems, or deploying machine learning on robots.",
    "summary": "The OpenAI team is now 45 people. Together, we‚Äôre pushing the frontier of AI capabilities‚Äîwhether by validating novel ideas, creating new software systems, or deploying machine learning on robots.",
    "pubDate": "Mon, 30 Jan 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update-january",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcoming Llama Guard 4 on Hugging Face Hub",
    "description": "",
    "summary": "Welcoming Llama Guard 4 on Hugging Face Hub TL;DR: Today, Meta releases Llama Guard 4, a 12B dense (...",
    "pubDate": "Tue, 29 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama-guard-4",
    "thumbnail": "https://huggingface.co/blog/assets/llama-guard-4/thumbnail.png"
  },
  {
    "title": "Introducing Spaces Dev Mode for a seamless developer experience",
    "description": "",
    "summary": "Introducing Spaces Dev Mode for a seamless developer experience Hugging Face Spaces makes it easy fo...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spaces-dev-mode",
    "thumbnail": "https://huggingface.co/blog/assets/spaces-dev-mode/thumbnail.jpg"
  },
  {
    "title": "OpenAI licenses GPT-3 technology to Microsoft",
    "description": "OpenAI has agreed to license GPT-3 to Microsoft for their own products and services.",
    "summary": "OpenAI has agreed to license GPT-3 to Microsoft for their own products and services.",
    "pubDate": "Tue, 22 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-licenses-gpt-3-technology-to-microsoft",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fixing Gradient Accumulation",
    "description": "",
    "summary": "Fixing Gradient Accumulation Our friends at Unsloth shared an issue regarding gradient accumulation ...",
    "pubDate": "Wed, 16 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradient_accumulation",
    "thumbnail": "https://huggingface.co/blog/assets/gradient_accumulation/gradient_accumulation.png"
  },
  {
    "title": "Discovering types for entity disambiguation",
    "description": "We‚Äôve built a system for automatically figuring out which object is meant by a word by having a neural network decide if the word belongs to each of about 100 automatically-discovered ‚Äútypes‚Äù (non-exclusive categories).",
    "summary": "We‚Äôve built a system for automatically figuring out which object is meant by a word by having a neural network decide if the word belongs to each of about 100 automatically-discovered ‚Äútypes‚Äù (non-exclusive categories).",
    "pubDate": "Wed, 07 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/discovering-types-for-entity-disambiguation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Asymmetric actor critic for image-based robot learning",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 18 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/asymmetric-actor-critic-for-image-based-robot-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o1 and new tools for developers",
    "description": "Introducing OpenAI o1, Realtime API improvements, a new fine-tuning method and more for developers.",
    "summary": "Introducing OpenAI o1, Realtime API improvements, a new fine-tuning method and more for developers.",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-and-new-tools-for-developers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Avoiding Catastrophe in Online Learning by Asking for Help",
    "description": "arXiv:2402.08062v5 Announce Type: replace-cross Abstract: Most learning algorithms with formal regret guarantees assume that all mistakes are recoverable and essentially rely on trying all possible behaviors. This approach is problematic when some mistakes are 'catastrophic', i.e., irreparable. We propose an online learning problem where the goal is to minimize the chance of catastrophe. Specifically, we assume that the payoff in each round represents the chance of avoiding catastrophe in that round and try to maximize the product of payoffs (the overall chance of avoiding catastrophe) while allowing a limited number of queries to a mentor. We also assume that the agent can transfer knowledge between similar inputs. We first show that in general, any algorithm either queries the mentor at a linear rate or is nearly guaranteed to cause catastrophe. However, in settings where the mentor policy class is learnable in the standard online model, we provide an algorithm whose regret and rate of querying the mentor both approach 0 as the time horizon grows. Although our focus is the product of payoffs, we provide matching bounds for the typical additive regret. Conceptually, if a policy class is learnable in the absence of catastrophic risk, it is learnable in the presence of catastrophic risk if the agent can ask for help.",
    "summary": "arXiv:2402.08062v5 Announce Type: replace-cross Abstract: Most learning algorithms with formal regret guarantees assume that all mistakes are recoverable and essentially rely on trying all possible behaviors. This approach is problematic when some mistakes are 'catastrophic', i.e., irreparable. We propose an online learning problem where the goal is to minimize the chance of catastrophe. Specifically, we assume that the payoff in each round represents the chance of avoiding catastrophe in that round and try to maximize the product of payoffs (the overall chance of avoiding catastrophe) while allowing a limited number of queries to a mentor. We also assume that the agent can transfer knowledge between similar inputs. We first show that in general, any algorithm either queries the mentor at a linear rate or is nearly guaranteed to cause catastrophe. However, in settings where the mentor policy class is learnable in the standard online model, we provide an algorithm whose regret and rate of querying the mentor both approach 0 as the time horizon grows. Although our focus is the product of payoffs, we provide matching bounds for the typical additive regret. Conceptually, if a policy class is learnable in the absence of catastrophic risk, it is learnable in the presence of catastrophic risk if the agent can ask for help.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2402.08062",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The AI for Science Forum: A new era of discovery",
    "description": "The AI Science Forum highlights AI's present and potential role in revolutionizing scientific discovery and solving global challenges, emphasizing collaboration between the scientific community, policymakers, and industry leaders.",
    "summary": "The AI Science Forum highlights AI's present and potential role in revolutionizing scientific discovery and solving global challenges, emphasizing collaboration between the scientific community, policymakers, and industry leaders.",
    "pubDate": "Mon, 18 Nov 2024 19:57:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/the-ai-for-science-forum-a-new-era-of-discovery/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AIFS_Collection_SS.max-1440x810.jpg"
  },
  {
    "title": "OpenAI‚Äôs Raising Concerns Policy",
    "description": "We‚Äôre publishing our Raising Concerns Policy, which protects employees‚Äô rights to make protected disclosures.",
    "summary": "We‚Äôre publishing our Raising Concerns Policy, which protects employees‚Äô rights to make protected disclosures.",
    "pubDate": "Fri, 04 Oct 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-raising-concerns-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Inception Labs„ÅÆÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÇíË©¶„Åó„Å¶„Åø„Åü",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Êú¨Ë®ò‰∫ã„Åß„ÅØInception Labs„ÅÆMercury API„ÅÆ„Éô„Éº„ÇøÁâà„Åå‰Ωø„Åà„Çã„Çà„ÅÜ„Å´„Å™„Å£„Åü„ÅÆ„Åß„ÄÅÁ∞°Âçò„Å´Ë©¶„Åó„Å¶„Åø„Åæ„Åó„Åü„ÄÇ „Éâ„Ç≠„É•„É°„É≥„Éà„ÅØ„Åì„Å°„Çâ„ÅßÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ Êã°Êï£Ë®ÄË™û„É¢„Éá„É´ ÁèæÂú®„ÅÆ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5738' rel='nofollow'>Inception Labs„ÅÆÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÇíË©¶„Åó„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Êú¨Ë®ò‰∫ã„Åß„ÅØInception Labs„ÅÆMercury API„ÅÆ„Éô„Éº„ÇøÁâà„Åå‰Ωø„Åà„Çã„Çà„ÅÜ„Å´„Å™„Å£„Åü„ÅÆ„Åß„ÄÅÁ∞°Âçò„Å´Ë©¶„Åó„Å¶„Åø„Åæ„Åó„Åü„ÄÇ „Éâ„Ç≠„É•„É°„É≥„Éà„ÅØ„Åì„Å°„Çâ„ÅßÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ Êã°Êï£Ë®ÄË™û„É¢„Éá„É´ ÁèæÂú®„ÅÆ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5738' rel='nofollow'>Inception Labs„ÅÆÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÇíË©¶„Åó„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Thu, 01 May 2025 03:02:11 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5738",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "AI and efficiency",
    "description": "We‚Äôre releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet¬†classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet¬†(by contrast, Moore‚Äôs Law¬†would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware¬†efficiency.",
    "summary": "We‚Äôre releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet¬†classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet¬†(by contrast, Moore‚Äôs Law¬†would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware¬†efficiency.",
    "pubDate": "Tue, 05 May 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-and-efficiency",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerated Portfolio Optimization and Option Pricing with Reinforcement Learning",
    "description": "arXiv:2507.01972v1 Announce Type: cross Abstract: We present a reinforcement learning (RL)-driven framework for optimizing block-preconditioner sizes in iterative solvers used in portfolio optimization and option pricing. The covariance matrix in portfolio optimization or the discretization of differential operators in option pricing models lead to large linear systems of the form $mathbf{A}textbf{x}=textbf{b}$. Direct inversion of high-dimensional portfolio or fine-grid option pricing incurs a significant computational cost. Therefore, iterative methods are usually used for portfolios in real-world situations. Ill-conditioned systems, however, suffer from slow convergence. Traditional preconditioning techniques often require problem-specific parameter tuning. To overcome this limitation, we rely on RL to dynamically adjust the block-preconditioner sizes and accelerate iterative solver convergence. Evaluations on a suite of real-world portfolio optimization matrices demonstrate that our RL framework can be used to adjust preconditioning and significantly accelerate convergence and reduce computational cost. The proposed accelerated solver supports faster decision-making in dynamic portfolio allocation and real-time option pricing.",
    "summary": "arXiv:2507.01972v1 Announce Type: cross Abstract: We present a reinforcement learning (RL)-driven framework for optimizing block-preconditioner sizes in iterative solvers used in portfolio optimization and option pricing. The covariance matrix in portfolio optimization or the discretization of differential operators in option pricing models lead to large linear systems of the form $mathbf{A}textbf{x}=textbf{b}$. Direct inversion of high-dimensional portfolio or fine-grid option pricing incurs a significant computational cost. Therefore, iterative methods are usually used for portfolios in real-world situations. Ill-conditioned systems, however, suffer from slow convergence. Traditional preconditioning techniques often require problem-specific parameter tuning. To overcome this limitation, we rely on RL to dynamically adjust the block-preconditioner sizes and accelerate iterative solver convergence. Evaluations on a suite of real-world portfolio optimization matrices demonstrate that our RL framework can be used to adjust preconditioning and significantly accelerate convergence and reduce computational cost. The proposed accelerated solver supports faster decision-making in dynamic portfolio allocation and real-time option pricing.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01972",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Building a data-driven, efficient culture with AI",
    "description": "Holiday Extras rolls out ChatGPT Enterprise across every team, boosting productivity by 500 hours weekly.",
    "summary": "Holiday Extras rolls out ChatGPT Enterprise across every team, boosting productivity by 500 hours weekly.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/holiday-extras",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating fairness in ChatGPT",
    "description": "We've analyzed how ChatGPT responds to users based on their name, using AI research assistants to protect privacy.",
    "summary": "We've analyzed how ChatGPT responds to users based on their name, using AI research assistants to protect privacy.",
    "pubDate": "Tue, 15 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evaluating-fairness-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "We Raised $100 Million for Open & Collaborative Machine Learning üöÄ",
    "description": "",
    "summary": "We Raised $100 Million for Open & Collaborative Machine Learning üöÄ Today we have some exciting news ...",
    "pubDate": "Mon, 09 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/series-c",
    "thumbnail": "https://huggingface.co/blog/assets/65_series_c/thumbnail.jpg"
  },
  {
    "title": "New commission to provide insight as OpenAI builds the world‚Äôs best-equipped nonprofit",
    "description": "Already a nonprofit, and already using AI to help people solve hard problems, OpenAI aims to build the best-equipped nonprofit the world has ever seen‚Äîcombining potentially historic financial resources with something even more powerful: technology that can scale human ingenuity itself.",
    "summary": "Already a nonprofit, and already using AI to help people solve hard problems, OpenAI aims to build the best-equipped nonprofit the world has ever seen‚Äîcombining potentially historic financial resources with something even more powerful: technology that can scale human ingenuity itself.",
    "pubDate": "Wed, 02 Apr 2025 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonprofit-commission-guidance",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Enabling a Data-Driven Workforce",
    "description": "In this video, we share practical examples of how employees can use ChatGPT Enterprise to efficiently analyze data and uncover insights.",
    "summary": "In this video, we share practical examples of how employees can use ChatGPT Enterprise to efficiently analyze data and uncover insights.",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/enabling-a-data-driven-workforce-webinar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A catalogue of genetic mutations to help pinpoint the cause of diseases",
    "description": "New AI tool classifies the effects of 71 million ‚Äòmissense‚Äô mutations.",
    "summary": "New AI tool classifies the effects of 71 million ‚Äòmissense‚Äô mutations.",
    "pubDate": "Tue, 19 Sep 2023 13:37:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/a-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases/",
    "thumbnail": "https://lh3.googleusercontent.com/JySjDTZvGqEzUfDic5QOU6Rne3r6RWpiw5JZQ9VdzK1O5C20EbAkSPURGoCmAhea_U-gyyRu4KdCZmeWSCtYjGHHMvM0jVK5fWiqOwa0rpcC5uzM=w1200-h630-n-nu"
  },
  {
    "title": "Fast and Simplex: 2-Simplicial Attention in Triton",
    "description": "arXiv:2507.02754v1 Announce Type: cross Abstract: Recent work has shown that training loss scales as a power law with both model size and the number of tokens, and that achieving compute-optimal models requires scaling model size and token count together. However, these scaling laws assume an infinite supply of data and apply primarily in compute-bound settings. As modern large language models increasingly rely on massive internet-scale datasets, the assumption that they are compute-bound is becoming less valid. This shift highlights the need for architectures that prioritize token efficiency. In this work, we investigate the use of the 2-simplicial Transformer, an architecture that generalizes standard dot-product attention to trilinear functions through an efficient Triton kernel implementation. We demonstrate that the 2-simplicial Transformer achieves better token efficiency than standard Transformers: for a fixed token budget, similarly sized models outperform their dot-product counterparts on tasks involving mathematics, coding, reasoning, and logic. We quantify these gains by demonstrating that $2$-simplicial attention changes the exponent in the scaling laws for knowledge and reasoning tasks compared to dot product attention.",
    "summary": "arXiv:2507.02754v1 Announce Type: cross Abstract: Recent work has shown that training loss scales as a power law with both model size and the number of tokens, and that achieving compute-optimal models requires scaling model size and token count together. However, these scaling laws assume an infinite supply of data and apply primarily in compute-bound settings. As modern large language models increasingly rely on massive internet-scale datasets, the assumption that they are compute-bound is becoming less valid. This shift highlights the need for architectures that prioritize token efficiency. In this work, we investigate the use of the 2-simplicial Transformer, an architecture that generalizes standard dot-product attention to trilinear functions through an efficient Triton kernel implementation. We demonstrate that the 2-simplicial Transformer achieves better token efficiency than standard Transformers: for a fixed token budget, similarly sized models outperform their dot-product counterparts on tasks involving mathematics, coding, reasoning, and logic. We quantify these gains by demonstrating that $2$-simplicial attention changes the exponent in the scaling laws for knowledge and reasoning tasks compared to dot product attention.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02754",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing HuggingFace blog for Chinese speakers: Fostering Collaboration with the Chinese AI community",
    "description": "",
    "summary": "Introducing HuggingFace blog for Chinese speakers: Fostering Collaboration with the Chinese AI commu...",
    "pubDate": "Mon, 24 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chinese-language-blog",
    "thumbnail": "https://huggingface.co/blog/assets/chinese-language-blog/thumbnail.png"
  },
  {
    "title": "Training CodeParrot ü¶ú from Scratch",
    "description": "",
    "summary": "Training CodeParrot ü¶ú from Scratch In this blog post we'll take a look at what it takes to build the...",
    "pubDate": "Wed, 08 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codeparrot",
    "thumbnail": "https://huggingface.co/blog/assets/40_codeparrot/thumbnail.png"
  },
  {
    "title": "Introducing Gemini 2.5 Flash",
    "description": "Gemini 2.5 Flash is our first fully hybrid reasoning model, giving developers the ability to turn thinking on or off.",
    "summary": "Gemini 2.5 Flash is our first fully hybrid reasoning model, giving developers the ability to turn thinking on or off.",
    "pubDate": "Thu, 17 Apr 2025 19:02:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-2-5-flash/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini-2-5-Flash-ai.dev.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Report from the self-organizing conference",
    "description": "Last week we hosted over a hundred and fifty AI practitioners in our offices for our first self-organizing conference on machine learning.",
    "summary": "Last week we hosted over a hundred and fifty AI practitioners in our offices for our first self-organizing conference on machine learning.",
    "pubDate": "Thu, 13 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/report-from-the-self-organizing-conference",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Toward understanding and preventing misalignment generalization",
    "description": "We study how training on incorrect responses can cause broader misalignment in language models and identify an internal feature driving this behavior‚Äîone that can be reversed with minimal fine-tuning.",
    "summary": "We study how training on incorrect responses can cause broader misalignment in language models and identify an internal feature driving this behavior‚Äîone that can be reversed with minimal fine-tuning.",
    "pubDate": "Wed, 18 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergent-misalignment",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LLMs factor in unrelated information when recommending medical treatments",
    "description": "Researchers find nonclinical information in patient messages ‚Äî like typos, extra white space, and colorful language ‚Äî reduces the accuracy of an AI model.",
    "summary": "Researchers find nonclinical information in patient messages ‚Äî like typos, extra white space, and colorful language ‚Äî reduces the accuracy of an AI model.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/llms-factor-unrelated-information-when-recommending-medical-treatments-0623",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_Medium-Message-01-press.jpg"
  },
  {
    "title": "Concrete AI safety problems",
    "description": "We (along with researchers from Berkeley and Stanford) are co-authors on today‚Äôs paper led by Google Brain researchers,¬†Concrete Problems in AI Safety. The paper explores many research problems around ensuring that modern machine learning systems operate as intended.",
    "summary": "We (along with researchers from Berkeley and Stanford) are co-authors on today‚Äôs paper led by Google Brain researchers,¬†Concrete Problems in AI Safety. The paper explores many research problems around ensuring that modern machine learning systems operate as intended.",
    "pubDate": "Tue, 21 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/concrete-ai-safety-problems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Holistic Continual Learning under Concept Drift with Adaptive Memory Realignment",
    "description": "arXiv:2507.02310v1 Announce Type: cross Abstract: Traditional continual learning methods prioritize knowledge retention and focus primarily on mitigating catastrophic forgetting, implicitly assuming that the data distribution of previously learned tasks remains static. This overlooks the dynamic nature of real-world data streams, where concept drift permanently alters previously seen data and demands both stability and rapid adaptation. We introduce a holistic framework for continual learning under concept drift that simulates realistic scenarios by evolving task distributions. As a baseline, we consider Full Relearning (FR), in which the model is retrained from scratch on newly labeled samples from the drifted distribution. While effective, this approach incurs substantial annotation and computational overhead. To address these limitations, we propose Adaptive Memory Realignment (AMR), a lightweight alternative that equips rehearsal-based learners with a drift-aware adaptation mechanism. AMR selectively removes outdated samples of drifted classes from the replay buffer and repopulates it with a small number of up-to-date instances, effectively realigning memory with the new distribution. This targeted resampling matches the performance of FR while reducing the need for labeled data and computation by orders of magnitude. To enable reproducible evaluation, we introduce four concept-drift variants of standard vision benchmarks: Fashion-MNIST-CD, CIFAR10-CD, CIFAR100-CD, and Tiny-ImageNet-CD, where previously seen classes reappear with shifted representations. Comprehensive experiments on these datasets using several rehearsal-based baselines show that AMR consistently counters concept drift, maintaining high accuracy with minimal overhead. These results position AMR as a scalable solution that reconciles stability and plasticity in non-stationary continual learning environments.",
    "summary": "arXiv:2507.02310v1 Announce Type: cross Abstract: Traditional continual learning methods prioritize knowledge retention and focus primarily on mitigating catastrophic forgetting, implicitly assuming that the data distribution of previously learned tasks remains static. This overlooks the dynamic nature of real-world data streams, where concept drift permanently alters previously seen data and demands both stability and rapid adaptation. We introduce a holistic framework for continual learning under concept drift that simulates realistic scenarios by evolving task distributions. As a baseline, we consider Full Relearning (FR), in which the model is retrained from scratch on newly labeled samples from the drifted distribution. While effective, this approach incurs substantial annotation and computational overhead. To address these limitations, we propose Adaptive Memory Realignment (AMR), a lightweight alternative that equips rehearsal-based learners with a drift-aware adaptation mechanism. AMR selectively removes outdated samples of drifted classes from the replay buffer and repopulates it with a small number of up-to-date instances, effectively realigning memory with the new distribution. This targeted resampling matches the performance of FR while reducing the need for labeled data and computation by orders of magnitude. To enable reproducible evaluation, we introduce four concept-drift variants of standard vision benchmarks: Fashion-MNIST-CD, CIFAR10-CD, CIFAR100-CD, and Tiny-ImageNet-CD, where previously seen classes reappear with shifted representations. Comprehensive experiments on these datasets using several rehearsal-based baselines show that AMR consistently counters concept drift, maintaining high accuracy with minimal overhead. These results position AMR as a scalable solution that reconciles stability and plasticity in non-stationary continual learning environments.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02310",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How to host a Unity game in a Space",
    "description": "",
    "summary": "How to host a Unity game in a Space Did you know you can host a Unity game in a Hugging Face Space? ...",
    "pubDate": "Fri, 21 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-in-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-in-spaces-thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT Enterprise",
    "description": "Get enterprise-grade security & privacy and the most powerful version of ChatGPT yet.",
    "summary": "Get enterprise-grade security & privacy and the most powerful version of ChatGPT yet.",
    "pubDate": "Mon, 28 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Êó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶Âàù„ÄÅÊù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅåNVIDIA DGX„ÅÆAI„Çπ„Éë„Ç≥„É≥„ÇíÊßãÁØâ„ÄÇ„ÄåAIÂ§ßÂ≠¶„ÄçÊßãÊÉ≥„ÇíÂä†ÈÄü",
    "description": "<p>Êù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅØ„ÄÅAIÊïôËÇ≤„Å®Á†îÁ©∂„ÇíÂä†ÈÄü„Åï„Åõ„Çã„Åü„ÇÅ„ÄÅNVIDIA DGX B200„Ç∑„Çπ„ÉÜ„É†„ÇíÁî®„ÅÑ„ÅüÊó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶ÊúÄÂ§ß„ÅÆAI„Çπ„Éº„Éë„Éº„Ç≥„É≥„Éî„É•„Éº„Çø„Éº„ÇíÊßãÁØâ„Åó„ÄÅ2025Âπ¥10Êúà„Å´Êú¨Ê†ºÁ®ºÂÉç‰∫àÂÆö„Åß„Åô„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Êù±‰∫¨Â∑•Áßë [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/teu-ac-nvidia-dgx/'>Êó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶Âàù„ÄÅÊù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅåNVIDIA DGX„ÅÆAI„Çπ„Éë„Ç≥„É≥„ÇíÊßãÁØâ„ÄÇ„ÄåAIÂ§ßÂ≠¶„ÄçÊßãÊÉ≥„ÇíÂä†ÈÄü</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>Êù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅØ„ÄÅAIÊïôËÇ≤„Å®Á†îÁ©∂„ÇíÂä†ÈÄü„Åï„Åõ„Çã„Åü„ÇÅ„ÄÅNVIDIA DGX B200„Ç∑„Çπ„ÉÜ„É†„ÇíÁî®„ÅÑ„ÅüÊó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶ÊúÄÂ§ß„ÅÆAI„Çπ„Éº„Éë„Éº„Ç≥„É≥„Éî„É•„Éº„Çø„Éº„ÇíÊßãÁØâ„Åó„ÄÅ2025Âπ¥10Êúà„Å´Êú¨Ê†ºÁ®ºÂÉç‰∫àÂÆö„Åß„Åô„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Êù±‰∫¨Â∑•Áßë [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/teu-ac-nvidia-dgx/'>Êó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶Âàù„ÄÅÊù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅåNVIDIA DGX„ÅÆAI„Çπ„Éë„Ç≥„É≥„ÇíÊßãÁØâ„ÄÇ„ÄåAIÂ§ßÂ≠¶„ÄçÊßãÊÉ≥„ÇíÂä†ÈÄü</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Wed, 25 Jun 2025 09:24:03 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/teu-ac-nvidia-dgx/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/teu0.png"
  },
  {
    "title": "LLM„ÅßÊåë„ÇÄTitanicÁîüÂ≠ò‰∫àÊ∏¨: Few-Shot Leaning„ÅßË°®ÂΩ¢Âºè„Éá„Éº„Çø„ÅØ„Å©„Åì„ÅæËß£„Åë„ÇãÔºü",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Kaggle„ÅÆTitanic„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ„ÄÅÊ©üÊ¢∞Â≠¶Áøí„ÅÆÂÖ•ÈñÄ„Å®„Åó„Å¶ÂÆöÁï™„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ Â§ö„Åè„ÅÆÊ©üÊ¢∞Â≠¶ÁøíÊâãÊ≥ï„ÅåË©¶„Åï„Çå„Å¶„Åç„Åü„Åì„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´ÂØæ„Åó„ÄÅ‰ªäÂõû„ÅØÂ∞ë„ÅóÁï∞„Å™„Çã„Ç¢„Éó„É≠„Éº„ÉÅ„ÇíË©¶„Åø„Åü„ÅÑ„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5560' rel='nofollow'>LLM„ÅßÊåë„ÇÄTitanicÁîüÂ≠ò‰∫àÊ∏¨: Few-Shot Leaning„ÅßË°®ÂΩ¢Âºè„Éá„Éº„Çø„ÅØ„Å©„Åì„ÅæËß£„Åë„ÇãÔºü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Kaggle„ÅÆTitanic„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ„ÄÅÊ©üÊ¢∞Â≠¶Áøí„ÅÆÂÖ•ÈñÄ„Å®„Åó„Å¶ÂÆöÁï™„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ Â§ö„Åè„ÅÆÊ©üÊ¢∞Â≠¶ÁøíÊâãÊ≥ï„ÅåË©¶„Åï„Çå„Å¶„Åç„Åü„Åì„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´ÂØæ„Åó„ÄÅ‰ªäÂõû„ÅØÂ∞ë„ÅóÁï∞„Å™„Çã„Ç¢„Éó„É≠„Éº„ÉÅ„ÇíË©¶„Åø„Åü„ÅÑ„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5560' rel='nofollow'>LLM„ÅßÊåë„ÇÄTitanicÁîüÂ≠ò‰∫àÊ∏¨: Few-Shot Leaning„ÅßË°®ÂΩ¢Âºè„Éá„Éº„Çø„ÅØ„Å©„Åì„ÅæËß£„Åë„ÇãÔºü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Mon, 17 Mar 2025 21:16:00 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5560",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/f81fd2e4c52864042852c112ce927ae2.png"
  },
  {
    "title": "Achieving 10x growth with agentic sales prospecting",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Jun 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/clay",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New funding to build towards AGI",
    "description": "Today we‚Äôre announcing new funding‚Äî$40B at a $300B post-money valuation, which enables us to push the frontiers of AI research even further, scale our compute infrastructure, and deliver increasingly powerful tools for the 500 million people who use ChatGPT every week.",
    "summary": "Today we‚Äôre announcing new funding‚Äî$40B at a $300B post-money valuation, which enables us to push the frontiers of AI research even further, scale our compute infrastructure, and deliver increasingly powerful tools for the 500 million people who use ChatGPT every week.",
    "pubDate": "Mon, 31 Mar 2025 15:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/march-funding-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DolphinGemma: How Google AI is helping decode dolphin communication",
    "description": "DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate ‚Äî and hopefully find out what they're saying, too.",
    "summary": "DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate ‚Äî and hopefully find out what they're saying, too.",
    "pubDate": "Mon, 14 Apr 2025 17:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/dolphingemma-how-google-ai-is-helping-decode-dolphin-communication/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_SocialExplainers_16x9_DolphinGem.width-1300.png"
  },
  {
    "title": "Scaling security with responsible disclosure",
    "description": "OpenAI introduces its Outbound Coordinated Disclosure Policy to guide how it responsibly reports vulnerabilities in third-party software‚Äîemphasizing integrity, collaboration, and proactive security at scale.",
    "summary": "OpenAI introduces its Outbound Coordinated Disclosure Policy to guide how it responsibly reports vulnerabilities in third-party software‚Äîemphasizing integrity, collaboration, and proactive security at scale.",
    "pubDate": "Mon, 09 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-coordinated-vulnerability-disclosure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fanatics Betting and Gaming uses AI to focus on the big picture",
    "description": "A conversation with Andrea Ellis, Chief Financial Officer of Fanatics Betting and Gaming.",
    "summary": "A conversation with Andrea Ellis, Chief Financial Officer of Fanatics Betting and Gaming.",
    "pubDate": "Thu, 13 Feb 2025 10:01:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fanatics-betting-gaming-andrea-ellis",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Prompt Caching in the API",
    "description": "Offering automatic discounts on inputs that the model has recently seen",
    "summary": "Offering automatic discounts on inputs that the model has recently seen",
    "pubDate": "Tue, 01 Oct 2024 10:03:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-prompt-caching",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Domain randomization and generative models for robotic grasping",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 17 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/domain-randomization-and-generative-models-for-robotic-grasping",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling laws for reward model overoptimization",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 19 Oct 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-laws-for-reward-model-overoptimization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine tuning CLIP with Remote Sensing (Satellite) images and captions",
    "description": "",
    "summary": "Fine tuning CLIP with Remote Sensing (Satellite) images and captions Fine tuning CLIP with Remote Se...",
    "pubDate": "Wed, 13 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-clip-rsicd",
    "thumbnail": "https://huggingface.co/blog/assets/30_clip_rsicd/clip_schematic.png"
  },
  {
    "title": "Frontier AI regulation: Managing emerging risks to public safety",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 06 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-ai-regulation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Review completed & Altman, Brockman to continue to lead OpenAI",
    "description": "New board members named and enhancements to the governance structure introduced",
    "summary": "New board members named and enhancements to the governance structure introduced",
    "pubDate": "Fri, 08 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/review-completed-altman-brockman-to-continue-to-lead-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating PyTorch distributed fine-tuning with Intel technologies",
    "description": "",
    "summary": "Accelerating PyTorch distributed fine-tuning with Intel technologies For all their amazing performan...",
    "pubDate": "Fri, 19 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerating-pytorch",
    "thumbnail": "https://huggingface.co/blog/assets/36_accelerating_pytorch/04_four_nodes.png"
  },
  {
    "title": "Building an early warning system for LLM-aided biological threat creation",
    "description": "We‚Äôre developing a blueprint for evaluating the risk that a large language model (LLM) could aid someone in creating a biological threat.¬†In an evaluation involving both biology experts and students, we found that GPT-4 provides at most a mild uplift in biological threat creation accuracy. While this uplift is not large enough to be conclusive, our finding is a starting point for continued research and community deliberation.",
    "summary": "We‚Äôre developing a blueprint for evaluating the risk that a large language model (LLM) could aid someone in creating a biological threat.¬†In an evaluation involving both biology experts and students, we found that GPT-4 provides at most a mild uplift in biological threat creation accuracy. While this uplift is not large enough to be conclusive, our finding is a starting point for continued research and community deliberation.",
    "pubDate": "Wed, 31 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/building-an-early-warning-system-for-llm-aided-biological-threat-creation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CyberRAG: An agentic RAG cyber attack classification and reporting tool",
    "description": "arXiv:2507.02424v1 Announce Type: cross Abstract: Intrusion Detection and Prevention Systems (IDS/IPS) in large enterprises can generate hundreds of thousands of alerts per hour, overwhelming security analysts with logs that demand deep, rapidly evolving domain expertise. Conventional machine-learning detectors trim the alert volume but still yield high false-positive rates, while standard single-pass Retrieval-Augmented Generation (RAG) pipelines often retrieve irrelevant context and fail to justify their predictions. To overcome these shortcomings, we present CyberRAG, a modular, agent-based RAG framework that delivers real-time classification, explanation, and structured reporting for cyber-attacks. A central LLM agent orchestrates (i) a pool of fine-tuned specialized classifiers, each tailored to a distinct attack family; (ii) tool adapters for enrichment and alerting; and (iii) an iterative retrieval-and-reason loop that continuously queries a domain-specific knowledge base until the evidence is both relevant and self-consistent. Unlike traditional RAG systems, CyberRAG embraces an agentic design that enables dynamic control flow and adaptive reasoning. This agent-centric architecture refines its threat labels and natural-language justifications autonomously, reducing false positives and enhancing interpretability. The framework is fully extensible: new attack types can be supported by simply adding a classifier without retraining the core agent. CyberRAG has been evaluated achieving over 94% accuracy per class and pushing final classification accuracy to 94.92% through semantic orchestration. Generated explanations score up to 0.94 in BERTScore and 4.9/5 in GPT-4-based expert evaluation. These results show that agentic, specialist-oriented RAG can pair high detection accuracy with trustworthy, SOC-ready prose, offering a practical and scalable path toward semi-autonomous cyber-defence workflows.",
    "summary": "arXiv:2507.02424v1 Announce Type: cross Abstract: Intrusion Detection and Prevention Systems (IDS/IPS) in large enterprises can generate hundreds of thousands of alerts per hour, overwhelming security analysts with logs that demand deep, rapidly evolving domain expertise. Conventional machine-learning detectors trim the alert volume but still yield high false-positive rates, while standard single-pass Retrieval-Augmented Generation (RAG) pipelines often retrieve irrelevant context and fail to justify their predictions. To overcome these shortcomings, we present CyberRAG, a modular, agent-based RAG framework that delivers real-time classification, explanation, and structured reporting for cyber-attacks. A central LLM agent orchestrates (i) a pool of fine-tuned specialized classifiers, each tailored to a distinct attack family; (ii) tool adapters for enrichment and alerting; and (iii) an iterative retrieval-and-reason loop that continuously queries a domain-specific knowledge base until the evidence is both relevant and self-consistent. Unlike traditional RAG systems, CyberRAG embraces an agentic design that enables dynamic control flow and adaptive reasoning. This agent-centric architecture refines its threat labels and natural-language justifications autonomously, reducing false positives and enhancing interpretability. The framework is fully extensible: new attack types can be supported by simply adding a classifier without retraining the core agent. CyberRAG has been evaluated achieving over 94% accuracy per class and pushing final classification accuracy to 94.92% through semantic orchestration. Generated explanations score up to 0.94 in BERTScore and 4.9/5 in GPT-4-based expert evaluation. These results show that agentic, specialist-oriented RAG can pair high detection accuracy with trustworthy, SOC-ready prose, offering a practical and scalable path toward semi-autonomous cyber-defence workflows.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02424",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FunSearch: Making new discoveries in mathematical sciences using Large Language Models",
    "description": "In a paper published in Nature, we introduce FunSearch, a method for searching for ‚Äúfunctions‚Äù written in computer code, and find new solutions in mathematics and computer science. FunSearch works by pairing a pre-trained LLM, whose goal is to provide creative solutions in the form of computer code, with an automated ‚Äúevaluator‚Äù, which guards against hallucinations and incorrect ideas.",
    "summary": "In a paper published in Nature, we introduce FunSearch, a method for searching for ‚Äúfunctions‚Äù written in computer code, and find new solutions in mathematics and computer science. FunSearch works by pairing a pre-trained LLM, whose goal is to provide creative solutions in the form of computer code, with an automated ‚Äúevaluator‚Äù, which guards against hallucinations and incorrect ideas.",
    "pubDate": "Thu, 14 Dec 2023 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/GC6SH0u6DyyCT9C1LH6XXmproSod7o5QGp9-Oe8BsuXyPzBlfcxFHX9pxXg69ZftEVU0Joga7tyo0VwQOSBBrugZ8qfl9_X-pgiH527p71S7DC32Jw=w1200-h630-n-nu"
  },
  {
    "title": "Procgen and MineRL Competitions",
    "description": "We‚Äôre excited to announce that OpenAI is co-organizing two NeurIPS 2020 competitions with AIcrowd, Carnegie Mellon University, and DeepMind, using Procgen Benchmark and MineRL.",
    "summary": "We‚Äôre excited to announce that OpenAI is co-organizing two NeurIPS 2020 competitions with AIcrowd, Carnegie Mellon University, and DeepMind, using Procgen Benchmark and MineRL.",
    "pubDate": "Sat, 20 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/procgen-minerl-competitions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Streamlining financial solutions for safety and growth",
    "description": "Stripe leverages GPT-4 to streamline user experience and combat fraud.",
    "summary": "Stripe leverages GPT-4 to streamline user experience and combat fraud.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/stripe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PaliGemma ‚Äì Google's Cutting-Edge Open Vision Language Model",
    "description": "",
    "summary": "PaliGemma ‚Äì Google's Cutting-Edge Open Vision Language Model Updated on 23-05-2024: We have introduc...",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma/Paligemma.png"
  },
  {
    "title": "Introducing Activation Atlases",
    "description": "We‚Äôve created¬†activation atlases¬†(in¬†collaboration¬†with Google researchers), a new technique for visualizing what interactions between neurons can represent. As AI systems are deployed in increasingly sensitive contexts, having a better understanding of their internal decision-making processes will let us identify weaknesses and investigate¬†failures.",
    "summary": "We‚Äôve created¬†activation atlases¬†(in¬†collaboration¬†with Google researchers), a new technique for visualizing what interactions between neurons can represent. As AI systems are deployed in increasingly sensitive contexts, having a better understanding of their internal decision-making processes will let us identify weaknesses and investigate¬†failures.",
    "pubDate": "Wed, 06 Mar 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-activation-atlases",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing ChatGPT",
    "description": "We‚Äôve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.",
    "summary": "We‚Äôve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.",
    "pubDate": "Wed, 30 Nov 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement",
    "description": "arXiv:2507.02252v1 Announce Type: cross Abstract: Precise surgical interventions are vital to patient safety, and advanced enhancement algorithms have been developed to assist surgeons in decision-making. Despite significant progress, these algorithms are typically designed for single tasks in specific scenarios, limiting their effectiveness in complex real-world situations. To address this limitation, we propose SurgVisAgent, an end-to-end intelligent surgical vision agent built on multimodal large language models (MLLMs). SurgVisAgent dynamically identifies distortion categories and severity levels in endoscopic images, enabling it to perform a variety of enhancement tasks such as low-light enhancement, overexposure correction, motion blur elimination, and smoke removal. Specifically, to achieve superior surgical scenario understanding, we design a prior model that provides domain-specific knowledge. Additionally, through in-context few-shot learning and chain-of-thought (CoT) reasoning, SurgVisAgent delivers customized image enhancements tailored to a wide range of distortion types and severity levels, thereby addressing the diverse requirements of surgeons. Furthermore, we construct a comprehensive benchmark simulating real-world surgical distortions, on which extensive experiments demonstrate that SurgVisAgent surpasses traditional single-task models, highlighting its potential as a unified solution for surgical assistance.",
    "summary": "arXiv:2507.02252v1 Announce Type: cross Abstract: Precise surgical interventions are vital to patient safety, and advanced enhancement algorithms have been developed to assist surgeons in decision-making. Despite significant progress, these algorithms are typically designed for single tasks in specific scenarios, limiting their effectiveness in complex real-world situations. To address this limitation, we propose SurgVisAgent, an end-to-end intelligent surgical vision agent built on multimodal large language models (MLLMs). SurgVisAgent dynamically identifies distortion categories and severity levels in endoscopic images, enabling it to perform a variety of enhancement tasks such as low-light enhancement, overexposure correction, motion blur elimination, and smoke removal. Specifically, to achieve superior surgical scenario understanding, we design a prior model that provides domain-specific knowledge. Additionally, through in-context few-shot learning and chain-of-thought (CoT) reasoning, SurgVisAgent delivers customized image enhancements tailored to a wide range of distortion types and severity levels, thereby addressing the diverse requirements of surgeons. Furthermore, we construct a comprehensive benchmark simulating real-world surgical distortions, on which extensive experiments demonstrate that SurgVisAgent surpasses traditional single-task models, highlighting its potential as a unified solution for surgical assistance.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02252",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI for Game Development: Creating a Farming Game in 5 Days. Part 2",
    "description": "",
    "summary": "AI for Game Development: Creating a Farming Game in 5 Days. Part 2 Welcome to AI for Game Developmen...",
    "pubDate": "Mon, 09 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-2",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail2.png"
  },
  {
    "title": "Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU",
    "description": "",
    "summary": "Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU We are excited to officially release the integ...",
    "pubDate": "Thu, 09 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trl-peft",
    "thumbnail": "https://huggingface.co/blog/trl-peft/assets/133_trl_peft/thumbnail.png"
  },
  {
    "title": "Infrastructure for deep learning",
    "description": "Deep learning is an empirical science, and the quality of a group‚Äôs infrastructure is a multiplier on progress. Fortunately, today‚Äôs open-source ecosystem makes it possible for anyone to build great deep learning infrastructure.",
    "summary": "Deep learning is an empirical science, and the quality of a group‚Äôs infrastructure is a multiplier on progress. Fortunately, today‚Äôs open-source ecosystem makes it possible for anyone to build great deep learning infrastructure.",
    "pubDate": "Mon, 29 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/infrastructure-for-deep-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy Meta Llama 3.1 405B on Google Cloud Vertex AI",
    "description": "",
    "summary": "Deploy Meta Llama 3.1 405B on Google Cloud Vertex AI Meta Llama 3.1 is the latest open LLM from Meta...",
    "pubDate": "Mon, 19 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama31-on-vertex-ai",
    "thumbnail": "https://huggingface.co/blog/assets/llama31-on-vertex-ai/thumbnail.png"
  },
  {
    "title": "New tool evaluates progress in reinforcement learning",
    "description": "‚ÄúIntersectionZoo,‚Äù a benchmarking tool, uses a real-world traffic problem to test progress in deep reinforcement learning algorithms.",
    "summary": "‚ÄúIntersectionZoo,‚Äù a benchmarking tool, uses a real-world traffic problem to test progress in deep reinforcement learning algorithms.",
    "pubDate": "Mon, 05 May 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-tool-evaluate-progress-reinforcement-learning-0505",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/Intersection-Zoo.jpg"
  },
  {
    "title": "Train and Fine-Tune Sentence Transformers Models",
    "description": "",
    "summary": "Train and Fine-Tune Sentence Transformers Models This guide is only suited for Sentence Transformers...",
    "pubDate": "Wed, 10 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-train-sentence-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/95_training_st_models/thumbnail.png"
  },
  {
    "title": "Generative language modeling for automated theorem proving",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 07 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generative-language-modeling-for-automated-theorem-proving",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "œÄ0 and œÄ0-FAST: Vision-Language-Action Models for General Robot Control",
    "description": "",
    "summary": "œÄ0 and œÄ0-FAST: Vision-Language-Action Models for General Robot Control We have ported the first rob...",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pi0",
    "thumbnail": "https://huggingface.co/blog/assets/192_pi0/new_thumbnail_pi0.001.png"
  },
  {
    "title": "GraphCast: AI model for faster and more accurate global weather forecasting",
    "description": "We introduce GraphCast, a state-of-the-art AI model able to make medium-range weather forecasts with unprecedented accuracy",
    "summary": "We introduce GraphCast, a state-of-the-art AI model able to make medium-range weather forecasts with unprecedented accuracy",
    "pubDate": "Tue, 14 Nov 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/",
    "thumbnail": "https://lh3.googleusercontent.com/5dL0Cm8RLhoDdfPzVy5MlKB5JDcfYucbgxzNLJVFdtqRe15-bFTvfdOrpqnrM4m5XMEEboWtvyCLQgSCvHEH62QqZZI0V_zuBAz71fghXgU5UNFFwg=w1200-h630-n-nu"
  },
  {
    "title": "Rox goes ‚Äúall in‚Äù on OpenAI",
    "description": "By combining commercial experience and deep LLM expertise with OpenAI‚Äôs models, Rox makes every seller a top 1% seller.",
    "summary": "By combining commercial experience and deep LLM expertise with OpenAI‚Äôs models, Rox makes every seller a top 1% seller.",
    "pubDate": "Tue, 19 Nov 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rox",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Robots that learn",
    "description": "We‚Äôve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can learn a new task after seeing it done once.",
    "summary": "We‚Äôve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can learn a new task after seeing it done once.",
    "pubDate": "Tue, 16 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/robots-that-learn",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing the Hugging Face Fellowship Program",
    "description": "",
    "summary": "Announcing the Hugging Face Fellowship Program The Fellowship is a network of exceptional people fro...",
    "pubDate": "Tue, 17 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fellowship",
    "thumbnail": "https://huggingface.co/blog/assets/62_fellowship/fellowship-thumbnail.png"
  },
  {
    "title": "Prediction and control with temporal segment models",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 12 Mar 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/prediction-and-control-with-temporal-segment-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sam & Jony",
    "description": "Sam & Jony",
    "summary": "Sam & Jony",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/sam-and-jony",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introduction to 3D Gaussian Splatting",
    "description": "",
    "summary": "Introduction to 3D Gaussian Splatting 3D Gaussian Splatting is a rasterization technique described i...",
    "pubDate": "Mon, 18 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gaussian-splatting",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail-gaussian-splatting.png"
  },
  {
    "title": "New tools for building agents",
    "description": "We‚Äôre evolving our platform to help developers and enterprises build useful and reliable agents.",
    "summary": "We‚Äôre evolving our platform to help developers and enterprises build useful and reliable agents.",
    "pubDate": "Tue, 11 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-for-building-agents",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Chatbot on your Laptop: Phi-2 on Intel Meteor Lake",
    "description": "",
    "summary": "A Chatbot on your Laptop: Phi-2 on Intel Meteor Lake Because of their impressive abilities, large la...",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/phi2-intel-meteor-lake",
    "thumbnail": "https://huggingface.co/blog/assets/phi2-intel-meteor-lake/02.jpg"
  },
  {
    "title": "OpenAI partners with Scale to provide support for enterprises fine-tuning models",
    "description": "OpenAI‚Äôs customers can leverage Scale‚Äôs AI expertise to customize our most advanced models.",
    "summary": "OpenAI‚Äôs customers can leverage Scale‚Äôs AI expertise to customize our most advanced models.",
    "pubDate": "Thu, 24 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-partners-with-scale-to-provide-support-for-enterprises-fine-tuning-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Code Llama: Llama 2 learns to code",
    "description": "",
    "summary": "Code Llama: Llama 2 learns to code Introduction Code Llama is a family of state-of-the-art, open-acc...",
    "pubDate": "Fri, 25 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codellama",
    "thumbnail": "https://huggingface.co/blog/assets/160_codellama/thumbnail.jpg"
  },
  {
    "title": "Some considerations on learning to explore via meta-reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 03 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/some-considerations-on-learning-to-explore-via-meta-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI helps John Deere transform agriculture",
    "description": "John Deere‚Äôs Justin Rose talks about transforming agriculture with AI and shares how the company is scaling innovation to help farmers work smarter, more efficiently, and sustainably.",
    "summary": "John Deere‚Äôs Justin Rose talks about transforming agriculture with AI and shares how the company is scaling innovation to help farmers work smarter, more efficiently, and sustainably.",
    "pubDate": "Tue, 06 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/john-deere-justin-rose",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Confronting the AI/energy conundrum",
    "description": "The MIT Energy Initiative‚Äôs annual research symposium explores artificial intelligence as both a problem and a solution for the clean energy transition.",
    "summary": "The MIT Energy Initiative‚Äôs annual research symposium explores artificial intelligence as both a problem and a solution for the clean energy transition.",
    "pubDate": "Wed, 02 Jul 2025 15:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/confronting-ai-energy-conundrum-0702",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MITEI-evelyn-wang.JPG"
  },
  {
    "title": "üß® Diffusers welcomes Stable Diffusion 3.5 Large",
    "description": "",
    "summary": "üß® Diffusers welcomes Stable Diffusion 3.5 Large Stable Diffusion 3.5 is the improved variant of its ...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd3-5",
    "thumbnail": "https://huggingface.co/blog/assets/sd3-5/thumbnail.png"
  },
  {
    "title": "Study shows vision-language models can‚Äôt handle queries with negation words",
    "description": "Words like ‚Äúno‚Äù and ‚Äúnot‚Äù can cause this popular class of AI models to fail unexpectedly in high-stakes settings, such as medical diagnosis.",
    "summary": "Words like ‚Äúno‚Äù and ‚Äúnot‚Äù can cause this popular class of AI models to fail unexpectedly in high-stakes settings, such as medical diagnosis.",
    "pubDate": "Wed, 14 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/study-shows-vision-language-models-cant-handle-negation-words-queries-0514",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-LMNegation-01-press.jpg"
  },
  {
    "title": "Microsoft invests in and partners with OpenAI to support us building beneficial AGI",
    "description": "Microsoft is investing $1 billion in OpenAI to support us building artificial general intelligence (AGI) with widely distributed economic benefits. We‚Äôre partnering to develop a hardware and software platform within Microsoft Azure which will scale to AGI. We‚Äôll jointly develop new Azure AI supercomputing technologies, and Microsoft will become our exclusive cloud provider‚Äîso we‚Äôll be working hard together to further extend Microsoft Azure‚Äôs capabilities in large-scale AI systems.",
    "summary": "Microsoft is investing $1 billion in OpenAI to support us building artificial general intelligence (AGI) with widely distributed economic benefits. We‚Äôre partnering to develop a hardware and software platform within Microsoft Azure which will scale to AGI. We‚Äôll jointly develop new Azure AI supercomputing technologies, and Microsoft will become our exclusive cloud provider‚Äîso we‚Äôll be working hard together to further extend Microsoft Azure‚Äôs capabilities in large-scale AI systems.",
    "pubDate": "Mon, 22 Jul 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/microsoft-invests-in-and-partners-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using transformers, accelerate and bitsandbytes",
    "description": "",
    "summary": "A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using Hugging Face Tr...",
    "pubDate": "Wed, 17 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hf-bitsandbytes-integration",
    "thumbnail": "https://huggingface.co/blog/assets/96_hf_bitsandbytes_integration/Thumbnail_blue.png"
  },
  {
    "title": "ChatGPT can now see, hear, and speak",
    "description": "We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you‚Äôre talking about.",
    "summary": "We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you‚Äôre talking about.",
    "pubDate": "Mon, 25 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-can-now-see-hear-and-speak",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DALL¬∑E 2: Extending creativity",
    "description": "As part of our DALL¬∑E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL¬∑E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL¬∑E and have served as key voices as we‚Äôve made decisions about DALL¬∑E‚Äôs¬†features.",
    "summary": "As part of our DALL¬∑E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL¬∑E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL¬∑E and have served as key voices as we‚Äôve made decisions about DALL¬∑E‚Äôs¬†features.",
    "pubDate": "Thu, 14 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-extending-creativity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interpretable machine learning through teaching",
    "description": "We‚Äôve designed a method that encourages AIs to teach each other with examples that also make sense to humans. Our approach automatically selects the most informative examples to teach a concept‚Äîfor instance, the best images to describe the concept of dogs‚Äîand experimentally we found our approach to be effective at teaching both AIs",
    "summary": "We‚Äôve designed a method that encourages AIs to teach each other with examples that also make sense to humans. Our approach automatically selects the most informative examples to teach a concept‚Äîfor instance, the best images to describe the concept of dogs‚Äîand experimentally we found our approach to be effective at teaching both AIs",
    "pubDate": "Thu, 15 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/interpretable-machine-learning-through-teaching",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Automating customer support agents",
    "description": "MavenAGI is a new software company for the AI era. They recently launched an AI customer service agent, built on the flexibility of GPT-4, which a number of companies like Tripadvisor, Clickup and Rho are already using to save time and better serve their customers.",
    "summary": "MavenAGI is a new software company for the AI era. They recently launched an AI customer service agent, built on the flexibility of GPT-4, which a number of companies like Tripadvisor, Clickup and Rho are already using to save time and better serve their customers.",
    "pubDate": "Wed, 29 May 2024 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mavenagi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deliberative alignment: reasoning enables safer language models",
    "description": "Deliberative alignment: reasoning enables safer language models Introducing our new alignment strategy for o1 models, which are directly taught safety specifications and how to reason over them.",
    "summary": "Deliberative alignment: reasoning enables safer language models Introducing our new alignment strategy for o1 models, which are directly taught safety specifications and how to reason over them.",
    "pubDate": "Fri, 20 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deliberative-alignment",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Customizing models for legal professionals",
    "description": "Harvey partners with OpenAI to build a custom-trained model for legal professionals.",
    "summary": "Harvey partners with OpenAI to build a custom-trained model for legal professionals.",
    "pubDate": "Tue, 02 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/harvey",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing next-generation audio models in the API",
    "description": "For the first time, developers can also instruct the text-to-speech model to speak in a specific way‚Äîfor example, ‚Äútalk like a sympathetic customer service agent‚Äù‚Äîunlocking a new level of customization for voice agents.",
    "summary": "For the first time, developers can also instruct the text-to-speech model to speak in a specific way‚Äîfor example, ‚Äútalk like a sympathetic customer service agent‚Äù‚Äîunlocking a new level of customization for voice agents.",
    "pubDate": "Thu, 20 Mar 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-our-next-generation-audio-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Model Safety Behavior with Rule-Based Rewards",
    "description": "We've developed and applied a new method leveraging Rule-Based Rewards (RBRs) that aligns models to behave safely without extensive human data collection.",
    "summary": "We've developed and applied a new method leveraging Rule-Based Rewards (RBRs) that aligns models to behave safely without extensive human data collection.",
    "pubDate": "Wed, 24 Jul 2024 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-model-safety-behavior-with-rule-based-rewards",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2019: Applications open",
    "description": "We are now accepting applications for our second cohort of OpenAI Scholars, a program where we provide 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "summary": "We are now accepting applications for our second cohort of OpenAI Scholars, a program where we provide 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "pubDate": "Thu, 11 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Codex",
    "description": "We‚Äôve created an improved version of OpenAI Codex, our AI system that translates natural language to code, and we are releasing it through our API in private beta starting today.",
    "summary": "We‚Äôve created an improved version of OpenAI Codex, our AI system that translates natural language to code, and we are releasing it through our API in private beta starting today.",
    "pubDate": "Tue, 10 Aug 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-codex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars",
    "description": "We‚Äôre providing 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "summary": "We‚Äôre providing 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "pubDate": "Tue, 06 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "On first-order meta-learning algorithms",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 08 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/on-first-order-meta-learning-algorithms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Training and Finetuning Sparse Embedding Models with Sentence Transformers v5",
    "description": "",
    "summary": "Training and Finetuning Sparse Embedding Models with Sentence Transformers v5 Sentence Transformers ...",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-sparse-encoder",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "Fine-tuning GPT-3 to scale video creation",
    "description": "Fine-tuning GPT-3 to power and scale done-for-you video creation.",
    "summary": "Fine-tuning GPT-3 to power and scale done-for-you video creation.",
    "pubDate": "Tue, 03 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/waymark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 11 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-connection-between-generative-adversarial-networks-inverse-reinforcement-learning-and-energy-based-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "17 Reasons Why Gradio Isn't Just Another UI Library",
    "description": "",
    "summary": "17 Reasons Why Gradio Isn't Just Another UI Library Introduction 'Oh, Gradio? That's a Python librar...",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/why-gradio-stands-out",
    "thumbnail": "https://huggingface.co/blog/assets/why-gradio-stands-out/thumbnail.png"
  },
  {
    "title": "Data Diversification Methods In Alignment Enhance Math Performance In LLMs",
    "description": "arXiv:2507.02173v1 Announce Type: new Abstract: While recent advances in preference learning have enhanced alignment in human feedback, mathematical reasoning remains a persistent challenge. We investigate how data diversification strategies in preference optimization can improve the mathematical reasoning abilities of large language models (LLMs). We evaluate three common data generation methods: temperature sampling, Chain-of-Thought prompting, and Monte Carlo Tree Search (MCTS), and introduce Diversified-ThinkSolve (DTS), a novel structured approach that systematically decomposes problems into diverse reasoning paths. Our results show that with strategically diversified preference data, models can substantially improve mathematical reasoning performance, with the best approach yielding gains of 7.1% on GSM8K and 4.2% on MATH over the base model. Despite its strong performance, DTS incurs only a marginal computational overhead (1.03x) compared to the baseline, while MCTS is nearly five times more costly with lower returns. These findings demonstrate that structured exploration of diverse problem-solving methods creates more effective preference data for mathematical alignment than traditional approaches.",
    "summary": "arXiv:2507.02173v1 Announce Type: new Abstract: While recent advances in preference learning have enhanced alignment in human feedback, mathematical reasoning remains a persistent challenge. We investigate how data diversification strategies in preference optimization can improve the mathematical reasoning abilities of large language models (LLMs). We evaluate three common data generation methods: temperature sampling, Chain-of-Thought prompting, and Monte Carlo Tree Search (MCTS), and introduce Diversified-ThinkSolve (DTS), a novel structured approach that systematically decomposes problems into diverse reasoning paths. Our results show that with strategically diversified preference data, models can substantially improve mathematical reasoning performance, with the best approach yielding gains of 7.1% on GSM8K and 4.2% on MATH over the base model. Despite its strong performance, DTS incurs only a marginal computational overhead (1.03x) compared to the baseline, while MCTS is nearly five times more costly with lower returns. These findings demonstrate that structured exploration of diverse problem-solving methods creates more effective preference data for mathematical alignment than traditional approaches.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.02173",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop",
    "description": "arXiv:2506.23351v2 Announce Type: replace-cross Abstract: Embodied Artificial Intelligence (Embodied AI) is an emerging frontier in robotics, driven by the need for autonomous systems that can perceive, reason, and act in complex physical environments. While single-arm systems have shown strong task performance, collaborative dual-arm systems are essential for handling more intricate tasks involving rigid, deformable, and tactile-sensitive objects. To advance this goal, we launched the RoboTwin Dual-Arm Collaboration Challenge at the 2nd MEIS Workshop, CVPR 2025. Built on the RoboTwin Simulation platform (1.0 and 2.0) and the AgileX COBOT-Magic Robot platform, the competition consisted of three stages: Simulation Round 1, Simulation Round 2, and a final Real-World Round. Participants totally tackled 17 dual-arm manipulation tasks, covering rigid, deformable, and tactile-based scenarios. The challenge attracted 64 global teams and over 400 participants, producing top-performing solutions like SEM and AnchorDP3 and generating valuable insights into generalizable bimanual policy learning. This report outlines the competition setup, task design, evaluation methodology, key findings and future direction, aiming to support future research on robust and generalizable bimanual manipulation policies. The Challenge Webpage is available at https://robotwin-benchmark.github.io/cvpr-2025-challenge/.",
    "summary": "arXiv:2506.23351v2 Announce Type: replace-cross Abstract: Embodied Artificial Intelligence (Embodied AI) is an emerging frontier in robotics, driven by the need for autonomous systems that can perceive, reason, and act in complex physical environments. While single-arm systems have shown strong task performance, collaborative dual-arm systems are essential for handling more intricate tasks involving rigid, deformable, and tactile-sensitive objects. To advance this goal, we launched the RoboTwin Dual-Arm Collaboration Challenge at the 2nd MEIS Workshop, CVPR 2025. Built on the RoboTwin Simulation platform (1.0 and 2.0) and the AgileX COBOT-Magic Robot platform, the competition consisted of three stages: Simulation Round 1, Simulation Round 2, and a final Real-World Round. Participants totally tackled 17 dual-arm manipulation tasks, covering rigid, deformable, and tactile-based scenarios. The challenge attracted 64 global teams and over 400 participants, producing top-performing solutions like SEM and AnchorDP3 and generating valuable insights into generalizable bimanual policy learning. This report outlines the competition setup, task design, evaluation methodology, key findings and future direction, aiming to support future research on robust and generalizable bimanual manipulation policies. The Challenge Webpage is available at https://robotwin-benchmark.github.io/cvpr-2025-challenge/.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23351",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Q&A: A roadmap for revolutionizing health care through data-driven innovation",
    "description": "A new book coauthored by MIT‚Äôs Dimitris Bertsimas explores how analytics is driving decisions and outcomes in health care.",
    "summary": "A new book coauthored by MIT‚Äôs Dimitris Bertsimas explores how analytics is driving decisions and outcomes in health care.",
    "pubDate": "Mon, 05 May 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/qa-roadmap-revolutionizing-health-care-through-data-driven-innovation-0505",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/Analytics-Edge-in-Healthcare-Dimitris-Bertsimas-00.png"
  },
  {
    "title": "Introducing Structured Outputs in the API",
    "description": "We are introducing Structured Outputs in the API‚Äîmodel outputs now reliably adhere to developer-supplied JSON Schemas.",
    "summary": "We are introducing Structured Outputs in the API‚Äîmodel outputs now reliably adhere to developer-supplied JSON Schemas.",
    "pubDate": "Tue, 06 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-structured-outputs-in-the-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Train a Sentence Embedding Model with 1B Training Pairs",
    "description": "",
    "summary": "Train a Sentence Embedding Model with 1 Billion Training Pairs Sentence embedding is a method that m...",
    "pubDate": "Mon, 25 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/1b-sentence-embeddings",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Gym Retro",
    "description": "We‚Äôre releasing the full version of¬†Gym Retro, a platform for reinforcement learning research on games. This brings our publicly-released game count from around 70 Atari games and 30 Sega games to over 1,000 games across a variety of backing emulators. We‚Äôre also releasing the tool we use to add new games to the¬†platform.",
    "summary": "We‚Äôre releasing the full version of¬†Gym Retro, a platform for reinforcement learning research on games. This brings our publicly-released game count from around 70 Atari games and 30 Sega games to over 1,000 games across a variety of backing emulators. We‚Äôre also releasing the tool we use to add new games to the¬†platform.",
    "pubDate": "Fri, 25 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gym-retro",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bringing meaning into technology deployment",
    "description": "The MIT Ethics of Computing Research Symposium showcases projects at the intersection of technology, ethics, and social responsibility.",
    "summary": "The MIT Ethics of Computing Research Symposium showcases projects at the intersection of technology, ethics, and social responsibility.",
    "pubDate": "Wed, 11 Jun 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/bringing-meaning-technology-deployment-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-SERC-Symposium.jpg"
  },
  {
    "title": "AI„ÅÆÊòéÊó•„ÅØ„ÄåÂ§±Êúõ„Äçor„ÄåÂ∏åÊúõ„ÄçÔºü‚îÄ‚îÄApple„Å®„Çµ„É†„Éª„Ç¢„É´„Éà„Éû„É≥„ÅÆ‚Äú2„Å§„ÅÆÊú™Êù•‰∫àÊ∏¨‚Äù„ÄÄ„Åù„ÅÆÊÑèÂë≥„ÇíËÄÉ„Åà„Çã",
    "description": "6Êúà„ÄÅAI„ÅÆÊú™Êù•„Å´Èñ¢„Åô„Çã2„Å§„ÅÆ‰∫àÊ∏¨„Åå„Åï„Çå„Åü„ÄÇÁ±≥Apple„ÅÆÁ†îÁ©∂ËÄÖ„Çâ„ÅåÂü∑Á≠Ü„Åó„ÅüË´ñÊñá„Å®„ÄÅÁ±≥OpenAI„ÅÆ„Çµ„É†„Éª„Ç¢„É´„Éà„Éû„É≥CEO„ÅÆ„Éñ„É≠„Ç∞Ë®ò‰∫ã„Å†„ÄÇ‰ªäÂõû„ÅØ„Åì„ÅÆ2„Å§„ÅÆ‰∏ªÂºµ„ÇíÂèñ„Çä‰∏ä„Åí„ÄÅ„Åù„ÅÆÊÑèÁæ©„Å´„Å§„ÅÑ„Å¶ËÄÉ„Åà„Å¶„Åø„Åü„ÅÑ„ÄÇ",
    "summary": "6Êúà„ÄÅAI„ÅÆÊú™Êù•„Å´Èñ¢„Åô„Çã2„Å§„ÅÆ‰∫àÊ∏¨„Åå„Åï„Çå„Åü„ÄÇÁ±≥Apple„ÅÆÁ†îÁ©∂ËÄÖ„Çâ„ÅåÂü∑Á≠Ü„Åó„ÅüË´ñÊñá„Å®„ÄÅÁ±≥OpenAI„ÅÆ„Çµ„É†„Éª„Ç¢„É´„Éà„Éû„É≥CEO„ÅÆ„Éñ„É≠„Ç∞Ë®ò‰∫ã„Å†„ÄÇ‰ªäÂõû„ÅØ„Åì„ÅÆ2„Å§„ÅÆ‰∏ªÂºµ„ÇíÂèñ„Çä‰∏ä„Åí„ÄÅ„Åù„ÅÆÊÑèÁæ©„Å´„Å§„ÅÑ„Å¶ËÄÉ„Åà„Å¶„Åø„Åü„ÅÑ„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 12:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news035.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news035.jpg"
  },
  {
    "title": "Open-source LLMs as LangChain Agents",
    "description": "",
    "summary": "Open-source LLMs as LangChain Agents TL;DR Open-source LLMs have now reached a performance level tha...",
    "pubDate": "Wed, 24 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-source-llms-as-agents",
    "thumbnail": "https://huggingface.co/blog/assets/open-source-llms-as-agents/thumbnail_open_source_agents.png"
  },
  {
    "title": "Learning to play Minecraft with Video PreTraining",
    "description": "We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model can learn to craft diamond tools, a task that usually takes proficient humans over 20 minutes (24,000 actions). Our model uses the native human interface of keypresses and mouse movements, making it quite general, and represents a step towards general computer-using¬†agents.",
    "summary": "We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model can learn to craft diamond tools, a task that usually takes proficient humans over 20 minutes (24,000 actions). Our model uses the native human interface of keypresses and mouse movements, making it quite general, and represents a step towards general computer-using¬†agents.",
    "pubDate": "Thu, 23 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/vpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Converting Vertex-Colored Meshes to Textured Meshes",
    "description": "",
    "summary": "Converting Vertex-Colored Meshes to Textured Meshes Convert vertex-colored meshes to UV-mapped, text...",
    "pubDate": "Mon, 30 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vertex-colored-to-textured-mesh",
    "thumbnail": "https://huggingface.co/blog/assets/vertex-colored-to-textured-mesh/thumbnail.png"
  },
  {
    "title": "A glimpse of the next generation of AlphaFold",
    "description": "Progress update: Our latest AlphaFold model shows significantly improved accuracy and expands coverage beyond proteins to other biological molecules, including ligands.",
    "summary": "Progress update: Our latest AlphaFold model shows significantly improved accuracy and expands coverage beyond proteins to other biological molecules, including ligands.",
    "pubDate": "Tue, 31 Oct 2023 13:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/",
    "thumbnail": "https://lh3.googleusercontent.com/1xoO5BAUUU8kLns4myMNnKw6RRQyUk1JdlWL1M0aDiagMgaBeDA9O8Y4rYFAo9hfnzmb0cnUMrT_-cStBqnyp_zW59F5Edwbvxcy3EVmfeKS-PNgVw=w1200-h630-n-nu"
  },
  {
    "title": "GenCast predicts weather and the risks of extreme conditions with state-of-the-art accuracy",
    "description": "New AI model advances the prediction of weather uncertainties and risks, delivering faster, more accurate forecasts up to 15 days ahead",
    "summary": "New AI model advances the prediction of weather uncertainties and risks, delivering faster, more accurate forecasts up to 15 days ahead",
    "pubDate": "Wed, 04 Dec 2024 15:59:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/",
    "thumbnail": "https://lh3.googleusercontent.com/4u3n6FBe0eE86yXgppDN_yj_AkiCF5FaSToa8f3Mh5bFWzIH01ewGN737emoYKcGXLxQagYFMxi9j-cAZyAzkdFndCDg2ne9E42w4YZD7HyBChaf=w1200-h630-n-nu"
  },
  {
    "title": "Introducing the OpenAI Academy",
    "description": "New initiative will fuel innovation by investing in developers and organizations leveraging AI, starting in low- and middle-income countries.",
    "summary": "New initiative will fuel innovation by investing in developers and organizations leveraging AI, starting in low- and middle-income countries.",
    "pubDate": "Mon, 23 Sep 2024 03:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "API Partnership with Stack Overflow",
    "description": "API Partnership with Stack Overflow Stack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world‚Äôs leading knowledge platform for highly technical content with the world‚Äôs most popular LLM models for AI development.",
    "summary": "API Partnership with Stack Overflow Stack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world‚Äôs leading knowledge platform for highly technical content with the world‚Äôs most popular LLM models for AI development.",
    "pubDate": "Mon, 06 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-partnership-with-stack-overflow",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Tiny Agents in Python: a MCP-powered agent in ~70 lines of code",
    "description": "",
    "summary": "Tiny Agents in Python: an MCP-powered agent in ~70 lines of code Inspired by Tiny Agents in JS, we p...",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/python-tiny-agents",
    "thumbnail": "https://huggingface.co/blog/assets/python-tiny-agents/thumbnail.png"
  },
  {
    "title": "Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Disaster Tweets Analysis with Lora",
    "description": "",
    "summary": "Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Disaster Tweet...",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/Lora-for-sequence-classification-with-Roberta-Llama-Mistral",
    "thumbnail": "https://huggingface.co/blog/assets/Lora-for-sequence-classification-with-Roberta-Llama-Mistral/Thumbnail.png"
  },
  {
    "title": "Zero-shot image segmentation with CLIPSeg",
    "description": "",
    "summary": "Zero-shot image segmentation with CLIPSeg This guide shows how you can use CLIPSeg, a zero-shot imag...",
    "pubDate": "Wed, 21 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/clipseg-zero-shot",
    "thumbnail": "https://huggingface.co/blog/assets/123_clipseg-zero-shot/thumb.png"
  },
  {
    "title": "CMD-HAR: Cross-Modal Disentanglement for Wearable Human Activity Recognition",
    "description": "arXiv:2503.21843v2 Announce Type: replace-cross Abstract: Human Activity Recognition (HAR) is a fundamental technology for numerous human - centered intelligent applications. Although deep learning methods have been utilized to accelerate feature extraction, issues such as multimodal data mixing, activity heterogeneity, and complex model deployment remain largely unresolved. The aim of this paper is to address issues such as multimodal data mixing, activity heterogeneity, and complex model deployment in sensor-based human activity recognition. We propose a spatiotemporal attention modal decomposition alignment fusion strategy to tackle the problem of the mixed distribution of sensor data. Key discriminative features of activities are captured through cross-modal spatio-temporal disentangled representation, and gradient modulation is combined to alleviate data heterogeneity. In addition, a wearable deployment simulation system is constructed. We conducted experiments on a large number of public datasets, demonstrating the effectiveness of the model.",
    "summary": "arXiv:2503.21843v2 Announce Type: replace-cross Abstract: Human Activity Recognition (HAR) is a fundamental technology for numerous human - centered intelligent applications. Although deep learning methods have been utilized to accelerate feature extraction, issues such as multimodal data mixing, activity heterogeneity, and complex model deployment remain largely unresolved. The aim of this paper is to address issues such as multimodal data mixing, activity heterogeneity, and complex model deployment in sensor-based human activity recognition. We propose a spatiotemporal attention modal decomposition alignment fusion strategy to tackle the problem of the mixed distribution of sensor data. Key discriminative features of activities are captured through cross-modal spatio-temporal disentangled representation, and gradient modulation is combined to alleviate data heterogeneity. In addition, a wearable deployment simulation system is constructed. We conducted experiments on a large number of public datasets, demonstrating the effectiveness of the model.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.21843",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Llama can now see and run on your device - welcome Llama 3.2",
    "description": "",
    "summary": "Llama can now see and run on your device - welcome Llama 3.2 Llama 3.2 is out! Today, we welcome the...",
    "pubDate": "Wed, 25 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama32",
    "thumbnail": "https://huggingface.co/blog/assets/llama32/thumbnail.jpg"
  },
  {
    "title": "Early methods for studying affective use and emotional well-being on ChatGPT",
    "description": "An OpenAI and MIT Media Lab Research collaboration.",
    "summary": "An OpenAI and MIT Media Lab Research collaboration.",
    "pubDate": "Fri, 21 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/affective-use-study",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Zero-shot image-to-text generation with BLIP-2",
    "description": "",
    "summary": "Zero-shot image-to-text generation with BLIP-2 This guide introduces BLIP-2 from Salesforce Research...",
    "pubDate": "Wed, 15 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/blip-2",
    "thumbnail": "https://huggingface.co/blog/assets/blip-2/thumbnail.png"
  },
  {
    "title": "OpenAI Gym Beta",
    "description": "We‚Äôre releasing the public beta of OpenAI Gym, a toolkit for developing and comparing reinforcement learning (RL) algorithms. It consists of a growing suite of environments (from simulated robots to Atari games), and a site for comparing and reproducing results.",
    "summary": "We‚Äôre releasing the public beta of OpenAI Gym, a toolkit for developing and comparing reinforcement learning (RL) algorithms. It consists of a growing suite of environments (from simulated robots to Atari games), and a site for comparing and reproducing results.",
    "pubDate": "Wed, 27 Apr 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-gym-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerate BERT inference with Hugging Face Transformers and AWS inferentia",
    "description": "",
    "summary": "Accelerate BERT inference with Hugging Face Transformers and AWS Inferentia notebook: sagemaker/18_i...",
    "pubDate": "Wed, 16 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-inferentia-sagemaker",
    "thumbnail": "https://huggingface.co/blog//assets/55_bert_inferentia_sagemaker/thumbnail.png"
  },
  {
    "title": "Preserving languages for the future",
    "description": "How Iceland is using GPT-4 to preserve its language.",
    "summary": "How Iceland is using GPT-4 to preserve its language.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/government-of-iceland",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy Livebook notebooks as apps to Hugging Face Spaces",
    "description": "",
    "summary": "Deploy Livebook notebooks as apps to Hugging Face Spaces The Elixir community has been making great ...",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/livebook-app-deployment",
    "thumbnail": "https://huggingface.co/blog/assets/120_elixir-bumblebee/thumbnail.png"
  },
  {
    "title": "Frontier Model Forum",
    "description": "We‚Äôre forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
    "summary": "We‚Äôre forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
    "pubDate": "Wed, 26 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-model-forum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Merging AI and underwater photography to reveal hidden ocean worlds",
    "description": "The LOBSTgER research initiative at MIT Sea Grant explores how generative AI can expand scientific storytelling by building on field-based photographic data.",
    "summary": "The LOBSTgER research initiative at MIT Sea Grant explores how generative AI can expand scientific storytelling by building on field-based photographic data.",
    "pubDate": "Wed, 25 Jun 2025 09:55:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/lobstger-merging-ai-underwater-photography-to-reveal-hidden-ocean-worlds-0625",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-LOBSTgER.jpg"
  },
  {
    "title": "Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series",
    "description": "arXiv:2505.20697v3 Announce Type: replace-cross Abstract: The field of hypothesis generation promises to reduce costs in neuroscience by narrowing the range of interventional studies needed to study various phenomena. Existing machine learning methods can generate scientific hypotheses from complex datasets, but many approaches assume causal relationships are static over time, limiting their applicability to systems with dynamic, state-dependent behavior, such as the brain. While some techniques attempt dynamic causal discovery through factor models, they often restrict relationships to linear patterns or impose other simplifying assumptions. We propose a novel method that models dynamic graphs as a conditionally weighted superposition of static graphs, where each static graph can capture nonlinear relationships. This approach enables the detection of complex, time-varying interactions between variables beyond linear limitations. Our method improves f1-scores of predicted dynamic causal patterns by roughly 22-28% on average over baselines in some of our experiments, with some improvements reaching well over 60%. A case study on real brain data demonstrates our method's ability to uncover relationships linked to specific behavioral states, offering valuable insights into neural dynamics.",
    "summary": "arXiv:2505.20697v3 Announce Type: replace-cross Abstract: The field of hypothesis generation promises to reduce costs in neuroscience by narrowing the range of interventional studies needed to study various phenomena. Existing machine learning methods can generate scientific hypotheses from complex datasets, but many approaches assume causal relationships are static over time, limiting their applicability to systems with dynamic, state-dependent behavior, such as the brain. While some techniques attempt dynamic causal discovery through factor models, they often restrict relationships to linear patterns or impose other simplifying assumptions. We propose a novel method that models dynamic graphs as a conditionally weighted superposition of static graphs, where each static graph can capture nonlinear relationships. This approach enables the detection of complex, time-varying interactions between variables beyond linear limitations. Our method improves f1-scores of predicted dynamic causal patterns by roughly 22-28% on average over baselines in some of our experiments, with some improvements reaching well over 60%. A case study on real brain data demonstrates our method's ability to uncover relationships linked to specific behavioral states, offering valuable insights into neural dynamics.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.20697",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "2D Asset Generation: AI for Game Development #4",
    "description": "",
    "summary": "2D Asset Generation: AI for Game Development #4 Welcome to AI for Game Development! In this series, ...",
    "pubDate": "Thu, 26 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-4",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail4.png"
  },
  {
    "title": "Decoding genetics with OpenAI o1",
    "description": "Geneticist Catherine Brownstein demonstrates how OpenAI o1 can speed up the process of diagnosing rare medical challenges.",
    "summary": "Geneticist Catherine Brownstein demonstrates how OpenAI o1 can speed up the process of diagnosing rare medical challenges.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-genetics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Significativity Indices for Agreement Values",
    "description": "arXiv:2504.15325v2 Announce Type: replace-cross Abstract: Agreement measures, such as Cohen's kappa or intraclass correlation, gauge the matching between two or more classifiers. They are used in a wide range of contexts from medicine, where they evaluate the effectiveness of medical treatments and clinical trials, to artificial intelligence, where they can quantify the approximation due to the reduction of a classifier. The consistency of different classifiers to a golden standard can be compared simply by using the order induced by their agreement measure with respect to the golden standard itself. Nevertheless, labelling an approach as good or bad exclusively by using the value of an agreement measure requires a scale or a significativity index. Some quality scales have been proposed in the literature for Cohen's kappa, but they are mainly na'ive, and their boundaries are arbitrary. This work proposes a general approach to evaluate the significativity of any agreement value between two classifiers and introduces two significativity indices: one dealing with finite data sets, the other one handling classification probability distributions. Moreover, this manuscript addresses the computational challenges of evaluating such indices and proposes some efficient algorithms for their evaluation.",
    "summary": "arXiv:2504.15325v2 Announce Type: replace-cross Abstract: Agreement measures, such as Cohen's kappa or intraclass correlation, gauge the matching between two or more classifiers. They are used in a wide range of contexts from medicine, where they evaluate the effectiveness of medical treatments and clinical trials, to artificial intelligence, where they can quantify the approximation due to the reduction of a classifier. The consistency of different classifiers to a golden standard can be compared simply by using the order induced by their agreement measure with respect to the golden standard itself. Nevertheless, labelling an approach as good or bad exclusively by using the value of an agreement measure requires a scale or a significativity index. Some quality scales have been proposed in the literature for Cohen's kappa, but they are mainly na'ive, and their boundaries are arbitrary. This work proposes a general approach to evaluate the significativity of any agreement value between two classifiers and introduces two significativity indices: one dealing with finite data sets, the other one handling classification probability distributions. Moreover, this manuscript addresses the computational challenges of evaluating such indices and proposes some efficient algorithms for their evaluation.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.15325",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Superalignment Fast Grants",
    "description": "We‚Äôre launching $10M in grants to support technical research towards the alignment and safety of superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.",
    "summary": "We‚Äôre launching $10M in grants to support technical research towards the alignment and safety of superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/superalignment-fast-grants",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MIT and Mass General Brigham launch joint seed program to accelerate innovations in health",
    "description": "The MIT-MGB Seed Program, launched with support from Analog Devices Inc., will fund joint research projects that advance technology and clinical research.",
    "summary": "The MIT-MGB Seed Program, launched with support from Analog Devices Inc., will fund joint research projects that advance technology and clinical research.",
    "pubDate": "Fri, 27 Jun 2025 13:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-mass-general-brigham-launch-seed-program-innovations-health-0627",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-mgb-seed-program.jpg"
  },
  {
    "title": "Improving Hugging Face Model Access for Kaggle Users",
    "description": "",
    "summary": "Improving Hugging Face Model Access for Kaggle Users Kaggle and Hugging Face users are part of one A...",
    "pubDate": "Wed, 14 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kaggle-integration",
    "thumbnail": "https://huggingface.co/blog/assets/kaggle-integration/thumbnail.png"
  },
  {
    "title": "Microsoft and Hugging Face expand collaboration",
    "description": "",
    "summary": "Microsoft and Hugging Face expand collaboration to make open models easy to use on Azure Today at th...",
    "pubDate": "Mon, 19 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/azure-ai-foundry",
    "thumbnail": "https://huggingface.co/blog/assets/azure-ai-foundry/satya-hf-build-compressed.png"
  },
  {
    "title": "One-shot imitation learning",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 21 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/one-shot-imitation-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CodeGemma - an official Google release for code LLMs",
    "description": "",
    "summary": "CodeGemma - an official Google release for code LLMs CodeGemma is a family of open-access versions o...",
    "pubDate": "Tue, 09 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codegemma",
    "thumbnail": "https://huggingface.co/blog/assets/codegemma/thumbnail_b.png"
  },
  {
    "title": "Welcome to Inference Providers on the Hub üî•",
    "description": "",
    "summary": "Welcome to Inference Providers on the Hub üî• Today, we are launching the integration of four awesome ...",
    "pubDate": "Tue, 28 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/thumbnail.png"
  },
  {
    "title": "HAPI: A Model for Learning Robot Facial Expressions from Human Preferences",
    "description": "arXiv:2503.17046v2 Announce Type: replace-cross Abstract: Automatic robotic facial expression generation is crucial for human-robot interaction, as handcrafted methods based on fixed joint configurations often yield rigid and unnatural behaviors. Although recent automated techniques reduce the need for manual tuning, they tend to fall short by not adequately bridging the gap between human preferences and model predictions-resulting in a deficiency of nuanced and realistic expressions due to limited degrees of freedom and insufficient perceptual integration. In this work, we propose a novel learning-to-rank framework that leverages human feedback to address this discrepancy and enhanced the expressiveness of robotic faces. Specifically, we conduct pairwise comparison annotations to collect human preference data and develop the Human Affective Pairwise Impressions (HAPI) model, a Siamese RankNet-based approach that refines expression evaluation. Results obtained via Bayesian Optimization and online expression survey on a 35-DOF android platform demonstrate that our approach produces significantly more realistic and socially resonant expressions of Anger, Happiness, and Surprise than those generated by baseline and expert-designed methods. This confirms that our framework effectively bridges the gap between human preferences and model predictions while robustly aligning robotic expression generation with human affective responses.",
    "summary": "arXiv:2503.17046v2 Announce Type: replace-cross Abstract: Automatic robotic facial expression generation is crucial for human-robot interaction, as handcrafted methods based on fixed joint configurations often yield rigid and unnatural behaviors. Although recent automated techniques reduce the need for manual tuning, they tend to fall short by not adequately bridging the gap between human preferences and model predictions-resulting in a deficiency of nuanced and realistic expressions due to limited degrees of freedom and insufficient perceptual integration. In this work, we propose a novel learning-to-rank framework that leverages human feedback to address this discrepancy and enhanced the expressiveness of robotic faces. Specifically, we conduct pairwise comparison annotations to collect human preference data and develop the Human Affective Pairwise Impressions (HAPI) model, a Siamese RankNet-based approach that refines expression evaluation. Results obtained via Bayesian Optimization and online expression survey on a 35-DOF android platform demonstrate that our approach produces significantly more realistic and socially resonant expressions of Anger, Happiness, and Surprise than those generated by baseline and expert-designed methods. This confirms that our framework effectively bridges the gap between human preferences and model predictions while robustly aligning robotic expression generation with human affective responses.",
    "pubDate": "Fri, 04 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.17046",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "March 20 ChatGPT outage: Here‚Äôs what happened",
    "description": "An update on our findings, the actions we‚Äôve taken, and technical details of the bug.",
    "summary": "An update on our findings, the actions we‚Äôve taken, and technical details of the bug.",
    "pubDate": "Fri, 24 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/march-20-chatgpt-outage",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From cloud to developers: Hugging Face and Microsoft Deepen Collaboration",
    "description": "",
    "summary": "From cloud to developers: Hugging Face and Microsoft Deepen Collaboration Today at Microsoft Build w...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/microsoft-collaboration",
    "thumbnail": "https://huggingface.co/blog/assets/microsoft-collaboration/thumbnail.jpg"
  },
  {
    "title": "Learning to cooperate, compete, and communicate",
    "description": "Multiagent environments where agents compete for resources are stepping stones on the path to AGI. Multiagent environments have two useful properties: first, there is a natural curriculum‚Äîthe difficulty of the environment is determined by the skill of your competitors (and if you‚Äôre competing against clones of yourself, the environment exactly matches your skill level). Second, a multiagent environment has no stable equilibrium: no matter how smart an agent is, there‚Äôs always pressure to get smarter. These environments have a very different feel from traditional environments, and it‚Äôll take a lot more research before we become good at them.",
    "summary": "Multiagent environments where agents compete for resources are stepping stones on the path to AGI. Multiagent environments have two useful properties: first, there is a natural curriculum‚Äîthe difficulty of the environment is determined by the skill of your competitors (and if you‚Äôre competing against clones of yourself, the environment exactly matches your skill level). Second, a multiagent environment has no stable equilibrium: no matter how smart an agent is, there‚Äôs always pressure to get smarter. These environments have a very different feel from traditional environments, and it‚Äôll take a lot more research before we become good at them.",
    "pubDate": "Thu, 08 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-cooperate-compete-and-communicate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the SQL Console on Datasets",
    "description": "",
    "summary": "Introducing the SQL Console on Datasets Datasets use has been exploding and Hugging Face has become ...",
    "pubDate": "Tue, 17 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sql-console",
    "thumbnail": "https://huggingface.co/blog/assets/sql_console/thumbnail.png"
  },
  {
    "title": "Accelerate StarCoder with ü§ó Optimum Intel on Xeon: Q8/Q4 and Speculative Decoding",
    "description": "",
    "summary": "Accelerate StarCoder with ü§ó Optimum Intel on Xeon: Q8/Q4 and Speculative Decoding Introduction Recen...",
    "pubDate": "Tue, 30 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-starcoder-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Sentence Transformers in the ü§ó Hub",
    "description": "",
    "summary": "Sentence Transformers in the Hugging Face Hub Over the past few weeks, we've built collaborations wi...",
    "pubDate": "Mon, 28 Jun 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentence-transformers-in-the-hub",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Accelerating the development of life-saving treatments",
    "description": "Accelerating the development of life-saving treatments.",
    "summary": "Accelerating the development of life-saving treatments.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/moderna",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  }
]