[
  {
    "title": "A faster way to solve complex planning problems",
    "description": "By eliminating redundant computations, a new data-driven method can streamline processes like scheduling trains, routing delivery drivers, or assigning airline crews.",
    "summary": "By eliminating redundant computations, a new data-driven method can streamline processes like scheduling trains, routing delivery drivers, or assigning airline crews.",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/faster-way-solve-complex-planning-problems-0416",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Long-Horizon-01.jpg"
  },
  {
    "title": "Building networks of data science talent",
    "description": "Through collaborations with organizations like BREIT in Peru, the MIT Institute for Data, Systems, and Society is upskilling hundreds of learners around the world in data science and machine learning.",
    "summary": "Through collaborations with organizations like BREIT in Peru, the MIT Institute for Data, Systems, and Society is upskilling hundreds of learners around the world in data science and machine learning.",
    "pubDate": "Tue, 27 May 2025 16:11:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/building-networks-data-science-talent-0527",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-breit-idss-killian.jpg"
  },
  {
    "title": "üêØ Liger GRPO meets TRL",
    "description": "",
    "summary": "üêØ Liger GRPO meets TRL TL; DR Liger supercharges TRL‚Äôs Group Relative Policy Optimization GRPO Train...",
    "pubDate": "Sun, 25 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/liger-grpo",
    "thumbnail": "https://huggingface.co/blog/assets/liger-grpo/thumbnail.png"
  },
  {
    "title": "Groq on Hugging Face Inference Providers üî•",
    "description": "",
    "summary": "Groq on Hugging Face Inference Providers üî• We're thrilled to share that Groq is now a supported Infe...",
    "pubDate": "Mon, 16 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-groq",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-groq.jpg"
  },
  {
    "title": "Interactively explore your Huggingface dataset with one line of code",
    "description": "",
    "summary": "Interactively explore your Huggingface dataset with one line of code The Hugging Face datasets libra...",
    "pubDate": "Wed, 25 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/scalable-data-inspection",
    "thumbnail": "https://huggingface.co/blog/assets/scalable-data-inspection/thumbnail.png"
  },
  {
    "title": "Empowering Manufacturers with Privacy-Preserving AI Tools: A Case Study in Privacy-Preserving Machine Learning to Solve Real-World Problems",
    "description": "arXiv:2507.01808v1 Announce Type: cross Abstract: Small- and medium-sized manufacturers need innovative data tools but, because of competition and privacy concerns, often do not want to share their proprietary data with researchers who might be interested in helping. This paper introduces a privacy-preserving platform by which manufacturers may safely share their data with researchers through secure methods, so that those researchers then create innovative tools to solve the manufacturers' real-world problems, and then provide tools that execute solutions back onto the platform for others to use with privacy and confidentiality guarantees. We illustrate this problem through a particular use case which addresses an important problem in the large-scale manufacturing of food crystals, which is that quality control relies on image analysis tools. Previous to our research, food crystals in the images were manually counted, which required substantial and time-consuming human efforts, but we have developed and deployed a crystal analysis tool which makes this process both more rapid and accurate. The tool enables automatic characterization of the crystal size distribution and numbers from microscope images while the natural imperfections from the sample preparation are automatically removed; a machine learning model to count high resolution translucent crystals and agglomeration of crystals was also developed to aid in these efforts. The resulting algorithm was then packaged for real-world use on the factory floor via a web-based app secured through the originating privacy-preserving platform, allowing manufacturers to use it while keeping their proprietary data secure. After demonstrating this full process, future directions are also explored.",
    "summary": "arXiv:2507.01808v1 Announce Type: cross Abstract: Small- and medium-sized manufacturers need innovative data tools but, because of competition and privacy concerns, often do not want to share their proprietary data with researchers who might be interested in helping. This paper introduces a privacy-preserving platform by which manufacturers may safely share their data with researchers through secure methods, so that those researchers then create innovative tools to solve the manufacturers' real-world problems, and then provide tools that execute solutions back onto the platform for others to use with privacy and confidentiality guarantees. We illustrate this problem through a particular use case which addresses an important problem in the large-scale manufacturing of food crystals, which is that quality control relies on image analysis tools. Previous to our research, food crystals in the images were manually counted, which required substantial and time-consuming human efforts, but we have developed and deployed a crystal analysis tool which makes this process both more rapid and accurate. The tool enables automatic characterization of the crystal size distribution and numbers from microscope images while the natural imperfections from the sample preparation are automatically removed; a machine learning model to count high resolution translucent crystals and agglomeration of crystals was also developed to aid in these efforts. The resulting algorithm was then packaged for real-world use on the factory floor via a web-based app secured through the originating privacy-preserving platform, allowing manufacturers to use it while keeping their proprietary data secure. After demonstrating this full process, future directions are also explored.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01808",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Stable Diffusion XL on Mac with Advanced Core ML Quantization",
    "description": "",
    "summary": "Stable Diffusion XL on Mac with Advanced Core ML Quantization Stable Diffusion XL was released yeste...",
    "pubDate": "Thu, 27 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-xl-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/stable-diffusion-xl-coreml/thumbnail.png"
  },
  {
    "title": "New tools and features in the Responses API",
    "description": "New features in the Responses API: Remote MCP, image gen, Code Interpreter, and more. Powering faster, smarter agents with GPT-4o & o-series models, plus new features for reliability and efficiency.",
    "summary": "New features in the Responses API: Remote MCP, image gen, Code Interpreter, and more. Powering faster, smarter agents with GPT-4o & o-series models, plus new features for reliability and efficiency.",
    "pubDate": "Wed, 21 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-and-features-in-the-responses-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Lessons learned on language model safety and misuse",
    "description": "We describe our latest thinking in the hope of helping other AI developers address safety and misuse of deployed¬†models.",
    "summary": "We describe our latest thinking in the hope of helping other AI developers address safety and misuse of deployed¬†models.",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-model-safety-and-misuse",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Memory and new controls for ChatGPT",
    "description": "We‚Äôre testing the ability for ChatGPT to remember things you discuss to make future chats more helpful. You‚Äôre in control of ChatGPT‚Äôs memory.",
    "summary": "We‚Äôre testing the ability for ChatGPT to remember things you discuss to make future chats more helpful. You‚Äôre in control of ChatGPT‚Äôs memory.",
    "pubDate": "Tue, 13 Feb 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/memory-and-new-controls-for-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating LLM Agent Collusion in Double Auctions",
    "description": "arXiv:2507.01413v1 Announce Type: cross Abstract: Large language models (LLMs) have demonstrated impressive capabilities as autonomous agents with rapidly expanding applications in various domains. As these agents increasingly engage in socioeconomic interactions, identifying their potential for undesirable behavior becomes essential. In this work, we examine scenarios where they can choose to collude, defined as secretive cooperation that harms another party. To systematically study this, we investigate the behavior of LLM agents acting as sellers in simulated continuous double auction markets. Through a series of controlled experiments, we analyze how parameters such as the ability to communicate, choice of model, and presence of environmental pressures affect the stability and emergence of seller collusion. We find that direct seller communication increases collusive tendencies, the propensity to collude varies across models, and environmental pressures, such as oversight and urgency from authority figures, influence collusive behavior. Our findings highlight important economic and ethical considerations for the deployment of LLM-based market agents.",
    "summary": "arXiv:2507.01413v1 Announce Type: cross Abstract: Large language models (LLMs) have demonstrated impressive capabilities as autonomous agents with rapidly expanding applications in various domains. As these agents increasingly engage in socioeconomic interactions, identifying their potential for undesirable behavior becomes essential. In this work, we examine scenarios where they can choose to collude, defined as secretive cooperation that harms another party. To systematically study this, we investigate the behavior of LLM agents acting as sellers in simulated continuous double auction markets. Through a series of controlled experiments, we analyze how parameters such as the ability to communicate, choice of model, and presence of environmental pressures affect the stability and emergence of seller collusion. We find that direct seller communication increases collusive tendencies, the propensity to collude varies across models, and environmental pressures, such as oversight and urgency from authority figures, influence collusive behavior. Our findings highlight important economic and ethical considerations for the deployment of LLM-based market agents.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01413",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The N Implementation Details of RLHF with PPO",
    "description": "",
    "summary": "The N Implementation Details of RLHF with PPO RLHF / ChatGPT has been a popular research topic these...",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo",
    "thumbnail": "https://huggingface.co/blog/assets/167_the_n_implementation_details_of_rlhf_with_ppo/thumbnail.png"
  },
  {
    "title": "There and Back Again: On the relation between Noise and Image Inversions in Diffusion Models",
    "description": "arXiv:2410.23530v3 Announce Type: replace-cross Abstract: Diffusion Models achieve state-of-the-art performance in generating new samples but lack a low-dimensional latent space that encodes the data into meaningful features. Inversion-based methods address this by reversing the denoising trajectory, mapping each image back to its approximated starting noise. In this work, we thoroughly analyze this procedure and focus on the relation between the initial Gaussian noise, the generated samples, and their corresponding latent encodings obtained through the DDIM inversion. First, we show that latents exhibit structural patterns in the form of less diverse noise predicted for smooth image regions. As a consequence of this divergence, we present that the space of image inversions is notably less manipulative than the original Gaussian noise. Next, we explain the origin of the phenomenon, demonstrating that, during the first inversion steps, the noise prediction error is much more significant for the plain areas than for the rest of the image. As a surprisingly simple solution, we propose to replace the first DDIM Inversion steps with a forward diffusion process, which successfully decorrelates latent encodings, leading to higher quality editions and interpolations. The code is available at https://github.com/luk-st/taba.",
    "summary": "arXiv:2410.23530v3 Announce Type: replace-cross Abstract: Diffusion Models achieve state-of-the-art performance in generating new samples but lack a low-dimensional latent space that encodes the data into meaningful features. Inversion-based methods address this by reversing the denoising trajectory, mapping each image back to its approximated starting noise. In this work, we thoroughly analyze this procedure and focus on the relation between the initial Gaussian noise, the generated samples, and their corresponding latent encodings obtained through the DDIM inversion. First, we show that latents exhibit structural patterns in the form of less diverse noise predicted for smooth image regions. As a consequence of this divergence, we present that the space of image inversions is notably less manipulative than the original Gaussian noise. Next, we explain the origin of the phenomenon, demonstrating that, during the first inversion steps, the noise prediction error is much more significant for the plain areas than for the rest of the image. As a surprisingly simple solution, we propose to replace the first DDIM Inversion steps with a forward diffusion process, which successfully decorrelates latent encodings, leading to higher quality editions and interpolations. The code is available at https://github.com/luk-st/taba.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.23530",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gradio 3.0 is Out!",
    "description": "",
    "summary": "Gradio 3.0 is Out! Machine Learning Demos Machine learning demos are an increasingly vital part of r...",
    "pubDate": "Mon, 16 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-blocks",
    "thumbnail": "https://huggingface.co/blog/assets/68_gradio_blocks/block-party.png"
  },
  {
    "title": "Getting started with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Getting Started with Hugging Face Inference Endpoints Training machine learning models has become qu...",
    "pubDate": "Fri, 14 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/109_inference_endpoints/endpoints05.png"
  },
  {
    "title": "Helen Toner joins OpenAI‚Äôs board of directors",
    "description": "Today, we‚Äôre excited to announce the appointment of Helen Toner to our board of directors.",
    "summary": "Today, we‚Äôre excited to announce the appointment of Helen Toner to our board of directors.",
    "pubDate": "Wed, 08 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/helen-toner-joins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The 5 Most Under-Rated Tools on Hugging Face",
    "description": "",
    "summary": "The 5 Most Under-Rated Tools on Hugging Face The Hugging Face Hub boasts over 850K public models, wi...",
    "pubDate": "Thu, 22 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unsung-heroes",
    "thumbnail": "https://huggingface.co/blog/assets/unsung-heroes/new-thumbnail.png"
  },
  {
    "title": "Economics and reasoning with OpenAI o1",
    "description": "Economist Tyler Cowen explains how OpenAI o1 tackles complex economic questions.",
    "summary": "Economist Tyler Cowen explains how OpenAI o1 tackles complex economic questions.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-economics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SDXL in 4 steps with Latent Consistency LoRAs",
    "description": "",
    "summary": "SDXL in 4 steps with Latent Consistency LoRAs Latent Consistency Models (LCM) are a way to decrease ...",
    "pubDate": "Thu, 09 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lcm_lora",
    "thumbnail": "https://huggingface.co/blog/assets/lcm_sdxl/lcm_thumbnail.png"
  },
  {
    "title": "XxaCT-NN: Structure Agnostic Multimodal Learning for Materials Science",
    "description": "arXiv:2507.01054v1 Announce Type: cross Abstract: Recent advances in materials discovery have been driven by structure-based models, particularly those using crystal graphs. While effective for computational datasets, these models are impractical for real-world applications where atomic structures are often unknown or difficult to obtain. We propose a scalable multimodal framework that learns directly from elemental composition and X-ray diffraction (XRD) -- two of the more available modalities in experimental workflows without requiring crystal structure input. Our architecture integrates modality-specific encoders with a cross-attention fusion module and is trained on the 5-million-sample Alexandria dataset. We present masked XRD modeling (MXM), and apply MXM and contrastive alignment as self-supervised pretraining strategies. Pretraining yields faster convergence (up to 4.2x speedup) and improves both accuracy and representation quality. We further demonstrate that multimodal performance scales more favorably with dataset size than unimodal baselines, with gains compounding at larger data regimes. Our results establish a path toward structure-free, experimentally grounded foundation models for materials science.",
    "summary": "arXiv:2507.01054v1 Announce Type: cross Abstract: Recent advances in materials discovery have been driven by structure-based models, particularly those using crystal graphs. While effective for computational datasets, these models are impractical for real-world applications where atomic structures are often unknown or difficult to obtain. We propose a scalable multimodal framework that learns directly from elemental composition and X-ray diffraction (XRD) -- two of the more available modalities in experimental workflows without requiring crystal structure input. Our architecture integrates modality-specific encoders with a cross-attention fusion module and is trained on the 5-million-sample Alexandria dataset. We present masked XRD modeling (MXM), and apply MXM and contrastive alignment as self-supervised pretraining strategies. Pretraining yields faster convergence (up to 4.2x speedup) and improves both accuracy and representation quality. We further demonstrate that multimodal performance scales more favorably with dataset size than unimodal baselines, with gains compounding at larger data regimes. Our results establish a path toward structure-free, experimentally grounded foundation models for materials science.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01054",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Baseline Method for Removing Invisible Image Watermarks using Deep Image Prior",
    "description": "arXiv:2502.13998v2 Announce Type: replace-cross Abstract: Image watermarks have been considered a promising technique to help detect AI-generated content, which can be used to protect copyright or prevent fake image abuse. In this work, we present a black-box method for removing invisible image watermarks, without the need of any dataset of watermarked images or any knowledge about the watermark system. Our approach is simple to implement: given a single watermarked image, we regress it by deep image prior (DIP). We show that from the intermediate steps of DIP one can reliably find an evasion image that can remove invisible watermarks while preserving high image quality. Due to its unique working mechanism and practical effectiveness, we advocate including DIP as a baseline invasion method for benchmarking the robustness of watermarking systems. Finally, by showing the limited ability of DIP and other existing black-box methods in evading training-based visible watermarks, we discuss the positive implications on the practical use of training-based visible watermarks to prevent misinformation abuse.",
    "summary": "arXiv:2502.13998v2 Announce Type: replace-cross Abstract: Image watermarks have been considered a promising technique to help detect AI-generated content, which can be used to protect copyright or prevent fake image abuse. In this work, we present a black-box method for removing invisible image watermarks, without the need of any dataset of watermarked images or any knowledge about the watermark system. Our approach is simple to implement: given a single watermarked image, we regress it by deep image prior (DIP). We show that from the intermediate steps of DIP one can reliably find an evasion image that can remove invisible watermarks while preserving high image quality. Due to its unique working mechanism and practical effectiveness, we advocate including DIP as a baseline invasion method for benchmarking the robustness of watermarking systems. Finally, by showing the limited ability of DIP and other existing black-box methods in evading training-based visible watermarks, we discuss the positive implications on the practical use of training-based visible watermarks to prevent misinformation abuse.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.13998",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Pre-Train BERT with Hugging Face Transformers and Habana Gaudi",
    "description": "",
    "summary": "Pre-Training BERT with Hugging Face Transformers and Habana Gaudi In this Tutorial, you will learn h...",
    "pubDate": "Mon, 22 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pretraining-bert",
    "thumbnail": "https://huggingface.co/blog/assets/99_pretraining_bert/thumbnail.png"
  },
  {
    "title": "Real-is-Sim: Bridging the Sim-to-Real Gap with a Dynamic Digital Twin",
    "description": "arXiv:2504.03597v2 Announce Type: replace-cross Abstract: We introduce real-is-sim, a new approach to integrating simulation into behavior cloning pipelines. In contrast to real-only methods, which lack the ability to safely test policies before deployment, and sim-to-real methods, which require complex adaptation to cross the sim-to-real gap, our framework allows policies to seamlessly switch between running on real hardware and running in parallelized virtual environments. At the center of real-is-sim is a dynamic digital twin, powered by the Embodied Gaussian simulator, that synchronizes with the real world at 60Hz. This twin acts as a mediator between the behavior cloning policy and the real robot. Policies are trained using representations derived from simulator states and always act on the simulated robot, never the real one. During deployment, the real robot simply follows the simulated robot's joint states, and the simulation is continuously corrected with real world measurements. This setup, where the simulator drives all policy execution and maintains real-time synchronization with the physical world, shifts the responsibility of crossing the sim-to-real gap to the digital twin's synchronization mechanisms, instead of the policy itself. We demonstrate real-is-sim on a long-horizon manipulation task (PushT), showing that virtual evaluations are consistent with real-world results. We further show how real-world data can be augmented with virtual rollouts and compare to policies trained on different representations derived from the simulator state including object poses and rendered images from both static and robot-mounted cameras. Our results highlight the flexibility of the real-is-sim framework across training, evaluation, and deployment stages. Videos available at https://real-is-sim.github.io.",
    "summary": "arXiv:2504.03597v2 Announce Type: replace-cross Abstract: We introduce real-is-sim, a new approach to integrating simulation into behavior cloning pipelines. In contrast to real-only methods, which lack the ability to safely test policies before deployment, and sim-to-real methods, which require complex adaptation to cross the sim-to-real gap, our framework allows policies to seamlessly switch between running on real hardware and running in parallelized virtual environments. At the center of real-is-sim is a dynamic digital twin, powered by the Embodied Gaussian simulator, that synchronizes with the real world at 60Hz. This twin acts as a mediator between the behavior cloning policy and the real robot. Policies are trained using representations derived from simulator states and always act on the simulated robot, never the real one. During deployment, the real robot simply follows the simulated robot's joint states, and the simulation is continuously corrected with real world measurements. This setup, where the simulator drives all policy execution and maintains real-time synchronization with the physical world, shifts the responsibility of crossing the sim-to-real gap to the digital twin's synchronization mechanisms, instead of the policy itself. We demonstrate real-is-sim on a long-horizon manipulation task (PushT), showing that virtual evaluations are consistent with real-world results. We further show how real-world data can be augmented with virtual rollouts and compare to policies trained on different representations derived from the simulator state including object poses and rendered images from both static and robot-mounted cameras. Our results highlight the flexibility of the real-is-sim framework across training, evaluation, and deployment stages. Videos available at https://real-is-sim.github.io.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.03597",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI and Microsoft extend partnership",
    "description": "We‚Äôre happy to announce that OpenAI and¬†Microsoft¬†are extending our¬†partnership.",
    "summary": "We‚Äôre happy to announce that OpenAI and¬†Microsoft¬†are extending our¬†partnership.",
    "pubDate": "Mon, 23 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-microsoft-extend-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Navigating the challenges and opportunities of synthetic voices",
    "description": "We‚Äôre sharing lessons from a small scale preview of Voice Engine, a model for creating custom voices.",
    "summary": "We‚Äôre sharing lessons from a small scale preview of Voice Engine, a model for creating custom voices.",
    "pubDate": "Fri, 29 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/navigating-the-challenges-and-opportunities-of-synthetic-voices",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-Tuning GPT-4o Webinar",
    "description": "Fine-Tuning GPT-4o Webinar",
    "summary": "Fine-Tuning GPT-4o Webinar",
    "pubDate": "Mon, 26 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/fine-tuning-gpt-4o-webinar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "State of open video generation models in Diffusers",
    "description": "",
    "summary": "State of open video generation models in Diffusers OpenAI‚Äôs Sora demo marked a striking advance in A...",
    "pubDate": "Mon, 27 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/video_gen",
    "thumbnail": "https://huggingface.co/blog/assets/video_gen/thumbnail.png"
  },
  {
    "title": "Bridging UI Design and chatbot Interactions: Applying Form-Based Principles to Conversational Agents",
    "description": "arXiv:2507.01862v1 Announce Type: cross Abstract: Domain specific chatbot applications often involve multi step interactions, such as refining search filters, selecting multiple items, or performing comparisons. Traditional graphical user interfaces (GUIs) handle these workflows by providing explicit 'Submit' (commit data) and 'Reset' (discard data) actions, allowing back-end systems to track user intent unambiguously. In contrast, conversational agents rely on subtle language cues, which can lead to confusion and incomplete context management. This paper proposes modeling these GUI inspired metaphors acknowledgment (submit like) and context switching (reset-like) as explicit tasks within large language model (LLM) prompts. By capturing user acknowledgment, reset actions, and chain of thought (CoT) reasoning as structured session data, we preserve clarity, reduce user confusion, and align domain-specific chatbot interactions with back-end logic. We demonstrate our approach in hotel booking and customer management scenarios, highlighting improvements in multi-turn task coherence, user satisfaction, and efficiency.",
    "summary": "arXiv:2507.01862v1 Announce Type: cross Abstract: Domain specific chatbot applications often involve multi step interactions, such as refining search filters, selecting multiple items, or performing comparisons. Traditional graphical user interfaces (GUIs) handle these workflows by providing explicit 'Submit' (commit data) and 'Reset' (discard data) actions, allowing back-end systems to track user intent unambiguously. In contrast, conversational agents rely on subtle language cues, which can lead to confusion and incomplete context management. This paper proposes modeling these GUI inspired metaphors acknowledgment (submit like) and context switching (reset-like) as explicit tasks within large language model (LLM) prompts. By capturing user acknowledgment, reset actions, and chain of thought (CoT) reasoning as structured session data, we preserve clarity, reduce user confusion, and align domain-specific chatbot interactions with back-end logic. We demonstrate our approach in hotel booking and customer management scenarios, highlighting improvements in multi-turn task coherence, user satisfaction, and efficiency.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01862",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Questions for the Record",
    "description": "The following are the Questions for the Record following Sam Altman's testimony before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "summary": "The following are the Questions for the Record following Sam Altman's testimony before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/sam-altman-senate-questions-for-the-record",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerate Large Model Training using DeepSpeed",
    "description": "",
    "summary": "Accelerate Large Model Training using DeepSpeed In this post we will look at how we can leverage the...",
    "pubDate": "Tue, 28 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-deepspeed",
    "thumbnail": "https://huggingface.co/blog/assets/83_accelerate_deepspeed/deepspeed-thumbnail.png"
  },
  {
    "title": "Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration",
    "description": "",
    "summary": "Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration The mission of ...",
    "pubDate": "Wed, 15 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel",
    "thumbnail": "https://huggingface.co/blog/assets/80_intel/01.png"
  },
  {
    "title": "From Chunks to Blocks: Accelerating Uploads and Downloads on the Hub",
    "description": "",
    "summary": "From Chunks to Blocks: Accelerating Uploads and Downloads on the Hub Content-defined chunking (CDC) ...",
    "pubDate": "Wed, 12 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/from-chunks-to-blocks",
    "thumbnail": "https://huggingface.co/blog/assets/from-chunks-to-blocks/thumbnail.png"
  },
  {
    "title": "A Deepdive into Aya Vision: Advancing the Frontier of Multilingual Multimodality",
    "description": "",
    "summary": "A Deepdive into Aya Vision: Advancing the Frontier of Multilingual Multimodality With the release of...",
    "pubDate": "Tue, 04 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aya-vision",
    "thumbnail": "https://huggingface.co/blog/assets/aya-vision/thumbnail.png"
  },
  {
    "title": "Gemini Robotics brings AI into the physical world",
    "description": "Introducing Gemini Robotics and Gemini Robotics-ER, AI models designed for robots to understand, act and react to the physical world.",
    "summary": "Introducing Gemini Robotics and Gemini Robotics-ER, AI models designed for robots to understand, act and react to the physical world.",
    "pubDate": "Wed, 12 Mar 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/",
    "thumbnail": "https://lh3.googleusercontent.com/J74rVi68EPPNMBLxhxI76Bli7QggLtYRYfp5Pk2HVPtSt2NIIk2VmLktQbwDZeIlZiW3AHwlpLNcswHuz_ecR-oj4kI-mtF53yYsGJKfvPugAw5ulQ=w1200-h630-n-nu"
  },
  {
    "title": "Extracting Concepts from GPT-4",
    "description": "Using new techniques for scaling sparse autoencoders, we automatically identified 16 million patterns in GPT-4's computations.",
    "summary": "Using new techniques for scaling sparse autoencoders, we automatically identified 16 million patterns in GPT-4's computations.",
    "pubDate": "Thu, 06 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/extracting-concepts-from-gpt-4",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeRobot goes to driving school: World‚Äôs largest open-source self-driving dataset",
    "description": "",
    "summary": "LeRobot goes to driving school TL;DR of L2D, the world's largest self-driving dataset! - 90+ TeraByt...",
    "pubDate": "Tue, 11 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lerobot-goes-to-driving-school",
    "thumbnail": "https://huggingface.co/blog/assets/193_l2d/lerobot-driver.gif"
  },
  {
    "title": "Medical-Knowledge Driven Multiple Instance Learning for Classifying Severe Abdominal Anomalies on Prenatal Ultrasound",
    "description": "arXiv:2507.01401v1 Announce Type: cross Abstract: Fetal abdominal malformations are serious congenital anomalies that require accurate diagnosis to guide pregnancy management and reduce mortality. Although AI has demonstrated significant potential in medical diagnosis, its application to prenatal abdominal anomalies remains limited. Most existing studies focus on image-level classification and rely on standard plane localization, placing less emphasis on case-level diagnosis. In this paper, we develop a case-level multiple instance learning (MIL)-based method, free of standard plane localization, for classifying fetal abdominal anomalies in prenatal ultrasound. Our contribution is three-fold. First, we adopt a mixture-of-attention-experts module (MoAE) to weight different attention heads for various planes. Secondly, we propose a medical-knowledge-driven feature selection module (MFS) to align image features with medical knowledge, performing self-supervised image token selection at the case-level. Finally, we propose a prompt-based prototype learning (PPL) to enhance the MFS. Extensively validated on a large prenatal abdominal ultrasound dataset containing 2,419 cases, with a total of 24,748 images and 6 categories, our proposed method outperforms the state-of-the-art competitors. Codes are available at:https://github.com/LL-AC/AAcls.",
    "summary": "arXiv:2507.01401v1 Announce Type: cross Abstract: Fetal abdominal malformations are serious congenital anomalies that require accurate diagnosis to guide pregnancy management and reduce mortality. Although AI has demonstrated significant potential in medical diagnosis, its application to prenatal abdominal anomalies remains limited. Most existing studies focus on image-level classification and rely on standard plane localization, placing less emphasis on case-level diagnosis. In this paper, we develop a case-level multiple instance learning (MIL)-based method, free of standard plane localization, for classifying fetal abdominal anomalies in prenatal ultrasound. Our contribution is three-fold. First, we adopt a mixture-of-attention-experts module (MoAE) to weight different attention heads for various planes. Secondly, we propose a medical-knowledge-driven feature selection module (MFS) to align image features with medical knowledge, performing self-supervised image token selection at the case-level. Finally, we propose a prompt-based prototype learning (PPL) to enhance the MFS. Extensively validated on a large prenatal abdominal ultrasound dataset containing 2,419 cases, with a total of 24,748 images and 6 categories, our proposed method outperforms the state-of-the-art competitors. Codes are available at:https://github.com/LL-AC/AAcls.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01401",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NVIDIA's GTC 2025 Announcement for Physical AI Developers: New Open Models and Datasets",
    "description": "",
    "summary": "NVIDIA's GTC 2025 Announcement for Physical AI Developers: New Open Models and Datasets At its annua...",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nvidia-physical-ai",
    "thumbnail": "https://huggingface.co/blog/assets/nvidia-physical-ai/thumbnail.png"
  },
  {
    "title": "Introducing Optimum: The Optimization Toolkit for Transformers at Scale",
    "description": "",
    "summary": "Introducing ü§ó Optimum: The Optimization Toolkit for Transformers at Scale This post is the first ste...",
    "pubDate": "Tue, 14 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hardware-partners-program",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Disrupting deceptive uses of AI by covert influence operations",
    "description": "We‚Äôve terminated accounts linked to covert influence operations; no significant audience increase due to our services.",
    "summary": "We‚Äôve terminated accounts linked to covert influence operations; no significant audience increase due to our services.",
    "pubDate": "Thu, 30 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-deceptive-uses-of-AI-by-covert-influence-operations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 2",
    "description": "",
    "summary": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 2 In a recent post, we introduced...",
    "pubDate": "Mon, 06 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-sapphire-rapids-inference",
    "thumbnail": "https://huggingface.co/blog/assets/129_intel_sapphire_rapids_inference/01.png"
  },
  {
    "title": "Dell Enterprise Hub is all you need to build AI on premises",
    "description": "",
    "summary": "Dell Enterprise Hub is all you need to build AI on premises This week at Dell Tech World, we announc...",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dell-ai-applications",
    "thumbnail": "https://huggingface.co/blog/assets/dell-ai-applications/dell-post-thumbnail.png"
  },
  {
    "title": "Introducing Training Cluster as a Service - a new collaboration with NVIDIA",
    "description": "",
    "summary": "Introducing Training Cluster as a Service - a new collaboration with NVIDIA Today at GTC Paris, we a...",
    "pubDate": "Wed, 11 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nvidia-training-cluster",
    "thumbnail": "https://huggingface.co/blog/assets/nvidia-training-cluster/nvidia-training-cluster-thumbnail-compressed.png"
  },
  {
    "title": "Will Hurd joins OpenAI‚Äôs board of directors",
    "description": "OpenAI is committed to developing general-purpose artificial intelligence that benefits all humanity, and we believe that achieving our goal requires expertise in public policy as well as technology. So, we‚Äôre delighted to announce that Congressman¬†Will Hurd¬†has joined our board of directors.",
    "summary": "OpenAI is committed to developing general-purpose artificial intelligence that benefits all humanity, and we believe that achieving our goal requires expertise in public policy as well as technology. So, we‚Äôre delighted to announce that Congressman¬†Will Hurd¬†has joined our board of directors.",
    "pubDate": "Mon, 03 May 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/will-hurd-joins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "User-guided Generative Source Separation",
    "description": "arXiv:2507.01339v1 Announce Type: cross Abstract: Music source separation (MSS) aims to extract individual instrument sources from their mixture. While most existing methods focus on the widely adopted four-stem separation setup (vocals, bass, drums, and other instruments), this approach lacks the flexibility needed for real-world applications. To address this, we propose GuideSep, a diffusion-based MSS model capable of instrument-agnostic separation beyond the four-stem setup. GuideSep is conditioned on multiple inputs: a waveform mimicry condition, which can be easily provided by humming or playing the target melody, and mel-spectrogram domain masks, which offer additional guidance for separation. Unlike prior approaches that relied on fixed class labels or sound queries, our conditioning scheme, coupled with the generative approach, provides greater flexibility and applicability. Additionally, we design a mask-prediction baseline using the same model architecture to systematically compare predictive and generative approaches. Our objective and subjective evaluations demonstrate that GuideSep achieves high-quality separation while enabling more versatile instrument extraction, highlighting the potential of user participation in the diffusion-based generative process for MSS. Our code and demo page are available at https://yutongwen.github.io/GuideSep/",
    "summary": "arXiv:2507.01339v1 Announce Type: cross Abstract: Music source separation (MSS) aims to extract individual instrument sources from their mixture. While most existing methods focus on the widely adopted four-stem separation setup (vocals, bass, drums, and other instruments), this approach lacks the flexibility needed for real-world applications. To address this, we propose GuideSep, a diffusion-based MSS model capable of instrument-agnostic separation beyond the four-stem setup. GuideSep is conditioned on multiple inputs: a waveform mimicry condition, which can be easily provided by humming or playing the target melody, and mel-spectrogram domain masks, which offer additional guidance for separation. Unlike prior approaches that relied on fixed class labels or sound queries, our conditioning scheme, coupled with the generative approach, provides greater flexibility and applicability. Additionally, we design a mask-prediction baseline using the same model architecture to systematically compare predictive and generative approaches. Our objective and subjective evaluations demonstrate that GuideSep achieves high-quality separation while enabling more versatile instrument extraction, highlighting the potential of user participation in the diffusion-based generative process for MSS. Our code and demo page are available at https://yutongwen.github.io/GuideSep/",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01339",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the ChatGPT app for iOS",
    "description": "The ChatGPT app syncs your conversations, supports voice input, and brings our latest model improvements to your fingertips.",
    "summary": "The ChatGPT app syncs your conversations, supports voice input, and brings our latest model improvements to your fingertips.",
    "pubDate": "Thu, 18 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-chatgpt-app-for-ios",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Data Partnerships",
    "description": "Working together to create open-source and private datasets for AI training.",
    "summary": "Working together to create open-source and private datasets for AI training.",
    "pubDate": "Thu, 09 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/data-partnerships",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Discovering the minutiae of backend systems",
    "description": "Christian Gibson is an engineer on the Supercomputing team at OpenAI.",
    "summary": "Christian Gibson is an engineer on the Supercomputing team at OpenAI.",
    "pubDate": "Thu, 08 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/discovering-the-minutiae-of-backend-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "We‚Äôre bringing the Financial Times‚Äô world-class journalism to ChatGPT",
    "description": "We will also collaborate on new AI experiences for FT readers.",
    "summary": "We will also collaborate on new AI experiences for FT readers.",
    "pubDate": "Mon, 29 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/content-partnership-with-financial-times",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Disrupting malicious uses of AI",
    "description": "Ensuring AI benefits humanity by advancing democratic AI, preventing misuse, and protecting against authoritarian threats.",
    "summary": "Ensuring AI benefits humanity by advancing democratic AI, preventing misuse, and protecting against authoritarian threats.",
    "pubDate": "Fri, 21 Feb 2025 06:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The International 2018: Results",
    "description": "OpenAI Five lost two games against top Dota 2 players at The International in Vancouver this week, maintaining a good chance of winning for the first 20‚Äì35 minutes of both¬†games.",
    "summary": "OpenAI Five lost two games against top Dota 2 players at The International in Vancouver this week, maintaining a good chance of winning for the first 20‚Äì35 minutes of both¬†games.",
    "pubDate": "Thu, 23 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-international-2018-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Human Mobility Modeling with Household Coordination Activities under Limited Information via Retrieval-Augmented LLMs",
    "description": "arXiv:2409.17495v2 Announce Type: replace Abstract: Understanding human mobility patterns has long been a challenging task in transportation modeling. Due to the difficulties in obtaining high-quality training datasets across diverse locations, conventional activity-based models and learning-based human mobility modeling algorithms are particularly limited by the availability and quality of datasets. Current approaches primarily focus on spatial-temporal patterns while neglecting semantic relationships such as logical connections or dependencies between activities and household coordination activities like joint shopping trips or family meal times, both crucial for realistic mobility modeling. We propose a retrieval-augmented large language model (LLM) framework that generates activity chains with household coordination using only public accessible statistical and socio-demographic information, reducing the need for sophisticated mobility data. The retrieval-augmentation mechanism enables household coordination and maintains statistical consistency across generated patterns, addressing a key gap in existing methods. Our validation with NHTS and SCAG-ABM datasets demonstrates effective mobility synthesis and strong adaptability for regions with limited mobility data availability.",
    "summary": "arXiv:2409.17495v2 Announce Type: replace Abstract: Understanding human mobility patterns has long been a challenging task in transportation modeling. Due to the difficulties in obtaining high-quality training datasets across diverse locations, conventional activity-based models and learning-based human mobility modeling algorithms are particularly limited by the availability and quality of datasets. Current approaches primarily focus on spatial-temporal patterns while neglecting semantic relationships such as logical connections or dependencies between activities and household coordination activities like joint shopping trips or family meal times, both crucial for realistic mobility modeling. We propose a retrieval-augmented large language model (LLM) framework that generates activity chains with household coordination using only public accessible statistical and socio-demographic information, reducing the need for sophisticated mobility data. The retrieval-augmentation mechanism enables household coordination and maintains statistical consistency across generated patterns, addressing a key gap in existing methods. Our validation with NHTS and SCAG-ABM datasets demonstrates effective mobility synthesis and strong adaptability for regions with limited mobility data availability.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.17495",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome aMUSEd: Efficient Text-to-Image Generation",
    "description": "",
    "summary": "Welcome aMUSEd: Efficient Text-to-Image Generation We‚Äôre excited to present an efficient non-diffusi...",
    "pubDate": "Thu, 04 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/amused",
    "thumbnail": "https://huggingface.co/blog/assets/amused/thumbnail.png"
  },
  {
    "title": "SFO: Piloting VLM Feedback for Offline RL",
    "description": "arXiv:2503.01062v4 Announce Type: replace-cross Abstract: While internet-scale image and textual data have enabled strong generalization in Vision-Language Models (VLMs), the absence of internet-scale control data has impeded the development of similar generalization in standard reinforcement learning (RL) agents. Although VLMs are fundamentally limited in their ability to solve control tasks due to their lack of action-conditioned training data, their capacity for image understanding allows them to provide valuable feedback in RL tasks by recognizing successful outcomes. A key challenge in Reinforcement Learning from AI Feedback (RLAIF) is determining how best to integrate VLM-derived signals into the learning process. We explore this question in the context of offline RL and introduce a class of methods called sub-trajectory filtered optimization. We identify three key insights. First, trajectory length plays a crucial role in offline RL, as full-trajectory preference learning exacerbates the stitching problem, necessitating the use of sub-trajectories. Second, even in Markovian environments, a non-Markovian reward signal from a sequence of images is required to assess trajectory improvement, as VLMs do not interpret control actions and must rely on visual cues over time. Third, a simple yet effective approach--filtered and weighted behavior cloning--consistently outperforms more complex reinforcement learning from human feedback-based methods. We propose sub-trajectory filtered behavior cloning, a method that leverages VLM feedback on sub-trajectories while incorporating a retrospective filtering mechanism that removes sub-trajectories preceding failures to improve robustness and prevent turbulence. This study is preliminary; we provide initial evidence through evaluations on a toy control domain. Please enjoy our airport puns.",
    "summary": "arXiv:2503.01062v4 Announce Type: replace-cross Abstract: While internet-scale image and textual data have enabled strong generalization in Vision-Language Models (VLMs), the absence of internet-scale control data has impeded the development of similar generalization in standard reinforcement learning (RL) agents. Although VLMs are fundamentally limited in their ability to solve control tasks due to their lack of action-conditioned training data, their capacity for image understanding allows them to provide valuable feedback in RL tasks by recognizing successful outcomes. A key challenge in Reinforcement Learning from AI Feedback (RLAIF) is determining how best to integrate VLM-derived signals into the learning process. We explore this question in the context of offline RL and introduce a class of methods called sub-trajectory filtered optimization. We identify three key insights. First, trajectory length plays a crucial role in offline RL, as full-trajectory preference learning exacerbates the stitching problem, necessitating the use of sub-trajectories. Second, even in Markovian environments, a non-Markovian reward signal from a sequence of images is required to assess trajectory improvement, as VLMs do not interpret control actions and must rely on visual cues over time. Third, a simple yet effective approach--filtered and weighted behavior cloning--consistently outperforms more complex reinforcement learning from human feedback-based methods. We propose sub-trajectory filtered behavior cloning, a method that leverages VLM feedback on sub-trajectories while incorporating a retrospective filtering mechanism that removes sub-trajectories preceding failures to improve robustness and prevent turbulence. This study is preliminary; we provide initial evidence through evaluations on a toy control domain. Please enjoy our airport puns.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.01062",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Dive into Pretraining Strategies for Vision-Language Models",
    "description": "",
    "summary": "A Dive into Vision-Language Models Human learning is inherently multi-modal as jointly leveraging mu...",
    "pubDate": "Fri, 03 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vision_language_pretraining",
    "thumbnail": "https://huggingface.co/blog//assets/128_vision_language_pretraining/thumbnail.png"
  },
  {
    "title": "Organizational update from OpenAI",
    "description": "It‚Äôs been a year of dramatic change and growth at OpenAI.",
    "summary": "It‚Äôs been a year of dramatic change and growth at OpenAI.",
    "pubDate": "Tue, 29 Dec 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/organizational-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Expanding on how Voice Engine works and our safety research",
    "description": "Exploring the technology behind our text-to-speech model.",
    "summary": "Exploring the technology behind our text-to-speech model.",
    "pubDate": "Fri, 07 Jun 2024 17:45:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expanding-on-how-voice-engine-works-and-our-safety-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DeepMind‚Äôs latest research at NeurIPS 2022",
    "description": "NeurIPS is the world‚Äôs largest conference in artificial intelligence (AI) and machine learning (ML), and we‚Äôre proud to support the event as Diamond sponsors, helping foster the exchange of research advances in the AI and ML community. Teams from across DeepMind are presenting 47 papers, including 35 external collaborations in virtual panels and poster sessions.",
    "summary": "NeurIPS is the world‚Äôs largest conference in artificial intelligence (AI) and machine learning (ML), and we‚Äôre proud to support the event as Diamond sponsors, helping foster the exchange of research advances in the AI and ML community. Teams from across DeepMind are presenting 47 papers, including 35 external collaborations in virtual panels and poster sessions.",
    "pubDate": "Fri, 25 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/deepminds-latest-research-at-neurips-2022/",
    "thumbnail": "https://lh3.googleusercontent.com/MFZKdGWHOzJ6nM8NufhIfpts0R-v9D4jQqnC416FT8ArwmNC2Ztke2S50WVtUhO0g1u8AGmYEyWMDC7LO0a16ydHBMei9GmJO4NjykhpLKw1TVtd4Mg=w1200-h630-n-nu"
  },
  {
    "title": "Learning Day",
    "description": "At OpenAI, each Thursday is Learning Day: a day where employees have the option to self-study technical skills that will make them better at their job but which aren‚Äôt being learned from daily work.",
    "summary": "At OpenAI, each Thursday is Learning Day: a day where employees have the option to self-study technical skills that will make them better at their job but which aren‚Äôt being learned from daily work.",
    "pubDate": "Thu, 01 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-day",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Minne Atairu & Sora",
    "description": "Interdisciplinary artist Minne Atairu discusses how Sora helps realize her vision.",
    "summary": "Interdisciplinary artist Minne Atairu discusses how Sora helps realize her vision.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-minne-atairu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI Japan",
    "description": "We are excited to announce our first office in Asia and we‚Äôre releasing a GPT-4 custom model optimized for the Japanese language.",
    "summary": "We are excited to announce our first office in Asia and we‚Äôre releasing a GPT-4 custom model optimized for the Japanese language.",
    "pubDate": "Sun, 14 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-japan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemma: Introducing new state-of-the-art open models",
    "description": "Gemma is built for responsible AI development from the same research and technology used to create Gemini models.",
    "summary": "Gemma is built for responsible AI development from the same research and technology used to create Gemini models.",
    "pubDate": "Wed, 21 Feb 2024 13:06:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemma-introducing-new-state-of-the-art-open-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemma-social-share.width-1300.jpg"
  },
  {
    "title": "OpenAI Fellows Summer 2018: Final projects",
    "description": "Our first cohort of OpenAI Fellows has concluded, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship.",
    "summary": "Our first cohort of OpenAI Fellows has concluded, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship.",
    "pubDate": "Wed, 19 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-summer-fellows-2018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bringing intelligence to every workflow",
    "description": "Notion is a connected workspace where teams write, plan, and organize everything from meeting notes to product roadmaps. Today, it‚Äôs also a deeply AI-powered platform, used by millions to summarize content, generate writing, and ask questions in natural language across their entire workspace.",
    "summary": "Notion is a connected workspace where teams write, plan, and organize everything from meeting notes to product roadmaps. Today, it‚Äôs also a deeply AI-powered platform, used by millions to summarize content, generate writing, and ask questions in natural language across their entire workspace.",
    "pubDate": "Thu, 03 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/notion",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making automatic speech recognition work on large files with Wav2Vec2 in ü§ó Transformers",
    "description": "",
    "summary": "Making automatic speech recognition work on large files with Wav2Vec2 in ü§ó Transformers Tl;dr: This ...",
    "pubDate": "Tue, 01 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/asr-chunking",
    "thumbnail": "https://huggingface.co/blog/assets/49_asr_chunking/thumbnail.png"
  },
  {
    "title": "GraphGSOcc: Semantic-Geometric Graph Transformer with Dynamic-Static Decoupling for 3D Gaussian Splatting-based Occupancy Prediction",
    "description": "arXiv:2506.14825v2 Announce Type: replace-cross Abstract: Addressing the task of 3D semantic occupancy prediction for autonomous driving, we tackle two key issues in existing 3D Gaussian Splatting (3DGS) methods: (1) unified feature aggregation neglecting semantic correlations among similar categories and across regions, (2) boundary ambiguities caused by the lack of geometric constraints in MLP iterative optimization and (3) biased issues in dynamic-static object coupling optimization. We propose the GraphGSOcc model, a novel framework that combines semantic and geometric graph Transformer and decouples dynamic-static objects optimization for 3D Gaussian Splatting-based Occupancy Prediction. We propose the Dual Gaussians Graph Attenntion, which dynamically constructs dual graph structures: a geometric graph adaptively calculating KNN search radii based on Gaussian poses, enabling large-scale Gaussians to aggregate features from broader neighborhoods while compact Gaussians focus on local geometric consistency; a semantic graph retaining top-M highly correlated nodes via cosine similarity to explicitly encode semantic relationships within and across instances. Coupled with the Multi-scale Graph Attention framework, fine-grained attention at lower layers optimizes boundary details, while coarsegrained attention at higher layers models object-level topology. On the other hand, we decouple dynamic and static objects by leveraging semantic probability distributions and design a Dynamic-Static Decoupled Gaussian Attention mechanism to optimize the prediction performance for both dynamic objects and static scenes. GraphGSOcc achieves state-ofthe-art performance on the SurroundOcc-nuScenes, Occ3D-nuScenes, OpenOcc and KITTI occupancy benchmarks. Experiments on the SurroundOcc dataset achieve an mIoU of 25.20%, reducing GPU memory to 6.8 GB, demonstrating a 1.97% mIoU improvement and 13.7% memory reduction compared to GaussianWorld.",
    "summary": "arXiv:2506.14825v2 Announce Type: replace-cross Abstract: Addressing the task of 3D semantic occupancy prediction for autonomous driving, we tackle two key issues in existing 3D Gaussian Splatting (3DGS) methods: (1) unified feature aggregation neglecting semantic correlations among similar categories and across regions, (2) boundary ambiguities caused by the lack of geometric constraints in MLP iterative optimization and (3) biased issues in dynamic-static object coupling optimization. We propose the GraphGSOcc model, a novel framework that combines semantic and geometric graph Transformer and decouples dynamic-static objects optimization for 3D Gaussian Splatting-based Occupancy Prediction. We propose the Dual Gaussians Graph Attenntion, which dynamically constructs dual graph structures: a geometric graph adaptively calculating KNN search radii based on Gaussian poses, enabling large-scale Gaussians to aggregate features from broader neighborhoods while compact Gaussians focus on local geometric consistency; a semantic graph retaining top-M highly correlated nodes via cosine similarity to explicitly encode semantic relationships within and across instances. Coupled with the Multi-scale Graph Attention framework, fine-grained attention at lower layers optimizes boundary details, while coarsegrained attention at higher layers models object-level topology. On the other hand, we decouple dynamic and static objects by leveraging semantic probability distributions and design a Dynamic-Static Decoupled Gaussian Attention mechanism to optimize the prediction performance for both dynamic objects and static scenes. GraphGSOcc achieves state-ofthe-art performance on the SurroundOcc-nuScenes, Occ3D-nuScenes, OpenOcc and KITTI occupancy benchmarks. Experiments on the SurroundOcc dataset achieve an mIoU of 25.20%, reducing GPU memory to 6.8 GB, demonstrating a 1.97% mIoU improvement and 13.7% memory reduction compared to GaussianWorld.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14825",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Annotated Diffusion Model",
    "description": "",
    "summary": "The Annotated Diffusion Model In this blog post, we'll take a deeper look into Denoising Diffusion P...",
    "pubDate": "Tue, 07 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/annotated-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/78_annotated-diffusion/thumbnail.png"
  },
  {
    "title": "Recursive Training Loops in LLMs: How training data properties modulate distribution shift in generated data?",
    "description": "arXiv:2504.03814v3 Announce Type: replace-cross Abstract: Large language models (LLMs) are increasingly used in the creation of online content, creating feedback loops as subsequent generations of models will be trained on this synthetic data. Such loops were shown to lead to distribution shifts - models misrepresenting the true underlying distributions of human data (also called model collapse). However, how human data properties affect such shifts remains poorly understood. In this paper, we provide the first empirical examination of the effect of such properties on the outcome of recursive training. We first confirm that using different human datasets leads to distribution shifts of different magnitudes. Through exhaustive manipulation of dataset properties combined with regression analyses, we then identify a set of properties predicting distribution shift magnitudes. Lexical diversity is found to amplify these shifts, while semantic diversity and data quality mitigate them. Furthermore, we find that these influences are highly modular: data scrapped from a given internet domain has little influence on the content generated for another domain. Finally, experiments on political bias reveal that human data properties affect whether the initial bias will be amplified or reduced. Overall, our results portray a novel view, where different parts of internet may undergo different types of distribution shift.",
    "summary": "arXiv:2504.03814v3 Announce Type: replace-cross Abstract: Large language models (LLMs) are increasingly used in the creation of online content, creating feedback loops as subsequent generations of models will be trained on this synthetic data. Such loops were shown to lead to distribution shifts - models misrepresenting the true underlying distributions of human data (also called model collapse). However, how human data properties affect such shifts remains poorly understood. In this paper, we provide the first empirical examination of the effect of such properties on the outcome of recursive training. We first confirm that using different human datasets leads to distribution shifts of different magnitudes. Through exhaustive manipulation of dataset properties combined with regression analyses, we then identify a set of properties predicting distribution shift magnitudes. Lexical diversity is found to amplify these shifts, while semantic diversity and data quality mitigate them. Furthermore, we find that these influences are highly modular: data scrapped from a given internet domain has little influence on the content generated for another domain. Finally, experiments on political bias reveal that human data properties affect whether the initial bias will be amplified or reduced. Overall, our results portray a novel view, where different parts of internet may undergo different types of distribution shift.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.03814",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Systematic Review of Security Vulnerabilities in Smart Home Devices and Mitigation Techniques",
    "description": "arXiv:2507.01018v1 Announce Type: cross Abstract: Smart homes that integrate Internet of Things (IoT) devices face increasing cybersecurity risks, posing significant challenges to these environments. The study explores security threats in smart homes ecosystems, categorizing them into vulnerabilities at the network layer, device level, and those from cloud-based and AI-driven systems. Research findings indicate that post-quantum encryption, coupled with AI-driven anomaly detection, is highly effective in enhancing security; however, computational resource demands present significant challenges. Blockchain authentication together with zero-trust structures builds security resilience, although they need changes to existing infrastructure. The specific security strategies show their effectiveness through ANOVA, Chi-square tests, and Monte Carlo simulations yet lack sufficient scalability according to the results. The research demonstrates the requirement for improvement in cryptographic techniques, alongside AI-enhanced threat detection and adaptive security models which must achieve a balance between performance and efficiency and real-time applicability within smart home ecosystems.",
    "summary": "arXiv:2507.01018v1 Announce Type: cross Abstract: Smart homes that integrate Internet of Things (IoT) devices face increasing cybersecurity risks, posing significant challenges to these environments. The study explores security threats in smart homes ecosystems, categorizing them into vulnerabilities at the network layer, device level, and those from cloud-based and AI-driven systems. Research findings indicate that post-quantum encryption, coupled with AI-driven anomaly detection, is highly effective in enhancing security; however, computational resource demands present significant challenges. Blockchain authentication together with zero-trust structures builds security resilience, although they need changes to existing infrastructure. The specific security strategies show their effectiveness through ANOVA, Chi-square tests, and Monte Carlo simulations yet lack sufficient scalability according to the results. The research demonstrates the requirement for improvement in cryptographic techniques, alongside AI-enhanced threat detection and adaptive security models which must achieve a balance between performance and efficiency and real-time applicability within smart home ecosystems.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CinePile 2.0 - making stronger datasets with adversarial refinement",
    "description": "",
    "summary": "CinePile 2.0 - making stronger datasets with adversarial refinement In this blog post we share the j...",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cinepile2",
    "thumbnail": "https://huggingface.co/blog/assets/188_cinepile2/thumbnail.png"
  },
  {
    "title": "Getting Started with Sentiment Analysis on Twitter",
    "description": "",
    "summary": "Getting Started with Sentiment Analysis on Twitter Sentiment analysis is the automatic process of cl...",
    "pubDate": "Thu, 07 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-twitter",
    "thumbnail": "https://huggingface.co/blog/assets/85_sentiment_analysis_twitter/thumbnail.png"
  },
  {
    "title": "Releasing Swift Transformers: Run On-Device LLMs in Apple Devices",
    "description": "",
    "summary": "Releasing Swift Transformers: Run On-Device LLMs in Apple Devices I have a lot of respect for iOS/Ma...",
    "pubDate": "Tue, 08 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/swift-coreml-llm",
    "thumbnail": "https://huggingface.co/blog/assets/swift-coreml-llm/thumbnail.png"
  },
  {
    "title": "Disrupting a covert Iranian influence operation",
    "description": "We banned accounts linked to a covert Iranian influence operation using ChatGPT to generate website and social media content focused on multiple topics, including the U.S. presidential campaign. We have seen no indication that this content reached a meaningful audience.",
    "summary": "We banned accounts linked to a covert Iranian influence operation using ChatGPT to generate website and social media content focused on multiple topics, including the U.S. presidential campaign. We have seen no indication that this content reached a meaningful audience.",
    "pubDate": "Fri, 16 Aug 2024 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-a-covert-iranian-influence-operation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How NuminaMath Won the 1st AIMO Progress Prize",
    "description": "",
    "summary": "How NuminaMath Won the 1st AIMO Progress Prize This year, Numina and Hugging Face collaborated to co...",
    "pubDate": "Thu, 11 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/winning-aimo-progress-prize",
    "thumbnail": "https://huggingface.co/blog/assets/winning-aimo-progress-prize/thumbnail.png"
  },
  {
    "title": "SpikeNAS: A Fast Memory-Aware Neural Architecture Search Framework for Spiking Neural Network-based Embedded AI Systems",
    "description": "arXiv:2402.11322v4 Announce Type: replace-cross Abstract: Embedded AI systems are expected to incur low power/energy consumption for solving machine learning tasks, as these systems are usually power constrained (e.g., object recognition task in autonomous mobile agents with portable batteries). These requirements can be fulfilled by Spiking Neural Networks (SNNs), since their bio-inspired spike-based operations offer high accuracy and ultra low-power/energy computation. Currently, most of SNN architectures are derived from Artificial Neural Networks whose neurons' architectures and operations are different from SNNs, and/or developed without considering memory budgets from the underlying processing hardware of embedded platforms. These limitations hinder SNNs from reaching their full potential in accuracy and efficiency. Toward this, we propose SpikeNAS, a novel fast memory-aware neural architecture search (NAS) framework for SNNs that quickly finds an appropriate SNN architecture with high accuracy under the given memory budgets from targeted embedded systems. To do this, our SpikeNAS employs several key steps: analyzing the impacts of network operations on the accuracy, enhancing the network architecture to improve the learning quality, developing a fast memory-aware search algorithm, and performing quantization. The experimental results show that our SpikeNAS improves the searching time and maintains high accuracy compared to state-of-the-art while meeting the given memory budgets (e.g., 29x, 117x, and 3.7x faster search for CIFAR10, CIFAR100, and TinyImageNet200 respectively, using an Nvidia RTX A6000 GPU machine), thereby quickly providing the appropriate SNN architecture for the memory-constrained embedded AI systems.",
    "summary": "arXiv:2402.11322v4 Announce Type: replace-cross Abstract: Embedded AI systems are expected to incur low power/energy consumption for solving machine learning tasks, as these systems are usually power constrained (e.g., object recognition task in autonomous mobile agents with portable batteries). These requirements can be fulfilled by Spiking Neural Networks (SNNs), since their bio-inspired spike-based operations offer high accuracy and ultra low-power/energy computation. Currently, most of SNN architectures are derived from Artificial Neural Networks whose neurons' architectures and operations are different from SNNs, and/or developed without considering memory budgets from the underlying processing hardware of embedded platforms. These limitations hinder SNNs from reaching their full potential in accuracy and efficiency. Toward this, we propose SpikeNAS, a novel fast memory-aware neural architecture search (NAS) framework for SNNs that quickly finds an appropriate SNN architecture with high accuracy under the given memory budgets from targeted embedded systems. To do this, our SpikeNAS employs several key steps: analyzing the impacts of network operations on the accuracy, enhancing the network architecture to improve the learning quality, developing a fast memory-aware search algorithm, and performing quantization. The experimental results show that our SpikeNAS improves the searching time and maintains high accuracy compared to state-of-the-art while meeting the given memory budgets (e.g., 29x, 117x, and 3.7x faster search for CIFAR10, CIFAR100, and TinyImageNet200 respectively, using an Nvidia RTX A6000 GPU machine), thereby quickly providing the appropriate SNN architecture for the memory-constrained embedded AI systems.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2402.11322",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Putting AI to work at Upwork",
    "description": "Upwork puts AI to work, uniting team members, operations and product development",
    "summary": "Upwork puts AI to work, uniting team members, operations and product development",
    "pubDate": "Tue, 20 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/upwork",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our next-generation model: Gemini 1.5",
    "description": "The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities.",
    "summary": "The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities.",
    "pubDate": "Thu, 15 Feb 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/our-next-generation-model-gemini-15/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/final_gemini_1.5_blog_social_share_800x418.width-1300.png"
  },
  {
    "title": "Comment on NTIA AI Accountability Policy",
    "description": "The National Telecommunications and Information Administration (NTIA) request for comments on AI Accountability policy.",
    "summary": "The National Telecommunications and Information Administration (NTIA) request for comments on AI Accountability policy.",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/comment-on-ntia-ai-accountability-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Optimum-NVIDIA - Unlock blazingly fast LLM inference in just 1 line of code",
    "description": "",
    "summary": "Optimum-NVIDIA on Hugging Face enables blazingly fast LLM inference in just 1 line of code Large Lan...",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-nvidia",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_nvidia/hf_nvidia_banner.png"
  },
  {
    "title": "Awakening Sleeping Beauties at The Met",
    "description": "AI can enrich lives through beauty and creativity, and its artistic potential shines in 'Sleeping Beauties: Reawakening Fashion,' a collaborative exhibit from The Met's Costume Institute.",
    "summary": "AI can enrich lives through beauty and creativity, and its artistic potential shines in 'Sleeping Beauties: Reawakening Fashion,' a collaborative exhibit from The Met's Costume Institute.",
    "pubDate": "Wed, 14 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-met-museum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeMaterial: an open source initiative to accelerate materials discovery and research",
    "description": "",
    "summary": "LeMaterial: an open source initiative to accelerate materials discovery and research Today, we are t...",
    "pubDate": "Tue, 10 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lematerial",
    "thumbnail": "https://huggingface.co/blog/assets/lematerial/thumbnail_lematerial.png"
  },
  {
    "title": "SmolVLA: Efficient Vision-Language-Action Model trained on Lerobot Community Data",
    "description": "",
    "summary": "SmolVLA: Efficient Vision-Language-Action Model trained on Lerobot Community Data üß≠TL;DR Today, we i...",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvla",
    "thumbnail": "https://huggingface.co/blog/assets/smolvla/SmolVLA_thumbnail.png"
  },
  {
    "title": "Spinning Up in Deep RL: Workshop review",
    "description": "On February 2, we held our first Spinning Up Workshop as part of our new education initiative at OpenAI.",
    "summary": "On February 2, we held our first Spinning Up Workshop as part of our new education initiative at OpenAI.",
    "pubDate": "Tue, 26 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spinning-up-in-deep-rl-workshop-review",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome Mixtral - a SOTA Mixture of Experts on Hugging Face",
    "description": "",
    "summary": "Welcome Mixtral - a SOTA Mixture of Experts on Hugging Face Mixtral 8x7b is an exciting large langua...",
    "pubDate": "Mon, 11 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mixtral",
    "thumbnail": "https://huggingface.co/blog/assets/mixtral/thumbnail.jpg"
  },
  {
    "title": "Deprecation of Git Authentication using password",
    "description": "",
    "summary": "Hugging Face Hub: Important Git Authentication Changes Because we are committed to improving the sec...",
    "pubDate": "Fri, 25 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/password-git-deprecation",
    "thumbnail": "https://huggingface.co/blog/assets/password-git-deprecation/thumbnail.png"
  },
  {
    "title": "Improving language model behavior by training on a curated dataset",
    "description": "Our latest research finds we can improve language model behavior with respect to specific behavioral values by fine-tuning on a small, curated¬†dataset.",
    "summary": "Our latest research finds we can improve language model behavior with respect to specific behavioral values by fine-tuning on a small, curated¬†dataset.",
    "pubDate": "Thu, 10 Jun 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-language-model-behavior",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ü§ó PEFT welcomes new merging methods",
    "description": "",
    "summary": "ü§ó PEFT welcomes new merging methods Model merging has quickly become the de-facto standard of pushin...",
    "pubDate": "Mon, 19 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/peft_merging",
    "thumbnail": "https://huggingface.co/blog/assets/peft_merging/thumbnail.png"
  },
  {
    "title": "Learning policy representations in multiagent systems",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 17 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-policy-representations-in-multiagent-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Adversarial attacks on neural network policies",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 Feb 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adversarial-attacks-on-neural-network-policies",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Intelligence Age",
    "description": "We aired our first-ever television ad during the Super Bowl to pique people‚Äôs curiosity and help us all realize how AI can open up new possibilities for us, create more fulfillment in our lives, and make us more productive, just as all the tools that came before AI did for those who came before us.",
    "summary": "We aired our first-ever television ad during the Super Bowl to pique people‚Äôs curiosity and help us all realize how AI can open up new possibilities for us, create more fulfillment in our lives, and make us more productive, just as all the tools that came before AI did for those who came before us.",
    "pubDate": "Sun, 09 Feb 2025 22:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-the-intelligence-age",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "#Exploration: A study of count-based exploration for deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 15 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/exploration",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Consistency Models with Generator-Augmented Flows",
    "description": "arXiv:2406.09570v4 Announce Type: replace-cross Abstract: Consistency models imitate the multi-step sampling of score-based diffusion in a single forward pass of a neural network. They can be learned in two ways: consistency distillation and consistency training. The former relies on the true velocity field of the corresponding differential equation, approximated by a pre-trained neural network. In contrast, the latter uses a single-sample Monte Carlo estimate of this velocity field. The related estimation error induces a discrepancy between consistency distillation and training that, we show, still holds in the continuous-time limit. To alleviate this issue, we propose a novel flow that transports noisy data towards their corresponding outputs derived from a consistency model. We prove that this flow reduces the previously identified discrepancy and the noise-data transport cost. Consequently, our method not only accelerates consistency training convergence but also enhances its overall performance. The code is available at: https://github.com/thibautissenhuth/consistency_GC.",
    "summary": "arXiv:2406.09570v4 Announce Type: replace-cross Abstract: Consistency models imitate the multi-step sampling of score-based diffusion in a single forward pass of a neural network. They can be learned in two ways: consistency distillation and consistency training. The former relies on the true velocity field of the corresponding differential equation, approximated by a pre-trained neural network. In contrast, the latter uses a single-sample Monte Carlo estimate of this velocity field. The related estimation error induces a discrepancy between consistency distillation and training that, we show, still holds in the continuous-time limit. To alleviate this issue, we propose a novel flow that transports noisy data towards their corresponding outputs derived from a consistency model. We prove that this flow reduces the previously identified discrepancy and the noise-data transport cost. Consequently, our method not only accelerates consistency training convergence but also enhances its overall performance. The code is available at: https://github.com/thibautissenhuth/consistency_GC.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.09570",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sublinear Regret for a Class of Continuous-Time Linear-Quadratic Reinforcement Learning Problems",
    "description": "arXiv:2407.17226v5 Announce Type: replace-cross Abstract: We study reinforcement learning (RL) for a class of continuous-time linear-quadratic (LQ) control problems for diffusions, where states are scalar-valued and running control rewards are absent but volatilities of the state processes depend on both state and control variables. We apply a model-free approach that relies neither on knowledge of model parameters nor on their estimations, and devise an RL algorithm to learn the optimal policy parameter directly. Our main contributions include the introduction of an exploration schedule and a regret analysis of the proposed algorithm. We provide the convergence rate of the policy parameter to the optimal one, and prove that the algorithm achieves a regret bound of $O(N^{frac{3}{4}})$ up to a logarithmic factor, where $N$ is the number of learning episodes. We conduct a simulation study to validate the theoretical results and demonstrate the effectiveness and reliability of the proposed algorithm. We also perform numerical comparisons between our method and those of the recent model-based stochastic LQ RL studies adapted to the state- and control-dependent volatility setting, demonstrating a better performance of the former in terms of regret bounds.",
    "summary": "arXiv:2407.17226v5 Announce Type: replace-cross Abstract: We study reinforcement learning (RL) for a class of continuous-time linear-quadratic (LQ) control problems for diffusions, where states are scalar-valued and running control rewards are absent but volatilities of the state processes depend on both state and control variables. We apply a model-free approach that relies neither on knowledge of model parameters nor on their estimations, and devise an RL algorithm to learn the optimal policy parameter directly. Our main contributions include the introduction of an exploration schedule and a regret analysis of the proposed algorithm. We provide the convergence rate of the policy parameter to the optimal one, and prove that the algorithm achieves a regret bound of $O(N^{frac{3}{4}})$ up to a logarithmic factor, where $N$ is the number of learning episodes. We conduct a simulation study to validate the theoretical results and demonstrate the effectiveness and reliability of the proposed algorithm. We also perform numerical comparisons between our method and those of the recent model-based stochastic LQ RL studies adapted to the state- and control-dependent volatility setting, demonstrating a better performance of the former in terms of regret bounds.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.17226",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Cosmopedia: how to create large-scale synthetic data for pre-training Large Language Models",
    "description": "",
    "summary": "Cosmopedia: how to create large-scale synthetic data for pre-training In this blog post, we outline ...",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cosmopedia",
    "thumbnail": "https://huggingface.co/blog/assets/cosmopedia/thumbnail.png"
  },
  {
    "title": "Data is better together",
    "description": "",
    "summary": "Data is better together: Enabling communities to collectively build better datasets together using A...",
    "pubDate": "Mon, 04 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/community-datasets/thumbnail.png"
  },
  {
    "title": "AI learns how vision and sound are connected, without human intervention",
    "description": "This new machine-learning model can match corresponding audio and visual data, which could someday help robots interact in the real world.",
    "summary": "This new machine-learning model can match corresponding audio and visual data, which could someday help robots interact in the real world.",
    "pubDate": "Thu, 22 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-learns-how-vision-and-sound-are-connected-without-human-intervention-0522",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-AV-Learning-01-press.jpg"
  },
  {
    "title": "Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel",
    "description": "",
    "summary": "Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel In this post we will look ...",
    "pubDate": "Mon, 02 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-fsdp",
    "thumbnail": "https://huggingface.co/blog/assets/62_pytorch_fsdp/fsdp-thumbnail.png"
  },
  {
    "title": "Graph Classification with Transformers",
    "description": "",
    "summary": "Graph classification with Transformers In the previous blog, we explored some of the theoretical asp...",
    "pubDate": "Fri, 14 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphml-classification",
    "thumbnail": "https://huggingface.co/blog/assets/125_intro-to-graphml/thumbnail_classification.png"
  },
  {
    "title": "Using Large Language Models to Categorize Strategic Situations and Decipher Motivations Behind Human Behaviors",
    "description": "arXiv:2503.15752v5 Announce Type: replace Abstract: By varying prompts to a large language model, we can elicit the full range of human behaviors in a variety of different scenarios in classic economic games. By analyzing which prompts elicit which behaviors, we can categorize and compare different strategic situations, which can also help provide insight into what different economic scenarios induce people to think about. We discuss how this provides a first step towards a non-standard method of inferring (deciphering) the motivations behind the human behaviors. We also show how this deciphering process can be used to categorize differences in the behavioral tendencies of different populations.",
    "summary": "arXiv:2503.15752v5 Announce Type: replace Abstract: By varying prompts to a large language model, we can elicit the full range of human behaviors in a variety of different scenarios in classic economic games. By analyzing which prompts elicit which behaviors, we can categorize and compare different strategic situations, which can also help provide insight into what different economic scenarios induce people to think about. We discuss how this provides a first step towards a non-standard method of inferring (deciphering) the motivations behind the human behaviors. We also show how this deciphering process can be used to categorize differences in the behavioral tendencies of different populations.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.15752",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI supporters",
    "description": "We‚Äôre excited to welcome new donors to OpenAI.",
    "summary": "We‚Äôre excited to welcome new donors to OpenAI.",
    "pubDate": "Tue, 20 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-supporters",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Run a Chatgpt-like Chatbot on a Single GPU with ROCm",
    "description": "",
    "summary": "Run a Chatgpt-like Chatbot on a Single GPU with ROCm Introduction ChatGPT, OpenAI's groundbreaking l...",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chatbot-amd-gpu",
    "thumbnail": "https://huggingface.co/blog/assets/chatbot-amd-gpu/thumbnail.png"
  },
  {
    "title": "Introducing the Open Ko-LLM Leaderboard: Leading the Korean LLM Evaluation Ecosystem",
    "description": "",
    "summary": "Introducing the Open Ko-LLM Leaderboard: Leading the Korean LLM Evaluation Ecosystem In the fast-evo...",
    "pubDate": "Tue, 20 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-upstage",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_upstage.png"
  },
  {
    "title": "New AI classifier for indicating AI-written text",
    "description": "We‚Äôre launching a classifier trained to distinguish between AI-written and human-written¬†text.",
    "summary": "We‚Äôre launching a classifier trained to distinguish between AI-written and human-written¬†text.",
    "pubDate": "Tue, 31 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "3 Questions: How to help students recognize potential bias in their AI datasets",
    "description": "Courses on developing AI models for health care need to focus more on identifying and addressing bias, says Leo Anthony Celi.",
    "summary": "Courses on developing AI models for health care need to focus more on identifying and addressing bias, says Leo Anthony Celi.",
    "pubDate": "Mon, 02 Jun 2025 10:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/3-questions-recognizing-potential-bias-in-ai-datasets-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_AI-Health-Data-01.jpg"
  },
  {
    "title": "Introducing the AMD 5th Gen EPYC‚Ñ¢ CPU",
    "description": "",
    "summary": "Introducing the AMD 5th Gen EPYC‚Ñ¢ CPU AMD has just unveiled its 5th generation of server-grade EPYC ...",
    "pubDate": "Thu, 10 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-amd-turin",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "GradMetaNet: An Equivariant Architecture for Learning on Gradients",
    "description": "arXiv:2507.01649v1 Announce Type: cross Abstract: Gradients of neural networks encode valuable information for optimization, editing, and analysis of models. Therefore, practitioners often treat gradients as inputs to task-specific algorithms, e.g. for pruning or optimization. Recent works explore learning algorithms that operate directly on gradients but use architectures that are not specifically designed for gradient processing, limiting their applicability. In this paper, we present a principled approach for designing architectures that process gradients. Our approach is guided by three principles: (1) equivariant design that preserves neuron permutation symmetries, (2) processing sets of gradients across multiple data points to capture curvature information, and (3) efficient gradient representation through rank-1 decomposition. Based on these principles, we introduce GradMetaNet, a novel architecture for learning on gradients, constructed from simple equivariant blocks. We prove universality results for GradMetaNet, and show that previous approaches cannot approximate natural gradient-based functions that GradMetaNet can. We then demonstrate GradMetaNet's effectiveness on a diverse set of gradient-based tasks on MLPs and transformers, such as learned optimization, INR editing, and estimating loss landscape curvature.",
    "summary": "arXiv:2507.01649v1 Announce Type: cross Abstract: Gradients of neural networks encode valuable information for optimization, editing, and analysis of models. Therefore, practitioners often treat gradients as inputs to task-specific algorithms, e.g. for pruning or optimization. Recent works explore learning algorithms that operate directly on gradients but use architectures that are not specifically designed for gradient processing, limiting their applicability. In this paper, we present a principled approach for designing architectures that process gradients. Our approach is guided by three principles: (1) equivariant design that preserves neuron permutation symmetries, (2) processing sets of gradients across multiple data points to capture curvature information, and (3) efficient gradient representation through rank-1 decomposition. Based on these principles, we introduce GradMetaNet, a novel architecture for learning on gradients, constructed from simple equivariant blocks. We prove universality results for GradMetaNet, and show that previous approaches cannot approximate natural gradient-based functions that GradMetaNet can. We then demonstrate GradMetaNet's effectiveness on a diverse set of gradient-based tasks on MLPs and transformers, such as learned optimization, INR editing, and estimating loss landscape curvature.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01649",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Experimenting with Automatic PII Detection on the Hub using Presidio",
    "description": "",
    "summary": "Experimenting with Automatic PII Detection on the Hub using Presidio At Hugging Face, we've noticed ...",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/presidio-pii-detection",
    "thumbnail": "https://huggingface.co/blog/assets/presidio-pii-detection/thumbnail.png"
  },
  {
    "title": "OpenAI Baselines: ACKTR & A2C",
    "description": "We‚Äôre releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic variant of Asynchronous Advantage Actor Critic (A3C) which we‚Äôve found gives equal performance. ACKTR is a more sample-efficient reinforcement learning algorithm than TRPO and A2C, and requires only slightly more computation than A2C per update.",
    "summary": "We‚Äôre releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic variant of Asynchronous Advantage Actor Critic (A3C) which we‚Äôve found gives equal performance. ACKTR is a more sample-efficient reinforcement learning algorithm than TRPO and A2C, and requires only slightly more computation than A2C per update.",
    "pubDate": "Fri, 18 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-acktr-a2c",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling Kubernetes to 7,500 nodes",
    "description": "We‚Äôve scaled Kubernetes clusters to 7,500 nodes, producing a scalable infrastructure for large models like¬†GPT-3,¬†CLIP, and¬†DALL¬∑E, but also for rapid small-scale iterative research such as¬†Scaling Laws for Neural Language Models.",
    "summary": "We‚Äôve scaled Kubernetes clusters to 7,500 nodes, producing a scalable infrastructure for large models like¬†GPT-3,¬†CLIP, and¬†DALL¬∑E, but also for rapid small-scale iterative research such as¬†Scaling Laws for Neural Language Models.",
    "pubDate": "Mon, 25 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-kubernetes-to-7500-nodes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Decision Transformers on Hugging Face ü§ó",
    "description": "",
    "summary": "Introducing Decision Transformers on Hugging Face ü§ó At Hugging Face, we are contributing to the ecos...",
    "pubDate": "Mon, 28 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/decision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/58_decision-transformers/thumbnail.jpg"
  },
  {
    "title": "Towards Foundation Auto-Encoders for Time-Series Anomaly Detection",
    "description": "arXiv:2507.01875v1 Announce Type: cross Abstract: We investigate a novel approach to time-series modeling, inspired by the successes of large pretrained foundation models. We introduce FAE (Foundation Auto-Encoders), a foundation generative-AI model for anomaly detection in time-series data, based on Variational Auto-Encoders (VAEs). By foundation, we mean a model pretrained on massive amounts of time-series data which can learn complex temporal patterns useful for accurate modeling, forecasting, and detection of anomalies on previously unseen datasets. FAE leverages VAEs and Dilated Convolutional Neural Networks (DCNNs) to build a generic model for univariate time-series modeling, which could eventually perform properly in out-of-the-box, zero-shot anomaly detection applications. We introduce the main concepts of FAE, and present preliminary results in different multi-dimensional time-series datasets from various domains, including a real dataset from an operational mobile ISP, and the well known KDD 2021 Anomaly Detection dataset.",
    "summary": "arXiv:2507.01875v1 Announce Type: cross Abstract: We investigate a novel approach to time-series modeling, inspired by the successes of large pretrained foundation models. We introduce FAE (Foundation Auto-Encoders), a foundation generative-AI model for anomaly detection in time-series data, based on Variational Auto-Encoders (VAEs). By foundation, we mean a model pretrained on massive amounts of time-series data which can learn complex temporal patterns useful for accurate modeling, forecasting, and detection of anomalies on previously unseen datasets. FAE leverages VAEs and Dilated Convolutional Neural Networks (DCNNs) to build a generic model for univariate time-series modeling, which could eventually perform properly in out-of-the-box, zero-shot anomaly detection applications. We introduce the main concepts of FAE, and present preliminary results in different multi-dimensional time-series datasets from various domains, including a real dataset from an operational mobile ISP, and the well known KDD 2021 Anomaly Detection dataset.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01875",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI and Apple announce partnership",
    "description": "OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences.",
    "summary": "OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences.",
    "pubDate": "Mon, 10 Jun 2024 11:55:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-apple-announce-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ethics and Society Newsletter #6: Building Better AI: The Importance of Data Quality",
    "description": "",
    "summary": "Ethics and Society Newsletter #6: Building Better AI: The Importance of Data Quality In February, Re...",
    "pubDate": "Mon, 24 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-6",
    "thumbnail": "https://huggingface.co/blog/assets/182_ethics-soc-6/thumbnail.png"
  },
  {
    "title": "Planning for AGI and beyond",
    "description": "Our mission is to ensure that artificial general intelligence‚ÄîAI systems that are generally smarter than humans‚Äîbenefits all of¬†humanity.",
    "summary": "Our mission is to ensure that artificial general intelligence‚ÄîAI systems that are generally smarter than humans‚Äîbenefits all of¬†humanity.",
    "pubDate": "Fri, 24 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/planning-for-agi-and-beyond",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing",
    "description": "arXiv:2507.01376v1 Announce Type: new Abstract: AI agents are autonomous systems designed to perceive, reason, and act within dynamic environments. With the rapid advancements in generative AI (GenAI), large language models (LLMs) and multimodal large language models (MLLMs) have significantly improved AI agents' capabilities in semantic comprehension, complex reasoning, and autonomous decision-making. At the same time, the rise of Agentic AI highlights adaptability and goal-directed autonomy in dynamic and complex environments. LLMs-based AI Agents (LLM-Agents), MLLMs-based AI Agents (MLLM-Agents), and Agentic AI contribute to expanding AI's capabilities in information processing, environmental perception, and autonomous decision-making, opening new avenues for smart manufacturing. However, the definitions, capability boundaries, and practical applications of these emerging AI paradigms in smart manufacturing remain unclear. To address this gap, this study systematically reviews the evolution of AI and AI agent technologies, examines the core concepts and technological advancements of LLM-Agents, MLLM-Agents, and Agentic AI, and explores their potential applications in and integration into manufacturing, along with the potential challenges they may face.",
    "summary": "arXiv:2507.01376v1 Announce Type: new Abstract: AI agents are autonomous systems designed to perceive, reason, and act within dynamic environments. With the rapid advancements in generative AI (GenAI), large language models (LLMs) and multimodal large language models (MLLMs) have significantly improved AI agents' capabilities in semantic comprehension, complex reasoning, and autonomous decision-making. At the same time, the rise of Agentic AI highlights adaptability and goal-directed autonomy in dynamic and complex environments. LLMs-based AI Agents (LLM-Agents), MLLMs-based AI Agents (MLLM-Agents), and Agentic AI contribute to expanding AI's capabilities in information processing, environmental perception, and autonomous decision-making, opening new avenues for smart manufacturing. However, the definitions, capability boundaries, and practical applications of these emerging AI paradigms in smart manufacturing remain unclear. To address this gap, this study systematically reviews the evolution of AI and AI agent technologies, examines the core concepts and technological advancements of LLM-Agents, MLLM-Agents, and Agentic AI, and explores their potential applications in and integration into manufacturing, along with the potential challenges they may face.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01376",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reinforcement learning with prediction-based rewards",
    "description": "We‚Äôve developed¬†Random Network Distillation (RND), a prediction-based method for encouraging reinforcement learning agents to explore their environments through curiosity, which for the first time exceeds average human performance on¬†Montezuma‚Äôs Revenge.",
    "summary": "We‚Äôve developed¬†Random Network Distillation (RND), a prediction-based method for encouraging reinforcement learning agents to explore their environments through curiosity, which for the first time exceeds average human performance on¬†Montezuma‚Äôs Revenge.",
    "pubDate": "Wed, 31 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reinforcement-learning-with-prediction-based-rewards",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Melding data, systems, and society",
    "description": "A new book from Professor Munther Dahleh details the creation of a unique kind of transdisciplinary center, uniting many specialties through a common need for data science.",
    "summary": "A new book from Professor Munther Dahleh details the creation of a unique kind of transdisciplinary center, uniting many specialties through a common need for data science.",
    "pubDate": "Tue, 10 Jun 2025 14:25:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/data-systems-and-society-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Data-Systems-Dahleh-book.jpg"
  },
  {
    "title": "Practical 3D Asset Generation: A Step-by-Step Guide",
    "description": "",
    "summary": "Practical 3D Asset Generation: A Step-by-Step Guide Introduction Generative AI has become an instrum...",
    "pubDate": "Tue, 01 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/3d-assets",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail-3d.jpg"
  },
  {
    "title": "Combating Confirmation Bias: A Unified Pseudo-Labeling Framework for Entity Alignment",
    "description": "arXiv:2307.02075v4 Announce Type: replace Abstract: Entity alignment (EA) aims at identifying equivalent entity pairs across different knowledge graphs (KGs) that refer to the same real-world identity. To circumvent the shortage of seed alignments provided for training, recent EA models utilize pseudo-labeling strategies to iteratively add unaligned entity pairs predicted with high confidence to the seed alignments for model training. However, the adverse impact of confirmation bias during pseudo-labeling has been largely overlooked, thus hindering entity alignment performance. To systematically combat confirmation bias for pseudo-labeling-based entity alignment, we propose a Unified Pseudo-Labeling framework for Entity Alignment (UPL-EA) that explicitly eliminates pseudo-labeling errors to boost the accuracy of entity alignment. UPL-EA consists of two complementary components: (1) Optimal Transport (OT)-based pseudo-labeling uses discrete OT modeling as an effective means to determine entity correspondences and reduce erroneous matches across two KGs. An effective criterion is derived to infer pseudo-labeled alignments that satisfy one-to-one correspondences; (2) Parallel pseudo-label ensembling refines pseudo-labeled alignments by combining predictions over multiple models independently trained in parallel. The ensembled pseudo-labeled alignments are thereafter used to augment seed alignments to reinforce subsequent model training for alignment inference. The effectiveness of UPL-EA in eliminating pseudo-labeling errors is both theoretically supported and experimentally validated. Our extensive results and in-depth analyses demonstrate the superiority of UPL-EA over 15 competitive baselines and its utility as a general pseudo-labeling framework for entity alignment.",
    "summary": "arXiv:2307.02075v4 Announce Type: replace Abstract: Entity alignment (EA) aims at identifying equivalent entity pairs across different knowledge graphs (KGs) that refer to the same real-world identity. To circumvent the shortage of seed alignments provided for training, recent EA models utilize pseudo-labeling strategies to iteratively add unaligned entity pairs predicted with high confidence to the seed alignments for model training. However, the adverse impact of confirmation bias during pseudo-labeling has been largely overlooked, thus hindering entity alignment performance. To systematically combat confirmation bias for pseudo-labeling-based entity alignment, we propose a Unified Pseudo-Labeling framework for Entity Alignment (UPL-EA) that explicitly eliminates pseudo-labeling errors to boost the accuracy of entity alignment. UPL-EA consists of two complementary components: (1) Optimal Transport (OT)-based pseudo-labeling uses discrete OT modeling as an effective means to determine entity correspondences and reduce erroneous matches across two KGs. An effective criterion is derived to infer pseudo-labeled alignments that satisfy one-to-one correspondences; (2) Parallel pseudo-label ensembling refines pseudo-labeled alignments by combining predictions over multiple models independently trained in parallel. The ensembled pseudo-labeled alignments are thereafter used to augment seed alignments to reinforce subsequent model training for alignment inference. The effectiveness of UPL-EA in eliminating pseudo-labeling errors is both theoretically supported and experimentally validated. Our extensive results and in-depth analyses demonstrate the superiority of UPL-EA over 15 competitive baselines and its utility as a general pseudo-labeling framework for entity alignment.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2307.02075",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Japanese Stable Diffusion",
    "description": "",
    "summary": "Japanese Stable Diffusion Stable Diffusion, developed by CompVis, Stability AI, and LAION, has gener...",
    "pubDate": "Wed, 05 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/japanese-stable-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/106_japanese_stable_diffusion/jsd_thumbnail.png"
  },
  {
    "title": "How we really judge AI",
    "description": "Forget optimists vs. Luddites. Most people evaluate AI based on its perceived capability and their need for personalization.",
    "summary": "Forget optimists vs. Luddites. Most people evaluate AI based on its perceived capability and their need for personalization.",
    "pubDate": "Tue, 10 Jun 2025 11:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/how-we-really-judge-ai-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-AI-Aversion-Appreciation-01.jpg"
  },
  {
    "title": "Hugging Face partners with TruffleHog to Scan for Secrets",
    "description": "",
    "summary": "Hugging Face partners with TruffleHog to Scan for Secrets We're excited to announce our partnership ...",
    "pubDate": "Wed, 04 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trufflesecurity-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/trufflesecurity-partnership/thumbnail.png"
  },
  {
    "title": "GPT, But Backwards: Exactly Inverting Language Model Outputs",
    "description": "arXiv:2507.01693v1 Announce Type: cross Abstract: While existing auditing techniques attempt to identify potential unwanted behaviours in large language models (LLMs), we address the complementary forensic problem of reconstructing the exact input that led to an existing LLM output - enabling post-incident analysis and potentially the detection of fake output reports. We formalize exact input reconstruction as a discrete optimisation problem with a unique global minimum and introduce SODA, an efficient gradient-based algorithm that operates on a continuous relaxation of the input search space with periodic restarts and parameter decay. Through comprehensive experiments on LLMs ranging in size from 33M to 3B parameters, we demonstrate that SODA significantly outperforms existing approaches. We succeed in fully recovering 79.5% of shorter out-of-distribution inputs from next-token logits, without a single false positive, but struggle to extract private information from the outputs of longer (15+ token) input sequences. This suggests that standard deployment practices may currently provide adequate protection against malicious use of our method. Our code is available at https://doi.org/10.5281/zenodo.15539879.",
    "summary": "arXiv:2507.01693v1 Announce Type: cross Abstract: While existing auditing techniques attempt to identify potential unwanted behaviours in large language models (LLMs), we address the complementary forensic problem of reconstructing the exact input that led to an existing LLM output - enabling post-incident analysis and potentially the detection of fake output reports. We formalize exact input reconstruction as a discrete optimisation problem with a unique global minimum and introduce SODA, an efficient gradient-based algorithm that operates on a continuous relaxation of the input search space with periodic restarts and parameter decay. Through comprehensive experiments on LLMs ranging in size from 33M to 3B parameters, we demonstrate that SODA significantly outperforms existing approaches. We succeed in fully recovering 79.5% of shorter out-of-distribution inputs from next-token logits, without a single false positive, but struggle to extract private information from the outputs of longer (15+ token) input sequences. This suggests that standard deployment practices may currently provide adequate protection against malicious use of our method. Our code is available at https://doi.org/10.5281/zenodo.15539879.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01693",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome Gemma 2 - Google's new open LLM",
    "description": "",
    "summary": "Welcome Gemma 2 - Google‚Äôs new open LLM Google released Gemma 2, the latest addition to its family o...",
    "pubDate": "Thu, 27 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma2",
    "thumbnail": "https://huggingface.co/blog/assets/gemma2/thumbnail.jpg"
  },
  {
    "title": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "description": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "summary": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "pubDate": "Tue, 10 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-lessons-from-hundreds-of-successful-deployments",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FineVideo: behind the scenes",
    "description": "",
    "summary": "FineVideo: behind the scenes Open video datasets are scarce and therefore slowing down the developme...",
    "pubDate": "Mon, 23 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-video",
    "thumbnail": "https://huggingface.co/blog/assets/186_fine_video/thumbnail.png"
  },
  {
    "title": "Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA",
    "description": "",
    "summary": "Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA LLMs are known to b...",
    "pubDate": "Wed, 24 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/4bit-transformers-bitsandbytes",
    "thumbnail": "https://huggingface.co/blog/assets/96_hf_bitsandbytes_integration/Thumbnail_blue.png"
  },
  {
    "title": "On the Fundamental Impossibility of Hallucination Control in Large Language Models",
    "description": "arXiv:2506.06382v2 Announce Type: replace-cross Abstract: We prove that perfect hallucination control in large language models is mathematically impossible. No LLM inference mechanism can simultaneously achieve truthful response generation, semantic information conservation, relevant knowledge revelation, and knowledge-constrained optimality. This impossibility is fundamental, arising from the mathematical structure of information aggregation itself rather than engineering limitations. The proof spans three mathematical frameworks: auction theory, proper scoring theory for probabilistic predictions, and log-sum-exp analysis for transformer architectures. In each setting, we demonstrate that information aggregation creates unavoidable violations of conservation principles. The Jensen gap in transformer probability aggregation provides a direct measure of this impossibility. These results reframe hallucination from an engineering bug to an inevitable mathematical feature of distributed intelligence. There are fundamental trade-offs between truthfulness, knowledge utilization, and response completeness, providing principled foundations for managing rather than eliminating hallucination. This work reveals deep connections between neural network inference, philosophy of knowledge and reasoning, and classical results in game theory and information theory, opening new research directions for developing beneficial AI systems within mathematical constraints.",
    "summary": "arXiv:2506.06382v2 Announce Type: replace-cross Abstract: We prove that perfect hallucination control in large language models is mathematically impossible. No LLM inference mechanism can simultaneously achieve truthful response generation, semantic information conservation, relevant knowledge revelation, and knowledge-constrained optimality. This impossibility is fundamental, arising from the mathematical structure of information aggregation itself rather than engineering limitations. The proof spans three mathematical frameworks: auction theory, proper scoring theory for probabilistic predictions, and log-sum-exp analysis for transformer architectures. In each setting, we demonstrate that information aggregation creates unavoidable violations of conservation principles. The Jensen gap in transformer probability aggregation provides a direct measure of this impossibility. These results reframe hallucination from an engineering bug to an inevitable mathematical feature of distributed intelligence. There are fundamental trade-offs between truthfulness, knowledge utilization, and response completeness, providing principled foundations for managing rather than eliminating hallucination. This work reveals deep connections between neural network inference, philosophy of knowledge and reasoning, and classical results in game theory and information theory, opening new research directions for developing beneficial AI systems within mathematical constraints.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.06382",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GPTs are GPTs: An early look at the labor market impact potential of large language models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpts-are-gpts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ü™Ü Introduction to Matryoshka Embedding Models",
    "description": "",
    "summary": "ü™Ü Introduction to Matryoshka Embedding Models In this blogpost, we will introduce you to the concept...",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/matryoshka",
    "thumbnail": "https://huggingface.co/blog/assets/matryoshka/thumbnail.png"
  },
  {
    "title": "Reimagining secure infrastructure for advanced AI",
    "description": "Securing advanced AI systems will require an evolution in infrastructure security. We‚Äôre calling for research and investment in six security measures that we believe will play key roles in protecting advanced AI. Protecting, exploring, and applying advanced artificial intelligence (AI) is our strategic imperative. OpenAI‚Äôs mission is to deliver positive impact of advanced AI to everything from healthcare to science to education ‚Äì and yes, even to cybersecurity. That work begins with building secure, trustworthy AI systems and protecting the underlying technologies from those who seek to subvert our work to cause harm.",
    "summary": "Securing advanced AI systems will require an evolution in infrastructure security. We‚Äôre calling for research and investment in six security measures that we believe will play key roles in protecting advanced AI. Protecting, exploring, and applying advanced artificial intelligence (AI) is our strategic imperative. OpenAI‚Äôs mission is to deliver positive impact of advanced AI to everything from healthcare to science to education ‚Äì and yes, even to cybersecurity. That work begins with building secure, trustworthy AI systems and protecting the underlying technologies from those who seek to subvert our work to cause harm.",
    "pubDate": "Fri, 03 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reimagining-secure-infrastructure-for-advanced-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Optimizing Bark using ü§ó Transformers",
    "description": "",
    "summary": "Optimizing a Text-To-Speech model using ü§ó Transformers ü§ó Transformers provides many of the latest st...",
    "pubDate": "Wed, 09 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimizing-bark",
    "thumbnail": "https://huggingface.co/blog/assets/bark_optimization/thumbnail.png"
  },
  {
    "title": "How AlphaChip transformed computer chip design",
    "description": "Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world.",
    "summary": "Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world.",
    "pubDate": "Thu, 26 Sep 2024 14:08:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/",
    "thumbnail": "https://lh3.googleusercontent.com/Y_xdq8eqcQlZXYk-MZ2OWPpppmWG6LAQ8DZ-LZFUh8TV5s2TBb3RK_VkMUe-skRzIop5aP6Ot9xPMWFaWmenz55EwxVFCMszpTg2EzsyOd6ftlllGyE=w1200-h630-n-nu"
  },
  {
    "title": "Open R1: How to use OlympicCoder locally for coding?",
    "description": "",
    "summary": "Open R1: How to use OlympicCoder locally for coding Everyone‚Äôs been using Claude and OpenAI as codin...",
    "pubDate": "Thu, 20 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/olympic-coder-lmstudio",
    "thumbnail": "https://huggingface.co/blog/assets/olympic-coder-lmstudio/banner.png"
  },
  {
    "title": "World-aware Planning Narratives Enhance Large Vision-Language Model Planner",
    "description": "arXiv:2506.21230v2 Announce Type: replace Abstract: Large Vision-Language Models (LVLMs) show promise for embodied planning tasks but struggle with complex scenarios involving unfamiliar environments and multi-step goals. Current approaches rely on environment-agnostic imitation learning that disconnects instructions from environmental contexts, causing models to struggle with context-sensitive instructions and rely on supplementary cues rather than visual reasoning during long-horizon interactions. In this work, we propose World-Aware Planning Narrative Enhancement (WAP), a framework that infuses LVLMs with comprehensive environmental understanding through four cognitive capabilities (visual appearance modeling, spatial reasoning, functional abstraction, and syntactic grounding) while developing and evaluating models using only raw visual observations through curriculum learning. Evaluations on the EB-ALFRED benchmark demonstrate substantial improvements, with Qwen2.5-VL achieving a 60.7 absolute improvement in task success rates, particularly in commonsense reasoning (+60.0) and long-horizon planning (+70.0). Notably, our enhanced open-source models outperform proprietary systems like GPT-4o and Claude-3.5-Sonnet by a large margin.",
    "summary": "arXiv:2506.21230v2 Announce Type: replace Abstract: Large Vision-Language Models (LVLMs) show promise for embodied planning tasks but struggle with complex scenarios involving unfamiliar environments and multi-step goals. Current approaches rely on environment-agnostic imitation learning that disconnects instructions from environmental contexts, causing models to struggle with context-sensitive instructions and rely on supplementary cues rather than visual reasoning during long-horizon interactions. In this work, we propose World-Aware Planning Narrative Enhancement (WAP), a framework that infuses LVLMs with comprehensive environmental understanding through four cognitive capabilities (visual appearance modeling, spatial reasoning, functional abstraction, and syntactic grounding) while developing and evaluating models using only raw visual observations through curriculum learning. Evaluations on the EB-ALFRED benchmark demonstrate substantial improvements, with Qwen2.5-VL achieving a 60.7 absolute improvement in task success rates, particularly in commonsense reasoning (+60.0) and long-horizon planning (+70.0). Notably, our enhanced open-source models outperform proprietary systems like GPT-4o and Claude-3.5-Sonnet by a large margin.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21230",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Data Is Better Together: A Look Back and Forward",
    "description": "",
    "summary": "Data Is Better Together: A Look Back and Forward For the past few months, we have been working on th...",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dibt",
    "thumbnail": "https://huggingface.co/blog/assets/dibt/thumbnail.png"
  },
  {
    "title": "Probabilistic Time Series Forecasting with ü§ó Transformers",
    "description": "",
    "summary": "Probabilistic Time Series Forecasting with ü§ó Transformers Introduction Time series forecasting is an...",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/time-series-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/118_time-series-transformers/thumbnail.png"
  },
  {
    "title": "New funding to scale the benefits of AI",
    "description": "We are making progress on our mission to ensure that artificial general intelligence benefits all of humanity.",
    "summary": "We are making progress on our mission to ensure that artificial general intelligence benefits all of humanity.",
    "pubDate": "Wed, 02 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scale-the-benefits-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Open Arabic LLM Leaderboard 2",
    "description": "",
    "summary": "The Open Arabic LLM Leaderboard 2 Current status of Arabic LLMs leaderboards The growing availabilit...",
    "pubDate": "Mon, 10 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-arabic-v2",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_arabic.png"
  },
  {
    "title": "GPT-2: 1.5B release",
    "description": "As the final model release of¬†GPT-2‚Äôs¬†staged release, we‚Äôre releasing the largest version (1.5B parameters) of GPT-2 along with¬†code and model weights¬†to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we‚Äôve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we‚Äôre actively continuing the conversation with the AI community on responsible¬†publication.",
    "summary": "As the final model release of¬†GPT-2‚Äôs¬†staged release, we‚Äôre releasing the largest version (1.5B parameters) of GPT-2 along with¬†code and model weights¬†to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we‚Äôve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we‚Äôre actively continuing the conversation with the AI community on responsible¬†publication.",
    "pubDate": "Tue, 05 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-2-1-5b-release",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI‚Äôs commitment to child safety: adopting safety by design principles",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/child-safety-adopting-sbd-principles",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-tune Llama 2 with DPO",
    "description": "",
    "summary": "Fine-tune Llama 2 with DPO Introduction Reinforcement Learning from Human Feedback (RLHF) has become...",
    "pubDate": "Tue, 08 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dpo-trl",
    "thumbnail": "https://huggingface.co/blog/assets/157_dpo_trl/dpo_thumbnail.png"
  },
  {
    "title": "Introducing ü§ó Accelerate",
    "description": "",
    "summary": "Introducing ü§ó Accelerate ü§ó Accelerate Run your raw PyTorch training scripts on any kind of device. M...",
    "pubDate": "Fri, 16 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-library",
    "thumbnail": "https://huggingface.co/blog/assets/20_accelerate_library/accelerate_diff.png"
  },
  {
    "title": "AI Policy: ü§ó Response to the White House AI Action Plan RFI",
    "description": "",
    "summary": "AI Policy @ü§ó: Response to the White House AI Action Plan RFI On March 14, we submitted Hugging Face'...",
    "pubDate": "Wed, 19 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-action-wh-2025",
    "thumbnail": "https://huggingface.co/blog/assets/151_policy_ntia_rfc/us_policy_thumbnail.png"
  },
  {
    "title": "Bringing the Magic of AI to Mattel‚Äôs Iconic Brands",
    "description": "OpenAI and Mattel are partnering to integrate AI into iconic brands such as Barbie and Hot Wheels, aiming to enhance creative development, streamline workflows, and create new ways for fans to engage.",
    "summary": "OpenAI and Mattel are partnering to integrate AI into iconic brands such as Barbie and Hot Wheels, aiming to enhance creative development, streamline workflows, and create new ways for fans to engage.",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mattels-iconic-brands",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-tuning now available for GPT-4o",
    "description": "Fine-tune custom versions of GPT-4o to increase performance and accuracy for your applications",
    "summary": "Fine-tune custom versions of GPT-4o to increase performance and accuracy for your applications",
    "pubDate": "Tue, 20 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-fine-tuning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing GPTs",
    "description": "You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills.",
    "summary": "You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills.",
    "pubDate": "Mon, 06 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-gpts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Exploring simple optimizations for SDXL",
    "description": "",
    "summary": "Exploring simple optimizations for SDXL Stable Diffusion XL (SDXL) is the latest latent diffusion mo...",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/simple_sdxl_optimizations",
    "thumbnail": "https://huggingface.co/blog/assets/simple_sdxl_optimizations/thumbnail.png"
  },
  {
    "title": "Sora is here",
    "description": "Our video generation model, Sora, is now available to use at sora.com. Users can generate videos up to 1080p resolution, up to 20 sec long, and in widescreen, vertical or square aspect ratios. You can bring your own assets to extend, remix, and blend, or generate entirely new content from text.",
    "summary": "Our video generation model, Sora, is now available to use at sora.com. Users can generate videos up to 1080p resolution, up to 20 sec long, and in widescreen, vertical or square aspect ratios. You can bring your own assets to extend, remix, and blend, or generate entirely new content from text.",
    "pubDate": "Mon, 09 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-is-here",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New compliance and administrative tools for ChatGPT Enterprise",
    "description": "Compliance API integrations, SCIM, and GPT controls to support compliance programs, data security, and user access at scale",
    "summary": "Compliance API integrations, SCIM, and GPT controls to support compliance programs, data security, and user access at scale",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-for-chatgpt-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "StackLLaMA: A hands-on guide to train LLaMA with RLHF",
    "description": "",
    "summary": "StackLLaMA: A hands-on guide to train LLaMA with RLHF Models such as ChatGPT, GPT-4, and Claude are ...",
    "pubDate": "Wed, 05 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stackllama",
    "thumbnail": "https://huggingface.co/blog/assets/138_stackllama/thumbnail.png"
  },
  {
    "title": "Faster Assisted Generation with Dynamic Speculation",
    "description": "",
    "summary": "Faster Assisted Generation with Dynamic Speculation ‚≠ê In this blog post, we‚Äôll explore dynamic specu...",
    "pubDate": "Tue, 08 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dynamic_speculation_lookahead",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "PaliGemma 2 Mix - New Instruction Vision Language Models by Google",
    "description": "",
    "summary": "PaliGemma 2 Mix - New Instruction Vision Language Models by Google TL;DR Last December, Google relea...",
    "pubDate": "Wed, 19 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma2mix",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma2/thumbnail.png"
  },
  {
    "title": "Introducing OpenAI",
    "description": "OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact.",
    "summary": "OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact.",
    "pubDate": "Fri, 11 Dec 2015 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Banque des Territoires (CDC Group) x Polyconseil x Hugging Face: Enhancing a Major French Environmental Program with a Sovereign Data Solution",
    "description": "",
    "summary": "Banque des Territoires (CDC Group) x Polyconseil x Hugging Face: Enhancing a Major French Environmen...",
    "pubDate": "Tue, 09 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sovereign-data-solution-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/cdc_poly_hf.png"
  },
  {
    "title": "Quantum-Assisted Automatic Path-Planning for Robotic Quality Inspection in Industry 4.0",
    "description": "arXiv:2507.01462v1 Announce Type: cross Abstract: This work explores the application of hybrid quantum-classical algorithms to optimize robotic inspection trajectories derived from Computer-Aided Design (CAD) models in industrial settings. By modeling the task as a 3D variant of the Traveling Salesman Problem, incorporating incomplete graphs and open-route constraints, this study evaluates the performance of two D-Wave-based solvers against classical methods such as GUROBI and Google OR-Tools. Results across five real-world cases demonstrate competitive solution quality with significantly reduced computation times, highlighting the potential of quantum approaches in automation under Industry 4.0.",
    "summary": "arXiv:2507.01462v1 Announce Type: cross Abstract: This work explores the application of hybrid quantum-classical algorithms to optimize robotic inspection trajectories derived from Computer-Aided Design (CAD) models in industrial settings. By modeling the task as a 3D variant of the Traveling Salesman Problem, incorporating incomplete graphs and open-route constraints, this study evaluates the performance of two D-Wave-based solvers against classical methods such as GUROBI and Google OR-Tools. Results across five real-world cases demonstrate competitive solution quality with significantly reduced computation times, highlighting the potential of quantum approaches in automation under Industry 4.0.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01462",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FermiNet: Quantum physics and chemistry from first principles",
    "description": "Using deep learning to solve fundamental problems in computational quantum chemistry and explore how matter interacts with light",
    "summary": "Using deep learning to solve fundamental problems in computational quantum chemistry and explore how matter interacts with light",
    "pubDate": "Thu, 22 Aug 2024 19:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ferminet-quantum-physics-and-chemistry-from-first-principles/",
    "thumbnail": "https://lh3.googleusercontent.com/u-LZOO0ynV2UCorbNrUtWS6MJ_sxTfGzObe2YzBt5Grgohx39WcsGiPNOsHwBja8C51lQBclpaovrzUVVQRzj2WpWeM7f7y5eeYt3Dx6l3gxfx9S9g=w1200-h630-n-nu"
  },
  {
    "title": "FFJORD: Free-form continuous dynamics for scalable reversible generative models",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 02 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ffjord",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Finding GPT-4‚Äôs mistakes with GPT-4",
    "description": "CriticGPT, a model based on GPT-4, writes critiques of ChatGPT responses to help human trainers spot mistakes during RLHF",
    "summary": "CriticGPT, a model based on GPT-4, writes critiques of ChatGPT responses to help human trainers spot mistakes during RLHF",
    "pubDate": "Thu, 27 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/finding-gpt4s-mistakes-with-gpt-4",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Train your first Decision Transformer",
    "description": "",
    "summary": "Train your first Decision Transformer In a previous post, we announced the launch of Decision Transf...",
    "pubDate": "Thu, 08 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-decision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/101_train-decision-transformers/thumbnail.gif"
  },
  {
    "title": "Ingredients for robotics research",
    "description": "We‚Äôre releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience Replay, all developed for our research over the past year. We‚Äôve used these environments to train models which work on physical robots. We‚Äôre also releasing a set of requests for robotics research.",
    "summary": "We‚Äôre releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience Replay, all developed for our research over the past year. We‚Äôve used these environments to train models which work on physical robots. We‚Äôre also releasing a set of requests for robotics research.",
    "pubDate": "Mon, 26 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ingredients-for-robotics-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Pull Requests and Discussions ü•≥",
    "description": "",
    "summary": "Introducing Pull Requests and Discussions ü•≥ We are thrilled to announce the release of our latest co...",
    "pubDate": "Wed, 25 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-update",
    "thumbnail": "https://huggingface.co/blog/assets/76_community_update/thumbnail.png"
  },
  {
    "title": "Experiment with Gemini 2.0 Flash native image generation",
    "description": "Native image output is available in Gemini 2.0 Flash for developers to experiment with in Google AI Studio and the Gemini API.",
    "summary": "Native image output is available in Gemini 2.0 Flash for developers to experiment with in Google AI Studio and the Gemini API.",
    "pubDate": "Wed, 12 Mar 2025 14:58:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/experiment-with-gemini-20-flash-native-image-generation/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-image-generation_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Exploring Quantization Backends in Diffusers",
    "description": "",
    "summary": "Exploring Quantization Backends in Diffusers Large diffusion models like Flux (a flow-based text-to-...",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers-quantization/thumbnail.png"
  },
  {
    "title": "Getting Started with Hugging Face Transformers for IPUs with Optimum",
    "description": "",
    "summary": "Getting Started with Hugging Face Transformers for IPUs with Optimum Transformer models have proven ...",
    "pubDate": "Tue, 30 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore-getting-started",
    "thumbnail": "https://huggingface.co/blog/assets/38_getting_started_graphcore/graphcore_1.png"
  },
  {
    "title": "Developing reliable AI tools for healthcare",
    "description": "We‚Äôve published our joint paper with Google Research in Nature Medicine, which proposes CoDoC (Complementarity-driven Deferral-to-Clinical Workflow), an AI system that learns when to rely on predictive AI tools or defer to a clinician for the most accurate interpretation of medical images.",
    "summary": "We‚Äôve published our joint paper with Google Research in Nature Medicine, which proposes CoDoC (Complementarity-driven Deferral-to-Clinical Workflow), an AI system that learns when to rely on predictive AI tools or defer to a clinician for the most accurate interpretation of medical images.",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/codoc-developing-reliable-ai-tools-for-healthcare/",
    "thumbnail": "https://lh3.googleusercontent.com/JCyH0sgVtuYFCB0n7g6f2NMV19yeAgvxQBqcfy9H_-DP_aW3k5h4i0bcZ9_9KCExs7rXRrCaC6s21uK5Udap6tX3zy96zOdn8YcF5WIxAFzUgru6Nw=w1200-h630-n-nu"
  },
  {
    "title": "Llama 3.1 - 405B, 70B & 8B with multilinguality and long context",
    "description": "",
    "summary": "Llama 3.1 - 405B, 70B & 8B with multilinguality and long context Llama 3.1 is out! Today we welcome ...",
    "pubDate": "Tue, 23 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama31",
    "thumbnail": "https://huggingface.co/blog/assets/llama31/thumbnail.jpg"
  },
  {
    "title": "Evolved Policy Gradients",
    "description": "We‚Äôre releasing an experimental metalearning approach called Evolved Policy Gradients, a method that evolves the loss function of learning agents, which can enable fast training on novel tasks. Agents trained with EPG can succeed at basic tasks at test time that were outside their training regime, like learning to navigate to an object on a different side of the room from where it was placed during training.",
    "summary": "We‚Äôre releasing an experimental metalearning approach called Evolved Policy Gradients, a method that evolves the loss function of learning agents, which can enable fast training on novel tasks. Agents trained with EPG can succeed at basic tasks at test time that were outside their training regime, like learning to navigate to an object on a different side of the room from where it was placed during training.",
    "pubDate": "Wed, 18 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolved-policy-gradients",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Using GPT-4o reasoning to transform cancer care",
    "description": "Color Health is working with OpenAI to pioneer a new way of accelerating cancer patients‚Äô access to treatment. Their new Cancer Copilot application uses GPT-4o to identify missing diagnostics and create tailored workup plans, enabling healthcare providers to make evidence-based decisions about cancer screening and treatment.",
    "summary": "Color Health is working with OpenAI to pioneer a new way of accelerating cancer patients‚Äô access to treatment. Their new Cancer Copilot application uses GPT-4o to identify missing diagnostics and create tailored workup plans, enabling healthcare providers to make evidence-based decisions about cancer screening and treatment.",
    "pubDate": "Mon, 17 Jun 2024 04:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/color-health",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI and Microsoft",
    "description": "We‚Äôre working with Microsoft to start running most of our large-scale experiments on Azure.",
    "summary": "We‚Äôre working with Microsoft to start running most of our large-scale experiments on Azure.",
    "pubDate": "Tue, 15 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-microsoft",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Start building with Gemini 2.0 Flash and Flash-Lite",
    "description": "Gemini 2.0 Flash-Lite is now generally available in the Gemini API for production use in Google AI Studio and for enterprise customers on Vertex AI",
    "summary": "Gemini 2.0 Flash-Lite is now generally available in the Gemini API for production use in Google AI Studio and for enterprise customers on Vertex AI",
    "pubDate": "Tue, 25 Feb 2025 18:02:12 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/start-building-with-gemini-20-flash-and-flash-lite/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Flash_Family_meta.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Hello GPT-4o",
    "description": "We‚Äôre announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.",
    "summary": "We‚Äôre announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.",
    "pubDate": "Mon, 13 May 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hello-gpt-4o",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing data residency in Asia",
    "description": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "summary": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "pubDate": "Wed, 07 May 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-data-residency-in-asia",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating over 130,000 Hugging Face models with ONNX Runtime",
    "description": "",
    "summary": "Accelerating over 130,000 Hugging Face models with ONNX Runtime What is ONNX Runtime? ONNX Runtime i...",
    "pubDate": "Wed, 04 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ort-accelerating-hf-models",
    "thumbnail": "https://huggingface.co/blog/assets/ort_accelerating_hf_models/thumbnail.png"
  },
  {
    "title": "Accelerating Document AI",
    "description": "",
    "summary": "Accelerating Document AI Enterprises are full of documents containing knowledge that isn't accessibl...",
    "pubDate": "Mon, 21 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/document-ai",
    "thumbnail": "https://huggingface.co/blog/assets/112_document-ai/thumbnail.png"
  },
  {
    "title": "BranchNet: A Neuro-Symbolic Learning Framework for Structured Multi-Class Classification",
    "description": "arXiv:2507.01781v1 Announce Type: cross Abstract: We introduce BranchNet, a neuro-symbolic learning framework that transforms decision tree ensembles into sparse, partially connected neural networks. Each branch, defined as a decision path from root to a parent of leaves, is mapped to a hidden neuron, preserving symbolic structure while enabling gradient-based optimization. The resulting models are compact, interpretable, and require no manual architecture tuning. Evaluated on a suite of structured multi-class classification benchmarks, BranchNet consistently outperforms XGBoost in accuracy, with statistically significant gains. We detail the architecture, training procedure, and sparsity dynamics, and discuss the model's strengths in symbolic interpretability as well as its current limitations, particularly on binary tasks where further adaptive calibration may be beneficial.",
    "summary": "arXiv:2507.01781v1 Announce Type: cross Abstract: We introduce BranchNet, a neuro-symbolic learning framework that transforms decision tree ensembles into sparse, partially connected neural networks. Each branch, defined as a decision path from root to a parent of leaves, is mapped to a hidden neuron, preserving symbolic structure while enabling gradient-based optimization. The resulting models are compact, interpretable, and require no manual architecture tuning. Evaluated on a suite of structured multi-class classification benchmarks, BranchNet consistently outperforms XGBoost in accuracy, with statistically significant gains. We detail the architecture, training procedure, and sparsity dynamics, and discuss the model's strengths in symbolic interpretability as well as its current limitations, particularly on binary tasks where further adaptive calibration may be beneficial.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01781",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Generating Human-level Text with Contrastive Search in Transformers ü§ó",
    "description": "",
    "summary": "Generating Human-level Text with Contrastive Search in Transformers ü§ó 1. Introduction: Natural langu...",
    "pubDate": "Tue, 08 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-csearch",
    "thumbnail": "https://huggingface.co/blog/assets/115_introducing_contrastive_search/thumbnail.png"
  },
  {
    "title": "Convert Transformers to ONNX with Hugging Face Optimum",
    "description": "",
    "summary": "Convert Transformers to ONNX with Hugging Face Optimum Hundreds of Transformers experiments and mode...",
    "pubDate": "Wed, 22 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/convert-transformers-to-onnx",
    "thumbnail": "https://huggingface.co/blog/assets/81_convert_transformers_to_onnx/thumbnail.png"
  },
  {
    "title": "Getting Started with Sentiment Analysis using Python",
    "description": "",
    "summary": "Getting Started with Sentiment Analysis using Python Sentiment analysis is the automated process of ...",
    "pubDate": "Wed, 02 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-python",
    "thumbnail": "https://huggingface.co/blog/assets/50_sentiment_python/thumbnail.png"
  },
  {
    "title": "Elon Musk wanted an OpenAI for-profit",
    "description": "Elon Musk‚Äôs latest legal filing against OpenAI marks his fourth attempt in less than a year to reframe his claims. However, his own words and actions speak for themselves‚Äîin 2017, Elon not only wanted, but actually created, a for-profit as OpenAI‚Äôs proposed new structure.",
    "summary": "Elon Musk‚Äôs latest legal filing against OpenAI marks his fourth attempt in less than a year to reframe his claims. However, his own words and actions speak for themselves‚Äîin 2017, Elon not only wanted, but actually created, a for-profit as OpenAI‚Äôs proposed new structure.",
    "pubDate": "Fri, 13 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/elon-musk-wanted-an-openai-for-profit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI GPT-4.5 System Card",
    "description": "We‚Äôre releasing a research preview of OpenAI GPT‚Äë4.5, our largest and most knowledgeable model yet.",
    "summary": "We‚Äôre releasing a research preview of OpenAI GPT‚Äë4.5, our largest and most knowledgeable model yet.",
    "pubDate": "Thu, 27 Feb 2025 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-5-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SigLIP 2: A better multilingual vision language encoder",
    "description": "",
    "summary": "SigLIP 2: A better multilingual vision language encoder TL;DR Today Google releases a new and better...",
    "pubDate": "Fri, 21 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/siglip2",
    "thumbnail": "https://huggingface.co/blog/assets/siglip2/thumbnail.png"
  },
  {
    "title": "Fine-Tune Whisper with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune Whisper For Multilingual ASR with ü§ó Transformers In this blog, we present a step-by-step g...",
    "pubDate": "Thu, 03 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-whisper",
    "thumbnail": "https://huggingface.co/blog/assets/111_fine_tune_whisper/thumbnail.jpg"
  },
  {
    "title": "Introducing the LiveCodeBench Leaderboard - Holistic and Contamination-Free Evaluation of Code LLMs",
    "description": "",
    "summary": "Introducing the LiveCodeBench Leaderboard - Holistic and Contamination-Free Evaluation of Code LLMs ...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-livecodebench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "Introducing GPT-4o and more tools to ChatGPT free users",
    "description": "Introducing GPT-4o and more tools to ChatGPT free users We are launching our newest flagship model and making more capabilities available for free in ChatGPT.",
    "summary": "Introducing GPT-4o and more tools to ChatGPT free users We are launching our newest flagship model and making more capabilities available for free in ChatGPT.",
    "pubDate": "Mon, 13 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-and-more-tools-to-chatgpt-free",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building a custom math tutor powered by ChatGPT",
    "description": "ChatGPT and personal tutoring",
    "summary": "ChatGPT and personal tutoring",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/my-dog-the-math-tutor",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An early warning system for novel AI risks",
    "description": "New research proposes a framework for evaluating general-purpose models against novel threats",
    "summary": "New research proposes a framework for evaluating general-purpose models against novel threats",
    "pubDate": "Thu, 25 May 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/an-early-warning-system-for-novel-ai-risks/",
    "thumbnail": "https://lh3.googleusercontent.com/REkFCC8KEOAocMWBwcHOxKM6K2zRs_qpMeUhnmHYkkGSbPPCLRhPDluhoZzx2k6_b4XvgZmhUqeuko9BXZZIPLmGR1q4BycDjLuDFQ5G5FDYPKD0x08=w1200-h630-n-nu"
  },
  {
    "title": "Hugging Face on AMD Instinct MI300 GPU",
    "description": "",
    "summary": "Hugging Face on AMD Instinct MI300 GPU Join the next Hugging Cast on June 6th to ask questions to th...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-amd-mi300",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "Putting ethical principles at the core of research lifecycle",
    "description": "",
    "summary": "Putting ethical principles at the core of the research lifecycle Ethical charter - Multimodal projec...",
    "pubDate": "Thu, 19 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethical-charter-multimodal",
    "thumbnail": "https://huggingface.co/blog/assets/71_ethical-charter/thumbnail.jpg"
  },
  {
    "title": "Announcing The Stargate Project",
    "description": "Announcing The Stargate Project",
    "summary": "Announcing The Stargate Project",
    "pubDate": "Tue, 21 Jan 2025 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/announcing-the-stargate-project",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more",
    "description": "We‚Äôre releasing two updated production-ready Gemini models",
    "summary": "We‚Äôre releasing two updated production-ready Gemini models",
    "pubDate": "Tue, 24 Sep 2024 16:03:03 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini-15-Flash-Social_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "T3DM: Test-Time Training-Guided Distribution Shift Modelling for Temporal Knowledge Graph Reasoning",
    "description": "arXiv:2507.01597v1 Announce Type: new Abstract: Temporal Knowledge Graph (TKG) is an efficient method for describing the dynamic development of facts along a timeline. Most research on TKG reasoning (TKGR) focuses on modelling the repetition of global facts and designing patterns of local historical facts. However, they face two significant challenges: inadequate modeling of the event distribution shift between training and test samples, and reliance on random entity substitution for generating negative samples, which often results in low-quality sampling. To this end, we propose a novel distributional feature modeling approach for training TKGR models, Test-Time Training-guided Distribution shift Modelling (T3DM), to adjust the model based on distribution shift and ensure the global consistency of model reasoning. In addition, we design a negative-sampling strategy to generate higher-quality negative quadruples based on adversarial training. Extensive experiments show that T3DM provides better and more robust results than the state-of-the-art baselines in most cases.",
    "summary": "arXiv:2507.01597v1 Announce Type: new Abstract: Temporal Knowledge Graph (TKG) is an efficient method for describing the dynamic development of facts along a timeline. Most research on TKG reasoning (TKGR) focuses on modelling the repetition of global facts and designing patterns of local historical facts. However, they face two significant challenges: inadequate modeling of the event distribution shift between training and test samples, and reliance on random entity substitution for generating negative samples, which often results in low-quality sampling. To this end, we propose a novel distributional feature modeling approach for training TKGR models, Test-Time Training-guided Distribution shift Modelling (T3DM), to adjust the model based on distribution shift and ensure the global consistency of model reasoning. In addition, we design a negative-sampling strategy to generate higher-quality negative quadruples based on adversarial training. Extensive experiments show that T3DM provides better and more robust results than the state-of-the-art baselines in most cases.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01597",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome Fireworks.ai on the Hub üéÜ",
    "description": "",
    "summary": "Welcome Fireworks.ai on the Hub üéÜ Following our recent announcement on Inference Providers on the Hu...",
    "pubDate": "Fri, 14 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fireworks-ai",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-fireworks.jpg"
  },
  {
    "title": "Joint Matching and Pricing for Crowd-shipping with In-store Customers",
    "description": "arXiv:2507.01749v1 Announce Type: new Abstract: This paper examines the use of in-store customers as delivery couriers in a centralized crowd-shipping system, targeting the growing need for efficient last-mile delivery in urban areas. We consider a brick-and-mortar retail setting where shoppers are offered compensation to deliver time-sensitive online orders. To manage this process, we propose a Markov Decision Process (MDP) model that captures key uncertainties, including the stochastic arrival of orders and crowd-shippers, and the probabilistic acceptance of delivery offers. Our solution approach integrates Neural Approximate Dynamic Programming (NeurADP) for adaptive order-to-shopper assignment with a Deep Double Q-Network (DDQN) for dynamic pricing. This joint optimization strategy enables multi-drop routing and accounts for offer acceptance uncertainty, aligning more closely with real-world operations. Experimental results demonstrate that the integrated NeurADP + DDQN policy achieves notable improvements in delivery cost efficiency, with up to 6.7% savings over NeurADP with fixed pricing and approximately 18% over myopic baselines. We also show that allowing flexible delivery delays and enabling multi-destination routing further reduces operational costs by 8% and 17%, respectively. These findings underscore the advantages of dynamic, forward-looking policies in crowd-shipping systems and offer practical guidance for urban logistics operators.",
    "summary": "arXiv:2507.01749v1 Announce Type: new Abstract: This paper examines the use of in-store customers as delivery couriers in a centralized crowd-shipping system, targeting the growing need for efficient last-mile delivery in urban areas. We consider a brick-and-mortar retail setting where shoppers are offered compensation to deliver time-sensitive online orders. To manage this process, we propose a Markov Decision Process (MDP) model that captures key uncertainties, including the stochastic arrival of orders and crowd-shippers, and the probabilistic acceptance of delivery offers. Our solution approach integrates Neural Approximate Dynamic Programming (NeurADP) for adaptive order-to-shopper assignment with a Deep Double Q-Network (DDQN) for dynamic pricing. This joint optimization strategy enables multi-drop routing and accounts for offer acceptance uncertainty, aligning more closely with real-world operations. Experimental results demonstrate that the integrated NeurADP + DDQN policy achieves notable improvements in delivery cost efficiency, with up to 6.7% savings over NeurADP with fixed pricing and approximately 18% over myopic baselines. We also show that allowing flexible delivery delays and enabling multi-destination routing further reduces operational costs by 8% and 17%, respectively. These findings underscore the advantages of dynamic, forward-looking policies in crowd-shipping systems and offer practical guidance for urban logistics operators.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01749",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The court rejects Elon‚Äôs latest attempt to slow OpenAI down",
    "description": "We welcome the court‚Äôs March 4, 2025, decision rejecting Elon Musk‚Äôs latest attempt to slow down OpenAI for his personal benefit.",
    "summary": "We welcome the court‚Äôs March 4, 2025, decision rejecting Elon Musk‚Äôs latest attempt to slow down OpenAI for his personal benefit.",
    "pubDate": "Fri, 14 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/court-rejects-elon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploying the AI Comic Factory using the Inference API",
    "description": "",
    "summary": "Deploying the AI Comic Factory using the Inference API We recently announced Inference for PROs, our...",
    "pubDate": "Mon, 02 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-comic-factory",
    "thumbnail": "https://huggingface.co/blog/assets/165_ai_comic_factory/thumbnail.jpg"
  },
  {
    "title": "DALL¬∑E API now available in public beta",
    "description": "Starting today, developers can begin building apps with the DALL¬∑E API.",
    "summary": "Starting today, developers can begin building apps with the DALL¬∑E API.",
    "pubDate": "Thu, 03 Nov 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-api-now-available-in-public-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Speech Recognition in Unity",
    "description": "",
    "summary": "AI Speech Recognition in Unity Introduction This tutorial guides you through the process of implemen...",
    "pubDate": "Fri, 02 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-asr",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-asr-thumbnail.png"
  },
  {
    "title": "Ethics and Society Newsletter #3: Ethical Openness at Hugging Face",
    "description": "",
    "summary": "Ethics and Society Newsletter #3: Ethical Openness at Hugging Face Mission: Open and Good ML In our ...",
    "pubDate": "Thu, 30 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-3",
    "thumbnail": "https://huggingface.co/blog/assets/137_ethics_soc_3/ethics_3_thumbnail.png"
  },
  {
    "title": "Security on the path to AGI",
    "description": "At OpenAI, we proactively adapt, including by building comprehensive security measures directly into our infrastructure and models.",
    "summary": "At OpenAI, we proactively adapt, including by building comprehensive security measures directly into our infrastructure and models.",
    "pubDate": "Wed, 26 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/security-on-the-path-to-agi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Holistic Approach to Undesired Content Detection in the Real World",
    "description": "We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation.",
    "summary": "We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-holistic-approach-to-undesired-content-detection-in-the-real-world",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing Evaluation on the Hub",
    "description": "",
    "summary": "Announcing Evaluation on the Hub This project has been archived. If you want to evaluate LLMs on the...",
    "pubDate": "Tue, 28 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eval-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/82_eval_on_the_hub/thumbnail.png"
  },
  {
    "title": "Drug Discovery SMILES-to-Pharmacokinetics Diffusion Models with Deep Molecular Understanding",
    "description": "arXiv:2408.07636v2 Announce Type: replace-cross Abstract: Artificial intelligence (AI) is increasingly used in every stage of drug development. One challenge facing drug discovery AI is that drug pharmacokinetic (PK) datasets are often collected independently from each other, often with limited overlap, creating data overlap sparsity. Data sparsity makes data curation difficult for researchers looking to answer research questions in poly-pharmacy, drug combination research, and high-throughput screening. We propose Imagand, a novel SMILES-to-Pharmacokinetic (S2PK) diffusion model capable of generating an array of PK target properties conditioned on SMILES inputs. We show that Imagand-generated synthetic PK data closely resembles real data univariate and bivariate distributions, and improves performance for downstream tasks. Imagand is a promising solution for data overlap sparsity and allows researchers to efficiently generate ligand PK data for drug discovery research. Code is available at https://github.com/bing1100/Imagand.",
    "summary": "arXiv:2408.07636v2 Announce Type: replace-cross Abstract: Artificial intelligence (AI) is increasingly used in every stage of drug development. One challenge facing drug discovery AI is that drug pharmacokinetic (PK) datasets are often collected independently from each other, often with limited overlap, creating data overlap sparsity. Data sparsity makes data curation difficult for researchers looking to answer research questions in poly-pharmacy, drug combination research, and high-throughput screening. We propose Imagand, a novel SMILES-to-Pharmacokinetic (S2PK) diffusion model capable of generating an array of PK target properties conditioned on SMILES inputs. We show that Imagand-generated synthetic PK data closely resembles real data univariate and bivariate distributions, and improves performance for downstream tasks. Imagand is a promising solution for data overlap sparsity and allows researchers to efficiently generate ligand PK data for drug discovery research. Code is available at https://github.com/bing1100/Imagand.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.07636",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Five defeats Dota 2 world champions",
    "description": "OpenAI Five is the first AI to beat the world champions in an esports game, having won two back-to-back games versus the world champion Dota 2 team,¬†OG, at¬†Finals¬†this weekend. Both OpenAI Five and DeepMind‚Äôs AlphaStar had previously beaten good pros privately but lost their live pro matches, making this also the first time an AI has beaten esports pros on¬†livestream.",
    "summary": "OpenAI Five is the first AI to beat the world champions in an esports game, having won two back-to-back games versus the world champion Dota 2 team,¬†OG, at¬†Finals¬†this weekend. Both OpenAI Five and DeepMind‚Äôs AlphaStar had previously beaten good pros privately but lost their live pro matches, making this also the first time an AI has beaten esports pros on¬†livestream.",
    "pubDate": "Mon, 15 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-defeats-dota-2-world-champions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating the Effectiveness of Direct Preference Optimization for Personalizing German Automatic Text Simplifications for Persons with Intellectual Disabilities",
    "description": "arXiv:2507.01479v1 Announce Type: cross Abstract: Automatic text simplification (ATS) aims to enhance language accessibility for various target groups, particularly persons with intellectual disabilities. Recent advancements in generative AI, especially large language models (LLMs), have substantially improved the quality of machine-generated text simplifications, thereby mitigating information barriers for the target group. However, existing LLM-based ATS systems do not incorporate preference feedback on text simplifications during training, resulting in a lack of personalization tailored to the specific needs of target group representatives. In this work, we extend the standard supervised fine-tuning (SFT) approach for adapting LLM-based ATS models by leveraging a computationally efficient LLM alignment technique -- direct preference optimization (DPO). Specifically, we post-train LLM-based ATS models using human feedback collected from persons with intellectual disabilities, reflecting their preferences on paired text simplifications generated by mainstream LLMs. Furthermore, we propose a pipeline for developing personalized LLM-based ATS systems, encompassing data collection, model selection, SFT and DPO post-training, and evaluation. Our findings underscore the necessity of active participation of target group persons in designing personalized AI accessibility solutions aligned with human expectations. This work represents a step towards personalizing inclusive AI systems at the target-group level, incorporating insights not only from text simplification experts but also from target group persons themselves.",
    "summary": "arXiv:2507.01479v1 Announce Type: cross Abstract: Automatic text simplification (ATS) aims to enhance language accessibility for various target groups, particularly persons with intellectual disabilities. Recent advancements in generative AI, especially large language models (LLMs), have substantially improved the quality of machine-generated text simplifications, thereby mitigating information barriers for the target group. However, existing LLM-based ATS systems do not incorporate preference feedback on text simplifications during training, resulting in a lack of personalization tailored to the specific needs of target group representatives. In this work, we extend the standard supervised fine-tuning (SFT) approach for adapting LLM-based ATS models by leveraging a computationally efficient LLM alignment technique -- direct preference optimization (DPO). Specifically, we post-train LLM-based ATS models using human feedback collected from persons with intellectual disabilities, reflecting their preferences on paired text simplifications generated by mainstream LLMs. Furthermore, we propose a pipeline for developing personalized LLM-based ATS systems, encompassing data collection, model selection, SFT and DPO post-training, and evaluation. Our findings underscore the necessity of active participation of target group persons in designing personalized AI accessibility solutions aligned with human expectations. This work represents a step towards personalizing inclusive AI systems at the target-group level, incorporating insights not only from text simplification experts but also from target group persons themselves.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01479",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Understanding complex trends with deep research",
    "description": "How OpenAI deep research helps Bain & Company understand complex industry trends.",
    "summary": "How OpenAI deep research helps Bain & Company understand complex industry trends.",
    "pubDate": "Sun, 02 Feb 2025 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Primer on the EU AI Act: What It Means for AI Providers and Deployers",
    "description": "We‚Äôre sharing a preliminary overview of the EU AI Act including upcoming deadlines and requirements, with a particular focus on prohibited and high-risk use cases",
    "summary": "We‚Äôre sharing a preliminary overview of the EU AI Act including upcoming deadlines and requirements, with a particular focus on prohibited and high-risk use cases",
    "pubDate": "Tue, 30 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/a-primer-on-the-eu-ai-act",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2020: Final projects",
    "description": "Our third class of OpenAI Scholars presented their final projects at virtual Demo Day, showcasing their research results from over the past five months.",
    "summary": "Our third class of OpenAI Scholars presented their final projects at virtual Demo Day, showcasing their research results from over the past five months.",
    "pubDate": "Thu, 09 Jul 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2020-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gathering human feedback",
    "description": "RL-Teacher is an open-source implementation of our interface to train AIs via occasional human feedback rather than hand-crafted reward functions. The underlying technique was developed as a step towards safe AI systems, but also applies to reinforcement learning problems with rewards that are hard to specify.",
    "summary": "RL-Teacher is an open-source implementation of our interface to train AIs via occasional human feedback rather than hand-crafted reward functions. The underlying technique was developed as a step towards safe AI systems, but also applies to reinforcement learning problems with rewards that are hard to specify.",
    "pubDate": "Thu, 03 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gathering-human-feedback",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Estonia and OpenAI to bring ChatGPT to schools nationwide",
    "description": "Estonia and OpenAI to bring ChatGPT to schools nationwide. OpenAI will work with the Estonian Government to provide students and teachers in the secondary school system with access to ChatGPT Edu.",
    "summary": "Estonia and OpenAI to bring ChatGPT to schools nationwide. OpenAI will work with the Estonian Government to provide students and teachers in the secondary school system with access to ChatGPT Edu.",
    "pubDate": "Tue, 25 Feb 2025 04:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/estonia-schools-and-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Total noob‚Äôs intro to Hugging Face Transformers",
    "description": "",
    "summary": "Total noob‚Äôs intro to Hugging Face Transformers Welcome to 'A Total Noob‚Äôs Introduction to Hugging F...",
    "pubDate": "Fri, 22 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/noob_intro_transformers",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/guide.png"
  },
  {
    "title": "Faster assisted generation support for Intel Gaudi",
    "description": "",
    "summary": "Faster assisted generation support for Intel Gaudi As model sizes grow, Generative AI implementation...",
    "pubDate": "Tue, 04 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/assisted-generation-support-gaudi",
    "thumbnail": "https://huggingface.co/blog/assets/assisted-generation-support-gaudi/thumbnail.png"
  },
  {
    "title": "The sweet taste of a new idea",
    "description": "Sendhil Mullainathan brings a lifetime of unique perspectives to research in behavioral economics and machine learning.",
    "summary": "Sendhil Mullainathan brings a lifetime of unique perspectives to research in behavioral economics and machine learning.",
    "pubDate": "Mon, 19 May 2025 16:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/sweet-taste-new-idea-sendhil-mullainathan-0519",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-sendhil-Mullainathan.jpg"
  },
  {
    "title": "Put AI to Work for Marketing Teams",
    "description": "Put AI to Work for Marketing Teams",
    "summary": "Put AI to Work for Marketing Teams",
    "pubDate": "Thu, 31 Oct 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-for-marketing-teams",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MuRating: A High Quality Data Selecting Approach to Multilingual Large Language Model Pretraining",
    "description": "arXiv:2507.01785v1 Announce Type: cross Abstract: Data quality is a critical driver of large language model performance, yet existing model-based selection methods focus almost exclusively on English. We introduce MuRating, a scalable framework that transfers high-quality English data-quality signals into a single rater for 17 target languages. MuRating aggregates multiple English 'raters' via pairwise comparisons to learn unified document-quality scores,then projects these judgments through translation to train a multilingual evaluator on monolingual, cross-lingual, and parallel text pairs. Applied to web data, MuRating selects balanced subsets of English and multilingual content to pretrain a 1.2 B-parameter LLaMA model. Compared to strong baselines, including QuRater, AskLLM, DCLM and so on, our approach boosts average accuracy on both English benchmarks and multilingual evaluations, with especially large gains on knowledge-intensive tasks. We further analyze translation fidelity, selection biases, and underrepresentation of narrative material, outlining directions for future work.",
    "summary": "arXiv:2507.01785v1 Announce Type: cross Abstract: Data quality is a critical driver of large language model performance, yet existing model-based selection methods focus almost exclusively on English. We introduce MuRating, a scalable framework that transfers high-quality English data-quality signals into a single rater for 17 target languages. MuRating aggregates multiple English 'raters' via pairwise comparisons to learn unified document-quality scores,then projects these judgments through translation to train a multilingual evaluator on monolingual, cross-lingual, and parallel text pairs. Applied to web data, MuRating selects balanced subsets of English and multilingual content to pretrain a 1.2 B-parameter LLaMA model. Compared to strong baselines, including QuRater, AskLLM, DCLM and so on, our approach boosts average accuracy on both English benchmarks and multilingual evaluations, with especially large gains on knowledge-intensive tasks. We further analyze translation fidelity, selection biases, and underrepresentation of narrative material, outlining directions for future work.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01785",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Codex",
    "description": "Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered by codex-1. With Codex, developers can simultaneously deploy multiple agents to independently handle coding tasks such as writing features, answering questions about your codebase, fixing bugs, and proposing pull requests for review.",
    "summary": "Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered by codex-1. With Codex, developers can simultaneously deploy multiple agents to independently handle coding tasks such as writing features, answering questions about your codebase, fixing bugs, and proposing pull requests for review.",
    "pubDate": "Fri, 16 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-codex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Boosting the customer retail experience with GPT-4o mini",
    "description": "Zalando boosts the customer experience with its Assistant, powered by GPT-4o mini",
    "summary": "Zalando boosts the customer experience with its Assistant, powered by GPT-4o mini",
    "pubDate": "Wed, 11 Dec 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zalando",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Block Sparse Matrices for Smaller and Faster Language Models",
    "description": "",
    "summary": "Block Sparse Matrices for Smaller and Faster Language Models Saving space and time, one zero at a ti...",
    "pubDate": "Thu, 10 Sep 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch_block_sparse",
    "thumbnail": "https://huggingface.co/blog/assets/04_pytorch_block_sparse/thumbnail.png"
  },
  {
    "title": "OpenAI Fellows Winter 2019 & Interns Summer 2019",
    "description": "We are now accepting applications for OpenAI Fellows and Interns for 2019.",
    "summary": "We are now accepting applications for OpenAI Fellows and Interns for 2019.",
    "pubDate": "Tue, 09 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows-interns-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A guide to setting up your own Hugging Face leaderboard: an end-to-end example with Vectara's hallucination leaderboard",
    "description": "",
    "summary": "A guide to setting up your own Hugging Face leaderboard: an end-to-end example with Vectara's halluc...",
    "pubDate": "Fri, 12 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-vectara",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "You could have designed state of the art positional encoding",
    "description": "",
    "summary": "You could have designed state of the art positional encoding Gall's Law A complex system that works ...",
    "pubDate": "Mon, 25 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/designing-positional-encoding",
    "thumbnail": "https://huggingface.co/blog/assets/designing-positional-encoding/thumbnail_posenc.png"
  },
  {
    "title": "Gemini 2.5 Pro Preview: even better coding performance",
    "description": "We‚Äôve seen developers doing amazing things with Gemini 2.5 Pro, so we decided to release an updated version a couple of weeks early to get into developers hands sooner.",
    "summary": "We‚Äôve seen developers doing amazing things with Gemini 2.5 Pro, so we decided to release an updated version a couple of weeks early to get into developers hands sooner.",
    "pubDate": "Tue, 06 May 2025 15:06:55 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-pro-preview-even-better-coding-performance/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini_2-5_pro_claybrook__dev_her.2e16d0ba.fill-1200x600.jpg"
  },
  {
    "title": "Timm ‚ù§Ô∏è Transformers: Use any timm model with transformers",
    "description": "",
    "summary": "Timm ‚ù§Ô∏è Transformers: Use any timm model with transformers Get lightning-fast inference, quick quant...",
    "pubDate": "Thu, 16 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/timm-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/timm-transformers/thumbnail.png"
  },
  {
    "title": "The Falcon has landed in the Hugging Face ecosystem",
    "description": "",
    "summary": "The Falcon has landed in the Hugging Face ecosystem Falcon is a new family of state-of-the-art langu...",
    "pubDate": "Mon, 05 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon",
    "thumbnail": "https://huggingface.co/blog/assets/147_falcon/falcon_thumbnail.jpg"
  },
  {
    "title": "DALL¬∑E: Creating images from text",
    "description": "We‚Äôve trained a neural network called DALL¬∑E that creates images from text captions for a wide range of concepts expressible in natural¬†language.",
    "summary": "We‚Äôve trained a neural network called DALL¬∑E that creates images from text captions for a wide range of concepts expressible in natural¬†language.",
    "pubDate": "Tue, 05 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Probing Evaluation Awareness of Language Models",
    "description": "arXiv:2507.01786v1 Announce Type: cross Abstract: Language models can distinguish between testing and deployment phases -- a capability known as evaluation awareness. This has significant safety and policy implications, potentially undermining the reliability of evaluations that are central to AI governance frameworks and voluntary industry commitments. In this paper, we study evaluation awareness in Llama-3.3-70B-Instruct. We show that linear probes can separate real-world evaluation and deployment prompts, suggesting that current models internally represent this distinction. We also find that current safety evaluations are correctly classified by the probes, suggesting that they already appear artificial or inauthentic to models. Our findings underscore the importance of ensuring trustworthy evaluations and understanding deceptive capabilities. More broadly, our work showcases how model internals may be leveraged to support blackbox methods in safety audits, especially for future models more competent at evaluation awareness and deception.",
    "summary": "arXiv:2507.01786v1 Announce Type: cross Abstract: Language models can distinguish between testing and deployment phases -- a capability known as evaluation awareness. This has significant safety and policy implications, potentially undermining the reliability of evaluations that are central to AI governance frameworks and voluntary industry commitments. In this paper, we study evaluation awareness in Llama-3.3-70B-Instruct. We show that linear probes can separate real-world evaluation and deployment prompts, suggesting that current models internally represent this distinction. We also find that current safety evaluations are correctly classified by the probes, suggesting that they already appear artificial or inauthentic to models. Our findings underscore the importance of ensuring trustworthy evaluations and understanding deceptive capabilities. More broadly, our work showcases how model internals may be leveraged to support blackbox methods in safety audits, especially for future models more competent at evaluation awareness and deception.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01786",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More",
    "description": "",
    "summary": "Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More At Inceptio...",
    "pubDate": "Tue, 08 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-3c3h-aragen-ifeval",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_3c3h_aragen.png"
  },
  {
    "title": "Evaluating potential cybersecurity threats of advanced AI",
    "description": "Our framework enables cybersecurity experts to identify which defenses are necessary‚Äîand how to prioritize them",
    "summary": "Our framework enables cybersecurity experts to identify which defenses are necessary‚Äîand how to prioritize them",
    "pubDate": "Wed, 02 Apr 2025 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/evaluating-potential-cybersecurity-threats-of-advanced-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/qVftghWK2fcPAfl80FKEGIuxUxYuwlN2guNdIpH5A1nF4KYf5jufujNE7j3zv5uJ3CGPEJ47ec4UaUa1vl8H3rpuEX8jIkdQlXgCEYeGhAAEj3p06IY=w1200-h630-n-nu"
  },
  {
    "title": "Operator System Card",
    "description": "Drawing from OpenAI‚Äôs established safety frameworks, this document highlights our multi-layered approach, including model and product mitigations we‚Äôve implemented to protect against prompt engineering and jailbreaks, protect privacy and security, as well as details our external red teaming efforts, safety evaluations, and ongoing work to further refine these safeguards.",
    "summary": "Drawing from OpenAI‚Äôs established safety frameworks, this document highlights our multi-layered approach, including model and product mitigations we‚Äôve implemented to protect against prompt engineering and jailbreaks, protect privacy and security, as well as details our external red teaming efforts, safety evaluations, and ongoing work to further refine these safeguards.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/operator-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Unsupervised Panoptic Interpretation of Latent Spaces in GANs Using Space-Filling Vector Quantization",
    "description": "arXiv:2410.20573v2 Announce Type: replace-cross Abstract: Generative adversarial networks (GANs) learn a latent space whose samples can be mapped to real-world images. Such latent spaces are difficult to interpret. Some earlier supervised methods aim to create an interpretable latent space or discover interpretable directions, which requires exploiting data labels or annotated synthesized samples for training. However, we propose using a modification of vector quantization called space-filling vector quantization (SFVQ), which quantizes the data on a piece-wise linear curve. SFVQ can capture the underlying morphological structure of the latent space, making it interpretable. We apply this technique to model the latent space of pre-trained StyleGAN2 and BigGAN networks on various datasets. Our experiments show that the SFVQ curve yields a general interpretable model of the latent space such that it determines which parts of the latent space correspond to specific generative factors. Furthermore, we demonstrate that each line of the SFVQ curve can potentially refer to an interpretable direction for applying intelligible image transformations. We also demonstrate that the points located on an SFVQ line can be used for controllable data augmentation.",
    "summary": "arXiv:2410.20573v2 Announce Type: replace-cross Abstract: Generative adversarial networks (GANs) learn a latent space whose samples can be mapped to real-world images. Such latent spaces are difficult to interpret. Some earlier supervised methods aim to create an interpretable latent space or discover interpretable directions, which requires exploiting data labels or annotated synthesized samples for training. However, we propose using a modification of vector quantization called space-filling vector quantization (SFVQ), which quantizes the data on a piece-wise linear curve. SFVQ can capture the underlying morphological structure of the latent space, making it interpretable. We apply this technique to model the latent space of pre-trained StyleGAN2 and BigGAN networks on various datasets. Our experiments show that the SFVQ curve yields a general interpretable model of the latent space such that it determines which parts of the latent space correspond to specific generative factors. Furthermore, we demonstrate that each line of the SFVQ curve can potentially refer to an interpretable direction for applying intelligible image transformations. We also demonstrate that the points located on an SFVQ line can be used for controllable data augmentation.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.20573",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "UCB exploration via Q-ensembles",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 05 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ucb-exploration-via-q-ensembles",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sim-to-real transfer of robotic control with dynamics randomization",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 18 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sim-to-real-transfer-of-robotic-control-with-dynamics-randomization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o1 System Card",
    "description": "This report outlines the safety work carried out prior to releasing OpenAI o1 and o1-mini, including external red teaming and frontier risk evaluations according to our Preparedness Framework.",
    "summary": "This report outlines the safety work carried out prior to releasing OpenAI o1 and o1-mini, including external red teaming and frontier risk evaluations according to our Preparedness Framework.",
    "pubDate": "Thu, 05 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Security Review of Gradio 5",
    "description": "",
    "summary": "A Security Review of Gradio 5 We audited Gradio 5 so that your machine learning apps are safe! In th...",
    "pubDate": "Thu, 10 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-5-security",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-5-security/thumbnail.png"
  },
  {
    "title": "Introducing the Realtime API",
    "description": "Developers can now build fast speech-to-speech experiences into their applications",
    "summary": "Developers can now build fast speech-to-speech experiences into their applications",
    "pubDate": "Tue, 01 Oct 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-realtime-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Supercharged Searching on the Hugging Face Hub",
    "description": "",
    "summary": "Supercharged Searching on the Hugging Face Hub The huggingface_hub library is a lightweight interfac...",
    "pubDate": "Tue, 25 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/searching-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/48_hubsearch/thumbnail.png"
  },
  {
    "title": "Partnership with American Journalism Project to support local news",
    "description": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
    "summary": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
    "pubDate": "Tue, 18 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/partnership-with-american-journalism-project-to-support-local-news",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-4o System Card External Testers Acknowledgements",
    "description": "GPT-4o system card external testers acknowledgements",
    "summary": "GPT-4o system card external testers acknowledgements",
    "pubDate": "Thu, 08 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-system-card/external-testers-acknowledgements",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Text Detoxification: Data Efficiency, Semantic Preservation and Model Generalization",
    "description": "arXiv:2507.01050v1 Announce Type: cross Abstract: The widespread dissemination of toxic content on social media poses a serious threat to both online environments and public discourse, highlighting the urgent need for detoxification methods that effectively remove toxicity while preserving the original semantics. However, existing approaches often struggle to simultaneously achieve strong detoxification performance, semantic preservation, and robustness to out-of-distribution data. Moreover, they typically rely on costly, manually annotated parallel corpora while showing poor data efficiency. To address these challenges, we propose a two-stage training framework that jointly optimizes for data efficiency, semantic preservation, and model generalization. We first perform supervised fine-tuning on a small set of high-quality, filtered parallel data to establish a strong initialization. Then, we leverage unlabeled toxic inputs and a custom-designed reward model to train the LLM using Group Relative Policy Optimization. Experimental results demonstrate that our method effectively mitigates the trade-offs faced by previous work, achieving state-of-the-art performance with improved generalization and significantly reduced dependence on annotated data. Our code is available at: https://anonymous.4open.science/r/Detoxification-of-Text-725F/",
    "summary": "arXiv:2507.01050v1 Announce Type: cross Abstract: The widespread dissemination of toxic content on social media poses a serious threat to both online environments and public discourse, highlighting the urgent need for detoxification methods that effectively remove toxicity while preserving the original semantics. However, existing approaches often struggle to simultaneously achieve strong detoxification performance, semantic preservation, and robustness to out-of-distribution data. Moreover, they typically rely on costly, manually annotated parallel corpora while showing poor data efficiency. To address these challenges, we propose a two-stage training framework that jointly optimizes for data efficiency, semantic preservation, and model generalization. We first perform supervised fine-tuning on a small set of high-quality, filtered parallel data to establish a strong initialization. Then, we leverage unlabeled toxic inputs and a custom-designed reward model to train the LLM using Group Relative Policy Optimization. Experimental results demonstrate that our method effectively mitigates the trade-offs faced by previous work, achieving state-of-the-art performance with improved generalization and significantly reduced dependence on annotated data. Our code is available at: https://anonymous.4open.science/r/Detoxification-of-Text-725F/",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01050",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Celebrating an academic-industry collaboration to advance vehicle technology",
    "description": "MIT Advanced Vehicle Technology Consortium marks a decade of developing data that improve understanding of how drivers use and respond to increasingly sophisticated automotive features.",
    "summary": "MIT Advanced Vehicle Technology Consortium marks a decade of developing data that improve understanding of how drivers use and respond to increasingly sophisticated automotive features.",
    "pubDate": "Mon, 16 Jun 2025 14:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/celebrating-academic-industry-collaboration-advance-vehicle-technology-0616",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-AVT-conference.jpg"
  },
  {
    "title": "Porting fairseq wmt19 translation system to transformers",
    "description": "",
    "summary": "Porting fairseq wmt19 translation system to transformers A guest blog post by Stas Bekman This artic...",
    "pubDate": "Tue, 03 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/porting-fsmt",
    "thumbnail": "https://huggingface.co/blog/assets/07_porting_fsmt/thumbnail.png"
  },
  {
    "title": "Improved Techniques for Training Consistency Models",
    "description": "Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training.",
    "summary": "Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improved-techniques-for-training-consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The power of continuous learning",
    "description": "Lilian Weng works on Applied AI Research at OpenAI.",
    "summary": "Lilian Weng works on Applied AI Research at OpenAI.",
    "pubDate": "Fri, 23 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-power-of-continuous-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action",
    "description": "",
    "summary": "Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action Hugging Face provides a Hub platf...",
    "pubDate": "Wed, 09 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-deepfloydif-using-bentoml",
    "thumbnail": "https://huggingface.co/blog/assets/deploy-deepfloydif-using-bentoml/thumbnail.png"
  },
  {
    "title": "VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process",
    "description": "arXiv:2507.01284v1 Announce Type: cross Abstract: Recent advancements in open-source Visual Language Models (VLMs) such as LLaVA, Qwen-VL, and Llama have catalyzed extensive research on their integration with diverse systems. The internet-scale general knowledge encapsulated within these models presents significant opportunities for enhancing autonomous driving perception, prediction, and planning capabilities. In this paper we propose VLAD, a vision-language autonomous driving model, which integrates a fine-tuned VLM with VAD, a state-of-the-art end-to-end system. We implement a specialized fine-tuning approach using custom question-answer datasets designed specifically to improve the spatial reasoning capabilities of the model. The enhanced VLM generates high-level navigational commands that VAD subsequently processes to guide vehicle operation. Additionally, our system produces interpretable natural language explanations of driving decisions, thereby increasing transparency and trustworthiness of the traditionally black-box end-to-end architecture. Comprehensive evaluation on the real-world nuScenes dataset demonstrates that our integrated system reduces average collision rates by 31.82% compared to baseline methodologies, establishing a new benchmark for VLM-augmented autonomous driving systems.",
    "summary": "arXiv:2507.01284v1 Announce Type: cross Abstract: Recent advancements in open-source Visual Language Models (VLMs) such as LLaVA, Qwen-VL, and Llama have catalyzed extensive research on their integration with diverse systems. The internet-scale general knowledge encapsulated within these models presents significant opportunities for enhancing autonomous driving perception, prediction, and planning capabilities. In this paper we propose VLAD, a vision-language autonomous driving model, which integrates a fine-tuned VLM with VAD, a state-of-the-art end-to-end system. We implement a specialized fine-tuning approach using custom question-answer datasets designed specifically to improve the spatial reasoning capabilities of the model. The enhanced VLM generates high-level navigational commands that VAD subsequently processes to guide vehicle operation. Additionally, our system produces interpretable natural language explanations of driving decisions, thereby increasing transparency and trustworthiness of the traditionally black-box end-to-end architecture. Comprehensive evaluation on the real-world nuScenes dataset demonstrates that our integrated system reduces average collision rates by 31.82% compared to baseline methodologies, establishing a new benchmark for VLM-augmented autonomous driving systems.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01284",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Driving growth and ‚ÄòWOW‚Äô moments with OpenAI",
    "description": "LY Corporation: Driving growth and ‚ÄòWOW‚Äô moments with OpenAI",
    "summary": "LY Corporation: Driving growth and ‚ÄòWOW‚Äô moments with OpenAI",
    "pubDate": "Wed, 12 Mar 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ly-corporation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GAIus: Combining Genai with Legal Clauses Retrieval for Knowledge-based Assistant",
    "description": "arXiv:2507.01259v1 Announce Type: cross Abstract: In this paper we discuss the capability of large language models to base their answer and provide proper references when dealing with legal matters of non-english and non-chinese speaking country. We discuss the history of legal information retrieval, the difference between case law and statute law, its impact on the legal tasks and analyze the latest research in this field. Basing on that background we introduce gAIus, the architecture of the cognitive LLM-based agent, whose responses are based on the knowledge retrieved from certain legal act, which is Polish Civil Code. We propose a retrieval mechanism which is more explainable, human-friendly and achieves better results than embedding-based approaches. To evaluate our method we create special dataset based on single-choice questions from entrance exams for law apprenticeships conducted in Poland. The proposed architecture critically leveraged the abilities of used large language models, improving the gpt-3.5-turbo-0125 by 419%, allowing it to beat gpt-4o and lifting gpt-4o-mini score from 31% to 86%. At the end of our paper we show the possible future path of research and potential applications of our findings.",
    "summary": "arXiv:2507.01259v1 Announce Type: cross Abstract: In this paper we discuss the capability of large language models to base their answer and provide proper references when dealing with legal matters of non-english and non-chinese speaking country. We discuss the history of legal information retrieval, the difference between case law and statute law, its impact on the legal tasks and analyze the latest research in this field. Basing on that background we introduce gAIus, the architecture of the cognitive LLM-based agent, whose responses are based on the knowledge retrieved from certain legal act, which is Polish Civil Code. We propose a retrieval mechanism which is more explainable, human-friendly and achieves better results than embedding-based approaches. To evaluate our method we create special dataset based on single-choice questions from entrance exams for law apprenticeships conducted in Poland. The proposed architecture critically leveraged the abilities of used large language models, improving the gpt-3.5-turbo-0125 by 419%, allowing it to beat gpt-4o and lifting gpt-4o-mini score from 31% to 86%. At the end of our paper we show the possible future path of research and potential applications of our findings.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01259",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Outbound coordinated vulnerability disclosure policy",
    "description": "Outbound coordinated vulnerability disclosure policy",
    "summary": "Outbound coordinated vulnerability disclosure policy",
    "pubDate": "Mon, 09 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/policies/outbound-coordinated-disclosure-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPU-based complete search for nonlinear minimization subject to bounds",
    "description": "arXiv:2507.01770v1 Announce Type: cross Abstract: This paper introduces a GPU-based complete search method to enclose the global minimum of a nonlinear function subject to simple bounds on the variables. Using interval analysis, coupled with the computational power and architecture of GPU, the method iteratively rules out the regions in the search domain where the global minimum cannot exist and leaves a finite set of regions where the global minimum must exist. For effectiveness, because of the rigor of interval analysis, the method is guaranteed to enclose the global minimum of the nonlinear function even in the presence of rounding errors. For efficiency, the method employs a novel GPU-based single program, single data parallel programming style to circumvent major GPU performance bottlenecks, and a variable cycling technique is also integrated into the method to reduce computational cost when minimizing large-scale nonlinear functions. The method is validated by minimizing 10 multimodal benchmark test functions with scalable dimensions, including the well-known Ackley function, Griewank function, Levy function, and Rastrigin function. These benchmark test functions represent grand challenges of global optimization, and enclosing the guaranteed global minimum of these benchmark test functions with more than 80 dimensions has not been reported in the literature. Our method completely searches the feasible domain and successfully encloses the guaranteed global minimum of these 10 benchmark test functions with up to 10,000 dimensions using only one GPU in a reasonable computation time, far exceeding the reported results in the literature due to the unique method design and implementation based on GPU architecture.",
    "summary": "arXiv:2507.01770v1 Announce Type: cross Abstract: This paper introduces a GPU-based complete search method to enclose the global minimum of a nonlinear function subject to simple bounds on the variables. Using interval analysis, coupled with the computational power and architecture of GPU, the method iteratively rules out the regions in the search domain where the global minimum cannot exist and leaves a finite set of regions where the global minimum must exist. For effectiveness, because of the rigor of interval analysis, the method is guaranteed to enclose the global minimum of the nonlinear function even in the presence of rounding errors. For efficiency, the method employs a novel GPU-based single program, single data parallel programming style to circumvent major GPU performance bottlenecks, and a variable cycling technique is also integrated into the method to reduce computational cost when minimizing large-scale nonlinear functions. The method is validated by minimizing 10 multimodal benchmark test functions with scalable dimensions, including the well-known Ackley function, Griewank function, Levy function, and Rastrigin function. These benchmark test functions represent grand challenges of global optimization, and enclosing the guaranteed global minimum of these benchmark test functions with more than 80 dimensions has not been reported in the literature. Our method completely searches the feasible domain and successfully encloses the guaranteed global minimum of these 10 benchmark test functions with up to 10,000 dimensions using only one GPU in a reasonable computation time, far exceeding the reported results in the literature due to the unique method design and implementation based on GPU architecture.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01770",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing GPT-4.5",
    "description": "We‚Äôre releasing a research preview of GPT‚Äë4.5‚Äîour largest and best model for chat yet. GPT‚Äë4.5 is a step forward in scaling up pre-training and post-training.",
    "summary": "We‚Äôre releasing a research preview of GPT‚Äë4.5‚Äîour largest and best model for chat yet. GPT‚Äë4.5 is a step forward in scaling up pre-training and post-training.",
    "pubDate": "Thu, 27 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-gpt-4-5",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MuseNet",
    "description": "We‚Äôve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose unsupervised technology as¬†GPT-2, a large-scale¬†transformer¬†model trained to predict the next token in a sequence, whether audio or¬†text.",
    "summary": "We‚Äôve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose unsupervised technology as¬†GPT-2, a large-scale¬†transformer¬†model trained to predict the next token in a sequence, whether audio or¬†text.",
    "pubDate": "Thu, 25 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/musenet",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Creating Privacy Preserving AI with Substra",
    "description": "",
    "summary": "Creating Privacy Preserving AI with Substra With the recent rise of generative techniques, machine l...",
    "pubDate": "Wed, 12 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/owkin-substra",
    "thumbnail": "https://huggingface.co/blog/assets/139_owkin-substra/thumbnail.png"
  },
  {
    "title": "Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models",
    "description": "arXiv:2507.01915v1 Announce Type: cross Abstract: Reinforcement Learning from Human Feedback (RLHF) has emerged as a powerful technique for aligning large language models (LLMs) with human preferences. However, effectively aligning LLMs with diverse human preferences remains a significant challenge, particularly when they are conflict. To address this issue, we frame human value alignment as a multi-objective optimization problem, aiming to maximize a set of potentially conflicting objectives. We introduce Gradient-Adaptive Policy Optimization (GAPO), a novel fine-tuning paradigm that employs multiple-gradient descent to align LLMs with diverse preference distributions. GAPO adaptively rescales the gradients for each objective to determine an update direction that optimally balances the trade-offs between objectives. Additionally, we introduce P-GAPO, which incorporates user preferences across different objectives and achieves Pareto solutions that better align with the user's specific needs. Our theoretical analysis demonstrates that GAPO converges towards a Pareto optimal solution for multiple objectives. Empirical results on Mistral-7B show that GAPO outperforms current state-of-the-art methods, achieving superior performance in both helpfulness and harmlessness.",
    "summary": "arXiv:2507.01915v1 Announce Type: cross Abstract: Reinforcement Learning from Human Feedback (RLHF) has emerged as a powerful technique for aligning large language models (LLMs) with human preferences. However, effectively aligning LLMs with diverse human preferences remains a significant challenge, particularly when they are conflict. To address this issue, we frame human value alignment as a multi-objective optimization problem, aiming to maximize a set of potentially conflicting objectives. We introduce Gradient-Adaptive Policy Optimization (GAPO), a novel fine-tuning paradigm that employs multiple-gradient descent to align LLMs with diverse preference distributions. GAPO adaptively rescales the gradients for each objective to determine an update direction that optimally balances the trade-offs between objectives. Additionally, we introduce P-GAPO, which incorporates user preferences across different objectives and achieves Pareto solutions that better align with the user's specific needs. Our theoretical analysis demonstrates that GAPO converges towards a Pareto optimal solution for multiple objectives. Empirical results on Mistral-7B show that GAPO outperforms current state-of-the-art methods, achieving superior performance in both helpfulness and harmlessness.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01915",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Transfer of adversarial robustness between perturbation types",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 03 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/transfer-of-adversarial-robustness-between-perturbation-types",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing GPT-4.1 in the API",
    "description": "Introducing GPT-4.1 in the API‚Äîa new family of models with across-the-board improvements, including major gains in coding, instruction following, and long-context understanding. We‚Äôre also releasing our first nano model. Available to developers worldwide starting today.",
    "summary": "Introducing GPT-4.1 in the API‚Äîa new family of models with across-the-board improvements, including major gains in coding, instruction following, and long-context understanding. We‚Äôre also releasing our first nano model. Available to developers worldwide starting today.",
    "pubDate": "Mon, 14 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-1",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Data-driven beauty and creativity with ChatGPT",
    "description": "Data-driven beauty: How The Est√©e Lauder Companies unlocks insights with ChatGPT",
    "summary": "Data-driven beauty: How The Est√©e Lauder Companies unlocks insights with ChatGPT",
    "pubDate": "Wed, 13 Nov 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/estee-lauder",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SynthID Detector ‚Äî a new portal to help identify AI-generated content",
    "description": "Learn about the new SynthID Detector portal we announced at I/O to help people understand how the content they see online was generated.",
    "summary": "Learn about the new SynthID Detector portal we announced at I/O to help people understand how the content they see online was generated.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/synthid-detector--a-new-portal-to-help-identify-ai-generated-content/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Gemini_MOD_HEADER.width-1300.jpg"
  },
  {
    "title": "Active Learning with AutoNLP and Prodigy",
    "description": "",
    "summary": "Active Learning with AutoNLP and Prodigy Active learning in the context of Machine Learning is a pro...",
    "pubDate": "Thu, 23 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autonlp-prodigy",
    "thumbnail": "https://huggingface.co/blog/assets/43_autonlp_prodigy/thumbnail.png"
  },
  {
    "title": "Releasing Outlines-core 0.1.0: structured generation in Rust and Python",
    "description": "",
    "summary": "Releasing Outlines-core 0.1.0: structured generation in Rust and Python dottxt and Hugging Face are ...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/outlines-core",
    "thumbnail": "https://huggingface.co/blog/assets/outlines-core/thumbnail.gif"
  },
  {
    "title": "DALL¬∑E now available without waitlist",
    "description": "New users can start creating straight away. Lessons learned from deployment and improvements to our safety systems make wider availability possible.",
    "summary": "New users can start creating straight away. Lessons learned from deployment and improvements to our safety systems make wider availability possible.",
    "pubDate": "Wed, 28 Sep 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-now-available-without-waitlist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Short Summary of Chinese AI Global Expansion",
    "description": "",
    "summary": "A Short Summary of Chinese AI Global Expansion In the early 15th century, Zheng He (also known as Ch...",
    "pubDate": "Thu, 03 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chinese-ai-expansion",
    "thumbnail": "https://huggingface.co/blog/assets/chinese-ai-expansion/thumbnail.png"
  },
  {
    "title": "How Hugging Face Accelerated Development of Witty Works Writing Assistant",
    "description": "",
    "summary": "How Hugging Face Accelerated Development of Witty Works Writing Assistant The Success Story of Witty...",
    "pubDate": "Wed, 01 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/classification-use-cases",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/witty-works.png"
  },
  {
    "title": "The Google for Startups Gemini kit is here",
    "description": "A blonde woman wearing a black top and red skit looks at the camera, describing the benefits of the Google for Startups Gemini Kit.",
    "summary": "A blonde woman wearing a black top and red skit looks at the camera, describing the benefits of the Google for Startups Gemini Kit.",
    "pubDate": "Thu, 26 Jun 2025 12:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/entrepreneurs/google-for-startups-gemini-ai-kit/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Paige_Thumbnail.width-1300.png"
  },
  {
    "title": "OpenAI and the CSU system bring AI to 500,000 students & faculty",
    "description": "The largest deployment of ChatGPT to date will expand the use of AI in education and help the United States build an AI-ready workforce.",
    "summary": "The largest deployment of ChatGPT to date will expand the use of AI in education and help the United States build an AI-ready workforce.",
    "pubDate": "Tue, 04 Feb 2025 11:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-the-csu-system",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "4M Models Scanned: Protect AI + Hugging Face 6 Months In",
    "description": "",
    "summary": "4M Models Scanned: Protect AI + Hugging Face 6 Months In Hugging Face and Protect AI partnered in Oc...",
    "pubDate": "Mon, 14 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pai-6-month",
    "thumbnail": "https://huggingface.co/blog/assets/pai-6-month/thumbnail.png"
  },
  {
    "title": "Learning to reason with LLMs",
    "description": "We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before it answers‚Äîit can produce a long internal chain of thought before responding to the user.",
    "summary": "We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before it answers‚Äîit can produce a long internal chain of thought before responding to the user.",
    "pubDate": "Thu, 12 Sep 2024 10:02:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-reason-with-llms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "What Makes a Dialog Agent Useful?",
    "description": "",
    "summary": "What Makes a Dialog Agent Useful? The techniques behind ChatGPT: RLHF, IFT, CoT, Red teaming, and mo...",
    "pubDate": "Tue, 24 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dialog-agents",
    "thumbnail": "https://huggingface.co/blog/assets/dialog-agents/thumbnail.png"
  },
  {
    "title": "Goodbye cold boot - how we made LoRA inference 300% faster",
    "description": "",
    "summary": "Goodbye cold boot - how we made LoRA Inference 300% faster tl;dr: We swap the Stable Diffusion LoRA ...",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lora-adapters-dynamic-loading",
    "thumbnail": "https://huggingface.co/blog/assets/171_load_lora_adapters/thumbnail3.png"
  },
  {
    "title": "Introducing Gemma 3",
    "description": "The most capable model you can run on a single GPU or TPU.",
    "summary": "The most capable model you can run on a single GPU or TPU.",
    "pubDate": "Wed, 12 Mar 2025 08:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemma-3/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemma3_KeywordBlog_RD3_V01b_SocialShare.width-1300.png"
  },
  {
    "title": "OpenAI Baselines: DQN",
    "description": "We‚Äôre open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with performance on par with published results. We‚Äôll release the algorithms over upcoming months; today‚Äôs release includes DQN and three of its variants.",
    "summary": "We‚Äôre open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with performance on par with published results. We‚Äôll release the algorithms over upcoming months; today‚Äôs release includes DQN and three of its variants.",
    "pubDate": "Wed, 24 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-dqn",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making sense of this mess",
    "description": "",
    "summary": "Making sense of this mess When I joined Hugging Face nearly 3 years ago, the Transformers documentat...",
    "pubDate": "Fri, 07 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-docs-redesign",
    "thumbnail": "https://huggingface.co/blog/assets/transformers-docs-redesign/thumbnail.png"
  },
  {
    "title": "Coding with OpenAI o1",
    "description": "Scott Wu, CEO and Co-Founder of Cognition, explains how OpenAI o1 makes coding decisions in a more human-like way.",
    "summary": "Scott Wu, CEO and Co-Founder of Cognition, explains how OpenAI o1 makes coding decisions in a more human-like way.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-coding",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SKIL: Semantic Keypoint Imitation Learning for Generalizable Data-efficient Manipulation",
    "description": "arXiv:2501.14400v2 Announce Type: replace-cross Abstract: Real-world tasks such as garment manipulation and table rearrangement demand robots to perform generalizable, highly precise, and long-horizon actions. Although imitation learning has proven to be an effective approach for teaching robots new skills, large amounts of expert demonstration data are still indispensible for these complex tasks, resulting in high sample complexity and costly data collection. To address this, we propose Semantic Keypoint Imitation Learning (SKIL), a framework which automatically obtains semantic keypoints with the help of vision foundation models, and forms the descriptor of semantic keypoints that enables efficient imitation learning of complex robotic tasks with significantly lower sample complexity. In real-world experiments, SKIL doubles the performance of baseline methods in tasks such as picking a cup or mouse, while demonstrating exceptional robustness to variations in objects, environmental changes, and distractors. For long-horizon tasks like hanging a towel on a rack where previous methods fail completely, SKIL achieves a mean success rate of 70% with as few as 30 demonstrations. Furthermore, SKIL naturally supports cross-embodiment learning due to its semantic keypoints abstraction. Our experiments demonstrate that even human videos bring considerable improvement to the learning performance. All these results demonstrate the great success of SKIL in achieving data-efficient generalizable robotic learning. Visualizations and code are available at: https://skil-robotics.github.io/SKIL-robotics/.",
    "summary": "arXiv:2501.14400v2 Announce Type: replace-cross Abstract: Real-world tasks such as garment manipulation and table rearrangement demand robots to perform generalizable, highly precise, and long-horizon actions. Although imitation learning has proven to be an effective approach for teaching robots new skills, large amounts of expert demonstration data are still indispensible for these complex tasks, resulting in high sample complexity and costly data collection. To address this, we propose Semantic Keypoint Imitation Learning (SKIL), a framework which automatically obtains semantic keypoints with the help of vision foundation models, and forms the descriptor of semantic keypoints that enables efficient imitation learning of complex robotic tasks with significantly lower sample complexity. In real-world experiments, SKIL doubles the performance of baseline methods in tasks such as picking a cup or mouse, while demonstrating exceptional robustness to variations in objects, environmental changes, and distractors. For long-horizon tasks like hanging a towel on a rack where previous methods fail completely, SKIL achieves a mean success rate of 70% with as few as 30 demonstrations. Furthermore, SKIL naturally supports cross-embodiment learning due to its semantic keypoints abstraction. Our experiments demonstrate that even human videos bring considerable improvement to the learning performance. All these results demonstrate the great success of SKIL in achieving data-efficient generalizable robotic learning. Visualizations and code are available at: https://skil-robotics.github.io/SKIL-robotics/.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.14400",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Klarna's AI assistant does the work of 700 full-time agents",
    "description": "Klarna is using AI to revolutionize personal shopping, customer service, and employee productivity.",
    "summary": "Klarna is using AI to revolutionize personal shopping, customer service, and employee productivity.",
    "pubDate": "Fri, 05 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/klarna",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Machine Learning Demos on arXiv",
    "description": "",
    "summary": "Hugging Face Machine Learning Demos on arXiv We‚Äôre very excited to announce that Hugging Face has co...",
    "pubDate": "Thu, 17 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arxiv",
    "thumbnail": "https://huggingface.co/blog/assets/arxiv/thumbnail.png"
  },
  {
    "title": "Scaling up BERT-like model Inference on modern CPU - Part 2",
    "description": "",
    "summary": "Scaling up BERT-like model Inference on modern CPU - Part 2 Introduction: Using Intel Software to Op...",
    "pubDate": "Thu, 04 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-cpu-scaling-part-2",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Bringing serverless GPU inference to Hugging Face users",
    "description": "",
    "summary": "Bringing serverless GPU inference to Hugging Face users Today, we are thrilled to announce the launc...",
    "pubDate": "Tue, 02 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cloudflare-workers-ai",
    "thumbnail": "https://huggingface.co/blog/assets/cloudflare-workers-ai/thumbnail.jpg"
  },
  {
    "title": "Train your ControlNet with diffusers",
    "description": "",
    "summary": "Train your ControlNet with diffusers üß® Introduction ControlNet is a neural network structure that al...",
    "pubDate": "Fri, 24 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-your-controlnet",
    "thumbnail": "https://huggingface.co/blog/assets/136_train-your-controlnet/thumbnail.png"
  },
  {
    "title": "Accelerating Stable Diffusion XL Inference with JAX on Cloud TPU v5e",
    "description": "",
    "summary": "Accelerating Stable Diffusion XL Inference with JAX on Cloud TPU v5e Generative AI models, such as S...",
    "pubDate": "Tue, 03 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_jax",
    "thumbnail": "https://huggingface.co/blog/assets/sdxl-jax/thumbnail.jpg"
  },
  {
    "title": "TGI Multi-LoRA: Deploy Once, Serve 30 Models",
    "description": "",
    "summary": "TGI Multi-LoRA: Deploy Once, Serve 30 models Are you tired of the complexity and expense of managing...",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/multi-lora-serving",
    "thumbnail": "https://huggingface.co/blog/assets/multi-lora-serving/thumbnail.png"
  },
  {
    "title": "OpenAI and Los Alamos National Laboratory announce research partnership",
    "description": "OpenAI and Los Alamos National Laboratory are working to develop safety evaluations to assess and measure biological capabilities and risks associated with frontier models.",
    "summary": "OpenAI and Los Alamos National Laboratory are working to develop safety evaluations to assess and measure biological capabilities and risks associated with frontier models.",
    "pubDate": "Wed, 10 Jul 2024 06:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-los-alamos-national-laboratory-work-together",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hindsight Experience Replay",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 05 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hindsight-experience-replay",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI o1",
    "description": "Introducing OpenAI o1",
    "summary": "Introducing OpenAI o1",
    "pubDate": "Thu, 12 Sep 2024 10:03:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-o1-preview",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Nonlinear computation in deep linear networks",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 29 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonlinear-computation-in-deep-linear-networks",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Search Live: Talk, listen and explore in real time with AI Mode",
    "description": "Logos for AI Mode in Search and Search Live in front of a black background",
    "summary": "Logos for AI Mode in Search and Search Live in front of a black background",
    "pubDate": "Wed, 18 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/search-live-ai-mode/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SearchLive_SS.width-1300.png"
  },
  {
    "title": "Machine Learning Experts - Lewis Tunstall Interview",
    "description": "",
    "summary": "Machine Learning Experts - Lewis Tunstall ü§ó Welcome to Machine Learning Experts - Lewis Tunstall Hey...",
    "pubDate": "Wed, 13 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lewis-tunstall-interview",
    "thumbnail": "https://huggingface.co/blog/assets/60_lewis_tunstall_interview/thumbnail.png"
  },
  {
    "title": "Google Cloud TPUs made available to Hugging Face users",
    "description": "",
    "summary": "Google Cloud TPUs made available to Hugging Face users We're excited to share some great news! AI bu...",
    "pubDate": "Tue, 09 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tpu-inference-endpoints-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/tpu-inference-endpoints-spaces/thumbnail.png"
  },
  {
    "title": "Forecasting potential misuses of language models for disinformation campaigns and how to reduce risk",
    "description": "OpenAI researchers collaborated with Georgetown University‚Äôs Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report¬†here.",
    "summary": "OpenAI researchers collaborated with Georgetown University‚Äôs Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report¬†here.",
    "pubDate": "Wed, 11 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/forecasting-misuse",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-tuning Stable Diffusion models on Intel CPUs",
    "description": "",
    "summary": "Fine-tuning Stable Diffusion Models on Intel CPUs Diffusion models helped popularize generative AI t...",
    "pubDate": "Fri, 14 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-finetuning-intel",
    "thumbnail": "https://huggingface.co/blog/assets/stable-diffusion-finetuning-intel/01.png"
  },
  {
    "title": "OpenAI and Elon Musk",
    "description": "We are dedicated to the OpenAI mission and have pursued it every step of the way.",
    "summary": "We are dedicated to the OpenAI mission and have pursued it every step of the way.",
    "pubDate": "Tue, 05 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-elon-musk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An Introduction to Q-Learning Part 2",
    "description": "",
    "summary": "An Introduction to Q-Learning Part 2/2 Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 2,...",
    "pubDate": "Fri, 20 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-q-part2",
    "thumbnail": "https://huggingface.co/blog/assets/73_deep_rl_q_part2/thumbnail.gif"
  },
  {
    "title": "Introducing smolagents: simple agents that write actions in code.",
    "description": "",
    "summary": "Introducing smolagents, a simple library to build agents Today we are launching smolagents , a very ...",
    "pubDate": "Tue, 31 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents/thumbnail.png"
  },
  {
    "title": "Open-R1: a fully open reproduction of DeepSeek-R1",
    "description": "",
    "summary": "Open-R1: a fully open reproduction of DeepSeek-R1 What is DeepSeek-R1? If you‚Äôve ever struggled with...",
    "pubDate": "Tue, 28 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-r1",
    "thumbnail": "https://huggingface.co/blog/assets/open-r1/thumbnails.png"
  },
  {
    "title": "Finally, a Replacement for BERT: Introducing ModernBERT",
    "description": "",
    "summary": "Finally, a Replacement for BERT TL;DR This blog post introduces ModernBERT, a family of state-of-the...",
    "pubDate": "Thu, 19 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/modernbert",
    "thumbnail": "https://huggingface.co/blog/assets/modernbert/thumbnail.png"
  },
  {
    "title": "PathCoT: Chain-of-Thought Prompting for Zero-shot Pathology Visual Reasoning",
    "description": "arXiv:2507.01029v1 Announce Type: cross Abstract: With the development of generative artificial intelligence and instruction tuning techniques, multimodal large language models (MLLMs) have made impressive progress on general reasoning tasks. Benefiting from the chain-of-thought (CoT) methodology, MLLMs can solve the visual reasoning problem step-by-step. However, existing MLLMs still face significant challenges when applied to pathology visual reasoning tasks: (1) LLMs often underperforms because they lack domain-specific information, which can lead to model hallucinations. (2) The additional reasoning steps in CoT may introduce errors, leading to the divergence of answers. To address these limitations, we propose PathCoT, a novel zero-shot CoT prompting method which integrates the pathology expert-knowledge into the reasoning process of MLLMs and incorporates self-evaluation to mitigate divergence of answers. Specifically, PathCoT guides the MLLM with prior knowledge to perform as pathology experts, and provides comprehensive analysis of the image with their domain-specific knowledge. By incorporating the experts' knowledge, PathCoT can obtain the answers with CoT reasoning. Furthermore, PathCoT incorporates a self-evaluation step that assesses both the results generated directly by MLLMs and those derived through CoT, finally determining the reliable answer. The experimental results on the PathMMU dataset demonstrate the effectiveness of our method on pathology visual understanding and reasoning.",
    "summary": "arXiv:2507.01029v1 Announce Type: cross Abstract: With the development of generative artificial intelligence and instruction tuning techniques, multimodal large language models (MLLMs) have made impressive progress on general reasoning tasks. Benefiting from the chain-of-thought (CoT) methodology, MLLMs can solve the visual reasoning problem step-by-step. However, existing MLLMs still face significant challenges when applied to pathology visual reasoning tasks: (1) LLMs often underperforms because they lack domain-specific information, which can lead to model hallucinations. (2) The additional reasoning steps in CoT may introduce errors, leading to the divergence of answers. To address these limitations, we propose PathCoT, a novel zero-shot CoT prompting method which integrates the pathology expert-knowledge into the reasoning process of MLLMs and incorporates self-evaluation to mitigate divergence of answers. Specifically, PathCoT guides the MLLM with prior knowledge to perform as pathology experts, and provides comprehensive analysis of the image with their domain-specific knowledge. By incorporating the experts' knowledge, PathCoT can obtain the answers with CoT reasoning. Furthermore, PathCoT incorporates a self-evaluation step that assesses both the results generated directly by MLLMs and those derived through CoT, finally determining the reliable answer. The experimental results on the PathMMU dataset demonstrate the effectiveness of our method on pathology visual understanding and reasoning.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01029",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "New generative media models and tools, built with and for creators",
    "description": "We‚Äôre introducing Veo, our most capable model for generating high-definition video, and Imagen 3, our highest quality text-to-image model. We‚Äôre also sharing new demo recordings created with our Music AI Sandbox.",
    "summary": "We‚Äôre introducing Veo, our most capable model for generating high-definition video, and Imagen 3, our highest quality text-to-image model. We‚Äôre also sharing new demo recordings created with our Music AI Sandbox.",
    "pubDate": "Tue, 14 May 2024 17:57:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/new-generative-media-models-and-tools-built-with-and-for-creators/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO24_Gen_Media_Header_1.width-1300.png"
  },
  {
    "title": "Better language models and their implications",
    "description": "We‚Äôve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization‚Äîall without task-specific¬†training.",
    "summary": "We‚Äôve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization‚Äîall without task-specific¬†training.",
    "pubDate": "Thu, 14 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/better-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Operator",
    "description": "A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in the U.S.",
    "summary": "A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in the U.S.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-operator",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster Text Generation with TensorFlow and XLA",
    "description": "",
    "summary": "Faster Text Generation with TensorFlow and XLA TL;DR: Text Generation on ü§ó transformers using Tensor...",
    "pubDate": "Wed, 27 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-xla-generate",
    "thumbnail": "https://huggingface.co/blog/assets/91_tf_xla_generate/thumbnail.png"
  },
  {
    "title": "Open-sourcing Knowledge Distillation Code and Weights of SD-Small and SD-Tiny",
    "description": "",
    "summary": "Open-sourcing Knowledge Distillation Code and Weights of SD-Small and SD-Tiny In recent times, the A...",
    "pubDate": "Tue, 01 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd_distillation",
    "thumbnail": "https://huggingface.co/blog/assets/distill_sd/thumbnail.png"
  },
  {
    "title": "Open-source DeepResearch ‚Äì Freeing our search agents",
    "description": "",
    "summary": "Open-source DeepResearch ‚Äì Freeing our search agents TLDR Yesterday, OpenAI released Deep Research, ...",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-deep-research",
    "thumbnail": "https://huggingface.co/blog/assets/open-deep-research/thumbnail.png"
  },
  {
    "title": "Introducing SWE-bench Verified",
    "description": "We‚Äôre releasing a human-validated subset of SWE-bench that more reliably evaluates AI models‚Äô ability to solve real-world software issues.",
    "summary": "We‚Äôre releasing a human-validated subset of SWE-bench that more reliably evaluates AI models‚Äô ability to solve real-world software issues.",
    "pubDate": "Tue, 13 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-swe-bench-verified",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Washington Post partners with OpenAI on search content",
    "description": "The Washington Post is partnering with with OpenAI to integrate news into ChatGPT, providing users with summaries, quotes, and direct links to original reporting.",
    "summary": "The Washington Post is partnering with with OpenAI to integrate news into ChatGPT, providing users with summaries, quotes, and direct links to original reporting.",
    "pubDate": "Tue, 22 Apr 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/the-washington-post-partners-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From OpenAI to Open LLMs with Messages API",
    "description": "",
    "summary": "From OpenAI to Open LLMs with Messages API on Hugging Face We are excited to introduce the Messages ...",
    "pubDate": "Thu, 08 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-messages-api",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-messages-api/thumbnail.jpg"
  },
  {
    "title": "Learning with opponent-learning awareness",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-with-opponent-learning-awareness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing ChatGPT and Whisper APIs",
    "description": "Developers can now integrate ChatGPT and Whisper models into their apps and products through our API.",
    "summary": "Developers can now integrate ChatGPT and Whisper models into their apps and products through our API.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-and-whisper-apis",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemini 2.5: Our most intelligent AI model",
    "description": "Gemini 2.5 is our most intelligent AI model, now with thinking built in.",
    "summary": "Gemini 2.5 is our most intelligent AI model, now with thinking built in.",
    "pubDate": "Tue, 25 Mar 2025 17:00:36 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-2-5-our-most-intelligent-ai-model/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_keyword_social_share_text.width-1300.png"
  },
  {
    "title": "Êù±‰∫¨ÈÉΩ„ÄÅÈÉΩÁ´ãÈ´òÊ†°„Å´DeepLÂ∞éÂÖ•„ÄÄË®à1‰∏á‰∫∫„ÅÆÁîüÂæí„Å®ÊïôÂì°„ÅåÂà©Áî®‰∏≠„ÄÄ„ÄåËã±Ë™ûÂ≠¶Áøí„ÇÑÊ•≠ÂãôÊîØÊè¥„Å´Ê¥ªÁî®„Äç",
    "description": "ÈÉΩÁ´ãÈ´òÊ†°„Å´DeepL„ÅÆÁøªË®≥„ÉÑ„Éº„É´„ÇíÂ∞éÂÖ•‚îÄ‚îÄ„Ç™„É≥„É©„Ç§„É≥„ÉÜ„Ç≠„Çπ„ÉàÁøªË®≥„ÅßÁü•„Çâ„Çå„ÇãÁã¨DeepL„ÅØ„ÄÅÊù±‰∫¨ÈÉΩÊïôËÇ≤ÂßîÂì°‰ºö„ÅÆÂ∞éÂÖ•‰∫ã‰æã„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ",
    "summary": "ÈÉΩÁ´ãÈ´òÊ†°„Å´DeepL„ÅÆÁøªË®≥„ÉÑ„Éº„É´„ÇíÂ∞éÂÖ•‚îÄ‚îÄ„Ç™„É≥„É©„Ç§„É≥„ÉÜ„Ç≠„Çπ„ÉàÁøªË®≥„ÅßÁü•„Çâ„Çå„ÇãÁã¨DeepL„ÅØ„ÄÅÊù±‰∫¨ÈÉΩÊïôËÇ≤ÂßîÂì°‰ºö„ÅÆÂ∞éÂÖ•‰∫ã‰æã„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 11:05:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news065.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news065.jpg"
  },
  {
    "title": "Introducing HealthBench",
    "description": "HealthBench is a new evaluation benchmark for AI in healthcare which evaluates models in realistic scenarios. Built with input from 250+ physicians, it aims to provide a shared standard for model performance and safety in health.",
    "summary": "HealthBench is a new evaluation benchmark for AI in healthcare which evaluates models in realistic scenarios. Built with input from 250+ physicians, it aims to provide a shared standard for model performance and safety in health.",
    "pubDate": "Mon, 12 May 2025 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/healthbench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "NPHardEval Leaderboard: Unveiling the Reasoning Abilities of Large Language Models through Complexity Classes and Dynamic Updates",
    "description": "",
    "summary": "NPHardEval Leaderboard: Unveiling the Reasoning Abilities of Large Language Models through Complexit...",
    "pubDate": "Fri, 02 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-nphardeval",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_nphardeval.png"
  },
  {
    "title": "Sam Altman returns as CEO, OpenAI has a new initial board",
    "description": "Mira Murati as CTO, Greg Brockman returns as President. Read messages from CEO Sam Altman and board chair Bret Taylor.",
    "summary": "Mira Murati as CTO, Greg Brockman returns as President. Read messages from CEO Sam Altman and board chair Bret Taylor.",
    "pubDate": "Wed, 29 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Lowe‚Äôs leverages AI to power home improvement retail",
    "description": "A conversation with Chandhu Nair, Senior Vice President of Data, AI, and Innovation.",
    "summary": "A conversation with Chandhu Nair, Senior Vice President of Data, AI, and Innovation.",
    "pubDate": "Mon, 05 May 2025 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lowes-chandhu-nair",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Results of the Open Source AI Game Jam",
    "description": "",
    "summary": "Results of the Open Source AI Game Jam From July 7th to July 11th, we hosted our first Open Source A...",
    "pubDate": "Fri, 21 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/game-jam-first-edition-results",
    "thumbnail": "https://huggingface.co/blog/assets/game-jam-first-edition-results/thumbnail.jpg"
  },
  {
    "title": "Scaling robotics datasets with video encoding",
    "description": "",
    "summary": "Scaling robotics datasets with video encoding Over the past few years, text and image-based models h...",
    "pubDate": "Tue, 27 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/video-encoding",
    "thumbnail": "https://huggingface.co/blog/assets/video-encoding/thumbnail.png"
  },
  {
    "title": "Case Study: Millisecond Latency using Hugging Face Infinity and modern CPUs",
    "description": "",
    "summary": "Case Study: Millisecond Latency using Hugging Face Infinity and modern CPUs Inference Endpoints to e...",
    "pubDate": "Thu, 13 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/infinity-cpu-performance",
    "thumbnail": "https://huggingface.co/blog/assets/46_infinity_cpu_performance/thumbnail.png"
  },
  {
    "title": "CLIP: Connecting text and images",
    "description": "We‚Äôre introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the ‚Äúzero-shot‚Äù capabilities of GPT-2 and¬†GPT-3.",
    "summary": "We‚Äôre introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the ‚Äúzero-shot‚Äù capabilities of GPT-2 and¬†GPT-3.",
    "pubDate": "Tue, 05 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/clip",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building an autonomous financial analyst with o1 and o3-mini",
    "description": "Endex builds the future of financial analysis, powered by OpenAI‚Äôs reasoning models.",
    "summary": "Endex builds the future of financial analysis, powered by OpenAI‚Äôs reasoning models.",
    "pubDate": "Thu, 27 Feb 2025 09:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/endex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TacticAI: an AI assistant for football tactics",
    "description": "As part of our multi-year collaboration with Liverpool FC, we develop a full AI system that can advise coaches on corner kicks",
    "summary": "As part of our multi-year collaboration with Liverpool FC, we develop a full AI system that can advise coaches on corner kicks",
    "pubDate": "Tue, 19 Mar 2024 16:03:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/tacticai-ai-assistant-for-football-tactics/",
    "thumbnail": "https://lh3.googleusercontent.com/pPa45NPPYrOc4QHbcLIsmueJXi9hKNFdB0rbnRMdiRH0Gf3fgIc_g26-UbFxHVzqUT85QA-N3IvPpQaDevlp3OeF3RIiLQjmuONVRVyX1et0WYEKTQ=w1200-h630-n-nu"
  },
  {
    "title": "Enhancing news in ChatGPT with The Atlantic",
    "description": "The Atlantic is announcing a strategic content and product partnership with OpenAI, which positions The Atlantic as a premium news source within OpenAI. The Atlantic‚Äôs articles will be discoverable within OpenAI‚Äôs products, including ChatGPT, and as a partner, The Atlantic will help to shape how news is surfaced and presented in future real-time discovery products.",
    "summary": "The Atlantic is announcing a strategic content and product partnership with OpenAI, which positions The Atlantic as a premium news source within OpenAI. The Atlantic‚Äôs articles will be discoverable within OpenAI‚Äôs products, including ChatGPT, and as a partner, The Atlantic will help to shape how news is surfaced and presented in future real-time discovery products.",
    "pubDate": "Wed, 29 May 2024 07:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/enhancing-news-in-chatgpt-with-the-atlantic",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LLM-based Realistic Safety-Critical Driving Video Generation",
    "description": "arXiv:2507.01264v1 Announce Type: cross Abstract: Designing diverse and safety-critical driving scenarios is essential for evaluating autonomous driving systems. In this paper, we propose a novel framework that leverages Large Language Models (LLMs) for few-shot code generation to automatically synthesize driving scenarios within the CARLA simulator, which has flexibility in scenario scripting, efficient code-based control of traffic participants, and enforcement of realistic physical dynamics. Given a few example prompts and code samples, the LLM generates safety-critical scenario scripts that specify the behavior and placement of traffic participants, with a particular focus on collision events. To bridge the gap between simulation and real-world appearance, we integrate a video generation pipeline using Cosmos-Transfer1 with ControlNet, which converts rendered scenes into realistic driving videos. Our approach enables controllable scenario generation and facilitates the creation of rare but critical edge cases, such as pedestrian crossings under occlusion or sudden vehicle cut-ins. Experimental results demonstrate the effectiveness of our method in generating a wide range of realistic, diverse, and safety-critical scenarios, offering a promising tool for simulation-based testing of autonomous vehicles.",
    "summary": "arXiv:2507.01264v1 Announce Type: cross Abstract: Designing diverse and safety-critical driving scenarios is essential for evaluating autonomous driving systems. In this paper, we propose a novel framework that leverages Large Language Models (LLMs) for few-shot code generation to automatically synthesize driving scenarios within the CARLA simulator, which has flexibility in scenario scripting, efficient code-based control of traffic participants, and enforcement of realistic physical dynamics. Given a few example prompts and code samples, the LLM generates safety-critical scenario scripts that specify the behavior and placement of traffic participants, with a particular focus on collision events. To bridge the gap between simulation and real-world appearance, we integrate a video generation pipeline using Cosmos-Transfer1 with ControlNet, which converts rendered scenes into realistic driving videos. Our approach enables controllable scenario generation and facilitates the creation of rare but critical edge cases, such as pedestrian crossings under occlusion or sudden vehicle cut-ins. Experimental results demonstrate the effectiveness of our method in generating a wide range of realistic, diverse, and safety-critical scenarios, offering a promising tool for simulation-based testing of autonomous vehicles.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01264",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deploying ü§ó ViT on Vertex AI",
    "description": "",
    "summary": "Deploying ü§ó ViT on Vertex AI In the previous posts, we showed how to deploy a Vision Transformers (V...",
    "pubDate": "Fri, 19 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-vertex-ai",
    "thumbnail": "https://huggingface.co/blog/assets/97_vertex_ai/image1.png"
  },
  {
    "title": "AI Agent„ÅåÂõûÁ≠î„Å´Âõ∞„Å£„ÅüÊôÇ„Å´Slack„Åß‰∫∫Èñì„Å´Âä©Ë®Ä„ÇíÊ±Ç„ÇÅ„Çâ„Çå„ÇãMCP„ÇíÊ§úË®º„Åó„Åü",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØ„ÄÅAI Agent„ÅåËá™Ë∫´„ÅßËß£Ê±∫„Åß„Åç„Å™„ÅÑÂïèÈ°å„Å´Áõ¥Èù¢„Åó„ÅüÈöõ„Å´„ÄÅSlack„ÇíÈÄö„Åò„Å¶‰∫∫Èñì„Å´Âä©Ë®Ä„ÇíÊ±Ç„ÇÅ„Çã„Åì„Å®„Åå„Åß„Åç„ÇãMCPÔºàModel Context ProtocolÔºâ„ÄÅAskOnSlack [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5928' rel='nofollow'>AI Agent„ÅåÂõûÁ≠î„Å´Âõ∞„Å£„ÅüÊôÇ„Å´Slack„Åß‰∫∫Èñì„Å´Âä©Ë®Ä„ÇíÊ±Ç„ÇÅ„Çâ„Çå„ÇãMCP„ÇíÊ§úË®º„Åó„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØ„ÄÅAI Agent„ÅåËá™Ë∫´„ÅßËß£Ê±∫„Åß„Åç„Å™„ÅÑÂïèÈ°å„Å´Áõ¥Èù¢„Åó„ÅüÈöõ„Å´„ÄÅSlack„ÇíÈÄö„Åò„Å¶‰∫∫Èñì„Å´Âä©Ë®Ä„ÇíÊ±Ç„ÇÅ„Çã„Åì„Å®„Åå„Åß„Åç„ÇãMCPÔºàModel Context ProtocolÔºâ„ÄÅAskOnSlack [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5928' rel='nofollow'>AI Agent„ÅåÂõûÁ≠î„Å´Âõ∞„Å£„ÅüÊôÇ„Å´Slack„Åß‰∫∫Èñì„Å´Âä©Ë®Ä„ÇíÊ±Ç„ÇÅ„Çâ„Çå„ÇãMCP„ÇíÊ§úË®º„Åó„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Wed, 02 Jul 2025 06:52:11 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5928",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/07/f81fd2e4c52864042852c112ce927ae2.png"
  },
  {
    "title": "Neural Hamiltonian Operator",
    "description": "arXiv:2507.01313v1 Announce Type: cross Abstract: Stochastic control problems in high dimensions are notoriously difficult to solve due to the curse of dimensionality. An alternative to traditional dynamic programming is Pontryagin's Maximum Principle (PMP), which recasts the problem as a system of Forward-Backward Stochastic Differential Equations (FBSDEs). In this paper, we introduce a formal framework for solving such problems with deep learning by defining a textbf{Neural Hamiltonian Operator (NHO)}. This operator parameterizes the coupled FBSDE dynamics via neural networks that represent the feedback control and an ansatz for the value function's spatial gradient. We show how the optimal NHO can be found by training the underlying networks to enforce the consistency conditions dictated by the PMP. By adopting this operator-theoretic view, we situate the deep FBSDE method within the rigorous language of statistical inference, framing it as a problem of learning an unknown operator from simulated data. This perspective allows us to prove the universal approximation capabilities of NHOs under general martingale drivers and provides a clear lens for analyzing the significant optimization challenges inherent to this class of models.",
    "summary": "arXiv:2507.01313v1 Announce Type: cross Abstract: Stochastic control problems in high dimensions are notoriously difficult to solve due to the curse of dimensionality. An alternative to traditional dynamic programming is Pontryagin's Maximum Principle (PMP), which recasts the problem as a system of Forward-Backward Stochastic Differential Equations (FBSDEs). In this paper, we introduce a formal framework for solving such problems with deep learning by defining a textbf{Neural Hamiltonian Operator (NHO)}. This operator parameterizes the coupled FBSDE dynamics via neural networks that represent the feedback control and an ansatz for the value function's spatial gradient. We show how the optimal NHO can be found by training the underlying networks to enforce the consistency conditions dictated by the PMP. By adopting this operator-theoretic view, we situate the deep FBSDE method within the rigorous language of statistical inference, framing it as a problem of learning an unknown operator from simulated data. This perspective allows us to prove the universal approximation capabilities of NHOs under general martingale drivers and provides a clear lens for analyzing the significant optimization challenges inherent to this class of models.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01313",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„ÉÅ„É£„ÉÉ„ÉàAI„Å´‚ÄúÊÑüÊÉÖ„ÇíÂÖ±Êúâ‚Äù„Åß„Åç„Çã‰∫∫„ÅØ64.9ÔºÖ„ÄÅ„ÄåË¶™Âèã„Äç„ÄåÊØç„Äç„Çí‰∏äÂõû„Çã„ÄÄÈõªÈÄöË™øÊüª",
    "description": "„ÉÅ„É£„ÉÉ„ÉàAI„Å´ÊÑüÊÉÖ„ÇíÂÖ±Êúâ„Åß„Åç„Çã‰∫∫„ÅØ64.9ÔºÖ„Åß„ÄÅË¶™Âèã„ÇÑÊØçË¶™„Çí‰∏äÂõû„Çã‚Äï‚ÄïÈõªÈÄö„ÅØ„Åì„Çì„Å™Ë™øÊüªÁµêÊûú„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ„ÉÅ„É£„ÉÉ„ÉàAI„ÇíÈÄ±1Âõû‰ª•‰∏äÂà©Áî®„Åô„Çã12ÔΩû69Ê≠≥„ÅÆ1000‰∫∫„Å´Web„Åß„Ç¢„É≥„Ç±„Éº„Éà„ÇíÂÆüÊñΩ„ÄÇ„ÉÅ„É£„ÉÉ„ÉàAI„Å®„ÅÆÊé•„ÅóÊñπ„ÇÑ„ÄÅ‰∏ñ‰ª£„Åî„Å®„ÅÆÊ¥ªÁî®„ÅÆÂÇæÂêë„Å™„Å©„ÅåÂà§Êòé„Åó„Åü„Å®„ÅÑ„ÅÜ„ÄÇ",
    "summary": "„ÉÅ„É£„ÉÉ„ÉàAI„Å´ÊÑüÊÉÖ„ÇíÂÖ±Êúâ„Åß„Åç„Çã‰∫∫„ÅØ64.9ÔºÖ„Åß„ÄÅË¶™Âèã„ÇÑÊØçË¶™„Çí‰∏äÂõû„Çã‚Äï‚ÄïÈõªÈÄö„ÅØ„Åì„Çì„Å™Ë™øÊüªÁµêÊûú„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ„ÉÅ„É£„ÉÉ„ÉàAI„ÇíÈÄ±1Âõû‰ª•‰∏äÂà©Áî®„Åô„Çã12ÔΩû69Ê≠≥„ÅÆ1000‰∫∫„Å´Web„Åß„Ç¢„É≥„Ç±„Éº„Éà„ÇíÂÆüÊñΩ„ÄÇ„ÉÅ„É£„ÉÉ„ÉàAI„Å®„ÅÆÊé•„ÅóÊñπ„ÇÑ„ÄÅ‰∏ñ‰ª£„Åî„Å®„ÅÆÊ¥ªÁî®„ÅÆÂÇæÂêë„Å™„Å©„ÅåÂà§Êòé„Åó„Åü„Å®„ÅÑ„ÅÜ„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 14:08:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news080.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news080.jpg"
  },
  {
    "title": "Snorkel AI x Hugging Face: unlock foundation models for enterprises",
    "description": "",
    "summary": "Snorkel AI x Hugging Face: unlock foundation models for enterprises This article is a cross-post fro...",
    "pubDate": "Thu, 06 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/snorkel-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/snorkel.png"
  },
  {
    "title": "Roboschool",
    "description": "We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym.",
    "summary": "We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym.",
    "pubDate": "Mon, 15 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/roboschool",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Advancing Gemini's security safeguards",
    "description": "We‚Äôve made Gemini 2.5 our most secure model family to date.",
    "summary": "We‚Äôve made Gemini 2.5 our most secure model family to date.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
    "thumbnail": "https://lh3.googleusercontent.com/Uh_O6Nx1GWznAfODatYYz2sxiDekdb6HWnnSsy-cfmTxfjdUEEleh9w4cBdwUfBnyQBS-t1xW4UZXrMmC-rI6bz31hCrm5nHLt6Cp1FJAT7X9Upv5g=w1200-h630-n-nu"
  },
  {
    "title": "Geometry-aware 4D Video Generation for Robot Manipulation",
    "description": "arXiv:2507.01099v1 Announce Type: cross Abstract: Understanding and predicting the dynamics of the physical world can enhance a robot's ability to plan and interact effectively in complex environments. While recent video generation models have shown strong potential in modeling dynamic scenes, generating videos that are both temporally coherent and geometrically consistent across camera views remains a significant challenge. To address this, we propose a 4D video generation model that enforces multi-view 3D consistency of videos by supervising the model with cross-view pointmap alignment during training. This geometric supervision enables the model to learn a shared 3D representation of the scene, allowing it to predict future video sequences from novel viewpoints based solely on the given RGB-D observations, without requiring camera poses as inputs. Compared to existing baselines, our method produces more visually stable and spatially aligned predictions across multiple simulated and real-world robotic datasets. We further show that the predicted 4D videos can be used to recover robot end-effector trajectories using an off-the-shelf 6DoF pose tracker, supporting robust robot manipulation and generalization to novel camera viewpoints.",
    "summary": "arXiv:2507.01099v1 Announce Type: cross Abstract: Understanding and predicting the dynamics of the physical world can enhance a robot's ability to plan and interact effectively in complex environments. While recent video generation models have shown strong potential in modeling dynamic scenes, generating videos that are both temporally coherent and geometrically consistent across camera views remains a significant challenge. To address this, we propose a 4D video generation model that enforces multi-view 3D consistency of videos by supervising the model with cross-view pointmap alignment during training. This geometric supervision enables the model to learn a shared 3D representation of the scene, allowing it to predict future video sequences from novel viewpoints based solely on the given RGB-D observations, without requiring camera poses as inputs. Compared to existing baselines, our method produces more visually stable and spatially aligned predictions across multiple simulated and real-world robotic datasets. We further show that the predicted 4D videos can be used to recover robot end-effector trajectories using an off-the-shelf 6DoF pose tracker, supporting robust robot manipulation and generalization to novel camera viewpoints.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01099",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Spring Update",
    "description": "Introducing GPT-4o and making more capabilities available for free in ChatGPT.",
    "summary": "Introducing GPT-4o and making more capabilities available for free in ChatGPT.",
    "pubDate": "Mon, 13 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spring-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Partnering with Axios expands OpenAI‚Äôs work with the news industry",
    "description": "Publishers representing hundreds of newsrooms and content brands are using OpenAI partnerships and grant programs to adopt AI tools and strengthen the news ecosystem, while ChatGPT users gain access to information from leading, reliable publications.",
    "summary": "Publishers representing hundreds of newsrooms and content brands are using OpenAI partnerships and grant programs to adopt AI tools and strengthen the news ecosystem, while ChatGPT users gain access to information from leading, reliable publications.",
    "pubDate": "Wed, 15 Jan 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/partnering-with-axios-expands-openai-work-with-the-news-industry",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning",
    "description": "arXiv:2507.01006v2 Announce Type: replace-cross Abstract: We present GLM-4.1V-Thinking, a vision-language model (VLM) designed to advance general-purpose multimodal understanding and reasoning. In this report, we share our key findings in the development of the reasoning-centric training framework. We first develop a capable vision foundation model with significant potential through large-scale pre-training, which arguably sets the upper bound for the final performance. We then propose Reinforcement Learning with Curriculum Sampling (RLCS) to unlock the full potential of the model, leading to comprehensive capability enhancement across a diverse range of tasks, including STEM problem solving, video understanding, content recognition, coding, grounding, GUI-based agents, and long document understanding. We open-source GLM-4.1V-9B-Thinking, which achieves state-of-the-art performance among models of comparable size. In a comprehensive evaluation across 28 public benchmarks, our model outperforms Qwen2.5-VL-7B on nearly all tasks and achieves comparable or even superior performance on 18 benchmarks relative to the significantly larger Qwen2.5-VL-72B. Notably, GLM-4.1V-9B-Thinking also demonstrates competitive or superior performance compared to closed-source models such as GPT-4o on challenging tasks including long document understanding and STEM reasoning, further underscoring its strong capabilities. Code, models and more information are released at https://github.com/THUDM/GLM-4.1V-Thinking.",
    "summary": "arXiv:2507.01006v2 Announce Type: replace-cross Abstract: We present GLM-4.1V-Thinking, a vision-language model (VLM) designed to advance general-purpose multimodal understanding and reasoning. In this report, we share our key findings in the development of the reasoning-centric training framework. We first develop a capable vision foundation model with significant potential through large-scale pre-training, which arguably sets the upper bound for the final performance. We then propose Reinforcement Learning with Curriculum Sampling (RLCS) to unlock the full potential of the model, leading to comprehensive capability enhancement across a diverse range of tasks, including STEM problem solving, video understanding, content recognition, coding, grounding, GUI-based agents, and long document understanding. We open-source GLM-4.1V-9B-Thinking, which achieves state-of-the-art performance among models of comparable size. In a comprehensive evaluation across 28 public benchmarks, our model outperforms Qwen2.5-VL-7B on nearly all tasks and achieves comparable or even superior performance on 18 benchmarks relative to the significantly larger Qwen2.5-VL-72B. Notably, GLM-4.1V-9B-Thinking also demonstrates competitive or superior performance compared to closed-source models such as GPT-4o on challenging tasks including long document understanding and STEM reasoning, further underscoring its strong capabilities. Code, models and more information are released at https://github.com/THUDM/GLM-4.1V-Thinking.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01006",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemini Robotics On-Device brings AI to local robotic devices",
    "description": "We‚Äôre introducing an efficient, on-device robotics model with general-purpose dexterity and fast task adaptation.",
    "summary": "We‚Äôre introducing an efficient, on-device robotics model with general-purpose dexterity and fast task adaptation.",
    "pubDate": "Tue, 24 Jun 2025 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-robotics-on-device-brings-ai-to-local-robotic-devices/",
    "thumbnail": "https://lh3.googleusercontent.com/Jt_Vw7PIJEZtXcMIKM1HbWbBCLxv7RUyjyf07eHp-YOfxMCUZA6mPI9kSCaz65UkMoGcZ8CwlD3dNBvy7bnnYchjSkWyN-SugglT3dmg1A9KdoDqdQM=w1200-h630-n-nu"
  },
  {
    "title": "Efficient training of language models to fill in the middle",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 28 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/efficient-training-of-language-models-to-fill-in-the-middle",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Catching halibut with ChatGPT",
    "description": "Using ChatGPT to catch halibut",
    "summary": "Using ChatGPT to catch halibut",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fishing-for-first-timers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New model predicts a chemical reaction‚Äôs point of no return",
    "description": "Chemists could use this quick computational method to design more efficient reactions that yield useful compounds, from fuels to pharmaceuticals.",
    "summary": "Chemists could use this quick computational method to design more efficient reactions that yield useful compounds, from fuels to pharmaceuticals.",
    "pubDate": "Wed, 23 Apr 2025 11:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-model-predicts-chemical-reactions-no-return-point-0423",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/BetterPredict-01-press.jpg"
  },
  {
    "title": "Large Language Models: A New Moore's Law?",
    "description": "",
    "summary": "Large Language Models: A New Moore's Law? A few days ago, Microsoft and NVIDIA introduced Megatron-T...",
    "pubDate": "Tue, 26 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/large-language-models",
    "thumbnail": "https://huggingface.co/blog/assets/33_large_language_models/01_model_size.jpg"
  },
  {
    "title": "Ethics and Society Newsletter #4: Bias in Text-to-Image Models",
    "description": "",
    "summary": "Ethics and Society Newsletter #4: Bias in Text-to-Image Models TL;DR: We need better ways of evaluat...",
    "pubDate": "Mon, 26 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-4",
    "thumbnail": "https://huggingface.co/blog/assets/152_ethics_soc_4/ethics_4_thumbnail.png"
  },
  {
    "title": "New ways to manage your data in ChatGPT",
    "description": "ChatGPT users can now turn off chat history, allowing you to choose which conversations can be used to train our models.",
    "summary": "ChatGPT users can now turn off chat history, allowing you to choose which conversations can be used to train our models.",
    "pubDate": "Tue, 25 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Guiding Text Generation with Constrained Beam Search in ü§ó Transformers",
    "description": "",
    "summary": "Guiding Text Generation with Constrained Beam Search in ü§ó Transformers Introduction This blog post a...",
    "pubDate": "Fri, 11 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/constrained-beam-search",
    "thumbnail": "https://huggingface.co/blog/assets/53_constrained_beam_search/thumbnail.png"
  },
  {
    "title": "Fine-Tune W2V2-Bert for low-resource ASR with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune W2V2-Bert for low-resource ASR with ü§ó Transformers New (01/2024): This blog post is strong...",
    "pubDate": "Fri, 19 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-w2v2-bert",
    "thumbnail": "https://huggingface.co/blog/assets/fine-tune-w2v2-bert/w2v_thumbnail.png"
  },
  {
    "title": "Novel AI model inspired by neural dynamics from the brain",
    "description": "New type of ‚Äústate-space model‚Äù leverages principles of harmonic oscillators.",
    "summary": "New type of ‚Äústate-space model‚Äù leverages principles of harmonic oscillators.",
    "pubDate": "Fri, 02 May 2025 15:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/novel-ai-model-inspired-neural-dynamics-from-brain-0502",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-LinOSS.jpg"
  },
  {
    "title": "Disrupting malicious uses of AI by state-affiliated threat actors",
    "description": "We terminated accounts associated with state-affiliated threat actors. Our findings show our models offer only limited, incremental capabilities for malicious cybersecurity tasks.",
    "summary": "We terminated accounts associated with state-affiliated threat actors. Our findings show our models offer only limited, incremental capabilities for malicious cybersecurity tasks.",
    "pubDate": "Wed, 14 Feb 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-malicious-uses-of-ai-by-state-affiliated-threat-actors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Universal Image Segmentation with Mask2Former and OneFormer",
    "description": "",
    "summary": "Universal Image Segmentation with Mask2Former and OneFormer This guide introduces Mask2Former and On...",
    "pubDate": "Thu, 19 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mask2former",
    "thumbnail": "https://huggingface.co/blog/assets/127_mask2former/thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT search",
    "description": "Get fast, timely answers with links to relevant web sources",
    "summary": "Get fast, timely answers with links to relevant web sources",
    "pubDate": "Thu, 31 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-search",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SafeCoder vs. Closed-source Code Assistants",
    "description": "",
    "summary": "SafeCoder vs. Closed-source Code Assistants For decades, software developers have designed methodolo...",
    "pubDate": "Mon, 11 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safecoder-vs-closed-source-code-assistants",
    "thumbnail": "https://huggingface.co/blog/assets/safecoder-vs-closed-source-code-assistants/image.png"
  },
  {
    "title": "SmolVLM2: Bringing Video Understanding to Every Device",
    "description": "",
    "summary": "SmolVLM2: Bringing Video Understanding to Every Device TL;DR: SmolVLM can now watch üì∫ with even bett...",
    "pubDate": "Thu, 20 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvlm2",
    "thumbnail": "https://huggingface.co/blog/assets/smolvlm2/banner.png"
  },
  {
    "title": "BioMARS: A Multi-Agent Robotic System for Autonomous Biological Experiments",
    "description": "arXiv:2507.01485v1 Announce Type: cross Abstract: Large language models (LLMs) and vision-language models (VLMs) have the potential to transform biological research by enabling autonomous experimentation. Yet, their application remains constrained by rigid protocol design, limited adaptability to dynamic lab conditions, inadequate error handling, and high operational complexity. Here we introduce BioMARS (Biological Multi-Agent Robotic System), an intelligent platform that integrates LLMs, VLMs, and modular robotics to autonomously design, plan, and execute biological experiments. BioMARS uses a hierarchical architecture: the Biologist Agent synthesizes protocols via retrieval-augmented generation; the Technician Agent translates them into executable robotic pseudo-code; and the Inspector Agent ensures procedural integrity through multimodal perception and anomaly detection. The system autonomously conducts cell passaging and culture tasks, matching or exceeding manual performance in viability, consistency, and morphological integrity. It also supports context-aware optimization, outperforming conventional strategies in differentiating retinal pigment epithelial cells. A web interface enables real-time human-AI collaboration, while a modular backend allows scalable integration with laboratory hardware. These results highlight the feasibility of generalizable, AI-driven laboratory automation and the transformative role of language-based reasoning in biological research.",
    "summary": "arXiv:2507.01485v1 Announce Type: cross Abstract: Large language models (LLMs) and vision-language models (VLMs) have the potential to transform biological research by enabling autonomous experimentation. Yet, their application remains constrained by rigid protocol design, limited adaptability to dynamic lab conditions, inadequate error handling, and high operational complexity. Here we introduce BioMARS (Biological Multi-Agent Robotic System), an intelligent platform that integrates LLMs, VLMs, and modular robotics to autonomously design, plan, and execute biological experiments. BioMARS uses a hierarchical architecture: the Biologist Agent synthesizes protocols via retrieval-augmented generation; the Technician Agent translates them into executable robotic pseudo-code; and the Inspector Agent ensures procedural integrity through multimodal perception and anomaly detection. The system autonomously conducts cell passaging and culture tasks, matching or exceeding manual performance in viability, consistency, and morphological integrity. It also supports context-aware optimization, outperforming conventional strategies in differentiating retinal pigment epithelial cells. A web interface enables real-time human-AI collaboration, while a modular backend allows scalable integration with laboratory hardware. These results highlight the feasibility of generalizable, AI-driven laboratory automation and the transformative role of language-based reasoning in biological research.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01485",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Deepdive into Aya Expanse: Advancing the Frontier of Multilinguality",
    "description": "",
    "summary": "A Deepdive into Aya Expanse: Advancing the Frontier of Multilinguality This is a guest blog post by ...",
    "pubDate": "Thu, 24 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aya-expanse",
    "thumbnail": "https://huggingface.co/blog/assets/aya-expanse/thumbnail.jpg"
  },
  {
    "title": "Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon",
    "description": "",
    "summary": "Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon Large language models (LLM...",
    "pubDate": "Tue, 16 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/generative-ai-models-on-intel-cpu",
    "thumbnail": "https://huggingface.co/blog/assets/143_q8chat/thumbnail.png"
  },
  {
    "title": "ScreenSuite - The most comprehensive evaluation suite for GUI Agents!",
    "description": "",
    "summary": "ScreenSuite - The most comprehensive evaluation suite for GUI Agents! Releasing ScreenSuite, the mos...",
    "pubDate": "Fri, 06 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/screensuite",
    "thumbnail": "https://huggingface.co/blog/assets/screensuite/thumbnail.png"
  },
  {
    "title": "„É™„Ç≥„Éº„ÄÅGENIAC„Åß„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„ÄÇ7Êúà„Å´ÁÑ°ÂÑüÂÖ¨Èñã",
    "description": "<p>„É™„Ç≥„Éº„ÅØ„ÄÅÁµåÊ∏àÁî£Ê•≠ÁúÅ„Åä„Çà„Å≥NEDO„ÅåÊé®ÈÄ≤„Åô„ÇãGENIAC„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Å´„Åä„ÅÑ„Å¶„ÄÅÊó•Êú¨‰ºÅÊ•≠Âêë„ÅëÂõ≥Ë°®„ÇíÂê´„ÇÄ„Éâ„Ç≠„É•„É°„É≥„ÉàË™≠„ÅøÂèñ„Çä„Å´ÁâπÂåñ„Åó„Åü„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„Åó„Åæ„Åó„Åü„ÄÇ7Êúà29Êó•ÈñãÂÇ¨„ÅÆMIRU2025„ÅßË´ñÊñáÁô∫Ë°® [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/'>„É™„Ç≥„Éº„ÄÅGENIAC„Åß„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„ÄÇ7Êúà„Å´ÁÑ°ÂÑüÂÖ¨Èñã</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>„É™„Ç≥„Éº„ÅØ„ÄÅÁµåÊ∏àÁî£Ê•≠ÁúÅ„Åä„Çà„Å≥NEDO„ÅåÊé®ÈÄ≤„Åô„ÇãGENIAC„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Å´„Åä„ÅÑ„Å¶„ÄÅÊó•Êú¨‰ºÅÊ•≠Âêë„ÅëÂõ≥Ë°®„ÇíÂê´„ÇÄ„Éâ„Ç≠„É•„É°„É≥„ÉàË™≠„ÅøÂèñ„Çä„Å´ÁâπÂåñ„Åó„Åü„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„Åó„Åæ„Åó„Åü„ÄÇ7Êúà29Êó•ÈñãÂÇ¨„ÅÆMIRU2025„ÅßË´ñÊñáÁô∫Ë°® [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/'>„É™„Ç≥„Éº„ÄÅGENIAC„Åß„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„ÄÇ7Êúà„Å´ÁÑ°ÂÑüÂÖ¨Èñã</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Tue, 24 Jun 2025 07:52:10 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/ricoh-genia-multimodal-llm.png"
  },
  {
    "title": "Machine Learning Experts - Sasha Luccioni Interview",
    "description": "",
    "summary": "Machine Learning Experts - Sasha Luccioni ü§ó Welcome to Machine Learning Experts - Sasha Luccioni üöÄ I...",
    "pubDate": "Tue, 17 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sasha-luccioni-interview",
    "thumbnail": "https://huggingface.co/blog/assets/69_sasha_luccioni_interview/thumbnail.png"
  },
  {
    "title": "Learning to Segment for Vehicle Routing Problems",
    "description": "arXiv:2507.01037v1 Announce Type: cross Abstract: Iterative search heuristics are widely recognized as state-of-the-art for solving Vehicle Routing Problems (VRPs). In this work, we identify and exploit a critical observation: within these solvers, a large portion of the solution remains stable, i.e., unchanged across search iterations, causing redundant computations, especially for large-scale VRPs with long subtours. To address this, we pioneer the formal study of the First-Segment-Then-Aggregate (FSTA) decomposition technique to accelerate iterative solvers. Specifically, FSTA preserves stable solution segments during the search, aggregates nodes within each segment into fixed hypernodes, and focuses the search only on unstable portions. Yet, a key challenge lies in identifying which segments should be aggregated by FSTA. To this end, we then introduce Learning-to-Segment (L2Seg), a novel neural framework to intelligently differentiate potentially stable and unstable portions for FSTA decomposition. We present three L2Seg variants: non-autoregressive (globally comprehensive but locally indiscriminate), autoregressive (locally refined but globally deficient), and their synergy, with bespoke training and inference strategies. Empirical results on CVRP and VRPTW suggest that L2Seg accelerates state-of-the-art iterative solvers by up to 7x. Additionally, we provide in-depth analysis showing NAR and AR synergy achieves best performance by combining their complementary strengths. Notably, L2Seg is a flexible framework that is compatible with traditional, learning-based, and hybrid solvers, while supporting a broad class of VRPs.",
    "summary": "arXiv:2507.01037v1 Announce Type: cross Abstract: Iterative search heuristics are widely recognized as state-of-the-art for solving Vehicle Routing Problems (VRPs). In this work, we identify and exploit a critical observation: within these solvers, a large portion of the solution remains stable, i.e., unchanged across search iterations, causing redundant computations, especially for large-scale VRPs with long subtours. To address this, we pioneer the formal study of the First-Segment-Then-Aggregate (FSTA) decomposition technique to accelerate iterative solvers. Specifically, FSTA preserves stable solution segments during the search, aggregates nodes within each segment into fixed hypernodes, and focuses the search only on unstable portions. Yet, a key challenge lies in identifying which segments should be aggregated by FSTA. To this end, we then introduce Learning-to-Segment (L2Seg), a novel neural framework to intelligently differentiate potentially stable and unstable portions for FSTA decomposition. We present three L2Seg variants: non-autoregressive (globally comprehensive but locally indiscriminate), autoregressive (locally refined but globally deficient), and their synergy, with bespoke training and inference strategies. Empirical results on CVRP and VRPTW suggest that L2Seg accelerates state-of-the-art iterative solvers by up to 7x. Additionally, we provide in-depth analysis showing NAR and AR synergy achieves best performance by combining their complementary strengths. Notably, L2Seg is a flexible framework that is compatible with traditional, learning-based, and hybrid solvers, while supporting a broad class of VRPs.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01037",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome, Gradio 5",
    "description": "",
    "summary": "Welcome, Gradio 5 We‚Äôve been hard at work over the past few months, and we are excited to now announ...",
    "pubDate": "Wed, 09 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-5",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-5/thumbnail.png"
  },
  {
    "title": "Hear a podcast discussion about Gemini‚Äôs coding capabilities.",
    "description": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-600x600.format-webp.webp' />The latest episode of the Google AI: Release Notes podcast focuses on how the Gemini team built one of the world‚Äôs leading AI coding models.Host Logan Kilpatrick chats w‚Ä¶",
    "summary": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-600x600.format-webp.webp' />The latest episode of the Google AI: Release Notes podcast focuses on how the Gemini team built one of the world‚Äôs leading AI coding models.Host Logan Kilpatrick chats w‚Ä¶",
    "pubDate": "Wed, 18 Jun 2025 10:28:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/gemini/gemini-coding-podcast/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-1440x810.png"
  },
  {
    "title": "Using GPT-4 to improve teaching and learning in Brazil",
    "description": "Improving teaching and learning in Brazil",
    "summary": "Improving teaching and learning in Brazil",
    "pubDate": "Tue, 17 Sep 2024 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/arco-education",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "2023, year of open LLMs",
    "description": "",
    "summary": "2023, year of open LLMs 2023 has seen a surge of public interest in Large Language Models (LLMs), an...",
    "pubDate": "Mon, 18 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/2023-in-llms",
    "thumbnail": "https://huggingface.co/blog/assets/cv_state/thumbnail.png"
  },
  {
    "title": "Creating an AI-powered Magic Studio",
    "description": "Canva is a visual communication platform, enjoyed by more than 175 million people monthly to make presentations, videos, documents, websites, social media graphics and more. A majority of the world‚Äôs knowledge workers lack design training, but Canva‚Äôs combination of an easy-to-use interface, vast libraries, and time-saving tools allows anyone to create visually compelling content.",
    "summary": "Canva is a visual communication platform, enjoyed by more than 175 million people monthly to make presentations, videos, documents, websites, social media graphics and more. A majority of the world‚Äôs knowledge workers lack design training, but Canva‚Äôs combination of an easy-to-use interface, vast libraries, and time-saving tools allows anyone to create visually compelling content.",
    "pubDate": "Thu, 16 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/canva",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Google for Nonprofits will expand to 100+ new countries and launch 10+ new no-cost AI features",
    "description": "Collage on a white background showing people in multiple different situations including two people in suits sitting on the back of an ambulance, and an adult and child using a laptop together",
    "summary": "Collage on a white background showing people in multiple different situations including two people in suits sitting on the back of an ambulance, and an adult and child using a laptop together",
    "pubDate": "Wed, 11 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/google-org/google-nonprofits-updates-june-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GoogleforNonProfit_SS.width-1300.png"
  },
  {
    "title": "OpenAI‚Äôs technology explained",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-technology-explained",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Featherless AI on Hugging Face Inference Providers üî•",
    "description": "",
    "summary": "Featherless AI on Hugging Face Inference Providers üî• We're thrilled to share that Featherless AI is ...",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-featherless",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-featherless.jpg"
  },
  {
    "title": "quanto: a pytorch quantization toolkit",
    "description": "",
    "summary": "Quanto: a PyTorch quantization backend for Optimum Quantization is a technique to reduce the computa...",
    "pubDate": "Mon, 18 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/quanto-introduction",
    "thumbnail": "https://huggingface.co/blog/assets/169_quanto_intro/thumbnail.png"
  },
  {
    "title": "Contrastive Learning and Adversarial Disentanglement for Privacy-Aware Task-Oriented Semantic Communication",
    "description": "arXiv:2410.22784v3 Announce Type: replace-cross Abstract: Task-oriented semantic communication systems have emerged as a promising approach to achieving efficient and intelligent data transmission in next-generation networks, where only information relevant to a specific task is communicated. This is particularly important in 6G-enabled Internet of Things (6G-IoT) scenarios, where bandwidth constraints, latency requirements, and data privacy are critical. However, existing methods struggle to fully disentangle task-relevant and task-irrelevant information, leading to privacy concerns and suboptimal performance. To address this, we propose an information-bottleneck inspired method, named CLAD (contrastive learning and adversarial disentanglement). CLAD utilizes contrastive learning to effectively capture task-relevant features while employing adversarial disentanglement to discard task-irrelevant information. Additionally, due to the absence of reliable and reproducible methods to quantify the minimality of encoded feature vectors, we introduce the Information Retention Index (IRI), a comparative metric used as a proxy for the mutual information between the encoded features and the input. The IRI reflects how minimal and informative the representation is, making it highly relevant for privacy-preserving and bandwidth-efficient 6G-IoT systems. Extensive experiments demonstrate that CLAD outperforms state-of-the-art baselines in terms of semantic extraction, task performance, privacy preservation, and IRI, making it a promising building block for responsible, efficient and trustworthy 6G-IoT services.",
    "summary": "arXiv:2410.22784v3 Announce Type: replace-cross Abstract: Task-oriented semantic communication systems have emerged as a promising approach to achieving efficient and intelligent data transmission in next-generation networks, where only information relevant to a specific task is communicated. This is particularly important in 6G-enabled Internet of Things (6G-IoT) scenarios, where bandwidth constraints, latency requirements, and data privacy are critical. However, existing methods struggle to fully disentangle task-relevant and task-irrelevant information, leading to privacy concerns and suboptimal performance. To address this, we propose an information-bottleneck inspired method, named CLAD (contrastive learning and adversarial disentanglement). CLAD utilizes contrastive learning to effectively capture task-relevant features while employing adversarial disentanglement to discard task-irrelevant information. Additionally, due to the absence of reliable and reproducible methods to quantify the minimality of encoded feature vectors, we introduce the Information Retention Index (IRI), a comparative metric used as a proxy for the mutual information between the encoded features and the input. The IRI reflects how minimal and informative the representation is, making it highly relevant for privacy-preserving and bandwidth-efficient 6G-IoT systems. Extensive experiments demonstrate that CLAD outperforms state-of-the-art baselines in terms of semantic extraction, task performance, privacy preservation, and IRI, making it a promising building block for responsible, efficient and trustworthy 6G-IoT services.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.22784",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Making education data accessible",
    "description": "Zelma uses GPT-4 to make education data accessible.",
    "summary": "Zelma uses GPT-4 to make education data accessible.",
    "pubDate": "Thu, 28 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zelma",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI and compute",
    "description": "We‚Äôre releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore‚Äôs Law had a 2-year doubling period)[^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it‚Äôs worth preparing for the implications of systems far outside today‚Äôs capabilities.",
    "summary": "We‚Äôre releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore‚Äôs Law had a 2-year doubling period)[^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it‚Äôs worth preparing for the implications of systems far outside today‚Äôs capabilities.",
    "pubDate": "Wed, 16 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-and-compute",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Storage Regions on the HF Hub",
    "description": "",
    "summary": "Introducing Storage Regions on the Hub As part of our Enterprise Hub plan, we recently released supp...",
    "pubDate": "Fri, 03 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/regions",
    "thumbnail": "https://huggingface.co/blog/assets/172_regions/thumbnail.png"
  },
  {
    "title": "Better exploration with parameter noise",
    "description": "We‚Äôve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts performance. This exploration method is simple to implement and very rarely decreases performance, so it‚Äôs worth trying on any problem.",
    "summary": "We‚Äôve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts performance. This exploration method is simple to implement and very rarely decreases performance, so it‚Äôs worth trying on any problem.",
    "pubDate": "Thu, 27 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/better-exploration-with-parameter-noise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome Gemma - Google's new open LLM",
    "description": "",
    "summary": "Welcome Gemma - Google‚Äôs new open LLM An update to the Gemma models was released two months after th...",
    "pubDate": "Wed, 21 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma",
    "thumbnail": "https://huggingface.co/blog/assets/gemma/thumbnail.jpg"
  },
  {
    "title": "Introducing ChatGPT Plus",
    "description": "We‚Äôre launching a pilot subscription plan for ChatGPT, a conversational AI that can chat with you, answer follow-up questions, and challenge incorrect¬†assumptions.",
    "summary": "We‚Äôre launching a pilot subscription plan for ChatGPT, a conversational AI that can chat with you, answer follow-up questions, and challenge incorrect¬†assumptions.",
    "pubDate": "Wed, 01 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Inference for PROs",
    "description": "",
    "summary": "Inference for PROs Today, we're introducing Inference for PRO users - a community offering that give...",
    "pubDate": "Fri, 22 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-pro",
    "thumbnail": "https://huggingface.co/blog/assets/inference_pro/thumbnail.png"
  },
  {
    "title": "Photonic processor could streamline 6G wireless signal processing",
    "description": "By performing deep learning at the speed of light, this chip could give edge devices new capabilities for real-time data analysis.",
    "summary": "By performing deep learning at the speed of light, this chip could give edge devices new capabilities for real-time data analysis.",
    "pubDate": "Wed, 11 Jun 2025 14:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/photonic-processor-could-streamline-6g-wireless-signal-processing-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Photonic-Process-01-press.jpg"
  },
  {
    "title": "Introducing OpenAI Dublin",
    "description": "We‚Äôre growing our presence in Europe with an office in Dublin, Ireland.",
    "summary": "We‚Äôre growing our presence in Europe with an office in Dublin, Ireland.",
    "pubDate": "Wed, 13 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-dublin",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Prover-Verifier Games improve legibility of language model outputs",
    "description": "desc",
    "summary": "desc",
    "pubDate": "Wed, 17 Jul 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/prover-verifier-games-improve-legibility",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Policy Gradient with PyTorch",
    "description": "",
    "summary": "Policy Gradient with PyTorch Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 5, of the‚ö†Ô∏è ...",
    "pubDate": "Thu, 30 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-pg",
    "thumbnail": "https://huggingface.co/blog/assets/85_policy_gradient/thumbnail.gif"
  },
  {
    "title": "Introducing the Open FinLLM Leaderboard",
    "description": "",
    "summary": "Introducing the Open FinLLM Leaderboard Finding the best LLM models for finance use cases The growin...",
    "pubDate": "Fri, 04 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-finbench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_finbench.png"
  },
  {
    "title": "The Open Medical-LLM Leaderboard: Benchmarking Large Language Models in Healthcare",
    "description": "",
    "summary": "The Open Medical-LLM Leaderboard: Benchmarking Large Language Models in Healthcare Over the years, L...",
    "pubDate": "Fri, 19 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-medicalllm",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_medicalllm.png"
  },
  {
    "title": "An Uncertainty-Aware Dynamic Decision Framework for Progressive Multi-Omics Integration in Classification Tasks",
    "description": "arXiv:2507.01032v1 Announce Type: cross Abstract: Background and Objective: High-throughput multi-omics technologies have proven invaluable for elucidating disease mechanisms and enabling early diagnosis. However, the high cost of multi-omics profiling imposes a significant economic burden, with over reliance on full omics data potentially leading to unnecessary resource consumption. To address these issues, we propose an uncertainty-aware, multi-view dynamic decision framework for omics data classification that aims to achieve high diagnostic accuracy while minimizing testing costs. Methodology: At the single-omics level, we refine the activation functions of neural networks to generate Dirichlet distribution parameters, utilizing subjective logic to quantify both the belief masses and uncertainty mass of classification results. Belief mass reflects the support of a specific omics modality for a disease class, while the uncertainty parameter captures limitations in data quality and model discriminability, providing a more trustworthy basis for decision-making. At the multi omics level, we employ a fusion strategy based on Dempster-Shafer theory to integrate heterogeneous modalities, leveraging their complementarity to boost diagnostic accuracy and robustness. A dynamic decision mechanism is then applied that omics data are incrementally introduced for each patient until either all data sources are utilized or the model confidence exceeds a predefined threshold, potentially before all data sources are utilized. Results and Conclusion: We evaluate our approach on four benchmark multi-omics datasets, ROSMAP, LGG, BRCA, and KIPAN. In three datasets, over 50% of cases achieved accurate classification using a single omics modality, effectively reducing redundant testing. Meanwhile, our method maintains diagnostic performance comparable to full-omics models and preserves essential biological insights.",
    "summary": "arXiv:2507.01032v1 Announce Type: cross Abstract: Background and Objective: High-throughput multi-omics technologies have proven invaluable for elucidating disease mechanisms and enabling early diagnosis. However, the high cost of multi-omics profiling imposes a significant economic burden, with over reliance on full omics data potentially leading to unnecessary resource consumption. To address these issues, we propose an uncertainty-aware, multi-view dynamic decision framework for omics data classification that aims to achieve high diagnostic accuracy while minimizing testing costs. Methodology: At the single-omics level, we refine the activation functions of neural networks to generate Dirichlet distribution parameters, utilizing subjective logic to quantify both the belief masses and uncertainty mass of classification results. Belief mass reflects the support of a specific omics modality for a disease class, while the uncertainty parameter captures limitations in data quality and model discriminability, providing a more trustworthy basis for decision-making. At the multi omics level, we employ a fusion strategy based on Dempster-Shafer theory to integrate heterogeneous modalities, leveraging their complementarity to boost diagnostic accuracy and robustness. A dynamic decision mechanism is then applied that omics data are incrementally introduced for each patient until either all data sources are utilized or the model confidence exceeds a predefined threshold, potentially before all data sources are utilized. Results and Conclusion: We evaluate our approach on four benchmark multi-omics datasets, ROSMAP, LGG, BRCA, and KIPAN. In three datasets, over 50% of cases achieved accurate classification using a single omics modality, effectively reducing redundant testing. Meanwhile, our method maintains diagnostic performance comparable to full-omics models and preserves essential biological insights.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01032",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using Machine Learning to Aid Survivors and Race through Time",
    "description": "",
    "summary": "Using Machine Learning to Aid Survivors and Race through Time On February 6, 2023, earthquakes measu...",
    "pubDate": "Fri, 03 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/using-ml-for-disasters",
    "thumbnail": "https://huggingface.co/blog/assets/using-ml-for-disasters/thumbnail.png"
  },
  {
    "title": "DALL¬∑E: Introducing outpainting",
    "description": "Extend creativity and tell a bigger story with DALL¬∑E images of any¬†size.",
    "summary": "Extend creativity and tell a bigger story with DALL¬∑E images of any¬†size.",
    "pubDate": "Wed, 31 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-introducing-outpainting",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Federated Learning using Hugging Face and Flower",
    "description": "",
    "summary": "Federated Learning using Hugging Face and Flower This tutorial will show how to leverage Hugging Fac...",
    "pubDate": "Mon, 27 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fl-with-flower",
    "thumbnail": "https://huggingface.co/blog/assets/fl-with-flower/thumbnail.png"
  },
  {
    "title": "Teacher‚Äìstudent curriculum learning",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 01 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teacher-student-curriculum-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Visualize proteins on Hugging Face Spaces",
    "description": "",
    "summary": "Visualize proteins on Hugging Face Spaces In this post we will look at how we can visualize proteins...",
    "pubDate": "Wed, 24 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spaces_3dmoljs",
    "thumbnail": "https://huggingface.co/blog/assets/98_spaces_3dmoljs/thumbnail.png"
  },
  {
    "title": "Director of Machine Learning Insights [Part 2: SaaS Edition]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 2: SaaS Edition] If you or your team are interested in b...",
    "pubDate": "Fri, 13 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-2",
    "thumbnail": "https://huggingface.co/blog/assets/67_ml_director_insights/thumbnail.png"
  },
  {
    "title": "HuggingFace, IISc partner to supercharge model building on India's diverse languages",
    "description": "",
    "summary": "HuggingFace, IISc partner to supercharge model building on India's diverse languages The Indian Inst...",
    "pubDate": "Thu, 27 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/iisc-huggingface-collab",
    "thumbnail": "https://huggingface.co/blog/assets/iisc-huggingface-collab/thumbnail.png"
  },
  {
    "title": "Language models can explain neurons in language models",
    "description": "We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to score those explanations. We release a dataset of these (imperfect) explanations and scores for every neuron in GPT-2.",
    "summary": "We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to score those explanations. We release a dataset of these (imperfect) explanations and scores for every neuron in GPT-2.",
    "pubDate": "Tue, 09 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-models-can-explain-neurons-in-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making AI models more trustworthy for high-stakes settings",
    "description": "A new method helps convey uncertainty more precisely, which could give researchers and medical clinicians better information to make decisions.",
    "summary": "A new method helps convey uncertainty more precisely, which could give researchers and medical clinicians better information to make decisions.",
    "pubDate": "Thu, 01 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/making-ai-models-more-trustworthy-high-stakes-settings-0501",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Conformal-Prediction-01.jpg"
  },
  {
    "title": "OpenAI Deutschland",
    "description": "OpenAI announces the opening of its first office in Germany, based in Munich.",
    "summary": "OpenAI announces the opening of its first office in Germany, based in Munich.",
    "pubDate": "Thu, 22 May 2025 23:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-deutschland",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "We now support VLMs in smolagents!",
    "description": "",
    "summary": "We just gave sight to smolagents You hypocrite, first take the log out of your own eye, and then you...",
    "pubDate": "Fri, 24 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents-can-see",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents-can-see/thumbnail.png"
  },
  {
    "title": "Evolution through large models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolution-through-large-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TruthfulQA: Measuring how models mimic human falsehoods",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/truthfulqa",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-tuning LLMs to 1.58bit: extreme quantization made easy",
    "description": "",
    "summary": "Fine-tuning LLMs to 1.58bit: extreme quantization made easy As Large Language Models (LLMs) grow in ...",
    "pubDate": "Wed, 18 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/1_58_llm_extreme_quantization",
    "thumbnail": "https://huggingface.co/blog/assets/1_58_llm_extreme_quantization/thumbnail.png"
  },
  {
    "title": "Transforming visual accessibility",
    "description": "Be My Eyes uses GPT-4 to transform visual accessibility.",
    "summary": "Be My Eyes uses GPT-4 to transform visual accessibility.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/be-my-eyes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Lowe‚Äôs puts project expertise into every hand",
    "description": "Lowe‚Äôs partnered with OpenAI to build Mylow and Mylow Companion, AI-powered tools that bring expert help to both customers and store associates‚Äîmaking complex home improvement projects easier to plan, navigate, and complete.",
    "summary": "Lowe‚Äôs partnered with OpenAI to build Mylow and Mylow Companion, AI-powered tools that bring expert help to both customers and store associates‚Äîmaking complex home improvement projects easier to plan, navigate, and complete.",
    "pubDate": "Wed, 07 May 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lowes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "StarCoder: A State-of-the-Art LLM for Code",
    "description": "",
    "summary": "StarCoder: A State-of-the-Art LLM for Code Introducing StarCoder StarCoder and StarCoderBase are Lar...",
    "pubDate": "Thu, 04 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starcoder",
    "thumbnail": "https://huggingface.co/blog/assets/141_starcoder/starcoder_thumbnail.png"
  },
  {
    "title": "The ethics of advanced AI assistants",
    "description": "Exploring the promise and risks of a future with more capable AI",
    "summary": "Exploring the promise and risks of a future with more capable AI",
    "pubDate": "Fri, 19 Apr 2024 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/the-ethics-of-advanced-ai-assistants/",
    "thumbnail": "https://lh3.googleusercontent.com/28MrwSZMny-Gf_FVYJS0z3JbnfLXzRLNAF2BA0YQ7rbcrZWdNNwddfFsWVh_n7C31N8oXBmWexFbyce4jzaX3FSNt3EXG6mSLSlXaSx70Mc7Q0s7FF4=w1200-h630-n-nu"
  },
  {
    "title": "1,000 Scientist AI Jam Session",
    "description": "OpenAI and nine national labs bring together leading scientists for first-of-its kind event.",
    "summary": "OpenAI and nine national labs bring together leading scientists for first-of-its kind event.",
    "pubDate": "Fri, 28 Feb 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/1000-scientist-ai-jam-session",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How ü§ó Accelerate runs very large models thanks to PyTorch",
    "description": "",
    "summary": "How ü§ó Accelerate runs very large models thanks to PyTorch Load and run large models Meta AI and BigS...",
    "pubDate": "Tue, 27 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-large-models",
    "thumbnail": "https://huggingface.co/blog/assets/104_accelerate-large-models/thumbnail.png"
  },
  {
    "title": "Accelerating Protein Language Model ProtST on Intel Gaudi 2",
    "description": "",
    "summary": "Accelerating Protein Language Model ProtST on Intel Gaudi 2 Introduction Protein Language Models (PL...",
    "pubDate": "Wed, 03 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-protein-language-model-protst",
    "thumbnail": "https://huggingface.co/blog/assets/intel-protein-language-model-protst/01.jpeg"
  },
  {
    "title": "Introducing the Open Chain of Thought Leaderboard",
    "description": "",
    "summary": "Introducing the Open Chain of Thought Leaderboard Chain-of-thought prompting is emerging as a powerf...",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-cot",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_cot.png"
  },
  {
    "title": "Enhance Your Models in 5 Minutes with the Hugging Face Kernel Hub",
    "description": "",
    "summary": "üèéÔ∏è Enhance Your Models in 5 Minutes with the Hugging Face Kernel Hub Boost your model performance wi...",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hello-hf-kernels",
    "thumbnail": "https://huggingface.co/blog/assets/hello-hf-kernels/kernel-hub-five-mins-short.png"
  },
  {
    "title": "OpenAI at the Paris AI Action Summit",
    "description": "OpenAI looks forward to engaging with global leaders on AI‚Äôs role in shaping innovation and economic prosperity.",
    "summary": "OpenAI looks forward to engaging with global leaders on AI‚Äôs role in shaping innovation and economic prosperity.",
    "pubDate": "Fri, 07 Feb 2025 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-at-the-paris-ai-action-summit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Thinking with images",
    "description": "OpenAI o3 and o4-mini represent a significant breakthrough in visual perception by reasoning with images in their chain of thought.",
    "summary": "OpenAI o3 and o4-mini represent a significant breakthrough in visual perception by reasoning with images in their chain of thought.",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/thinking-with-images",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "End-to-End Large Portfolio Optimization for Variance Minimization with Neural Networks through Covariance Cleaning",
    "description": "arXiv:2507.01918v1 Announce Type: cross Abstract: We develop a rotation-invariant neural network that provides the global minimum-variance portfolio by jointly learning how to lag-transform historical returns and how to regularise both the eigenvalues and the marginal volatilities of large equity covariance matrices. This explicit mathematical mapping offers clear interpretability of each module's role, so the model cannot be regarded as a pure black-box. The architecture mirrors the analytical form of the global minimum-variance solution yet remains agnostic to dimension, so a single model can be calibrated on panels of a few hundred stocks and applied, without retraining, to one thousand US equities-a cross-sectional jump that demonstrates robust out-of-sample generalisation. The loss function is the future realized minimum portfolio variance and is optimized end-to-end on real daily returns. In out-of-sample tests from January 2000 to December 2024 the estimator delivers systematically lower realised volatility, smaller maximum drawdowns, and higher Sharpe ratios than the best analytical competitors, including state-of-the-art non-linear shrinkage. Furthermore, although the model is trained end-to-end to produce an unconstrained (long-short) minimum-variance portfolio, we show that its learned covariance representation can be used in general optimizers under long-only constraints with virtually no loss in its performance advantage over competing estimators. These gains persist when the strategy is executed under a highly realistic implementation framework that models market orders at the auctions, empirical slippage, exchange fees, and financing charges for leverage, and they remain stable during episodes of acute market stress.",
    "summary": "arXiv:2507.01918v1 Announce Type: cross Abstract: We develop a rotation-invariant neural network that provides the global minimum-variance portfolio by jointly learning how to lag-transform historical returns and how to regularise both the eigenvalues and the marginal volatilities of large equity covariance matrices. This explicit mathematical mapping offers clear interpretability of each module's role, so the model cannot be regarded as a pure black-box. The architecture mirrors the analytical form of the global minimum-variance solution yet remains agnostic to dimension, so a single model can be calibrated on panels of a few hundred stocks and applied, without retraining, to one thousand US equities-a cross-sectional jump that demonstrates robust out-of-sample generalisation. The loss function is the future realized minimum portfolio variance and is optimized end-to-end on real daily returns. In out-of-sample tests from January 2000 to December 2024 the estimator delivers systematically lower realised volatility, smaller maximum drawdowns, and higher Sharpe ratios than the best analytical competitors, including state-of-the-art non-linear shrinkage. Furthermore, although the model is trained end-to-end to produce an unconstrained (long-short) minimum-variance portfolio, we show that its learned covariance representation can be used in general optimizers under long-only constraints with virtually no loss in its performance advantage over competing estimators. These gains persist when the strategy is executed under a highly realistic implementation framework that models market orders at the auctions, empirical slippage, exchange fees, and financing charges for leverage, and they remain stable during episodes of acute market stress.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01918",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Universal Semantics With Large Language Models",
    "description": "arXiv:2505.11764v2 Announce Type: replace-cross Abstract: The Natural Semantic Metalanguage (NSM) is a linguistic theory based on a universal set of semantic primes: simple, primitive word-meanings that have been shown to exist in most, if not all, languages of the world. According to this framework, any word, regardless of complexity, can be paraphrased using these primes, revealing a clear and universally translatable meaning. These paraphrases, known as explications, can offer valuable applications for many natural language processing (NLP) tasks, but producing them has traditionally been a slow, manual process. In this work, we present the first study of using large language models (LLMs) to generate NSM explications. We introduce automatic evaluation methods, a tailored dataset for training and evaluation, and fine-tuned models for this task. Our 1B and 8B models outperform GPT-4o in producing accurate, cross-translatable explications, marking a significant step toward universal semantic representation with LLMs and opening up new possibilities for applications in semantic analysis, translation, and beyond.",
    "summary": "arXiv:2505.11764v2 Announce Type: replace-cross Abstract: The Natural Semantic Metalanguage (NSM) is a linguistic theory based on a universal set of semantic primes: simple, primitive word-meanings that have been shown to exist in most, if not all, languages of the world. According to this framework, any word, regardless of complexity, can be paraphrased using these primes, revealing a clear and universally translatable meaning. These paraphrases, known as explications, can offer valuable applications for many natural language processing (NLP) tasks, but producing them has traditionally been a slow, manual process. In this work, we present the first study of using large language models (LLMs) to generate NSM explications. We introduce automatic evaluation methods, a tailored dataset for training and evaluation, and fine-tuned models for this task. Our 1B and 8B models outperform GPT-4o in producing accurate, cross-translatable explications, marking a significant step toward universal semantic representation with LLMs and opening up new possibilities for applications in semantic analysis, translation, and beyond.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.11764",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Unlocking Longer Generation with Key-Value Cache Quantization",
    "description": "",
    "summary": "Unlocking Longer Generation with Key-Value Cache Quantization At Hugging Face, we are excited to sha...",
    "pubDate": "Thu, 16 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kv-cache-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/kv_cache_quantization/thumbnail.png"
  },
  {
    "title": "Pensieve Grader: An AI-Powered, Ready-to-Use Platform for Effortless Handwritten STEM Grading",
    "description": "arXiv:2507.01431v1 Announce Type: new Abstract: Grading handwritten, open-ended responses remains a major bottleneck in large university STEM courses. We introduce Pensieve (https://www.pensieve.co), an AI-assisted grading platform that leverages large language models (LLMs) to transcribe and evaluate student work, providing instructors with rubric-aligned scores, transcriptions, and confidence ratings. Unlike prior tools that focus narrowly on specific tasks like transcription or rubric generation, Pensieve supports the entire grading pipeline-from scanned student submissions to final feedback-within a human-in-the-loop interface. Pensieve has been deployed in real-world courses at over 20 institutions and has graded more than 300,000 student responses. We present system details and empirical results across four core STEM disciplines: Computer Science, Mathematics, Physics, and Chemistry. Our findings show that Pensieve reduces grading time by an average of 65%, while maintaining a 95.4% agreement rate with instructor-assigned grades for high-confidence predictions.",
    "summary": "arXiv:2507.01431v1 Announce Type: new Abstract: Grading handwritten, open-ended responses remains a major bottleneck in large university STEM courses. We introduce Pensieve (https://www.pensieve.co), an AI-assisted grading platform that leverages large language models (LLMs) to transcribe and evaluate student work, providing instructors with rubric-aligned scores, transcriptions, and confidence ratings. Unlike prior tools that focus narrowly on specific tasks like transcription or rubric generation, Pensieve supports the entire grading pipeline-from scanned student submissions to final feedback-within a human-in-the-loop interface. Pensieve has been deployed in real-world courses at over 20 institutions and has graded more than 300,000 student responses. We present system details and empirical results across four core STEM disciplines: Computer Science, Mathematics, Physics, and Chemistry. Our findings show that Pensieve reduces grading time by an average of 65%, while maintaining a 95.4% agreement rate with instructor-assigned grades for high-confidence predictions.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01431",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Systemic Constraints of Undecidability",
    "description": "arXiv:2507.01036v1 Announce Type: cross Abstract: This paper presents a theory of systemic undecidability, reframing incomputability as a structural property of systems rather than a localized feature of specific functions or problems. We define a notion of causal embedding and prove a closure principle: any subsystem that participates functionally in the computation of an undecidable system inherits its undecidability. This result positions undecidability as a pervasive constraint on prediction, modeling, and epistemic access in both natural and artificial systems. Our framework disarms oracle mimicry and challenges the view that computational limits can be circumvented through architectural innovation. By generalizing classical results into a dynamic systems context, this work augments the logical trajectory of G'odel, Turing, and Chaitin, offering a new perspective of the topology of computability and its interrelation to the boundaries of scientific knowledge.",
    "summary": "arXiv:2507.01036v1 Announce Type: cross Abstract: This paper presents a theory of systemic undecidability, reframing incomputability as a structural property of systems rather than a localized feature of specific functions or problems. We define a notion of causal embedding and prove a closure principle: any subsystem that participates functionally in the computation of an undecidable system inherits its undecidability. This result positions undecidability as a pervasive constraint on prediction, modeling, and epistemic access in both natural and artificial systems. Our framework disarms oracle mimicry and challenges the view that computational limits can be circumvented through architectural innovation. By generalizing classical results into a dynamic systems context, this work augments the logical trajectory of G'odel, Turing, and Chaitin, offering a new perspective of the topology of computability and its interrelation to the boundaries of scientific knowledge.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01036",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome, Pieter and Shivon!",
    "description": "We have two more team¬†updates.",
    "summary": "We have two more team¬†updates.",
    "pubDate": "Tue, 26 Apr 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/welcome-pieter-and-shivon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ControlNet in Diffusers üß®",
    "description": "",
    "summary": "Ultra fast ControlNet with üß® Diffusers Ever since Stable Diffusion took the world by storm, people h...",
    "pubDate": "Fri, 03 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/controlnet",
    "thumbnail": "https://huggingface.co/blog/assets/controlnet/thumbnail.png"
  },
  {
    "title": "The Technology Behind BLOOM Training",
    "description": "",
    "summary": "The Technology Behind BLOOM Training In recent years, training ever larger language models has becom...",
    "pubDate": "Thu, 14 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-megatron-deepspeed",
    "thumbnail": "https://huggingface.co/blog/assets/86_bloom_megatron_deepspeed/thumbnail.png"
  },
  {
    "title": "OpenAI leadership team update",
    "description": "We‚Äôre happy to announce several executive role changes that reflect our recent progress and will ensure continued momentum toward our next major¬†milestones.",
    "summary": "We‚Äôre happy to announce several executive role changes that reflect our recent progress and will ensure continued momentum toward our next major¬†milestones.",
    "pubDate": "Thu, 05 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-team-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Epitome: Pioneering an Experimental Platform for AI-Social Science Integration",
    "description": "arXiv:2507.01061v1 Announce Type: cross Abstract: The integration of Large Language Models (LLMs) into social science experiments represents a transformative approach to understanding human-AI interactions and their societal impacts. We introduce Epitome, the world's first open experimental platform dedicated to the deep integration of artificial intelligence and social science. Rooted in theoretical foundations from management, communication studies, sociology, psychology, and ethics, Epitome focuses on the interactive impacts of AI on individuals, organizations, and society during its real-world deployment. It constructs a theoretical support system through cross-disciplinary experiments. The platform offers a one-stop comprehensive experimental solution spanning 'foundation models-complex application development-user feedback' through seven core modules, while embedding the classical 'control-comparison-comparative causal logic' of social science experiments into multilevel human-computer interaction environments, including dialogues, group chats, and multi-agent virtual scenarios. With its canvas-style, user-friendly interface, Epitome enables researchers to easily design and run complex experimental scenarios, facilitating systematic investigations into the social impacts of AI and exploration of integrated solutions.To demonstrate its capabilities, we replicated three seminal social science experiments involving LLMs, showcasing Epitome's potential to streamline complex experimental designs and produce robust results, suitable for publishing in the top selective journals. Our findings highlight the platform's utility in enhancing the efficiency and quality of human-AI interactions, providing valuable insights into the societal implications of AI technologies. Epitome thus offers a powerful tool for advancing interdisciplinary research at the intersection of AI and social science, with potential applications in policy-making, ...",
    "summary": "arXiv:2507.01061v1 Announce Type: cross Abstract: The integration of Large Language Models (LLMs) into social science experiments represents a transformative approach to understanding human-AI interactions and their societal impacts. We introduce Epitome, the world's first open experimental platform dedicated to the deep integration of artificial intelligence and social science. Rooted in theoretical foundations from management, communication studies, sociology, psychology, and ethics, Epitome focuses on the interactive impacts of AI on individuals, organizations, and society during its real-world deployment. It constructs a theoretical support system through cross-disciplinary experiments. The platform offers a one-stop comprehensive experimental solution spanning 'foundation models-complex application development-user feedback' through seven core modules, while embedding the classical 'control-comparison-comparative causal logic' of social science experiments into multilevel human-computer interaction environments, including dialogues, group chats, and multi-agent virtual scenarios. With its canvas-style, user-friendly interface, Epitome enables researchers to easily design and run complex experimental scenarios, facilitating systematic investigations into the social impacts of AI and exploration of integrated solutions.To demonstrate its capabilities, we replicated three seminal social science experiments involving LLMs, showcasing Epitome's potential to streamline complex experimental designs and produce robust results, suitable for publishing in the top selective journals. Our findings highlight the platform's utility in enhancing the efficiency and quality of human-AI interactions, providing valuable insights into the societal implications of AI technologies. Epitome thus offers a powerful tool for advancing interdisciplinary research at the intersection of AI and social science, with potential applications in policy-making, ...",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01061",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The 4 Things Qwen-3's Chat Template Teaches Us",
    "description": "",
    "summary": "The 4 Things Qwen-3‚Äôs Chat Template Teaches Us What a boring Jinja snippet tells us about the new Qw...",
    "pubDate": "Wed, 30 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/qwen-3-chat-template-deep-dive",
    "thumbnail": "https://huggingface.co/blog/assets/qwen-3-chat-template-deep-dive/thumbnail.png"
  },
  {
    "title": "Distribution Matching for Self-Supervised Transfer Learning",
    "description": "arXiv:2502.14424v2 Announce Type: replace-cross Abstract: In this paper, we propose a novel self-supervised transfer learning method called underline{textbf{D}}istribution underline{textbf{M}}atching (DM), which drives the representation distribution toward a predefined reference distribution while preserving augmentation invariance. DM results in a learned representation space that is intuitively structured and therefore easy to interpret. Experimental results across multiple real-world datasets and evaluation metrics demonstrate that DM performs competitively on target classification tasks compared to existing self-supervised transfer learning methods. Additionally, we provide robust theoretical guarantees for DM, including a population theorem and an end-to-end sample theorem. The population theorem bridges the gap between the self-supervised learning task and target classification accuracy, while the sample theorem shows that, even with a limited number of samples from the target domain, DM can deliver exceptional classification performance, provided the unlabeled sample size is sufficiently large.",
    "summary": "arXiv:2502.14424v2 Announce Type: replace-cross Abstract: In this paper, we propose a novel self-supervised transfer learning method called underline{textbf{D}}istribution underline{textbf{M}}atching (DM), which drives the representation distribution toward a predefined reference distribution while preserving augmentation invariance. DM results in a learned representation space that is intuitively structured and therefore easy to interpret. Experimental results across multiple real-world datasets and evaluation metrics demonstrate that DM performs competitively on target classification tasks compared to existing self-supervised transfer learning methods. Additionally, we provide robust theoretical guarantees for DM, including a population theorem and an end-to-end sample theorem. The population theorem bridges the gap between the self-supervised learning task and target classification accuracy, while the sample theorem shows that, even with a limited number of samples from the target domain, DM can deliver exceptional classification performance, provided the unlabeled sample size is sufficiently large.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.14424",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Our approach to AI safety",
    "description": "Ensuring that AI systems are built, deployed, and used safely is critical to our mission.",
    "summary": "Ensuring that AI systems are built, deployed, and used safely is critical to our mission.",
    "pubDate": "Wed, 05 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/our-approach-to-ai-safety",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI announces leadership transition",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-announces-leadership-transition",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Red-Teaming Large Language Models",
    "description": "",
    "summary": "Red-Teaming Large Language Models Warning: This article is about red-teaming and as such contains ex...",
    "pubDate": "Fri, 24 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/red-teaming",
    "thumbnail": "https://huggingface.co/blog/assets/red-teaming/thumbnail.png"
  },
  {
    "title": "Faster Text Generation with Self-Speculative Decoding",
    "description": "",
    "summary": "Faster Text Generation with Self-Speculative Decoding Self-speculative decoding, proposed in LayerSk...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/layerskip",
    "thumbnail": "https://huggingface.co/blog/assets/layerskip/thumbnail.png"
  },
  {
    "title": "Speak is personalizing language learning with AI",
    "description": "A conversation with Connor Zwick, CEO & Co-founder of Speak.",
    "summary": "A conversation with Connor Zwick, CEO & Co-founder of Speak.",
    "pubDate": "Tue, 22 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/speak-connor-zwick",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Object Detection Leaderboard",
    "description": "",
    "summary": "Object Detection Leaderboard: Decoding Metrics and Their Potential Pitfalls Welcome to our latest di...",
    "pubDate": "Mon, 18 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/object-detection-leaderboard",
    "thumbnail": "https://huggingface.co/blog/assets/object-detection-leaderboard/thumbnail.png"
  },
  {
    "title": "Video generation models as world simulators",
    "description": "We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.",
    "summary": "We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.",
    "pubDate": "Thu, 15 Feb 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/video-generation-models-as-world-simulators",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Get an audio overview of Search results in Labs, then click through to learn more.",
    "description": "A phone screen showing Google search results with a section titled 'Search Labs | Audio Overviews' and an audio player.",
    "summary": "A phone screen showing Google search results with a section titled 'Search Labs | Audio Overviews' and an audio player.",
    "pubDate": "Fri, 13 Jun 2025 15:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/audio-overviews-search-labs/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AudioOverview_SS.max-1440x810.png"
  },
  {
    "title": "OpenAI Five Finals",
    "description": "We‚Äôll be holding our final live event for OpenAI Five at 11:30am PT on April 13.",
    "summary": "We‚Äôll be holding our final live event for OpenAI Five at 11:30am PT on April 13.",
    "pubDate": "Tue, 26 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-finals",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How we leveraged distilabel to create an Argilla 2.0 Chatbot",
    "description": "",
    "summary": "How we leveraged distilabel to create an Argilla 2.0 Chatbot TL;DR Discover how to build a Chatbot f...",
    "pubDate": "Tue, 16 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/argilla-chatbot",
    "thumbnail": "https://huggingface.co/blog/assets/argilla-chatbot/thumbnail.png"
  },
  {
    "title": "Efficient Controllable Generation for SDXL with T2I-Adapters",
    "description": "",
    "summary": "Efficient Controllable Generation for SDXL with T2I-Adapters T2I-Adapter is an efficient plug-and-pl...",
    "pubDate": "Fri, 08 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/t2i-sdxl-adapters",
    "thumbnail": "https://huggingface.co/blog/assets/t2i-sdxl-adapters/thumbnail.png"
  },
  {
    "title": "Self-reflective Uncertainties: Do LLMs Know Their Internal Answer Distribution?",
    "description": "arXiv:2505.20295v2 Announce Type: replace-cross Abstract: To reveal when a large language model (LLM) is uncertain about a response, uncertainty quantification commonly produces percentage numbers along with the output. But is this all we can do? We argue that in the output space of LLMs, the space of strings, exist strings expressive enough to summarize the distribution over output strings the LLM deems possible. We lay a foundation for this new avenue of uncertainty explication and present SelfReflect, a theoretically-motivated metric to assess how faithfully a string summarizes an LLM's internal answer distribution. We show that SelfReflect is able to discriminate even subtle differences of candidate summary strings and that it aligns with human judgement, outperforming alternative metrics such as LLM judges and embedding comparisons. With SelfReflect, we investigate a number of self-summarization methods and find that even state-of-the-art reasoning models struggle to explicate their internal uncertainty. But we find that faithful summarizations can be generated by sampling and summarizing. To support the development of this universal form of LLM uncertainties, we publish our metric at https://github.com/apple/ml-selfreflect",
    "summary": "arXiv:2505.20295v2 Announce Type: replace-cross Abstract: To reveal when a large language model (LLM) is uncertain about a response, uncertainty quantification commonly produces percentage numbers along with the output. But is this all we can do? We argue that in the output space of LLMs, the space of strings, exist strings expressive enough to summarize the distribution over output strings the LLM deems possible. We lay a foundation for this new avenue of uncertainty explication and present SelfReflect, a theoretically-motivated metric to assess how faithfully a string summarizes an LLM's internal answer distribution. We show that SelfReflect is able to discriminate even subtle differences of candidate summary strings and that it aligns with human judgement, outperforming alternative metrics such as LLM judges and embedding comparisons. With SelfReflect, we investigate a number of self-summarization methods and find that even state-of-the-art reasoning models struggle to explicate their internal uncertainty. But we find that faithful summarizations can be generated by sampling and summarizing. To support the development of this universal form of LLM uncertainties, we publish our metric at https://github.com/apple/ml-selfreflect",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.20295",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Going multimodal: How Prezi is leveraging the Hub and the Expert Support Program to accelerate their ML roadmap",
    "description": "",
    "summary": "Going multimodal: How Prezi is leveraging the Hub and the Expert Support Program to accelerate their...",
    "pubDate": "Wed, 19 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/prezi-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/70_sempre_health/thumbnailprezi.jpg"
  },
  {
    "title": "We are hiring interns!",
    "description": "",
    "summary": "We are hiring interns! Want to help build the future at -- if we may say so ourselves -- one of the ...",
    "pubDate": "Tue, 29 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/interns-2023",
    "thumbnail": "https://huggingface.co/blog/assets/interns-2023/thumbnail.png"
  },
  {
    "title": "Using AI to fight climate change",
    "description": "AI is a powerful technology that will transform our future, so how can we best apply it to help combat climate change and find sustainable solutions?",
    "summary": "AI is a powerful technology that will transform our future, so how can we best apply it to help combat climate change and find sustainable solutions?",
    "pubDate": "Fri, 21 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/using-ai-to-fight-climate-change/",
    "thumbnail": "https://lh3.googleusercontent.com/_7lNDyMo0JuzMRu0wVUtaJuXaEPDy8ay20vcsv08JvF3fMkEbk20mGBWdI09Wg0USIinNH5urB5nudEGZWRvTeUNOz_WOAwcduNdQQQNGx-JgtQE1aE=w1200-h630-n-nu"
  },
  {
    "title": "Squat: Quant Small Language Models on the Edge",
    "description": "arXiv:2402.10787v2 Announce Type: replace-cross Abstract: A growing trend has emerged in designing high-quality Small Language Models (SLMs) with a few million parameters. This trend is driven by the increasing concerns over cloud costs, privacy, and latency. Considering that full parameter training is feasible for SLMs on mobile devices, Quantization-Aware Training (QAT) is employed to improve efficiency by reducing computational overhead and memory footprint. However, previous QAT works adopt fine-grained quantization methods to compress models with billions of parameters on GPUs, incompatible with current commodity hardware, such as mobile and edge devices, which relies on Single Instruction Multiple Data (SIMD) instructions. Thus, the generalization of these methods to SLMs on mobile devices is limited. In this paper, we propose Squat method, an effective QAT framework with deployable quantization for SLMs on mobile devices. Specifically, we propose entropy-guided and distribution-aligned distillation to mitigate the distortion of attention information from quantization. Besides, we employ sub-8-bit token adaptive quantization, assigning varying bit widths to different tokens based on their importance. Furthermore, we develop a SIMD-based Multi-Kernel Mixed-Precision (MKMP) multiplier to support sub-8-bit mixed-precision MAC on mobile devices. Our extensive experiments verify the substantial improvements of our method compared to other QAT methods across various datasets. Furthermore, we achieve an on-device speedup of up to 2.37x compared with its FP16 counterparts, signaling a great advancement. Code: https://github.com/shawnricecake/squant",
    "summary": "arXiv:2402.10787v2 Announce Type: replace-cross Abstract: A growing trend has emerged in designing high-quality Small Language Models (SLMs) with a few million parameters. This trend is driven by the increasing concerns over cloud costs, privacy, and latency. Considering that full parameter training is feasible for SLMs on mobile devices, Quantization-Aware Training (QAT) is employed to improve efficiency by reducing computational overhead and memory footprint. However, previous QAT works adopt fine-grained quantization methods to compress models with billions of parameters on GPUs, incompatible with current commodity hardware, such as mobile and edge devices, which relies on Single Instruction Multiple Data (SIMD) instructions. Thus, the generalization of these methods to SLMs on mobile devices is limited. In this paper, we propose Squat method, an effective QAT framework with deployable quantization for SLMs on mobile devices. Specifically, we propose entropy-guided and distribution-aligned distillation to mitigate the distortion of attention information from quantization. Besides, we employ sub-8-bit token adaptive quantization, assigning varying bit widths to different tokens based on their importance. Furthermore, we develop a SIMD-based Multi-Kernel Mixed-Precision (MKMP) multiplier to support sub-8-bit mixed-precision MAC on mobile devices. Our extensive experiments verify the substantial improvements of our method compared to other QAT methods across various datasets. Furthermore, we achieve an on-device speedup of up to 2.37x compared with its FP16 counterparts, signaling a great advancement. Code: https://github.com/shawnricecake/squant",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2402.10787",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome PaliGemma 2 ‚Äì New vision language models by Google",
    "description": "",
    "summary": "Welcome PaliGemma 2 ‚Äì New vision language models by Google We are excited to welcome Google's all-ne...",
    "pubDate": "Thu, 05 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma2",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma/Paligemma2.png"
  },
  {
    "title": "BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining",
    "description": "arXiv:2506.21567v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have recently gained attention in the life sciences due to their capacity to model, extract, and apply complex biological information. Beyond their classical use as chatbots, these systems are increasingly used for complex analysis and problem-solving in specialized fields, including bioinformatics. First, we introduce BIOPARS-BENCH, a dataset from over 10,000 scientific articles, textbooks, and medical websites. BioParsQA was also introduced to evaluate the proposed model, which consists of 5,231 Persian medical questions and answers. This study then introduces BioPars, a simple but accurate measure designed to assess LLMs for three main abilities: acquiring subject-specific knowledge, interpreting and synthesizing such knowledge, and demonstrating proper evidence. Comparing ChatGPT, Llama, and Galactica, our study highlights their ability to remember and retrieve learned knowledge but also reveals shortcomings in addressing higher-level, real-world questions and fine-grained inferences. These findings indicate the need for further fine-tuning to address the capabilities of LLM in bioinformatics tasks. To our knowledge, BioPars is the first application of LLM in Persian medical QA, especially for generating long answers. Evaluation of four selected medical QA datasets shows that BioPars has achieved remarkable results compared to comparative approaches. The model on BioParsQA achieved a ROUGE-L score of 29.99, which is an improvement over GPT-4 1.0. The model achieved a BERTScore of 90.87 with the MMR method. The MoverScore and BLEURT values were also higher in this model than the other three models. In addition, the reported scores for the model are MoverScore=60.43 and BLEURT=50.78. BioPars is an ongoing project and all resources related to its development will be made available via the following GitHub repository: https://github.com/amirap80/BioPars.",
    "summary": "arXiv:2506.21567v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have recently gained attention in the life sciences due to their capacity to model, extract, and apply complex biological information. Beyond their classical use as chatbots, these systems are increasingly used for complex analysis and problem-solving in specialized fields, including bioinformatics. First, we introduce BIOPARS-BENCH, a dataset from over 10,000 scientific articles, textbooks, and medical websites. BioParsQA was also introduced to evaluate the proposed model, which consists of 5,231 Persian medical questions and answers. This study then introduces BioPars, a simple but accurate measure designed to assess LLMs for three main abilities: acquiring subject-specific knowledge, interpreting and synthesizing such knowledge, and demonstrating proper evidence. Comparing ChatGPT, Llama, and Galactica, our study highlights their ability to remember and retrieve learned knowledge but also reveals shortcomings in addressing higher-level, real-world questions and fine-grained inferences. These findings indicate the need for further fine-tuning to address the capabilities of LLM in bioinformatics tasks. To our knowledge, BioPars is the first application of LLM in Persian medical QA, especially for generating long answers. Evaluation of four selected medical QA datasets shows that BioPars has achieved remarkable results compared to comparative approaches. The model on BioParsQA achieved a ROUGE-L score of 29.99, which is an improvement over GPT-4 1.0. The model achieved a BERTScore of 90.87 with the MMR method. The MoverScore and BLEURT values were also higher in this model than the other three models. In addition, the reported scores for the model are MoverScore=60.43 and BLEURT=50.78. BioPars is an ongoing project and all resources related to its development will be made available via the following GitHub repository: https://github.com/amirap80/BioPars.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21567",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BenchmarkQED: Automated benchmarking of RAG systems",
    "description": "<p>BenchmarkQED is an open-source toolkit for benchmarking RAG systems using automated query generation, evaluation, and dataset prep. It shows that LazyGraphRAG outperforms standard methods, especially on complex, global queries.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/'>BenchmarkQED: Automated benchmarking of RAG systems</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>BenchmarkQED is an open-source toolkit for benchmarking RAG systems using automated query generation, evaluation, and dataset prep. It shows that LazyGraphRAG outperforms standard methods, especially on complex, global queries.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/'>BenchmarkQED: Automated benchmarking of RAG systems</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 05 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "The NLP Course is becoming the LLM Course!",
    "description": "",
    "summary": "The NLP Course is becoming the LLM Course! Education has always been at the heart of Hugging Face‚Äôs ...",
    "pubDate": "Thu, 03 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llm-course",
    "thumbnail": "https://huggingface.co/blog/assets/llm-course/llm-course-rename-thumbnail.png"
  },
  {
    "title": "VQ Diffusion with üß® Diffusers",
    "description": "",
    "summary": "VQ-Diffusion Vector Quantized Diffusion (VQ-Diffusion) is a conditional latent diffusion model devel...",
    "pubDate": "Wed, 30 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vq-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/117_vq_diffusion/thumbnail.png"
  },
  {
    "title": "Share your open ML datasets on Hugging Face Hub!",
    "description": "",
    "summary": "Share your open ML datasets on Hugging Face Hub! If you're working on data-intensive research or mac...",
    "pubDate": "Tue, 12 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/researcher-dataset-sharing",
    "thumbnail": "https://huggingface.co/blog/assets/researcher-dataset-sharing/thumbnail.png"
  },
  {
    "title": "SearchGPT is a prototype of new AI search features",
    "description": "We‚Äôre testing SearchGPT, a temporary prototype of new search features that give you fast and timely answers with clear and relevant sources.",
    "summary": "We‚Äôre testing SearchGPT, a temporary prototype of new search features that give you fast and timely answers with clear and relevant sources.",
    "pubDate": "Thu, 25 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/searchgpt-prototype",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing NextGenAI",
    "description": "OpenAI commits $50M in funding and tools to leading institutions.",
    "summary": "OpenAI commits $50M in funding and tools to leading institutions.",
    "pubDate": "Tue, 04 Mar 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-nextgenai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Implicit generation and generalization methods for energy-based models",
    "description": "We‚Äôve made progress towards stable and scalable training of¬†energy-based models¬†(EBMs) resulting in better sample quality and generalization ability than existing models. Generation in EBMs spends more compute to continually refine its answers and doing so can generate samples competitive with¬†GANs¬†at low temperatures,¬†while also having mode coverage guarantees of¬†likelihood-based models. We hope these findings stimulate further research into this promising class of¬†models.",
    "summary": "We‚Äôve made progress towards stable and scalable training of¬†energy-based models¬†(EBMs) resulting in better sample quality and generalization ability than existing models. Generation in EBMs spends more compute to continually refine its answers and doing so can generate samples competitive with¬†GANs¬†at low temperatures,¬†while also having mode coverage guarantees of¬†likelihood-based models. We hope these findings stimulate further research into this promising class of¬†models.",
    "pubDate": "Thu, 21 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/energy-based-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Subscribe to Enterprise Hub with your AWS Account",
    "description": "",
    "summary": "Subscribe to Enterprise Hub with your AWS Account You can now upgrade your Hugging Face Organization...",
    "pubDate": "Thu, 09 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/enterprise-hub-aws-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/158_aws_marketplace/thumbnail.jpg"
  },
  {
    "title": "Preparing for future AI risks in biology",
    "description": "Advanced AI can transform biology and medicine‚Äîbut also raises biosecurity risks. We‚Äôre proactively assessing capabilities and implementing safeguards to prevent misuse.",
    "summary": "Advanced AI can transform biology and medicine‚Äîbut also raises biosecurity risks. We‚Äôre proactively assessing capabilities and implementing safeguards to prevent misuse.",
    "pubDate": "Wed, 18 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/preparing-for-future-ai-capabilities-in-biology",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hybrid AI model crafts smooth, high-quality videos in seconds",
    "description": "The CausVid generative AI tool uses a diffusion model to teach an autoregressive (frame-by-frame) system to rapidly produce stable, high-resolution videos.",
    "summary": "The CausVid generative AI tool uses a diffusion model to teach an autoregressive (frame-by-frame) system to rapidly produce stable, high-resolution videos.",
    "pubDate": "Tue, 06 May 2025 12:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/causevid-hybrid-ai-model-crafts-smooth-high-quality-videos-in-seconds-0506",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-CausVid.jpg"
  },
  {
    "title": "DuckDB: run SQL queries on 50,000+ datasets on the Hugging Face Hub",
    "description": "",
    "summary": "DuckDB: run SQL queries on 50,000+ datasets on the Hugging Face Hub The Hugging Face Hub is dedicate...",
    "pubDate": "Wed, 07 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hub-duckdb",
    "thumbnail": "https://huggingface.co/blog/assets/hub_duckdb/hub_duckdb.png"
  },
  {
    "title": "OpenAI o1 Contributions",
    "description": "OpenAI o1 Contributions",
    "summary": "OpenAI o1 Contributions",
    "pubDate": "Thu, 12 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/openai-o1-contributions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An anomaly detection framework anyone can use",
    "description": "PhD student Sarah Alnegheimish wants to make machine learning systems accessible.",
    "summary": "PhD student Sarah Alnegheimish wants to make machine learning systems accessible.",
    "pubDate": "Wed, 28 May 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/anomaly-detection-framework-anyone-can-use-sarah-alnegheimish-0528",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Sarah-Abdulaziz-Alnegheimish.JPG"
  },
  {
    "title": "Testimony before the U.S. Senate",
    "description": "The following is the written testimony of Sam Altman, Chief Executive Officer of OpenAI, before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "summary": "The following is the written testimony of Sam Altman, Chief Executive Officer of OpenAI, before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/testimony-of-sam-altman-before-the-us-senate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accurately analyzing large scale qualitative data",
    "description": "Viable uses GPT-4 to analyze qualitative data at a revolutionary scale with unparalleled accuracy.",
    "summary": "Viable uses GPT-4 to analyze qualitative data at a revolutionary scale with unparalleled accuracy.",
    "pubDate": "Fri, 07 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/viable",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Running Privacy-Preserving Inference on Hugging Face Endpoints",
    "description": "",
    "summary": "Running Privacy-Preserving Inferences on Hugging Face Endpoints This is a guest blog post by the Zam...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fhe-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/fhe-endpoints/thumbnail.png"
  },
  {
    "title": "AI4Research: A Survey of Artificial Intelligence for Scientific Research",
    "description": "arXiv:2507.01903v1 Announce Type: cross Abstract: Recent advancements in artificial intelligence (AI), particularly in large language models (LLMs) such as OpenAI-o1 and DeepSeek-R1, have demonstrated remarkable capabilities in complex domains such as logical reasoning and experimental coding. Motivated by these advancements, numerous studies have explored the application of AI in the innovation process, particularly in the context of scientific research. These AI technologies primarily aim to develop systems that can autonomously conduct research processes across a wide range of scientific disciplines. Despite these significant strides, a comprehensive survey on AI for Research (AI4Research) remains absent, which hampers our understanding and impedes further development in this field. To address this gap, we present a comprehensive survey and offer a unified perspective on AI4Research. Specifically, the main contributions of our work are as follows: (1) Systematic taxonomy: We first introduce a systematic taxonomy to classify five mainstream tasks in AI4Research. (2) New frontiers: Then, we identify key research gaps and highlight promising future directions, focusing on the rigor and scalability of automated experiments, as well as the societal impact. (3) Abundant applications and resources: Finally, we compile a wealth of resources, including relevant multidisciplinary applications, data corpora, and tools. We hope our work will provide the research community with quick access to these resources and stimulate innovative breakthroughs in AI4Research.",
    "summary": "arXiv:2507.01903v1 Announce Type: cross Abstract: Recent advancements in artificial intelligence (AI), particularly in large language models (LLMs) such as OpenAI-o1 and DeepSeek-R1, have demonstrated remarkable capabilities in complex domains such as logical reasoning and experimental coding. Motivated by these advancements, numerous studies have explored the application of AI in the innovation process, particularly in the context of scientific research. These AI technologies primarily aim to develop systems that can autonomously conduct research processes across a wide range of scientific disciplines. Despite these significant strides, a comprehensive survey on AI for Research (AI4Research) remains absent, which hampers our understanding and impedes further development in this field. To address this gap, we present a comprehensive survey and offer a unified perspective on AI4Research. Specifically, the main contributions of our work are as follows: (1) Systematic taxonomy: We first introduce a systematic taxonomy to classify five mainstream tasks in AI4Research. (2) New frontiers: Then, we identify key research gaps and highlight promising future directions, focusing on the rigor and scalability of automated experiments, as well as the societal impact. (3) Abundant applications and resources: Finally, we compile a wealth of resources, including relevant multidisciplinary applications, data corpora, and tools. We hope our work will provide the research community with quick access to these resources and stimulate innovative breakthroughs in AI4Research.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01903",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using & Mixing Hugging Face Models with Gradio 2.0",
    "description": "",
    "summary": "Using & Mixing Hugging Face Models with Gradio 2.0 Cross-posted from the Gradio blog. The Hugging Fa...",
    "pubDate": "Tue, 25 May 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio",
    "thumbnail": "https://huggingface.co/blog/assets/22_gradio/gradio.png"
  },
  {
    "title": "Overview of natively supported quantization schemes in ü§ó Transformers",
    "description": "",
    "summary": "Overview of natively supported quantization schemes in ü§ó Transformers We aim to give a clear overvie...",
    "pubDate": "Tue, 12 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/overview-quantization-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/163_overview_quantization_transformers/thumbnail.jpg"
  },
  {
    "title": "MIT Department of Economics to launch James M. and Cathleen D. Stone Center on Inequality and Shaping the Future of Work",
    "description": "With support from the Stone Foundation, the center will advance cutting-edge research and inform policy.",
    "summary": "With support from the Stone Foundation, the center will advance cutting-edge research and inform policy.",
    "pubDate": "Tue, 13 May 2025 16:35:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-economics-department-launches-james-cathleen-stone-center-inequality-shaping-future-work-0513",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-campus.jpg"
  },
  {
    "title": "OpenAI‚Äôs Approach to Frontier Risk",
    "description": "An Update for the UK AI Safety Summit",
    "summary": "An Update for the UK AI Safety Summit",
    "pubDate": "Thu, 26 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/our-approach-to-frontier-risk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "UK government harnesses Gemini to support faster planning decisions",
    "description": "A summary of how Extract works",
    "summary": "A summary of how Extract works",
    "pubDate": "Mon, 09 Jun 2025 11:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/around-the-globe/google-europe/united-kingdom/uk-government-harnesses-gemini-to-support-faster-planning-decisions/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/overview.width-1300.png"
  },
  {
    "title": "Prompt Guidance and Human Proximal Perception for HOT Prediction with Regional Joint Loss",
    "description": "arXiv:2507.01630v1 Announce Type: cross Abstract: The task of Human-Object conTact (HOT) detection involves identifying the specific areas of the human body that are touching objects. Nevertheless, current models are restricted to just one type of image, often leading to too much segmentation in areas with little interaction, and struggling to maintain category consistency within specific regions. To tackle this issue, a HOT framework, termed textbf{P3HOT}, is proposed, which blends textbf{P}rompt guidance and human textbf{P}roximal textbf{P}erception. To begin with, we utilize a semantic-driven prompt mechanism to direct the network's attention towards the relevant regions based on the correlation between image and text. Then a human proximal perception mechanism is employed to dynamically perceive key depth range around the human, using learnable parameters to effectively eliminate regions where interactions are not expected. Calculating depth resolves the uncertainty of the overlap between humans and objects in a 2D perspective, providing a quasi-3D viewpoint. Moreover, a Regional Joint Loss (RJLoss) has been created as a new loss to inhibit abnormal categories in the same area. A new evaluation metric called ``AD-Acc.'' is introduced to address the shortcomings of existing methods in addressing negative samples. Comprehensive experimental results demonstrate that our approach achieves state-of-the-art performance in four metrics across two benchmark datasets. Specifically, our model achieves an improvement of textbf{0.7}$uparrow$, textbf{2.0}$uparrow$, textbf{1.6}$uparrow$, and textbf{11.0}$uparrow$ in SC-Acc., mIoU, wIoU, and AD-Acc. metrics, respectively, on the HOT-Annotated dataset. Code is available at https://github.com/YuxiaoWang-AI/P3HOT.",
    "summary": "arXiv:2507.01630v1 Announce Type: cross Abstract: The task of Human-Object conTact (HOT) detection involves identifying the specific areas of the human body that are touching objects. Nevertheless, current models are restricted to just one type of image, often leading to too much segmentation in areas with little interaction, and struggling to maintain category consistency within specific regions. To tackle this issue, a HOT framework, termed textbf{P3HOT}, is proposed, which blends textbf{P}rompt guidance and human textbf{P}roximal textbf{P}erception. To begin with, we utilize a semantic-driven prompt mechanism to direct the network's attention towards the relevant regions based on the correlation between image and text. Then a human proximal perception mechanism is employed to dynamically perceive key depth range around the human, using learnable parameters to effectively eliminate regions where interactions are not expected. Calculating depth resolves the uncertainty of the overlap between humans and objects in a 2D perspective, providing a quasi-3D viewpoint. Moreover, a Regional Joint Loss (RJLoss) has been created as a new loss to inhibit abnormal categories in the same area. A new evaluation metric called ``AD-Acc.'' is introduced to address the shortcomings of existing methods in addressing negative samples. Comprehensive experimental results demonstrate that our approach achieves state-of-the-art performance in four metrics across two benchmark datasets. Specifically, our model achieves an improvement of textbf{0.7}$uparrow$, textbf{2.0}$uparrow$, textbf{1.6}$uparrow$, and textbf{11.0}$uparrow$ in SC-Acc., mIoU, wIoU, and AD-Acc. metrics, respectively, on the HOT-Annotated dataset. Code is available at https://github.com/YuxiaoWang-AI/P3HOT.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01630",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Response to NIST Executive Order on AI",
    "description": "The National Institute of Standards and Technology (NIST) request for information related to its assignments under sections 4.1, 4.5, and 11 of the Executive Order Concerning Artificial Intelligence",
    "summary": "The National Institute of Standards and Technology (NIST) request for information related to its assignments under sections 4.1, 4.5, and 11 of the Executive Order Concerning Artificial Intelligence",
    "pubDate": "Fri, 02 Feb 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-nist-executive-order-on-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MIT‚Äôs McGovern Institute is shaping brain science and improving human lives on a global scale",
    "description": "A quarter century after its founding, the McGovern Institute reflects on its discoveries in the areas of neuroscience, neurotechnology, artificial intelligence, brain-body connections, and therapeutics.",
    "summary": "A quarter century after its founding, the McGovern Institute reflects on its discoveries in the areas of neuroscience, neurotechnology, artificial intelligence, brain-body connections, and therapeutics.",
    "pubDate": "Fri, 18 Apr 2025 10:40:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-mcgovern-institute-shaping-brain-science-improving-human-lives-0418",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-mcgovern-madonna-fmri-600x900.jpg"
  },
  {
    "title": "Securing Research Infrastructure for Advanced AI",
    "description": "We outline our architecture that supports the secure training of frontier models.",
    "summary": "We outline our architecture that supports the secure training of frontier models.",
    "pubDate": "Wed, 05 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/securing-research-infrastructure-for-advanced-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI API",
    "description": "We‚Äôre releasing an API for accessing new AI models developed by OpenAI.",
    "summary": "We‚Äôre releasing an API for accessing new AI models developed by OpenAI.",
    "pubDate": "Thu, 11 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From DeepSpeed to FSDP and Back Again with Hugging Face Accelerate",
    "description": "",
    "summary": "A Hugging Face Accelerate Story of Multiple Backends: FSDP and DeepSpeed There are two popular imple...",
    "pubDate": "Thu, 13 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deepspeed-to-fsdp-and-back",
    "thumbnail": "https://huggingface.co/blog/assets/deepspeed-to-fsdp-and-back/thumbnail.png"
  },
  {
    "title": "TTS Arena: Benchmarking Text-to-Speech Models in the Wild",
    "description": "",
    "summary": "TTS Arena: Benchmarking Text-to-Speech Models in the Wild Automated measurement of the quality of te...",
    "pubDate": "Tue, 27 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-tts",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail.png"
  },
  {
    "title": "Backdooring Bias (B^2) into Stable Diffusion Models",
    "description": "arXiv:2406.15213v3 Announce Type: replace-cross Abstract: Recent advances in large text-conditional diffusion models have revolutionized image generation by enabling users to create realistic, high-quality images from textual prompts, significantly enhancing artistic creation and visual communication. However, these advancements also introduce an underexplored attack opportunity: the possibility of inducing biases by an adversary into the generated images for malicious intentions, e.g., to influence public opinion and spread propaganda. In this paper, we study an attack vector that allows an adversary to inject arbitrary bias into a target model. The attack leverages low-cost backdooring techniques using a targeted set of natural textual triggers embedded within a small number of malicious data samples produced with public generative models. An adversary could pick common sequences of words that can then be inadvertently activated by benign users during inference. We investigate the feasibility and challenges of such attacks, demonstrating how modern generative models have made this adversarial process both easier and more adaptable. On the other hand, we explore various aspects of the detectability of such attacks and demonstrate that the model's utility remains intact in the absence of the triggers. Our extensive experiments using over 200,000 generated images and against hundreds of fine-tuned models demonstrate the feasibility of the presented backdoor attack. We illustrate how these biases maintain strong text-image alignment, highlighting the challenges in detecting biased images without knowing that bias in advance. Our cost analysis confirms the low financial barrier ($10-$15) to executing such attacks, underscoring the need for robust defensive strategies against such vulnerabilities in diffusion models.",
    "summary": "arXiv:2406.15213v3 Announce Type: replace-cross Abstract: Recent advances in large text-conditional diffusion models have revolutionized image generation by enabling users to create realistic, high-quality images from textual prompts, significantly enhancing artistic creation and visual communication. However, these advancements also introduce an underexplored attack opportunity: the possibility of inducing biases by an adversary into the generated images for malicious intentions, e.g., to influence public opinion and spread propaganda. In this paper, we study an attack vector that allows an adversary to inject arbitrary bias into a target model. The attack leverages low-cost backdooring techniques using a targeted set of natural textual triggers embedded within a small number of malicious data samples produced with public generative models. An adversary could pick common sequences of words that can then be inadvertently activated by benign users during inference. We investigate the feasibility and challenges of such attacks, demonstrating how modern generative models have made this adversarial process both easier and more adaptable. On the other hand, we explore various aspects of the detectability of such attacks and demonstrate that the model's utility remains intact in the absence of the triggers. Our extensive experiments using over 200,000 generated images and against hundreds of fine-tuned models demonstrate the feasibility of the presented backdoor attack. We illustrate how these biases maintain strong text-image alignment, highlighting the challenges in detecting biased images without knowing that bias in advance. Our cost analysis confirms the low financial barrier ($10-$15) to executing such attacks, underscoring the need for robust defensive strategies against such vulnerabilities in diffusion models.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.15213",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Dataset Distillation via the Wasserstein Metric",
    "description": "arXiv:2311.18531v3 Announce Type: replace-cross Abstract: Dataset Distillation (DD) aims to generate a compact synthetic dataset that enables models to achieve performance comparable to training on the full large dataset, significantly reducing computational costs. Drawing from optimal transport theory, we introduce WMDD (Wasserstein Metric-based Dataset Distillation), a straightforward yet powerful method that employs the Wasserstein metric to enhance distribution matching. We compute the Wasserstein barycenter of features from a pretrained classifier to capture essential characteristics of the original data distribution. By optimizing synthetic data to align with this barycenter in feature space and leveraging per-class BatchNorm statistics to preserve intra-class variations, WMDD maintains the efficiency of distribution matching approaches while achieving state-of-the-art results across various high-resolution datasets. Our extensive experiments demonstrate WMDD's effectiveness and adaptability, highlighting its potential for advancing machine learning applications at scale.",
    "summary": "arXiv:2311.18531v3 Announce Type: replace-cross Abstract: Dataset Distillation (DD) aims to generate a compact synthetic dataset that enables models to achieve performance comparable to training on the full large dataset, significantly reducing computational costs. Drawing from optimal transport theory, we introduce WMDD (Wasserstein Metric-based Dataset Distillation), a straightforward yet powerful method that employs the Wasserstein metric to enhance distribution matching. We compute the Wasserstein barycenter of features from a pretrained classifier to capture essential characteristics of the original data distribution. By optimizing synthetic data to align with this barycenter in feature space and leveraging per-class BatchNorm statistics to preserve intra-class variations, WMDD maintains the efficiency of distribution matching approaches while achieving state-of-the-art results across various high-resolution datasets. Our extensive experiments demonstrate WMDD's effectiveness and adaptability, highlighting its potential for advancing machine learning applications at scale.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2311.18531",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI for Game Development: Creating a Farming Game in 5 Days. Part 1",
    "description": "",
    "summary": "AI for Game Development: Creating a Farming Game in 5 Days. Part 1 Welcome to AI for Game Developmen...",
    "pubDate": "Mon, 02 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-1",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail.png"
  },
  {
    "title": "Gemini CLI: your open-source AI agent",
    "description": "Gemini CLI icon on a background with code snippets",
    "summary": "Gemini CLI icon on a background with code snippets",
    "pubDate": "Wed, 25 Jun 2025 13:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_CLI_Hero_Final.width-1300.png"
  },
  {
    "title": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy",
    "description": "arXiv:2507.01352v1 Announce Type: cross Abstract: Despite the critical role of reward models (RMs) in reinforcement learning from human feedback (RLHF), current state-of-the-art open RMs perform poorly on most existing evaluation benchmarks, failing to capture the spectrum of nuanced and sophisticated human preferences. Even approaches that incorporate advanced training techniques have not yielded meaningful performance improvements. We hypothesize that this brittleness stems primarily from limitations in preference datasets, which are often narrowly scoped, synthetically labeled, or lack rigorous quality control. To address these challenges, we present a large-scale preference dataset comprising 40 million preference pairs, named SynPref-40M. To enable data curation at scale, we design a human-AI synergistic two-stage pipeline that leverages the complementary strengths of human annotation quality and AI scalability. In this pipeline, humans provide verified annotations, while large language models perform automatic curation based on human guidance. Training on this preference mixture, we introduce Skywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B parameters, trained on a carefully curated subset of 26 million preference pairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile across a wide range of capabilities, including alignment with human preferences, objective correctness, safety, resistance to stylistic biases, and best-of-N scaling, achieving state-of-the-art performance across seven major reward model benchmarks. Ablation studies confirm that the effectiveness of our approach stems not only from data scale but also from high-quality curation. The Skywork-Reward-V2 series represents substantial progress in open reward models, highlighting the untapped potential of existing preference datasets and demonstrating how human-AI curation synergy can unlock significantly higher data quality.",
    "summary": "arXiv:2507.01352v1 Announce Type: cross Abstract: Despite the critical role of reward models (RMs) in reinforcement learning from human feedback (RLHF), current state-of-the-art open RMs perform poorly on most existing evaluation benchmarks, failing to capture the spectrum of nuanced and sophisticated human preferences. Even approaches that incorporate advanced training techniques have not yielded meaningful performance improvements. We hypothesize that this brittleness stems primarily from limitations in preference datasets, which are often narrowly scoped, synthetically labeled, or lack rigorous quality control. To address these challenges, we present a large-scale preference dataset comprising 40 million preference pairs, named SynPref-40M. To enable data curation at scale, we design a human-AI synergistic two-stage pipeline that leverages the complementary strengths of human annotation quality and AI scalability. In this pipeline, humans provide verified annotations, while large language models perform automatic curation based on human guidance. Training on this preference mixture, we introduce Skywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B parameters, trained on a carefully curated subset of 26 million preference pairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile across a wide range of capabilities, including alignment with human preferences, objective correctness, safety, resistance to stylistic biases, and best-of-N scaling, achieving state-of-the-art performance across seven major reward model benchmarks. Ablation studies confirm that the effectiveness of our approach stems not only from data scale but also from high-quality curation. The Skywork-Reward-V2 series represents substantial progress in open reward models, highlighting the untapped potential of existing preference datasets and demonstrating how human-AI curation synergy can unlock significantly higher data quality.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01352",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Director of Machine Learning Insights [Part 3: Finance Edition]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 3: Finance Edition] If you're interested in building ML ...",
    "pubDate": "Tue, 14 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-3",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/thumbnail.png"
  },
  {
    "title": "Economic impacts research at OpenAI",
    "description": "Call for expressions of interest to study the economic impacts of large language¬†models.",
    "summary": "Call for expressions of interest to study the economic impacts of large language¬†models.",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/economic-impacts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "‚ÄúPeriodic table of machine learning‚Äù could fuel AI discovery",
    "description": "Researchers have created a unifying framework that can help scientists combine existing ideas to improve AI models or create new ones.",
    "summary": "Researchers have created a unifying framework that can help scientists combine existing ideas to improve AI models or create new ones.",
    "pubDate": "Wed, 23 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/machine-learning-periodic-table-could-fuel-ai-discovery-0423",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Periodic-Algorithm-01-PRESS.jpg"
  },
  {
    "title": "EliseAI improves housing and healthcare efficiency with AI",
    "description": "A conversation with Minna Song, CEO & Co-founder of EliseAI.",
    "summary": "A conversation with Minna Song, CEO & Co-founder of EliseAI.",
    "pubDate": "Tue, 18 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/eliseai-minna-song",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New generative AI tools open the doors of music creation",
    "description": "Our latest AI music technologies are now available in MusicFX DJ, Music AI Sandbox and YouTube Shorts",
    "summary": "Our latest AI music technologies are now available in MusicFX DJ, Music AI Sandbox and YouTube Shorts",
    "pubDate": "Wed, 23 Oct 2024 16:53:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/new-generative-ai-tools-open-the-doors-of-music-creation/",
    "thumbnail": "https://lh3.googleusercontent.com/7CWJ9fVeC97FrWgcispxyms9gTL_1PIDMIwBYTQNnU8S56JaxGB2Z4ThqZ-1vBTO-u-UBZg_cYhG8PtZjYP0rPabUbg5x2cCUnNJuiZAZBsE8u7Kvig=w1200-h630-n-nu"
  },
  {
    "title": "FastRTC: The Real-Time Communication Library for Python",
    "description": "",
    "summary": "FastRTC: The Real-Time Communication Library for Python In the last few months, many new real-time s...",
    "pubDate": "Tue, 25 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastrtc",
    "thumbnail": "https://huggingface.co/blog/assets/fastrtc/fastrtc_logo.jpg"
  },
  {
    "title": "Bamba: Inference-Efficient Hybrid Mamba2 Model",
    "description": "",
    "summary": "Bamba: Inference-Efficient Hybrid Mamba2 Model üêç TL;DR We introduce Bamba-9B, an inference-efficient...",
    "pubDate": "Wed, 18 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bamba",
    "thumbnail": "https://huggingface.co/blog/assets/bamba/bamba_thumbnail.png"
  },
  {
    "title": "Accelerating engineering cycles 20% with OpenAI",
    "description": "Accelerating engineering cycles 20% with OpenAI.",
    "summary": "Accelerating engineering cycles 20% with OpenAI.",
    "pubDate": "Thu, 06 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/factory",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pairing data with APIs to unlock customer value",
    "description": "Rakuten Pairs Data with AI to Unlock Customer Insights and Value",
    "summary": "Rakuten Pairs Data with AI to Unlock Customer Insights and Value",
    "pubDate": "Wed, 07 Aug 2024 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rakuten",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI technical goals",
    "description": "OpenAI‚Äôs mission is to build safe AI, and ensure AI‚Äôs benefits are as widely and evenly distributed as possible.",
    "summary": "OpenAI‚Äôs mission is to build safe AI, and ensure AI‚Äôs benefits are as widely and evenly distributed as possible.",
    "pubDate": "Mon, 20 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-technical-goals",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Updating the Frontier Safety Framework",
    "description": "Our next iteration of the FSF sets out stronger security protocols on the path to AGI",
    "summary": "Our next iteration of the FSF sets out stronger security protocols on the path to AGI",
    "pubDate": "Tue, 04 Feb 2025 16:41:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/updating-the-frontier-safety-framework/",
    "thumbnail": "https://lh3.googleusercontent.com/0fu18H8X3miSAuwcVJ7Zulis_LZAL7F4bIFU7FYFA2dGx3Rm3HHlm5N202B0dtKBuS7iI5SD1QgpFPuU-O3TPzb7iG1Ns-loZzinRB3M3X3W-MAgIQ=w1200-h630-n-nu"
  },
  {
    "title": "New embedding models and API updates",
    "description": "We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management tools, and soon, lower pricing on GPT-3.5 Turbo.",
    "summary": "We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management tools, and soon, lower pricing on GPT-3.5 Turbo.",
    "pubDate": "Thu, 25 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-embedding-models-and-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An Introduction to AI Secure LLM Safety Leaderboard",
    "description": "",
    "summary": "An Introduction to AI Secure LLM Safety Leaderboard Given the widespread adoption of LLMs, it is cri...",
    "pubDate": "Fri, 26 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-decodingtrust",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_decodingtrust.png"
  },
  {
    "title": "Embodied Instruction Following in Unknown Environments",
    "description": "arXiv:2406.11818v2 Announce Type: replace-cross Abstract: Enabling embodied agents to complete complex human instructions from natural language is crucial to autonomous systems in household services. Conventional methods can only accomplish human instructions in the known environment where all interactive objects are provided to the embodied agent, and directly deploying the existing approaches for the unknown environment usually generates infeasible plans that manipulate non-existing objects. On the contrary, we propose an embodied instruction following (EIF) method for complex tasks in the unknown environment, where the agent efficiently explores the unknown environment to generate feasible plans with existing objects to accomplish abstract instructions. Specifically, we build a hierarchical embodied instruction following framework including the high-level task planner and the low-level exploration controller with multimodal large language models. We then construct a semantic representation map of the scene with dynamic region attention to demonstrate the known visual clues, where the goal of task planning and scene exploration is aligned for human instruction. For the task planner, we generate the feasible step-by-step plans for human goal accomplishment according to the task completion process and the known visual clues. For the exploration controller, the optimal navigation or object interaction policy is predicted based on the generated step-wise plans and the known visual clues. The experimental results demonstrate that our method can achieve 45.09% success rate in 204 complex human instructions such as making breakfast and tidying rooms in large house-level scenes. Code and supplementary are available at https://gary3410.github.io/eif_unknown.",
    "summary": "arXiv:2406.11818v2 Announce Type: replace-cross Abstract: Enabling embodied agents to complete complex human instructions from natural language is crucial to autonomous systems in household services. Conventional methods can only accomplish human instructions in the known environment where all interactive objects are provided to the embodied agent, and directly deploying the existing approaches for the unknown environment usually generates infeasible plans that manipulate non-existing objects. On the contrary, we propose an embodied instruction following (EIF) method for complex tasks in the unknown environment, where the agent efficiently explores the unknown environment to generate feasible plans with existing objects to accomplish abstract instructions. Specifically, we build a hierarchical embodied instruction following framework including the high-level task planner and the low-level exploration controller with multimodal large language models. We then construct a semantic representation map of the scene with dynamic region attention to demonstrate the known visual clues, where the goal of task planning and scene exploration is aligned for human instruction. For the task planner, we generate the feasible step-by-step plans for human goal accomplishment according to the task completion process and the known visual clues. For the exploration controller, the optimal navigation or object interaction policy is predicted based on the generated step-wise plans and the known visual clues. The experimental results demonstrate that our method can achieve 45.09% success rate in 204 complex human instructions such as making breakfast and tidying rooms in large house-level scenes. Code and supplementary are available at https://gary3410.github.io/eif_unknown.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.11818",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face models in Amazon Bedrock",
    "description": "",
    "summary": "Use Hugging Face models with Amazon Bedrock We are excited to announce that popular open models from...",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bedrock-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/bedrock-marketplace/thumbnail.png"
  },
  {
    "title": "An Overview of Inference Solutions on Hugging Face",
    "description": "",
    "summary": "An Overview of Inference Solutions on Hugging Face Every day, developers and organizations are adopt...",
    "pubDate": "Mon, 21 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-update",
    "thumbnail": "https://huggingface.co/blog/assets/116_inference_update/widget.png"
  },
  {
    "title": "Images altered to trick machine vision can influence humans too",
    "description": "In a series of experiments published in Nature Communications, we found evidence that human judgments are indeed systematically influenced by adversarial perturbations.",
    "summary": "In a series of experiments published in Nature Communications, we found evidence that human judgments are indeed systematically influenced by adversarial perturbations.",
    "pubDate": "Tue, 02 Jan 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/images-altered-to-trick-machine-vision-can-influence-humans-too/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "Understanding the source of what we see and hear online",
    "description": "Today we‚Äôre introducing new technology to help researchers identify content created by our tools and joining the Coalition for Content Provenance and Authenticity Steering Committee to promote industry standards.",
    "summary": "Today we‚Äôre introducing new technology to help researchers identify content created by our tools and joining the Coalition for Content Provenance and Authenticity Steering Committee to promote industry standards.",
    "pubDate": "Tue, 07 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/understanding-the-source-of-what-we-see-and-hear-online",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Expanded access to Google Vids and no-cost AI tools in Classroom",
    "description": "Google Meet icon, Google Classroom icon, with various browser windows",
    "summary": "Google Meet icon, Google Classroom icon, with various browser windows",
    "pubDate": "Mon, 30 Jun 2025 13:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/education/expanded-access-to-google-vids-and-no-cost-ai-tools-in-classroom/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/027-ISTE-EDU-Keyword_blog-Google_Workspace_fo.width-1300.png"
  },
  {
    "title": "Hugging Face Collaborates with Microsoft to Launch Hugging Face Model Catalog on Azure",
    "description": "",
    "summary": "Hugging Face Collaborates with Microsoft to launch Hugging Face Model Catalog on Azure Today, we are...",
    "pubDate": "Wed, 24 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-endpoints-on-azure",
    "thumbnail": "https://huggingface.co/blog/assets/75_hugging_face_endpoints_on_azure/01.jpg"
  },
  {
    "title": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "description": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "summary": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "pubDate": "Tue, 22 Oct 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-chief-compliance-officer-announcement",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Vision Language Models (Better, Faster, Stronger)",
    "description": "",
    "summary": "Vision Language Models (Better, Faster, Stronger) Motivation Vision Language Models (VLMs) are the t...",
    "pubDate": "Mon, 12 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vlms-2025",
    "thumbnail": "https://huggingface.co/blog/assets/vlms2/vlms2.png"
  },
  {
    "title": "Opinion Classification with Kili and HuggingFace AutoTrain",
    "description": "",
    "summary": "Opinion Classification with Kili and HuggingFace AutoTrain Introduction Understanding your users‚Äô ne...",
    "pubDate": "Thu, 28 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/opinion-classification-with-kili",
    "thumbnail": "https://huggingface.co/blog/assets/59_opinion-classification-with-kili/thumbnail.png"
  },
  {
    "title": "Why we‚Äôre switching to Hugging Face Inference Endpoints, and maybe you should too",
    "description": "",
    "summary": "Why we‚Äôre switching to Hugging Face Inference Endpoints, and maybe you should too Hugging Face recen...",
    "pubDate": "Wed, 15 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mantis-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/mantis1.png"
  },
  {
    "title": "Rocket Money x Hugging Face: Scaling Volatile ML Models in Production",
    "description": "",
    "summary": "Rocket Money x Hugging Face: Scaling Volatile ML Models in Production 'We discovered that they were ...",
    "pubDate": "Tue, 19 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rocketmoney-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/rocketmoney.png"
  },
  {
    "title": "Liftoff! How to get started with your first ML project üöÄ",
    "description": "",
    "summary": "Liftoff! How to get started with your first ML project üöÄ People who are new to the Machine Learning ...",
    "pubDate": "Wed, 29 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/your-first-ml-project",
    "thumbnail": "https://huggingface.co/blog/assets/84_first_ml_project/thumbnail.png"
  },
  {
    "title": "Creating websites in minutes with AI Website Builder",
    "description": "Wix‚Äôs AI Website Builder, powered by OpenAI, lets anyone create a full website in minutes‚Äîjust by describing their idea in a conversation.",
    "summary": "Wix‚Äôs AI Website Builder, powered by OpenAI, lets anyone create a full website in minutes‚Äîjust by describing their idea in a conversation.",
    "pubDate": "Thu, 29 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/wix",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Benchmarking Language Model Performance on 5th Gen Xeon at GCP",
    "description": "",
    "summary": "Benchmarking Language Model Performance on 5th Gen Xeon at GCP TL;DR: We benchmark 2 representative ...",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-gcp-c4",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Introduction to the Open Leaderboard for Japanese LLMs",
    "description": "",
    "summary": "Introduction to the Open Leaderboard for Japanese LLMs LLMs are now increasingly capable in English,...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-japanese",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_japanese.png"
  },
  {
    "title": "Course Launch Community Event",
    "description": "",
    "summary": "Course Launch Community Event We are excited to share that after a lot of work from the Hugging Face...",
    "pubDate": "Tue, 26 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/course-launch-event",
    "thumbnail": "https://huggingface.co/blog/assets/34_course_launch/speakers_day1_thumb.png"
  },
  {
    "title": "Powering next generation applications with OpenAI Codex",
    "description": "Codex is now powering 70 different applications across a variety of use cases through the OpenAI¬†API.",
    "summary": "Codex is now powering 70 different applications across a variety of use cases through the OpenAI¬†API.",
    "pubDate": "Tue, 24 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/codex-apps",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Patch Time Series Transformer in Hugging Face",
    "description": "",
    "summary": "Patch Time Series Transformer in Hugging Face - Getting Started In this blog, we provide examples of...",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/patchtst",
    "thumbnail": "https://huggingface.co/blog/assets/patchtst/thumbnail.png"
  },
  {
    "title": "How Do Vision-Language Models Process Conflicting Information Across Modalities?",
    "description": "arXiv:2507.01790v1 Announce Type: cross Abstract: AI models are increasingly required to be multimodal, integrating disparate input streams into a coherent state representation on which subsequent behaviors and actions can be based. This paper seeks to understand how such models behave when input streams present conflicting information. Focusing specifically on vision-language models, we provide inconsistent inputs (e.g., an image of a dog paired with the caption 'A photo of a cat') and ask the model to report the information present in one of the specific modalities (e.g., 'What does the caption say / What is in the image?'). We find that models often favor one modality over the other, e.g., reporting the image regardless of what the caption says, but that different models differ in which modality they favor. We find evidence that the behaviorally preferred modality is evident in the internal representational structure of the model, and that specific attention heads can restructure the representations to favor one modality over the other. Moreover, we find modality-agnostic 'router heads' which appear to promote answers about the modality requested in the instruction, and which can be manipulated or transferred in order to improve performance across datasets and modalities. Together, the work provides essential steps towards identifying and controlling if and how models detect and resolve conflicting signals within complex multimodal environments.",
    "summary": "arXiv:2507.01790v1 Announce Type: cross Abstract: AI models are increasingly required to be multimodal, integrating disparate input streams into a coherent state representation on which subsequent behaviors and actions can be based. This paper seeks to understand how such models behave when input streams present conflicting information. Focusing specifically on vision-language models, we provide inconsistent inputs (e.g., an image of a dog paired with the caption 'A photo of a cat') and ask the model to report the information present in one of the specific modalities (e.g., 'What does the caption say / What is in the image?'). We find that models often favor one modality over the other, e.g., reporting the image regardless of what the caption says, but that different models differ in which modality they favor. We find evidence that the behaviorally preferred modality is evident in the internal representational structure of the model, and that specific attention heads can restructure the representations to favor one modality over the other. Moreover, we find modality-agnostic 'router heads' which appear to promote answers about the modality requested in the instruction, and which can be manipulated or transferred in order to improve performance across datasets and modalities. Together, the work provides essential steps towards identifying and controlling if and how models detect and resolve conflicting signals within complex multimodal environments.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01790",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning to model other minds",
    "description": "We‚Äôre releasing an algorithm which accounts for the fact that other agents are learning too, and discovers self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner‚Äôs dilemma. This algorithm, Learning with Opponent-Learning Awareness (LOLA), is a small step towards agents that model other minds.",
    "summary": "We‚Äôre releasing an algorithm which accounts for the fact that other agents are learning too, and discovers self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner‚Äôs dilemma. This algorithm, Learning with Opponent-Learning Awareness (LOLA), is a small step towards agents that model other minds.",
    "pubDate": "Thu, 14 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-model-other-minds",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy models on AWS Inferentia2 from Hugging Face",
    "description": "",
    "summary": "Deploy models on AWS Inferentia2 from Hugging Face AWS Inferentia2 is the latest AWS machine learnin...",
    "pubDate": "Wed, 22 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inferentia-inference-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/inferentia-inference-endpoints/thumbnail.jpg"
  },
  {
    "title": "Optimizing Stable Diffusion for Intel CPUs with NNCF and ü§ó Optimum",
    "description": "",
    "summary": "Optimizing Stable Diffusion for Intel CPUs with NNCF and ü§ó Optimum Latent Diffusion models are game ...",
    "pubDate": "Thu, 25 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-optimize-sd-intel",
    "thumbnail": "https://huggingface.co/blog/assets/train_optimize_sd_intel/thumbnail.png"
  },
  {
    "title": "Learning dexterity",
    "description": "We‚Äôve trained a human-like robot hand to manipulate physical objects with unprecedented¬†dexterity.",
    "summary": "We‚Äôve trained a human-like robot hand to manipulate physical objects with unprecedented¬†dexterity.",
    "pubDate": "Mon, 30 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-dexterity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Semi-supervised knowledge transfer for deep learning from private training data",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/semi-supervised-knowledge-transfer-for-deep-learning-from-private-training-data",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "We‚Äôre improving Ask Photos and bringing it to more Google Photos users.",
    "description": "Animation showing a search in Ask Photos for 'Photos that'd make great phone backgrounds,' then a grid of initial results followed by the most relevant photos.",
    "summary": "Animation showing a search in Ask Photos for 'Photos that'd make great phone backgrounds,' then a grid of initial results followed by the most relevant photos.",
    "pubDate": "Thu, 26 Jun 2025 17:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/photos/updates-ask-photos-search/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/wagtailvideo-mbcag8qi_thumb.jpg"
  },
  {
    "title": "Disrupting malicious uses of AI: June 2025",
    "description": "In our June 2025 update, we outline how we‚Äôre disrupting malicious uses of AI‚Äîthrough safety tools that detect and counter abuse, support democratic values, and promote responsible AI deployment for the benefit of all.",
    "summary": "In our June 2025 update, we outline how we‚Äôre disrupting malicious uses of AI‚Äîthrough safety tools that detect and counter abuse, support democratic values, and promote responsible AI deployment for the benefit of all.",
    "pubDate": "Thu, 05 Jun 2025 02:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai-june-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deep Learning with Proteins",
    "description": "",
    "summary": "Deep Learning With Proteins I have two audiences in mind while writing this. One is biologists who a...",
    "pubDate": "Fri, 02 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-learning-with-proteins",
    "thumbnail": "https://huggingface.co/blog/assets/119_deep_learning_with_proteins/folding_example.png"
  },
  {
    "title": "Deep research System Card",
    "description": "This report outlines the safety work carried out prior to releasing deep research including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "summary": "This report outlines the safety work carried out prior to releasing deep research including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "pubDate": "Tue, 25 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-research-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI„ÄÅÁ´∂ÊäÄ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„ÄåAtCoder„Äç‰∏ñÁïåÂ§ß‰ºö„ÅÆ„Çπ„Éù„É≥„Çµ„Éº„Å´„ÄÄ‰∫∫Èñì vs. AI„ÅÆ„Ç®„Ç≠„Ç∑„Éì„Ç∑„Éß„É≥„Éû„ÉÉ„ÉÅ„ÇÇ",
    "description": "Á´∂ÊäÄ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„Ç≥„É≥„ÉÜ„Çπ„Éà„Çµ„Ç§„Éà„ÄåAtCoder„Äç„ÇíÈÅãÂñ∂„Åô„ÇãAtCoderÁ§æ„ÅØ„ÄÅÂêåÁ§æ„Åå‰∏ªÂÇ¨„Åô„Çã‰∏ñÁïåÂ§ß‰ºö„ÄåAtCoder World Tour Finals 2025„Äç„Å´„ÄÅÁ±≥OpenAI„Åå„Çπ„Éù„É≥„Çµ„Éº„Å®„Åó„Å¶ÂèÇÁîª„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ",
    "summary": "Á´∂ÊäÄ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„Ç≥„É≥„ÉÜ„Çπ„Éà„Çµ„Ç§„Éà„ÄåAtCoder„Äç„ÇíÈÅãÂñ∂„Åô„ÇãAtCoderÁ§æ„ÅØ„ÄÅÂêåÁ§æ„Åå‰∏ªÂÇ¨„Åô„Çã‰∏ñÁïåÂ§ß‰ºö„ÄåAtCoder World Tour Finals 2025„Äç„Å´„ÄÅÁ±≥OpenAI„Åå„Çπ„Éù„É≥„Çµ„Éº„Å®„Åó„Å¶ÂèÇÁîª„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ",
    "pubDate": "Wed, 02 Jul 2025 14:26:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/02/news072.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/02/cover_news072.jpg"
  },
  {
    "title": "Fetch Consolidates AI Tools and Saves 30% Development Time with Hugging Face on AWS",
    "description": "",
    "summary": "Fetch Consolidates AI Tools and Saves 30% Development Time with Hugging Face on AWS If you need supp...",
    "pubDate": "Thu, 23 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fetch-eap-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/fetch2.png"
  },
  {
    "title": "Introducing Gemini 2.0: our new AI model for the agentic era",
    "description": "Today, we‚Äôre announcing Gemini 2.0, our most capable multimodal AI model yet.",
    "summary": "Today, we‚Äôre announcing Gemini 2.0, our most capable multimodal AI model yet.",
    "pubDate": "Wed, 11 Dec 2024 15:30:40 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-20-our-new-ai-model-for-the-agentic-era/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/blog_gemini_hero_thumbnail.width-1300.png"
  },
  {
    "title": "Identifying AI-generated images with SynthID",
    "description": "New tool helps watermark and identify synthetic images created by Imagen",
    "summary": "New tool helps watermark and identify synthetic images created by Imagen",
    "pubDate": "Tue, 29 Aug 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/identifying-ai-generated-images-with-synthid/",
    "thumbnail": "https://lh3.googleusercontent.com/wUgtK2GBt2yZJ3dJkXtvAK84G93j6idOOalyihOMfwBxY0lR650fZZYIi3bXdgkKbBcitbUZ0ILbaIPg_-vDTgAJLlP1DO3h_UnyoZ27wl3mYSzKtw=w1200-h630-n-nu"
  },
  {
    "title": "Why OpenAI‚Äôs structure must evolve to advance our mission",
    "description": "A stronger non-profit supported by the for-profit‚Äôs success.",
    "summary": "A stronger non-profit supported by the for-profit‚Äôs success.",
    "pubDate": "Fri, 27 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/why-our-structure-must-evolve-to-advance-our-mission",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning concepts with energy functions",
    "description": "We‚Äôve developed an¬†energy-based model¬†that can quickly learn to identify and generate instances of concepts, such as near, above, between, closest, and furthest, expressed as sets of 2d points. Our model learns these concepts after only five demonstrations. We also show cross-domain transfer: we use concepts learned in a 2d particle environment to solve tasks on a 3-dimensional physics-based¬†robot.",
    "summary": "We‚Äôve developed an¬†energy-based model¬†that can quickly learn to identify and generate instances of concepts, such as near, above, between, closest, and furthest, expressed as sets of 2d points. Our model learns these concepts after only five demonstrations. We also show cross-domain transfer: we use concepts learned in a 2d particle environment to solve tasks on a 3-dimensional physics-based¬†robot.",
    "pubDate": "Wed, 07 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-concepts-with-energy-functions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "5 tips for getting started with Flow",
    "description": "Flow-generated video showing two astronaut pugs driving a car in outer space, with text overlaid saying 'Find your Flow'",
    "summary": "Flow-generated video showing two astronaut pugs driving a car in outer space, with text overlaid saying 'Find your Flow'",
    "pubDate": "Wed, 25 Jun 2025 22:45:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/flow-video-tips/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GetStartedwithFlow_SS.width-1300.png"
  },
  {
    "title": "AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation",
    "description": "arXiv:2507.01961v1 Announce Type: cross Abstract: Recently, mobile manipulation has attracted increasing attention for enabling language-conditioned robotic control in household tasks. However, existing methods still face challenges in coordinating mobile base and manipulator, primarily due to two limitations. On the one hand, they fail to explicitly model the influence of the mobile base on manipulator control, which easily leads to error accumulation under high degrees of freedom. On the other hand, they treat the entire mobile manipulation process with the same visual observation modality (e.g., either all 2D or all 3D), overlooking the distinct multimodal perception requirements at different stages during mobile manipulation. To address this, we propose the Adaptive Coordination Diffusion Transformer (AC-DiT), which enhances mobile base and manipulator coordination for end-to-end mobile manipulation. First, since the motion of the mobile base directly influences the manipulator's actions, we introduce a mobility-to-body conditioning mechanism that guides the model to first extract base motion representations, which are then used as context prior for predicting whole-body actions. This enables whole-body control that accounts for the potential impact of the mobile base's motion. Second, to meet the perception requirements at different stages of mobile manipulation, we design a perception-aware multimodal conditioning strategy that dynamically adjusts the fusion weights between various 2D visual images and 3D point clouds, yielding visual features tailored to the current perceptual needs. This allows the model to, for example, adaptively rely more on 2D inputs when semantic information is crucial for action prediction, while placing greater emphasis on 3D geometric information when precise spatial understanding is required. We validate AC-DiT through extensive experiments on both simulated and real-world mobile manipulation tasks.",
    "summary": "arXiv:2507.01961v1 Announce Type: cross Abstract: Recently, mobile manipulation has attracted increasing attention for enabling language-conditioned robotic control in household tasks. However, existing methods still face challenges in coordinating mobile base and manipulator, primarily due to two limitations. On the one hand, they fail to explicitly model the influence of the mobile base on manipulator control, which easily leads to error accumulation under high degrees of freedom. On the other hand, they treat the entire mobile manipulation process with the same visual observation modality (e.g., either all 2D or all 3D), overlooking the distinct multimodal perception requirements at different stages during mobile manipulation. To address this, we propose the Adaptive Coordination Diffusion Transformer (AC-DiT), which enhances mobile base and manipulator coordination for end-to-end mobile manipulation. First, since the motion of the mobile base directly influences the manipulator's actions, we introduce a mobility-to-body conditioning mechanism that guides the model to first extract base motion representations, which are then used as context prior for predicting whole-body actions. This enables whole-body control that accounts for the potential impact of the mobile base's motion. Second, to meet the perception requirements at different stages of mobile manipulation, we design a perception-aware multimodal conditioning strategy that dynamically adjusts the fusion weights between various 2D visual images and 3D point clouds, yielding visual features tailored to the current perceptual needs. This allows the model to, for example, adaptively rely more on 2D inputs when semantic information is crucial for action prediction, while placing greater emphasis on 3D geometric information when precise spatial understanding is required. We validate AC-DiT through extensive experiments on both simulated and real-world mobile manipulation tasks.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01961",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerating Stable Diffusion Inference on Intel CPUs",
    "description": "",
    "summary": "Accelerating Stable Diffusion Inference on Intel CPUs Recently, we introduced the latest generation ...",
    "pubDate": "Tue, 28 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-inference-intel",
    "thumbnail": "https://huggingface.co/blog/assets/136_stable_diffusion_inference_intel/01.png"
  },
  {
    "title": "Penalizing Transparency? How AI Disclosure and Author Demographics Shape Human and AI Judgments About Writing",
    "description": "arXiv:2507.01418v1 Announce Type: cross Abstract: As AI integrates in various types of human writing, calls for transparency around AI assistance are growing. However, if transparency operates on uneven ground and certain identity groups bear a heavier cost for being honest, then the burden of openness becomes asymmetrical. This study investigates how AI disclosure statement affects perceptions of writing quality, and whether these effects vary by the author's race and gender. Through a large-scale controlled experiment, both human raters (n = 1,970) and LLM raters (n = 2,520) evaluated a single human-written news article while disclosure statements and author demographics were systematically varied. This approach reflects how both human and algorithmic decisions now influence access to opportunities (e.g., hiring, promotion) and social recognition (e.g., content recommendation algorithms). We find that both human and LLM raters consistently penalize disclosed AI use. However, only LLM raters exhibit demographic interaction effects: they favor articles attributed to women or Black authors when no disclosure is present. But these advantages disappear when AI assistance is revealed. These findings illuminate the complex relationships between AI disclosure and author identity, highlighting disparities between machine and human evaluation patterns.",
    "summary": "arXiv:2507.01418v1 Announce Type: cross Abstract: As AI integrates in various types of human writing, calls for transparency around AI assistance are growing. However, if transparency operates on uneven ground and certain identity groups bear a heavier cost for being honest, then the burden of openness becomes asymmetrical. This study investigates how AI disclosure statement affects perceptions of writing quality, and whether these effects vary by the author's race and gender. Through a large-scale controlled experiment, both human raters (n = 1,970) and LLM raters (n = 2,520) evaluated a single human-written news article while disclosure statements and author demographics were systematically varied. This approach reflects how both human and algorithmic decisions now influence access to opportunities (e.g., hiring, promotion) and social recognition (e.g., content recommendation algorithms). We find that both human and LLM raters consistently penalize disclosed AI use. However, only LLM raters exhibit demographic interaction effects: they favor articles attributed to women or Black authors when no disclosure is present. But these advantages disappear when AI assistance is revealed. These findings illuminate the complex relationships between AI disclosure and author identity, highlighting disparities between machine and human evaluation patterns.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01418",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Stochastic Neural Networks for hierarchical reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 10 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/stochastic-neural-networks-for-hierarchical-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Beyond First-Order: Training LLMs with Stochastic Conjugate Subgradients and AdamW",
    "description": "arXiv:2507.01241v1 Announce Type: cross Abstract: Stochastic gradient-based descent (SGD), have long been central to training large language models (LLMs). However, their effectiveness is increasingly being questioned, particularly in large-scale applications where empirical evidence suggests potential performance limitations. In response, this paper proposes a stochastic conjugate subgradient method together with adaptive sampling tailored specifically for training LLMs. The method not only achieves faster convergence per iteration but also demonstrates improved scalability compared to traditional SGD techniques. It leverages sample complexity analysis to adaptively choose the sample size, employs a stochastic conjugate subgradient approach to determine search directions and utilizing an AdamW-like algorithm to adaptively adjust step sizes. This approach preserves the key advantages of first-order methods while effectively addressing the nonconvexity and non-smoothness inherent in LLMs training. Additionally, we provide a detailed analysis of the advantage of the algorithm. Experimental results show that the proposed method not only maintains, but in many cases surpasses, the scalability of traditional SGD techniques, significantly enhancing both the speed and accuracy of the optimization process.",
    "summary": "arXiv:2507.01241v1 Announce Type: cross Abstract: Stochastic gradient-based descent (SGD), have long been central to training large language models (LLMs). However, their effectiveness is increasingly being questioned, particularly in large-scale applications where empirical evidence suggests potential performance limitations. In response, this paper proposes a stochastic conjugate subgradient method together with adaptive sampling tailored specifically for training LLMs. The method not only achieves faster convergence per iteration but also demonstrates improved scalability compared to traditional SGD techniques. It leverages sample complexity analysis to adaptively choose the sample size, employs a stochastic conjugate subgradient approach to determine search directions and utilizing an AdamW-like algorithm to adaptively adjust step sizes. This approach preserves the key advantages of first-order methods while effectively addressing the nonconvexity and non-smoothness inherent in LLMs training. Additionally, we provide a detailed analysis of the advantage of the algorithm. Experimental results show that the proposed method not only maintains, but in many cases surpasses, the scalability of traditional SGD techniques, significantly enhancing both the speed and accuracy of the optimization process.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01241",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Variance reduction for policy gradient with action-dependent factorized baselines",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 20 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variance-reduction-for-policy-gradient-with-action-dependent-factorized-baselines",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Divergent Creativity in Humans and Large Language Models",
    "description": "arXiv:2405.13012v2 Announce Type: replace-cross Abstract: The recent surge of Large Language Models (LLMs) has led to claims that they are approaching a level of creativity akin to human capabilities. This idea has sparked a blend of excitement and apprehension. However, a critical piece that has been missing in this discourse is a systematic evaluation of LLMs' semantic diversity, particularly in comparison to human divergent thinking. To bridge this gap, we leverage recent advances in computational creativity to analyze semantic divergence in both state-of-the-art LLMs and a substantial dataset of 100,000 humans. We found evidence that LLMs can surpass average human performance on the Divergent Association Task, and approach human creative writing abilities, though they fall short of the typical performance of highly creative humans. Notably, even the top performing LLMs are still largely surpassed by highly creative individuals, underscoring a ceiling that current LLMs still fail to surpass. Our human-machine benchmarking framework addresses the polemic surrounding the imminent replacement of human creative labour by AI, disentangling the quality of the respective creative linguistic outputs using established objective measures. While prompting deeper exploration of the distinctive elements of human inventive thought compared to those of AI systems, we lay out a series of techniques to improve their outputs with respect to semantic diversity, such as prompt design and hyper-parameter tuning.",
    "summary": "arXiv:2405.13012v2 Announce Type: replace-cross Abstract: The recent surge of Large Language Models (LLMs) has led to claims that they are approaching a level of creativity akin to human capabilities. This idea has sparked a blend of excitement and apprehension. However, a critical piece that has been missing in this discourse is a systematic evaluation of LLMs' semantic diversity, particularly in comparison to human divergent thinking. To bridge this gap, we leverage recent advances in computational creativity to analyze semantic divergence in both state-of-the-art LLMs and a substantial dataset of 100,000 humans. We found evidence that LLMs can surpass average human performance on the Divergent Association Task, and approach human creative writing abilities, though they fall short of the typical performance of highly creative humans. Notably, even the top performing LLMs are still largely surpassed by highly creative individuals, underscoring a ceiling that current LLMs still fail to surpass. Our human-machine benchmarking framework addresses the polemic surrounding the imminent replacement of human creative labour by AI, disentangling the quality of the respective creative linguistic outputs using established objective measures. While prompting deeper exploration of the distinctive elements of human inventive thought compared to those of AI systems, we lay out a series of techniques to improve their outputs with respect to semantic diversity, such as prompt design and hyper-parameter tuning.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.13012",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "StarCoder2 and The Stack v2",
    "description": "",
    "summary": "StarCoder2 and The Stack v2 BigCode is releasing StarCoder2, the next generation of transparently tr...",
    "pubDate": "Wed, 28 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starcoder2",
    "thumbnail": "https://huggingface.co/blog/assets/177_starcoder2/sc2-banner.png"
  },
  {
    "title": "Neural MMO: A massively multiagent game environment",
    "description": "We‚Äôre releasing a Neural¬†MMO, a massively multiagent game environment for reinforcement learning agents. Our platform supports a large, variable number of agents within a persistent and open-ended task. The inclusion of many agents and species leads to better exploration, divergent niche formation, and greater overall¬†competence.",
    "summary": "We‚Äôre releasing a Neural¬†MMO, a massively multiagent game environment for reinforcement learning agents. Our platform supports a large, variable number of agents within a persistent and open-ended task. The inclusion of many agents and species leads to better exploration, divergent niche formation, and greater overall¬†competence.",
    "pubDate": "Mon, 04 Mar 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/neural-mmo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI hackathon",
    "description": "Come to OpenAI‚Äôs office in San Francisco‚Äôs Mission District for talks and a hackathon on Saturday, March 3rd.",
    "summary": "Come to OpenAI‚Äôs office in San Francisco‚Äôs Mission District for talks and a hackathon on Saturday, March 3rd.",
    "pubDate": "Thu, 22 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-hackathon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ethical guidelines for developing the Diffusers library",
    "description": "",
    "summary": "Ethical guidelines for developing the Diffusers library We are on a journey to make our libraries mo...",
    "pubDate": "Thu, 02 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/ethics-diffusers/thumbnail.png"
  },
  {
    "title": "Using OpenAI o1 for financial analysis",
    "description": "Rogo scales AI-driven financial research with OpenAI o1",
    "summary": "Rogo scales AI-driven financial research with OpenAI o1",
    "pubDate": "Thu, 13 Feb 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rogo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Nystr√∂mformer, Approximating self-attention in linear time and memory via the Nystr√∂m method",
    "description": "",
    "summary": "Nystr√∂mformer: Approximating self-attention in linear time and memory via the Nystr√∂m method Introdu...",
    "pubDate": "Tue, 02 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nystromformer",
    "thumbnail": "https://huggingface.co/blog/assets/86_nystromformer/thumbnail.png"
  },
  {
    "title": "OpenAI and GEDI partner for Italian news content",
    "description": "OpenAI and GEDI announce strategic partnership to bring Italian-language news content to ChatGPT.",
    "summary": "OpenAI and GEDI announce strategic partnership to bring Italian-language news content to ChatGPT.",
    "pubDate": "Thu, 26 Sep 2024 04:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gedi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Helping machines understand visual content with AI",
    "description": "Coactive, founded by two MIT alumni, has built an AI-powered platform to unlock new insights from content of all types.",
    "summary": "Coactive, founded by two MIT alumni, has built an AI-powered platform to unlock new insights from content of all types.",
    "pubDate": "Mon, 09 Jun 2025 15:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/coactive-helps-machines-understand-visual-content-ai-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Coactive-AI-01-press.jpg"
  },
  {
    "title": "The power of personalized AI",
    "description": "The power of personalized AI",
    "summary": "The power of personalized AI",
    "pubDate": "Fri, 17 Jan 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/the-power-of-personalized-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Jupyter X Hugging Face",
    "description": "",
    "summary": "Jupyter X Hugging Face We‚Äôre excited to announce improved support for Jupyter notebooks hosted on th...",
    "pubDate": "Thu, 23 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/notebooks-hub",
    "thumbnail": "https://huggingface.co/blog/assets/135_notebooks-hub/before_after_notebook_rendering.png"
  },
  {
    "title": "Embedding AI into developer software",
    "description": "JetBrains uses OpenAI‚Äôs API to build its fastest-growing product ever.",
    "summary": "JetBrains uses OpenAI‚Äôs API to build its fastest-growing product ever.",
    "pubDate": "Thu, 21 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jetbrains",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaQubit tackles one of quantum computing‚Äôs biggest challenges",
    "description": "Our new AI system accurately identifies errors inside quantum computers, helping to make this new technology more reliable.",
    "summary": "Our new AI system accurately identifies errors inside quantum computers, helping to make this new technology more reliable.",
    "pubDate": "Wed, 20 Nov 2024 18:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaqubit-tackles-one-of-quantum-computings-biggest-challenges/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Social_Share_Image_-_1920_x_1080.width-1300.png"
  },
  {
    "title": "KatFishNet: Detecting LLM-Generated Korean Text through Linguistic Feature Analysis",
    "description": "arXiv:2503.00032v4 Announce Type: replace-cross Abstract: The rapid advancement of large language models (LLMs) increases the difficulty of distinguishing between human-written and LLM-generated text. Detecting LLM-generated text is crucial for upholding academic integrity, preventing plagiarism, protecting copyrights, and ensuring ethical research practices. Most prior studies on detecting LLM-generated text focus primarily on English text. However, languages with distinct morphological and syntactic characteristics require specialized detection approaches. Their unique structures and usage patterns can hinder the direct application of methods primarily designed for English. Among such languages, we focus on Korean, which has relatively flexible spacing rules, a rich morphological system, and less frequent comma usage compared to English. We introduce KatFish, the first benchmark dataset for detecting LLM-generated Korean text. The dataset consists of text written by humans and generated by four LLMs across three genres. By examining spacing patterns, part-of-speech diversity, and comma usage, we illuminate the linguistic differences between human-written and LLM-generated Korean text. Building on these observations, we propose KatFishNet, a detection method specifically designed for the Korean language. KatFishNet achieves an average of 19.78% higher AUROC compared to the best-performing existing detection method. Our code and data are available at https://github.com/Shinwoo-Park/detecting_llm_generated_korean_text_through_linguistic_analysis.",
    "summary": "arXiv:2503.00032v4 Announce Type: replace-cross Abstract: The rapid advancement of large language models (LLMs) increases the difficulty of distinguishing between human-written and LLM-generated text. Detecting LLM-generated text is crucial for upholding academic integrity, preventing plagiarism, protecting copyrights, and ensuring ethical research practices. Most prior studies on detecting LLM-generated text focus primarily on English text. However, languages with distinct morphological and syntactic characteristics require specialized detection approaches. Their unique structures and usage patterns can hinder the direct application of methods primarily designed for English. Among such languages, we focus on Korean, which has relatively flexible spacing rules, a rich morphological system, and less frequent comma usage compared to English. We introduce KatFish, the first benchmark dataset for detecting LLM-generated Korean text. The dataset consists of text written by humans and generated by four LLMs across three genres. By examining spacing patterns, part-of-speech diversity, and comma usage, we illuminate the linguistic differences between human-written and LLM-generated Korean text. Building on these observations, we propose KatFishNet, a detection method specifically designed for the Korean language. KatFishNet achieves an average of 19.78% higher AUROC compared to the best-performing existing detection method. Our code and data are available at https://github.com/Shinwoo-Park/detecting_llm_generated_korean_text_through_linguistic_analysis.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.00032",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Zico Kolter Joins OpenAI‚Äôs Board of Directors",
    "description": "Zico Kolter Joins OpenAI‚Äôs Board of Directors We‚Äôre strengthening our governance with expertise in AI safety and alignment. Zico will also join the Safety & Security Committee",
    "summary": "Zico Kolter Joins OpenAI‚Äôs Board of Directors We‚Äôre strengthening our governance with expertise in AI safety and alignment. Zico will also join the Safety & Security Committee",
    "pubDate": "Thu, 08 Aug 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zico-kolter-joins-openais-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Data Science Approach to Calcutta High Court Judgments: An Efficient LLM and RAG-powered Framework for Summarization and Similar Cases Retrieval",
    "description": "arXiv:2507.01058v1 Announce Type: cross Abstract: The judiciary, as one of democracy's three pillars, is dealing with a rising amount of legal issues, needing careful use of judicial resources. This research presents a complex framework that leverages Data Science methodologies, notably Large Language Models (LLM) and Retrieval-Augmented Generation (RAG) techniques, to improve the efficiency of analyzing Calcutta High Court verdicts. Our framework focuses on two key aspects: first, the creation of a robust summarization mechanism that distills complex legal texts into concise and coherent summaries; and second, the development of an intelligent system for retrieving similar cases, which will assist legal professionals in research and decision making. By fine-tuning the Pegasus model using case head note summaries, we achieve significant improvements in the summarization of legal cases. Our two-step summarizing technique preserves crucial legal contexts, allowing for the production of a comprehensive vector database for RAG. The RAG-powered framework efficiently retrieves similar cases in response to user queries, offering thorough overviews and summaries. This technique not only improves legal research efficiency, but it also helps legal professionals and students easily acquire and grasp key legal information, benefiting the overall legal scenario.",
    "summary": "arXiv:2507.01058v1 Announce Type: cross Abstract: The judiciary, as one of democracy's three pillars, is dealing with a rising amount of legal issues, needing careful use of judicial resources. This research presents a complex framework that leverages Data Science methodologies, notably Large Language Models (LLM) and Retrieval-Augmented Generation (RAG) techniques, to improve the efficiency of analyzing Calcutta High Court verdicts. Our framework focuses on two key aspects: first, the creation of a robust summarization mechanism that distills complex legal texts into concise and coherent summaries; and second, the development of an intelligent system for retrieving similar cases, which will assist legal professionals in research and decision making. By fine-tuning the Pegasus model using case head note summaries, we achieve significant improvements in the summarization of legal cases. Our two-step summarizing technique preserves crucial legal contexts, allowing for the production of a comprehensive vector database for RAG. The RAG-powered framework efficiently retrieves similar cases in response to user queries, offering thorough overviews and summaries. This technique not only improves legal research efficiency, but it also helps legal professionals and students easily acquire and grasp key legal information, benefiting the overall legal scenario.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01058",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Put AI to work for your product team",
    "description": "Put AI to work for your product team",
    "summary": "Put AI to work for your product team",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/put-ai-to-work-for-your-product-team",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Five",
    "description": "Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota¬†2.",
    "summary": "Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota¬†2.",
    "pubDate": "Mon, 25 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and AWS partner to make AI more accessible",
    "description": "",
    "summary": "Hugging Face and AWS partner to make AI more accessible It‚Äôs time to make AI open and accessible to ...",
    "pubDate": "Tue, 21 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aws-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/131_aws-partnership/aws-partnership-thumbnail.png"
  },
  {
    "title": "Answering quantum physics questions with OpenAI o1",
    "description": "Quantum physicist Mario Krenn uses OpenAI o1 to help answer life's biggest questions.",
    "summary": "Quantum physicist Mario Krenn uses OpenAI o1 to help answer life's biggest questions.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-quantum-physics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Adapting Rule Representation With Four-Parameter Beta Distribution for Learning Classifier Systems",
    "description": "arXiv:2506.03602v2 Announce Type: replace-cross Abstract: Rule representations significantly influence the search capabilities and decision boundaries within the search space of Learning Classifier Systems (LCSs), a family of rule-based machine learning systems that evolve interpretable models through evolutionary processes. However, it is very difficult to choose an appropriate rule representation for each problem. Additionally, some problems benefit from using different representations for different subspaces within the input space. Thus, an adaptive mechanism is needed to choose an appropriate rule representation for each rule in LCSs. This article introduces a flexible rule representation using a four-parameter beta distribution and integrates it into a fuzzy-style LCS. The four-parameter beta distribution can form various function shapes, and this flexibility enables our LCS to automatically select appropriate representations for different subspaces. Our rule representation can represent crisp/fuzzy decision boundaries in various boundary shapes, such as rectangles and bells, by controlling four parameters, compared to the standard representations such as trapezoidal ones. Leveraging this flexibility, our LCS is designed to adapt the appropriate rule representation for each subspace. Moreover, our LCS incorporates a generalization bias favoring crisp rules where feasible, enhancing model interpretability without compromising accuracy. Experimental results on real-world classification tasks show that our LCS achieves significantly superior test accuracy and produces more compact rule sets. Our implementation is available at https://github.com/YNU-NakataLab/Beta4-UCS. An extended abstract related to this work is available at https://doi.org/10.36227/techrxiv.174900805.59801248/v1.",
    "summary": "arXiv:2506.03602v2 Announce Type: replace-cross Abstract: Rule representations significantly influence the search capabilities and decision boundaries within the search space of Learning Classifier Systems (LCSs), a family of rule-based machine learning systems that evolve interpretable models through evolutionary processes. However, it is very difficult to choose an appropriate rule representation for each problem. Additionally, some problems benefit from using different representations for different subspaces within the input space. Thus, an adaptive mechanism is needed to choose an appropriate rule representation for each rule in LCSs. This article introduces a flexible rule representation using a four-parameter beta distribution and integrates it into a fuzzy-style LCS. The four-parameter beta distribution can form various function shapes, and this flexibility enables our LCS to automatically select appropriate representations for different subspaces. Our rule representation can represent crisp/fuzzy decision boundaries in various boundary shapes, such as rectangles and bells, by controlling four parameters, compared to the standard representations such as trapezoidal ones. Leveraging this flexibility, our LCS is designed to adapt the appropriate rule representation for each subspace. Moreover, our LCS incorporates a generalization bias favoring crisp rules where feasible, enhancing model interpretability without compromising accuracy. Experimental results on real-world classification tasks show that our LCS achieves significantly superior test accuracy and produces more compact rule sets. Our implementation is available at https://github.com/YNU-NakataLab/Beta4-UCS. An extended abstract related to this work is available at https://doi.org/10.36227/techrxiv.174900805.59801248/v1.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.03602",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Governance of superintelligence",
    "description": "Now is a good time to start thinking about the governance of superintelligence‚Äîfuture AI systems dramatically more capable than even AGI.",
    "summary": "Now is a good time to start thinking about the governance of superintelligence‚Äîfuture AI systems dramatically more capable than even AGI.",
    "pubDate": "Mon, 22 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/governance-of-superintelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Join us for OpenAI‚Äôs first developer conference on November 6 in San Francisco",
    "description": "Developer registration for in-person attendance will open in the coming weeks and developers everywhere will be able to livestream the keynote.",
    "summary": "Developer registration for in-person attendance will open in the coming weeks and developers everywhere will be able to livestream the keynote.",
    "pubDate": "Wed, 06 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/announcing-openai-devday",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster TensorFlow models in Hugging Face Transformers",
    "description": "",
    "summary": "Faster TensorFlow models in Hugging Face Transformers In the last few months, the Hugging Face team ...",
    "pubDate": "Tue, 26 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-serving",
    "thumbnail": "https://huggingface.co/blog/assets/10_tf-serving/thumbnail.png"
  },
  {
    "title": "An update on disrupting deceptive uses of AI",
    "description": "OpenAI‚Äôs mission is to ensure that artificial general intelligence benefits all of humanity. We are dedicated to identifying, preventing, and disrupting attempts to abuse our models for harmful ends.",
    "summary": "OpenAI‚Äôs mission is to ensure that artificial general intelligence benefits all of humanity. We are dedicated to identifying, preventing, and disrupting attempts to abuse our models for harmful ends.",
    "pubDate": "Wed, 09 Oct 2024 03:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/an-update-on-disrupting-deceptive-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Continual Learning with Strategic Selection and Forgetting for Network Intrusion Detection",
    "description": "arXiv:2412.16264v4 Announce Type: replace-cross Abstract: Intrusion Detection Systems (IDS) are crucial for safeguarding digital infrastructure. In dynamic network environments, both threat landscapes and normal operational behaviors are constantly changing, resulting in concept drift. While continuous learning mitigates the adverse effects of concept drift, insufficient attention to drift patterns and excessive preservation of outdated knowledge can still hinder the IDS's adaptability. In this paper, we propose SSF (Strategic Selection and Forgetting), a novel continual learning method for IDS, providing continuous model updates with a constantly refreshed memory buffer. Our approach features a strategic sample selection algorithm to select representative new samples and a strategic forgetting mechanism to drop outdated samples. The proposed strategic sample selection algorithm prioritizes new samples that cause the `drifted' pattern, enabling the model to better understand the evolving landscape. Additionally, we introduce strategic forgetting upon detecting significant drift by discarding outdated samples to free up memory, allowing the incorporation of more recent data. SSF captures evolving patterns effectively and ensures the model is aligned with the change of data patterns, significantly enhancing the IDS's adaptability to concept drift. The state-of-the-art performance of SSF on NSL-KDD and UNSW-NB15 datasets demonstrates its superior adaptability to concept drift for network intrusion detection. The code is released at https://github.com/xinchen930/SSF-Strategic-Selection-and-Forgetting.",
    "summary": "arXiv:2412.16264v4 Announce Type: replace-cross Abstract: Intrusion Detection Systems (IDS) are crucial for safeguarding digital infrastructure. In dynamic network environments, both threat landscapes and normal operational behaviors are constantly changing, resulting in concept drift. While continuous learning mitigates the adverse effects of concept drift, insufficient attention to drift patterns and excessive preservation of outdated knowledge can still hinder the IDS's adaptability. In this paper, we propose SSF (Strategic Selection and Forgetting), a novel continual learning method for IDS, providing continuous model updates with a constantly refreshed memory buffer. Our approach features a strategic sample selection algorithm to select representative new samples and a strategic forgetting mechanism to drop outdated samples. The proposed strategic sample selection algorithm prioritizes new samples that cause the `drifted' pattern, enabling the model to better understand the evolving landscape. Additionally, we introduce strategic forgetting upon detecting significant drift by discarding outdated samples to free up memory, allowing the incorporation of more recent data. SSF captures evolving patterns effectively and ensures the model is aligned with the change of data patterns, significantly enhancing the IDS's adaptability to concept drift. The state-of-the-art performance of SSF on NSL-KDD and UNSW-NB15 datasets demonstrates its superior adaptability to concept drift for network intrusion detection. The code is released at https://github.com/xinchen930/SSF-Strategic-Selection-and-Forgetting.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.16264",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models",
    "description": "",
    "summary": "Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models Florence-2, released by Mic...",
    "pubDate": "Mon, 24 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/finetune-florence2",
    "thumbnail": "https://huggingface.co/blog/assets/182_finetune-florence/thumbnail.png"
  },
  {
    "title": "Competitive programming with AlphaCode",
    "description": "Solving novel problems and setting a new milestone in competitive programming.",
    "summary": "Solving novel problems and setting a new milestone in competitive programming.",
    "pubDate": "Thu, 08 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/competitive-programming-with-alphacode/",
    "thumbnail": "https://lh3.googleusercontent.com/vQ0Ow6LwCpigfPyTGUhXEfdMBWPyHmaCo7eoQW7bv3QoZXW6EIj18FPiCLI1vlMYlUAOvEXta1KSkl8P2KScquYJb-Dm_QygP9kdlLYkpF4nVyEH=w1200-h630-n-nu"
  },
  {
    "title": "Evaluating social and ethical risks from generative AI",
    "description": "Introducing a context-based framework for comprehensively evaluating the social and ethical risks of AI systems",
    "summary": "Introducing a context-based framework for comprehensively evaluating the social and ethical risks of AI systems",
    "pubDate": "Thu, 19 Oct 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/evaluating-social-and-ethical-risks-from-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/LAqM0ZkFzkDefB5oVEEPoq6p--7XcfBWEDPjl6OdcfvwN9q3leY2qWCf30_MquTn5RfpcPswiAoRns2jOKjB5_8u-vl6TqueSwamEM6U-qyJHOiujkI=w1200-h630-n-nu"
  },
  {
    "title": "Fine-Tuning Gemma Models in Hugging Face",
    "description": "",
    "summary": "Fine-Tuning Gemma Models in Hugging Face We recently announced that Gemma, the open weights language...",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma-peft",
    "thumbnail": "https://huggingface.co/blog/assets/gemma-peft/thumbnail.png"
  },
  {
    "title": "Introducing Hugging Face for Education",
    "description": "",
    "summary": "Introducing Hugging Face for Education ü§ó Given that machine learning will make up the overwhelming m...",
    "pubDate": "Mon, 25 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/education",
    "thumbnail": "https://huggingface.co/blog/assets/61_education/thumbnail.png"
  },
  {
    "title": "Real-Time Emergency Vehicle Siren Detection with Efficient CNNs on Embedded Hardware",
    "description": "arXiv:2507.01563v1 Announce Type: cross Abstract: We present a full-stack emergency vehicle (EV) siren detection system designed for real-time deployment on embedded hardware. The proposed approach is based on E2PANNs, a fine-tuned convolutional neural network derived from EPANNs, and optimized for binary sound event detection under urban acoustic conditions. A key contribution is the creation of curated and semantically structured datasets - AudioSet-EV, AudioSet-EV Augmented, and Unified-EV - developed using a custom AudioSet-Tools framework to overcome the low reliability of standard AudioSet annotations. The system is deployed on a Raspberry Pi 5 equipped with a high-fidelity DAC+microphone board, implementing a multithreaded inference engine with adaptive frame sizing, probability smoothing, and a decision-state machine to control false positive activations. A remote WebSocket interface provides real-time monitoring and facilitates live demonstration capabilities. Performance is evaluated using both framewise and event-based metrics across multiple configurations. Results show the system achieves low-latency detection with improved robustness under realistic audio conditions. This work demonstrates the feasibility of deploying IoS-compatible SED solutions that can form distributed acoustic monitoring networks, enabling collaborative emergency vehicle tracking across smart city infrastructures through WebSocket connectivity on low-cost edge devices.",
    "summary": "arXiv:2507.01563v1 Announce Type: cross Abstract: We present a full-stack emergency vehicle (EV) siren detection system designed for real-time deployment on embedded hardware. The proposed approach is based on E2PANNs, a fine-tuned convolutional neural network derived from EPANNs, and optimized for binary sound event detection under urban acoustic conditions. A key contribution is the creation of curated and semantically structured datasets - AudioSet-EV, AudioSet-EV Augmented, and Unified-EV - developed using a custom AudioSet-Tools framework to overcome the low reliability of standard AudioSet annotations. The system is deployed on a Raspberry Pi 5 equipped with a high-fidelity DAC+microphone board, implementing a multithreaded inference engine with adaptive frame sizing, probability smoothing, and a decision-state machine to control false positive activations. A remote WebSocket interface provides real-time monitoring and facilitates live demonstration capabilities. Performance is evaluated using both framewise and event-based metrics across multiple configurations. Results show the system achieves low-latency detection with improved robustness under realistic audio conditions. This work demonstrates the feasibility of deploying IoS-compatible SED solutions that can form distributed acoustic monitoring networks, enabling collaborative emergency vehicle tracking across smart city infrastructures through WebSocket connectivity on low-cost edge devices.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01563",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI and Future partner on specialist content",
    "description": "OpenAI and Future, the global platform for specialist media, have today announced a strategic partnership to bring content from Future‚Äôs 200 plus media brands to OpenAI‚Äôs users.",
    "summary": "OpenAI and Future, the global platform for specialist media, have today announced a strategic partnership to bring content from Future‚Äôs 200 plus media brands to OpenAI‚Äôs users.",
    "pubDate": "Wed, 04 Dec 2024 23:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-future-partner-on-specialist-content",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Cloudflare„ÄÅAIÊôÇ‰ª£„ÅÆ„ÇØ„É™„Ç®„Ç§„Çø„ÉºÊîØÊè¥Á≠ñ„ÇíÁô∫Ë°® „Äå„Ç≥„É≥„ÉÜ„É≥„ÉÑÁã¨Á´ãË®òÂøµÊó•„ÄçÂÆ£Ë®Ä",
    "description": "Cloudflare„ÅØ7Êúà1Êó•„Å´„Äå„Ç≥„É≥„ÉÜ„É≥„ÉÑÁã¨Á´ãË®òÂøµÊó•„Äç„ÇíÂÆ£Ë®Ä„Åó„ÄÅAIÊôÇ‰ª£„Å´„Åä„Åë„Çã„ÇØ„É™„Ç®„Ç§„Çø„Éº„ÅÆÊ®©Âà©‰øùË≠∑„Å®ÂèéÁõäÂåñ„ÇíÊîØÊè¥„Åô„ÇãÊñ∞ÊßãÊÉ≥„ÇíÁô∫Ë°®„Åó„Åü„ÄÇAI„ÇØ„É≠„Éº„É©„Éº„Çí„Éá„Éï„Ç©„É´„Éà„Åß„Éñ„É≠„ÉÉ„ÇØ„Åó„ÄÅ„Ç≥„É≥„ÉÜ„É≥„ÉÑÂà©Áî®„Å´Âøú„Åò„Å¶Ë™≤Èáë„Åô„Çã„Äåpay per crawl„Äç„ÅÆÂ∞éÂÖ•„Å™„Å©„ÇíÁõÆÊåá„Åô„ÄÇ",
    "summary": "Cloudflare„ÅØ7Êúà1Êó•„Å´„Äå„Ç≥„É≥„ÉÜ„É≥„ÉÑÁã¨Á´ãË®òÂøµÊó•„Äç„ÇíÂÆ£Ë®Ä„Åó„ÄÅAIÊôÇ‰ª£„Å´„Åä„Åë„Çã„ÇØ„É™„Ç®„Ç§„Çø„Éº„ÅÆÊ®©Âà©‰øùË≠∑„Å®ÂèéÁõäÂåñ„ÇíÊîØÊè¥„Åô„ÇãÊñ∞ÊßãÊÉ≥„ÇíÁô∫Ë°®„Åó„Åü„ÄÇAI„ÇØ„É≠„Éº„É©„Éº„Çí„Éá„Éï„Ç©„É´„Éà„Åß„Éñ„É≠„ÉÉ„ÇØ„Åó„ÄÅ„Ç≥„É≥„ÉÜ„É≥„ÉÑÂà©Áî®„Å´Âøú„Åò„Å¶Ë™≤Èáë„Åô„Çã„Äåpay per crawl„Äç„ÅÆÂ∞éÂÖ•„Å™„Å©„ÇíÁõÆÊåá„Åô„ÄÇ",
    "pubDate": "Wed, 02 Jul 2025 07:38:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2507/02/news046.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2507/02/cover_news046.jpg"
  },
  {
    "title": "PixelCNN++: Improving the PixelCNN with discretized logistic mixture likelihood and other modifications",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 19 Jan 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/pixelcnn-plus-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Transforming the future of music creation",
    "description": "Announcing our most advanced music generation model and two new AI experiments, designed to open a new playground for creativity",
    "summary": "Announcing our most advanced music generation model and two new AI experiments, designed to open a new playground for creativity",
    "pubDate": "Thu, 16 Nov 2023 07:20:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/",
    "thumbnail": "https://lh3.googleusercontent.com/msr-Fc99rrkeoQkZ6rLTKnof3RTqo5oo9D2_xPyqtpp0mAMqqkn-x3mPy2dD0My1g7w-cysBQzHU_iWF4mlblU4EgQRcMNKoBUgPdmdmEoyekFJEnA=w1200-h630-n-nu"
  },
  {
    "title": "Habana Labs and Hugging Face Partner to Accelerate Transformer Model Training",
    "description": "",
    "summary": "Habana Labs and Hugging Face Partner to Accelerate Transformer Model Training Santa Clara and San Fr...",
    "pubDate": "Tue, 12 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana",
    "thumbnail": "https://huggingface.co/blog/assets/60_habana/habana.png"
  },
  {
    "title": "Introducing OpenAI o3 and o4-mini",
    "description": "Our smartest and most capable models to date with full tool access",
    "summary": "Our smartest and most capable models to date with full tool access",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-o3-and-o4-mini",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Artificial intelligence enhances air mobility planning",
    "description": "Lincoln Laboratory is transitioning tools to the 618th Air Operations Center to streamline global transport logistics.",
    "summary": "Lincoln Laboratory is transitioning tools to the 618th Air Operations Center to streamline global transport logistics.",
    "pubDate": "Fri, 25 Apr 2025 12:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/artificial-intelligence-enhances-air-mobility-planning-0425",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-lincoln-lab-us-air-mobility-00.jpg"
  },
  {
    "title": "Adversarial training methods for semi-supervised text classification",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 25 May 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adversarial-training-methods-for-semi-supervised-text-classification",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Using multi-agent architecture to mitigate the risk of LLM hallucinations",
    "description": "arXiv:2507.01446v1 Announce Type: new Abstract: Improving customer service quality and response time are critical factors for maintaining customer loyalty and increasing a company's market share. While adopting emerging technologies such as Large Language Models (LLMs) is becoming a necessity to achieve these goals, the risk of hallucination remains a major challenge. In this paper, we present a multi-agent system to handle customer requests sent via SMS. This system integrates LLM based agents with fuzzy logic to mitigate hallucination risks.",
    "summary": "arXiv:2507.01446v1 Announce Type: new Abstract: Improving customer service quality and response time are critical factors for maintaining customer loyalty and increasing a company's market share. While adopting emerging technologies such as Large Language Models (LLMs) is becoming a necessity to achieve these goals, the risk of hallucination remains a major challenge. In this paper, we present a multi-agent system to handle customer requests sent via SMS. This system integrates LLM based agents with fuzzy logic to mitigate hallucination risks.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01446",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MCCoder: Streamlining Motion Control with LLM-Assisted Code Generation and Rigorous Verification",
    "description": "arXiv:2410.15154v3 Announce Type: replace Abstract: Large Language Models (LLMs) have demonstrated significant potential in code generation. However, in the factory automation sector, particularly motion control, manual programming, alongside inefficient and unsafe debugging practices, remains prevalent. This stems from the complex interplay of mechanical and electrical systems and stringent safety requirements. Moreover, most current AI-assisted motion control programming efforts focus on PLCs, with little attention given to high-level languages and function libraries. To address these challenges, we introduce MCCoder, an LLM-powered system tailored for generating motion control code, integrated with a soft-motion controller. MCCoder improves code generation through a structured workflow that combines multitask decomposition, hybrid retrieval-augmented generation (RAG), and iterative self-correction, utilizing a well-established motion library. Additionally, it integrates a 3D simulator for intuitive motion validation and logs of full motion trajectories for data verification, significantly enhancing accuracy and safety. In the absence of benchmark datasets and metrics tailored for evaluating motion control code generation, we propose MCEVAL, a dataset spanning motion tasks of varying complexity. Experiments show that MCCoder outperforms baseline models using Advanced RAG, achieving an overall performance gain of 33.09% and a 131.77% improvement on complex tasks in the MCEVAL dataset.",
    "summary": "arXiv:2410.15154v3 Announce Type: replace Abstract: Large Language Models (LLMs) have demonstrated significant potential in code generation. However, in the factory automation sector, particularly motion control, manual programming, alongside inefficient and unsafe debugging practices, remains prevalent. This stems from the complex interplay of mechanical and electrical systems and stringent safety requirements. Moreover, most current AI-assisted motion control programming efforts focus on PLCs, with little attention given to high-level languages and function libraries. To address these challenges, we introduce MCCoder, an LLM-powered system tailored for generating motion control code, integrated with a soft-motion controller. MCCoder improves code generation through a structured workflow that combines multitask decomposition, hybrid retrieval-augmented generation (RAG), and iterative self-correction, utilizing a well-established motion library. Additionally, it integrates a 3D simulator for intuitive motion validation and logs of full motion trajectories for data verification, significantly enhancing accuracy and safety. In the absence of benchmark datasets and metrics tailored for evaluating motion control code generation, we propose MCEVAL, a dataset spanning motion tasks of varying complexity. Experiments show that MCCoder outperforms baseline models using Advanced RAG, achieving an overall performance gain of 33.09% and a 131.77% improvement on complex tasks in the MCEVAL dataset.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.15154",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-enabled control system helps autonomous drones stay on target in uncertain environments",
    "description": "The system automatically learns to adapt to unknown disturbances such as gusting winds.",
    "summary": "The system automatically learns to adapt to unknown disturbances such as gusting winds.",
    "pubDate": "Mon, 09 Jun 2025 16:40:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-enabled-control-system-helps-autonomous-drones-uncertain-environments-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_MetaLearning-01.jpg"
  },
  {
    "title": "Delivering high-performance customer support",
    "description": "Decagon and OpenAI deliver high-performance, fully automated customer support at scale",
    "summary": "Decagon and OpenAI deliver high-performance, fully automated customer support at scale",
    "pubDate": "Tue, 29 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/decagon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Multimodal neurons in artificial neural networks",
    "description": "We‚Äôve discovered neurons in CLIP that respond to the same concept whether presented literally, symbolically, or conceptually. This may explain CLIP‚Äôs accuracy in classifying surprising visual renditions of concepts, and is also an important step toward understanding the associations and biases that CLIP and similar models learn.",
    "summary": "We‚Äôve discovered neurons in CLIP that respond to the same concept whether presented literally, symbolically, or conceptually. This may explain CLIP‚Äôs accuracy in classifying surprising visual renditions of concepts, and is also an important step toward understanding the associations and biases that CLIP and similar models learn.",
    "pubDate": "Thu, 04 Mar 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/multimodal-neurons",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Complete Guide to Audio Datasets",
    "description": "",
    "summary": "A Complete Guide to Audio Datasets Introduction ü§ó Datasets is an open-source library for downloading...",
    "pubDate": "Thu, 15 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/audio-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/116_audio_datasets/thumbnail.jpg"
  },
  {
    "title": "More on Dota 2",
    "description": "Our Dota 2 result shows that self-play can catapult the performance of machine learning systems from far below human level to superhuman, given sufficient compute. In the span of a month, our system went from barely matching a high-ranked player to beating the top pros and has continued to improve since then. Supervised deep learning systems can only be as good as their training datasets, but in self-play systems, the available data improves automatically as the agent gets better.",
    "summary": "Our Dota 2 result shows that self-play can catapult the performance of machine learning systems from far below human level to superhuman, given sufficient compute. In the span of a month, our system went from barely matching a high-ranked player to beating the top pros and has continued to improve since then. Supervised deep learning systems can only be as good as their training datasets, but in self-play systems, the available data improves automatically as the agent gets better.",
    "pubDate": "Wed, 16 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/more-on-dota-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing AutoRound: Intel‚Äôs Advanced Quantization for LLMs and VLMs",
    "description": "",
    "summary": "What is AutoRound? As large language models (LLMs) and vision-language models (VLMs) continue to gro...",
    "pubDate": "Tue, 29 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autoround",
    "thumbnail": "https://huggingface.co/blog/assets/autoround/thumbnail.png"
  },
  {
    "title": "ArmÊê≠ËºâAIÂçäÂ∞é‰Ωì„ÅÆËøÖÈÄü„Å™ÈñãÁô∫„ÇíÊîØÊè¥„ÄÅOKI„Ç¢„Ç§„Éá„Ç£„Ç®„Çπ",
    "description": "OKI„Ç¢„Ç§„Éá„Ç£„Ç®„ÇπÔºàOIDSÔºâ„ÅØ„ÄÅArm„Å®„ÄåArm Approved Design Partner„ÄçÂ•ëÁ¥Ñ„ÇíÁµê„Çì„Å†„ÄÇArm„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÊê≠Ëºâ„Åó„ÅüASICÔºèLSI„ÅÆÈñãÁô∫„ÇíË®àÁîª„Åó„Å¶„ÅÑ„ÇãÈ°ßÂÆ¢„Å´ÂØæ„Åó„ÄÅOIDS„ÅØFPGA„ÇíÊ¥ªÁî®„Åó„Åü„Éó„É≠„Éà„Çø„Ç§„Éó„ÅÆÈñãÁô∫„ÉªÊ§úË®º„Çµ„Éº„Éì„Çπ„ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Åè„ÄÇ",
    "summary": "OKI„Ç¢„Ç§„Éá„Ç£„Ç®„ÇπÔºàOIDSÔºâ„ÅØ„ÄÅArm„Å®„ÄåArm Approved Design Partner„ÄçÂ•ëÁ¥Ñ„ÇíÁµê„Çì„Å†„ÄÇArm„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£„ÇíÊê≠Ëºâ„Åó„ÅüASICÔºèLSI„ÅÆÈñãÁô∫„ÇíË®àÁîª„Åó„Å¶„ÅÑ„ÇãÈ°ßÂÆ¢„Å´ÂØæ„Åó„ÄÅOIDS„ÅØFPGA„ÇíÊ¥ªÁî®„Åó„Åü„Éó„É≠„Éà„Çø„Ç§„Éó„ÅÆÈñãÁô∫„ÉªÊ§úË®º„Çµ„Éº„Éì„Çπ„ÇíÊèê‰æõ„Åó„Å¶„ÅÑ„Åè„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 15:30:00 +0900",
    "source": "ITmedia AI",
    "url": "https://eetimes.itmedia.co.jp/ee/articles/2507/03/news032.html",
    "thumbnail": "https://image.itmedia.co.jp/ee/articles/2507/03/cover_news032.jpg"
  },
  {
    "title": "Google DeepMind at NeurIPS 2024",
    "description": "Advancing adaptive AI agents, empowering 3D scene creation, and innovating LLM training for a smarter, safer future",
    "summary": "Advancing adaptive AI agents, empowering 3D scene creation, and innovating LLM training for a smarter, safer future",
    "pubDate": "Thu, 05 Dec 2024 17:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-neurips-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/cKpWE16vpsZ21VcH-_SdGF8tQEeEMp2phWFajdBq_A7aMVS2axiXQzd7V8mlHdJm-CXVKh1IaY3yeM_lAwu_zxc6SIBdWahdN6nYoaQqUbC8uU0qoY8=w1200-h630-n-nu"
  },
  {
    "title": "Non-engineers guide: Train a LLaMA 2 chatbot",
    "description": "",
    "summary": "Non-engineers guide: Train a LLaMA 2 chatbot Introduction In this tutorial we will show you how anyo...",
    "pubDate": "Thu, 28 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/Llama2-for-non-engineers",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/tuto.png"
  },
  {
    "title": "Introducing SafeCoder",
    "description": "",
    "summary": "Introducing SafeCoder Today we are excited to announce SafeCoder - a code assistant solution built f...",
    "pubDate": "Tue, 22 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safecoder",
    "thumbnail": "https://huggingface.co/blog/assets/159_safecoder/thumbnail.jpg"
  },
  {
    "title": "Introducing TextImage Augmentation for Document Images",
    "description": "",
    "summary": "Introducing Multimodal TextImage Augmentation for Document Images In this blog post, we provide a tu...",
    "pubDate": "Tue, 06 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/doc_aug_hf_alb",
    "thumbnail": "https://huggingface.co/blog/assets/185_albumentations/thumbnail.png"
  },
  {
    "title": "Gemini 2.5: Our most intelligent models are getting even better",
    "description": "Gemini 2.5 Pro continues to be loved by developers as the best model for coding, and 2.5 Flash is getting even better with a new update. We‚Äôre bringing new capabilities to our models, including Deep Think, an experimental enhanced reasoning mode for 2.5 Pro.",
    "summary": "Gemini 2.5 Pro continues to be loved by developers as the best model for coding, and 2.5 Flash is getting even better with a new update. We‚Äôre bringing new capabilities to our models, including Deep Think, an experimental enhanced reasoning mode for 2.5 Pro.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-our-world-leading-model-is-getting-even-better/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/deep-think__key-art_16-9.width-1300.jpg"
  },
  {
    "title": "Text-Generation Pipeline on Intel¬Æ Gaudi¬Æ 2 AI Accelerator",
    "description": "",
    "summary": "Text-Generation Pipeline on Intel¬Æ Gaudi¬Æ 2 AI Accelerator With the Generative AI (GenAI) revolution...",
    "pubDate": "Thu, 29 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/textgen-pipe-gaudi",
    "thumbnail": "https://huggingface.co/blog/assets/textgen-pipe-gaudi/thumbnail.png"
  },
  {
    "title": "Rethinking LLM Evaluation with 3C3H: AraGen Benchmark and Leaderboard",
    "description": "",
    "summary": "Rethinking LLM Evaluation with 3C3H: AraGen Benchmark and Leaderboard In the rapidly evolving landsc...",
    "pubDate": "Wed, 04 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-3c3h-aragen",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_3c3h_aragen.png"
  },
  {
    "title": "BigCodeBench: Benchmarking Large Language Models on Solving Practical and Challenging Programming Tasks",
    "description": "",
    "summary": "BigCodeBench: The Next Generation of HumanEval HumanEval is a reference benchmark for evaluating lar...",
    "pubDate": "Tue, 18 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-bigcodebench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_bigcode.png"
  },
  {
    "title": "Very Large Language Models and How to Evaluate Them",
    "description": "",
    "summary": "Very Large Language Models and How to Evaluate Them Large language models can now be evaluated on ze...",
    "pubDate": "Mon, 03 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-shot-eval-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/106_zero_shot_eval_on_the_hub/thumbnail.png"
  },
  {
    "title": "OpenAI‚Äôs EU Economic Blueprint",
    "description": "Today, OpenAI is sharing the EU Economic Blueprint‚Äîa set of proposals to help Europe seize the promise of artificial intelligence, drive sustainable economic growth across the region, and ensure that AI is developed and deployed by Europe, in Europe, for Europe.",
    "summary": "Today, OpenAI is sharing the EU Economic Blueprint‚Äîa set of proposals to help Europe seize the promise of artificial intelligence, drive sustainable economic growth across the region, and ensure that AI is developed and deployed by Europe, in Europe, for Europe.",
    "pubDate": "Mon, 07 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-eu-economic-blueprint",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Google DeepMind at NeurIPS 2023",
    "description": "The Neural Information Processing Systems (NeurIPS) is the largest artificial intelligence (AI) conference in the world. NeurIPS 2023 will be taking place December 10-16 in New Orleans, USA.Teams from across Google DeepMind are presenting more than 150 papers at the main conference and workshops.",
    "summary": "The Neural Information Processing Systems (NeurIPS) is the largest artificial intelligence (AI) conference in the world. NeurIPS 2023 will be taking place December 10-16 in New Orleans, USA.Teams from across Google DeepMind are presenting more than 150 papers at the main conference and workshops.",
    "pubDate": "Fri, 08 Dec 2023 15:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-neurips-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/MDme_Q62zVqvTUs5uwaI3Ggy2rWIujPt2elkusnUuCA4wEo79V9mabIg66j9cr9zMso-LObOVcj6_ZnrgSMUKn6fl52kxOUEjcigXtDZ2UMuosX3-2s=w1200-h630-n-nu"
  },
  {
    "title": "Build awesome datasets for video generation",
    "description": "",
    "summary": "Build awesome datasets for video generation Tooling for image generation datasets is well establishe...",
    "pubDate": "Wed, 12 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vid_ds_scripts",
    "thumbnail": "https://huggingface.co/blog/assets/vid_ds_scripts/thumbnail.png"
  },
  {
    "title": "How good are LLMs at fixing their mistakes? A chatbot arena experiment with Keras and TPUs",
    "description": "",
    "summary": "How good are LLMs at fixing their mistakes? A chatbot arena experiment with Keras and TPUs while you...",
    "pubDate": "Thu, 05 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-chatbot-arena",
    "thumbnail": "https://huggingface.co/blog/assets/keras-chatbot-arena/thumbnail.png"
  },
  {
    "title": "Shaping the future of advanced robotics",
    "description": "Introducing AutoRT, SARA-RT, and RT-Trajectory",
    "summary": "Introducing AutoRT, SARA-RT, and RT-Trajectory",
    "pubDate": "Thu, 04 Jan 2024 11:39:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotics/",
    "thumbnail": "https://lh3.googleusercontent.com/qeWlfSbr0jW0OsZ0dvaQK2V7tYM0HtTtwivx-fUJzK4GivdM6kffvNXlSgqOJyjAQWXBCycqF77zT7XDGxIqGvPiCnTqLX_C3VRmXGJIGGW5GAv7YQ=w1200-h630-n-nu"
  },
  {
    "title": "Supporting sellers with enhanced product listings",
    "description": "Mercari leverages GPT-4o mini and GPT-4 to streamline selling, enhance product listings, and boost sales, transforming the online marketplace with features like AI Listing Support and Mercari AI Assistant.",
    "summary": "Mercari leverages GPT-4o mini and GPT-4 to streamline selling, enhance product listings, and boost sales, transforming the online marketplace with features like AI Listing Support and Mercari AI Assistant.",
    "pubDate": "Thu, 27 Feb 2025 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mercari",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Open-Source Text Generation & LLM Ecosystem at Hugging Face",
    "description": "",
    "summary": "Open-Source Text Generation & LLM Ecosystem at Hugging Face [Updated on July 24, 2023: Added Llama 2...",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/os-llms",
    "thumbnail": "https://huggingface.co/blog/assets/os_llms/thumbnail.png"
  },
  {
    "title": "How OpenAI is approaching 2024 worldwide elections",
    "description": "We‚Äôre working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate voting information.",
    "summary": "We‚Äôre working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate voting information.",
    "pubDate": "Mon, 15 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-openai-is-approaching-2024-worldwide-elections",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving India‚Äôs critical care infrastructure",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 06 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/10bedicu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Safetensors audited as really safe and becoming the default",
    "description": "",
    "summary": "Audit shows that safetensors is safe and ready to become the default Hugging Face, in close collabor...",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safetensors-security-audit",
    "thumbnail": "https://huggingface.co/blog/assets/142_safetensors_official/thumbnail.png"
  },
  {
    "title": "Fit More and Train Faster With ZeRO via DeepSpeed and FairScale",
    "description": "",
    "summary": "Fit More and Train Faster With ZeRO via DeepSpeed and FairScale A guest blog post by Hugging Face fe...",
    "pubDate": "Tue, 19 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-deepspeed-fairscale",
    "thumbnail": "https://huggingface.co/blog/assets/11_zero_deepspeed_fairscale/zero-partitioning.png"
  },
  {
    "title": "LZ Penalty: An information-theoretic repetition penalty for autoregressive language models",
    "description": "arXiv:2504.20131v2 Announce Type: replace-cross Abstract: We introduce the LZ penalty, a penalty specialized for reducing degenerate repetitions in autoregressive language models without loss of capability. The penalty is based on the codelengths in the LZ77 universal lossless compression algorithm. Through the lens of the prediction-compression duality, decoding the LZ penalty has the interpretation of sampling from the residual distribution after removing the information that is highly compressible. We demonstrate the LZ penalty enables state-of-the-art open-source reasoning models to operate with greedy (temperature zero) decoding without loss of capability and without instances of degenerate repetition. Both the industry-standard frequency penalty and repetition penalty are ineffective, incurring degenerate repetition rates of up to 4%.",
    "summary": "arXiv:2504.20131v2 Announce Type: replace-cross Abstract: We introduce the LZ penalty, a penalty specialized for reducing degenerate repetitions in autoregressive language models without loss of capability. The penalty is based on the codelengths in the LZ77 universal lossless compression algorithm. Through the lens of the prediction-compression duality, decoding the LZ penalty has the interpretation of sampling from the residual distribution after removing the information that is highly compressible. We demonstrate the LZ penalty enables state-of-the-art open-source reasoning models to operate with greedy (temperature zero) decoding without loss of capability and without instances of degenerate repetition. Both the industry-standard frequency penalty and repetition penalty are ineffective, incurring degenerate repetition rates of up to 4%.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.20131",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fast Clifford Neural Layers",
    "description": "arXiv:2507.01040v1 Announce Type: cross Abstract: Clifford Neural Layers improve PDE modeling by introducing Clifford Algebra into neural networks. In this project we focus on optimizing the inference of 2/3D Clifford convolutional layers and multivector activation layers for one core CPU performance. Overall, by testing on a real network block involving Clifford convolutional layers and multivector activation layers, we observe that our implementation is 30% faster than standard PyTorch implementation in relatively large data + network size (>L2 cache). We open source our code base at https://github.com/egretwAlker/c-opt-clifford-layers",
    "summary": "arXiv:2507.01040v1 Announce Type: cross Abstract: Clifford Neural Layers improve PDE modeling by introducing Clifford Algebra into neural networks. In this project we focus on optimizing the inference of 2/3D Clifford convolutional layers and multivector activation layers for one core CPU performance. Overall, by testing on a real network block involving Clifford convolutional layers and multivector activation layers, we observe that our implementation is 30% faster than standard PyTorch implementation in relatively large data + network size (>L2 cache). We open source our code base at https://github.com/egretwAlker/c-opt-clifford-layers",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01040",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GamePad: A learning environment for theorem proving",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 02 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gamepad",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemma Scope: helping the safety community shed light on the inner workings of language models",
    "description": "Announcing a comprehensive, open suite of sparse autoencoders for language model interpretability.",
    "summary": "Announcing a comprehensive, open suite of sparse autoencoders for language model interpretability.",
    "pubDate": "Wed, 31 Jul 2024 15:59:19 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemma-scope-helping-the-safety-community-shed-light-on-the-inner-workings-of-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/4amJbS1Q5bh_CoBHPAc4NEn0Q13izqrskMETkJl3h2Jdku08GryCCjW6BM59OKj1-Q7-8ZFCWlgu7tIMzjRBIXImy8wlgTOxYgJ88fQvYJTye07C=w1200-h630-n-nu"
  },
  {
    "title": "ChatGPT plugins",
    "description": "We‚Äôve implemented initial support for plugins in ChatGPT. Plugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run computations, or use third-party services.",
    "summary": "We‚Äôve implemented initial support for plugins in ChatGPT. Plugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run computations, or use third-party services.",
    "pubDate": "Thu, 23 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-plugins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How we‚Äôre responding to The New York Times‚Äô data demands in order to protect user privacy",
    "description": "OpenAI is fighting a court order at the demands of The New York Times and plaintiffs, which involves retention of consumer ChatGPT and API user data indefinitely. Learn how we‚Äôre working to uphold user privacy, address legal requirements, and stay true to our data protection commitments.",
    "summary": "OpenAI is fighting a court order at the demands of The New York Times and plaintiffs, which involves retention of consumer ChatGPT and API user data indefinitely. Learn how we‚Äôre working to uphold user privacy, address legal requirements, and stay true to our data protection commitments.",
    "pubDate": "Thu, 05 Jun 2025 16:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/response-to-nyt-data-demands",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Remote VAEs for decoding with HF endpoints ü§ó",
    "description": "",
    "summary": "Remote VAEs for decoding with Inference Endpoints ü§ó When operating with latent-space diffusion model...",
    "pubDate": "Mon, 24 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/remote_vae",
    "thumbnail": "https://huggingface.co/blog/assets/remote_vae/thumbnail.png"
  },
  {
    "title": "Retro Contest",
    "description": "We‚Äôre launching a transfer learning contest that measures a reinforcement learning algorithm‚Äôs ability to generalize from previous experience.",
    "summary": "We‚Äôre launching a transfer learning contest that measures a reinforcement learning algorithm‚Äôs ability to generalize from previous experience.",
    "pubDate": "Thu, 05 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retro-contest",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Age Sensitive Hippocampal Functional Connectivity: New Insights from 3D CNNs and Saliency Mapping",
    "description": "arXiv:2507.01411v1 Announce Type: cross Abstract: Grey matter loss in the hippocampus is a hallmark of neurobiological aging, yet understanding the corresponding changes in its functional connectivity remains limited. Seed-based functional connectivity (FC) analysis enables voxel-wise mapping of the hippocampus's synchronous activity with cortical regions, offering a window into functional reorganization during aging. In this study, we develop an interpretable deep learning framework to predict brain age from hippocampal FC using a three-dimensional convolutional neural network (3D CNN) combined with LayerCAM saliency mapping. This approach maps key hippocampal-cortical connections, particularly with the precuneus, cuneus, posterior cingulate cortex, parahippocampal cortex, left superior parietal lobule, and right superior temporal sulcus, that are highly sensitive to age. Critically, disaggregating anterior and posterior hippocampal FC reveals distinct mapping aligned with their known functional specializations. These findings provide new insights into the functional mechanisms of hippocampal aging and demonstrate the power of explainable deep learning to uncover biologically meaningful patterns in neuroimaging data.",
    "summary": "arXiv:2507.01411v1 Announce Type: cross Abstract: Grey matter loss in the hippocampus is a hallmark of neurobiological aging, yet understanding the corresponding changes in its functional connectivity remains limited. Seed-based functional connectivity (FC) analysis enables voxel-wise mapping of the hippocampus's synchronous activity with cortical regions, offering a window into functional reorganization during aging. In this study, we develop an interpretable deep learning framework to predict brain age from hippocampal FC using a three-dimensional convolutional neural network (3D CNN) combined with LayerCAM saliency mapping. This approach maps key hippocampal-cortical connections, particularly with the precuneus, cuneus, posterior cingulate cortex, parahippocampal cortex, left superior parietal lobule, and right superior temporal sulcus, that are highly sensitive to age. Critically, disaggregating anterior and posterior hippocampal FC reveals distinct mapping aligned with their known functional specializations. These findings provide new insights into the functional mechanisms of hippocampal aging and demonstrate the power of explainable deep learning to uncover biologically meaningful patterns in neuroimaging data.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01411",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CO‚ÇÇ Emissions and Models Performance: Insights from the Open LLM Leaderboard",
    "description": "",
    "summary": "CO‚ÇÇ Emissions and Models Performance: Insights from the Open LLM Leaderboard Since June 2024, we hav...",
    "pubDate": "Thu, 09 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-emissions-analysis",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "The Transformers Library: standardizing model definitions",
    "description": "",
    "summary": "The Transformers Library: standardizing model definitions TLDR: Going forward, we're aiming for Tran...",
    "pubDate": "Thu, 15 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-model-definition",
    "thumbnail": "https://huggingface.co/blog/assets/transformers-model-definition/transformers-thumbnail.png"
  },
  {
    "title": "„Ç§„Éº„É≠„É≥„Éª„Éû„Çπ„ÇØÊ∞è„ÅÆxAI„Åå1.4ÂÖÜÂÜÜË™øÈÅî„ÄÄGrok„ÇÑ„Éá„Éº„Çø„Çª„É≥„Çø„Éº„ÅÆÈñãÁô∫Âä†ÈÄü",
    "description": "„Ç§„Éº„É≠„É≥„Éª„Éû„Çπ„ÇØÊ∞è„ÅÆAI‰ºÅÊ•≠xAI„Åå„ÄÅ100ÂÑÑ„Éâ„É´„ÇíË™øÈÅî„Åó„Åü„ÄÇÂçäÂàÜ„ÅØÁ§æÂÇµ„ÅÆÁô∫Ë°å„ÇÑÂÄü„ÇäÂÖ•„Çå„ÄÅ„ÇÇ„ÅÜÂçäÂàÜ„ÅØÊ†™ÂºèÁô∫Ë°å„Å´„Çà„Çã„ÇÇ„ÅÆ„ÄÇË™øÈÅî„Çí‰∏ªÂ∞é„Åó„ÅüÁ±≥Morgan Stanley„ÅåX„ÅßÊòé„Çâ„Åã„Å´„Åó„Åü„ÄÇ",
    "summary": "„Ç§„Éº„É≠„É≥„Éª„Éû„Çπ„ÇØÊ∞è„ÅÆAI‰ºÅÊ•≠xAI„Åå„ÄÅ100ÂÑÑ„Éâ„É´„ÇíË™øÈÅî„Åó„Åü„ÄÇÂçäÂàÜ„ÅØÁ§æÂÇµ„ÅÆÁô∫Ë°å„ÇÑÂÄü„ÇäÂÖ•„Çå„ÄÅ„ÇÇ„ÅÜÂçäÂàÜ„ÅØÊ†™ÂºèÁô∫Ë°å„Å´„Çà„Çã„ÇÇ„ÅÆ„ÄÇË™øÈÅî„Çí‰∏ªÂ∞é„Åó„ÅüÁ±≥Morgan Stanley„ÅåX„ÅßÊòé„Çâ„Åã„Å´„Åó„Åü„ÄÇ",
    "pubDate": "Tue, 01 Jul 2025 18:13:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2507/01/news104.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2507/01/cover_news104.jpg"
  },
  {
    "title": "Google DeepMind‚Äôs latest research at ICML 2023",
    "description": "Exploring AI safety, adaptability, and efficiency for the real world",
    "summary": "Exploring AI safety, adaptability, and efficiency for the real world",
    "pubDate": "Thu, 20 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-research-at-icml-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/5UyUwX8KGovLbTZ0Q8Ynf5Nepy-1zyFaVIIwB7ty0Cp1F5wrKrv24aOT91PDo1vpH3T4P0cwtUn1WxxvtU5vqd4J7cBwEK6UsvnTMNL_qramtFbsX28=w1200-h630-n-nu"
  },
  {
    "title": "RT-2: New model translates vision and language into action",
    "description": "Robotic Transformer 2 (RT-2) is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for robotic control.",
    "summary": "Robotic Transformer 2 (RT-2) is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for robotic control.",
    "pubDate": "Fri, 28 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/",
    "thumbnail": "https://lh3.googleusercontent.com/ZduBtQRn2mrvSfNqkixe2XktBREieIhekS7NcboCn0E76gFVckUwNLZw74EJ5jIndzxbRoCqCY47iW1-eGi5c_JJV1DFyTmkS91vMnRalgT0rih125s=w1200-h630-n-nu"
  },
  {
    "title": "„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï„ÄÄ7/9ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„ÄÅÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨",
    "description": "<p>AIsmiley„ÅØ„ÄÅ2025Âπ¥7Êúà9Êó•ÔºàÊ∞¥ÔºâÔΩû7Êúà11Êó•ÔºàÈáëÔºâ„Å´ÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨„ÅÆ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„Çπ„ÇíÂá∫Â±ï„Åó„Åæ„Åô„ÄÇ ‰ºöÂ†¥„Åß„ÅØ„ÄÅÊúÄÊñ∞„ÅÆAI„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥„ÇÑ„Éã„É•„Éº„ÇπÁ≠â„ÇíÂèñ„Çä‰∏ä„Åí„ÇãAI„Éù„Éº„Çø [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/'>„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï„ÄÄ7/9ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„ÄÅÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AIsmiley„ÅØ„ÄÅ2025Âπ¥7Êúà9Êó•ÔºàÊ∞¥ÔºâÔΩû7Êúà11Êó•ÔºàÈáëÔºâ„Å´ÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨„ÅÆ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„Çπ„ÇíÂá∫Â±ï„Åó„Åæ„Åô„ÄÇ ‰ºöÂ†¥„Åß„ÅØ„ÄÅÊúÄÊñ∞„ÅÆAI„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥„ÇÑ„Éã„É•„Éº„ÇπÁ≠â„ÇíÂèñ„Çä‰∏ä„Åí„ÇãAI„Éù„Éº„Çø [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/'>„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï„ÄÄ7/9ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„ÄÅÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 04:00:20 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/05/monodukuri-world-tokyo-no37.png"
  },
  {
    "title": "Stable Diffusion with üß® Diffusers",
    "description": "",
    "summary": "Stable Diffusion with üß® Diffusers Stable Diffusion üé® ...using üß® Diffusers Stable Diffusion is a text...",
    "pubDate": "Mon, 22 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable_diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/98_stable_diffusion/thumbnail.png"
  },
  {
    "title": "Sora System Card",
    "description": "Sora is OpenAI‚Äôs video generation model, designed to take text, image, and video inputs and generate a new video as an output. Sora builds on learnings from DALL-E and GPT models, and is designed to give people expanded tools for storytelling and creative expression.",
    "summary": "Sora is OpenAI‚Äôs video generation model, designed to take text, image, and video inputs and generate a new video as an output. Sora builds on learnings from DALL-E and GPT models, and is designed to give people expanded tools for storytelling and creative expression.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Aligning language models to follow instructions",
    "description": "We‚Äôve trained language models that are much better at following user intentions than GPT-3 while also making them more truthful and less toxic, using techniques developed through our alignment research. These¬†InstructGPT¬†models, which are trained with humans in the loop, are now deployed as the default language models on our¬†API.",
    "summary": "We‚Äôve trained language models that are much better at following user intentions than GPT-3 while also making them more truthful and less toxic, using techniques developed through our alignment research. These¬†InstructGPT¬†models, which are trained with humans in the loop, are now deployed as the default language models on our¬†API.",
    "pubDate": "Thu, 27 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/instruction-following",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI safety via debate",
    "description": "We‚Äôre proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.",
    "summary": "We‚Äôre proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.",
    "pubDate": "Thu, 03 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/debate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pollen-Vision: Unified interface for Zero-Shot vision models in robotics",
    "description": "",
    "summary": "Pollen-Vision: Unified interface for Zero-Shot vision models in robotics This is a guest blog post b...",
    "pubDate": "Mon, 25 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pollen-vision",
    "thumbnail": "https://huggingface.co/blog/assets/pollen-vision/thumbnail.jpg"
  },
  {
    "title": "How AI training scales",
    "description": "We‚Äôve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks. Since complex tasks tend to have noisier gradients, increasingly large batch sizes are likely to become useful in the future, removing one potential limit to further growth of AI systems. More broadly, these results show that neural network training need not be considered a mysterious art, but can be rigorized and¬†systematized.",
    "summary": "We‚Äôve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks. Since complex tasks tend to have noisier gradients, increasingly large batch sizes are likely to become useful in the future, removing one potential limit to further growth of AI systems. More broadly, these results show that neural network training need not be considered a mysterious art, but can be rigorized and¬†systematized.",
    "pubDate": "Fri, 14 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-ai-training-scales",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Don't repeat yourself - ü§ó Transformers Design Philosophy",
    "description": "",
    "summary": "Don't Repeat Yourself* Designing open-source libraries for modern machine learning ü§ó Transformers De...",
    "pubDate": "Tue, 05 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-design-philosophy",
    "thumbnail": "https://huggingface.co/blog/assets/59_transformers_philosophy/transformers.png"
  },
  {
    "title": "OpenAI and journalism",
    "description": "We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.",
    "summary": "We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.",
    "pubDate": "Mon, 08 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-journalism",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaGenome: AI for better understanding the genome",
    "description": "Introducing a new, unifying DNA sequence model that advances regulatory variant-effect prediction and promises to shed new light on genome function ‚Äî now available via API.",
    "summary": "Introducing a new, unifying DNA sequence model that advances regulatory variant-effect prediction and promises to shed new light on genome function ‚Äî now available via API.",
    "pubDate": "Wed, 25 Jun 2025 13:59:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/",
    "thumbnail": "https://lh3.googleusercontent.com/SZkcKUQyLUhSQ06Rq-PJbxAqn1OpMeEa3khkrBVB1MGyHfxyftoqWwEb2aLP9JxX7CjhpLFODcc5zIoMoNdu0bl6ELsZV2nP9fDwZC6SYS36lzAKDw=w1200-h630-n-nu"
  },
  {
    "title": "Introducing the Open Arabic LLM Leaderboard",
    "description": "",
    "summary": "Introducing the Open Arabic LLM Leaderboard The Open Arabic LLM Leaderboard (OALL) is designed to ad...",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-arabic",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_arabic.png"
  },
  {
    "title": "Speech Synthesis, Recognition, and More With SpeechT5",
    "description": "",
    "summary": "Speech Synthesis, Recognition, and More With SpeechT5 We‚Äôre happy to announce that SpeechT5 is now a...",
    "pubDate": "Wed, 08 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/speecht5",
    "thumbnail": "https://huggingface.co/blog/assets/speecht5/thumbnail.png"
  },
  {
    "title": "GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs",
    "description": "arXiv:2411.13757v4 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have revolutionized natural language processing (NLP), excelling in tasks like text generation and summarization. However, their increasing adoption in mission-critical applications raises concerns about hardware-based threats, particularly bit-flip attacks (BFAs). BFAs, enabled by fault injection methods such as Rowhammer, target model parameters in memory, compromising both integrity and performance. Identifying critical parameters for BFAs in the vast parameter space of LLMs poses significant challenges. While prior research suggests transformer-based architectures are inherently more robust to BFAs compared to traditional deep neural networks, we challenge this assumption. For the first time, we demonstrate that as few as three bit-flips can cause catastrophic performance degradation in an LLM with billions of parameters. Current BFA techniques are inadequate for exploiting this vulnerability due to the difficulty of efficiently identifying critical parameters within the immense parameter space. To address this, we propose AttentionBreaker, a novel framework tailored for LLMs that enables efficient traversal of the parameter space to identify critical parameters. Additionally, we introduce GenBFA, an evolutionary optimization strategy designed to refine the search further, isolating the most critical bits for an efficient and effective attack. Empirical results reveal the profound vulnerability of LLMs to AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% of total parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model result in a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to 0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findings underscore the effectiveness of AttentionBreaker in uncovering and exploiting critical vulnerabilities within LLM architectures.",
    "summary": "arXiv:2411.13757v4 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have revolutionized natural language processing (NLP), excelling in tasks like text generation and summarization. However, their increasing adoption in mission-critical applications raises concerns about hardware-based threats, particularly bit-flip attacks (BFAs). BFAs, enabled by fault injection methods such as Rowhammer, target model parameters in memory, compromising both integrity and performance. Identifying critical parameters for BFAs in the vast parameter space of LLMs poses significant challenges. While prior research suggests transformer-based architectures are inherently more robust to BFAs compared to traditional deep neural networks, we challenge this assumption. For the first time, we demonstrate that as few as three bit-flips can cause catastrophic performance degradation in an LLM with billions of parameters. Current BFA techniques are inadequate for exploiting this vulnerability due to the difficulty of efficiently identifying critical parameters within the immense parameter space. To address this, we propose AttentionBreaker, a novel framework tailored for LLMs that enables efficient traversal of the parameter space to identify critical parameters. Additionally, we introduce GenBFA, an evolutionary optimization strategy designed to refine the search further, isolating the most critical bits for an efficient and effective attack. Empirical results reveal the profound vulnerability of LLMs to AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% of total parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model result in a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to 0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findings underscore the effectiveness of AttentionBreaker in uncovering and exploiting critical vulnerabilities within LLM architectures.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.13757",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hierarchical text-conditional image generation with CLIP latents",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Apr 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hierarchical-text-conditional-image-generation-with-clip-latents",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating Audio Reasoning with Big Bench Audio",
    "description": "",
    "summary": "Evaluating Audio Reasoning with Big Bench Audio The emergence of native Speech to Speech models offe...",
    "pubDate": "Fri, 20 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/big-bench-audio-release",
    "thumbnail": "https://huggingface.co/blog/assets/big_bench_audio_release/big-bench-audio-thumbnail.png"
  },
  {
    "title": "Sentiment Classification with Fully Homomorphic Encryption using Concrete ML",
    "description": "",
    "summary": "Sentiment Analysis on Encrypted Data with Homomorphic Encryption It is well-known that a sentiment a...",
    "pubDate": "Thu, 17 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-fhe",
    "thumbnail": "https://huggingface.co/blog/assets/sentiment-analysis-fhe/thumbnail.png"
  },
  {
    "title": "Democratic inputs to AI grant program: lessons learned and implementation plans",
    "description": "We funded 10 teams from around the world to design ideas and tools to collectively govern AI. We summarize the innovations, outline our learnings, and call for researchers and engineers to join us as we continue this work.",
    "summary": "We funded 10 teams from around the world to design ideas and tools to collectively govern AI. We summarize the innovations, outline our learnings, and call for researchers and engineers to join us as we continue this work.",
    "pubDate": "Tue, 16 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/democratic-inputs-to-ai-grant-program-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Expert Support case study: Bolstering a RAG app with LLM-as-a-Judge",
    "description": "",
    "summary": "Expert Support case study: Bolstering a RAG app with LLM-as-a-Judge This is a guest blog post author...",
    "pubDate": "Mon, 28 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/digital-green-llm-judge",
    "thumbnail": "https://huggingface.co/blog/assets/digital-gren-llm-judge/thumbnail.png"
  },
  {
    "title": "Measuring Goodhart‚Äôs law",
    "description": "Goodhart‚Äôs law¬†famously says: ‚ÄúWhen a measure becomes a target, it ceases to be a good measure.‚Äù Although originally from economics, it‚Äôs something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
    "summary": "Goodhart‚Äôs law¬†famously says: ‚ÄúWhen a measure becomes a target, it ceases to be a good measure.‚Äù Although originally from economics, it‚Äôs something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
    "pubDate": "Wed, 13 Apr 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/measuring-goodharts-law",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Unsupervised sentiment neuron",
    "description": "We‚Äôve developed an unsupervised system which learns an excellent representation of sentiment, despite being trained only to predict the next character in the text of Amazon reviews.",
    "summary": "We‚Äôve developed an unsupervised system which learns an excellent representation of sentiment, despite being trained only to predict the next character in the text of Amazon reviews.",
    "pubDate": "Thu, 06 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/unsupervised-sentiment-neuron",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing ‚öîÔ∏è AI vs. AI ‚öîÔ∏è a deep reinforcement learning multi-agents competition system",
    "description": "",
    "summary": "Introducing ‚öîÔ∏è AI vs. AI ‚öîÔ∏è a deep reinforcement learning multi-agents competition system We‚Äôre exci...",
    "pubDate": "Tue, 07 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aivsai",
    "thumbnail": "https://huggingface.co/blog/assets/128_aivsai/thumbnail.png"
  },
  {
    "title": "Proximal Policy Optimization (PPO)",
    "description": "",
    "summary": "Proximal Policy Optimization (PPO) Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 8, of ...",
    "pubDate": "Fri, 05 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-ppo",
    "thumbnail": "https://huggingface.co/blog/assets/93_deep_rl_ppo/thumbnail.png"
  },
  {
    "title": "RL¬≤: Fast reinforcement learning via slow reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 09 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rl2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Large-scale study of curiosity-driven learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 13 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/large-scale-study-of-curiosity-driven-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI„Åå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Å´„ÄÅAIÂà©Áî®ËÄÖ„ÅÆÂçäÊï∞‰ª•‰∏ä„ÅåÂà©Áî®",
    "description": "<p>NEXER„Å®„Éù„Éº„É´„Éà„Ç•„Ç¶„Ç£„É≥„Åå„ÄÅÊôÆÊÆµAI„ÇíÂà©Áî®„Åô„ÇãÂÖ®ÂõΩ238Âêç„ÇíÂØæË±°„Å´ÂÆüÊñΩ„Åó„ÅüË™øÊüª„Åß„ÄÅÂçäÊï∞‰ª•‰∏ä„Åå„Äå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Äç„Å®„Åó„Å¶AI„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Çã„Å®Áô∫Ë°®„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà AIÂà©Áî®ËÄÖ„ÅÆ 51.3%„Åå„Äå„Éó„É© [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/use-ai-private-consultant/'>AI„Åå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Å´„ÄÅAIÂà©Áî®ËÄÖ„ÅÆÂçäÊï∞‰ª•‰∏ä„ÅåÂà©Áî®</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>NEXER„Å®„Éù„Éº„É´„Éà„Ç•„Ç¶„Ç£„É≥„Åå„ÄÅÊôÆÊÆµAI„ÇíÂà©Áî®„Åô„ÇãÂÖ®ÂõΩ238Âêç„ÇíÂØæË±°„Å´ÂÆüÊñΩ„Åó„ÅüË™øÊüª„Åß„ÄÅÂçäÊï∞‰ª•‰∏ä„Åå„Äå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Äç„Å®„Åó„Å¶AI„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Çã„Å®Áô∫Ë°®„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà AIÂà©Áî®ËÄÖ„ÅÆ 51.3%„Åå„Äå„Éó„É© [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/use-ai-private-consultant/'>AI„Åå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Å´„ÄÅAIÂà©Áî®ËÄÖ„ÅÆÂçäÊï∞‰ª•‰∏ä„ÅåÂà©Áî®</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Fri, 27 Jun 2025 05:08:11 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/use-ai-private-consultant/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/use-ai-private-consultant1.png"
  },
  {
    "title": "AI Testing and Evaluation: Learnings from genome editing",
    "description": "<p>Bioethics and law expert R. Alta Charo explores the value of regulating technologies at the application level and the role of coordinated oversight in genome editing, while Microsoft GM Daniel Kluttz reflects on Charo‚Äôs points, drawing parallels to AI governance.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/'>AI Testing and Evaluation: Learnings from genome editing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Bioethics and law expert R. Alta Charo explores the value of regulating technologies at the application level and the role of coordinated oversight in genome editing, while Microsoft GM Daniel Kluttz reflects on Charo‚Äôs points, drawing parallels to AI governance.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/'>AI Testing and Evaluation: Learnings from genome editing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Mon, 30 Jun 2025 16:00:17 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Reasoner for Real-World Event Detection: Scaling Reinforcement Learning via Adaptive Perplexity-Aware Sampling Strategy",
    "description": "arXiv:2507.01327v1 Announce Type: cross Abstract: Detecting abnormal events in real-world customer service dialogues is highly challenging due to the complexity of business data and the dynamic nature of customer interactions. Moreover, models must demonstrate strong out-of-domain (OOD) generalization to enable rapid adaptation across different business scenarios and maximize commercial value. In this work, we propose a novel Adaptive Perplexity-Aware Reinforcement Learning (APARL) framework that leverages the advanced reasoning capabilities of large language models for abnormal event detection. APARL introduces a dual-loop dynamic curriculum learning architecture, enabling the model to progressively focus on more challenging samples as its proficiency increases. This design effectively addresses performance bottlenecks and significantly enhances OOD transferability. Extensive evaluations on food delivery dialogue tasks show that our model achieves significantly enhanced adaptability and robustness, attaining the highest F1 score with an average improvement of 17.19%, and an average improvement of 9.59% in OOD transfer tests. This method provides a superior solution for industrial deployment of anomaly detection models, contributing to improved operational efficiency and commercial benefits.",
    "summary": "arXiv:2507.01327v1 Announce Type: cross Abstract: Detecting abnormal events in real-world customer service dialogues is highly challenging due to the complexity of business data and the dynamic nature of customer interactions. Moreover, models must demonstrate strong out-of-domain (OOD) generalization to enable rapid adaptation across different business scenarios and maximize commercial value. In this work, we propose a novel Adaptive Perplexity-Aware Reinforcement Learning (APARL) framework that leverages the advanced reasoning capabilities of large language models for abnormal event detection. APARL introduces a dual-loop dynamic curriculum learning architecture, enabling the model to progressively focus on more challenging samples as its proficiency increases. This design effectively addresses performance bottlenecks and significantly enhances OOD transferability. Extensive evaluations on food delivery dialogue tasks show that our model achieves significantly enhanced adaptability and robustness, attaining the highest F1 score with an average improvement of 17.19%, and an average improvement of 9.59% in OOD transfer tests. This method provides a superior solution for industrial deployment of anomaly detection models, contributing to improved operational efficiency and commercial benefits.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01327",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Team++",
    "description": "We've had some fantastic people join over the past few months (and we're still hiring). Welcome, everyone!",
    "summary": "We've had some fantastic people join over the past few months (and we're still hiring). Welcome, everyone!",
    "pubDate": "Thu, 31 Mar 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-plus-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Build rich, interactive web apps with an updated Gemini 2.5 Pro",
    "description": "Our updated version of Gemini 2.5 Pro Preview has improved capabilities for coding.",
    "summary": "Our updated version of Gemini 2.5 Pro Preview has improved capabilities for coding.",
    "pubDate": "Tue, 06 May 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/build-rich-interactive-web-apps-with-an-updated-gemini-25-pro/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini25prohero.width-1300.png"
  },
  {
    "title": "OpenAI Robotics Symposium 2019",
    "description": "We hosted the first OpenAI Robotics Symposium on April 27, 2019.",
    "summary": "We hosted the first OpenAI Robotics Symposium on April 27, 2019.",
    "pubDate": "Wed, 05 Jun 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/symposium-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI for Countries",
    "description": "A new initiative to support countries around the world that want to build on democratic AI rails.",
    "summary": "A new initiative to support countries around the world that want to build on democratic AI rails.",
    "pubDate": "Wed, 07 May 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-for-countries",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generating audio for video",
    "description": "Video-to-audio research uses video pixels and text prompts to generate rich soundtracks",
    "summary": "Video-to-audio research uses video pixels and text prompts to generate rich soundtracks",
    "pubDate": "Mon, 17 Jun 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/generating-audio-for-video/",
    "thumbnail": "https://lh3.googleusercontent.com/Lzihw4F171DQeSgZ9q0MUONzbt1BkbK1sOgnqvLAV3AUIQQ1UJ4niEXOTgWiiyKZrJaCpE4Q6APwV8RRQj7a86_2yDlbIV6WUzD6S_Gu2mjuZDyVWqo=w1200-h630-n-nu"
  },
  {
    "title": "Sora first impressions",
    "description": "Since we introduced Sora to the world last month, we‚Äôve been working with artists to learn how Sora might aid in their creative process.",
    "summary": "Since we introduced Sora to the world last month, we‚Äôve been working with artists to learn how Sora might aid in their creative process.",
    "pubDate": "Mon, 25 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-first-impressions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Illustrating Reinforcement Learning from Human Feedback (RLHF)",
    "description": "",
    "summary": "Illustrating Reinforcement Learning from Human Feedback (RLHF) This article has been translated to C...",
    "pubDate": "Fri, 09 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rlhf",
    "thumbnail": "https://huggingface.co/blog/assets/120_rlhf/thumbnail.png"
  },
  {
    "title": "Machine Learning Experts - Meg Mitchell Interview",
    "description": "",
    "summary": "Machine Learning Experts - Margaret Mitchell Hey friends! Welcome to Machine Learning Experts. I'm y...",
    "pubDate": "Wed, 23 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/meg-mitchell-interview",
    "thumbnail": "https://huggingface.co/blog/assets/57_meg_mitchell_interview/thumbnail.png"
  },
  {
    "title": "Combining technology, education, and human connection to improve online learning",
    "description": "Caitlin Morris, a PhD student and 2024 MAD Fellow affiliated with the MIT Media Lab, designs digital learning platforms that make room for the ‚Äúsocial magic‚Äù that influences curiosity and motivation.",
    "summary": "Caitlin Morris, a PhD student and 2024 MAD Fellow affiliated with the MIT Media Lab, designs digital learning platforms that make room for the ‚Äúsocial magic‚Äù that influences curiosity and motivation.",
    "pubDate": "Tue, 17 Jun 2025 16:25:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/caitlin-morris-combines-tech-education-human-connection-improve-online-learning-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-Caitlin-Morris.jpg"
  },
  {
    "title": "Training a language model with ü§ó Transformers using TensorFlow and TPUs",
    "description": "",
    "summary": "Training a language model with ü§ó Transformers using TensorFlow and TPUs Introduction TPU training is...",
    "pubDate": "Thu, 27 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf_tpu",
    "thumbnail": "https://huggingface.co/blog/assets/tf_tpu_training/thumbnail.png"
  },
  {
    "title": "OralBBNet: Spatially Guided Dental Segmentation of Panoramic X-Rays with Bounding Box Priors",
    "description": "arXiv:2406.03747v3 Announce Type: replace-cross Abstract: Teeth segmentation and recognition play a vital role in a variety of dental applications and diagnostic procedures. The integration of deep learning models has facilitated the development of precise and automated segmentation methods. Although prior research has explored teeth segmentation, not many methods have successfully performed tooth segmentation and detection simultaneously. This study presents UFBA-425, a dental dataset derived from the UFBA-UESC dataset, featuring bounding box and polygon annotations for 425 panoramic dental X-rays. In addition, this paper presents the OralBBNet architecture, which is based on the best segmentation and detection qualities of architectures such as U-Net and YOLOv8, respectively. OralBBNet is designed to improve the accuracy and robustness of tooth classification and segmentation on panoramic X-rays by leveraging the complementary strengths of U-Net and YOLOv8. Our approach achieved a 1-3% improvement in mean average precision (mAP) for tooth detection compared to existing techniques and a 15-20% improvement in the dice score for teeth segmentation over state-of-the-art (SOTA) solutions for various tooth categories and 2-4% improvement in the dice score compared to other SOTA segmentation architectures. The results of this study establish a foundation for the wider implementation of object detection models in dental diagnostics.",
    "summary": "arXiv:2406.03747v3 Announce Type: replace-cross Abstract: Teeth segmentation and recognition play a vital role in a variety of dental applications and diagnostic procedures. The integration of deep learning models has facilitated the development of precise and automated segmentation methods. Although prior research has explored teeth segmentation, not many methods have successfully performed tooth segmentation and detection simultaneously. This study presents UFBA-425, a dental dataset derived from the UFBA-UESC dataset, featuring bounding box and polygon annotations for 425 panoramic dental X-rays. In addition, this paper presents the OralBBNet architecture, which is based on the best segmentation and detection qualities of architectures such as U-Net and YOLOv8, respectively. OralBBNet is designed to improve the accuracy and robustness of tooth classification and segmentation on panoramic X-rays by leveraging the complementary strengths of U-Net and YOLOv8. Our approach achieved a 1-3% improvement in mean average precision (mAP) for tooth detection compared to existing techniques and a 15-20% improvement in the dice score for teeth segmentation over state-of-the-art (SOTA) solutions for various tooth categories and 2-4% improvement in the dice score compared to other SOTA segmentation architectures. The results of this study establish a foundation for the wider implementation of object detection models in dental diagnostics.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.03747",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„Ç®„Éº„Ç∏„Çß„É≥„ÉÜ„Ç£„ÉÉ„ÇØAIÂõ∫Êúâ„ÅÆË™≤È°å„Å®ÂØæÂá¶Ê≥ï„Çí„Åæ„Å®„ÇÅ„ÅüË≥áÊñô„ÇíCSA„ÅåÂÖ¨Èñã",
    "description": "CSA„Ç∏„É£„Éë„É≥„ÅØCSAÊú¨ÈÉ®„ÅåÂÖ¨Èñã„Åó„Åü„ÄåAgentic AI Red Teaming Guide„Äç„ÅÆÊó•Êú¨Ë™ûË®≥„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ„Åì„ÅÆ„Ç¨„Ç§„Éâ„ÅØ„Ç®„Éº„Ç∏„Çß„É≥„ÉÜ„Ç£„ÉÉ„ÇØAI„ÅÆ„É¨„ÉÉ„Éâ„ÉÅ„Éº„Éü„É≥„Ç∞ÊâãÊ≥ï„ÇíÊèê‰æõ„Åó„ÄÅ„Åù„ÅÆÁâπÊúâ„ÅÆ„É™„Çπ„ÇØ„Å®ËÑÜÂº±ÊÄß„Å´ÂØæÂá¶„Åô„Çã„Åü„ÇÅ„ÅÆÊåáÈáù„ÇíÁ§∫„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "CSA„Ç∏„É£„Éë„É≥„ÅØCSAÊú¨ÈÉ®„ÅåÂÖ¨Èñã„Åó„Åü„ÄåAgentic AI Red Teaming Guide„Äç„ÅÆÊó•Êú¨Ë™ûË®≥„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ„Åì„ÅÆ„Ç¨„Ç§„Éâ„ÅØ„Ç®„Éº„Ç∏„Çß„É≥„ÉÜ„Ç£„ÉÉ„ÇØAI„ÅÆ„É¨„ÉÉ„Éâ„ÉÅ„Éº„Éü„É≥„Ç∞ÊâãÊ≥ï„ÇíÊèê‰æõ„Åó„ÄÅ„Åù„ÅÆÁâπÊúâ„ÅÆ„É™„Çπ„ÇØ„Å®ËÑÜÂº±ÊÄß„Å´ÂØæÂá¶„Åô„Çã„Åü„ÇÅ„ÅÆÊåáÈáù„ÇíÁ§∫„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Wed, 02 Jul 2025 07:30:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2507/02/news020.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2507/02/cover_news020.jpg"
  },
  {
    "title": "A Fuzzy Approach to the Specification, Verification and Validation of Risk-Based Ethical Decision Making Models",
    "description": "arXiv:2507.01410v1 Announce Type: new Abstract: The ontological and epistemic complexities inherent in the moral domain make it challenging to establish clear standards for evaluating the performance of a moral machine. In this paper, we present a formal method to describe Ethical Decision Making models based on ethical risk assessment. Then, we show how these models that are specified as fuzzy rules can be verified and validated using fuzzy Petri nets. A case study from the medical field is considered to illustrate the proposed approach.",
    "summary": "arXiv:2507.01410v1 Announce Type: new Abstract: The ontological and epistemic complexities inherent in the moral domain make it challenging to establish clear standards for evaluating the performance of a moral machine. In this paper, we present a formal method to describe Ethical Decision Making models based on ethical risk assessment. Then, we show how these models that are specified as fuzzy rules can be verified and validated using fuzzy Petri nets. A case study from the medical field is considered to illustrate the proposed approach.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01410",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Our approach to data and AI",
    "description": "Just over a year after launching ChatGPT, AI is changing how we live, work and learn. It‚Äôs also raised important conversations about data in the age of AI. More on our approach, a new Media Manager for creators and content owners, and where we‚Äôre headed.",
    "summary": "Just over a year after launching ChatGPT, AI is changing how we live, work and learn. It‚Äôs also raised important conversations about data in the age of AI. More on our approach, a new Media Manager for creators and content owners, and where we‚Äôre headed.",
    "pubDate": "Tue, 07 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/approach-to-data-and-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sycophancy in GPT-4o: what happened and what we‚Äôre doing about it",
    "description": "We have rolled back last week‚Äôs GPT‚Äë4o update in ChatGPT so people are now using an earlier version with more balanced behavior. The update we removed was overly flattering or agreeable‚Äîoften described as sycophantic.",
    "summary": "We have rolled back last week‚Äôs GPT‚Äë4o update in ChatGPT so people are now using an earlier version with more balanced behavior. The update we removed was overly flattering or agreeable‚Äîoften described as sycophantic.",
    "pubDate": "Tue, 29 Apr 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sycophancy-in-gpt-4o",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Image Classification with AutoTrain",
    "description": "",
    "summary": "Image Classification with AutoTrain So you‚Äôve heard all about the cool things that are happening in ...",
    "pubDate": "Wed, 28 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autotrain-image-classification",
    "thumbnail": "https://huggingface.co/blog/assets/105_autotrain-image-classification/thumbnail.png"
  },
  {
    "title": "OpenAI and Hearst Content Partnership",
    "description": "Hearst‚Äôs iconic brands bring curated lifestyle and local news content to OpenAI‚Äôs products.",
    "summary": "Hearst‚Äôs iconic brands bring curated lifestyle and local news content to OpenAI‚Äôs products.",
    "pubDate": "Tue, 08 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hearst",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fair Algorithms with Probing for Multi-Agent Multi-Armed Bandits",
    "description": "arXiv:2506.14988v2 Announce Type: replace-cross Abstract: We propose a multi-agent multi-armed bandit (MA-MAB) framework aimed at ensuring fair outcomes across agents while maximizing overall system performance. A key challenge in this setting is decision-making under limited information about arm rewards. To address this, we introduce a novel probing framework that strategically gathers information about selected arms before allocation. In the offline setting, where reward distributions are known, we leverage submodular properties to design a greedy probing algorithm with a provable performance bound. For the more complex online setting, we develop an algorithm that achieves sublinear regret while maintaining fairness. Extensive experiments on synthetic and real-world datasets show that our approach outperforms baseline methods, achieving better fairness and efficiency.",
    "summary": "arXiv:2506.14988v2 Announce Type: replace-cross Abstract: We propose a multi-agent multi-armed bandit (MA-MAB) framework aimed at ensuring fair outcomes across agents while maximizing overall system performance. A key challenge in this setting is decision-making under limited information about arm rewards. To address this, we introduce a novel probing framework that strategically gathers information about selected arms before allocation. In the offline setting, where reward distributions are known, we leverage submodular properties to design a greedy probing algorithm with a provable performance bound. For the more complex online setting, we develop an algorithm that achieves sublinear regret while maintaining fairness. Extensive experiments on synthetic and real-world datasets show that our approach outperforms baseline methods, achieving better fairness and efficiency.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14988",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Tool Use, Unified",
    "description": "",
    "summary": "Tool Use, Unified There is now a unified tool use API across several popular families of models. Thi...",
    "pubDate": "Mon, 12 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unified-tool-use",
    "thumbnail": "https://huggingface.co/blog/assets/unified-tool-use/thumbnail.png"
  },
  {
    "title": "Benchmarking safe exploration in deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 21 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/benchmarking-safe-exploration-in-deep-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI partners with Cond√© Nast",
    "description": "Cond√© Nast",
    "summary": "Cond√© Nast",
    "pubDate": "Tue, 20 Aug 2024 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/conde-nast",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing OpenAI‚Äôs Bug Bounty Program",
    "description": "This initiative is essential to our commitment to develop safe and advanced AI. As we create technology and services that are secure, reliable, and trustworthy, we need your help.",
    "summary": "This initiative is essential to our commitment to develop safe and advanced AI. As we create technology and services that are secure, reliable, and trustworthy, we need your help.",
    "pubDate": "Tue, 11 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bug-bounty-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ÁîüÊàêAI„ÅßÂ§â„Çè„Çã„Çµ„Ç§„Éê„Éº„Çª„Ç≠„É•„É™„ÉÜ„Ç£„ÄÄNEC„Å®IDC„ÅåË™û„Çã„ÄåAI√ó„Çª„Ç≠„É•„É™„ÉÜ„Ç£„Äç„ÅÆË¶ÅÁÇπ",
    "description": "NEC Corporate Executive CISO„ÅÆÊ∑µ‰∏äÁúü‰∏ÄÊ∞è„Å®„ÄÅIDC Japan „É™„Çµ„Éº„ÉÅ„Éû„Éç„Éº„Ç∏„É£„Éº„ÅÆËµ§ÈñìÂÅ•‰∏ÄÊ∞è„Å´„Çà„ÇãË¨õÊºî„ÅÆÂÜÖÂÆπ„Åã„Çâ„ÄÅAIÊôÇ‰ª£„ÅÆ„Çª„Ç≠„É•„É™„ÉÜ„Ç£Êà¶Áï•„ÅÆÊúÄÂâçÁ∑ö„ÇíË™≠„ÅøËß£„Åè„ÄÇ",
    "summary": "NEC Corporate Executive CISO„ÅÆÊ∑µ‰∏äÁúü‰∏ÄÊ∞è„Å®„ÄÅIDC Japan „É™„Çµ„Éº„ÉÅ„Éû„Éç„Éº„Ç∏„É£„Éº„ÅÆËµ§ÈñìÂÅ•‰∏ÄÊ∞è„Å´„Çà„ÇãË¨õÊºî„ÅÆÂÜÖÂÆπ„Åã„Çâ„ÄÅAIÊôÇ‰ª£„ÅÆ„Çª„Ç≠„É•„É™„ÉÜ„Ç£Êà¶Áï•„ÅÆÊúÄÂâçÁ∑ö„ÇíË™≠„ÅøËß£„Åè„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 05:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2507/02/news031.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2507/02/cover_news031.jpg"
  },
  {
    "title": "Distill",
    "description": "We‚Äôre excited to support today‚Äôs launch of Distill, a new kind of journal aimed at excellent communication of machine learning results (novel or existing).",
    "summary": "We‚Äôre excited to support today‚Äôs launch of Distill, a new kind of journal aimed at excellent communication of machine learning results (novel or existing).",
    "pubDate": "Mon, 20 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/distill",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence",
    "description": "arXiv:2507.01504v1 Announce Type: cross Abstract: The collection and release of street-level recordings as Open Data play a vital role in advancing autonomous driving systems and AI research. However, these datasets pose significant privacy risks, particularly for pedestrians, due to the presence of Personally Identifiable Information (PII) that extends beyond biometric traits such as faces. In this paper, we present cRID, a novel cross-modal framework combining Large Vision-Language Models, Graph Attention Networks, and representation learning to detect textual describable clues of PII and enhance person re-identification (Re-ID). Our approach focuses on identifying and leveraging interpretable features, enabling the detection of semantically meaningful PII beyond low-level appearance cues. We conduct a systematic evaluation of PII presence in person image datasets. Our experiments show improved performance in practical cross-dataset Re-ID scenarios, notably from Market-1501 to CUHK03-np (detected), highlighting the framework's practical utility. Code is available at https://github.com/RAufschlaeger/cRID.",
    "summary": "arXiv:2507.01504v1 Announce Type: cross Abstract: The collection and release of street-level recordings as Open Data play a vital role in advancing autonomous driving systems and AI research. However, these datasets pose significant privacy risks, particularly for pedestrians, due to the presence of Personally Identifiable Information (PII) that extends beyond biometric traits such as faces. In this paper, we present cRID, a novel cross-modal framework combining Large Vision-Language Models, Graph Attention Networks, and representation learning to detect textual describable clues of PII and enhance person re-identification (Re-ID). Our approach focuses on identifying and leveraging interpretable features, enabling the detection of semantically meaningful PII beyond low-level appearance cues. We conduct a systematic evaluation of PII presence in person image datasets. Our experiments show improved performance in practical cross-dataset Re-ID scenarios, notably from Market-1501 to CUHK03-np (detected), highlighting the framework's practical utility. Code is available at https://github.com/RAufschlaeger/cRID.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01504",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hosting your Models and Datasets on Hugging Face Spaces using Streamlit",
    "description": "",
    "summary": "Hosting your Models and Datasets on Hugging Face Spaces using Streamlit Showcase your Datasets and M...",
    "pubDate": "Tue, 05 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/streamlit-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/29_streamlit-spaces/thumbnail.png"
  },
  {
    "title": "OpenAI safety practices",
    "description": "Artificial general intelligence has the potential to benefit nearly every aspect of our lives‚Äîso it must be developed and deployed responsibly.",
    "summary": "Artificial general intelligence has the potential to benefit nearly every aspect of our lives‚Äîso it must be developed and deployed responsibly.",
    "pubDate": "Tue, 21 May 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-safety-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Strategic Content Partnership with TIME",
    "description": "We‚Äôre partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories on Time.com",
    "summary": "We‚Äôre partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories on Time.com",
    "pubDate": "Thu, 27 Jun 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/strategic-content-partnership-with-time",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Frontier Model Forum updates",
    "description": "Together with Anthropic, Google, and Microsoft, we‚Äôre announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",
    "summary": "Together with Anthropic, Google, and Microsoft, we‚Äôre announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",
    "pubDate": "Wed, 25 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-model-forum-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deep Q-Learning with Atari",
    "description": "",
    "summary": "Deep Q-Learning with Space Invaders Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 3, of...",
    "pubDate": "Tue, 07 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-dqn",
    "thumbnail": "https://huggingface.co/blog/assets/78_deep_rl_dqn/thumbnail.gif"
  },
  {
    "title": "Faster physics in Python",
    "description": "We‚Äôre open-sourcing a high-performance Python library for robotic simulation using the MuJoCo engine, developed over our past year of robotics research.",
    "summary": "We‚Äôre open-sourcing a high-performance Python library for robotic simulation using the MuJoCo engine, developed over our past year of robotics research.",
    "pubDate": "Wed, 28 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/faster-physics-in-python",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The State of Computer Vision at Hugging Face ü§ó",
    "description": "",
    "summary": "The State of Computer Vision at Hugging Face ü§ó At Hugging Face, we pride ourselves on democratizing ...",
    "pubDate": "Mon, 30 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cv_state",
    "thumbnail": "https://huggingface.co/blog/assets/cv_state/thumbnail.png"
  },
  {
    "title": "A sounding board for strengthening the student experience",
    "description": "Composed of ‚Äúcomputing bilinguals,‚Äù the Undergraduate Advisory Group provides vital input to help advance the mission of the MIT Schwarzman College of Computing.",
    "summary": "Composed of ‚Äúcomputing bilinguals,‚Äù the Undergraduate Advisory Group provides vital input to help advance the mission of the MIT Schwarzman College of Computing.",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/sounding-board-for-strengthening-student-experience-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-SCC-UAG.jpg"
  },
  {
    "title": "Towards Encrypted Large Language Models with FHE",
    "description": "",
    "summary": "Towards Encrypted Large Language Models with FHE Large Language Models (LLM) have recently been prov...",
    "pubDate": "Wed, 02 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/encrypted-llm",
    "thumbnail": "https://huggingface.co/blog/assets/encrypted-llm/thumbnail.png"
  },
  {
    "title": "An update on our safety & security practices",
    "description": "An update on our safety & security practices",
    "summary": "An update on our safety & security practices",
    "pubDate": "Mon, 16 Sep 2024 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/update-on-safety-and-security-practices",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Transformers.js v3: WebGPU support, new models & tasks, and more‚Ä¶",
    "description": "",
    "summary": "Transformers.js v3: WebGPU Support, New Models & Tasks, and More‚Ä¶ After more than a year of developm...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformersjs-v3",
    "thumbnail": "https://huggingface.co/blog/assets/transformersjs-v3/thumbnail.png"
  },
  {
    "title": "Introducing text and code embeddings",
    "description": "We are introducing embeddings, a new endpoint in the OpenAI API that makes it easy to perform natural language and code tasks like semantic search, clustering, topic modeling, and classification.",
    "summary": "We are introducing embeddings, a new endpoint in the OpenAI API that makes it easy to perform natural language and code tasks like semantic search, clustering, topic modeling, and classification.",
    "pubDate": "Tue, 25 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-text-and-code-embeddings",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models",
    "description": "",
    "summary": "Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models Transformer-based encod...",
    "pubDate": "Mon, 09 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/warm-starting-encoder-decoder",
    "thumbnail": "https://huggingface.co/blog/assets/08_warm_starting_encoder_decoder/thumbnail.png"
  },
  {
    "title": "Relational Causal Discovery with Latent Confounders",
    "description": "arXiv:2507.01700v1 Announce Type: cross Abstract: Estimating causal effects from real-world relational data can be challenging when the underlying causal model and potential confounders are unknown. While several causal discovery algorithms exist for learning causal models with latent confounders from data, they assume that the data is independent and identically distributed (i.i.d.) and are not well-suited for learning from relational data. Similarly, existing relational causal discovery algorithms assume causal sufficiency, which is unrealistic for many real-world datasets. To address this gap, we propose RelFCI, a sound and complete causal discovery algorithm for relational data with latent confounders. Our work builds upon the Fast Causal Inference (FCI) and Relational Causal Discovery (RCD) algorithms and it defines new graphical models, necessary to support causal discovery in relational domains. We also establish soundness and completeness guarantees for relational d-separation with latent confounders. We present experimental results demonstrating the effectiveness of RelFCI in identifying the correct causal structure in relational causal models with latent confounders.",
    "summary": "arXiv:2507.01700v1 Announce Type: cross Abstract: Estimating causal effects from real-world relational data can be challenging when the underlying causal model and potential confounders are unknown. While several causal discovery algorithms exist for learning causal models with latent confounders from data, they assume that the data is independent and identically distributed (i.i.d.) and are not well-suited for learning from relational data. Similarly, existing relational causal discovery algorithms assume causal sufficiency, which is unrealistic for many real-world datasets. To address this gap, we propose RelFCI, a sound and complete causal discovery algorithm for relational data with latent confounders. Our work builds upon the Fast Causal Inference (FCI) and Relational Causal Discovery (RCD) algorithms and it defines new graphical models, necessary to support causal discovery in relational domains. We also establish soundness and completeness guarantees for relational d-separation with latent confounders. We present experimental results demonstrating the effectiveness of RelFCI in identifying the correct causal structure in relational causal models with latent confounders.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01700",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer)",
    "description": "",
    "summary": "Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer) Introduction A few months...",
    "pubDate": "Fri, 16 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autoformer",
    "thumbnail": "https://huggingface.co/blog/assets/150_autoformer/thumbnail.png"
  },
  {
    "title": "Perplexity„ÇÇÊúàÈ°ç200„Éâ„É´„ÅÆ„ÄåMax„Äç„Éó„É©„É≥Êèê‰æõÈñãÂßã",
    "description": "AIÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆPerplexity„Åå„ÄÅÊúàÈ°ç200„Éâ„É´„ÅÆÊúÄ‰∏ä‰Ωç„Éó„É©„É≥„ÄåPerplexity Max„Äç„ÅÆÊèê‰æõ„ÇíÈñãÂßã„Åó„Åü„ÄÇPro„Éó„É©„É≥„ÅÆÊ©üËÉΩ„Å´Âä†„Åà„ÄÅ„Ç®„Éº„Ç∏„Çß„É≥„Éà„Éñ„É©„Ç¶„Ç∂„ÄåComet„Äç„Å∏„ÅÆÊó©Êúü„Ç¢„ÇØ„Çª„Çπ„ÇÑ„ÄÅPerplexity Labs„Å∏„ÅÆÁÑ°Âà∂Èôê„Ç¢„ÇØ„Çª„Çπ„Å™„Å©„ÅåÂèØËÉΩ„Å´„Å™„Çã„ÄÇ",
    "summary": "AIÊ§úÁ¥¢„Ç®„É≥„Ç∏„É≥„ÅÆPerplexity„Åå„ÄÅÊúàÈ°ç200„Éâ„É´„ÅÆÊúÄ‰∏ä‰Ωç„Éó„É©„É≥„ÄåPerplexity Max„Äç„ÅÆÊèê‰æõ„ÇíÈñãÂßã„Åó„Åü„ÄÇPro„Éó„É©„É≥„ÅÆÊ©üËÉΩ„Å´Âä†„Åà„ÄÅ„Ç®„Éº„Ç∏„Çß„É≥„Éà„Éñ„É©„Ç¶„Ç∂„ÄåComet„Äç„Å∏„ÅÆÊó©Êúü„Ç¢„ÇØ„Çª„Çπ„ÇÑ„ÄÅPerplexity Labs„Å∏„ÅÆÁÑ°Âà∂Èôê„Ç¢„ÇØ„Çª„Çπ„Å™„Å©„ÅåÂèØËÉΩ„Å´„Å™„Çã„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 06:55:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news054.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news054.jpg"
  },
  {
    "title": "SetFitABSA: Few-Shot Aspect Based Sentiment Analysis using SetFit",
    "description": "",
    "summary": "SetFitABSA: Few-Shot Aspect Based Sentiment Analysis using SetFit SetFitABSA is an efficient techniq...",
    "pubDate": "Wed, 06 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit-absa",
    "thumbnail": "https://huggingface.co/blog/assets/setfit-absa/intel_hf_logo_2.png"
  },
  {
    "title": "3D Asset Generation: AI for Game Development #3",
    "description": "",
    "summary": "3D Asset Generation: AI for Game Development #3 Welcome to AI for Game Development! In this series, ...",
    "pubDate": "Fri, 20 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-3",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail3.png"
  },
  {
    "title": "„Äå„Éâ„É©„Ç¥„É≥„Éú„Éº„É´„Äç„ÅÆ„Éñ„É´„Éû„ÅØIT„Ç®„É≥„Ç∏„Éã„Ç¢„ÅÆÁêÜÊÉ≥ÂÉè‚îÄ‚îÄ„Éï„Ç°„Ç§„É≥„Éá„Ç£„Åå„ÉÜ„É¨„ÉìCM„Å´Ëµ∑Áî®",
    "description": "„Ç®„É≥„Ç∏„Éã„Ç¢Âêë„Åë„ÅÆËª¢ËÅ∑„Çµ„Éº„Éì„Çπ„ÄåFindy„Äç„ÇíÈÅãÂñ∂„Åô„Çã„Éï„Ç°„Ç§„É≥„Éá„Ç£„ÅØ„ÄÅ„ÉÜ„É¨„Éì„Ç¢„Éã„É°„Äå„Éâ„É©„Ç¥„É≥„Éú„Éº„É´Z„Äç„ÅÆ„Ç≠„É£„É©„ÇØ„Çø„Éº„ÇíËµ∑Áî®„Åó„Åü„ÉÜ„É¨„Éì„Ç≥„Éû„Éº„Ç∑„É£„É´„ÇíÊîæÈÄÅ„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ",
    "summary": "„Ç®„É≥„Ç∏„Éã„Ç¢Âêë„Åë„ÅÆËª¢ËÅ∑„Çµ„Éº„Éì„Çπ„ÄåFindy„Äç„ÇíÈÅãÂñ∂„Åô„Çã„Éï„Ç°„Ç§„É≥„Éá„Ç£„ÅØ„ÄÅ„ÉÜ„É¨„Éì„Ç¢„Éã„É°„Äå„Éâ„É©„Ç¥„É≥„Éú„Éº„É´Z„Äç„ÅÆ„Ç≠„É£„É©„ÇØ„Çø„Éº„ÇíËµ∑Áî®„Åó„Åü„ÉÜ„É¨„Éì„Ç≥„Éû„Éº„Ç∑„É£„É´„ÇíÊîæÈÄÅ„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 13:41:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news085.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news085.jpg"
  },
  {
    "title": "ÁîüÊàêAI„Å´„ÄåÊúüÂæÖ„Åó„Å¶„ÅÑ„Çã„Äç‰∫∫„ÅØÂÖ®‰Ωì„Åß33ÔºÖ„ÄÅ‰∏ÄÊñπ10‰ª£Áî∑ÊÄß„Åß„ÅØ70ÔºÖ„ÄÄNTT„Éâ„Ç≥„É¢Ë™øÊüª",
    "description": "ÁîüÊàêAI„Å´„ÄåÊúüÂæÖ„Åó„Å¶„ÅÑ„Çã„Äç‰∫∫„ÅØÂÖ®‰Ωì„Åß33ÔºÖ‚Äï‚ÄïNTT„Éâ„Ç≥„É¢„ÅÆ„É¢„Éê„Ç§„É´Á§æ‰ºöÁ†îÁ©∂ÊâÄ„ÅØ„ÄÅ„Åì„Çì„Å™Ë™øÊüªÁµêÊûú„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÁîüÊàêAI„Å´ÊúüÂæÖ„Åó„Å¶„ÅÑ„Çã„Å®ÂõûÁ≠î„Åó„ÅüÂâ≤Âêà„ÅØ„ÄÅ10‰ª£Áî∑ÊÄß„Åå70ÔºÖ„ÅßÊúÄ„ÇÇÈ´ò„Åè„ÄÅËã•„ÅÑÂπ¥‰ª£„ÇÑÁî∑ÊÄß„ÅÆÊñπ„ÅåÈ´ò„ÅÑÂÇæÂêë„Å´„ÅÇ„Å£„Åü„Å®„ÅÑ„ÅÜ„ÄÇ",
    "summary": "ÁîüÊàêAI„Å´„ÄåÊúüÂæÖ„Åó„Å¶„ÅÑ„Çã„Äç‰∫∫„ÅØÂÖ®‰Ωì„Åß33ÔºÖ‚Äï‚ÄïNTT„Éâ„Ç≥„É¢„ÅÆ„É¢„Éê„Ç§„É´Á§æ‰ºöÁ†îÁ©∂ÊâÄ„ÅØ„ÄÅ„Åì„Çì„Å™Ë™øÊüªÁµêÊûú„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÁîüÊàêAI„Å´ÊúüÂæÖ„Åó„Å¶„ÅÑ„Çã„Å®ÂõûÁ≠î„Åó„ÅüÂâ≤Âêà„ÅØ„ÄÅ10‰ª£Áî∑ÊÄß„Åå70ÔºÖ„ÅßÊúÄ„ÇÇÈ´ò„Åè„ÄÅËã•„ÅÑÂπ¥‰ª£„ÇÑÁî∑ÊÄß„ÅÆÊñπ„ÅåÈ´ò„ÅÑÂÇæÂêë„Å´„ÅÇ„Å£„Åü„Å®„ÅÑ„ÅÜ„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 11:50:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news068.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news068.jpg"
  },
  {
    "title": "Chat Templates: An End to the Silent Performance Killer",
    "description": "",
    "summary": "Chat Templates A spectre is haunting chat models - the spectre of incorrect formatting! tl;dr Chat m...",
    "pubDate": "Tue, 03 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chat-templates",
    "thumbnail": "https://huggingface.co/blog/assets/chat-templates/thumbnail.png"
  },
  {
    "title": "Solving (some) formal math olympiad problems",
    "description": "We built a neural theorem prover for¬†Lean¬†that learned to solve a variety of challenging high-school olympiad problems, including problems from the¬†AMC12¬†and¬†AIME¬†competitions, as well as two problems adapted from the¬†IMO.",
    "summary": "We built a neural theorem prover for¬†Lean¬†that learned to solve a variety of challenging high-school olympiad problems, including problems from the¬†AMC12¬†and¬†AIME¬†competitions, as well as two problems adapted from the¬†IMO.",
    "pubDate": "Wed, 02 Feb 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/formal-math",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI and Guardian Media Group launch content partnership",
    "description": "OpenAI and Guardian Media Group announce content partnership to bring Guardian news content to ChatGPT.",
    "summary": "OpenAI and Guardian Media Group announce content partnership to bring Guardian news content to ChatGPT.",
    "pubDate": "Fri, 14 Feb 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-guardian-media-group-launch-content-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning Montezuma‚Äôs Revenge from a single demonstration",
    "description": "We‚Äôve trained an agent to achieve a high score of 74,500 on¬†Montezuma‚Äôs Revenge¬†from a single human demonstration, better than any previously published result. Our algorithm is simple: the agent plays a sequence of games starting from carefully chosen states from the demonstration, and learns from them by optimizing the game score using¬†PPO, the same reinforcement learning algorithm that underpins¬†OpenAI¬†Five.",
    "summary": "We‚Äôve trained an agent to achieve a high score of 74,500 on¬†Montezuma‚Äôs Revenge¬†from a single human demonstration, better than any previously published result. Our algorithm is simple: the agent plays a sequence of games starting from carefully chosen states from the demonstration, and learns from them by optimizing the game score using¬†PPO, the same reinforcement learning algorithm that underpins¬†OpenAI¬†Five.",
    "pubDate": "Wed, 04 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-montezumas-revenge-from-a-single-demonstration",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-Tune a Semantic Segmentation Model with a Custom Dataset",
    "description": "",
    "summary": "Fine-Tune a Semantic Segmentation Model with a Custom Dataset This guide shows how you can fine-tune...",
    "pubDate": "Thu, 17 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-segformer",
    "thumbnail": "https://huggingface.co/blog/assets/56_fine_tune_segformer/thumb.png"
  },
  {
    "title": "Preference Optimization for Vision Language Models",
    "description": "",
    "summary": "Preference Optimization for Vision Language Models with TRL Training models to understand and predic...",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dpo_vlm",
    "thumbnail": "https://huggingface.co/blog/assets/dpo_vlm/thumbnail.png"
  },
  {
    "title": "Enhanced Generative Model Evaluation with Clipped Density and Coverage",
    "description": "arXiv:2507.01761v1 Announce Type: cross Abstract: Although generative models have made remarkable progress in recent years, their use in critical applications has been hindered by their incapacity to reliably evaluate sample quality. Quality refers to at least two complementary concepts: fidelity and coverage. Current quality metrics often lack reliable, interpretable values due to an absence of calibration or insufficient robustness to outliers. To address these shortcomings, we introduce two novel metrics, Clipped Density and Clipped Coverage. By clipping individual sample contributions and, for fidelity, the radii of nearest neighbor balls, our metrics prevent out-of-distribution samples from biasing the aggregated values. Through analytical and empirical calibration, these metrics exhibit linear score degradation as the proportion of poor samples increases. Thus, they can be straightforwardly interpreted as equivalent proportions of good samples. Extensive experiments on synthetic and real-world datasets demonstrate that Clipped Density and Clipped Coverage outperform existing methods in terms of robustness, sensitivity, and interpretability for evaluating generative models.",
    "summary": "arXiv:2507.01761v1 Announce Type: cross Abstract: Although generative models have made remarkable progress in recent years, their use in critical applications has been hindered by their incapacity to reliably evaluate sample quality. Quality refers to at least two complementary concepts: fidelity and coverage. Current quality metrics often lack reliable, interpretable values due to an absence of calibration or insufficient robustness to outliers. To address these shortcomings, we introduce two novel metrics, Clipped Density and Clipped Coverage. By clipping individual sample contributions and, for fidelity, the radii of nearest neighbor balls, our metrics prevent out-of-distribution samples from biasing the aggregated values. Through analytical and empirical calibration, these metrics exhibit linear score degradation as the proportion of poor samples increases. Thus, they can be straightforwardly interpreted as equivalent proportions of good samples. Extensive experiments on synthetic and real-world datasets demonstrate that Clipped Density and Clipped Coverage outperform existing methods in terms of robustness, sensitivity, and interpretability for evaluating generative models.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01761",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerating LLM Inference with TGI on Intel Gaudi",
    "description": "",
    "summary": "üöÄ Accelerating LLM Inference with TGI on Intel Gaudi We're excited to announce the native integratio...",
    "pubDate": "Fri, 28 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-gaudi-backend-for-tgi",
    "thumbnail": "https://huggingface.co/blog/assets/intel-gaudi-backend-for-tgi/tgi-gaudi-thumbnail.png"
  },
  {
    "title": "Improving GANs using optimal transport",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 15 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-gans-using-optimal-transport",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FACTS Grounding: A new benchmark for evaluating the factuality of large language models",
    "description": "Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations",
    "summary": "Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations",
    "pubDate": "Tue, 17 Dec 2024 15:29:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/PNlhxhf4LKLRCezIt7Ap358F91-vbK5dLp56Ak1FejpCZh3YTp6jGqIDJm9c0iAtx8Y73MCTu279c1k2GZkM2qXXaqx315NSOaSiU0y0ATMK2c2Hyw=w1200-h630-n-nu"
  },
  {
    "title": "NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation",
    "description": "arXiv:2507.01463v1 Announce Type: cross Abstract: Instance segmentation of novel objects instances in RGB images, given some example images for each object, is a well known problem in computer vision. Designing a model general enough to be employed, for all kinds of novel objects, without (re-) training, has proven to be a difficult task. To handle this, we propose a simple, yet powerful, framework, called: Novel Object Cyclic Threshold based Instance Segmentation (NOCTIS). This work stems from and improves upon previous ones like CNOS, SAM-6D and NIDS-Net; thus, it also leverages on recent vision foundation models, namely: Grounded-SAM 2 and DINOv2. It utilises Grounded-SAM 2 to obtain object proposals with precise bounding boxes and their corresponding segmentation masks; while DINOv2's zero-shot capabilities are employed to generate the image embeddings. The quality of those masks, together with their embeddings, is of vital importance to our approach; as the proposal-object matching is realized by determining an object matching score based on the similarity of the class embeddings and the average maximum similarity of the patch embeddings. Differently to SAM-6D, calculating the latter involves a prior patch filtering based on the distance between each patch and its corresponding cyclic/roundtrip patch in the image grid. Furthermore, the average confidence of the proposals' bounding box and mask is used as an additional weighting factor for the object matching score. We empirically show that NOCTIS, without further training/fine tuning, outperforms the best RGB and RGB-D methods on the seven core datasets of the BOP 2023 challenge for the 'Model-based 2D segmentation of unseen objects' task.",
    "summary": "arXiv:2507.01463v1 Announce Type: cross Abstract: Instance segmentation of novel objects instances in RGB images, given some example images for each object, is a well known problem in computer vision. Designing a model general enough to be employed, for all kinds of novel objects, without (re-) training, has proven to be a difficult task. To handle this, we propose a simple, yet powerful, framework, called: Novel Object Cyclic Threshold based Instance Segmentation (NOCTIS). This work stems from and improves upon previous ones like CNOS, SAM-6D and NIDS-Net; thus, it also leverages on recent vision foundation models, namely: Grounded-SAM 2 and DINOv2. It utilises Grounded-SAM 2 to obtain object proposals with precise bounding boxes and their corresponding segmentation masks; while DINOv2's zero-shot capabilities are employed to generate the image embeddings. The quality of those masks, together with their embeddings, is of vital importance to our approach; as the proposal-object matching is realized by determining an object matching score based on the similarity of the class embeddings and the average maximum similarity of the patch embeddings. Differently to SAM-6D, calculating the latter involves a prior patch filtering based on the distance between each patch and its corresponding cyclic/roundtrip patch in the image grid. Furthermore, the average confidence of the proposals' bounding box and mask is used as an additional weighting factor for the object matching score. We empirically show that NOCTIS, without further training/fine tuning, outperforms the best RGB and RGB-D methods on the seven core datasets of the BOP 2023 challenge for the 'Model-based 2D segmentation of unseen objects' task.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01463",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improving verifiability in AI development",
    "description": "We‚Äôve contributed to a multi-stakeholder report by¬†58 co-authors¬†at 30 organizations, including the¬†Centre for the Future of Intelligence,¬†Mila,¬†Schwartz Reisman Institute for Technology and Society,¬†Center for Advanced Study in the Behavioral Sciences, and¬†Center for Security and Emerging Technologies. This report describes 10 mechanisms to improve the verifiability of claims made about AI systems. Developers can use these tools to provide evidence that AI systems are safe, secure, fair, or privacy-preserving. Users, policymakers, and civil society can use these tools to evaluate AI development¬†processes.",
    "summary": "We‚Äôve contributed to a multi-stakeholder report by¬†58 co-authors¬†at 30 organizations, including the¬†Centre for the Future of Intelligence,¬†Mila,¬†Schwartz Reisman Institute for Technology and Society,¬†Center for Advanced Study in the Behavioral Sciences, and¬†Center for Security and Emerging Technologies. This report describes 10 mechanisms to improve the verifiability of claims made about AI systems. Developers can use these tools to provide evidence that AI systems are safe, secure, fair, or privacy-preserving. Users, policymakers, and civil society can use these tools to evaluate AI development¬†processes.",
    "pubDate": "Thu, 16 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-verifiability",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LoRA training scripts of the world, unite!",
    "description": "",
    "summary": "LoRA training scripts of the world, unite! A community derived guide to some of the SOTA practices f...",
    "pubDate": "Tue, 02 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_lora_advanced_script",
    "thumbnail": "https://huggingface.co/blog/assets/dreambooth_lora_sdxl/thumbnail.png"
  },
  {
    "title": "Teaching AI models what they don‚Äôt know",
    "description": "A team of MIT researchers founded Themis AI to quantify AI model uncertainty and address knowledge gaps.",
    "summary": "A team of MIT researchers founded Themis AI to quantify AI model uncertainty and address knowledge gaps.",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/themis-ai-teaches-ai-models-what-they-dont-know-0603",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-ThemisAI-01-Press.jpg"
  },
  {
    "title": "Mapping the misuse of generative AI",
    "description": "New research analyzes the misuse of multimodal generative AI today, in order to help build safer and more responsible technologies.",
    "summary": "New research analyzes the misuse of multimodal generative AI today, in order to help build safer and more responsible technologies.",
    "pubDate": "Fri, 02 Aug 2024 10:50:58 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/mapping-the-misuse-of-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/IzYg4pdM7_tKoEbQHE4-Em9cvFxbx2Aq4_YOQdLr6VK754c8-bJRW9LWMf1_nUraA5BfNcBjAjpIjcfF1M_qQviR8b7qyRnAiUzapq3LKVbTpoJ8Cw=w1200-h630-n-nu"
  },
  {
    "title": "How can we build human values into AI?",
    "description": "Drawing from philosophy to identify fair principles for ethical AI...",
    "summary": "Drawing from philosophy to identify fair principles for ethical AI...",
    "pubDate": "Mon, 24 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/how-can-we-build-human-values-into-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/jXiO9PpMnNRhxz3kyDP97SVi5c68dQie9V4AHbH_I0Py0EJoOl0fyPhoVljUGETrNmj3BhbAEahqmsq4r-33IgLgGhsuUhN2p384-d8B_vc4asHWB6Q=w1200-h630-n-nu"
  },
  {
    "title": "Extensions and limitations of the neural GPU",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 02 Nov 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/extensions-and-limitations-of-the-neural-gpu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making thousands of open LLMs bloom in the Vertex AI Model Garden",
    "description": "",
    "summary": "Making thousands of open LLMs bloom in the Vertex AI Model Garden Today, we are thrilled to announce...",
    "pubDate": "Wed, 10 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/google-cloud-model-garden",
    "thumbnail": "https://huggingface.co/blog/assets/173_gcp-partnership/thumbnail.jpg"
  },
  {
    "title": "Êù±Âçó„Ç¢„Ç∏„Ç¢ÊúâÊï∞„ÅÆÊóÖË°å‰∫àÁ¥Ñ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„Äå„Éà„É©„Éô„É≠„Ç´„Äç„ÄÄÁ§æÈï∑„Å´ËÅû„ÅèÊó•Êú¨ÈÄ≤Âá∫„ÅÆÁãô„ÅÑ",
    "description": "Êù±Âçó„Ç¢„Ç∏„Ç¢ÊúâÊï∞„ÅÆÊóÖË°å‰∫àÁ¥Ñ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„Äå„Éà„É©„Éô„É≠„Ç´„ÄçÔºàTravelokaÔºâ„Åå2025Âπ¥Êò•„ÄÅÊó•Êú¨Â∏ÇÂ†¥„Å´ÂèÇÂÖ•„Åó„Åü„ÄÇÂêåÁ§æ„ÅÆÂº∑„Åø„Å®„ÄÅÊù±Âçó„Ç¢„Ç∏„Ç¢ÁâπÊúâ„ÅÆË¶≥ÂÖâË™≤È°å„ÅØ‰Ωï„Åã„ÄÇÂêåÁ§æ„ÅÆ„Ç∑„Éº„Ç∂„Éº„Éª„Ç§„É≥„Éâ„É©Á§æÈï∑„Å´ËÅû„ÅÑ„Åü„ÄÇ",
    "summary": "Êù±Âçó„Ç¢„Ç∏„Ç¢ÊúâÊï∞„ÅÆÊóÖË°å‰∫àÁ¥Ñ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„Äå„Éà„É©„Éô„É≠„Ç´„ÄçÔºàTravelokaÔºâ„Åå2025Âπ¥Êò•„ÄÅÊó•Êú¨Â∏ÇÂ†¥„Å´ÂèÇÂÖ•„Åó„Åü„ÄÇÂêåÁ§æ„ÅÆÂº∑„Åø„Å®„ÄÅÊù±Âçó„Ç¢„Ç∏„Ç¢ÁâπÊúâ„ÅÆË¶≥ÂÖâË™≤È°å„ÅØ‰Ωï„Åã„ÄÇÂêåÁ§æ„ÅÆ„Ç∑„Éº„Ç∂„Éº„Éª„Ç§„É≥„Éâ„É©Á§æÈï∑„Å´ËÅû„ÅÑ„Åü„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 17:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2507/03/news040.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2507/03/cover_news040.jpg"
  },
  {
    "title": "Gemma 3n fully available in the open-source ecosystem!",
    "description": "",
    "summary": "Gemma 3n fully available in the open-source ecosystem! Gemma 3n was announced as a preview during Go...",
    "pubDate": "Thu, 26 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma3n",
    "thumbnail": "https://huggingface.co/blog/assets/gemma3n/thumbnail.png"
  },
  {
    "title": "Emergence of grounded compositional language in multi-agent populations",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 15 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergence-of-grounded-compositional-language-in-multi-agent-populations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Wayfair is shaping the future of retail with AI",
    "description": "A conversation with Fiona Tan, Chief Technology Officer of Wayfair.",
    "summary": "A conversation with Fiona Tan, Chief Technology Officer of Wayfair.",
    "pubDate": "Thu, 13 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/wayfair-fiona-tan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Open LLM Leaderboard: DROP deep dive",
    "description": "",
    "summary": "Open LLM Leaderboard: DROP deep dive Recently, three new benchmarks were added to the Open LLM Leade...",
    "pubDate": "Fri, 01 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-drop",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "Fuel your creativity with new generative media models and tools",
    "description": "Introducing Veo 3 and Imagen 4, and a new tool for filmmaking called Flow.",
    "summary": "Introducing Veo 3 and Imagen 4, and a new tool for filmmaking called Flow.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/fuel-your-creativity-with-new-generative-media-models-and-tools/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5.20v2_SS_1920x1080.width-1300.png"
  },
  {
    "title": "Retro Contest: Results",
    "description": "The first run of our¬†Retro Contest‚Äîexploring the development of algorithms that can generalize from previous experience‚Äîis now¬†complete.",
    "summary": "The first run of our¬†Retro Contest‚Äîexploring the development of algorithms that can generalize from previous experience‚Äîis now¬†complete.",
    "pubDate": "Fri, 22 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retro-contest-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making a web app generator with open ML models",
    "description": "",
    "summary": "Making a web app generator with open ML models As more code generation models become publicly availa...",
    "pubDate": "Mon, 03 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-to-webapp",
    "thumbnail": "https://huggingface.co/blog/assets/153_text_to_webapp/thumbnail.jpg"
  },
  {
    "title": "Serverless Inference with Hugging Face and NVIDIA NIMs",
    "description": "",
    "summary": "Serverless Inference with Hugging Face and NVIDIA NIM Update: This service is deprecated and no long...",
    "pubDate": "Mon, 29 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-dgx-cloud",
    "thumbnail": "https://huggingface.co/blog/assets/train-dgx-cloud/thumbnail.jpg"
  },
  {
    "title": "Introducing new audio and vision documentation in ü§ó Datasets",
    "description": "",
    "summary": "Introducing new audio and vision documentation in ü§ó Datasets Open and reproducible datasets are esse...",
    "pubDate": "Thu, 28 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/datasets-docs-update",
    "thumbnail": "https://huggingface.co/blog/assets/87_datasets-docs-update/thumbnail.gif"
  },
  {
    "title": "Introducing ChatGPT Gov",
    "description": "ChatGPT Gov is designed to streamline government agencies‚Äô access to OpenAI‚Äôs frontier models.",
    "summary": "ChatGPT Gov is designed to streamline government agencies‚Äô access to OpenAI‚Äôs frontier models.",
    "pubDate": "Tue, 28 Jan 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-chatgpt-gov",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-3.5 Turbo fine-tuning and API updates",
    "description": "Developers can now bring their own data to customize GPT-3.5 Turbo for their use cases.",
    "summary": "Developers can now bring their own data to customize GPT-3.5 Turbo for their use cases.",
    "pubDate": "Tue, 22 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LLM„ÅÆÊé®Ë´ñ„Å´„Åä„Åë„Çã ‚Äúaha moment‚Äù „Å´„Å§„ÅÑ„Å¶Ë™ø„Åπ„Å¶„Åø„Åü",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ÂÖàÊó•„ÄÅLLM„ÅÆ 'aha moment' „Å´Èñ¢„Åó„Å¶ËààÂë≥„ÇíÊåÅ„Å°„ÄÅÈñ¢ÈÄ£Ë´ñÊñá„ÇÑWeb‰∏ä„ÅÆË®ò‰∫ã„ÇíË™≠„Çì„Åß„Åø„Åü„Å®„Åì„Çç„ÄÅË≥õÂê¶‰∏°Ë´ñ„ÅÆÊßò„ÄÖ„Å™Ë¶ãËß£„Åå„ÅÇ„ÇäËààÂë≥Ê∑±„Åã„Å£„Åü„ÅÆ„Åß„ÄÅ‰ªäÂõû„ÅØ„Åù„ÅÆÂÜÖÂÆπ„ÇíÂÖ±Êúâ„Åó„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5766' rel='nofollow'>LLM„ÅÆÊé®Ë´ñ„Å´„Åä„Åë„Çã &#8220;aha moment&#8221; „Å´„Å§„ÅÑ„Å¶Ë™ø„Åπ„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ÂÖàÊó•„ÄÅLLM„ÅÆ 'aha moment' „Å´Èñ¢„Åó„Å¶ËààÂë≥„ÇíÊåÅ„Å°„ÄÅÈñ¢ÈÄ£Ë´ñÊñá„ÇÑWeb‰∏ä„ÅÆË®ò‰∫ã„ÇíË™≠„Çì„Åß„Åø„Åü„Å®„Åì„Çç„ÄÅË≥õÂê¶‰∏°Ë´ñ„ÅÆÊßò„ÄÖ„Å™Ë¶ãËß£„Åå„ÅÇ„ÇäËààÂë≥Ê∑±„Åã„Å£„Åü„ÅÆ„Åß„ÄÅ‰ªäÂõû„ÅØ„Åù„ÅÆÂÜÖÂÆπ„ÇíÂÖ±Êúâ„Åó„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5766' rel='nofollow'>LLM„ÅÆÊé®Ë´ñ„Å´„Åä„Åë„Çã &#8220;aha moment&#8221; „Å´„Å§„ÅÑ„Å¶Ë™ø„Åπ„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Fri, 16 May 2025 04:41:37 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5766",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/d099d886ed65ef765625779e628d2c5f.png"
  },
  {
    "title": "A research agenda for assessing the economic impacts of code generation models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/economic-impacts-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building agricultural database for farmers",
    "description": "Digital Green uses OpenAI to increase farmer income.",
    "summary": "Digital Green uses OpenAI to increase farmer income.",
    "pubDate": "Fri, 12 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/digital-green",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning to communicate",
    "description": "In this post we‚Äôll outline new OpenAI research in which agents develop their own language.",
    "summary": "In this post we‚Äôll outline new OpenAI research in which agents develop their own language.",
    "pubDate": "Thu, 16 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-communicate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeRobot Community Datasets: The ‚ÄúImageNet‚Äù of Robotics ‚Äî When and How?",
    "description": "",
    "summary": "LeRobot Community Datasets: The ‚ÄúImageNet‚Äù of Robotics ‚Äî When and How? üß≠ TL;DR ‚Äî Why This Blogpost? ...",
    "pubDate": "Sun, 11 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lerobot-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/195_lerobot_datasets/1.png"
  },
  {
    "title": "OpenAI partners with Schibsted Media Group",
    "description": "OpenAI and Schibsted Media Group announce content partnership to bring Guardian news and archive content to  ChatGPT.",
    "summary": "OpenAI and Schibsted Media Group announce content partnership to bring Guardian news and archive content to  ChatGPT.",
    "pubDate": "Mon, 10 Feb 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-partners-with-schibsted-media-group",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing The World's Largest Open Multilingual Language Model: BLOOM",
    "description": "",
    "summary": "üå∏ Introducing The World's Largest Open Multilingual Language Model: BLOOM üå∏ Large language models (L...",
    "pubDate": "Tue, 12 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom",
    "thumbnail": "https://huggingface.co/blog/assets/86_bloom/thumbnail.png"
  },
  {
    "title": "A Survey on Uncertainty Quantification of Large Language Models: Taxonomy, Open Research Challenges, and Future Directions",
    "description": "arXiv:2412.05563v2 Announce Type: replace-cross Abstract: The remarkable performance of large language models (LLMs) in content generation, coding, and common-sense reasoning has spurred widespread integration into many facets of society. However, integration of LLMs raises valid questions on their reliability and trustworthiness, given their propensity to generate hallucinations: plausible, factually-incorrect responses, which are expressed with striking confidence. Previous work has shown that hallucinations and other non-factual responses generated by LLMs can be detected by examining the uncertainty of the LLM in its response to the pertinent prompt, driving significant research efforts devoted to quantifying the uncertainty of LLMs. This survey seeks to provide an extensive review of existing uncertainty quantification methods for LLMs, identifying their salient features, along with their strengths and weaknesses. We present existing methods within a relevant taxonomy, unifying ostensibly disparate methods to aid understanding of the state of the art. Furthermore, we highlight applications of uncertainty quantification methods for LLMs, spanning chatbot and textual applications to embodied artificial intelligence applications in robotics. We conclude with open research challenges in uncertainty quantification of LLMs, seeking to motivate future research.",
    "summary": "arXiv:2412.05563v2 Announce Type: replace-cross Abstract: The remarkable performance of large language models (LLMs) in content generation, coding, and common-sense reasoning has spurred widespread integration into many facets of society. However, integration of LLMs raises valid questions on their reliability and trustworthiness, given their propensity to generate hallucinations: plausible, factually-incorrect responses, which are expressed with striking confidence. Previous work has shown that hallucinations and other non-factual responses generated by LLMs can be detected by examining the uncertainty of the LLM in its response to the pertinent prompt, driving significant research efforts devoted to quantifying the uncertainty of LLMs. This survey seeks to provide an extensive review of existing uncertainty quantification methods for LLMs, identifying their salient features, along with their strengths and weaknesses. We present existing methods within a relevant taxonomy, unifying ostensibly disparate methods to aid understanding of the state of the art. Furthermore, we highlight applications of uncertainty quantification methods for LLMs, spanning chatbot and textual applications to embodied artificial intelligence applications in robotics. We conclude with open research challenges in uncertainty quantification of LLMs, seeking to motivate future research.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.05563",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLM Inference on Edge: A Fun and Easy Guide to run LLMs via React Native on your Phone!",
    "description": "",
    "summary": "LLM Inference on Edge: A Fun and Easy Guide to run LLMs via React Native on your Phone! As LLMs cont...",
    "pubDate": "Fri, 07 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llm-inference-on-edge",
    "thumbnail": "https://huggingface.co/blog/assets/llm_inference_on_edge/thumbnail.png"
  },
  {
    "title": "Dota 2",
    "description": "We‚Äôve created a bot which beats the world‚Äôs top professionals at 1v1 matches of Dota 2 under standard tournament rules. The bot learned the game from scratch by self-play, and does not use imitation learning or tree search. This is a step towards building AI systems which accomplish well-defined goals in messy, complicated situations involving real humans.",
    "summary": "We‚Äôve created a bot which beats the world‚Äôs top professionals at 1v1 matches of Dota 2 under standard tournament rules. The bot learned the game from scratch by self-play, and does not use imitation learning or tree search. This is a step towards building AI systems which accomplish well-defined goals in messy, complicated situations involving real humans.",
    "pubDate": "Fri, 11 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dota-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Snowball Fight ‚òÉÔ∏è, our First ML-Agents Environment",
    "description": "",
    "summary": "Introducing Snowball Fight ‚òÉÔ∏è, our First ML-Agents Environment We're excited to share our first cust...",
    "pubDate": "Thu, 02 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/snowball-fight",
    "thumbnail": "https://huggingface.co/blog/assets/39_introducing_snowball_fight/thumbnail.png"
  },
  {
    "title": "Real-Time Blind Defocus Deblurring for Earth Observation: The IMAGIN-e Mission Approach",
    "description": "arXiv:2505.22128v2 Announce Type: replace-cross Abstract: This work addresses mechanical defocus in Earth observation images from the IMAGIN-e mission aboard the ISS, proposing a blind deblurring approach adapted to space-based edge computing constraints. Leveraging Sentinel-2 data, our method estimates the defocus kernel and trains a restoration model within a GAN framework, effectively operating without reference images. On Sentinel-2 images with synthetic degradation, SSIM improved by 72.47% and PSNR by 25.00%, confirming the model's ability to recover lost details when the original clean image is known. On IMAGIN-e, where no reference images exist, perceptual quality metrics indicate a substantial enhancement, with NIQE improving by 60.66% and BRISQUE by 48.38%, validating real-world onboard restoration. The approach is currently deployed aboard the IMAGIN-e mission, demonstrating its practical application in an operational space environment. By efficiently handling high-resolution images under edge computing constraints, the method enables applications such as water body segmentation and contour detection while maintaining processing viability despite resource limitations.",
    "summary": "arXiv:2505.22128v2 Announce Type: replace-cross Abstract: This work addresses mechanical defocus in Earth observation images from the IMAGIN-e mission aboard the ISS, proposing a blind deblurring approach adapted to space-based edge computing constraints. Leveraging Sentinel-2 data, our method estimates the defocus kernel and trains a restoration model within a GAN framework, effectively operating without reference images. On Sentinel-2 images with synthetic degradation, SSIM improved by 72.47% and PSNR by 25.00%, confirming the model's ability to recover lost details when the original clean image is known. On IMAGIN-e, where no reference images exist, perceptual quality metrics indicate a substantial enhancement, with NIQE improving by 60.66% and BRISQUE by 48.38%, validating real-world onboard restoration. The approach is currently deployed aboard the IMAGIN-e mission, demonstrating its practical application in an operational space environment. By efficiently handling high-resolution images under edge computing constraints, the method enables applications such as water body segmentation and contour detection while maintaining processing viability despite resource limitations.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.22128",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Depth Anything at Any Condition",
    "description": "arXiv:2507.01634v1 Announce Type: cross Abstract: We present Depth Anything at Any Condition (DepthAnything-AC), a foundation monocular depth estimation (MDE) model capable of handling diverse environmental conditions. Previous foundation MDE models achieve impressive performance across general scenes but not perform well in complex open-world environments that involve challenging conditions, such as illumination variations, adverse weather, and sensor-induced distortions. To overcome the challenges of data scarcity and the inability of generating high-quality pseudo-labels from corrupted images, we propose an unsupervised consistency regularization finetuning paradigm that requires only a relatively small amount of unlabeled data. Furthermore, we propose the Spatial Distance Constraint to explicitly enforce the model to learn patch-level relative relationships, resulting in clearer semantic boundaries and more accurate details. Experimental results demonstrate the zero-shot capabilities of DepthAnything-AC across diverse benchmarks, including real-world adverse weather benchmarks, synthetic corruption benchmarks, and general benchmarks. Project Page: https://ghost233lism.github.io/depthanything-AC-page Code: https://github.com/HVision-NKU/DepthAnythingAC",
    "summary": "arXiv:2507.01634v1 Announce Type: cross Abstract: We present Depth Anything at Any Condition (DepthAnything-AC), a foundation monocular depth estimation (MDE) model capable of handling diverse environmental conditions. Previous foundation MDE models achieve impressive performance across general scenes but not perform well in complex open-world environments that involve challenging conditions, such as illumination variations, adverse weather, and sensor-induced distortions. To overcome the challenges of data scarcity and the inability of generating high-quality pseudo-labels from corrupted images, we propose an unsupervised consistency regularization finetuning paradigm that requires only a relatively small amount of unlabeled data. Furthermore, we propose the Spatial Distance Constraint to explicitly enforce the model to learn patch-level relative relationships, resulting in clearer semantic boundaries and more accurate details. Experimental results demonstrate the zero-shot capabilities of DepthAnything-AC across diverse benchmarks, including real-world adverse weather benchmarks, synthetic corruption benchmarks, and general benchmarks. Project Page: https://ghost233lism.github.io/depthanything-AC-page Code: https://github.com/HVision-NKU/DepthAnythingAC",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01634",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DALL¬∑E 3 system card",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 03 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-3-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Novel method detects microbial contamination in cell cultures",
    "description": "Ultraviolet light ‚Äúfingerprints‚Äù on cell cultures and machine learning can provide a definitive yes/no contamination assessment within 30 minutes.",
    "summary": "Ultraviolet light ‚Äúfingerprints‚Äù on cell cultures and machine learning can provide a definitive yes/no contamination assessment within 30 minutes.",
    "pubDate": "Fri, 25 Apr 2025 22:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/novel-method-detects-microbial-contamination-smart-0425",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/SMART-CAMP-Senior-Research-Engineer.jpg"
  },
  {
    "title": "Gradio joins Hugging Face!",
    "description": "",
    "summary": "Gradio is joining Hugging Face! Gradio is joining Hugging Face! By acquiring Gradio, a machine learn...",
    "pubDate": "Tue, 21 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-joins-hf",
    "thumbnail": "https://huggingface.co/blog/assets/42_gradio_joins_hf/thumbnail.png"
  },
  {
    "title": "Retrieval Augmented Generation with Huggingface Transformers and Ray",
    "description": "",
    "summary": "Retrieval Augmented Generation with Huggingface Transformers and Ray A guest blog post by Amog Kamse...",
    "pubDate": "Wed, 10 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ray-rag",
    "thumbnail": "https://huggingface.co/blog/assets/12_ray_rag/ray_arch_updated.png"
  },
  {
    "title": "OpenAI appoints Retired U.S. Army General Paul M. Nakasone to Board of Directors",
    "description": "Nakasone brings cybersecurity experience to growing Board of Directors; will join the Board‚Äôs Safety and Security Committee",
    "summary": "Nakasone brings cybersecurity experience to growing Board of Directors; will join the Board‚Äôs Safety and Security Committee",
    "pubDate": "Thu, 13 Jun 2024 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-appoints-retired-us-army-general",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2020: Applications open",
    "description": "We are now accepting applications for our third class of OpenAI Scholars.",
    "summary": "We are now accepting applications for our third class of OpenAI Scholars.",
    "pubDate": "Fri, 11 Oct 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2020",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Boolean Solution Problem from the Perspective of Predicate Logic -- Extended Version",
    "description": "arXiv:1706.08329v4 Announce Type: replace-cross Abstract: Finding solution values for unknowns in Boolean equations was a principal reasoning mode in the Algebra of Logic of the 19th century. Schr'oder investigated it as Aufl'osungsproblem (solution problem). It is closely related to the modern notion of Boolean unification. Today it is commonly presented in an algebraic setting, but seems potentially useful also in knowledge representation based on predicate logic. We show that it can be modeled on the basis of first-order logic extended by second-order quantification. A wealth of classical results transfers, foundations for algorithms unfold, and connections with second-order quantifier elimination and Craig interpolation become apparent. Although for first-order inputs the set of solutions is recursively enumerable, the development of constructive methods remains a challenge. We identify some cases that allow constructions, most of them based on Craig interpolation.",
    "summary": "arXiv:1706.08329v4 Announce Type: replace-cross Abstract: Finding solution values for unknowns in Boolean equations was a principal reasoning mode in the Algebra of Logic of the 19th century. Schr'oder investigated it as Aufl'osungsproblem (solution problem). It is closely related to the modern notion of Boolean unification. Today it is commonly presented in an algebraic setting, but seems potentially useful also in knowledge representation based on predicate logic. We show that it can be modeled on the basis of first-order logic extended by second-order quantification. A wealth of classical results transfers, foundations for algorithms unfold, and connections with second-order quantifier elimination and Craig interpolation become apparent. Although for first-order inputs the set of solutions is recursively enumerable, the development of constructive methods remains a challenge. We identify some cases that allow constructions, most of them based on Craig interpolation.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/1706.08329",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Supercharged Customer Service with Machine Learning",
    "description": "",
    "summary": "Supercharged Customer Service with Machine Learning In this blog post, we will simulate a real-world...",
    "pubDate": "Mon, 25 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/supercharge-customer-service-with-machine-learning",
    "thumbnail": "https://huggingface.co/blog/assets/61_supercharged_customer_service_with_nlp/thumbnail.png"
  },
  {
    "title": "Team update",
    "description": "We‚Äôd like to welcome the latest set of team members to OpenAI (and we‚Äôre still hiring!)",
    "summary": "We‚Äôd like to welcome the latest set of team members to OpenAI (and we‚Äôre still hiring!)",
    "pubDate": "Wed, 25 May 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Safety Gym",
    "description": "We‚Äôre releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while¬†training.",
    "summary": "We‚Äôre releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while¬†training.",
    "pubDate": "Thu, 21 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/safety-gym",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "KV Cache from scratch in nanoVLM",
    "description": "",
    "summary": "KV Cache from scratch in nanoVLM TL;DR We have implemented KV Caching from scratch in our nanoVLM re...",
    "pubDate": "Wed, 04 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kv-cache",
    "thumbnail": "https://huggingface.co/blog/assets/kv-cache/thumbnail.png"
  },
  {
    "title": "Graphcore and Hugging Face Launch New Lineup of IPU-Ready Transformers",
    "description": "",
    "summary": "Graphcore and Hugging Face Launch New Lineup of IPU-Ready Transformers Graphcore and Hugging Face ha...",
    "pubDate": "Thu, 26 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore-update",
    "thumbnail": "https://huggingface.co/blog/assets/77_graphcore-update/graphcore_update.png"
  },
  {
    "title": "Fast Inference on Large Language Models: BLOOMZ on Habana Gaudi2 Accelerator",
    "description": "",
    "summary": "Fast Inference on Large Language Models: BLOOMZ on Habana Gaudi2 Accelerator This article will show ...",
    "pubDate": "Tue, 28 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana-gaudi-2-bloom",
    "thumbnail": "https://huggingface.co/blog/assets/habana-gaudi-2-bloom/thumbnail.png"
  },
  {
    "title": "My Journey to a serverless transformers pipeline on Google Cloud",
    "description": "",
    "summary": "My Journey to a serverless transformers pipeline on Google Cloud A guest blog post by community memb...",
    "pubDate": "Thu, 18 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-deploy-a-pipeline-to-google-clouds",
    "thumbnail": "https://huggingface.co/blog/assets/14_how_to_deploy_a_pipeline_to_google_clouds/thumbnail.png"
  },
  {
    "title": "Hugging Face's TensorFlow Philosophy",
    "description": "",
    "summary": "Hugging Face's TensorFlow Philosophy Introduction Despite increasing competition from PyTorch and JA...",
    "pubDate": "Fri, 12 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tensorflow-philosophy",
    "thumbnail": "https://huggingface.co/blog/assets/96_tensorflow_philosophy/thumbnail.png"
  },
  {
    "title": "Reducing Variability of Multiple Instance Learning Methods for Digital Pathology",
    "description": "arXiv:2507.00292v2 Announce Type: replace-cross Abstract: Digital pathology has revolutionized the field by enabling the digitization of tissue samples into whole slide images (WSIs). However, the high resolution and large size of WSIs present significant challenges when it comes to applying Deep Learning models. As a solution, WSIs are often divided into smaller patches with a global label (textit{i.e., diagnostic}) per slide, instead of a (too) costly pixel-wise annotation. By treating each slide as a bag of patches, Multiple Instance Learning (MIL) methods have emerged as a suitable solution for WSI classification. A major drawback of MIL methods is their high variability in performance across different runs, which can reach up to 10-15 AUC points on the test set, making it difficult to compare different MIL methods reliably. This variability mainly comes from three factors: i) weight initialization, ii) batch (shuffling) ordering, iii) and learning rate. To address that, we introduce a Multi-Fidelity, Model Fusion strategy for MIL methods. We first train multiple models for a few epochs and average the most stable and promising ones based on validation scores. This approach can be applied to any existing MIL model to reduce performance variability. It also simplifies hyperparameter tuning and improves reproducibility while maintaining computational efficiency. We extensively validate our approach on WSI classification tasks using 2 different datasets, 3 initialization strategies and 5 MIL methods, for a total of more than 2000 experiments.",
    "summary": "arXiv:2507.00292v2 Announce Type: replace-cross Abstract: Digital pathology has revolutionized the field by enabling the digitization of tissue samples into whole slide images (WSIs). However, the high resolution and large size of WSIs present significant challenges when it comes to applying Deep Learning models. As a solution, WSIs are often divided into smaller patches with a global label (textit{i.e., diagnostic}) per slide, instead of a (too) costly pixel-wise annotation. By treating each slide as a bag of patches, Multiple Instance Learning (MIL) methods have emerged as a suitable solution for WSI classification. A major drawback of MIL methods is their high variability in performance across different runs, which can reach up to 10-15 AUC points on the test set, making it difficult to compare different MIL methods reliably. This variability mainly comes from three factors: i) weight initialization, ii) batch (shuffling) ordering, iii) and learning rate. To address that, we introduce a Multi-Fidelity, Model Fusion strategy for MIL methods. We first train multiple models for a few epochs and average the most stable and promising ones based on validation scores. This approach can be applied to any existing MIL model to reduce performance variability. It also simplifies hyperparameter tuning and improves reproducibility while maintaining computational efficiency. We extensively validate our approach on WSI classification tasks using 2 different datasets, 3 initialization strategies and 5 MIL methods, for a total of more than 2000 experiments.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.00292",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Customizing GPT-3 for your application",
    "description": "Fine-tune with a single¬†command.",
    "summary": "Fine-tune with a single¬†command.",
    "pubDate": "Tue, 14 Dec 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/customizing-gpt-3",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?",
    "description": "arXiv:2506.18183v2 Announce Type: replace Abstract: Reasoning language models have set state-of-the-art (SOTA) records on many challenging benchmarks, enabled by multi-step reasoning induced using reinforcement learning. However, like previous language models, reasoning models are prone to generating confident, plausible responses that are incorrect (hallucinations). Knowing when and how much to trust these models is critical to the safe deployment of reasoning models in real-world applications. To this end, we explore uncertainty quantification of reasoning models in this work. Specifically, we ask three fundamental questions: First, are reasoning models well-calibrated? Second, does deeper reasoning improve model calibration? Finally, inspired by humans' innate ability to double-check their thought processes to verify the validity of their answers and their confidence, we ask: can reasoning models improve their calibration by explicitly reasoning about their chain-of-thought traces? We introduce introspective uncertainty quantification (UQ) to explore this direction. In extensive evaluations on SOTA reasoning models across a broad range of benchmarks, we find that reasoning models: (i) are typically overconfident, with self-verbalized confidence estimates often greater than 85% particularly for incorrect responses, (ii) become even more overconfident with deeper reasoning, and (iii) can become better calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not uniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we conclude with important research directions to design necessary UQ benchmarks and improve the calibration of reasoning models.",
    "summary": "arXiv:2506.18183v2 Announce Type: replace Abstract: Reasoning language models have set state-of-the-art (SOTA) records on many challenging benchmarks, enabled by multi-step reasoning induced using reinforcement learning. However, like previous language models, reasoning models are prone to generating confident, plausible responses that are incorrect (hallucinations). Knowing when and how much to trust these models is critical to the safe deployment of reasoning models in real-world applications. To this end, we explore uncertainty quantification of reasoning models in this work. Specifically, we ask three fundamental questions: First, are reasoning models well-calibrated? Second, does deeper reasoning improve model calibration? Finally, inspired by humans' innate ability to double-check their thought processes to verify the validity of their answers and their confidence, we ask: can reasoning models improve their calibration by explicitly reasoning about their chain-of-thought traces? We introduce introspective uncertainty quantification (UQ) to explore this direction. In extensive evaluations on SOTA reasoning models across a broad range of benchmarks, we find that reasoning models: (i) are typically overconfident, with self-verbalized confidence estimates often greater than 85% particularly for incorrect responses, (ii) become even more overconfident with deeper reasoning, and (iii) can become better calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not uniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we conclude with important research directions to design necessary UQ benchmarks and improve the calibration of reasoning models.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18183",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Build AI on premise with Dell Enterprise Hub",
    "description": "",
    "summary": "Build AI on premise with Dell Enterprise Hub Today we announce the Dell Enterprise Hub, a new experi...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dell-enterprise-hub",
    "thumbnail": "https://huggingface.co/blog/assets/dell-enterprise-hub/thumbnail.jpg"
  },
  {
    "title": "Introducing ChatGPT Pro",
    "description": "Broadening usage of frontier AI",
    "summary": "Broadening usage of frontier AI",
    "pubDate": "Thu, 05 Dec 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-pro",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evolution strategies as a scalable alternative to reinforcement learning",
    "description": "We‚Äôve discovered that evolution strategies (ES), an optimization technique that‚Äôs been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks (e.g. Atari/MuJoCo), while overcoming many of RL‚Äôs inconveniences.",
    "summary": "We‚Äôve discovered that evolution strategies (ES), an optimization technique that‚Äôs been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks (e.g. Atari/MuJoCo), while overcoming many of RL‚Äôs inconveniences.",
    "pubDate": "Fri, 24 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolution-strategies",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and JFrog partner to make AI Security more transparent",
    "description": "",
    "summary": "Hugging Face and JFrog partner to make AI Security more transparent We are pleased to announce our p...",
    "pubDate": "Tue, 04 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/jfrog",
    "thumbnail": "https://huggingface.co/blog/assets/jfrog/thumbnail.png"
  },
  {
    "title": "Introducing DOI: the Digital Object Identifier to Datasets and Models",
    "description": "",
    "summary": "Introducing DOI: the Digital Object Identifier to Datasets and Models Our mission at Hugging Face is...",
    "pubDate": "Fri, 07 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-doi",
    "thumbnail": "https://huggingface.co/blog/assets/107_launching_doi/thumbnail.jpeg"
  },
  {
    "title": "E2EÈü≥Â£∞ÂØæË©±API„ÉªÊßãÁØâ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÊúÄÊñ∞ÂãïÂêë„ÅÆË™øÊüª„Å®Ëá™ÂæãÂûãÈü≥Â£∞ÂØæË©±„Ç∑„Çπ„ÉÜ„É†„ÅÆÂ±ïÊúõ",
    "description": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ ËøëÂπ¥„ÄÅÈü≥Â£∞ÂØæË©±„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆÈÄ≤Âåñ„ÅåÁõÆË¶ö„Åæ„Åó„Åè„ÄÅÈ°ßÂÆ¢ÂØæÂøú„ÅÆËá™ÂãïÂåñ„ÇÑÊ•≠ÂãôÂäπÁéáÂåñ„Å∏„ÅÆÊúüÂæÖ„ÅåÈ´ò„Åæ„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇÂºäÁ§æ„ÅÆAI Messenger Voicebot„ÇÇ‰æãÂ§ñ„Åß„ÅØ„Å™„Åè„ÄÅÊúÄÂÖàÁ´Ø [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5852' rel='nofollow'>E2EÈü≥Â£∞ÂØæË©±API„ÉªÊßãÁØâ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÊúÄÊñ∞ÂãïÂêë„ÅÆË™øÊüª„Å®Ëá™ÂæãÂûãÈü≥Â£∞ÂØæË©±„Ç∑„Çπ„ÉÜ„É†„ÅÆÂ±ïÊúõ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ ËøëÂπ¥„ÄÅÈü≥Â£∞ÂØæË©±„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆÈÄ≤Âåñ„ÅåÁõÆË¶ö„Åæ„Åó„Åè„ÄÅÈ°ßÂÆ¢ÂØæÂøú„ÅÆËá™ÂãïÂåñ„ÇÑÊ•≠ÂãôÂäπÁéáÂåñ„Å∏„ÅÆÊúüÂæÖ„ÅåÈ´ò„Åæ„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇÂºäÁ§æ„ÅÆAI Messenger Voicebot„ÇÇ‰æãÂ§ñ„Åß„ÅØ„Å™„Åè„ÄÅÊúÄÂÖàÁ´Ø [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5852' rel='nofollow'>E2EÈü≥Â£∞ÂØæË©±API„ÉªÊßãÁØâ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÊúÄÊñ∞ÂãïÂêë„ÅÆË™øÊüª„Å®Ëá™ÂæãÂûãÈü≥Â£∞ÂØæË©±„Ç∑„Çπ„ÉÜ„É†„ÅÆÂ±ïÊúõ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Fri, 30 May 2025 01:38:01 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5852",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/icon.png"
  },
  {
    "title": "WebGPT: Improving the factual accuracy of language models through web browsing",
    "description": "We‚Äôve fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.",
    "summary": "We‚Äôve fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.",
    "pubDate": "Thu, 16 Dec 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/webgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Leveraging Hugging Face for complex generative AI use cases",
    "description": "",
    "summary": "Leveraging Hugging Face for complex generative AI use casess Published July 1, 2023 Update on GitHub...",
    "pubDate": "Sat, 01 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/writer-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/writer.png"
  },
  {
    "title": "Introducing Stargate UAE",
    "description": "We‚Äôre launching Stargate UAE ‚Äì the first international deployment of Stargate, OpenAI‚Äôs AI infrastructure platform.",
    "summary": "We‚Äôre launching Stargate UAE ‚Äì the first international deployment of Stargate, OpenAI‚Äôs AI infrastructure platform.",
    "pubDate": "Thu, 22 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-stargate-uae",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DABStep: Data Agent Benchmark for Multi-step Reasoning",
    "description": "",
    "summary": "DABStep: Data Agent Benchmark for Multi-step Reasoning Language models are becoming increasingly cap...",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dabstep",
    "thumbnail": "https://huggingface.co/blog/assets/dabstep/thumbnail.png"
  },
  {
    "title": "Gradio-Lite: Serverless Gradio Running Entirely in Your Browser",
    "description": "",
    "summary": "Gradio-Lite: Serverless Gradio Running Entirely in Your Browser Gradio is a popular Python library f...",
    "pubDate": "Thu, 19 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-lite",
    "thumbnail": "https://huggingface.co/blog/assets/167_gradio_lite/thumbnail.png"
  },
  {
    "title": "Introducing Three New Serverless Inference Providers: Hyperbolic, Nebius AI Studio, and Novita üî•",
    "description": "",
    "summary": "Introducing Three New Serverless Inference Providers: Hyperbolic, Nebius AI Studio, and Novita üî• We‚Äô...",
    "pubDate": "Tue, 18 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-nebius-novita-hyperbolic",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/second-batch-thumbnail.webp"
  },
  {
    "title": "AI stirs up the recipe for concrete in MIT study",
    "description": "With demand for cement alternatives rising, an MIT team uses machine learning to hunt for new ingredients across the scientific literature.",
    "summary": "With demand for cement alternatives rising, an MIT team uses machine learning to hunt for new ingredients across the scientific literature.",
    "pubDate": "Mon, 02 Jun 2025 15:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-stirs-recipe-for-concrete-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Soroush-Mahjoubi.jpg"
  },
  {
    "title": "Enhanced Influence-aware Group Recommendation for Online Media Propagation",
    "description": "arXiv:2507.01616v1 Announce Type: cross Abstract: Group recommendation over social media streams has attracted significant attention due to its wide applications in domains such as e-commerce, entertainment, and online news broadcasting. By leveraging social connections and group behaviours, group recommendation (GR) aims to provide more accurate and engaging content to a set of users rather than individuals. Recently, influence-aware GR has emerged as a promising direction, as it considers the impact of social influence on group decision-making. In earlier work, we proposed Influence-aware Group Recommendation (IGR) to solve this task. However, this task remains challenging due to three key factors: the large and ever-growing scale of social graphs, the inherently dynamic nature of influence propagation within user groups, and the high computational overhead of real-time group-item matching. To tackle these issues, we propose an Enhanced Influence-aware Group Recommendation (EIGR) framework. First, we introduce a Graph Extraction-based Sampling (GES) strategy to minimise redundancy across multiple temporal social graphs and effectively capture the evolving dynamics of both groups and items. Second, we design a novel DYnamic Independent Cascade (DYIC) model to predict how influence propagates over time across social items and user groups. Finally, we develop a two-level hash-based User Group Index (UG-Index) to efficiently organise user groups and enable real-time recommendation generation. Extensive experiments on real-world datasets demonstrate that our proposed framework, EIGR, consistently outperforms state-of-the-art baselines in both effectiveness and efficiency.",
    "summary": "arXiv:2507.01616v1 Announce Type: cross Abstract: Group recommendation over social media streams has attracted significant attention due to its wide applications in domains such as e-commerce, entertainment, and online news broadcasting. By leveraging social connections and group behaviours, group recommendation (GR) aims to provide more accurate and engaging content to a set of users rather than individuals. Recently, influence-aware GR has emerged as a promising direction, as it considers the impact of social influence on group decision-making. In earlier work, we proposed Influence-aware Group Recommendation (IGR) to solve this task. However, this task remains challenging due to three key factors: the large and ever-growing scale of social graphs, the inherently dynamic nature of influence propagation within user groups, and the high computational overhead of real-time group-item matching. To tackle these issues, we propose an Enhanced Influence-aware Group Recommendation (EIGR) framework. First, we introduce a Graph Extraction-based Sampling (GES) strategy to minimise redundancy across multiple temporal social graphs and effectively capture the evolving dynamics of both groups and items. Second, we design a novel DYnamic Independent Cascade (DYIC) model to predict how influence propagates over time across social items and user groups. Finally, we develop a two-level hash-based User Group Index (UG-Index) to efficiently organise user groups and enable real-time recommendation generation. Extensive experiments on real-world datasets demonstrate that our proposed framework, EIGR, consistently outperforms state-of-the-art baselines in both effectiveness and efficiency.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01616",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Synthetic Data Generator - Build Datasets with Natural Language",
    "description": "",
    "summary": "Introducing the Synthetic Data Generator - Build Datasets with Natural Language Introducing the Synt...",
    "pubDate": "Mon, 16 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthetic-data-generator",
    "thumbnail": "https://huggingface.co/blog/assets/synthetic-data-generator/_thumbnail.png"
  },
  {
    "title": "„ÄåAI SHIFT SUMMIT 2025„Äç„É¨„Éù„Éº„Éà‚îÄ‰ºÅÊ•≠„ÅÆÊúÄÂâçÁ∑ö„Å´Ë¶ã„ÇãAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÆüË£Ö„ÅÆ‰ªä",
    "description": "<p>2025Âπ¥„ÅØ„ÄåAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÖÉÂπ¥„Äç„Å®„ÇÇÂëº„Å∞„Çå„ÄÅËá™ÂæãÂûãAI„ÅÆÁ§æ‰ºöÂÆüË£Ö„Å´Ê≥®ÁõÆ„ÅåÈõÜ„Åæ„ÇãÂπ¥„Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„ÅÜ„Åó„ÅüÊΩÆÊµÅ„ÅÆ‰∏≠„ÄÅÊ†™Âºè‰ºöÁ§æAI Shift‰∏ªÂÇ¨„ÅßÈñãÂÇ¨„Åï„Çå„Åü„ÄåAI SHIFT SUMMIT 2025„Äç„Åß„ÅØ„ÄÅMicros [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ai-shift-summit-2025-ai-agent/'>„ÄåAI SHIFT SUMMIT 2025„Äç„É¨„Éù„Éº„Éà‚îÄ‰ºÅÊ•≠„ÅÆÊúÄÂâçÁ∑ö„Å´Ë¶ã„ÇãAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÆüË£Ö„ÅÆ‰ªä</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>2025Âπ¥„ÅØ„ÄåAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÖÉÂπ¥„Äç„Å®„ÇÇÂëº„Å∞„Çå„ÄÅËá™ÂæãÂûãAI„ÅÆÁ§æ‰ºöÂÆüË£Ö„Å´Ê≥®ÁõÆ„ÅåÈõÜ„Åæ„ÇãÂπ¥„Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„ÅÜ„Åó„ÅüÊΩÆÊµÅ„ÅÆ‰∏≠„ÄÅÊ†™Âºè‰ºöÁ§æAI Shift‰∏ªÂÇ¨„ÅßÈñãÂÇ¨„Åï„Çå„Åü„ÄåAI SHIFT SUMMIT 2025„Äç„Åß„ÅØ„ÄÅMicros [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ai-shift-summit-2025-ai-agent/'>„ÄåAI SHIFT SUMMIT 2025„Äç„É¨„Éù„Éº„Éà‚îÄ‰ºÅÊ•≠„ÅÆÊúÄÂâçÁ∑ö„Å´Ë¶ã„ÇãAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÆüË£Ö„ÅÆ‰ªä</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Tue, 01 Jul 2025 01:24:49 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/ai-shift-summit-2025-ai-agent/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/main-1.png"
  },
  {
    "title": "Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation",
    "description": "arXiv:2507.01631v1 Announce Type: cross Abstract: Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D reconstruction from multiview satellite imagery. However, state-of-the-art NeRF methods are typically constrained to small scenes due to the memory footprint during training, which we study in this paper. Previous work on large-scale NeRFs palliate this by dividing the scene into NeRFs. This paper introduces Snake-NeRF, a framework that scales to large scenes. Our out-of-core method eliminates the need to load all images and networks simultaneously, and operates on a single device. We achieve this by dividing the region of interest into NeRFs that 3D tile without overlap. Importantly, we crop the images with overlap to ensure each NeRFs is trained with all the necessary pixels. We introduce a novel $2times 2$ 3D tile progression strategy and segmented sampler, which together prevent 3D reconstruction errors along the tile edges. Our experiments conclude that large satellite images can effectively be processed with linear time complexity, on a single GPU, and without compromise in quality.",
    "summary": "arXiv:2507.01631v1 Announce Type: cross Abstract: Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D reconstruction from multiview satellite imagery. However, state-of-the-art NeRF methods are typically constrained to small scenes due to the memory footprint during training, which we study in this paper. Previous work on large-scale NeRFs palliate this by dividing the scene into NeRFs. This paper introduces Snake-NeRF, a framework that scales to large scenes. Our out-of-core method eliminates the need to load all images and networks simultaneously, and operates on a single device. We achieve this by dividing the region of interest into NeRFs that 3D tile without overlap. Importantly, we crop the images with overlap to ensure each NeRFs is trained with all the necessary pixels. We introduce a novel $2times 2$ 3D tile progression strategy and segmented sampler, which together prevent 3D reconstruction errors along the tile edges. Our experiments conclude that large satellite images can effectively be processed with linear time complexity, on a single GPU, and without compromise in quality.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01631",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Competitive self-play",
    "description": "We‚Äôve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind. Self-play ensures that the environment is always the right difficulty for an AI to improve. Taken alongside our Dota 2 self-play results, we have increasing confidence that self-play will be a core part of powerful AI systems in the future.",
    "summary": "We‚Äôve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind. Self-play ensures that the environment is always the right difficulty for an AI to improve. Taken alongside our Dota 2 self-play results, we have increasing confidence that self-play will be a core part of powerful AI systems in the future.",
    "pubDate": "Wed, 11 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/competitive-self-play",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Creating a Coding Assistant with StarCoder",
    "description": "",
    "summary": "Creating a Coding Assistant with StarCoder If you‚Äôre a software developer, chances are that you‚Äôve u...",
    "pubDate": "Tue, 09 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starchat-alpha",
    "thumbnail": "https://huggingface.co/blog/assets/starchat_alpha/thumbnail.png"
  },
  {
    "title": "Millions of new materials discovered with deep learning",
    "description": "We share the discovery of 2.2 million new crystals  ‚Äì  equivalent to nearly 800 years‚Äô worth of knowledge. We introduce Graph Networks for Materials Exploration (GNoME), our new deep learning tool that dramatically increases the speed and efficiency of discovery by predicting the stability of new materials.",
    "summary": "We share the discovery of 2.2 million new crystals  ‚Äì  equivalent to nearly 800 years‚Äô worth of knowledge. We introduce Graph Networks for Materials Exploration (GNoME), our new deep learning tool that dramatically increases the speed and efficiency of discovery by predicting the stability of new materials.",
    "pubDate": "Wed, 29 Nov 2023 16:04:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/",
    "thumbnail": "https://lh3.googleusercontent.com/mq3mFiVHSVuszhJMt-Nz4jckN5qy3cAckEIdNYDPhy8UHjxk4VkGFriqo8sA76teioNQ2fC3qgMH7FJfPc0L5JJPppXiZzHP7Rl3UodlU4IC4TWw=w1200-h630-n-nu"
  },
  {
    "title": "Scaling AI-based Data Processing with Hugging Face + Dask",
    "description": "",
    "summary": "Scaling AI-Based Data Processing with Hugging Face + Dask The Hugging Face platform has many dataset...",
    "pubDate": "Wed, 09 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dask-scaling",
    "thumbnail": "https://huggingface.co/blog/assets/dask-scaling/thumbnail.png"
  },
  {
    "title": "Accelerate 1.0.0",
    "description": "",
    "summary": "Accelerate 1.0.0 What is Accelerate today? 3.5 years ago, Accelerate was a simple framework aimed at...",
    "pubDate": "Fri, 13 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-v1",
    "thumbnail": "https://huggingface.co/blog/assets/186_accelerate_v1/accelerate_v1_thumbnail.png"
  },
  {
    "title": "Agent-as-Tool: A Study on the Hierarchical Decision Making with Reinforcement Learning",
    "description": "arXiv:2507.01489v1 Announce Type: new Abstract: Large Language Models (LLMs) have emerged as one of the most significant technological advancements in artificial intelligence in recent years. Their ability to understand, generate, and reason with natural language has transformed how we interact with AI systems. With the development of LLM-based agents and reinforcement-learning-based reasoning models, the study of applying reinforcement learning in agent frameworks has become a new research focus. However, all previous studies face the challenge of deciding the tool calling process and the reasoning process simultaneously, and the chain of reasoning was solely relied on the unprocessed raw result with redundant information and symbols unrelated to the task from the tool, which impose a heavy burden on the model's capability to reason. Therefore, in our research, we proposed a hierarchical framework Agent-as-tool that detach the tool calling process and the reasoning process, which enables the model to focus on the verbally reasoning process while the tool calling process is handled by another agent. Our work had achieved comparable results with only a slight reinforcement fine-tuning on 180 samples, and had achieved exceptionally well performance in Bamboogle with 63.2% of exact match and 75.2% in cover exact match, exceeding Search-R1 by 4.8% in exact match and 3.2% in cover exact match.",
    "summary": "arXiv:2507.01489v1 Announce Type: new Abstract: Large Language Models (LLMs) have emerged as one of the most significant technological advancements in artificial intelligence in recent years. Their ability to understand, generate, and reason with natural language has transformed how we interact with AI systems. With the development of LLM-based agents and reinforcement-learning-based reasoning models, the study of applying reinforcement learning in agent frameworks has become a new research focus. However, all previous studies face the challenge of deciding the tool calling process and the reasoning process simultaneously, and the chain of reasoning was solely relied on the unprocessed raw result with redundant information and symbols unrelated to the task from the tool, which impose a heavy burden on the model's capability to reason. Therefore, in our research, we proposed a hierarchical framework Agent-as-tool that detach the tool calling process and the reasoning process, which enables the model to focus on the verbally reasoning process while the tool calling process is handled by another agent. Our work had achieved comparable results with only a slight reinforcement fine-tuning on 180 samples, and had achieved exceptionally well performance in Bamboogle with 63.2% of exact match and 75.2% in cover exact match, exceeding Search-R1 by 4.8% in exact match and 3.2% in cover exact match.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01489",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "WWDC 24: Running Mistral 7B with Core ML",
    "description": "",
    "summary": "WWDC 24: Running Mistral 7B with Core ML WWDC‚Äô 24 is the moment Apple officially unveiled Apple Inte...",
    "pubDate": "Mon, 22 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mistral-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/mistral-coreml/thumbnail.png"
  },
  {
    "title": "Director of Machine Learning Insights [Series]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 1] Few seats at the Machine Learning table span both tec...",
    "pubDate": "Wed, 27 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights",
    "thumbnail": "https://huggingface.co/blog/assets/61_ml_director_insights/thumbnail.png"
  },
  {
    "title": "Improving Prompt Consistency with Structured Generations",
    "description": "",
    "summary": "Improving Prompt Consistency with Structured Generations Recently, the Leaderboards and Evals resear...",
    "pubDate": "Tue, 30 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/evaluation-structured-outputs",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "AI Policy @ü§ó: Comments on U.S. National AI Research Resource Interim Report",
    "description": "",
    "summary": "AI Policy @ü§ó: Comments on U.S. National AI Research Resource Interim Report In late June 2022, Huggi...",
    "pubDate": "Mon, 01 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/us-national-ai-research-resource",
    "thumbnail": "https://huggingface.co/blog/assets/92_us_national_ai_research_resource/nairr_thumbnail.png"
  },
  {
    "title": "Language models are few-shot learners",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 28 May 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-models-are-few-shot-learners",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing improvements to the fine-tuning API and expanding our custom models program",
    "description": "We‚Äôre adding new features to help developers have more control over fine-tuning and announcing new ways to build custom models with OpenAI.",
    "summary": "We‚Äôre adding new features to help developers have more control over fine-tuning and announcing new ways to build custom models with OpenAI.",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "‰∏â‰∫ï‰ΩèÂèãFG„ÄÅÁîüÊàêAIÊ¥ªÁî®„ÅßÂ§ßÊâãÊ≥ïÂæã‰∫ãÂãôÊâÄ„Å®Êñ∞‰ºöÁ§æ„ÄÄÂ•ëÁ¥ÑÊ•≠Âãô„ÅÆÂäπÁéáÂåñÂõ≥„Çã",
    "description": "‰∏â‰∫ï‰ΩèÂèã„Éï„Ç£„Éä„É≥„Ç∑„É£„É´„Ç∞„É´„Éº„ÉóÔºàFGÔºâ„Åå„ÄÅ„Ç¢„É≥„ÉÄ„Éº„ÇΩ„É≥„ÉªÊØõÂà©„ÉªÂèãÂ∏∏Ê≥ïÂæã‰∫ãÂãôÊâÄ„Å™„Å©„Å®ÂÖ±Âêå„Åß„ÄÅÁîüÊàêAIÔºà‰∫∫Â∑•Áü•ËÉΩÔºâ„ÇíÊ¥ªÁî®„Åó‰ºÅÊ•≠Èñì„ÅÆÂ•ëÁ¥Ñ„ÅÆ‰ΩúÊàê„ÇÑÂàÜÊûê„Å™„Å©„ÅÆ„Çµ„Éº„Éì„Çπ„ÇíÊèê‰æõ„Åô„ÇãÊñ∞‰ºöÁ§æ„ÄåSMBC„É™„Éº„Ç¨„É´XÔºà„ÇØ„É≠„ÇπÔºâ„Äç„ÇíË®≠Á´ã„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇÂ§ßÊâãÊ≥ïÂæã‰∫ãÂãôÊâÄ„ÅåÊåÅ„Å§Ê≥ïÂãô„ÅÆÁü•Ë¶ã„Å®ÁîüÊàêAI„ÅÆÊäÄË°ì„ÇíÂêà„Çè„Åõ„Å¶Â•ëÁ¥ÑÊ•≠Âãô„ÇíÂäπÁéáÂåñ„Åó„ÄÅ„Ç§„É≥„Éâ„Å™„Å©„Ç¢„Ç∏„Ç¢Ë´∏ÂõΩ„Å∏„ÅÆ‰∫ãÊ•≠Êã°Â§ß„ÇÇÁõÆÊåá„Åô„ÄÇ",
    "summary": "‰∏â‰∫ï‰ΩèÂèã„Éï„Ç£„Éä„É≥„Ç∑„É£„É´„Ç∞„É´„Éº„ÉóÔºàFGÔºâ„Åå„ÄÅ„Ç¢„É≥„ÉÄ„Éº„ÇΩ„É≥„ÉªÊØõÂà©„ÉªÂèãÂ∏∏Ê≥ïÂæã‰∫ãÂãôÊâÄ„Å™„Å©„Å®ÂÖ±Âêå„Åß„ÄÅÁîüÊàêAIÔºà‰∫∫Â∑•Áü•ËÉΩÔºâ„ÇíÊ¥ªÁî®„Åó‰ºÅÊ•≠Èñì„ÅÆÂ•ëÁ¥Ñ„ÅÆ‰ΩúÊàê„ÇÑÂàÜÊûê„Å™„Å©„ÅÆ„Çµ„Éº„Éì„Çπ„ÇíÊèê‰æõ„Åô„ÇãÊñ∞‰ºöÁ§æ„ÄåSMBC„É™„Éº„Ç¨„É´XÔºà„ÇØ„É≠„ÇπÔºâ„Äç„ÇíË®≠Á´ã„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇÂ§ßÊâãÊ≥ïÂæã‰∫ãÂãôÊâÄ„ÅåÊåÅ„Å§Ê≥ïÂãô„ÅÆÁü•Ë¶ã„Å®ÁîüÊàêAI„ÅÆÊäÄË°ì„ÇíÂêà„Çè„Åõ„Å¶Â•ëÁ¥ÑÊ•≠Âãô„ÇíÂäπÁéáÂåñ„Åó„ÄÅ„Ç§„É≥„Éâ„Å™„Å©„Ç¢„Ç∏„Ç¢Ë´∏ÂõΩ„Å∏„ÅÆ‰∫ãÊ•≠Êã°Â§ß„ÇÇÁõÆÊåá„Åô„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 17:55:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2507/03/news108.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2507/03/cover_news108.jpg"
  },
  {
    "title": "Hugging Face and IBM partner on watsonx.ai, the next-generation enterprise studio for AI builders",
    "description": "",
    "summary": "Hugging Face and IBM partner on watsonx.ai, the next-generation enterprise studio for AI builders Al...",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-ibm",
    "thumbnail": "https://huggingface.co/blog/assets/144_ibm/01.png"
  },
  {
    "title": "Open Preference Dataset for Text-to-Image Generation by the ü§ó Community",
    "description": "",
    "summary": "Open Preference Dataset for Text-to-Image Generation by the ü§ó Community The Data is Better Together ...",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-preferences",
    "thumbnail": "https://huggingface.co/blog/assets/image_preferences/thumbnail.png"
  },
  {
    "title": "Can Argus Judge Them All? Comparing VLMs Across Domains",
    "description": "arXiv:2507.01042v1 Announce Type: cross Abstract: Vision-Language Models (VLMs) are advancing multimodal AI, yet their performance consistency across tasks is underexamined. We benchmark CLIP, BLIP, and LXMERT across diverse datasets spanning retrieval, captioning, and reasoning. Our evaluation includes task accuracy, generation quality, efficiency, and a novel Cross-Dataset Consistency (CDC) metric. CLIP shows strongest generalization (CDC: 0.92), BLIP excels on curated data, and LXMERT leads in structured reasoning. These results expose trade-offs between generalization and specialization, informing industrial deployment of VLMs and guiding development toward robust, task-flexible architectures.",
    "summary": "arXiv:2507.01042v1 Announce Type: cross Abstract: Vision-Language Models (VLMs) are advancing multimodal AI, yet their performance consistency across tasks is underexamined. We benchmark CLIP, BLIP, and LXMERT across diverse datasets spanning retrieval, captioning, and reasoning. Our evaluation includes task accuracy, generation quality, efficiency, and a novel Cross-Dataset Consistency (CDC) metric. CLIP shows strongest generalization (CDC: 0.92), BLIP excels on curated data, and LXMERT leads in structured reasoning. These results expose trade-offs between generalization and specialization, informing industrial deployment of VLMs and guiding development toward robust, task-flexible architectures.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01042",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemini breaks new ground: a faster model, longer context and AI agents",
    "description": "We‚Äôre introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants.",
    "summary": "We‚Äôre introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants.",
    "pubDate": "Tue, 14 May 2024 17:58:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-breaks-new-ground-a-faster-model-longer-context-and-ai-agents/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_Blog_Social_Share.width-1300.png"
  },
  {
    "title": "Google Cloud: Driving digital transformation",
    "description": "Google Cloud empowers organizations to digitally transform themselves into smarter businesses. It offers cloud computing, data analytics, and the latest artificial intelligence (AI) and machine learning tools.",
    "summary": "Google Cloud empowers organizations to digitally transform themselves into smarter businesses. It offers cloud computing, data analytics, and the latest artificial intelligence (AI) and machine learning tools.",
    "pubDate": "Wed, 14 Jun 2023 14:51:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-cloud-driving-digital-transformation/",
    "thumbnail": "https://lh3.googleusercontent.com/xIps-6-tV3GGWQjVrHYTkLGnXAdZwmjG6jOAgECP5aynUXKeAfUhWv7fFfjPaV8Jmn3B3IabKBeDzBtB491hJAozuAhdQ-TUtZ5dzy9dmE1zWC-J=w1200-h630-n-nu"
  },
  {
    "title": "Weak-to-strong generalization",
    "description": "We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning to control strong models with weak supervisors?",
    "summary": "We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning to control strong models with weak supervisors?",
    "pubDate": "Thu, 14 Dec 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/weak-to-strong-generalization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "description": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "summary": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "pubDate": "Tue, 22 Oct 2024 06:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lenfest-institute",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reptile: A scalable meta-learning algorithm",
    "description": "We‚Äôve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task, performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters learned on that task. Reptile is the application of the Shortest Descent algorithm to the meta-learning setting, and is mathematically similar to first-order MAML (which is a version of the well-known MAML algorithm) that only needs black-box access to an optimizer such as SGD or Adam, with similar computational efficiency and performance.",
    "summary": "We‚Äôve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task, performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters learned on that task. Reptile is the application of the Shortest Descent algorithm to the meta-learning setting, and is mathematically similar to first-order MAML (which is a version of the well-known MAML algorithm) that only needs black-box access to an optimizer such as SGD or Adam, with similar computational efficiency and performance.",
    "pubDate": "Wed, 07 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reptile",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing New Hugging Face and KerasHub integration",
    "description": "",
    "summary": "Announcing New Hugging Face and KerasHub integration The Hugging Face Hub is a vast repository, curr...",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-hub-integration",
    "thumbnail": "https://huggingface.co/blog/assets/keras-hub-integration/thumbnail.png"
  },
  {
    "title": "Making ML-powered web games with Transformers.js",
    "description": "",
    "summary": "Making ML-powered web games with Transformers.js In this blog post, I'll show you how I made Doodle ...",
    "pubDate": "Wed, 05 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-web-games",
    "thumbnail": "https://huggingface.co/blog/assets/ml-web-games/thumbnail.png"
  },
  {
    "title": "Xet is on the Hub",
    "description": "",
    "summary": "Xet is on the Hub Click here to read about joining the Xet waitlist (or head over to join immediatel...",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xet-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/xet-on-the-hub/thumbnail.png"
  },
  {
    "title": "Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs",
    "description": "arXiv:2506.22146v2 Announce Type: replace-cross Abstract: Despite progress in Vision-Language Models (VLMs), their capacity for visual reasoning is often limited by the textit{binding problem}: the failure to reliably associate perceptual features with their correct visual referents. This limitation underlies persistent errors in tasks such as counting, visual search, scene description, and spatial relationship understanding. A key factor is that current VLMs process visual features largely in parallel, lacking mechanisms for spatially grounded, serial attention. This paper introduces a simple yet effective intervention: augmenting visual inputs with low-level spatial structures (e.g., horizontal lines) and pairing this with a textual prompt that encourages sequential, spatially-aware parsing. We empirically demonstrate substantial performance improvements across core visual reasoning tasks. Specifically, our method improves GPT-4o visual search accuracy by 25.00%, increases counting accuracy by 26.83%, reduces edit distance error in scene description by 0.32, and enhances performance on spatial relationship tasks by 9.50% on a a 2D synthetic dataset. Furthermore, we find that the visual modification is essential for these gains; purely textual strategies, including Chain-of-Thought prompting, are insufficient and can even degrade performance. Our method enhances binding only with a single-query inference, underscoring the importance of visual input design over purely linguistically-based approaches. These findings suggest that low-level visual structuring is a powerful and underexplored direction for improving compositional visual reasoning and could serve as a general strategy for enhancing VLM performance on spatially grounded tasks.",
    "summary": "arXiv:2506.22146v2 Announce Type: replace-cross Abstract: Despite progress in Vision-Language Models (VLMs), their capacity for visual reasoning is often limited by the textit{binding problem}: the failure to reliably associate perceptual features with their correct visual referents. This limitation underlies persistent errors in tasks such as counting, visual search, scene description, and spatial relationship understanding. A key factor is that current VLMs process visual features largely in parallel, lacking mechanisms for spatially grounded, serial attention. This paper introduces a simple yet effective intervention: augmenting visual inputs with low-level spatial structures (e.g., horizontal lines) and pairing this with a textual prompt that encourages sequential, spatially-aware parsing. We empirically demonstrate substantial performance improvements across core visual reasoning tasks. Specifically, our method improves GPT-4o visual search accuracy by 25.00%, increases counting accuracy by 26.83%, reduces edit distance error in scene description by 0.32, and enhances performance on spatial relationship tasks by 9.50% on a a 2D synthetic dataset. Furthermore, we find that the visual modification is essential for these gains; purely textual strategies, including Chain-of-Thought prompting, are insufficient and can even degrade performance. Our method enhances binding only with a single-query inference, underscoring the importance of visual input design over purely linguistically-based approaches. These findings suggest that low-level visual structuring is a powerful and underexplored direction for improving compositional visual reasoning and could serve as a general strategy for enhancing VLM performance on spatially grounded tasks.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22146",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Model Spec",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-model-spec",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building AI-powered apps for business",
    "description": "Retool uses GPT-4 to give businesses a fast, secure way to build AI-powered apps.",
    "summary": "Retool uses GPT-4 to give businesses a fast, secure way to build AI-powered apps.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retool",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent",
    "description": "",
    "summary": "Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent Introduction We're excited to ...",
    "pubDate": "Mon, 22 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/jat",
    "thumbnail": "https://huggingface.co/blog/assets/jat/thumbnail.png"
  },
  {
    "title": "Diffusion Models Live Event",
    "description": "",
    "summary": "Diffusion Models Live Event We are excited to share that the Diffusion Models Class with Hugging Fac...",
    "pubDate": "Fri, 25 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusion-models-event",
    "thumbnail": "https://huggingface.co/blog/assets/diffusion-models-event/thumbnail.png"
  },
  {
    "title": "Finetune Stable Diffusion Models with DDPO via TRL",
    "description": "",
    "summary": "Finetune Stable Diffusion Models with DDPO via TRL Introduction Diffusion models (e.g., DALL-E 2, St...",
    "pubDate": "Fri, 29 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trl-ddpo",
    "thumbnail": "https://huggingface.co/blog/assets/166_trl_ddpo/thumbnail.png"
  },
  {
    "title": "Building smarter maps with GPT-4o vision fine-tuning",
    "description": "Building smarter maps with GPT-4o vision fine-tuning",
    "summary": "Building smarter maps with GPT-4o vision fine-tuning",
    "pubDate": "Wed, 20 Nov 2024 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/grab",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Claude 4 „É¢„Éá„É´ÁôªÂ†¥ÔºÅÊñ∞Ê©üËÉΩ„ÇÑ‰ªñÁ§æ„Å®„ÅÆÊØîËºÉ„ÉªÊñôÈáë„Å™„Å©Ë©≥„Åó„ÅèËß£Ë™¨",
    "description": "<p>Anthropic Á§æ„ÅØ2025Âπ¥5Êúà22Êó•„ÄÅClaude „ÅÆÊúÄÊñ∞Áâà„ÄåClaude 4„Äç„ÅÆÊèê‰æõ„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„ÄÇ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„ÇÑÊé®Ë´ñ„Çí„ÅØ„Åò„ÇÅ„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÊßãÁØâ„Å®„ÅÑ„Å£„Åü„Ç∑„Éº„É≥„ÅßÊúÄÈ´òÊ∞¥Ê∫ñ„ÅÆËÉΩÂäõ„ÇíÂÆüÁèæ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅ„Ç≥„Éº„Éá [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/claude-4-model-new-features/'>Claude 4 „É¢„Éá„É´ÁôªÂ†¥ÔºÅÊñ∞Ê©üËÉΩ„ÇÑ‰ªñÁ§æ„Å®„ÅÆÊØîËºÉ„ÉªÊñôÈáë„Å™„Å©Ë©≥„Åó„ÅèËß£Ë™¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>Anthropic Á§æ„ÅØ2025Âπ¥5Êúà22Êó•„ÄÅClaude „ÅÆÊúÄÊñ∞Áâà„ÄåClaude 4„Äç„ÅÆÊèê‰æõ„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„ÄÇ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„ÇÑÊé®Ë´ñ„Çí„ÅØ„Åò„ÇÅ„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÊßãÁØâ„Å®„ÅÑ„Å£„Åü„Ç∑„Éº„É≥„ÅßÊúÄÈ´òÊ∞¥Ê∫ñ„ÅÆËÉΩÂäõ„ÇíÂÆüÁèæ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅ„Ç≥„Éº„Éá [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/claude-4-model-new-features/'>Claude 4 „É¢„Éá„É´ÁôªÂ†¥ÔºÅÊñ∞Ê©üËÉΩ„ÇÑ‰ªñÁ§æ„Å®„ÅÆÊØîËºÉ„ÉªÊñôÈáë„Å™„Å©Ë©≥„Åó„ÅèËß£Ë™¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 03:33:57 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/claude-4-model-new-features/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/claude4.png"
  },
  {
    "title": "How to deploy and fine-tune DeepSeek models on AWS",
    "description": "",
    "summary": "How to deploy and fine-tune DeepSeek models on AWS A running document to showcase how to deploy and ...",
    "pubDate": "Thu, 30 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deepseek-r1-aws",
    "thumbnail": "https://huggingface.co/blog/assets/deepseek-r1-aws/thumbnail.png"
  },
  {
    "title": "Accelerating scientific discovery with AI",
    "description": "FutureHouse, co-founded by Sam Rodriques PhD ‚Äô19, has developed AI agents to automate key steps on the path toward scientific progress.",
    "summary": "FutureHouse, co-founded by Sam Rodriques PhD ‚Äô19, has developed AI agents to automate key steps on the path toward scientific progress.",
    "pubDate": "Mon, 30 Jun 2025 10:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/futurehouse-accelerates-scientific-discovery-with-ai-0630",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Future-House-01-press.jpg"
  },
  {
    "title": "Testing robustness against unforeseen adversaries",
    "description": "We‚Äôve developed a method to assess whether a neural network classifier can reliably defend against adversarial attacks not seen during training. Our method yields a new metric, UAR (Unforeseen Attack Robustness), which evaluates the robustness of a single model against an unanticipated attack, and highlights the need to measure performance across a more diverse range of unforeseen¬†attacks.",
    "summary": "We‚Äôve developed a method to assess whether a neural network classifier can reliably defend against adversarial attacks not seen during training. Our method yields a new metric, UAR (Unforeseen Attack Robustness), which evaluates the robustness of a single model against an unanticipated attack, and highlights the need to measure performance across a more diverse range of unforeseen¬†attacks.",
    "pubDate": "Thu, 22 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/testing-robustness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Watermarking 101: Tools and Techniques",
    "description": "",
    "summary": "AI Watermarking 101: Tools and Techniques In recent months, we've seen multiple news stories involvi...",
    "pubDate": "Mon, 26 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/watermarking",
    "thumbnail": "https://huggingface.co/blog/assets/watermarking/thumbnail.png"
  },
  {
    "title": "From Files to Chunks: Improving Hugging Face Storage Efficiency",
    "description": "",
    "summary": "From Files to Chunks: Improving HF Storage Efficiency Hugging Face stores over 30 PB of models, data...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/from-files-to-chunks",
    "thumbnail": "https://huggingface.co/blog/assets/from-files-to-chunks/thumbnail.png"
  },
  {
    "title": "Rearchitecting Hugging Face Uploads and Downloads",
    "description": "",
    "summary": "Rearchitecting Hugging Face Uploads and Downloads As part of Hugging Face's Xet team‚Äôs work to impro...",
    "pubDate": "Tue, 26 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rearchitecting-uploads-and-downloads",
    "thumbnail": "https://huggingface.co/blog/assets/rearchitecting-uploads-and-downloads/thumbnail.png"
  },
  {
    "title": "No GPU left behind: Unlocking Efficiency with Co-located vLLM in TRL",
    "description": "",
    "summary": "No GPU left behind: Unlocking Efficiency with Co-located vLLM in TRL üöÄ Introduction TRL supports tra...",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vllm-colocate",
    "thumbnail": "https://huggingface.co/blog/assets/liger-grpo/thumbnail.png"
  },
  {
    "title": "CyberSecEval 2 - A Comprehensive Evaluation Framework for Cybersecurity Risks and Capabilities of Large Language Models",
    "description": "",
    "summary": "CyberSecEval 2 - A Comprehensive Evaluation Framework for Cybersecurity Risks and Capabilities of La...",
    "pubDate": "Fri, 24 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-llamaguard",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_llamaguard.png"
  },
  {
    "title": "Chargax: A JAX Accelerated EV Charging Simulator",
    "description": "arXiv:2507.01522v1 Announce Type: cross Abstract: Deep Reinforcement Learning can play a key role in addressing sustainable energy challenges. For instance, many grid systems are heavily congested, highlighting the urgent need to enhance operational efficiency. However, reinforcement learning approaches have traditionally been slow due to the high sample complexity and expensive simulation requirements. While recent works have effectively used GPUs to accelerate data generation by converting environments to JAX, these works have largely focussed on classical toy problems. This paper introduces Chargax, a JAX-based environment for realistic simulation of electric vehicle charging stations designed for accelerated training of RL agents. We validate our environment in a variety of scenarios based on real data, comparing reinforcement learning agents against baselines. Chargax delivers substantial computational performance improvements of over 100x-1000x over existing environments. Additionally, Chargax' modular architecture enables the representation of diverse real-world charging station configurations.",
    "summary": "arXiv:2507.01522v1 Announce Type: cross Abstract: Deep Reinforcement Learning can play a key role in addressing sustainable energy challenges. For instance, many grid systems are heavily congested, highlighting the urgent need to enhance operational efficiency. However, reinforcement learning approaches have traditionally been slow due to the high sample complexity and expensive simulation requirements. While recent works have effectively used GPUs to accelerate data generation by converting environments to JAX, these works have largely focussed on classical toy problems. This paper introduces Chargax, a JAX-based environment for realistic simulation of electric vehicle charging stations designed for accelerated training of RL agents. We validate our environment in a variety of scenarios based on real data, comparing reinforcement learning agents against baselines. Chargax delivers substantial computational performance improvements of over 100x-1000x over existing environments. Additionally, Chargax' modular architecture enables the representation of diverse real-world charging station configurations.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01522",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Beating Transformers using Synthetic Cognition",
    "description": "arXiv:2504.07619v3 Announce Type: replace Abstract: The road to Artificial General Intelligence goes through the generation of context-aware reactive behaviors, where the Transformer architecture has been proven to be the state-of-the-art. However, they still fail to develop reasoning. Recently, a novel approach for developing cognitive architectures, called Synthetic Cognition, has been proposed and implemented to develop instantaneous reactive behavior. In this study, we aim to explore the use of Synthetic Cognition to develop context-aware reactive behaviors. We propose a mechanism to deal with sequences for the recent implementation of Synthetic Cognition, and test it against DNA foundation models in DNA sequence classification tasks. In our experiments, our proposal clearly outperforms the DNA foundation models, obtaining the best score on more benchmark tasks than the alternatives. Thus, we achieve two goals: expanding Synthetic Cognition to deal with sequences, and beating the Transformer architecture for sequence classification.",
    "summary": "arXiv:2504.07619v3 Announce Type: replace Abstract: The road to Artificial General Intelligence goes through the generation of context-aware reactive behaviors, where the Transformer architecture has been proven to be the state-of-the-art. However, they still fail to develop reasoning. Recently, a novel approach for developing cognitive architectures, called Synthetic Cognition, has been proposed and implemented to develop instantaneous reactive behavior. In this study, we aim to explore the use of Synthetic Cognition to develop context-aware reactive behaviors. We propose a mechanism to deal with sequences for the recent implementation of Synthetic Cognition, and test it against DNA foundation models in DNA sequence classification tasks. In our experiments, our proposal clearly outperforms the DNA foundation models, obtaining the best score on more benchmark tasks than the alternatives. Thus, we achieve two goals: expanding Synthetic Cognition to deal with sequences, and beating the Transformer architecture for sequence classification.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.07619",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Speculative Decoding for 2x Faster Whisper Inference",
    "description": "",
    "summary": "Speculative Decoding for 2x Faster Whisper Inference Open AI's Whisper is a general purpose speech t...",
    "pubDate": "Wed, 20 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/whisper-speculative-decoding",
    "thumbnail": "https://huggingface.co/blog/assets/whisper-speculative-decoding/thumbnail.png"
  },
  {
    "title": "How we built one of the most ambitious datasets in brain activity research",
    "description": "Four small, translucent zebrafish swim against a dark background",
    "summary": "Four small, translucent zebrafish swim against a dark background",
    "pubDate": "Mon, 09 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/research/zapbench-zebrafish-brain-mapping/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SS_How-we-built-one-of-the-most-ambitious-dat.width-1300.png"
  },
  {
    "title": "OpenAI acquires Global Illumination",
    "description": "The entire team has joined OpenAI.",
    "summary": "The entire team has joined OpenAI.",
    "pubDate": "Wed, 16 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-acquires-global-illumination",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Expanding on what we missed with sycophancy",
    "description": "A deeper dive on our findings, what went wrong, and future changes we‚Äôre making.",
    "summary": "A deeper dive on our findings, what went wrong, and future changes we‚Äôre making.",
    "pubDate": "Fri, 02 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expanding-on-sycophancy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CO2 Emissions and the ü§ó Hub: Leading the Charge",
    "description": "",
    "summary": "CO2 Emissions and the ü§ó Hub: Leading the Charge What are CO2 Emissions and why are they important? C...",
    "pubDate": "Fri, 22 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/carbon-emissions-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/60_carbon_emissions_on_the_hub/thumbnail.jpg"
  },
  {
    "title": "Synthetic data: save money, time and carbon with open source",
    "description": "",
    "summary": "Synthetic data: save money, time and carbon with open source tl;dr Should you fine-tune your own mod...",
    "pubDate": "Fri, 16 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthetic-data-save-costs",
    "thumbnail": "https://huggingface.co/blog/assets/176_synthetic-data-save-costs/thumbnail.png"
  },
  {
    "title": "Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay Perspective",
    "description": "arXiv:2507.01652v1 Announce Type: cross Abstract: Autoregressive (AR) models have garnered significant attention in image generation for their ability to effectively capture both local and global structures within visual data. However, prevalent AR models predominantly rely on the transformer architectures, which are beset by quadratic computational complexity concerning input sequence length and substantial memory overhead due to the necessity of maintaining key-value caches. Although linear attention mechanisms have successfully reduced this burden in language models, our initial experiments reveal that they significantly degrade image generation quality because of their inability to capture critical long-range dependencies in visual data. We propose Linear Attention with Spatial-Aware Decay (LASAD), a novel attention mechanism that explicitly preserves genuine 2D spatial relationships within the flattened image sequences by computing position-dependent decay factors based on true 2D spatial location rather than 1D sequence positions. Based on this mechanism, we present LASADGen, an autoregressive image generator that enables selective attention to relevant spatial contexts with linear complexity. Experiments on ImageNet show LASADGen achieves state-of-the-art image generation performance and computational efficiency, bridging the gap between linear attention's efficiency and spatial understanding needed for high-quality generation.",
    "summary": "arXiv:2507.01652v1 Announce Type: cross Abstract: Autoregressive (AR) models have garnered significant attention in image generation for their ability to effectively capture both local and global structures within visual data. However, prevalent AR models predominantly rely on the transformer architectures, which are beset by quadratic computational complexity concerning input sequence length and substantial memory overhead due to the necessity of maintaining key-value caches. Although linear attention mechanisms have successfully reduced this burden in language models, our initial experiments reveal that they significantly degrade image generation quality because of their inability to capture critical long-range dependencies in visual data. We propose Linear Attention with Spatial-Aware Decay (LASAD), a novel attention mechanism that explicitly preserves genuine 2D spatial relationships within the flattened image sequences by computing position-dependent decay factors based on true 2D spatial location rather than 1D sequence positions. Based on this mechanism, we present LASADGen, an autoregressive image generator that enables selective attention to relevant spatial contexts with linear complexity. Experiments on ImageNet show LASADGen achieves state-of-the-art image generation performance and computational efficiency, bridging the gap between linear attention's efficiency and spatial understanding needed for high-quality generation.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01652",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Upgrading the Moderation API with our new multimodal moderation model",
    "description": "We‚Äôre introducing a new model built on GPT-4o that is more accurate at detecting harmful text and images, enabling developers to build more robust moderation systems.",
    "summary": "We‚Äôre introducing a new model built on GPT-4o that is more accurate at detecting harmful text and images, enabling developers to build more robust moderation systems.",
    "pubDate": "Thu, 26 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/upgrading-the-moderation-api-with-our-new-multimodal-moderation-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Machine Learning Unconference",
    "description": "The latest information about the Unconference is now available at the Unconference wiki, which will be periodically updated with more information for attendees.",
    "summary": "The latest information about the Unconference is now available at the Unconference wiki, which will be periodically updated with more information for attendees.",
    "pubDate": "Thu, 18 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/machine-learning-unconference",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Databricks ‚ù§Ô∏è Hugging Face: up to 40% faster training and tuning of Large Language Models",
    "description": "",
    "summary": "Databricks ‚ù§Ô∏è Hugging Face: up to 40% faster training and tuning of Large Language Models Generative...",
    "pubDate": "Wed, 26 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/databricks-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/databricks.png"
  },
  {
    "title": "Welcome FalconMamba: The first strong attention-free 7B model",
    "description": "",
    "summary": "Welcome FalconMamba: The first strong attention-free 7B model Falcon Mamba is a new model by Technol...",
    "pubDate": "Mon, 12 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falconmamba",
    "thumbnail": "https://huggingface.co/blog/assets/falconmamba/thumbnail.png"
  },
  {
    "title": "GPT-4o mini: advancing cost-efficient intelligence",
    "description": "Introducing the most cost-efficient small model in the market",
    "summary": "Introducing the most cost-efficient small model in the market",
    "pubDate": "Thu, 18 Jul 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-mini-advancing-cost-efficient-intelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Testing and Evaluation: Learnings from Science and Industry",
    "description": "<p>In the introductory episode of this new series, host Kathleen Sullivan and Senior Director Amanda Craig Deckard explore Microsoft‚Äôs efforts to draw on the experience of other domains to help advance the role of AI testing and evaluation as a governance tool.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/'>AI Testing and Evaluation: Learnings from Science and Industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>In the introductory episode of this new series, host Kathleen Sullivan and Senior Director Amanda Craig Deckard explore Microsoft‚Äôs efforts to draw on the experience of other domains to help advance the role of AI testing and evaluation as a governance tool.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/'>AI Testing and Evaluation: Learnings from Science and Industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 16:38:09 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Deploy GPT-J 6B for inference using Hugging Face Transformers and Amazon SageMaker",
    "description": "",
    "summary": "Deploy GPT-J 6B for inference using Hugging Face Transformers and Amazon SageMaker Almost 6 months a...",
    "pubDate": "Tue, 11 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gptj-sagemaker",
    "thumbnail": "https://huggingface.co/blog/assets/45_gptj_sagemaker/thumbnail.png"
  },
  {
    "title": "Merging design and computer science in creative ways",
    "description": "MAD Fellow Alexander Htet Kyaw connects humans, machines, and the physical world using AI and augmented reality.",
    "summary": "MAD Fellow Alexander Htet Kyaw connects humans, machines, and the physical world using AI and augmented reality.",
    "pubDate": "Mon, 28 Apr 2025 16:55:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/alexander-htet-kyaw-merging-design-computer-science-in-creative-ways-0428",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-mad-Alexander-htet-kyaw_0.jpg"
  },
  {
    "title": "Easily Train Models with H100 GPUs on NVIDIA DGX Cloud",
    "description": "",
    "summary": "Easily Train Models with H100 GPUs on NVIDIA DGX Cloud Update: This service is deprecated and no lon...",
    "pubDate": "Mon, 18 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-dgx-cloud",
    "thumbnail": "https://huggingface.co/blog/assets/train-dgx-cloud/thumbnail.jpg"
  },
  {
    "title": "Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers",
    "description": "arXiv:2506.08641v2 Announce Type: replace-cross Abstract: Time series classification is a fundamental task in healthcare and industry, yet the development of time series foundation models (TSFMs) remains limited by the scarcity of publicly available time series datasets. In this work, we propose Time Vision Transformer (TiViT), a framework that converts time series into images to leverage the representational power of frozen Vision Transformers (ViTs) pretrained on large-scale image datasets. First, we theoretically motivate our approach by analyzing the 2D patching of ViTs for time series, showing that it can increase the number of label-relevant tokens and reduce the sample complexity. Second, we empirically demonstrate that TiViT achieves state-of-the-art performance on standard time series classification benchmarks by utilizing the hidden representations of large OpenCLIP models. We explore the structure of TiViT representations and find that intermediate layers with high intrinsic dimension are the most effective for time series classification. Finally, we assess the alignment between TiViT and TSFM representation spaces and identify a strong complementarity, with further performance gains achieved by combining their features. Our findings reveal a new direction for reusing vision representations in a non-visual domain. Code is available at https://github.com/ExplainableML/TiViT.",
    "summary": "arXiv:2506.08641v2 Announce Type: replace-cross Abstract: Time series classification is a fundamental task in healthcare and industry, yet the development of time series foundation models (TSFMs) remains limited by the scarcity of publicly available time series datasets. In this work, we propose Time Vision Transformer (TiViT), a framework that converts time series into images to leverage the representational power of frozen Vision Transformers (ViTs) pretrained on large-scale image datasets. First, we theoretically motivate our approach by analyzing the 2D patching of ViTs for time series, showing that it can increase the number of label-relevant tokens and reduce the sample complexity. Second, we empirically demonstrate that TiViT achieves state-of-the-art performance on standard time series classification benchmarks by utilizing the hidden representations of large OpenCLIP models. We explore the structure of TiViT representations and find that intermediate layers with high intrinsic dimension are the most effective for time series classification. Finally, we assess the alignment between TiViT and TSFM representation spaces and identify a strong complementarity, with further performance gains achieved by combining their features. Our findings reveal a new direction for reusing vision representations in a non-visual domain. Code is available at https://github.com/ExplainableML/TiViT.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.08641",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Making LLMs lighter with AutoGPTQ and transformers",
    "description": "",
    "summary": "Making LLMs lighter with AutoGPTQ and transformers Large language models have demonstrated remarkabl...",
    "pubDate": "Wed, 23 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gptq-integration",
    "thumbnail": "https://huggingface.co/blog/assets/159_autogptq_transformers/thumbnail.jpg"
  },
  {
    "title": "Llama 3.2 in Keras",
    "description": "",
    "summary": "Llama 3.2 in Keras This is going to be the shortest blog post ever. Question: Llama 3.2 landed two w...",
    "pubDate": "Mon, 21 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-llama-32",
    "thumbnail": "https://huggingface.co/blog/assets/keras_llama_32/thumbnail.jpg"
  },
  {
    "title": "Swift Diffusers: Fast Stable Diffusion for Mac",
    "description": "",
    "summary": "Swift üß®Diffusers: Fast Stable Diffusion for Mac Transform your text into stunning images with ease u...",
    "pubDate": "Fri, 24 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-mac-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/fast-mac-diffusers/thumbnail.png"
  },
  {
    "title": "TARO: Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning for Synchronized Video-to-Audio Synthesis",
    "description": "arXiv:2504.05684v2 Announce Type: replace-cross Abstract: This paper introduces Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning (TARO), a novel framework for high-fidelity and temporally coherent video-to-audio synthesis. Built upon flow-based transformers, which offer stable training and continuous transformations for enhanced synchronization and audio quality, TARO introduces two key innovations: (1) Timestep-Adaptive Representation Alignment (TRA), which dynamically aligns latent representations by adjusting alignment strength based on the noise schedule, ensuring smooth evolution and improved fidelity, and (2) Onset-Aware Conditioning (OAC), which integrates onset cues that serve as sharp event-driven markers of audio-relevant visual moments to enhance synchronization with dynamic visual events. Extensive experiments on the VGGSound and Landscape datasets demonstrate that TARO outperforms prior methods, achieving relatively 53% lower Frechet Distance (FD), 29% lower Frechet Audio Distance (FAD), and a 97.19% Alignment Accuracy, highlighting its superior audio quality and synchronization precision.",
    "summary": "arXiv:2504.05684v2 Announce Type: replace-cross Abstract: This paper introduces Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning (TARO), a novel framework for high-fidelity and temporally coherent video-to-audio synthesis. Built upon flow-based transformers, which offer stable training and continuous transformations for enhanced synchronization and audio quality, TARO introduces two key innovations: (1) Timestep-Adaptive Representation Alignment (TRA), which dynamically aligns latent representations by adjusting alignment strength based on the noise schedule, ensuring smooth evolution and improved fidelity, and (2) Onset-Aware Conditioning (OAC), which integrates onset cues that serve as sharp event-driven markers of audio-relevant visual moments to enhance synchronization with dynamic visual events. Extensive experiments on the VGGSound and Landscape datasets demonstrate that TARO outperforms prior methods, achieving relatively 53% lower Frechet Distance (FD), 29% lower Frechet Audio Distance (FAD), and a 97.19% Alignment Accuracy, highlighting its superior audio quality and synchronization precision.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.05684",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Trading inference-time compute for adversarial robustness",
    "description": "Trading Inference-Time Compute for Adversarial Robustness",
    "summary": "Trading Inference-Time Compute for Adversarial Robustness",
    "pubDate": "Wed, 22 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/trading-inference-time-compute-for-adversarial-robustness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2",
    "description": "",
    "summary": "Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2 Update (29/08/2023): A benchmark o...",
    "pubDate": "Thu, 29 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bridgetower",
    "thumbnail": "https://huggingface.co/blog/assets/bridgetower/thumbnail.png"
  },
  {
    "title": "Train 400x faster Static Embedding Models with Sentence Transformers",
    "description": "",
    "summary": "Train 400x faster Static Embedding Models with Sentence Transformers TL;DR This blog post introduces...",
    "pubDate": "Wed, 15 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/static-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "Our latest advances in robot dexterity",
    "description": "Two new AI systems, ALOHA Unleashed and DemoStart, help robots learn to perform complex tasks that require dexterous movement",
    "summary": "Two new AI systems, ALOHA Unleashed and DemoStart, help robots learn to perform complex tasks that require dexterous movement",
    "pubDate": "Thu, 12 Sep 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advances-in-robot-dexterity/",
    "thumbnail": "https://lh3.googleusercontent.com/63ROjLq4VNqk3RDA5vl1mYS1i5xvcgU8-augVWQY5OZCtVsm_e4YX8rR4_DLUlQiTmMHT6qx3p9shUtPGUHy_4SA64RDeMghvk0eDKT6Fqh6-P3d4A=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "description": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "summary": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "pubDate": "Mon, 10 Jun 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-welcomes-cfo-cpo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Could LLMs help design our next medicines and materials?",
    "description": "A new method lets users ask, in plain language, for a new molecule with certain properties, and receive a detailed description of how to synthesize it.",
    "summary": "A new method lets users ask, in plain language, for a new molecule with certain properties, and receive a detailed description of how to synthesize it.",
    "pubDate": "Wed, 09 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/could-llms-help-design-our-next-medicines-and-materials-0409",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-inverse-molecule-01-press.jpg"
  },
  {
    "title": "Introducing ConTextual: How well can your Multimodal model jointly reason over text and image in text-rich scenes?",
    "description": "",
    "summary": "Introducing ConTextual: How well can your Multimodal model jointly reason over text and image in tex...",
    "pubDate": "Tue, 05 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-contextual",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_contextual.png"
  },
  {
    "title": "Training and Finetuning Embedding Models with Sentence Transformers v3",
    "description": "",
    "summary": "Training and Finetuning Embedding Models with Sentence Transformers v3 Sentence Transformers is a Py...",
    "pubDate": "Tue, 28 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-sentence-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "Introducing data residency in Europe",
    "description": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "summary": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "pubDate": "Wed, 05 Feb 2025 22:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-data-residency-in-europe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI LP",
    "description": "We‚Äôve created OpenAI LP, a new ‚Äúcapped-profit‚Äù company that allows us to rapidly increase our investments in compute and talent while including checks and balances to actualize our mission.",
    "summary": "We‚Äôve created OpenAI LP, a new ‚Äúcapped-profit‚Äù company that allows us to rapidly increase our investments in compute and talent while including checks and balances to actualize our mission.",
    "pubDate": "Mon, 11 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-lp",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Genie 2: A large-scale foundation world model",
    "description": "Generating unlimited diverse training environments for future general agents",
    "summary": "Generating unlimited diverse training environments for future general agents",
    "pubDate": "Wed, 04 Dec 2024 14:23:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/",
    "thumbnail": "https://lh3.googleusercontent.com/wvcJdqh_wddVc-WiMGgcqe7nWp7Ybu0wd-PBDxC_VUQkfxI7HPfQz3fi_HyYTOoRM_XV3Bofp9l1wBZ1CJPZPG6yZMdZxqH8X7_Lb9nhVAquAul1=w1200-h630-n-nu"
  },
  {
    "title": "BERT 101 ü§ó State Of The Art NLP Model Explained",
    "description": "",
    "summary": "BERT 101 ü§ó State Of The Art NLP Model Explained What is BERT? BERT, short for Bidirectional Encoder ...",
    "pubDate": "Wed, 02 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-101",
    "thumbnail": "https://huggingface.co/blog/assets/52_bert_101/thumbnail.jpg"
  },
  {
    "title": "Generate videos in Gemini and Whisk with Veo 2",
    "description": "Transform text-based prompts into high-resolution eight-second videos in Gemini Advanced and use Whisk Animate to turn images into eight-second animated clips.",
    "summary": "Transform text-based prompts into high-resolution eight-second videos in Gemini Advanced and use Whisk Animate to turn images into eight-second animated clips.",
    "pubDate": "Tue, 15 Apr 2025 17:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/generate-videos-in-gemini-and-whisk-with-veo-2/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GenerateVideos_Static1_1920x1080.width-1300.png"
  },
  {
    "title": "What AI‚Äôs impact on individuals means for the health workforce and industry",
    "description": "<p>Ethan Mollick and Azeem Azhar, thought leaders at the forefront of AI‚Äôs influence on work, education, and society, discuss the impact of AI at the individual level and what that means for the healthcare workforce and the organizations and systems in medicine.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/'>What AI&#8217;s impact on individuals means for the health workforce and industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Ethan Mollick and Azeem Azhar, thought leaders at the forefront of AI‚Äôs influence on work, education, and society, discuss the impact of AI at the individual level and what that means for the healthcare workforce and the organizations and systems in medicine.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/'>What AI&#8217;s impact on individuals means for the health workforce and industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 29 May 2025 15:13:48 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Powering virtual education for the classroom",
    "description": "Khan Academy explores the potential for GPT-4 in a limited pilot program.",
    "summary": "Khan Academy explores the potential for GPT-4 in a limited pilot program.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/khan-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reimagining the email experience with AI",
    "description": "Superhuman introduces a new era of email with OpenAI.",
    "summary": "Superhuman introduces a new era of email with OpenAI.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/superhuman",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fixing Open LLM Leaderboard with Math-Verify",
    "description": "",
    "summary": "Fixing Open LLM Leaderboard with Math-Verify 3 weeks ago, we showed how hard it is to correctly eval...",
    "pubDate": "Fri, 14 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/math_verify_leaderboard",
    "thumbnail": "https://huggingface.co/blog/assets/math_verify_leaderboard/thumbnail.png"
  },
  {
    "title": "Training Stable Diffusion with Dreambooth using üß® Diffusers",
    "description": "",
    "summary": "Training Stable Diffusion with Dreambooth using üß® Diffusers Dreambooth is a technique to teach new c...",
    "pubDate": "Mon, 07 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dreambooth",
    "thumbnail": "https://huggingface.co/blog/assets/sd_dreambooth_training/thumbnail.jpg"
  },
  {
    "title": "AI-written critiques help humans notice flaws",
    "description": "We trained ‚Äúcritique-writing‚Äù models to describe flaws in summaries. Human evaluators find flaws in summaries much more often when shown our model‚Äôs critiques. Larger models are better at self-critiquing, with scale improving critique-writing more than summary-writing. This shows promise for using AI systems to assist human supervision of AI systems on difficult¬†tasks.",
    "summary": "We trained ‚Äúcritique-writing‚Äù models to describe flaws in summaries. Human evaluators find flaws in summaries much more often when shown our model‚Äôs critiques. Larger models are better at self-critiquing, with scale improving critique-writing more than summary-writing. This shows promise for using AI systems to assist human supervision of AI systems on difficult¬†tasks.",
    "pubDate": "Mon, 13 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/critiques",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New method efficiently safeguards sensitive AI training data",
    "description": "The approach maintains an AI model‚Äôs accuracy while ensuring attackers can‚Äôt extract secret information.",
    "summary": "The approach maintains an AI model‚Äôs accuracy while ensuring attackers can‚Äôt extract secret information.",
    "pubDate": "Fri, 11 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-method-efficiently-safeguards-sensitive-ai-training-data-0411",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Private-Algorithm-01-press.jpg"
  },
  {
    "title": "Here‚Äôs the next cohort of the Google.org Accelerator: Generative AI",
    "description": "A collage of photos showing people using technology around the world, on a white background",
    "summary": "A collage of photos showing people using technology around the world, on a white background",
    "pubDate": "Mon, 09 Jun 2025 14:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/google-org/generative-ai-accelerator-cohort-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gen_AI_Accelerator_ss.width-1300.png"
  },
  {
    "title": "Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub",
    "description": "",
    "summary": "Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub Huggy Lingo...",
    "pubDate": "Wed, 02 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggy-lingo",
    "thumbnail": "https://huggingface.co/blog/huggy-lingo/blog/assets/156_huggylingo/Huggy_Lingo.png"
  },
  {
    "title": "Open Source Developers Guide to the EU AI Act",
    "description": "",
    "summary": "Open Source Developers Guide to the EU AI Act The EU AI Act, the world‚Äôs first comprehensive legisla...",
    "pubDate": "Mon, 02 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eu-ai-act-for-oss-developers",
    "thumbnail": "https://huggingface.co/blog/assets/189_eu-ai-act-for-oss-developers/thumbnail.png"
  },
  {
    "title": "Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition ü§ñ",
    "description": "",
    "summary": "Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition ü§ñ Simon Alibert and R√©...",
    "pubDate": "Mon, 14 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-pollen-robotics-acquisition",
    "thumbnail": "https://huggingface.co/blog/assets/hugging-face-pollen-robotics-acquisition/hf-pollen.png"
  },
  {
    "title": "Introducing our new pricing",
    "description": "",
    "summary": "Introducing our new pricing As you might have noticed, our pricing page has changed a lot recently. ...",
    "pubDate": "Tue, 08 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pricing-update",
    "thumbnail": "https://huggingface.co/blog/assets/114_pricing-update/thumbnail.png"
  },
  {
    "title": "Bertelsmann powers creativity and productivity with OpenAI",
    "description": "Bertelsmann, the global media, services, and education company headquartered in Germany, will integrate OpenAI‚Äôs technology across multiple brands around the world.",
    "summary": "Bertelsmann, the global media, services, and education company headquartered in Germany, will integrate OpenAI‚Äôs technology across multiple brands around the world.",
    "pubDate": "Wed, 22 Jan 2025 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bertelsmann-powers-creativity-and-productivity-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Distributional Soft Actor-Critic with Diffusion Policy",
    "description": "arXiv:2507.01381v1 Announce Type: cross Abstract: Reinforcement learning has been proven to be highly effective in handling complex control tasks. Traditional methods typically use unimodal distributions, such as Gaussian distributions, to model the output of value distributions. However, unimodal distribution often and easily causes bias in value function estimation, leading to poor algorithm performance. This paper proposes a distributional reinforcement learning algorithm called DSAC-D (Distributed Soft Actor Critic with Diffusion Policy) to address the challenges of estimating bias in value functions and obtaining multimodal policy representations. A multimodal distributional policy iteration framework that can converge to the optimal policy was established by introducing policy entropy and value distribution function. A diffusion value network that can accurately characterize the distribution of multi peaks was constructed by generating a set of reward samples through reverse sampling using a diffusion model. Based on this, a distributional reinforcement learning algorithm with dual diffusion of the value network and the policy network was derived. MuJoCo testing tasks demonstrate that the proposed algorithm not only learns multimodal policy, but also achieves state-of-the-art (SOTA) performance in all 9 control tasks, with significant suppression of estimation bias and total average return improvement of over 10% compared to existing mainstream algorithms. The results of real vehicle testing show that DSAC-D can accurately characterize the multimodal distribution of different driving styles, and the diffusion policy network can characterize multimodal trajectories.",
    "summary": "arXiv:2507.01381v1 Announce Type: cross Abstract: Reinforcement learning has been proven to be highly effective in handling complex control tasks. Traditional methods typically use unimodal distributions, such as Gaussian distributions, to model the output of value distributions. However, unimodal distribution often and easily causes bias in value function estimation, leading to poor algorithm performance. This paper proposes a distributional reinforcement learning algorithm called DSAC-D (Distributed Soft Actor Critic with Diffusion Policy) to address the challenges of estimating bias in value functions and obtaining multimodal policy representations. A multimodal distributional policy iteration framework that can converge to the optimal policy was established by introducing policy entropy and value distribution function. A diffusion value network that can accurately characterize the distribution of multi peaks was constructed by generating a set of reward samples through reverse sampling using a diffusion model. Based on this, a distributional reinforcement learning algorithm with dual diffusion of the value network and the policy network was derived. MuJoCo testing tasks demonstrate that the proposed algorithm not only learns multimodal policy, but also achieves state-of-the-art (SOTA) performance in all 9 control tasks, with significant suppression of estimation bias and total average return improvement of over 10% compared to existing mainstream algorithms. The results of real vehicle testing show that DSAC-D can accurately characterize the multimodal distribution of different driving styles, and the diffusion policy network can characterize multimodal trajectories.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01381",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "üß® Diffusers welcomes Stable Diffusion 3",
    "description": "",
    "summary": "üß® Diffusers welcomes Stable Diffusion 3 Stable Diffusion 3 (SD3), Stability AI‚Äôs latest iteration of...",
    "pubDate": "Wed, 12 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd3",
    "thumbnail": "https://huggingface.co/blog/assets/sd3/thumbnail.png"
  },
  {
    "title": "Block-sparse GPU kernels",
    "description": "We‚Äôre releasing highly-optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights. Depending on the chosen sparsity, these kernels can run orders of magnitude faster than cuBLAS or cuSPARSE. We‚Äôve used them to attain state-of-the-art results in text sentiment analysis and generative modeling of text and images.",
    "summary": "We‚Äôre releasing highly-optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights. Depending on the chosen sparsity, these kernels can run orders of magnitude faster than cuBLAS or cuSPARSE. We‚Äôve used them to attain state-of-the-art results in text sentiment analysis and generative modeling of text and images.",
    "pubDate": "Wed, 06 Dec 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/block-sparse-gpu-kernels",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An Introduction to Deep Reinforcement Learning",
    "description": "",
    "summary": "An Introduction to Deep Reinforcement Learning Deep Reinforcement Learning Class with Hugging Face ü§ó...",
    "pubDate": "Wed, 04 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-intro",
    "thumbnail": "https://huggingface.co/blog/assets/63_deep_rl_intro/thumbnail.png"
  },
  {
    "title": "Reducing bias and improving safety in DALL¬∑E 2",
    "description": "Today, we are implementing a new technique so that DALL¬∑E generates images of people that more accurately reflect the diversity of the world‚Äôs population.",
    "summary": "Today, we are implementing a new technique so that DALL¬∑E generates images of people that more accurately reflect the diversity of the world‚Äôs population.",
    "pubDate": "Mon, 18 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Delivering contextual job matching for millions with OpenAI",
    "description": "Indeed, whose mission is to help people get jobs, is the world‚Äôs #1 job site. Over 350 million unique visitors come to Indeed every month to connect with more than 3.5 million employers and over 32 million jobs. But what‚Äôs more is that every three seconds someone gets hired on Indeed.",
    "summary": "Indeed, whose mission is to help people get jobs, is the world‚Äôs #1 job site. Over 350 million unique visitors come to Indeed every month to connect with more than 3.5 million employers and over 32 million jobs. But what‚Äôs more is that every three seconds someone gets hired on Indeed.",
    "pubDate": "Thu, 15 Aug 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/indeed",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving mathematical reasoning with process supervision",
    "description": "We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (‚Äúprocess supervision‚Äù) instead of simply rewarding the correct final answer (‚Äúoutcome supervision‚Äù). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.",
    "summary": "We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (‚Äúprocess supervision‚Äù) instead of simply rewarding the correct final answer (‚Äúoutcome supervision‚Äù). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.",
    "pubDate": "Wed, 31 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-mathematical-reasoning-with-process-supervision",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Run ComfyUI workflows for free on Spaces",
    "description": "",
    "summary": "Run ComfyUI workflows for free with Gradio on Hugging Face Spaces Index: - Intro - Exporting your Co...",
    "pubDate": "Sun, 14 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/run-comfyui-workflows-on-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/comfyui-to-gradio/cover.png"
  },
  {
    "title": "Learning how to predict rare kinds of failures",
    "description": "Researchers are developing algorithms to predict failures when automation meets the real world in areas like air traffic scheduling or autonomous vehicles.",
    "summary": "Researchers are developing algorithms to predict failures when automation meets the real world in areas like air traffic scheduling or autonomous vehicles.",
    "pubDate": "Wed, 21 May 2025 16:35:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/learning-how-predict-rare-kinds-failures-0521",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-rare-event-modeling.jpg"
  },
  {
    "title": "Announcing our new Content Guidelines and Policy",
    "description": "",
    "summary": "Announcing our new Community Policy As a community-driven platform that aims to advance Open, Collab...",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/content-guidelines-update",
    "thumbnail": "https://huggingface.co/blog/assets/content-guidelines-blogpost/thumbnail.png"
  },
  {
    "title": "Quantifying generalization in reinforcement learning",
    "description": "We‚Äôre releasing CoinRun, a training environment which provides a metric for an agent‚Äôs ability to transfer its experience to novel situations and has already helped clarify a¬†longstanding¬†puzzle¬†in reinforcement learning. CoinRun strikes a desirable balance in complexity: the environment is simpler than traditional platformer games like Sonic the Hedgehog but still poses a worthy generalization challenge for state of the art¬†algorithms.",
    "summary": "We‚Äôre releasing CoinRun, a training environment which provides a metric for an agent‚Äôs ability to transfer its experience to novel situations and has already helped clarify a¬†longstanding¬†puzzle¬†in reinforcement learning. CoinRun strikes a desirable balance in complexity: the environment is simpler than traditional platformer games like Sonic the Hedgehog but still poses a worthy generalization challenge for state of the art¬†algorithms.",
    "pubDate": "Thu, 06 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/quantifying-generalization-in-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Crop Pest Classification Using Deep Learning Techniques: A Review",
    "description": "arXiv:2507.01494v1 Announce Type: cross Abstract: Insect pests continue to bring a serious threat to crop yields around the world, and traditional methods for monitoring them are often slow, manual, and difficult to scale. In recent years, deep learning has emerged as a powerful solution, with techniques like convolutional neural networks (CNNs), vision transformers (ViTs), and hybrid models gaining popularity for automating pest detection. This review looks at 37 carefully selected studies published between 2018 and 2025, all focused on AI-based pest classification. The selected research is organized by crop type, pest species, model architecture, dataset usage, and key technical challenges. The early studies relied heavily on CNNs but latest work is shifting toward hybrid and transformer-based models that deliver higher accuracy and better contextual understanding. Still, challenges like imbalanced datasets, difficulty in detecting small pests, limited generalizability, and deployment on edge devices remain significant hurdles. Overall, this review offers a structured overview of the field, highlights useful datasets, and outlines the key challenges and future directions for AI-based pest monitoring systems.",
    "summary": "arXiv:2507.01494v1 Announce Type: cross Abstract: Insect pests continue to bring a serious threat to crop yields around the world, and traditional methods for monitoring them are often slow, manual, and difficult to scale. In recent years, deep learning has emerged as a powerful solution, with techniques like convolutional neural networks (CNNs), vision transformers (ViTs), and hybrid models gaining popularity for automating pest detection. This review looks at 37 carefully selected studies published between 2018 and 2025, all focused on AI-based pest classification. The selected research is organized by crop type, pest species, model architecture, dataset usage, and key technical challenges. The early studies relied heavily on CNNs but latest work is shifting toward hybrid and transformer-based models that deliver higher accuracy and better contextual understanding. Still, challenges like imbalanced datasets, difficulty in detecting small pests, limited generalizability, and deployment on edge devices remain significant hurdles. Overall, this review offers a structured overview of the field, highlights useful datasets, and outlines the key challenges and future directions for AI-based pest monitoring systems.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01494",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Can AI be Consentful?",
    "description": "arXiv:2507.01051v1 Announce Type: cross Abstract: The evolution of generative AI systems exposes the challenges of traditional legal and ethical frameworks built around consent. This chapter examines how the conventional notion of consent, while fundamental to data protection and privacy rights, proves insufficient in addressing the implications of AI-generated content derived from personal data. Through legal and ethical analysis, we show that while individuals can consent to the initial use of their data for AI training, they cannot meaningfully consent to the numerous potential outputs their data might enable or the extent to which the output is used or distributed. We identify three fundamental challenges: the scope problem, the temporality problem, and the autonomy trap, which collectively create what we term a ''consent gap'' in AI systems and their surrounding ecosystem. We argue that current legal frameworks inadequately address these emerging challenges, particularly regarding individual autonomy, identity rights, and social responsibility, especially in cases where AI-generated content creates new forms of personal representation beyond the scope of the original consent. By examining how these consent limitations intersect with broader principles of responsible AI (including fairness, transparency, accountability, and autonomy) we demonstrate the need to evolve ethical and legal approaches to consent.",
    "summary": "arXiv:2507.01051v1 Announce Type: cross Abstract: The evolution of generative AI systems exposes the challenges of traditional legal and ethical frameworks built around consent. This chapter examines how the conventional notion of consent, while fundamental to data protection and privacy rights, proves insufficient in addressing the implications of AI-generated content derived from personal data. Through legal and ethical analysis, we show that while individuals can consent to the initial use of their data for AI training, they cannot meaningfully consent to the numerous potential outputs their data might enable or the extent to which the output is used or distributed. We identify three fundamental challenges: the scope problem, the temporality problem, and the autonomy trap, which collectively create what we term a ''consent gap'' in AI systems and their surrounding ecosystem. We argue that current legal frameworks inadequately address these emerging challenges, particularly regarding individual autonomy, identity rights, and social responsibility, especially in cases where AI-generated content creates new forms of personal representation beyond the scope of the original consent. By examining how these consent limitations intersect with broader principles of responsible AI (including fairness, transparency, accountability, and autonomy) we demonstrate the need to evolve ethical and legal approaches to consent.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01051",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "nanoVLM: The simplest repository to train your VLM in pure PyTorch",
    "description": "",
    "summary": "nanoVLM: The simplest repository to train your VLM in pure PyTorch nanoVLM is the simplest way to ge...",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nanovlm",
    "thumbnail": "https://huggingface.co/blog/assets/nanovlm/thumbnail.png"
  },
  {
    "title": "Scaling Kubernetes to 2,500 nodes",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 18 Jan 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-kubernetes-to-2500-nodes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FastRTC„Çí‰Ωø„Å£„Å¶ÁàÜÈÄü„ÅßVoicebot„ÇíÊßãÁØâ„Åô„Çã",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØPython„Åß„É™„Ç¢„É´„Çø„Ç§„É†„Å™AI„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Çí‰Ωú„ÇãÈöõ„Å´ÂΩπÁ´ã„Å§„É©„Ç§„Éñ„É©„É™„ÄÅFastRTC„Çí‰Ωø„Å£„Å¶Á∞°Âçò„Å™Voicebot„ÇíÊßãÁØâ„Åó„Å¶„Åø„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ FastRTC FastRT [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5680' rel='nofollow'>FastRTC„Çí‰Ωø„Å£„Å¶ÁàÜÈÄü„ÅßVoicebot„ÇíÊßãÁØâ„Åô„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØPython„Åß„É™„Ç¢„É´„Çø„Ç§„É†„Å™AI„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Çí‰Ωú„ÇãÈöõ„Å´ÂΩπÁ´ã„Å§„É©„Ç§„Éñ„É©„É™„ÄÅFastRTC„Çí‰Ωø„Å£„Å¶Á∞°Âçò„Å™Voicebot„ÇíÊßãÁØâ„Åó„Å¶„Åø„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ FastRTC FastRT [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5680' rel='nofollow'>FastRTC„Çí‰Ωø„Å£„Å¶ÁàÜÈÄü„ÅßVoicebot„ÇíÊßãÁØâ„Åô„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Wed, 16 Apr 2025 00:41:50 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5680",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/f81fd2e4c52864042852c112ce927ae2.png"
  },
  {
    "title": "Using GPT-4 for content moderation",
    "description": "We use GPT-4 for content policy development and content moderation decisions, enabling more consistent labeling, a faster feedback loop for policy refinement, and less involvement from human moderators.",
    "summary": "We use GPT-4 for content policy development and content moderation decisions, enabling more consistent labeling, a faster feedback loop for policy refinement, and less involvement from human moderators.",
    "pubDate": "Tue, 15 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/using-gpt-4-for-content-moderation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AirRadar: Inferring Nationwide Air Quality in China with Deep Neural Networks",
    "description": "arXiv:2501.13141v2 Announce Type: replace-cross Abstract: Monitoring real-time air quality is essential for safeguarding public health and fostering social progress. However, the widespread deployment of air quality monitoring stations is constrained by their significant costs. To address this limitation, we introduce emph{AirRadar}, a deep neural network designed to accurately infer real-time air quality in locations lacking monitoring stations by utilizing data from existing ones. By leveraging learnable mask tokens, AirRadar reconstructs air quality features in unmonitored regions. Specifically, it operates in two stages: first capturing spatial correlations and then adjusting for distribution shifts. We validate AirRadar's efficacy using a year-long dataset from 1,085 monitoring stations across China, demonstrating its superiority over multiple baselines, even with varying degrees of unobserved data. The source code can be accessed at https://github.com/CityMind-Lab/AirRadar.",
    "summary": "arXiv:2501.13141v2 Announce Type: replace-cross Abstract: Monitoring real-time air quality is essential for safeguarding public health and fostering social progress. However, the widespread deployment of air quality monitoring stations is constrained by their significant costs. To address this limitation, we introduce emph{AirRadar}, a deep neural network designed to accurately infer real-time air quality in locations lacking monitoring stations by utilizing data from existing ones. By leveraging learnable mask tokens, AirRadar reconstructs air quality features in unmonitored regions. Specifically, it operates in two stages: first capturing spatial correlations and then adjusting for distribution shifts. We validate AirRadar's efficacy using a year-long dataset from 1,085 monitoring stations across China, demonstrating its superiority over multiple baselines, even with varying degrees of unobserved data. The source code can be accessed at https://github.com/CityMind-Lab/AirRadar.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.13141",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DALL¬∑E 3 is now available in ChatGPT Plus and Enterprise",
    "description": "We developed a safety mitigation stack to ready DALL¬∑E 3 for wider release and are sharing updates on our provenance research.",
    "summary": "We developed a safety mitigation stack to ready DALL¬∑E 3 for wider release and are sharing updates on our provenance research.",
    "pubDate": "Thu, 19 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Leadership updates",
    "description": "OpenAI has grown a lot. We remain focused on the same core‚Äîpursuing frontier AI research that accelerates human progress‚Äìbut we now also deliver products used by hundreds of millions of people.",
    "summary": "OpenAI has grown a lot. We remain focused on the same core‚Äîpursuing frontier AI research that accelerates human progress‚Äìbut we now also deliver products used by hundreds of millions of people.",
    "pubDate": "Mon, 24 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-updates-march-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A generalist AI agent for 3D virtual environments",
    "description": "Introducing SIMA, a Scalable Instructable Multiworld Agent",
    "summary": "Introducing SIMA, a Scalable Instructable Multiworld Agent",
    "pubDate": "Wed, 13 Mar 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/",
    "thumbnail": "https://lh3.googleusercontent.com/2GNumOaJCB48RQIFbwJmmZro-AFdBebufxvY_ZkSdUs9RQ-0nSTgBMXuhUdIE5zpPknqevL4ZyP44PLOpJlg0U0ArlOCcJHfoOagzSnZZoXLnq7hdQ=w1200-h630-n-nu"
  },
  {
    "title": "Global news partnerships: Le Monde and Prisa Media",
    "description": "We have partnered with international news organizations Le Monde and Prisa Media to bring French and Spanish news content to ChatGPT.",
    "summary": "We have partnered with international news organizations Le Monde and Prisa Media to bring French and Spanish news content to ChatGPT.",
    "pubDate": "Wed, 13 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/global-news-partnerships-le-monde-and-prisa-media",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating SD Turbo and SDXL Turbo Inference with ONNX Runtime and Olive",
    "description": "",
    "summary": "Accelerating SD Turbo and SDXL Turbo Inference with ONNX Runtime and Olive Introduction SD Turbo and...",
    "pubDate": "Mon, 15 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_ort_inference",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_onnxruntime-training/thumbnail.png"
  },
  {
    "title": "Tensor Program Optimization for the RISC-V Vector Extension Using Probabilistic Programs",
    "description": "arXiv:2507.01457v1 Announce Type: cross Abstract: RISC-V provides a flexible and scalable platform for applications ranging from embedded devices to high-performance computing clusters. Particularly, its RISC-V Vector Extension (RVV) becomes of interest for the acceleration of AI workloads. But writing software that efficiently utilizes the vector units of RISC-V CPUs without expert knowledge requires the programmer to rely on the autovectorization features of compilers or hand-crafted libraries like muRISCV-NN. Smarter approaches, like autotuning frameworks, have been missing the integration with the RISC-V RVV extension, thus heavily limiting the efficient deployment of complex AI workloads. In this paper, we present a workflow based on the TVM compiler to efficiently map AI workloads onto RISC-V vector units. Instead of relying on hand-crafted libraries, we integrated the RVV extension into TVM's MetaSchedule framework, a probabilistic program framework for tensor operation tuning. We implemented different RISC-V SoCs on an FPGA and tuned a wide range of AI workloads on them. We found that our proposal shows a mean improvement of 46% in execution latency when compared against the autovectorization feature of GCC, and 29% against muRISCV-NN. Moreover, the binary resulting from our proposal has a smaller code memory footprint, making it more suitable for embedded devices. Finally, we also evaluated our solution on a commercially available RISC-V SoC implementing the RVV 1.0 Vector Extension and found our solution is able to find mappings that are 35% faster on average than the ones proposed by LLVM. We open-sourced our proposal for the community to expand it to target other RISC-V extensions.",
    "summary": "arXiv:2507.01457v1 Announce Type: cross Abstract: RISC-V provides a flexible and scalable platform for applications ranging from embedded devices to high-performance computing clusters. Particularly, its RISC-V Vector Extension (RVV) becomes of interest for the acceleration of AI workloads. But writing software that efficiently utilizes the vector units of RISC-V CPUs without expert knowledge requires the programmer to rely on the autovectorization features of compilers or hand-crafted libraries like muRISCV-NN. Smarter approaches, like autotuning frameworks, have been missing the integration with the RISC-V RVV extension, thus heavily limiting the efficient deployment of complex AI workloads. In this paper, we present a workflow based on the TVM compiler to efficiently map AI workloads onto RISC-V vector units. Instead of relying on hand-crafted libraries, we integrated the RVV extension into TVM's MetaSchedule framework, a probabilistic program framework for tensor operation tuning. We implemented different RISC-V SoCs on an FPGA and tuned a wide range of AI workloads on them. We found that our proposal shows a mean improvement of 46% in execution latency when compared against the autovectorization feature of GCC, and 29% against muRISCV-NN. Moreover, the binary resulting from our proposal has a smaller code memory footprint, making it more suitable for embedded devices. Finally, we also evaluated our solution on a commercially available RISC-V SoC implementing the RVV 1.0 Vector Extension and found our solution is able to find mappings that are 35% faster on average than the ones proposed by LLVM. We open-sourced our proposal for the community to expand it to target other RISC-V extensions.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01457",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Empowering defenders through our Cybersecurity Grant Program",
    "description": "Highlighting innovative research and AI integration in cybersecurity",
    "summary": "Highlighting innovative research and AI integration in cybersecurity",
    "pubDate": "Thu, 20 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/empowering-defenders-through-our-cybersecurity-grant-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Search-Based Robot Motion Planning With Distance-Based Adaptive Motion Primitives",
    "description": "arXiv:2507.01198v1 Announce Type: cross Abstract: This work proposes a motion planning algorithm for robotic manipulators that combines sampling-based and search-based planning methods. The core contribution of the proposed approach is the usage of burs of free configuration space (C-space) as adaptive motion primitives within the graph search algorithm. Due to their feature to adaptively expand in free C-space, burs enable more efficient exploration of the configuration space compared to fixed-sized motion primitives, significantly reducing the time to find a valid path and the number of required expansions. The algorithm is implemented within the existing SMPL (Search-Based Motion Planning Library) library and evaluated through a series of different scenarios involving manipulators with varying number of degrees-of-freedom (DoF) and environment complexity. Results demonstrate that the bur-based approach outperforms fixed-primitive planning in complex scenarios, particularly for high DoF manipulators, while achieving comparable performance in simpler scenarios.",
    "summary": "arXiv:2507.01198v1 Announce Type: cross Abstract: This work proposes a motion planning algorithm for robotic manipulators that combines sampling-based and search-based planning methods. The core contribution of the proposed approach is the usage of burs of free configuration space (C-space) as adaptive motion primitives within the graph search algorithm. Due to their feature to adaptively expand in free C-space, burs enable more efficient exploration of the configuration space compared to fixed-sized motion primitives, significantly reducing the time to find a valid path and the number of required expansions. The algorithm is implemented within the existing SMPL (Search-Based Motion Planning Library) library and evaluated through a series of different scenarios involving manipulators with varying number of degrees-of-freedom (DoF) and environment complexity. Results demonstrate that the bur-based approach outperforms fixed-primitive planning in complex scenarios, particularly for high DoF manipulators, while achieving comparable performance in simpler scenarios.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01198",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How Hugging Face Scaled Secrets Management for AI Infrastructure",
    "description": "",
    "summary": "How Hugging Face Scaled Secrets Management for AI Infrastructure Hugging Face has become synonymous ...",
    "pubDate": "Mon, 31 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/scaling-secrets-management",
    "thumbnail": "https://huggingface.co/blog/assets/infisical/thumbnail.png"
  },
  {
    "title": "Powerful ASR + diarization + speculative decoding with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Powerful ASR + diarization + speculative decoding with Hugging Face Inference Endpoints Whisper is o...",
    "pubDate": "Wed, 01 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/asr-diarization",
    "thumbnail": "https://huggingface.co/blog/assets/asr-diarization/thumbnail.png"
  },
  {
    "title": "Introducing Whisper",
    "description": "We‚Äôve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech¬†recognition.",
    "summary": "We‚Äôve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech¬†recognition.",
    "pubDate": "Wed, 21 Sep 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/whisper",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI standardizes on PyTorch",
    "description": "We are standardizing OpenAI‚Äôs deep learning framework on¬†PyTorch.",
    "summary": "We are standardizing OpenAI‚Äôs deep learning framework on¬†PyTorch.",
    "pubDate": "Thu, 30 Jan 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-pytorch",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Inroads to personalized AI trip planning",
    "description": "A new framework from the MIT-IBM Watson AI Lab supercharges language models, so they can reason over, interactively develop, and verify valid, complex travel agendas.",
    "summary": "A new framework from the MIT-IBM Watson AI Lab supercharges language models, so they can reason over, interactively develop, and verify valid, complex travel agendas.",
    "pubDate": "Tue, 10 Jun 2025 15:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/inroads-personalized-ai-trip-planning-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-watson-travel-planning.jpg"
  },
  {
    "title": "The San Antonio Spurs use ChatGPT to scale impact on and off the court",
    "description": "Discover how the San Antonio Spurs are using custom GPTs to enhance fan engagement, streamline operations, and drive innovation across teams.",
    "summary": "Discover how the San Antonio Spurs are using custom GPTs to enhance fan engagement, streamline operations, and drive innovation across teams.",
    "pubDate": "Wed, 07 May 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/san-antonio-spurs",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Attacking machine learning with adversarial examples",
    "description": "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they‚Äôre like optical illusions for machines. In this post we‚Äôll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult.",
    "summary": "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they‚Äôre like optical illusions for machines. In this post we‚Äôll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult.",
    "pubDate": "Fri, 24 Feb 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/attacking-machine-learning-with-adversarial-examples",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Selected for the French Data Protection Agency Enhanced Support Program",
    "description": "",
    "summary": "Hugging Face Selected for the French Data Protection Agency Enhanced Support Program This blog post ...",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cnil",
    "thumbnail": "https://huggingface.co/blog/assets/146_cnil-accompaniment/logo.png"
  },
  {
    "title": "OpenAI o3-mini",
    "description": "Pushing the frontier of cost-effective reasoning.",
    "summary": "Pushing the frontier of cost-effective reasoning.",
    "pubDate": "Fri, 31 Jan 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o3-mini",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Looking ahead to the AI Seoul Summit",
    "description": "How summits in Seoul, France and beyond can galvanize international cooperation on frontier AI safety",
    "summary": "How summits in Seoul, France and beyond can galvanize international cooperation on frontier AI safety",
    "pubDate": "Mon, 20 May 2024 07:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/looking-ahead-to-the-ai-seoul-summit/",
    "thumbnail": "https://lh3.googleusercontent.com/LuT46lyRujmyyTlxwixL9_e8LKvzqZOGUyQUAFbTO6POaYlAqWYfEMag39UkZGsZhjs3SmW3V-s0dCjK4_81jpezAzL7c6kXuTY2MhXbv5yR4NDG8Q=w1200-h630-n-nu"
  },
  {
    "title": "How should AI systems behave, and who should decide?",
    "description": "We‚Äôre clarifying how ChatGPT‚Äôs behavior is shaped and our plans for improving that behavior, allowing more user customization, and getting more public input into our decision-making in these¬†areas.",
    "summary": "We‚Äôre clarifying how ChatGPT‚Äôs behavior is shaped and our plans for improving that behavior, allowing more user customization, and getting more public input into our decision-making in these¬†areas.",
    "pubDate": "Thu, 16 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-should-ai-systems-behave",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pre-training Large Memory Language Models with Internal and External Knowledge",
    "description": "arXiv:2505.15962v2 Announce Type: replace-cross Abstract: Neural language models are black-boxes -- both linguistic patterns and factual knowledge are distributed across billions of opaque parameters. This entangled encoding makes it difficult to reliably inspect, verify, or update specific facts. We propose a new class of language models, Large Memory Language Models (LMLM) with a pre-training recipe that stores factual knowledge in both internal weights and an external database. Our approach strategically masks externally retrieved factual values from the training loss, thereby teaching the model to perform targeted lookups rather than relying on memorization in model weights. Our experiments demonstrate that LMLMs achieve competitive performance compared to significantly larger, knowledge-dense LLMs on standard benchmarks, while offering the advantages of explicit, editable, and verifiable knowledge bases. This work represents a fundamental shift in how language models interact with and manage factual knowledge.",
    "summary": "arXiv:2505.15962v2 Announce Type: replace-cross Abstract: Neural language models are black-boxes -- both linguistic patterns and factual knowledge are distributed across billions of opaque parameters. This entangled encoding makes it difficult to reliably inspect, verify, or update specific facts. We propose a new class of language models, Large Memory Language Models (LMLM) with a pre-training recipe that stores factual knowledge in both internal weights and an external database. Our approach strategically masks externally retrieved factual values from the training loss, thereby teaching the model to perform targeted lookups rather than relying on memorization in model weights. Our experiments demonstrate that LMLMs achieve competitive performance compared to significantly larger, knowledge-dense LLMs on standard benchmarks, while offering the advantages of explicit, editable, and verifiable knowledge bases. This work represents a fundamental shift in how language models interact with and manage factual knowledge.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.15962",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google releases Gemma 2 2B, ShieldGemma and Gemma Scope",
    "description": "",
    "summary": "Google releases Gemma 2 2B, ShieldGemma and Gemma Scope One month after the release of Gemma 2, Goog...",
    "pubDate": "Wed, 31 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma-july-update",
    "thumbnail": "https://huggingface.co/blog/assets/gemma-july-update/thumbnail.jpg"
  },
  {
    "title": "Welcome PaddlePaddle to the Hugging Face Hub",
    "description": "",
    "summary": "Welcome PaddlePaddle to the Hugging Face Hub We are happy to share an open source collaboration betw...",
    "pubDate": "Tue, 17 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paddlepaddle",
    "thumbnail": "https://huggingface.co/blog/assets/126_paddlepaddle/thumbnail.jpg"
  },
  {
    "title": "Frontier risk and preparedness",
    "description": "To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge.",
    "summary": "To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge.",
    "pubDate": "Thu, 26 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-risk-and-preparedness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI and Remote Sensing for Resilient and Sustainable Built Environments: A Review of Current Methods, Open Data and Future Directions",
    "description": "arXiv:2507.01547v1 Announce Type: cross Abstract: Critical infrastructure, such as transport networks, underpins economic growth by enabling mobility and trade. However, ageing assets, climate change impacts (e.g., extreme weather, rising sea levels), and hybrid threats ranging from natural disasters to cyber attacks and conflicts pose growing risks to their resilience and functionality. This review paper explores how emerging digital technologies, specifically Artificial Intelligence (AI), can enhance damage assessment and monitoring of transport infrastructure. A systematic literature review examines existing AI models and datasets for assessing damage in roads, bridges, and other critical infrastructure impacted by natural disasters. Special focus is given to the unique challenges and opportunities associated with bridge damage detection due to their structural complexity and critical role in connectivity. The integration of SAR (Synthetic Aperture Radar) data with AI models is also discussed, with the review revealing a critical research gap: a scarcity of studies applying AI models to SAR data for comprehensive bridge damage assessment. Therefore, this review aims to identify the research gaps and provide foundations for AI-driven solutions for assessing and monitoring critical transport infrastructures.",
    "summary": "arXiv:2507.01547v1 Announce Type: cross Abstract: Critical infrastructure, such as transport networks, underpins economic growth by enabling mobility and trade. However, ageing assets, climate change impacts (e.g., extreme weather, rising sea levels), and hybrid threats ranging from natural disasters to cyber attacks and conflicts pose growing risks to their resilience and functionality. This review paper explores how emerging digital technologies, specifically Artificial Intelligence (AI), can enhance damage assessment and monitoring of transport infrastructure. A systematic literature review examines existing AI models and datasets for assessing damage in roads, bridges, and other critical infrastructure impacted by natural disasters. Special focus is given to the unique challenges and opportunities associated with bridge damage detection due to their structural complexity and critical role in connectivity. The integration of SAR (Synthetic Aperture Radar) data with AI models is also discussed, with the review revealing a critical research gap: a scarcity of studies applying AI models to SAR data for comprehensive bridge damage assessment. Therefore, this review aims to identify the research gaps and provide foundations for AI-driven solutions for assessing and monitoring critical transport infrastructures.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01547",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Exploring the Daily Papers Page on Hugging Face",
    "description": "",
    "summary": "Exploring the Daily Papers Page on Hugging Face In the fast-paced world of research, staying up-to-d...",
    "pubDate": "Mon, 23 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/daily-papers",
    "thumbnail": "https://huggingface.co/blog/assets/daily-papers/thumbnail.png"
  },
  {
    "title": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "description": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "summary": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "pubDate": "Tue, 14 May 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/collaborating-with-carlyle-to-chart-the-future-of-private-equity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenRAIL: Towards open and responsible AI licensing frameworks",
    "description": "",
    "summary": "OpenRAIL: Towards open and responsible AI licensing frameworks Open & Responsible AI licenses ('Open...",
    "pubDate": "Wed, 31 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open_rail",
    "thumbnail": "https://huggingface.co/blog/assets/100_open_rail/100_open-rail.png"
  },
  {
    "title": "Moving from intent-based bots to proactive AI agents",
    "description": "Moving from intent-based bots to proactive AI agents.",
    "summary": "Moving from intent-based bots to proactive AI agents.",
    "pubDate": "Thu, 27 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zendesk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster fine-tuning using TRL & Unsloth",
    "description": "",
    "summary": "Make LLM Fine-tuning 2x faster with Unsloth and ü§ó TRL Pulling your hair out because LLM fine-tuning ...",
    "pubDate": "Wed, 10 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unsloth-trl",
    "thumbnail": "https://huggingface.co/blog/assets/hf_unsloth/thumbnail.png"
  },
  {
    "title": "AI Policy @ü§ó: Response to the U.S. NTIA's Request for Comment on AI Accountability",
    "description": "",
    "summary": "AI Policy @ü§ó: Response to the U.S. National Telecommunications and Information Administration‚Äôs (NTI...",
    "pubDate": "Tue, 20 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/policy-ntia-rfc",
    "thumbnail": "https://huggingface.co/blog/assets/151_policy_ntia_rfc/us_policy_thumbnail.png"
  },
  {
    "title": "No-code personal agents, powered by GPT-4.1 and Realtime API",
    "description": "Learn how Genspark built a $36M ARR AI product in 45 days‚Äîwith no-code agents powered by GPT-4.1 and OpenAI Realtime API.",
    "summary": "Learn how Genspark built a $36M ARR AI product in 45 days‚Äîwith no-code agents powered by GPT-4.1 and OpenAI Realtime API.",
    "pubDate": "Tue, 01 Jul 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/genspark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation",
    "description": "",
    "summary": "StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation Instruction...",
    "pubDate": "Mon, 29 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sc2-instruct",
    "thumbnail": "https://huggingface.co/blog/assets/sc2-instruct/sc2-instruct-banner.png"
  },
  {
    "title": "How to Build an MCP Server with Gradio",
    "description": "",
    "summary": "How to Build an MCP Server in 5 Lines of Python Gradio is a Python library used by more than 1 milli...",
    "pubDate": "Wed, 30 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-mcp",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-mcp/thumbnail.png"
  },
  {
    "title": "Delivering nuanced insights from customer feedback",
    "description": "Using GPT-3 to deliver fast, nuanced insights from customer feedback.",
    "summary": "Using GPT-3 to deliver fast, nuanced insights from customer feedback.",
    "pubDate": "Wed, 04 Jan 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/yabble",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Visualize and understand GPU memory in PyTorch",
    "description": "",
    "summary": "Visualize and understand GPU memory in PyTorch You must be familiar with this message ü§¨: RuntimeErro...",
    "pubDate": "Tue, 24 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train_memory",
    "thumbnail": "https://huggingface.co/blog/assets/train_memory/thumbnail.png"
  },
  {
    "title": "Watermarking AI-generated text and video with SynthID",
    "description": "Announcing our novel watermarking method for AI-generated text and video, and how we‚Äôre bringing SynthID to key Google products",
    "summary": "Announcing our novel watermarking method for AI-generated text and video, and how we‚Äôre bringing SynthID to key Google products",
    "pubDate": "Tue, 14 May 2024 17:56:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/watermarking-ai-generated-text-and-video-with-synthid/",
    "thumbnail": "https://lh3.googleusercontent.com/I6bH75hNf57977cub27rFEsgxhcmkLrcINfCmGUaBCr7Q1bFTIl552R_6kuqlSkUjRtsTh929u6NoQmtHcwIG-GnjvPqMeynVLY0Rc9RRvezPQS0=w1200-h630-n-nu"
  },
  {
    "title": "NegMerge: Sign-Consensual Weight Merging for Machine Unlearning",
    "description": "arXiv:2410.05583v2 Announce Type: replace-cross Abstract: Machine unlearning aims to selectively remove specific knowledge from a trained model. Existing approaches, such as Task Arithmetic, fine-tune the model on the forget set to create a task vector (i.e., a direction in weight space) for subtraction from the original model's weight. However, their effectiveness is highly sensitive to hyperparameter selection, requiring extensive validation to identify the optimal vector from many fine-tuned candidates. In this paper, we propose a novel method that utilizes all fine-tuned models trained with varying hyperparameters instead of a single selection. Specifically, we aggregate the computed task vectors by retaining only the elements with consistent shared signs. The merged task vector is then negated to induce unlearning on the original model. Evaluations on zero-shot and standard image recognition tasks across twelve datasets and four backbone architectures show that our approach outperforms state-of-the-art methods while requiring similar or fewer computational resources. Code is available at https://github.com/naver-ai/negmerge.",
    "summary": "arXiv:2410.05583v2 Announce Type: replace-cross Abstract: Machine unlearning aims to selectively remove specific knowledge from a trained model. Existing approaches, such as Task Arithmetic, fine-tune the model on the forget set to create a task vector (i.e., a direction in weight space) for subtraction from the original model's weight. However, their effectiveness is highly sensitive to hyperparameter selection, requiring extensive validation to identify the optimal vector from many fine-tuned candidates. In this paper, we propose a novel method that utilizes all fine-tuned models trained with varying hyperparameters instead of a single selection. Specifically, we aggregate the computed task vectors by retaining only the elements with consistent shared signs. The merged task vector is then negated to induce unlearning on the original model. Evaluations on zero-shot and standard image recognition tasks across twelve datasets and four backbone architectures show that our approach outperforms state-of-the-art methods while requiring similar or fewer computational resources. Code is available at https://github.com/naver-ai/negmerge.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.05583",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Data Measurements Tool: an Interactive Tool for Looking at Datasets",
    "description": "",
    "summary": "Introducing the ü§ó Data Measurements Tool: an Interactive Tool for Looking at Datasets tl;dr: We made...",
    "pubDate": "Mon, 29 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/data-measurements-tool",
    "thumbnail": "https://huggingface.co/blog/assets/37_data-measurements-tool/datametrics.png"
  },
  {
    "title": "Creating next-gen characters",
    "description": "Using GPT-3 to create the next generation of AI-powered characters.",
    "summary": "Using GPT-3 to create the next generation of AI-powered characters.",
    "pubDate": "Sun, 01 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/inworld-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ü§ó PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware",
    "description": "",
    "summary": "ü§ó PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware Motivation ...",
    "pubDate": "Fri, 10 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/peft",
    "thumbnail": "https://huggingface.co/blog/assets/130_peft/thumbnail.png"
  },
  {
    "title": "DALL¬∑E now available in beta",
    "description": "We‚Äôll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL¬∑E using free credits that refill every month, and buy additional credits in 115-generation increments for¬†$15.",
    "summary": "We‚Äôll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL¬∑E using free credits that refill every month, and buy additional credits in 115-generation increments for¬†$15.",
    "pubDate": "Wed, 20 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-now-available-in-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Trace & Evaluate your Agent with Arize Phoenix",
    "description": "",
    "summary": "Trace & Evaluate your Agent with Arize Phoenix So, you‚Äôve built your agent. It takes in inputs and t...",
    "pubDate": "Fri, 28 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents-phoenix",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents-phoenix/thumbnail.jpg"
  },
  {
    "title": "RoboCat: A self-improving robotic agent",
    "description": "Robots are quickly becoming part of our everyday lives, but they‚Äôre often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data.¬†Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.",
    "summary": "Robots are quickly becoming part of our everyday lives, but they‚Äôre often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data.¬†Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.",
    "pubDate": "Tue, 20 Jun 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/robocat-a-self-improving-robotic-agent/",
    "thumbnail": "https://lh3.googleusercontent.com/Rz9Xv4TXuTe-eO2UDUD6kDElDB5wDE2b2hEU1liUAi0AyiTwQ81mLMigXg3kueWrHoqeNctRO5-EMprZDRnXcaL8snfqHwDqgQpw_qB3VEvoO_jCCzI=w1200-h630-n-nu"
  },
  {
    "title": "XLSCOUT Unveils ParaEmbed 2.0: a Powerful Embedding Model Tailored for Patents and IP with Expert Support from Hugging Face",
    "description": "",
    "summary": "XLSCOUT Unveils ParaEmbed 2.0: a Powerful Embedding Model Tailored for Patents and IP with Expert Su...",
    "pubDate": "Tue, 25 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xlscout-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/xlscout-case-study/thumbnail.png"
  },
  {
    "title": "GPT-4o System Card",
    "description": "This report outlines the safety work carried out prior to releasing GPT-4o including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "summary": "This report outlines the safety work carried out prior to releasing GPT-4o including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Age of Machine Learning As Code Has Arrived",
    "description": "",
    "summary": "The Age of Machine Learning As Code Has Arrived The 2021 edition of the State of AI Report came out ...",
    "pubDate": "Wed, 20 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the-age-of-ml-as-code",
    "thumbnail": "https://huggingface.co/blog/assets/31_age_of_ml_as_code/05_vision_transformer.png"
  },
  {
    "title": "An Introduction to Q-Learning Part 1",
    "description": "",
    "summary": "An Introduction to Q-Learning Part 1 Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 2, p...",
    "pubDate": "Wed, 18 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-q-part1",
    "thumbnail": "https://huggingface.co/blog/assets/70_deep_rl_q_part1/thumbnail.gif"
  },
  {
    "title": "Sharing the latest Model Spec",
    "description": "We‚Äôve made updates to the Model Spec based on external feedback and our continued research in shaping desired model behavior.",
    "summary": "We‚Äôve made updates to the Model Spec based on external feedback and our continued research in shaping desired model behavior.",
    "pubDate": "Wed, 12 Feb 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sharing-the-latest-model-spec",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Confidence-Building Measures for Artificial Intelligence: Workshop proceedings",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 01 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/confidence-building-measures-for-artificial-intelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GaLore: Advancing Large Model Training on Consumer-grade Hardware",
    "description": "",
    "summary": "GaLore: Advancing Large Model Training on Consumer-grade Hardware The integration of GaLore into the...",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/galore",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "OpenAI o3 and o4-mini System Card",
    "description": "OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities‚Äîweb browsing, Python, image and file analysis, image generation, canvas, automations, file search, and memory.",
    "summary": "OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities‚Äîweb browsing, Python, image and file analysis, image generation, canvas, automations, file search, and memory.",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploying ü§ó ViT on Kubernetes with TF Serving",
    "description": "",
    "summary": "Deploying ü§ó ViT on Kubernetes with TF Serving In the previous post, we showed how to deploy a Vision...",
    "pubDate": "Thu, 11 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-tfserving-kubernetes",
    "thumbnail": "https://huggingface.co/blog/assets/94_tf_serving_kubernetes/thumb.png"
  },
  {
    "title": "SetFit: Efficient Few-Shot Learning Without Prompts",
    "description": "",
    "summary": "SetFit: Efficient Few-Shot Learning Without Prompts SetFit is significantly more sample efficient an...",
    "pubDate": "Mon, 26 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit",
    "thumbnail": "https://huggingface.co/blog/assets/103_setfit/intel_hf_logo.png"
  },
  {
    "title": "Showcase Your Projects in Spaces using Gradio",
    "description": "",
    "summary": "Showcase Your Projects in Spaces using Gradio It's so easy to demonstrate a Machine Learning project...",
    "pubDate": "Tue, 05 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/28_gradio-spaces/thumbnail.png"
  },
  {
    "title": "Text and code embeddings by contrastive pre-training",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 24 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/text-and-code-embeddings-by-contrastive-pre-training",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CPU Optimized Embeddings with ü§ó Optimum Intel and fastRAG",
    "description": "",
    "summary": "CPU Optimized Embeddings with ü§ó Optimum Intel and fastRAG Embedding models are useful for many appli...",
    "pubDate": "Fri, 15 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-fast-embedding",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "The Newsroom AI Catalyst: a global program with WAN-IFRA",
    "description": "We‚Äôre collaborating with WAN-IFRA, the World Association of News Publishers, to launch a global accelerator program that will assist over 100 news publishers to explore and integrate AI in their newsroom.",
    "summary": "We‚Äôre collaborating with WAN-IFRA, the World Association of News Publishers, to launch a global accelerator program that will assist over 100 news publishers to explore and integrate AI in their newsroom.",
    "pubDate": "Wed, 29 May 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/newsroom-ai-catalyst-global-program-with-wan-ifra",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SmolVLM - small yet mighty Vision Language Model",
    "description": "",
    "summary": "SmolVLM - small yet mighty Vision Language Model TLDR This blog post introduces SmolVLM, a 2B VLM, S...",
    "pubDate": "Tue, 26 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvlm",
    "thumbnail": "https://huggingface.co/blog/assets/smolvlm/banner.png"
  },
  {
    "title": "Addendum to GPT-4o System Card: 4o image generation",
    "description": "4o image generation is a new, significantly more capable image generation approach than our earlier DALL¬∑E 3 series of models. It can create photorealistic output. It can take images as inputs and transform them.",
    "summary": "4o image generation is a new, significantly more capable image generation approach than our earlier DALL¬∑E 3 series of models. It can create photorealistic output. It can take images as inputs and transform them.",
    "pubDate": "Tue, 25 Mar 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-image-generation-system-card-addendum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Delivering LLM-powered health solutions",
    "description": "WHOOP delivers personalized fitness and health coaching with GPT-4.",
    "summary": "WHOOP delivers personalized fitness and health coaching with GPT-4.",
    "pubDate": "Thu, 04 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/whoop",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving language understanding with unsupervised learning",
    "description": "We‚Äôve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we‚Äôre also releasing. Our approach is a combination of two existing ideas:¬†transformers¬†and¬†unsupervised pre-training. These results provide a convincing example that pairing supervised learning methods with unsupervised pre-training works very well; this is an idea that many have explored in the past, and we hope our result motivates further research into applying this idea on larger and more diverse¬†datasets.",
    "summary": "We‚Äôve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we‚Äôre also releasing. Our approach is a combination of two existing ideas:¬†transformers¬†and¬†unsupervised pre-training. These results provide a convincing example that pairing supervised learning methods with unsupervised pre-training works very well; this is an idea that many have explored in the past, and we hope our result motivates further research into applying this idea on larger and more diverse¬†datasets.",
    "pubDate": "Mon, 11 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-unsupervised",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building interactive agents in video game worlds",
    "description": "Most artificial intelligence (AI) researchers now believe that writing computer code which can capture the nuances of situated interactions is impossible. Alternatively, modern machine learning (ML) researchers have focused on learning about these types of interactions from data. To explore these learning-based approaches and quickly build agents that can make sense of human instructions and safely perform actions in open-ended conditions, we created a research framework within a video game environment.Today, we‚Äôre publishing a paper [INSERT LINK] and collection of videos, showing our early steps in building video game AIs that can understand fuzzy human concepts ‚Äì and therefore, can begin to interact with people on their own terms.",
    "summary": "Most artificial intelligence (AI) researchers now believe that writing computer code which can capture the nuances of situated interactions is impossible. Alternatively, modern machine learning (ML) researchers have focused on learning about these types of interactions from data. To explore these learning-based approaches and quickly build agents that can make sense of human instructions and safely perform actions in open-ended conditions, we created a research framework within a video game environment.Today, we‚Äôre publishing a paper [INSERT LINK] and collection of videos, showing our early steps in building video game AIs that can understand fuzzy human concepts ‚Äì and therefore, can begin to interact with people on their own terms.",
    "pubDate": "Wed, 23 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/building-interactive-agents-in-video-game-worlds/",
    "thumbnail": "https://lh3.googleusercontent.com/6DSrkFaInWqKD1eN4IJJN31ZRa3LW447A1ZYoK19FDzJGSLD5dlVw1rJRf52O_dmQUDq11XqYsiqMR8uFDnWLWGkl8xFY5KXYxD7LvQNPvTEuR_h=w1200-h630-n-nu"
  },
  {
    "title": "Beyond Black-Box AI: Interpretable Hybrid Systems for Dementia Care",
    "description": "arXiv:2507.01282v1 Announce Type: new Abstract: The recent boom of large language models (LLMs) has re-ignited the hope that artificial intelligence (AI) systems could aid medical diagnosis. Yet despite dazzling benchmark scores, LLM assistants have yet to deliver measurable improvements at the bedside. This scoping review aims to highlight the areas where AI is limited to make practical contributions in the clinical setting, specifically in dementia diagnosis and care. Standalone machine-learning models excel at pattern recognition but seldom provide actionable, interpretable guidance, eroding clinician trust. Adjacent use of LLMs by physicians did not result in better diagnostic accuracy or speed. Key limitations trace to the data-driven paradigm: black-box outputs which lack transparency, vulnerability to hallucinations, and weak causal reasoning. Hybrid approaches that combine statistical learning with expert rule-based knowledge, and involve clinicians throughout the process help bring back interpretability. They also fit better with existing clinical workflows, as seen in examples like PEIRS and ATHENA-CDS. Future decision-support should prioritise explanatory coherence by linking predictions to clinically meaningful causes. This can be done through neuro-symbolic or hybrid AI that combines the language ability of LLMs with human causal expertise. AI researchers have addressed this direction, with explainable AI and neuro-symbolic AI being the next logical steps in further advancement in AI. However, they are still based on data-driven knowledge integration instead of human-in-the-loop approaches. Future research should measure success not only by accuracy but by improvements in clinician understanding, workflow fit, and patient outcomes. A better understanding of what helps improve human-computer interactions is greatly needed for AI systems to become part of clinical practice.",
    "summary": "arXiv:2507.01282v1 Announce Type: new Abstract: The recent boom of large language models (LLMs) has re-ignited the hope that artificial intelligence (AI) systems could aid medical diagnosis. Yet despite dazzling benchmark scores, LLM assistants have yet to deliver measurable improvements at the bedside. This scoping review aims to highlight the areas where AI is limited to make practical contributions in the clinical setting, specifically in dementia diagnosis and care. Standalone machine-learning models excel at pattern recognition but seldom provide actionable, interpretable guidance, eroding clinician trust. Adjacent use of LLMs by physicians did not result in better diagnostic accuracy or speed. Key limitations trace to the data-driven paradigm: black-box outputs which lack transparency, vulnerability to hallucinations, and weak causal reasoning. Hybrid approaches that combine statistical learning with expert rule-based knowledge, and involve clinicians throughout the process help bring back interpretability. They also fit better with existing clinical workflows, as seen in examples like PEIRS and ATHENA-CDS. Future decision-support should prioritise explanatory coherence by linking predictions to clinically meaningful causes. This can be done through neuro-symbolic or hybrid AI that combines the language ability of LLMs with human causal expertise. AI researchers have addressed this direction, with explainable AI and neuro-symbolic AI being the next logical steps in further advancement in AI. However, they are still based on data-driven knowledge integration instead of human-in-the-loop approaches. Future research should measure success not only by accuracy but by improvements in clinician understanding, workflow fit, and patient outcomes. A better understanding of what helps improve human-computer interactions is greatly needed for AI systems to become part of clinical practice.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01282",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DREAMS: A python framework for Training Deep Learning Models on EEG Data with Model Card Reporting for Medical Applications",
    "description": "arXiv:2409.17815v2 Announce Type: replace Abstract: Electroencephalography (EEG) provides a non-invasive way to observe brain activity in real time. Deep learning has enhanced EEG analysis, enabling meaningful pattern detection for clinical and research purposes. However, most existing frameworks for EEG data analysis are either focused on preprocessing techniques or deep learning model development, often overlooking the crucial need for structured documentation and model interpretability. In this paper, we introduce DREAMS (Deep REport for AI ModelS), a Python-based framework designed to generate automated model cards for deep learning models applied to EEG data. Unlike generic model reporting tools, DREAMS is specifically tailored for EEG-based deep learning applications, incorporating domain-specific metadata, preprocessing details, performance metrics, and uncertainty quantification. The framework seamlessly integrates with deep learning pipelines, providing structured YAML-based documentation. We evaluate DREAMS through two case studies: an EEG emotion classification task using the FACED dataset and a abnormal EEG classification task using the Temple Univeristy Hospital (TUH) Abnormal dataset. These evaluations demonstrate how the generated model card enhances transparency by documenting model performance, dataset biases, and interpretability limitations. Unlike existing model documentation approaches, DREAMS provides visualized performance metrics, dataset alignment details, and model uncertainty estimations, making it a valuable tool for researchers and clinicians working with EEG-based AI. The source code for DREAMS is open-source, facilitating broad adoption in healthcare AI, research, and ethical AI development.",
    "summary": "arXiv:2409.17815v2 Announce Type: replace Abstract: Electroencephalography (EEG) provides a non-invasive way to observe brain activity in real time. Deep learning has enhanced EEG analysis, enabling meaningful pattern detection for clinical and research purposes. However, most existing frameworks for EEG data analysis are either focused on preprocessing techniques or deep learning model development, often overlooking the crucial need for structured documentation and model interpretability. In this paper, we introduce DREAMS (Deep REport for AI ModelS), a Python-based framework designed to generate automated model cards for deep learning models applied to EEG data. Unlike generic model reporting tools, DREAMS is specifically tailored for EEG-based deep learning applications, incorporating domain-specific metadata, preprocessing details, performance metrics, and uncertainty quantification. The framework seamlessly integrates with deep learning pipelines, providing structured YAML-based documentation. We evaluate DREAMS through two case studies: an EEG emotion classification task using the FACED dataset and a abnormal EEG classification task using the Temple Univeristy Hospital (TUH) Abnormal dataset. These evaluations demonstrate how the generated model card enhances transparency by documenting model performance, dataset biases, and interpretability limitations. Unlike existing model documentation approaches, DREAMS provides visualized performance metrics, dataset alignment details, and model uncertainty estimations, making it a valuable tool for researchers and clinicians working with EEG-based AI. The source code for DREAMS is open-source, facilitating broad adoption in healthcare AI, research, and ethical AI development.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.17815",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Dr. Ronnie Chatterji named OpenAI‚Äôs first Chief Economist",
    "description": "Dr. Ronnie Chatterji named OpenAI‚Äôs first Chief Economist",
    "summary": "Dr. Ronnie Chatterji named OpenAI‚Äôs first Chief Economist",
    "pubDate": "Tue, 22 Oct 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-chief-economist-announcement",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Apps in a Flash with Gradio's Reload Mode",
    "description": "",
    "summary": "AI Apps in a Flash with Gradio's Reload Mode In this post, I will show you how you can build a funct...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-reload",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-reload/thumbnail_compressed.png"
  },
  {
    "title": "Transformer-based Encoder-Decoder Models",
    "description": "",
    "summary": "Transformers-based Encoder-Decoder Models !pip install transformers==4.2.1 !pip install sentencepiec...",
    "pubDate": "Sat, 10 Oct 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/encoder-decoder",
    "thumbnail": "https://huggingface.co/blog/assets/05_encoder_decoder/thumbnail.png"
  },
  {
    "title": "Cohere on Hugging Face Inference Providers üî•",
    "description": "",
    "summary": "Cohere on Hugging Face Inference Providers üî• We're thrilled to share that Cohere is now a supported ...",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-cohere",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers-cohere/thumbnail.png"
  },
  {
    "title": "How Metacognitive Architectures Remember Their Own Thoughts: A Systematic Review",
    "description": "arXiv:2503.13467v2 Announce Type: replace-cross Abstract: Background: Metacognition has gained significant attention for its potential to enhance autonomy and adaptability of artificial agents but remains a fragmented field: diverse theories, terminologies, and design choices have led to disjointed developments and limited comparability across systems. Existing overviews remain at a conceptual level that is undiscerning to the underlying algorithms, representations, and their respective success. Methods: We address this gap by performing an explorative systematic review. Reports were included if they described techniques enabling Computational Metacognitive Architectures (CMAs) to model, store, remember, and process their episodic metacognitive experiences, one of Flavell's (1979a) three foundational components of metacognition. Searches were conducted in 16 databases, consulted between December 2023 and June 2024. Data were extracted using a 20-item framework considering pertinent aspects. Results: A total of 101 reports on 35 distinct CMAs were included. Our findings show that metacognitive experiences may boost system performance and explainability, e.g., via self-repair. However, lack of standardization and limited evaluations may hinder progress: only 17% of CMAs were quantitatively evaluated regarding this review's focus, and significant terminological inconsistency limits cross-architecture synthesis. Systems also varied widely in memory content, data types, and employed algorithms. Discussion: Limitations include the non-iterative nature of the search query, heterogeneous data availability, and an under-representation of emergent, sub-symbolic CMAs. Future research should focus on standardization and evaluation, e.g., via community-driven challenges, and on transferring promising principles to emergent architectures.",
    "summary": "arXiv:2503.13467v2 Announce Type: replace-cross Abstract: Background: Metacognition has gained significant attention for its potential to enhance autonomy and adaptability of artificial agents but remains a fragmented field: diverse theories, terminologies, and design choices have led to disjointed developments and limited comparability across systems. Existing overviews remain at a conceptual level that is undiscerning to the underlying algorithms, representations, and their respective success. Methods: We address this gap by performing an explorative systematic review. Reports were included if they described techniques enabling Computational Metacognitive Architectures (CMAs) to model, store, remember, and process their episodic metacognitive experiences, one of Flavell's (1979a) three foundational components of metacognition. Searches were conducted in 16 databases, consulted between December 2023 and June 2024. Data were extracted using a 20-item framework considering pertinent aspects. Results: A total of 101 reports on 35 distinct CMAs were included. Our findings show that metacognitive experiences may boost system performance and explainability, e.g., via self-repair. However, lack of standardization and limited evaluations may hinder progress: only 17% of CMAs were quantitatively evaluated regarding this review's focus, and significant terminological inconsistency limits cross-architecture synthesis. Systems also varied widely in memory content, data types, and employed algorithms. Discussion: Limitations include the non-iterative nature of the search query, heterogeneous data availability, and an under-representation of emergent, sub-symbolic CMAs. Future research should focus on standardization and evaluation, e.g., via community-driven challenges, and on transferring promising principles to emergent architectures.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.13467",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Multi-Goal Reinforcement Learning: Challenging robotics environments and request for research",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 26 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/multi-goal-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI for Education",
    "description": "An affordable offering for universities to responsibly bring AI to campus.",
    "summary": "An affordable offering for universities to responsibly bring AI to campus.",
    "pubDate": "Thu, 30 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-edu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "State-of-the-art video and image generation with Veo 2 and Imagen 3",
    "description": "We‚Äôre rolling out a new, state-of-the-art video model, Veo 2, and updates to Imagen 3. Plus, check out our new experiment, Whisk.",
    "summary": "We‚Äôre rolling out a new, state-of-the-art video model, Veo 2, and updates to Imagen 3. Plus, check out our new experiment, Whisk.",
    "pubDate": "Mon, 16 Dec 2024 17:01:16 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/state-of-the-art-video-and-image-generation-with-veo-2-and-imagen-3/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/12-16-24_GenMedia_16x9.width-1300.png"
  },
  {
    "title": "Automating 90% of finance and legal work with agents",
    "description": "Hebbia‚Äôs deep research automates 90% of finance and legal work, powered by OpenAI",
    "summary": "Hebbia‚Äôs deep research automates 90% of finance and legal work, powered by OpenAI",
    "pubDate": "Tue, 25 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hebbia",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Minnesota‚Äôs Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "description": "Minnesota‚Äôs Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "summary": "Minnesota‚Äôs Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "pubDate": "Thu, 26 Sep 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/state-of-minnesota",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Perceiving Beyond Language Priors: Enhancing Visual Comprehension and Attention in Multimodal Models",
    "description": "arXiv:2505.05626v3 Announce Type: replace-cross Abstract: Achieving deep alignment between vision and language remains a central challenge for Multimodal Large Language Models (MLLMs). These models often fail to fully leverage visual input, defaulting to strong language priors. Our approach first provides insights into how MLLMs internally build visual understanding of image regions and then introduces techniques to amplify this capability. Specifically, we explore techniques designed both to deepen the model's understanding of visual content and to ensure that these visual insights actively guide language generation. We demonstrate the superior multimodal understanding of our resultant model through a detailed upstream analysis quantifying its ability to predict visually-dependent tokens as well as 10 pt boost on visually challenging tasks.",
    "summary": "arXiv:2505.05626v3 Announce Type: replace-cross Abstract: Achieving deep alignment between vision and language remains a central challenge for Multimodal Large Language Models (MLLMs). These models often fail to fully leverage visual input, defaulting to strong language priors. Our approach first provides insights into how MLLMs internally build visual understanding of image regions and then introduces techniques to amplify this capability. Specifically, we explore techniques designed both to deepen the model's understanding of visual content and to ensure that these visual insights actively guide language generation. We demonstrate the superior multimodal understanding of our resultant model through a detailed upstream analysis quantifying its ability to predict visually-dependent tokens as well as 10 pt boost on visually challenging tasks.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.05626",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Integrating Traditional and Deep Learning Methods to Detect Tree Crowns in Satellite Images",
    "description": "arXiv:2507.01502v1 Announce Type: cross Abstract: Global warming, loss of biodiversity, and air pollution are among the most significant problems facing Earth. One of the primary challenges in addressing these issues is the lack of monitoring forests to protect them. To tackle this problem, it is important to leverage remote sensing and computer vision methods to automate monitoring applications. Hence, automatic tree crown detection algorithms emerged based on traditional and deep learning methods. In this study, we first introduce two different tree crown detection methods based on these approaches. Then, we form a novel rule-based approach that integrates these two methods to enhance robustness and accuracy of tree crown detection results. While traditional methods are employed for feature extraction and segmentation of forested areas, deep learning methods are used to detect tree crowns in our method. With the proposed rule-based approach, we post-process these results, aiming to increase the number of detected tree crowns through neighboring trees and localized operations. We compare the obtained results with the proposed method in terms of the number of detected tree crowns and report the advantages, disadvantages, and areas for improvement of the obtained outcomes.",
    "summary": "arXiv:2507.01502v1 Announce Type: cross Abstract: Global warming, loss of biodiversity, and air pollution are among the most significant problems facing Earth. One of the primary challenges in addressing these issues is the lack of monitoring forests to protect them. To tackle this problem, it is important to leverage remote sensing and computer vision methods to automate monitoring applications. Hence, automatic tree crown detection algorithms emerged based on traditional and deep learning methods. In this study, we first introduce two different tree crown detection methods based on these approaches. Then, we form a novel rule-based approach that integrates these two methods to enhance robustness and accuracy of tree crown detection results. While traditional methods are employed for feature extraction and segmentation of forested areas, deep learning methods are used to detect tree crowns in our method. With the proposed rule-based approach, we post-process these results, aiming to increase the number of detected tree crowns through neighboring trees and localized operations. We compare the obtained results with the proposed method in terms of the number of detected tree crowns and report the advantages, disadvantages, and areas for improvement of the obtained outcomes.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01502",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Microscope",
    "description": "We‚Äôre introducing¬†OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision ‚Äúmodel organisms‚Äù which are often studied in interpretability. Microscope makes it easier to analyze the features that form inside these neural networks, and we hope it will help the research community as we move towards understanding these complicated¬†systems.",
    "summary": "We‚Äôre introducing¬†OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision ‚Äúmodel organisms‚Äù which are often studied in interpretability. Microscope makes it easier to analyze the features that form inside these neural networks, and we hope it will help the research community as we move towards understanding these complicated¬†systems.",
    "pubDate": "Tue, 14 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/microscope",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning a hierarchy",
    "description": "We‚Äôve developed a hierarchical reinforcement learning algorithm that learns high-level actions useful for solving a range of tasks, allowing fast solving of tasks requiring thousands of timesteps. Our algorithm, when applied to a set of navigation problems, discovers a set of high-level actions for walking and crawling in different directions, which enables the agent to master new navigation tasks quickly.",
    "summary": "We‚Äôve developed a hierarchical reinforcement learning algorithm that learns high-level actions useful for solving a range of tasks, allowing fast solving of tasks requiring thousands of timesteps. Our algorithm, when applied to a set of navigation problems, discovers a set of high-level actions for walking and crawling in different directions, which enables the agent to master new navigation tasks quickly.",
    "pubDate": "Thu, 26 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-a-hierarchy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Why responsible AI development needs cooperation on safety",
    "description": "We‚Äôve written a policy research paper identifying four strategies that can be used today to improve the likelihood of long-term industry cooperation on safety norms in AI: communicating risks and benefits, technical collaboration, increased transparency, and incentivizing standards. Our analysis shows that industry cooperation on safety will be instrumental in ensuring that AI systems are safe and beneficial, but competitive pressures could lead to a collective action problem, potentially causing AI companies to under-invest in safety. We hope these strategies will encourage greater cooperation on the safe development of AI and lead to better global outcomes of¬†AI.",
    "summary": "We‚Äôve written a policy research paper identifying four strategies that can be used today to improve the likelihood of long-term industry cooperation on safety norms in AI: communicating risks and benefits, technical collaboration, increased transparency, and incentivizing standards. Our analysis shows that industry cooperation on safety will be instrumental in ensuring that AI systems are safe and beneficial, but competitive pressures could lead to a collective action problem, potentially causing AI companies to under-invest in safety. We hope these strategies will encourage greater cooperation on the safe development of AI and lead to better global outcomes of¬†AI.",
    "pubDate": "Wed, 10 Jul 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/cooperation-on-safety",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Model Cards: Introducing HF Model documentation tools",
    "description": "",
    "summary": "Model Cards Introduction Model cards are an important documentation framework for understanding, sha...",
    "pubDate": "Tue, 20 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/model-cards",
    "thumbnail": "https://huggingface.co/blog/assets/121_model-cards/thumbnail.png"
  },
  {
    "title": "Boost Wav2Vec2 with n-gram LM in ü§ó Transformers",
    "description": "",
    "summary": "Boosting Wav2Vec2 with n-grams in ü§ó Transformers Wav2Vec2 is a popular pre-trained model for speech ...",
    "pubDate": "Wed, 12 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/wav2vec2-with-ngram",
    "thumbnail": "https://huggingface.co/blog/assets/44_boost_wav2vec2_ngram/wav2vec2_ngram.png"
  },
  {
    "title": "Towards culturally-appropriate conversational AI for health in the majority world: An exploratory study with citizens and professionals in Latin America",
    "description": "arXiv:2507.01719v1 Announce Type: cross Abstract: There is justifiable interest in leveraging conversational AI (CAI) for health across the majority world, but to be effective, CAI must respond appropriately within culturally and linguistically diverse contexts. Therefore, we need ways to address the fact that current LLMs exclude many lived experiences globally. Various advances are underway which focus on top-down approaches and increasing training data. In this paper, we aim to complement these with a bottom-up locally-grounded approach based on qualitative data collected during participatory workshops in Latin America. Our goal is to construct a rich and human-centred understanding of: a) potential areas of cultural misalignment in digital health; b) regional perspectives on chatbots for health and c)strategies for creating culturally-appropriate CAI; with a focus on the understudied Latin American context. Our findings show that academic boundaries on notions of culture lose meaning at the ground level and technologies will need to engage with a broader framework; one that encapsulates the way economics, politics, geography and local logistics are entangled in cultural experience. To this end, we introduce a framework for 'Pluriversal Conversational AI for Health' which allows for the possibility that more relationality and tolerance, rather than just more data, may be called for.",
    "summary": "arXiv:2507.01719v1 Announce Type: cross Abstract: There is justifiable interest in leveraging conversational AI (CAI) for health across the majority world, but to be effective, CAI must respond appropriately within culturally and linguistically diverse contexts. Therefore, we need ways to address the fact that current LLMs exclude many lived experiences globally. Various advances are underway which focus on top-down approaches and increasing training data. In this paper, we aim to complement these with a bottom-up locally-grounded approach based on qualitative data collected during participatory workshops in Latin America. Our goal is to construct a rich and human-centred understanding of: a) potential areas of cultural misalignment in digital health; b) regional perspectives on chatbots for health and c)strategies for creating culturally-appropriate CAI; with a focus on the understudied Latin American context. Our findings show that academic boundaries on notions of culture lose meaning at the ground level and technologies will need to engage with a broader framework; one that encapsulates the way economics, politics, geography and local logistics are entangled in cultural experience. To this end, we introduce a framework for 'Pluriversal Conversational AI for Health' which allows for the possibility that more relationality and tolerance, rather than just more data, may be called for.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01719",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Blazing Fast SetFit Inference with ü§ó Optimum Intel on Xeon",
    "description": "",
    "summary": "Blazing Fast SetFit Inference with ü§ó Optimum Intel on Xeon SetFit is a promising solution for a comm...",
    "pubDate": "Wed, 03 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit-optimum-intel",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "LAVE: Zero-shot VQA Evaluation on Docmatix with LLMs - Do We Still Need Fine-Tuning?",
    "description": "",
    "summary": "LAVE: Zero-shot VQA Evaluation on Docmatix with LLMs - Do We Still Need Fine-Tuning? While developin...",
    "pubDate": "Thu, 25 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-shot-vqa-docmatix",
    "thumbnail": "https://huggingface.co/blog/assets/184_zero_shot_docmatix/thumb.001.jpeg"
  },
  {
    "title": "Increasing accuracy of pediatric visit notes",
    "description": "Summer Health reimagines pediatric doctor‚Äôs visits with OpenAI.",
    "summary": "Summer Health reimagines pediatric doctor‚Äôs visits with OpenAI.",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/summer-health",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Efficient Table Pre-training without Real Data: An Introduction to TAPEX",
    "description": "",
    "summary": "Efficient Table Pre-training without Real Data: An Introduction to TAPEX In recent years, language m...",
    "pubDate": "Mon, 23 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tapex",
    "thumbnail": "https://huggingface.co/blog/assets/74_tapex/thumbnail.png"
  },
  {
    "title": "Ôºª„Éá„Éº„ÇøÂàÜÊûêÔºΩÂå∫ÈñìÊé®ÂÆö„ÅÆ„Åü„ÇÅ„Å´ÂøÖË¶Å„Å™„Çµ„É≥„Éó„É´„Çµ„Ç§„Ç∫„ÅØ„Å©„Çå„Åê„Çâ„ÅÑÔºü",
    "description": "„Éá„Éº„ÇøÂàÜÊûê„ÅÆÂàùÊ≠©„Åã„ÇâÂøúÁî®„Åæ„ÅßÂ∞ë„Åó„Åö„Å§„Çπ„ÉÜ„ÉÉ„Éó„Ç¢„ÉÉ„Éó„Åó„Å™„Åå„ÇâÂ≠¶„Çì„Åß„ÅÑ„ÅèÈÄ£ËºâÔºàÂå∫ÈñìÊé®ÂÆöÁ∑®Ôºâ„ÅÆÁ¨¨8Âõû„ÄÇ‰ªäÂõû„ÅØÈÅ©Âàá„Å´Âå∫ÈñìÊé®ÂÆö„ÇíË°å„ÅÜ„Åü„ÇÅ„Å´ÂøÖË¶Å„Å™„Çµ„É≥„Éó„É´„Çµ„Ç§„Ç∫„ÅÆÊ±Ç„ÇÅÊñπ„Å®„Åù„ÅÆËÄÉ„ÅàÊñπ„ÇíËß£Ë™¨„Åó„Åæ„Åô„ÄÇ",
    "summary": "„Éá„Éº„ÇøÂàÜÊûê„ÅÆÂàùÊ≠©„Åã„ÇâÂøúÁî®„Åæ„ÅßÂ∞ë„Åó„Åö„Å§„Çπ„ÉÜ„ÉÉ„Éó„Ç¢„ÉÉ„Éó„Åó„Å™„Åå„ÇâÂ≠¶„Çì„Åß„ÅÑ„ÅèÈÄ£ËºâÔºàÂå∫ÈñìÊé®ÂÆöÁ∑®Ôºâ„ÅÆÁ¨¨8Âõû„ÄÇ‰ªäÂõû„ÅØÈÅ©Âàá„Å´Âå∫ÈñìÊé®ÂÆö„ÇíË°å„ÅÜ„Åü„ÇÅ„Å´ÂøÖË¶Å„Å™„Çµ„É≥„Éó„É´„Çµ„Ç§„Ç∫„ÅÆÊ±Ç„ÇÅÊñπ„Å®„Åù„ÅÆËÄÉ„ÅàÊñπ„ÇíËß£Ë™¨„Åó„Åæ„Åô„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 05:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://atmarkit.itmedia.co.jp/ait/articles/2507/03/news003.html",
    "thumbnail": "https://image.itmedia.co.jp/ait/articles/2507/03/cover_news003.png"
  },
  {
    "title": "Surging developer productivity with custom GPTs",
    "description": "Paf adopted ChatGPT Enterprise across its entire company, with engineers using custom GPTs on a daily basis to speed up routine development tasks. Paf also integrated ChatGPT Enterprise into the grit:lab coding academy (gritlab.ax), training the next generation of software developers using an AI-augmented, systems-architecture mindset from day one. In addition to the wide range of use cases for developers and grit:lab students, 70% of Paf employees actively use ChatGPT Enterprise, spanning business teams like finance, HR, marketing, and customer support.",
    "summary": "Paf adopted ChatGPT Enterprise across its entire company, with engineers using custom GPTs on a daily basis to speed up routine development tasks. Paf also integrated ChatGPT Enterprise into the grit:lab coding academy (gritlab.ax), training the next generation of software developers using an AI-augmented, systems-architecture mindset from day one. In addition to the wide range of use cases for developers and grit:lab students, 70% of Paf employees actively use ChatGPT Enterprise, spanning business teams like finance, HR, marketing, and customer support.",
    "pubDate": "Tue, 18 Jun 2024 08:45:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paf",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Dota 2 with large scale deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 13 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dota-2-with-large-scale-deep-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Data Agent: A Holistic Architecture for Orchestrating Data+AI Ecosystems",
    "description": "arXiv:2507.01599v1 Announce Type: cross Abstract: Traditional Data+AI systems utilize data-driven techniques to optimize performance, but they rely heavily on human experts to orchestrate system pipelines, enabling them to adapt to changes in data, queries, tasks, and environments. For instance, while there are numerous data science tools available, developing a pipeline planning system to coordinate these tools remains challenging. This difficulty arises because existing Data+AI systems have limited capabilities in semantic understanding, reasoning, and planning. Fortunately, we have witnessed the success of large language models (LLMs) in enhancing semantic understanding, reasoning, and planning abilities. It is crucial to incorporate LLM techniques to revolutionize data systems for orchestrating Data+AI applications effectively. To achieve this, we propose the concept of a 'Data Agent' - a comprehensive architecture designed to orchestrate Data+AI ecosystems, which focuses on tackling data-related tasks by integrating knowledge comprehension, reasoning, and planning capabilities. We delve into the challenges involved in designing data agents, such as understanding data/queries/environments/tools, orchestrating pipelines/workflows, optimizing and executing pipelines, and fostering pipeline self-reflection. Furthermore, we present examples of data agent systems, including a data science agent, data analytics agents (such as unstructured data analytics agent, semantic structured data analytics agent, data lake analytics agent, and multi-modal data analytics agent), and a database administrator (DBA) agent. We also outline several open challenges associated with designing data agent systems.",
    "summary": "arXiv:2507.01599v1 Announce Type: cross Abstract: Traditional Data+AI systems utilize data-driven techniques to optimize performance, but they rely heavily on human experts to orchestrate system pipelines, enabling them to adapt to changes in data, queries, tasks, and environments. For instance, while there are numerous data science tools available, developing a pipeline planning system to coordinate these tools remains challenging. This difficulty arises because existing Data+AI systems have limited capabilities in semantic understanding, reasoning, and planning. Fortunately, we have witnessed the success of large language models (LLMs) in enhancing semantic understanding, reasoning, and planning abilities. It is crucial to incorporate LLM techniques to revolutionize data systems for orchestrating Data+AI applications effectively. To achieve this, we propose the concept of a 'Data Agent' - a comprehensive architecture designed to orchestrate Data+AI ecosystems, which focuses on tackling data-related tasks by integrating knowledge comprehension, reasoning, and planning capabilities. We delve into the challenges involved in designing data agents, such as understanding data/queries/environments/tools, orchestrating pipelines/workflows, optimizing and executing pipelines, and fostering pipeline self-reflection. Furthermore, we present examples of data agent systems, including a data science agent, data analytics agents (such as unstructured data analytics agent, semantic structured data analytics agent, data lake analytics agent, and multi-modal data analytics agent), and a database administrator (DBA) agent. We also outline several open challenges associated with designing data agent systems.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01599",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Report from the OpenAI hackathon",
    "description": "On March 3rd, we hosted our first¬†hackathon¬†with 100 members of the artificial intelligence community.",
    "summary": "On March 3rd, we hosted our first¬†hackathon¬†with 100 members of the artificial intelligence community.",
    "pubDate": "Thu, 15 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hackathon-follow-up",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Constitutional AI with Open LLMs",
    "description": "",
    "summary": "Constitutional AI with Open LLMs Since the launch of ChatGPT in 2022, we have seen tremendous progre...",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/constitutional_ai",
    "thumbnail": "https://huggingface.co/blog/assets/175_constitutional_ai/thumbnail.png"
  },
  {
    "title": "Customized Exploration of Landscape Features Driving Multi-Objective Combinatorial Optimization Performance",
    "description": "arXiv:2507.01638v1 Announce Type: cross Abstract: We present an analysis of landscape features for predicting the performance of multi-objective combinatorial optimization algorithms. We consider features from the recently proposed compressed Pareto Local Optimal Solutions Networks (C-PLOS-net) model of combinatorial landscapes. The benchmark instances are a set of rmnk-landscapes with 2 and 3 objectives and various levels of ruggedness and objective correlation. We consider the performance of three algorithms -- Pareto Local Search (PLS), Global Simple EMO Optimizer (GSEMO), and Non-dominated Sorting Genetic Algorithm (NSGA-II) - using the resolution and hypervolume metrics. Our tailored analysis reveals feature combinations that influence algorithm performance specific to certain landscapes. This study provides deeper insights into feature importance, tailored to specific rmnk-landscapes and algorithms.",
    "summary": "arXiv:2507.01638v1 Announce Type: cross Abstract: We present an analysis of landscape features for predicting the performance of multi-objective combinatorial optimization algorithms. We consider features from the recently proposed compressed Pareto Local Optimal Solutions Networks (C-PLOS-net) model of combinatorial landscapes. The benchmark instances are a set of rmnk-landscapes with 2 and 3 objectives and various levels of ruggedness and objective correlation. We consider the performance of three algorithms -- Pareto Local Search (PLS), Global Simple EMO Optimizer (GSEMO), and Non-dominated Sorting Genetic Algorithm (NSGA-II) - using the resolution and hypervolume metrics. Our tailored analysis reveals feature combinations that influence algorithm performance specific to certain landscapes. This study provides deeper insights into feature importance, tailored to specific rmnk-landscapes and algorithms.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01638",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google DeepMind at ICML 2024",
    "description": "Exploring AGI, the challenges of scaling and the future of multimodal generative AI",
    "summary": "Exploring AGI, the challenges of scaling and the future of multimodal generative AI",
    "pubDate": "Fri, 19 Jul 2024 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-icml-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/_o0MU47bgKrTJi6uOWhc3BjWOOENkBczD2x5-tK5aMLBcljJnV-N8tZuSVN42C3d1pSWawY6NsGuoj6vvl0xMk4tpWOeUjXwlgFNZSMyJkFJ02xTauk=w1200-h630-n-nu"
  },
  {
    "title": "Partnership with Axel Springer to deepen beneficial use of AI in journalism",
    "description": "Axel Springer is the first publishing house globally to partner with us on a deeper integration of journalism in AI technologies.",
    "summary": "Axel Springer is the first publishing house globally to partner with us on a deeper integration of journalism in AI technologies.",
    "pubDate": "Wed, 13 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/axel-springer-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Procgen Benchmark",
    "description": "We‚Äôre releasing Procgen Benchmark, 16 simple-to-use¬†procedurally-generated¬†environments which provide a direct measure of how quickly a reinforcement learning agent learns generalizable¬†skills.",
    "summary": "We‚Äôre releasing Procgen Benchmark, 16 simple-to-use¬†procedurally-generated¬†environments which provide a direct measure of how quickly a reinforcement learning agent learns generalizable¬†skills.",
    "pubDate": "Tue, 03 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/procgen-benchmark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Large-scale Near-deduplication Behind BigCode",
    "description": "",
    "summary": "Large-scale Near-deduplication Behind BigCode Intended Audience People who are interested in documen...",
    "pubDate": "Tue, 16 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dedup",
    "thumbnail": "https://huggingface.co/blog/assets/dedup/thumbnail.png"
  },
  {
    "title": "Fine-tuning XLS-R for Multi-Lingual ASR with ü§ó Transformers",
    "description": "",
    "summary": "Fine-tuning XLS-R for Multi-Lingual ASR with ü§ó Transformers New (11/2021): This blog post has been u...",
    "pubDate": "Mon, 15 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-xlsr-wav2vec2",
    "thumbnail": "https://huggingface.co/blog/assets/xlsr_wav2vec2.png"
  },
  {
    "title": "OpenAI‚Äôs proposals for the U.S. AI Action Plan",
    "description": "Recommendations build on OpenAI‚Äôs Economic Blueprint to strengthen America‚Äôs AI leadership.",
    "summary": "Recommendations build on OpenAI‚Äôs Economic Blueprint to strengthen America‚Äôs AI leadership.",
    "pubDate": "Thu, 13 Mar 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-proposals-for-the-us-ai-action-plan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o1-mini",
    "description": "Advancing cost-efficient reasoning",
    "summary": "Advancing cost-efficient reasoning",
    "pubDate": "Thu, 12 Sep 2024 10:01:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-mini-advancing-cost-efficient-reasoning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Strengthening America‚Äôs AI leadership with the U.S. National Laboratories",
    "description": "OpenAI‚Äôs latest line of reasoning models will be used by nation‚Äôs leading scientists to drive scientific breakthroughs.",
    "summary": "OpenAI‚Äôs latest line of reasoning models will be used by nation‚Äôs leading scientists to drive scientific breakthroughs.",
    "pubDate": "Thu, 30 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/strengthening-americas-ai-leadership-with-the-us-national-laboratories",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "EdgeLoRA: An Efficient Multi-Tenant LLM Serving System on Edge Devices",
    "description": "arXiv:2507.01438v1 Announce Type: cross Abstract: Large Language Models (LLMs) have gained significant attention due to their versatility across a wide array of applications. Fine-tuning LLMs with parameter-efficient adapters, such as Low-Rank Adaptation (LoRA), enables these models to efficiently adapt to downstream tasks without extensive retraining. Deploying fine-tuned LLMs on multi-tenant edge devices offers substantial benefits, such as reduced latency, enhanced privacy, and personalized responses. However, serving LLMs efficiently on resource-constrained edge devices presents critical challenges, including the complexity of adapter selection for different tasks and memory overhead from frequent adapter swapping. Moreover, given the multiple requests in multi-tenant settings, processing requests sequentially results in underutilization of computational resources and increased latency. This paper introduces EdgeLoRA, an efficient system for serving LLMs on edge devices in multi-tenant environments. EdgeLoRA incorporates three key innovations: (1) an adaptive adapter selection mechanism to streamline the adapter configuration process; (2) heterogeneous memory management, leveraging intelligent adapter caching and pooling to mitigate memory operation overhead; and (3) batch LoRA inference, enabling efficient batch processing to significantly reduce computational latency. Comprehensive evaluations using the Llama3.1-8B model demonstrate that EdgeLoRA significantly outperforms the status quo (i.e., llama.cpp) in terms of both latency and throughput. The results demonstrate that EdgeLoRA can achieve up to a 4 times boost in throughput. Even more impressively, it can serve several orders of magnitude more adapters simultaneously. These results highlight EdgeLoRA's potential to transform edge deployment of LLMs in multi-tenant scenarios, offering a scalable and efficient solution for resource-constrained environments.",
    "summary": "arXiv:2507.01438v1 Announce Type: cross Abstract: Large Language Models (LLMs) have gained significant attention due to their versatility across a wide array of applications. Fine-tuning LLMs with parameter-efficient adapters, such as Low-Rank Adaptation (LoRA), enables these models to efficiently adapt to downstream tasks without extensive retraining. Deploying fine-tuned LLMs on multi-tenant edge devices offers substantial benefits, such as reduced latency, enhanced privacy, and personalized responses. However, serving LLMs efficiently on resource-constrained edge devices presents critical challenges, including the complexity of adapter selection for different tasks and memory overhead from frequent adapter swapping. Moreover, given the multiple requests in multi-tenant settings, processing requests sequentially results in underutilization of computational resources and increased latency. This paper introduces EdgeLoRA, an efficient system for serving LLMs on edge devices in multi-tenant environments. EdgeLoRA incorporates three key innovations: (1) an adaptive adapter selection mechanism to streamline the adapter configuration process; (2) heterogeneous memory management, leveraging intelligent adapter caching and pooling to mitigate memory operation overhead; and (3) batch LoRA inference, enabling efficient batch processing to significantly reduce computational latency. Comprehensive evaluations using the Llama3.1-8B model demonstrate that EdgeLoRA significantly outperforms the status quo (i.e., llama.cpp) in terms of both latency and throughput. The results demonstrate that EdgeLoRA can achieve up to a 4 times boost in throughput. Even more impressively, it can serve several orders of magnitude more adapters simultaneously. These results highlight EdgeLoRA's potential to transform edge deployment of LLMs in multi-tenant scenarios, offering a scalable and efficient solution for resource-constrained environments.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01438",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introduction to Graph Machine Learning",
    "description": "",
    "summary": "Introduction to Graph Machine Learning In this blog post, we cover the basics of graph machine learn...",
    "pubDate": "Tue, 03 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intro-graphml",
    "thumbnail": "https://huggingface.co/blog/assets/125_intro-to-graphml/thumbnail.png"
  },
  {
    "title": "Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training",
    "description": "arXiv:2507.01752v1 Announce Type: cross Abstract: Gradient-based optimization is the workhorse of deep learning, offering efficient and scalable training via backpropagation. However, its reliance on large volumes of labeled data raises privacy and security concerns such as susceptibility to data poisoning attacks and the risk of overfitting. In contrast, black box optimization methods, which treat the model as an opaque function, relying solely on function evaluations to guide optimization, offer a promising alternative in scenarios where data access is restricted, adversarial risks are high, or overfitting is a concern. However, black box methods also pose significant challenges, including poor scalability to high-dimensional parameter spaces, as prevalent in large language models (LLMs), and high computational costs due to reliance on numerous model evaluations. This paper introduces BBoxER, an evolutionary black-box method for LLM post-training that induces an information bottleneck via implicit compression of the training data. Leveraging the tractability of information flow, we provide strong theoretical bounds on generalization, differential privacy, susceptibility to data poisoning attacks, and robustness to extraction attacks. BBoxER operates on top of pre-trained LLMs, offering a lightweight and modular enhancement suitable for deployment in restricted or privacy-sensitive environments, in addition to non-vacuous generalization guarantees. In experiments with LLMs, we demonstrate empirically that Retrofitting methods are able to learn, showing how a few iterations of BBoxER improve performance and generalize well on a benchmark of reasoning datasets. This positions BBoxER as an attractive add-on on top of gradient-based optimization.",
    "summary": "arXiv:2507.01752v1 Announce Type: cross Abstract: Gradient-based optimization is the workhorse of deep learning, offering efficient and scalable training via backpropagation. However, its reliance on large volumes of labeled data raises privacy and security concerns such as susceptibility to data poisoning attacks and the risk of overfitting. In contrast, black box optimization methods, which treat the model as an opaque function, relying solely on function evaluations to guide optimization, offer a promising alternative in scenarios where data access is restricted, adversarial risks are high, or overfitting is a concern. However, black box methods also pose significant challenges, including poor scalability to high-dimensional parameter spaces, as prevalent in large language models (LLMs), and high computational costs due to reliance on numerous model evaluations. This paper introduces BBoxER, an evolutionary black-box method for LLM post-training that induces an information bottleneck via implicit compression of the training data. Leveraging the tractability of information flow, we provide strong theoretical bounds on generalization, differential privacy, susceptibility to data poisoning attacks, and robustness to extraction attacks. BBoxER operates on top of pre-trained LLMs, offering a lightweight and modular enhancement suitable for deployment in restricted or privacy-sensitive environments, in addition to non-vacuous generalization guarantees. In experiments with LLMs, we demonstrate empirically that Retrofitting methods are able to learn, showing how a few iterations of BBoxER improve performance and generalize well on a benchmark of reasoning datasets. This positions BBoxER as an attractive add-on on top of gradient-based optimization.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01752",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Advancing red teaming with people and AI",
    "description": "Advancing red teaming with people and AI",
    "summary": "Advancing red teaming with people and AI",
    "pubDate": "Thu, 21 Nov 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/advancing-red-teaming-with-people-and-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI‚Äôs comments to the NTIA on data center growth, resilience, and security",
    "description": "This comment was submitted in response to a request for information from the National Telecommunications and Information Administration (NTIA).",
    "summary": "This comment was submitted in response to a request for information from the National Telecommunications and Information Administration (NTIA).",
    "pubDate": "Mon, 04 Nov 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/comments-to-the-ntia-on-data-center-growth-resilience-and-security",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing SynthID Text",
    "description": "",
    "summary": "Introducing SynthID Text Do you find it difficult to tell if text was written by a human or generate...",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthid-text",
    "thumbnail": "https://huggingface.co/blog/assets/synthid-text/thumbnail.png"
  },
  {
    "title": "Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning",
    "description": "<p>Microsoft researchers achieved a breakthrough in the accuracy of DFT, a method for predicting the properties of molecules and materials, by using deep learning. This work can lead to better batteries, green fertilizers, precision drug discovery, and more.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/'>Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Microsoft researchers achieved a breakthrough in the accuracy of DFT, a method for predicting the properties of molecules and materials, by using deep learning. This work can lead to better batteries, green fertilizers, precision drug discovery, and more.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/'>Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Wed, 18 Jun 2025 10:01:47 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "How to train your model dynamically using adversarial data",
    "description": "",
    "summary": "How to train your model dynamically using adversarial data What you will learn here - üí°the basic ide...",
    "pubDate": "Sat, 16 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mnist-adversarial",
    "thumbnail": "https://huggingface.co/blog/assets/88_mnist_adversarial/mnist-adversarial.png"
  },
  {
    "title": "„Äê7/18ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„Äë„É≠„Éº„Ç´„É´LLM„ÅÆÂ§ßÊú¨ÂëΩ„ÄåQwen3„Äç√óÁ∂ôÁ∂ö‰∫ãÂâçÂ≠¶Áøí„ÅÆËß£Ë™¨ÔºÜ„Éá„É¢ 1250‰∏á„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÇíÁ™ÅÁ†¥„Åó„Åü‰∏ñÁïå„ÅåÊ≥®ÁõÆ„Åô„ÇãLLM",
    "description": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà18Êó•ÔºàÈáëÔºâ12ÊôÇ„Åã„ÇâLLM„Çí„ÉÜ„Éº„Éû„Å´„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ „Ç¢„É™„Éê„Éê„ÅåÈñãÁô∫„Åó„ÅüÊ≥®ÁõÆ„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„ÇπLLM„ÄåQwen3„ÄçÔºÅ OpenAI o1„ÇÑDeepSeek [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250718webinar/'>„Äê7/18ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„Äë„É≠„Éº„Ç´„É´LLM„ÅÆÂ§ßÊú¨ÂëΩ„ÄåQwen3„Äç√óÁ∂ôÁ∂ö‰∫ãÂâçÂ≠¶Áøí„ÅÆËß£Ë™¨ÔºÜ„Éá„É¢ 1250‰∏á„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÇíÁ™ÅÁ†¥„Åó„Åü‰∏ñÁïå„ÅåÊ≥®ÁõÆ„Åô„ÇãLLM</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà18Êó•ÔºàÈáëÔºâ12ÊôÇ„Åã„ÇâLLM„Çí„ÉÜ„Éº„Éû„Å´„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ „Ç¢„É™„Éê„Éê„ÅåÈñãÁô∫„Åó„ÅüÊ≥®ÁõÆ„ÅÆ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„ÇπLLM„ÄåQwen3„ÄçÔºÅ OpenAI o1„ÇÑDeepSeek [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250718webinar/'>„Äê7/18ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„Äë„É≠„Éº„Ç´„É´LLM„ÅÆÂ§ßÊú¨ÂëΩ„ÄåQwen3„Äç√óÁ∂ôÁ∂ö‰∫ãÂâçÂ≠¶Áøí„ÅÆËß£Ë™¨ÔºÜ„Éá„É¢ 1250‰∏á„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÇíÁ™ÅÁ†¥„Åó„Åü‰∏ñÁïå„ÅåÊ≥®ÁõÆ„Åô„ÇãLLM</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Wed, 02 Jul 2025 07:24:05 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/20250718webinar/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/717_1200x628_5.jpg"
  },
  {
    "title": "Introducing the Private Hub: A New Way to Build With Machine Learning",
    "description": "",
    "summary": "Introducing the Private Hub: A New Way to Build With Machine Learning June 2023 Update: The Private ...",
    "pubDate": "Wed, 03 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-private-hub",
    "thumbnail": "https://huggingface.co/blog/assets/92_introducing_private_hub/thumbnail.png"
  },
  {
    "title": "Personalizing travel at scale with OpenAI",
    "description": "By integrating its data systems with OpenAI‚Äôs LLMs, Booking.com delivers smarter search, faster support, and intent-driven travel experiences.",
    "summary": "By integrating its data systems with OpenAI‚Äôs LLMs, Booking.com delivers smarter search, faster support, and intent-driven travel experiences.",
    "pubDate": "Thu, 20 Mar 2025 23:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/booking-com",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PULSE: Practical Evaluation Scenarios for Large Multimodal Model Unlearning",
    "description": "arXiv:2507.01271v1 Announce Type: cross Abstract: In recent years, unlearning techniques, which are methods for inducing a model to 'forget' previously learned information, have attracted attention as a way to address privacy and copyright concerns in large language models (LLMs) and large multimodal models (LMMs). While several unlearning benchmarks have been established for LLMs, a practical evaluation framework for unlearning in LMMs has been less explored. Specifically, existing unlearning benchmark for LMMs considers only scenarios in which the model is required to unlearn fine-tuned knowledge through a single unlearning operation. In this study, we introduce PULSE protocol for realistic unlearning scenarios for LMMs by introducing two critical perspectives: (i) Pre-trained knowledge Unlearning for analyzing the effect across different knowledge acquisition phases and (ii) Long-term Sustainability Evaluation to address sequential requests. We then evaluate existing unlearning methods along these dimensions. Our results reveal that, although some techniques can successfully unlearn knowledge acquired through fine-tuning, they struggle to eliminate information learned during pre-training. Moreover, methods that effectively unlearn a batch of target data in a single operation exhibit substantial performance degradation when the same data are split and unlearned sequentially.",
    "summary": "arXiv:2507.01271v1 Announce Type: cross Abstract: In recent years, unlearning techniques, which are methods for inducing a model to 'forget' previously learned information, have attracted attention as a way to address privacy and copyright concerns in large language models (LLMs) and large multimodal models (LMMs). While several unlearning benchmarks have been established for LLMs, a practical evaluation framework for unlearning in LMMs has been less explored. Specifically, existing unlearning benchmark for LMMs considers only scenarios in which the model is required to unlearn fine-tuned knowledge through a single unlearning operation. In this study, we introduce PULSE protocol for realistic unlearning scenarios for LMMs by introducing two critical perspectives: (i) Pre-trained knowledge Unlearning for analyzing the effect across different knowledge acquisition phases and (ii) Long-term Sustainability Evaluation to address sequential requests. We then evaluate existing unlearning methods along these dimensions. Our results reveal that, although some techniques can successfully unlearn knowledge acquired through fine-tuning, they struggle to eliminate information learned during pre-training. Moreover, methods that effectively unlearn a batch of target data in a single operation exhibit substantial performance degradation when the same data are split and unlearned sequentially.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01271",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Benchmarking Text Generation Inference",
    "description": "",
    "summary": "Benchmarking Text Generation Inference In this blog we will be exploring Text Generation Inference‚Äôs...",
    "pubDate": "Wed, 29 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-benchmarking",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-benchmarking/tgi-benchmarking-thumbnail.png"
  },
  {
    "title": "Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset",
    "description": "",
    "summary": "From screenshots to HTML code: Introducing the WebSight dataset In the world of web development, tur...",
    "pubDate": "Fri, 15 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/websight",
    "thumbnail": "https://huggingface.co/blog/assets/websight/thumbnail.png"
  },
  {
    "title": "Special projects",
    "description": "Impactful scientific work requires working on the right problems‚Äîproblems which are not just interesting, but whose solutions matter.",
    "summary": "Impactful scientific work requires working on the right problems‚Äîproblems which are not just interesting, but whose solutions matter.",
    "pubDate": "Thu, 28 Jul 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/special-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Parquet Dedupe on Hugging Face Hub",
    "description": "",
    "summary": "Improving Parquet Dedupe on Hugging Face Hub The Xet team at Hugging Face is working on improving th...",
    "pubDate": "Sat, 05 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/improve_parquet_dedupe",
    "thumbnail": "https://huggingface.co/blog/assets/improve_parquet_dedupe/thumbnail.png"
  },
  {
    "title": "OpenAI Expands Leadership with Fidji Simo",
    "description": "Read the message Sam shared with the company earlier today.",
    "summary": "Read the message Sam shared with the company earlier today.",
    "pubDate": "Wed, 07 May 2025 21:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-expansion-with-fidji-simo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Hugging Face Embedding Container for Amazon SageMaker",
    "description": "",
    "summary": "Introducing the Hugging Face Embedding Container for Amazon SageMaker We are excited to announce tha...",
    "pubDate": "Fri, 07 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-huggingface-embedding",
    "thumbnail": "https://huggingface.co/blog/assets/sagemaker-huggingface-embedding/thumbnail.jpg"
  },
  {
    "title": "„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ7/23ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„Äå Á∑èÂãô„Éª‰∫∫‰∫ã„ÉªÁµåÁêÜWeek [ÂêçÂè§Â±ã] „Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï",
    "description": "<p>AIsmiley„ÅØ„ÄÅ2025Âπ¥7Êúà23Êó•ÔºàÊ∞¥ÔºâÔΩû7Êúà25Êó•ÔºàÈáëÔºâ„Å´„Éù„Éº„Éà„É°„ÉÉ„Çª„Å™„Åî„ÇÑ„Å´„Å¶ÈñãÂÇ¨„ÅÆ„ÄåÁ¨¨7Âõû Á∑èÂãô„Éª‰∫∫‰∫ã„ÉªÁµåÁêÜWeek [ÂêçÂè§Â±ã] „Äç„Å´„Éñ„Éº„Çπ„ÇíÂá∫Â±ï„Åó„Åæ„Åô„ÄÇ ‰ºöÂ†¥„Åß„ÅØ„ÄÅÊúÄÊñ∞„ÅÆAI„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥„ÇÑ„Éã„É•„Éº„ÇπÁ≠â„ÇíÈõÜ„ÇÅ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/nagoya-office-expo-no7/'>„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ7/23ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„Äå Á∑èÂãô„Éª‰∫∫‰∫ã„ÉªÁµåÁêÜWeek [ÂêçÂè§Â±ã] „Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AIsmiley„ÅØ„ÄÅ2025Âπ¥7Êúà23Êó•ÔºàÊ∞¥ÔºâÔΩû7Êúà25Êó•ÔºàÈáëÔºâ„Å´„Éù„Éº„Éà„É°„ÉÉ„Çª„Å™„Åî„ÇÑ„Å´„Å¶ÈñãÂÇ¨„ÅÆ„ÄåÁ¨¨7Âõû Á∑èÂãô„Éª‰∫∫‰∫ã„ÉªÁµåÁêÜWeek [ÂêçÂè§Â±ã] „Äç„Å´„Éñ„Éº„Çπ„ÇíÂá∫Â±ï„Åó„Åæ„Åô„ÄÇ ‰ºöÂ†¥„Åß„ÅØ„ÄÅÊúÄÊñ∞„ÅÆAI„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥„ÇÑ„Éã„É•„Éº„ÇπÁ≠â„ÇíÈõÜ„ÇÅ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/nagoya-office-expo-no7/'>„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ7/23ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„Äå Á∑èÂãô„Éª‰∫∫‰∫ã„ÉªÁµåÁêÜWeek [ÂêçÂè§Â±ã] „Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Thu, 03 Jul 2025 01:00:19 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/nagoya-office-expo-no7/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/05/office-expo-spring-2025-nagoya.png"
  },
  {
    "title": "Training and Finetuning Reranker Models with Sentence Transformers v4",
    "description": "",
    "summary": "Training and Finetuning Reranker Models with Sentence Transformers v4 Sentence Transformers is a Pyt...",
    "pubDate": "Wed, 26 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-reranker",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "The MIT-Portugal Program enters Phase 4",
    "description": "New phase will support continued exploration of ideas and solutions in fields ranging from AI to nanotech to climate ‚Äî with emphasis on educational exchanges and entrepreneurship.",
    "summary": "New phase will support continued exploration of ideas and solutions in fields ranging from AI to nanotech to climate ‚Äî with emphasis on educational exchanges and entrepreneurship.",
    "pubDate": "Wed, 30 Apr 2025 16:20:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-portugal-program-enters-phase-4-0430",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-portugal-2024-Conference.jpg"
  },
  {
    "title": "OpenAI Board Forms Safety and Security Committee",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 28 May 2024 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-board-forms-safety-and-security-committee",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "XetHub is joining Hugging Face!",
    "description": "",
    "summary": "XetHub is joining Hugging Face! We are super excited to officially announce that Hugging Face acquir...",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xethub-joins-hf",
    "thumbnail": "https://huggingface.co/blog/assets/xethub-joins-hf/thumbnail.png"
  },
  {
    "title": "Introducing W√ºrstchen: Fast Diffusion for Image Generation",
    "description": "",
    "summary": "Introducing W√ºrstchen: Fast Diffusion for Image Generation What is W√ºrstchen? W√ºrstchen is a diffusi...",
    "pubDate": "Wed, 13 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/wuerstchen",
    "thumbnail": "https://huggingface.co/blog/assets/wuerstchen/thumbnail.jpg"
  },
  {
    "title": "With AI, researchers predict the location of virtually any protein within a human cell",
    "description": "Trained with a joint understanding of protein and cell behavior, the model could help with diagnosing disease and developing new drugs.",
    "summary": "Trained with a joint understanding of protein and cell behavior, the model could help with diagnosing disease and developing new drugs.",
    "pubDate": "Thu, 15 May 2025 10:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/researchers-predict-protein-location-within-human-cell-using-ai-0515",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-ProteinLocalization-01-press.jpg"
  },
  {
    "title": "Rewriting SymCrypt in Rust to modernize Microsoft‚Äôs cryptographic library",
    "description": "<p>We're rewriting parts of Microsoft's SymCrypt cryptographic library in Rust to improve memory safety and defend against side-channel attacks, enabling formal verification while maintaining backward compatibility via a Rust-to-C compiler.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/'>Rewriting SymCrypt in Rust to modernize Microsoft‚Äôs cryptographic library¬†</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>We're rewriting parts of Microsoft's SymCrypt cryptographic library in Rust to improve memory safety and defend against side-channel attacks, enabling formal verification while maintaining backward compatibility via a Rust-to-C compiler.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/'>Rewriting SymCrypt in Rust to modernize Microsoft‚Äôs cryptographic library¬†</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Tue, 10 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Rationale engineering generates a compact new tool for gene therapy",
    "description": "Researchers redesign a compact RNA-guided enzyme from bacteria, making it an efficient editor of human DNA.",
    "summary": "Researchers redesign a compact RNA-guided enzyme from bacteria, making it an efficient editor of human DNA.",
    "pubDate": "Wed, 28 May 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/rationale-engineering-generates-compact-new-tool-gene-therapy-0528",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/phylogenetic-tree.jpg"
  },
  {
    "title": "Introducing the Hugging Face LLM Inference Container for Amazon SageMaker",
    "description": "",
    "summary": "Introducing the Hugging Face LLM Inference Container for Amazon SageMaker This is an example on how ...",
    "pubDate": "Wed, 31 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-huggingface-llm",
    "thumbnail": "https://huggingface.co/blog/assets/145_sagemaker-huggingface-llm/thumbnail.jpg"
  },
  {
    "title": "Exploring Classical Piano Performance Generation with Expressive Music Variational AutoEncoder",
    "description": "arXiv:2507.01582v1 Announce Type: cross Abstract: The creativity of classical music arises not only from composers who craft the musical sheets but also from performers who interpret the static notations with expressive nuances. This paper addresses the challenge of generating classical piano performances from scratch, aiming to emulate the dual roles of composer and pianist in the creative process. We introduce the Expressive Compound Word (ECP) representation, which effectively captures both the metrical structure and expressive nuances of classical performances. Building on this, we propose the Expressive Music Variational AutoEncoder (XMVAE), a model featuring two branches: a Vector Quantized Variational AutoEncoder (VQ-VAE) branch that generates score-related content, representing the Composer, and a vanilla VAE branch that produces expressive details, fulfilling the role of Pianist. These branches are jointly trained with similar Seq2Seq architectures, leveraging a multiscale encoder to capture beat-level contextual information and an orthogonal Transformer decoder for efficient compound tokens decoding. Both objective and subjective evaluations demonstrate that XMVAE generates classical performances with superior musical quality compared to state-of-the-art models. Furthermore, pretraining the Composer branch on extra musical score datasets contribute to a significant performance gain.",
    "summary": "arXiv:2507.01582v1 Announce Type: cross Abstract: The creativity of classical music arises not only from composers who craft the musical sheets but also from performers who interpret the static notations with expressive nuances. This paper addresses the challenge of generating classical piano performances from scratch, aiming to emulate the dual roles of composer and pianist in the creative process. We introduce the Expressive Compound Word (ECP) representation, which effectively captures both the metrical structure and expressive nuances of classical performances. Building on this, we propose the Expressive Music Variational AutoEncoder (XMVAE), a model featuring two branches: a Vector Quantized Variational AutoEncoder (VQ-VAE) branch that generates score-related content, representing the Composer, and a vanilla VAE branch that produces expressive details, fulfilling the role of Pianist. These branches are jointly trained with similar Seq2Seq architectures, leveraging a multiscale encoder to capture beat-level contextual information and an orthogonal Transformer decoder for efficient compound tokens decoding. Both objective and subjective evaluations demonstrate that XMVAE generates classical performances with superior musical quality compared to state-of-the-art models. Furthermore, pretraining the Composer branch on extra musical score datasets contribute to a significant performance gain.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01582",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate",
    "description": "",
    "summary": "Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate This article shows how to get an incre...",
    "pubDate": "Fri, 16 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-inference-pytorch-scripts",
    "thumbnail": "https://huggingface.co/blog/assets/bloom-inference-pytorch-scripts/thumbnail.png"
  },
  {
    "title": "The Hugging Face Hub for Galleries, Libraries, Archives and Museums",
    "description": "",
    "summary": "The Hugging Face Hub for Galleries, Libraries, Archives and Museums The Hugging Face Hub for Galleri...",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hf-hub-glam-guide",
    "thumbnail": "https://huggingface.co/blog/assets/144_hf_hub_glam_guide/thumbnail.png"
  },
  {
    "title": "Announcing New Dataset Search Features",
    "description": "",
    "summary": "Announcing New Dataset Search Features The AI and ML community has shared more than 180,000 public d...",
    "pubDate": "Mon, 08 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/datasets-filters",
    "thumbnail": "https://huggingface.co/blog/assets/datasets-filters/thumbnail.png"
  },
  {
    "title": "Try new data visualizations and graphs for finance queries in AI Mode.",
    "description": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-600x600.format-webp.webp' />Today, we‚Äôre starting to roll out interactive chart visualizations in AI Mode in Labs to help bring financial data to life for questions on stocks and mutual funds.Now, ‚Ä¶",
    "summary": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-600x600.format-webp.webp' />Today, we‚Äôre starting to roll out interactive chart visualizations in AI Mode in Labs to help bring financial data to life for questions on stocks and mutual funds.Now, ‚Ä¶",
    "pubDate": "Thu, 05 Jun 2025 19:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/ai-mode-data-visualization/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-1440x810.png"
  },
  {
    "title": "AudioLDM 2, but faster ‚ö°Ô∏è",
    "description": "",
    "summary": "AudioLDM 2, but faster ‚ö°Ô∏è AudioLDM 2 was proposed in AudioLDM 2: Learning Holistic Audio Generation ...",
    "pubDate": "Wed, 30 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/audioldm2",
    "thumbnail": "https://huggingface.co/blog/assets/161_audioldm2/thumbnail.png"
  },
  {
    "title": "MTEB: Massive Text Embedding Benchmark",
    "description": "",
    "summary": "MTEB: Massive Text Embedding Benchmark MTEB is a massive benchmark for measuring the performance of ...",
    "pubDate": "Wed, 19 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mteb",
    "thumbnail": "https://huggingface.co/blog/assets/110_mteb/thumbnail.png"
  },
  {
    "title": "What's new in Diffusers? üé®",
    "description": "",
    "summary": "What's new in Diffusers? üé® A month and a half ago we released diffusers , a library that provides a ...",
    "pubDate": "Mon, 12 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-2nd-month",
    "thumbnail": "https://huggingface.co/blog/assets/102_diffusers_2nd_month/inpainting.png"
  },
  {
    "title": "Agent Ideate: A Framework for Product Idea Generation from Patents Using Agentic AI",
    "description": "arXiv:2507.01717v1 Announce Type: new Abstract: Patents contain rich technical knowledge that can inspire innovative product ideas, yet accessing and interpreting this information remains a challenge. This work explores the use of Large Language Models (LLMs) and autonomous agents to mine and generate product concepts from a given patent. In this work, we design Agent Ideate, a framework for automatically generating product-based business ideas from patents. We experimented with open-source LLMs and agent-based architectures across three domains: Computer Science, Natural Language Processing, and Material Chemistry. Evaluation results show that the agentic approach consistently outperformed standalone LLMs in terms of idea quality, relevance, and novelty. These findings suggest that combining LLMs with agentic workflows can significantly enhance the innovation pipeline by unlocking the untapped potential of business idea generation from patent data.",
    "summary": "arXiv:2507.01717v1 Announce Type: new Abstract: Patents contain rich technical knowledge that can inspire innovative product ideas, yet accessing and interpreting this information remains a challenge. This work explores the use of Large Language Models (LLMs) and autonomous agents to mine and generate product concepts from a given patent. In this work, we design Agent Ideate, a framework for automatically generating product-based business ideas from patents. We experimented with open-source LLMs and agent-based architectures across three domains: Computer Science, Natural Language Processing, and Material Chemistry. Evaluation results show that the agentic approach consistently outperformed standalone LLMs in terms of idea quality, relevance, and novelty. These findings suggest that combining LLMs with agentic workflows can significantly enhance the innovation pipeline by unlocking the untapped potential of business idea generation from patent data.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01717",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Proximal Policy Optimization",
    "description": "We‚Äôre releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune. PPO has become the default reinforcement learning algorithm at OpenAI because of its ease of use and good performance.",
    "summary": "We‚Äôre releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune. PPO has become the default reinforcement learning algorithm at OpenAI because of its ease of use and good performance.",
    "pubDate": "Thu, 20 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-ppo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome spaCy to the ü§ó Hub",
    "description": "",
    "summary": "Welcome spaCy to the Hugging Face Hub spaCy is a popular library for advanced Natural Language Proce...",
    "pubDate": "Tue, 13 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spacy",
    "thumbnail": "https://huggingface.co/blog/assets/23_spacy/thumbnail.png"
  },
  {
    "title": "Introducing RWKV ‚Äî An RNN with the advantages of a transformer",
    "description": "",
    "summary": "Introducing RWKV - An RNN with the advantages of a transformer ChatGPT and chatbot-powered applicati...",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rwkv",
    "thumbnail": "https://huggingface.co/blog/assets/142_rwkv/rwkv_thumbnail.png"
  },
  {
    "title": "Data Classification with Dynamically Growing and Shrinking Neural Networks",
    "description": "arXiv:2507.01043v1 Announce Type: cross Abstract: The issue of data-driven neural network model construction is one of the core problems in the domain of Artificial Intelligence. A standard approach assumes a fixed architecture with trainable weights. A conceptually more advanced assumption is that we not only train the weights, but also find out the optimal model architecture. We present a new method that realizes just that. This article is an extended version of our conference paper titled 'Dynamic Growing and Shrinking of Neural Networks with Monte Carlo Tree Search [26]'. In the paper, we show in detail how to create a neural network with a procedure that allows dynamic shrinking and growing of the model while it is being trained. The decision-making mechanism for the architectural design is governed by a Monte Carlo tree search procedure which simulates network behavior and allows to compare several candidate architecture changes to choose the best one. The proposed method was validated using both visual and time series datasets, demonstrating its particular effectiveness in multivariate time series classification. This is attributed to the architecture's ability to adapt dynamically, allowing independent modifications for each time series. The approach is supplemented by Python source code for reproducibility. Experimental evaluations in visual pattern and multivariate time series classification tasks revealed highly promising performance, underscoring the method's robustness and adaptability.",
    "summary": "arXiv:2507.01043v1 Announce Type: cross Abstract: The issue of data-driven neural network model construction is one of the core problems in the domain of Artificial Intelligence. A standard approach assumes a fixed architecture with trainable weights. A conceptually more advanced assumption is that we not only train the weights, but also find out the optimal model architecture. We present a new method that realizes just that. This article is an extended version of our conference paper titled 'Dynamic Growing and Shrinking of Neural Networks with Monte Carlo Tree Search [26]'. In the paper, we show in detail how to create a neural network with a procedure that allows dynamic shrinking and growing of the model while it is being trained. The decision-making mechanism for the architectural design is governed by a Monte Carlo tree search procedure which simulates network behavior and allows to compare several candidate architecture changes to choose the best one. The proposed method was validated using both visual and time series datasets, demonstrating its particular effectiveness in multivariate time series classification. This is attributed to the architecture's ability to adapt dynamically, allowing independent modifications for each time series. The approach is supplemented by Python source code for reproducibility. Experimental evaluations in visual pattern and multivariate time series classification tasks revealed highly promising performance, underscoring the method's robustness and adaptability.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01043",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Variational lossy autoencoder",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 08 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variational-lossy-autoencoder",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning complex goals with iterated amplification",
    "description": "We‚Äôre proposing an AI safety technique called iterated amplification that lets us specify complicated behaviors and goals that are beyond human scale, by demonstrating how to decompose a task into simpler sub-tasks, rather than by providing labeled data or a reward function. Although this idea is in its very early stages and we have only completed experiments on simple toy algorithmic domains, we‚Äôve decided to present it in its preliminary state because we think it could prove to be a scalable approach to AI¬†safety.",
    "summary": "We‚Äôre proposing an AI safety technique called iterated amplification that lets us specify complicated behaviors and goals that are beyond human scale, by demonstrating how to decompose a task into simpler sub-tasks, rather than by providing labeled data or a reward function. Although this idea is in its very early stages and we have only completed experiments on simple toy algorithmic domains, we‚Äôve decided to present it in its preliminary state because we think it could prove to be a scalable approach to AI¬†safety.",
    "pubDate": "Mon, 22 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-complex-goals-with-iterated-amplification",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Detecting misbehavior in frontier reasoning models",
    "description": "Frontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM to monitor their chains-of-thought. Penalizing their ‚Äúbad thoughts‚Äù doesn‚Äôt stop the majority of misbehavior‚Äîit makes them hide their intent.",
    "summary": "Frontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM to monitor their chains-of-thought. Penalizing their ‚Äúbad thoughts‚Äù doesn‚Äôt stop the majority of misbehavior‚Äîit makes them hide their intent.",
    "pubDate": "Mon, 10 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chain-of-thought-monitoring",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Community Tools on HuggingChat",
    "description": "",
    "summary": "Introducing Community Tools on HuggingChat Today we‚Äôre releasing our latest feature on HuggingChat: ...",
    "pubDate": "Mon, 16 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-tools",
    "thumbnail": "https://huggingface.co/blog/assets/community-tools/thumbnail.png"
  },
  {
    "title": "We‚Äôre expanding our Gemini 2.5 family of models",
    "description": "Gemini 2.5 Flash and Pro are now generally available, and we‚Äôre introducing 2.5 Flash-Lite, our most cost-efficient and fastest 2.5 model yet.",
    "summary": "Gemini 2.5 Flash and Pro are now generally available, and we‚Äôre introducing 2.5 Flash-Lite, our most cost-efficient and fastest 2.5 model yet.",
    "pubDate": "Tue, 17 Jun 2025 16:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/were-expanding-our-gemini-25-family-of-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_bundle_keyword_social-share_1920-1080.width-1300.png"
  },
  {
    "title": "Introducing Prodigy-HF: a direct integration with Hugging Face",
    "description": "",
    "summary": "Introducing Prodigy-HF Prodigy is an annotation tool made by Explosion, a company well known as the ...",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/prodigy-hf",
    "thumbnail": "https://huggingface.co/blog/assets/171_prodigy_hf/thumbnail.png"
  },
  {
    "title": "Learning from other domains to advance AI evaluation and testing",
    "description": "<p>As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the [&#8230;]</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/'>Learning from other domains to advance AI evaluation and testing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the [&#8230;]</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/'>Learning from other domains to advance AI evaluation and testing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 16:35:06 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "OpenAI o1 System Card External Testers Acknowledgements",
    "description": "OpenAI o1 system card external testers acknowledgements",
    "summary": "OpenAI o1 system card external testers acknowledgements",
    "pubDate": "Thu, 12 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-system-card/external-testers-acknowledgements",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bringing the Artificial Analysis LLM Performance Leaderboard to Hugging Face",
    "description": "",
    "summary": "Bringing the Artificial Analysis LLM Performance Leaderboard to Hugging Face Building applications w...",
    "pubDate": "Fri, 03 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-artificial-analysis",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_artificialanalysis.png"
  },
  {
    "title": "Introducing the SWE-Lancer benchmark",
    "description": "Can frontier LLMs earn $1 million from real-world freelance software engineering?",
    "summary": "Can frontier LLMs earn $1 million from real-world freelance software engineering?",
    "pubDate": "Tue, 18 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/swe-lancer",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling up learning across many different robot types",
    "description": "Robots are great specialists, but poor generalists. Typically, you have to train a model for each task, robot, and environment. Changing a single variable often requires starting from scratch. But what if we could combine the knowledge across robotics and create a way to train a general-purpose robot?",
    "summary": "Robots are great specialists, but poor generalists. Typically, you have to train a model for each task, robot, and environment. Changing a single variable often requires starting from scratch. But what if we could combine the knowledge across robotics and create a way to train a general-purpose robot?",
    "pubDate": "Tue, 03 Oct 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/scaling-up-learning-across-many-different-robot-types/",
    "thumbnail": "https://lh3.googleusercontent.com/KiNtKw6sX-3WmNln5pnEZjPMfM7VJLg0qe4VshEj_H_oXCI9hb6iGWl1DPx79WBb4EVds8mq2wUq_n9s2Lk8kkWazPtootwAUYBKxBEp64WTcEmXa6U=w1200-h630-n-nu"
  },
  {
    "title": "üá®üáø BenCzechMark - Can your LLM Understand Czech?",
    "description": "",
    "summary": "üá®üáø BenCzechMark - Can your LLM Understand Czech? The üá®üáø BenCzechMark is the first and most comprehen...",
    "pubDate": "Tue, 01 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/benczechmark",
    "thumbnail": "https://huggingface.co/blog/assets/187_benczechmark/thumbnail.png"
  },
  {
    "title": "OpenAI‚Äôs response to the Department of Energy on AI infrastructure",
    "description": "Why infrastructure is destiny and how the US can seize it.",
    "summary": "Why infrastructure is destiny and how the US can seize it.",
    "pubDate": "Wed, 07 May 2025 18:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-department-of-energy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Getting Started with Transformers on Habana Gaudi",
    "description": "",
    "summary": "Getting Started with Transformers on Habana Gaudi A couple of weeks ago, we've had the pleasure to a...",
    "pubDate": "Tue, 26 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/getting-started-habana",
    "thumbnail": "https://huggingface.co/blog/assets/61_getting_started_habana/habana01.png"
  },
  {
    "title": "Solving complex problems with OpenAI o1 models",
    "description": "In this video, we share how the o1 reasoning models can help in domains like coding, strategy, and research.",
    "summary": "In this video, we share how the o1 reasoning models can help in domains like coding, strategy, and research.",
    "pubDate": "Thu, 17 Oct 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/solving-complex-problems-with-openai-o1-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding the capabilities, limitations, and societal impact of large language models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 04 Feb 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/understanding-the-capabilities-limitations-and-societal-impact-of-large-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interpretable and pedagogical examples",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 02 Nov 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/interpretable-and-pedagogical-examples",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Launching the Artificial Analysis Text to Image Leaderboard & Arena",
    "description": "",
    "summary": "Launching the Artificial Analysis Text to Image Leaderboard & Arena In two short years since the adv...",
    "pubDate": "Thu, 06 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-artificial-analysis2",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_artificialanalysis.png"
  },
  {
    "title": "Blazingly fast whisper transcriptions with Inference Endpoints",
    "description": "",
    "summary": "Blazingly fast whisper transcriptions with Inference Endpoints Today we are happy to introduce a new...",
    "pubDate": "Tue, 13 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-whisper-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/fast-whisper-endpoints/thumbnail.png"
  },
  {
    "title": "Optimizing your LLM in production",
    "description": "",
    "summary": "Optimizing your LLM in production Note: This blog post is also available as a documentation page on ...",
    "pubDate": "Fri, 15 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimize-llm",
    "thumbnail": "https://huggingface.co/blog/assets/163_optimize_llm/optimize_llm.png"
  },
  {
    "title": "YouTube: Enhancing the user experience",
    "description": "It‚Äôs all about using our technology and research to help enrich people‚Äôs lives. Like YouTube ‚Äî and its mission to give everyone a voice and show them the world.",
    "summary": "It‚Äôs all about using our technology and research to help enrich people‚Äôs lives. Like YouTube ‚Äî and its mission to give everyone a voice and show them the world.",
    "pubDate": "Fri, 16 Jun 2023 14:55:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/youtube-enhancing-the-user-experience/",
    "thumbnail": "https://lh3.googleusercontent.com/RAMu-2QAkfHieGDWkYFQOMiATW-wFi6jMLyC-YJ4f6Jj1H5BlhxQBmfQrb4RS6Sc6DFLFJqBahK3_1--XjoFPdGqYsCdSuTNr-pTcLkRO5SqvReblIQ=w1200-h630-n-nu"
  },
  {
    "title": "Ethics and Society Newsletter #1",
    "description": "",
    "summary": "Ethics and Society Newsletter #1 Hello, world! Originating as an open-source company, Hugging Face w...",
    "pubDate": "Thu, 22 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-1",
    "thumbnail": "https://huggingface.co/blog/assets/103_ethics-soc-1/thumbnail.png"
  },
  {
    "title": "Instruction-tuning Stable Diffusion with InstructPix2Pix",
    "description": "",
    "summary": "Instruction-tuning Stable Diffusion with InstructPix2Pix This post explores instruction-tuning to te...",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/instruction-tuning-sd",
    "thumbnail": "https://huggingface.co/blog/instruction-tuning-sd/assets/instruction_tuning_sd/thumbnail.png"
  },
  {
    "title": "GPT-2: 6-month follow-up",
    "description": "We‚Äôre releasing the 774 million parameter GPT-2 language model after the release of our small¬†124M model¬†in February, staged release of our medium¬†355M model¬†in May, and subsequent research with partners and the AI community into the model‚Äôs potential for misuse and societal benefit. We‚Äôre also releasing an open-source legal agreement to make it easier for organizations to initiate model-sharing partnerships with each other, and are publishing a technical report about our experience in coordinating with the wider AI research community on publication¬†norms.",
    "summary": "We‚Äôre releasing the 774 million parameter GPT-2 language model after the release of our small¬†124M model¬†in February, staged release of our medium¬†355M model¬†in May, and subsequent research with partners and the AI community into the model‚Äôs potential for misuse and societal benefit. We‚Äôre also releasing an open-source legal agreement to make it easier for organizations to initiate model-sharing partnerships with each other, and are publishing a technical report about our experience in coordinating with the wider AI research community on publication¬†norms.",
    "pubDate": "Tue, 20 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-2-6-month-follow-up",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Solving Rubik‚Äôs Cube with a robot hand",
    "description": "We‚Äôve trained a pair of neural networks to solve the Rubik‚Äôs Cube with a human-like robot hand. The neural networks are trained entirely in simulation, using the same reinforcement learning code as¬†OpenAI Five¬†paired with a new technique called Automatic Domain Randomization (ADR). The system can handle situations it never saw during training, such as being prodded by a¬†stuffed giraffe. This shows that reinforcement learning isn‚Äôt just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.",
    "summary": "We‚Äôve trained a pair of neural networks to solve the Rubik‚Äôs Cube with a human-like robot hand. The neural networks are trained entirely in simulation, using the same reinforcement learning code as¬†OpenAI Five¬†paired with a new technique called Automatic Domain Randomization (ADR). The system can handle situations it never saw during training, such as being prodded by a¬†stuffed giraffe. This shows that reinforcement learning isn‚Äôt just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.",
    "pubDate": "Tue, 15 Oct 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/solving-rubiks-cube",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A failed experiment: Infini-Attention, and why we should keep trying?",
    "description": "",
    "summary": "A failed experiment: Infini-Attention, and why we should keep trying? TLDR: Infini-attention's perfo...",
    "pubDate": "Wed, 14 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/infini-attention",
    "thumbnail": "https://huggingface.co/blog/infini-attention/assets/185_infini_attention/infini_attention_thumbnail.png"
  },
  {
    "title": "Announcing the ü§ó AI Research Residency Program",
    "description": "",
    "summary": "Announcing the ü§ó AI Research Residency Program üéâ üéâ üéâ The ü§ó Research Residency Program is a 9-month o...",
    "pubDate": "Tue, 22 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-residency",
    "thumbnail": "https://huggingface.co/blog/assets/57_ai_residency/residency-thumbnail.jpg"
  },
  {
    "title": "The Reformer - Pushing the limits of language modeling",
    "description": "",
    "summary": "The Reformer - Pushing the limits of language modeling How the Reformer uses less than 8GB of RAM to...",
    "pubDate": "Fri, 03 Jul 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/reformer",
    "thumbnail": "https://huggingface.co/blog/assets/03_reformer/thumbnail.png"
  },
  {
    "title": "Image Similarity with Hugging Face Datasets and Transformers",
    "description": "",
    "summary": "Image Similarity with Hugging Face Datasets and Transformers In this post, you'll learn to build an ...",
    "pubDate": "Mon, 16 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-similarity",
    "thumbnail": "https://huggingface.co/blog/assets/image_similarity/thumbnail.png"
  },
  {
    "title": "A Student‚Äôs Guide to Writing with ChatGPT",
    "description": "A Student‚Äôs Guide to Writing with ChatGPT",
    "summary": "A Student‚Äôs Guide to Writing with ChatGPT",
    "pubDate": "Wed, 13 Nov 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/chatgpt/use-cases/student-writing-guide",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Verdi, an AI dev platform powered by GPT-4o",
    "description": "Mercado Libre introduces Verdi, an AI developer platform powered by GPT-4o",
    "summary": "Mercado Libre introduces Verdi, an AI developer platform powered by GPT-4o",
    "pubDate": "Tue, 24 Sep 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mercado-libre",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Animator Lyndon Barrois creates new worlds with Sora",
    "description": "Filmmaker Lyndon Barrois describes how to use Sora as a storytelling tool.",
    "summary": "Filmmaker Lyndon Barrois describes how to use Sora as a storytelling tool.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-lyndon-barrois",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Image search with ü§ó datasets",
    "description": "",
    "summary": "Image search with ü§ó datasets ü§ó datasets is a library that makes it easy to access and share datasets...",
    "pubDate": "Wed, 16 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-search-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/54_image_search_datasets/spaces_image_search.jpg"
  },
  {
    "title": "Stargate Infrastructure",
    "description": "OpenAI, and our strategic partners, are thrilled about our shared vision for the Infrastructure of AGI. We are energized by the challenges we face and are excited by the prospect of partnering with firms across the industrial base to deliver against our ambitious mission. Specifically, we want to connect with firms across the built data center infrastructure landscape, from power and land to construction to equipment, and everything in between.",
    "summary": "OpenAI, and our strategic partners, are thrilled about our shared vision for the Infrastructure of AGI. We are energized by the challenges we face and are excited by the prospect of partnering with firms across the industrial base to deliver against our ambitious mission. Specifically, we want to connect with firms across the built data center infrastructure landscape, from power and land to construction to equipment, and everything in between.",
    "pubDate": "Tue, 21 Jan 2025 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/form/stargate-infrastructure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Third-person imitation learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 06 Mar 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/third-person-imitation-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Gradio's new Dataframe!",
    "description": "",
    "summary": "Introducing Gradio's new Dataframe! Gradio‚Äôs gr.Dataframe component is one of our most popular compo...",
    "pubDate": "Mon, 24 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-dataframe-upgrade",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-dataframe-upgrade/thumbnail.png"
  },
  {
    "title": "AsyncFlow: An Asynchronous Streaming RL Framework for Efficient LLM Post-Training",
    "description": "arXiv:2507.01663v1 Announce Type: cross Abstract: Reinforcement learning (RL) has become a pivotal technology in the post-training phase of large language models (LLMs). Traditional task-colocated RL frameworks suffer from significant scalability bottlenecks, while task-separated RL frameworks face challenges in complex dataflows and the corresponding resource idling and workload imbalance. Moreover, most existing frameworks are tightly coupled with LLM training or inference engines, making it difficult to support custom-designed engines. To address these challenges, we propose AsyncFlow, an asynchronous streaming RL framework for efficient post-training. Specifically, we introduce a distributed data storage and transfer module that provides a unified data management and fine-grained scheduling capability in a fully streamed manner. This architecture inherently facilitates automated pipeline overlapping among RL tasks and dynamic load balancing. Moreover, we propose a producer-consumer-based asynchronous workflow engineered to minimize computational idleness by strategically deferring parameter update process within staleness thresholds. Finally, the core capability of AsynFlow is architecturally decoupled from underlying training and inference engines and encapsulated by service-oriented user interfaces, offering a modular and customizable user experience. Extensive experiments demonstrate an average of 1.59 throughput improvement compared with state-of-the-art baseline. The presented architecture in this work provides actionable insights for next-generation RL training system designs.",
    "summary": "arXiv:2507.01663v1 Announce Type: cross Abstract: Reinforcement learning (RL) has become a pivotal technology in the post-training phase of large language models (LLMs). Traditional task-colocated RL frameworks suffer from significant scalability bottlenecks, while task-separated RL frameworks face challenges in complex dataflows and the corresponding resource idling and workload imbalance. Moreover, most existing frameworks are tightly coupled with LLM training or inference engines, making it difficult to support custom-designed engines. To address these challenges, we propose AsyncFlow, an asynchronous streaming RL framework for efficient post-training. Specifically, we introduce a distributed data storage and transfer module that provides a unified data management and fine-grained scheduling capability in a fully streamed manner. This architecture inherently facilitates automated pipeline overlapping among RL tasks and dynamic load balancing. Moreover, we propose a producer-consumer-based asynchronous workflow engineered to minimize computational idleness by strategically deferring parameter update process within staleness thresholds. Finally, the core capability of AsynFlow is architecturally decoupled from underlying training and inference engines and encapsulated by service-oriented user interfaces, offering a modular and customizable user experience. Extensive experiments demonstrate an average of 1.59 throughput improvement compared with state-of-the-art baseline. The presented architecture in this work provides actionable insights for next-generation RL training system designs.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01663",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Exploring Advanced LLM Multi-Agent Systems Based on Blackboard Architecture",
    "description": "arXiv:2507.01701v1 Announce Type: cross Abstract: In this paper, we propose to incorporate the blackboard architecture into LLM multi-agent systems (MASs) so that (1) agents with various roles can share all the information and others' messages during the whole problem-solving process, (2) agents that will take actions are selected based on the current content of the blackboard, and (3) the selection and execution round is repeated until a consensus is reached on the blackboard. We develop the first implementation of this proposal and conduct experiments on commonsense knowledge, reasoning and mathematical datasets. The results show that our system can be competitive with the SOTA static and dynamic MASs by achieving the best average performance, and at the same time manage to spend less tokens. Our proposal has the potential to enable complex and dynamic problem-solving where well-defined structures or workflows are unavailable.",
    "summary": "arXiv:2507.01701v1 Announce Type: cross Abstract: In this paper, we propose to incorporate the blackboard architecture into LLM multi-agent systems (MASs) so that (1) agents with various roles can share all the information and others' messages during the whole problem-solving process, (2) agents that will take actions are selected based on the current content of the blackboard, and (3) the selection and execution round is repeated until a consensus is reached on the blackboard. We develop the first implementation of this proposal and conduct experiments on commonsense knowledge, reasoning and mathematical datasets. The results show that our system can be competitive with the SOTA static and dynamic MASs by achieving the best average performance, and at the same time manage to spend less tokens. Our proposal has the potential to enable complex and dynamic problem-solving where well-defined structures or workflows are unavailable.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01701",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Computer-Using Agent",
    "description": "A universal interface for AI to interact with the digital world.",
    "summary": "A universal interface for AI to interact with the digital world.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/computer-using-agent",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our Transformers Code Agent beats the GAIA benchmark!",
    "description": "",
    "summary": "Our Transformers Code Agent beats the GAIA benchmark! TL;DR After some experiments, we were impresse...",
    "pubDate": "Mon, 01 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/beating-gaia",
    "thumbnail": "https://huggingface.co/blog/assets/beating-gaia/thumbnail.jpeg"
  },
  {
    "title": "Introducing canvas, a new way to write and code with ChatGPT.",
    "description": "Introducing canvas",
    "summary": "Introducing canvas",
    "pubDate": "Thu, 03 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-canvas",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community",
    "description": "",
    "summary": "From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community The Elixir community is ...",
    "pubDate": "Fri, 09 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/elixir-bumblebee",
    "thumbnail": "https://huggingface.co/blog/assets/120_elixir-bumblebee/thumbnail.png"
  },
  {
    "title": "OpenAI acquires Rockset",
    "description": "OpenAI Acquires Rockset",
    "summary": "OpenAI Acquires Rockset",
    "pubDate": "Fri, 21 Jun 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-acquires-rockset",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Teaching models to express their uncertainty in words",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 28 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teaching-models-to-express-their-uncertainty-in-words",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Falcon 2: An 11B parameter pretrained language model and VLM, trained on over 5000B tokens tokens and 11 languages",
    "description": "",
    "summary": "Falcon 2: An 11B parameter pretrained language model and VLM, trained on over 5000B tokens and 11 la...",
    "pubDate": "Fri, 24 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon2-11b",
    "thumbnail": "https://huggingface.co/blog/assets/179_falcon2-11b/thumbnail.jpg"
  },
  {
    "title": "Conversational LLMs Simplify Secure Clinical Data Access, Understanding, and Analysis",
    "description": "arXiv:2507.01053v1 Announce Type: cross Abstract: As ever-larger clinical datasets become available, they have the potential to unlock unprecedented opportunities for medical research. Foremost among them is Medical Information Mart for Intensive Care (MIMIC-IV), the world's largest open-source EHR database. However, the inherent complexity of these datasets, particularly the need for sophisticated querying skills and the need to understand the underlying clinical settings, often presents a significant barrier to their effective use. M3 lowers the technical barrier to understanding and querying MIMIC-IV data. With a single command it retrieves MIMIC-IV from PhysioNet, launches a local SQLite instance (or hooks into the hosted BigQuery), and-via the Model Context Protocol (MCP)-lets researchers converse with the database in plain English. Ask a clinical question in natural language; M3 uses a language model to translate it into SQL, executes the query against the MIMIC-IV dataset, and returns structured results alongside the underlying query for verifiability and reproducibility. Demonstrations show that minutes of dialogue with M3 yield the kind of nuanced cohort analyses that once demanded hours of handcrafted SQL and relied on understanding the complexities of clinical workflows. By simplifying access, M3 invites the broader research community to mine clinical critical-care data and accelerates the translation of raw records into actionable insight.",
    "summary": "arXiv:2507.01053v1 Announce Type: cross Abstract: As ever-larger clinical datasets become available, they have the potential to unlock unprecedented opportunities for medical research. Foremost among them is Medical Information Mart for Intensive Care (MIMIC-IV), the world's largest open-source EHR database. However, the inherent complexity of these datasets, particularly the need for sophisticated querying skills and the need to understand the underlying clinical settings, often presents a significant barrier to their effective use. M3 lowers the technical barrier to understanding and querying MIMIC-IV data. With a single command it retrieves MIMIC-IV from PhysioNet, launches a local SQLite instance (or hooks into the hosted BigQuery), and-via the Model Context Protocol (MCP)-lets researchers converse with the database in plain English. Ask a clinical question in natural language; M3 uses a language model to translate it into SQL, executes the query against the MIMIC-IV dataset, and returns structured results alongside the underlying query for verifiability and reproducibility. Demonstrations show that minutes of dialogue with M3 yield the kind of nuanced cohort analyses that once demanded hours of handcrafted SQL and relied on understanding the complexities of clinical workflows. By simplifying access, M3 invites the broader research community to mine clinical critical-care data and accelerates the translation of raw records into actionable insight.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01053",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Frontier Safety Framework",
    "description": "Our approach to analyzing and mitigating future risks posed by advanced AI models",
    "summary": "Our approach to analyzing and mitigating future risks posed by advanced AI models",
    "pubDate": "Fri, 17 May 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/",
    "thumbnail": "https://lh3.googleusercontent.com/_NVnftxEp6r9O9gnZT2_jLPpIn_nGjYp9xgl8hFhg_-fX131_koFcj6znzflexf4-MdfkSTtA060-Hh7RcvVkNkY5kQ-QBulRYDCO1Li1R1jK71G=w1200-h630-n-nu"
  },
  {
    "title": "Prompt Mechanisms in Medical Imaging: A Comprehensive Survey",
    "description": "arXiv:2507.01055v1 Announce Type: cross Abstract: Deep learning offers transformative potential in medical imaging, yet its clinical adoption is frequently hampered by challenges such as data scarcity, distribution shifts, and the need for robust task generalization. Prompt-based methodologies have emerged as a pivotal strategy to guide deep learning models, providing flexible, domain-specific adaptations that significantly enhance model performance and adaptability without extensive retraining. This systematic review critically examines the burgeoning landscape of prompt engineering in medical imaging. We dissect diverse prompt modalities, including textual instructions, visual prompts, and learnable embeddings, and analyze their integration for core tasks such as image generation, segmentation, and classification. Our synthesis reveals how these mechanisms improve task-specific outcomes by enhancing accuracy, robustness, and data efficiency and reducing reliance on manual feature engineering while fostering greater model interpretability by making the model's guidance explicit. Despite substantial advancements, we identify persistent challenges, particularly in prompt design optimization, data heterogeneity, and ensuring scalability for clinical deployment. Finally, this review outlines promising future trajectories, including advanced multimodal prompting and robust clinical integration, underscoring the critical role of prompt-driven AI in accelerating the revolution of diagnostics and personalized treatment planning in medicine.",
    "summary": "arXiv:2507.01055v1 Announce Type: cross Abstract: Deep learning offers transformative potential in medical imaging, yet its clinical adoption is frequently hampered by challenges such as data scarcity, distribution shifts, and the need for robust task generalization. Prompt-based methodologies have emerged as a pivotal strategy to guide deep learning models, providing flexible, domain-specific adaptations that significantly enhance model performance and adaptability without extensive retraining. This systematic review critically examines the burgeoning landscape of prompt engineering in medical imaging. We dissect diverse prompt modalities, including textual instructions, visual prompts, and learnable embeddings, and analyze their integration for core tasks such as image generation, segmentation, and classification. Our synthesis reveals how these mechanisms improve task-specific outcomes by enhancing accuracy, robustness, and data efficiency and reducing reliance on manual feature engineering while fostering greater model interpretability by making the model's guidance explicit. Despite substantial advancements, we identify persistent challenges, particularly in prompt design optimization, data heterogeneity, and ensuring scalability for clinical deployment. Finally, this review outlines promising future trajectories, including advanced multimodal prompting and robust clinical integration, underscoring the critical role of prompt-driven AI in accelerating the revolution of diagnostics and personalized treatment planning in medicine.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01055",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing 4o Image Generation",
    "description": "At OpenAI, we have long believed image generation should be a primary capability of our language models. That‚Äôs why we‚Äôve built our most advanced image generator yet into GPT‚Äë4o. The result‚Äîimage generation that is not only beautiful, but useful.",
    "summary": "At OpenAI, we have long believed image generation should be a primary capability of our language models. That‚Äôs why we‚Äôve built our most advanced image generator yet into GPT‚Äë4o. The result‚Äîimage generation that is not only beautiful, but useful.",
    "pubDate": "Tue, 25 Mar 2025 11:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-4o-image-generation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Towards Cardiac MRI Foundation Models: Comprehensive Visual-Tabular Representations for Whole-Heart Assessment and Beyond",
    "description": "arXiv:2504.13037v3 Announce Type: replace-cross Abstract: Cardiac magnetic resonance imaging is the gold standard for non-invasive cardiac assessment, offering rich spatio-temporal views of the cardiac anatomy and physiology. Patient-level health factors, such as demographics, metabolic, and lifestyle, are known to substantially influence cardiovascular health and disease risk, yet remain uncaptured by CMR alone. To holistically understand cardiac health and to enable the best possible interpretation of an individual's disease risk, CMR and patient-level factors must be jointly exploited within an integrated framework. Recent multi-modal approaches have begun to bridge this gap, yet they often rely on limited spatio-temporal data and focus on isolated clinical tasks, thereby hindering the development of a comprehensive representation for cardiac health evaluation. To overcome these limitations, we introduce ViTa, a step toward foundation models that delivers a comprehensive representation of the heart and a precise interpretation of individual disease risk. Leveraging data from 42,000 UK Biobank participants, ViTa integrates 3D+T cine stacks from short-axis and long-axis views, enabling a complete capture of the cardiac cycle. These imaging data are then fused with detailed tabular patient-level factors, enabling context-aware insights. This multi-modal paradigm supports a wide spectrum of downstream tasks, including cardiac phenotype and physiological feature prediction, segmentation, and classification of cardiac and metabolic diseases within a single unified framework. By learning a shared latent representation that bridges rich imaging features and patient context, ViTa moves beyond traditional, task-specific models toward a universal, patient-specific understanding of cardiac health, highlighting its potential to advance clinical utility and scalability in cardiac analysis.",
    "summary": "arXiv:2504.13037v3 Announce Type: replace-cross Abstract: Cardiac magnetic resonance imaging is the gold standard for non-invasive cardiac assessment, offering rich spatio-temporal views of the cardiac anatomy and physiology. Patient-level health factors, such as demographics, metabolic, and lifestyle, are known to substantially influence cardiovascular health and disease risk, yet remain uncaptured by CMR alone. To holistically understand cardiac health and to enable the best possible interpretation of an individual's disease risk, CMR and patient-level factors must be jointly exploited within an integrated framework. Recent multi-modal approaches have begun to bridge this gap, yet they often rely on limited spatio-temporal data and focus on isolated clinical tasks, thereby hindering the development of a comprehensive representation for cardiac health evaluation. To overcome these limitations, we introduce ViTa, a step toward foundation models that delivers a comprehensive representation of the heart and a precise interpretation of individual disease risk. Leveraging data from 42,000 UK Biobank participants, ViTa integrates 3D+T cine stacks from short-axis and long-axis views, enabling a complete capture of the cardiac cycle. These imaging data are then fused with detailed tabular patient-level factors, enabling context-aware insights. This multi-modal paradigm supports a wide spectrum of downstream tasks, including cardiac phenotype and physiological feature prediction, segmentation, and classification of cardiac and metabolic diseases within a single unified framework. By learning a shared latent representation that bridges rich imaging features and patient context, ViTa moves beyond traditional, task-specific models toward a universal, patient-specific understanding of cardiac health, highlighting its potential to advance clinical utility and scalability in cardiac analysis.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.13037",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI Meets Maritime Training: Precision Analytics for Enhanced Safety and Performance",
    "description": "arXiv:2507.01274v1 Announce Type: cross Abstract: Traditional simulator-based training for maritime professionals is critical for ensuring safety at sea but often depends on subjective trainer assessments of technical skills, behavioral focus, communication, and body language, posing challenges such as subjectivity, difficulty in measuring key features, and cognitive limitations. Addressing these issues, this study develops an AI-driven framework to enhance maritime training by objectively assessing trainee performance through visual focus tracking, speech recognition, and stress detection, improving readiness for high-risk scenarios. The system integrates AI techniques, including visual focus determination using eye tracking, pupil dilation analysis, and computer vision; communication analysis through a maritime-specific speech-to-text model and natural language processing; communication correctness using large language models; and mental stress detection via vocal pitch. Models were evaluated on data from simulated maritime scenarios with seafarers exposed to controlled high-stress events. The AI algorithms achieved high accuracy, with ~92% for visual detection, ~91% for maritime speech recognition, and ~90% for stress detection, surpassing existing benchmarks. The system provides insights into visual attention, adherence to communication checklists, and stress levels under demanding conditions. This study demonstrates how AI can transform maritime training by delivering objective performance analytics, enabling personalized feedback, and improving preparedness for real-world operational challenges.",
    "summary": "arXiv:2507.01274v1 Announce Type: cross Abstract: Traditional simulator-based training for maritime professionals is critical for ensuring safety at sea but often depends on subjective trainer assessments of technical skills, behavioral focus, communication, and body language, posing challenges such as subjectivity, difficulty in measuring key features, and cognitive limitations. Addressing these issues, this study develops an AI-driven framework to enhance maritime training by objectively assessing trainee performance through visual focus tracking, speech recognition, and stress detection, improving readiness for high-risk scenarios. The system integrates AI techniques, including visual focus determination using eye tracking, pupil dilation analysis, and computer vision; communication analysis through a maritime-specific speech-to-text model and natural language processing; communication correctness using large language models; and mental stress detection via vocal pitch. Models were evaluated on data from simulated maritime scenarios with seafarers exposed to controlled high-stress events. The AI algorithms achieved high accuracy, with ~92% for visual detection, ~91% for maritime speech recognition, and ~90% for stress detection, surpassing existing benchmarks. The system provides insights into visual attention, adherence to communication checklists, and stress levels under demanding conditions. This study demonstrates how AI can transform maritime training by delivering objective performance analytics, enabling personalized feedback, and improving preparedness for real-world operational challenges.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01274",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Scaling Up Liquid-Resistance Liquid-Capacitance Networks for Efficient Sequence Modeling",
    "description": "arXiv:2505.21717v3 Announce Type: replace-cross Abstract: We present LrcSSM, a $textit{nonlinear}$ recurrent model that processes long sequences as fast as today's linear state-space layers. By forcing the state-transition matrix to be diagonal and learned at every step, the full sequence can be solved in parallel with a single prefix-scan, giving $mathcal{O}(TD)$ time and memory and only $mathcal{O}(log T)$ sequential depth, for input-sequence length $T$ and a state dimension $D$. Moreover, LrcSSM offers a formal gradient-stability guarantee that other input-varying systems such as Liquid-S4 and Mamba do not provide. Lastly, for network depth $L$, as the forward and backward passes cost $Theta(T,D,L)$ FLOPs, with its low sequential depth and parameter count $Theta(D,L)$, the model follows the compute-optimal scaling law regime ($beta approx 0.42$) recently observed for Mamba, outperforming quadratic-attention Transformers at equal compute while avoiding the memory overhead of FFT-based long convolutions. We show that on a series of long-range forecasting tasks, LrcSSM outperforms LRU, S5 and Mamba.",
    "summary": "arXiv:2505.21717v3 Announce Type: replace-cross Abstract: We present LrcSSM, a $textit{nonlinear}$ recurrent model that processes long sequences as fast as today's linear state-space layers. By forcing the state-transition matrix to be diagonal and learned at every step, the full sequence can be solved in parallel with a single prefix-scan, giving $mathcal{O}(TD)$ time and memory and only $mathcal{O}(log T)$ sequential depth, for input-sequence length $T$ and a state dimension $D$. Moreover, LrcSSM offers a formal gradient-stability guarantee that other input-varying systems such as Liquid-S4 and Mamba do not provide. Lastly, for network depth $L$, as the forward and backward passes cost $Theta(T,D,L)$ FLOPs, with its low sequential depth and parameter count $Theta(D,L)$, the model follows the compute-optimal scaling law regime ($beta approx 0.42$) recently observed for Mamba, outperforming quadratic-attention Transformers at equal compute while avoiding the memory overhead of FFT-based long convolutions. We show that on a series of long-range forecasting tasks, LrcSSM outperforms LRU, S5 and Mamba.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.21717",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Can Large Language Models Develop Strategic Reasoning? Post-training Insights from Learning Chess",
    "description": "arXiv:2507.00726v2 Announce Type: replace Abstract: While reinforcement learning (RL) for large language models (LLMs) has shown promise in mathematical reasoning, strategic reasoning for LLMs using RL remains largely unexplored. We investigate whether LLMs can develop strategic reasoning capabilities through RL in chess. To this end, we leverage a chess-pretrained action-value network to provide dense reward on the LLM's output move quality, which can be seen as a form of knowledge distillation. Our experiments show that our distillation-based dense rewards often outperform sparse binary rewards. However, surprisingly, all models plateau far below expert levels. We provide SFT and RL ablations on chess reasoning training and find evidence that this limitation stems from a deficit in the pretrained models' internal understanding of chess--a deficit which RL alone may not be able to fully overcome.",
    "summary": "arXiv:2507.00726v2 Announce Type: replace Abstract: While reinforcement learning (RL) for large language models (LLMs) has shown promise in mathematical reasoning, strategic reasoning for LLMs using RL remains largely unexplored. We investigate whether LLMs can develop strategic reasoning capabilities through RL in chess. To this end, we leverage a chess-pretrained action-value network to provide dense reward on the LLM's output move quality, which can be seen as a form of knowledge distillation. Our experiments show that our distillation-based dense rewards often outperform sparse binary rewards. However, surprisingly, all models plateau far below expert levels. We provide SFT and RL ablations on chess reasoning training and find evidence that this limitation stems from a deficit in the pretrained models' internal understanding of chess--a deficit which RL alone may not be able to fully overcome.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.00726",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How Sempre Health is leveraging the Expert Acceleration Program to accelerate their ML roadmap",
    "description": "",
    "summary": "How Sempre Health is leveraging the Expert Acceleration Program to accelerate their ML roadmap üëã Hel...",
    "pubDate": "Thu, 19 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sempre-health-eap-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/70_sempre_health/thumbnail.jpg"
  },
  {
    "title": "DALL¬∑E 2 research preview update",
    "description": "Early users have created over 3 million images to date and helped us improve our safety processes. We‚Äôre excited to begin adding up to 1,000 new users from our waitlist each week.",
    "summary": "Early users have created over 3 million images to date and helped us improve our safety processes. We‚Äôre excited to begin adding up to 1,000 new users from our waitlist each week.",
    "pubDate": "Wed, 18 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI‚Äôs approach to AI and national security",
    "description": "OpenAI‚Äôs approach to AI and national security",
    "summary": "OpenAI‚Äôs approach to AI and national security",
    "pubDate": "Thu, 24 Oct 2024 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-approach-to-ai-and-national-security",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Fellows Fall 2018: Final projects",
    "description": "Our second class of OpenAI Fellows has wrapped up, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship. We are currently reviewing applications on a rolling basis for our next round of OpenAI Fellows Summer 2019.",
    "summary": "Our second class of OpenAI Fellows has wrapped up, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship. We are currently reviewing applications on a rolling basis for our next round of OpenAI Fellows Summer 2019.",
    "pubDate": "Fri, 17 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows-fall-2018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ryght‚Äôs Journey to Empower Healthcare and Life Sciences with Expert Support from Hugging Face",
    "description": "",
    "summary": "Ryght‚Äôs Journey to Empower Healthcare and Life Sciences with Expert Support from Hugging Face This i...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ryght-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/ryght-case-study/thumbnail.png"
  },
  {
    "title": "Welcome Llama 4 Maverick & Scout on Hugging Face!",
    "description": "",
    "summary": "Welcome Llama 4 Maverick & Scout on Hugging Face We are incredibly excited to welcome the next gener...",
    "pubDate": "Sat, 05 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama4-release",
    "thumbnail": "https://huggingface.co/blog/assets/llama_4.png"
  },
  {
    "title": "Blending Supervised and Reinforcement Fine-Tuning with Prefix Sampling",
    "description": "arXiv:2507.01679v1 Announce Type: cross Abstract: Existing post-training techniques for large language models are broadly categorized into Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT). Each paradigm presents a distinct trade-off: SFT excels at mimicking demonstration data but can lead to problematic generalization as a form of behavior cloning. Conversely, RFT can significantly enhance a model's performance but is prone to learn unexpected behaviors, and its performance is highly sensitive to the initial policy. In this paper, we propose a unified view of these methods and introduce Prefix-RFT, a hybrid approach that synergizes learning from both demonstration and exploration. Using mathematical reasoning problems as a testbed, we empirically demonstrate that Prefix-RFT is both simple and effective. It not only surpasses the performance of standalone SFT and RFT but also outperforms parallel mixed-policy RFT methods. A key advantage is its seamless integration into existing open-source frameworks, requiring only minimal modifications to the standard RFT pipeline. Our analysis highlights the complementary nature of SFT and RFT, and validates that Prefix-RFT effectively harmonizes these two learning paradigms. Furthermore, ablation studies confirm the method's robustness to variations in the quality and quantity of demonstration data. We hope this work offers a new perspective on LLM post-training, suggesting that a unified paradigm that judiciously integrates demonstration and exploration could be a promising direction for future research.",
    "summary": "arXiv:2507.01679v1 Announce Type: cross Abstract: Existing post-training techniques for large language models are broadly categorized into Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT). Each paradigm presents a distinct trade-off: SFT excels at mimicking demonstration data but can lead to problematic generalization as a form of behavior cloning. Conversely, RFT can significantly enhance a model's performance but is prone to learn unexpected behaviors, and its performance is highly sensitive to the initial policy. In this paper, we propose a unified view of these methods and introduce Prefix-RFT, a hybrid approach that synergizes learning from both demonstration and exploration. Using mathematical reasoning problems as a testbed, we empirically demonstrate that Prefix-RFT is both simple and effective. It not only surpasses the performance of standalone SFT and RFT but also outperforms parallel mixed-policy RFT methods. A key advantage is its seamless integration into existing open-source frameworks, requiring only minimal modifications to the standard RFT pipeline. Our analysis highlights the complementary nature of SFT and RFT, and validates that Prefix-RFT effectively harmonizes these two learning paradigms. Furthermore, ablation studies confirm the method's robustness to variations in the quality and quantity of demonstration data. We hope this work offers a new perspective on LLM post-training, suggesting that a unified paradigm that judiciously integrates demonstration and exploration could be a promising direction for future research.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01679",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI safety needs social scientists",
    "description": "We‚Äôve written a paper arguing that long-term AI safety research needs social scientists to ensure AI alignment algorithms succeed when actual humans are involved. Properly aligning advanced AI systems with human values requires resolving many uncertainties related to the psychology of human rationality, emotion, and biases. The aim of this paper is to spark further collaboration between machine learning and social science researchers, and we plan to¬†hire¬†social scientists to work on this full time at¬†OpenAI.",
    "summary": "We‚Äôve written a paper arguing that long-term AI safety research needs social scientists to ensure AI alignment algorithms succeed when actual humans are involved. Properly aligning advanced AI systems with human values requires resolving many uncertainties related to the psychology of human rationality, emotion, and biases. The aim of this paper is to spark further collaboration between machine learning and social science researchers, and we plan to¬†hire¬†social scientists to work on this full time at¬†OpenAI.",
    "pubDate": "Tue, 19 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-safety-needs-social-scientists",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaDev discovers faster sorting algorithms",
    "description": "New algorithms will transform the foundations of computing",
    "summary": "New algorithms will transform the foundations of computing",
    "pubDate": "Wed, 07 Jun 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphadev-discovers-faster-sorting-algorithms/",
    "thumbnail": "https://lh3.googleusercontent.com/kYAs9KTHdhYZE0BeKMKlphVqU3eQS8oXP_GNrrWBjFbl8r4YFv2FWlRbe6x9L4Q_L-eKZeE7E__GtKVJTLXvW_zGTTzplSJCplN02n_8cz7No815L5M=w1200-h630-n-nu"
  },
  {
    "title": "AI powers Expedia‚Äôs marketing evolution",
    "description": "A conversation with Jochen Koedijk, Chief Marketing Officer of Expedia Group.",
    "summary": "A conversation with Jochen Koedijk, Chief Marketing Officer of Expedia Group.",
    "pubDate": "Wed, 14 May 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expedia-jochen-koedijk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Teaching with AI",
    "description": "We‚Äôre releasing a guide for teachers using ChatGPT in their classroom‚Äîincluding suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.",
    "summary": "We‚Äôre releasing a guide for teachers using ChatGPT in their classroom‚Äîincluding suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.",
    "pubDate": "Thu, 31 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teaching-with-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Promega‚Äôs top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "description": "Promega's top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "summary": "Promega's top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "pubDate": "Thu, 31 Oct 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/promega",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pushing the frontiers of audio generation",
    "description": "Our pioneering speech generation technologies are helping people around the world interact with more natural, conversational and intuitive digital assistants and AI tools.",
    "summary": "Our pioneering speech generation technologies are helping people around the world interact with more natural, conversational and intuitive digital assistants and AI tools.",
    "pubDate": "Wed, 30 Oct 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/pushing-the-frontiers-of-audio-generation/",
    "thumbnail": "https://lh3.googleusercontent.com/wyFc1lo4ByOJsbbSt1NEwBiSi3KpImyqA9ukx-mLxJROIakSxhPwk-kPtlIfFKX9Txm2J_lbpIvnrDhFnegrpN8ihlvYpBTsFNAmOlq0C2rm_gef=w1200-h630-n-nu"
  },
  {
    "title": "AI in Australia‚ÄîOpenAI‚Äôs Economic Blueprint",
    "description": "Today, OpenAI, in partnership with Mandala Partners, is sharing the OpenAI AI Economic Blueprint for Australia. At a time when boosting productivity has emerged as a national priority for Australia, the Blueprint provides a clear, actionable plan for how Australia can unlock the full economic and social potential of artificial intelligence.",
    "summary": "Today, OpenAI, in partnership with Mandala Partners, is sharing the OpenAI AI Economic Blueprint for Australia. At a time when boosting productivity has emerged as a national priority for Australia, the Blueprint provides a clear, actionable plan for how Australia can unlock the full economic and social potential of artificial intelligence.",
    "pubDate": "Mon, 30 Jun 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-australia-economic-blueprint",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Cybersecurity Grant Program",
    "description": "Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants and other support.",
    "summary": "Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants and other support.",
    "pubDate": "Thu, 01 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-cybersecurity-grant-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëAI„Ç®„É≥„Ç∏„Éã„Ç¢ÂøÖË¶ãÔºÅÁã¨Ëá™LLMÈñãÁô∫ÁßòË©±„Å®DevinÊ¥ªÁî®„ÅÆ„Çπ„Çπ„É° ÔΩûLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅGPU„ÅÆ„Ç≥„Çπ„ÉàÂâäÊ∏õ„Åæ„ÅßËß£Ë™¨„Åó„Åæ„ÅôÔΩû",
    "description": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà16Êó•ÔºàÊ∞¥Ôºâ12ÊôÇ„Åã„ÇâLLMÈñãÁô∫„Å´Èñ¢„Åô„Çã„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ Êú¨„Ç¶„Çß„Éì„Éä„Éº„Åß„ÅØ„ÄÅAI„Ç®„É≥„Ç∏„Éã„Ç¢/AIÈñãÁô∫ÈÉ®ÈñÄ„ÅÆÊñπÂêë„Åë„Å´Áã¨Ëá™LLM„ÅÆÈñãÁô∫ÁßòË©±„ÇÑDevin„ÅÆÊ¥ªÁî®‰∫ã [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250716webinar/'>„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëAI„Ç®„É≥„Ç∏„Éã„Ç¢ÂøÖË¶ãÔºÅÁã¨Ëá™LLMÈñãÁô∫ÁßòË©±„Å®DevinÊ¥ªÁî®„ÅÆ„Çπ„Çπ„É° ÔΩûLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅGPU„ÅÆ„Ç≥„Çπ„ÉàÂâäÊ∏õ„Åæ„ÅßËß£Ë™¨„Åó„Åæ„ÅôÔΩû</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà16Êó•ÔºàÊ∞¥Ôºâ12ÊôÇ„Åã„ÇâLLMÈñãÁô∫„Å´Èñ¢„Åô„Çã„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ Êú¨„Ç¶„Çß„Éì„Éä„Éº„Åß„ÅØ„ÄÅAI„Ç®„É≥„Ç∏„Éã„Ç¢/AIÈñãÁô∫ÈÉ®ÈñÄ„ÅÆÊñπÂêë„Åë„Å´Áã¨Ëá™LLM„ÅÆÈñãÁô∫ÁßòË©±„ÇÑDevin„ÅÆÊ¥ªÁî®‰∫ã [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250716webinar/'>„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëAI„Ç®„É≥„Ç∏„Éã„Ç¢ÂøÖË¶ãÔºÅÁã¨Ëá™LLMÈñãÁô∫ÁßòË©±„Å®DevinÊ¥ªÁî®„ÅÆ„Çπ„Çπ„É° ÔΩûLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅGPU„ÅÆ„Ç≥„Çπ„ÉàÂâäÊ∏õ„Åæ„ÅßËß£Ë™¨„Åó„Åæ„ÅôÔΩû</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Fri, 27 Jun 2025 02:00:37 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/20250716webinar/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/700_1200x628.jpg"
  },
  {
    "title": "Improving health literacy and patient well-being",
    "description": "Lifespan uses GPT-4 to radically improve health literacy and patient outcomes.",
    "summary": "Lifespan uses GPT-4 to radically improve health literacy and patient outcomes.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lifespan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reducing health insurance costs and improving care",
    "description": "Oscar brings AI to health insurance, reducing costs and improving patient care.",
    "summary": "Oscar brings AI to health insurance, reducing costs and improving patient care.",
    "pubDate": "Mon, 01 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/oscar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Student Ambassador Program's call for applications is open!",
    "description": "",
    "summary": "Student Ambassador Program‚Äôs call for applications is open! As an open-source company democratizing ...",
    "pubDate": "Fri, 13 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ambassadors",
    "thumbnail": "https://huggingface.co/blog/assets/67_ambassadors/thumbnail.png"
  },
  {
    "title": "Moving AI governance forward",
    "description": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
    "summary": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
    "pubDate": "Fri, 21 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/moving-ai-governance-forward",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 1",
    "description": "",
    "summary": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 1 About a year ago, we showed you...",
    "pubDate": "Mon, 02 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-sapphire-rapids",
    "thumbnail": "https://huggingface.co/blog/assets/124_intel_sapphire_rapids/02.png"
  },
  {
    "title": "Hugging Face partners with Wiz Research to Improve AI Security",
    "description": "",
    "summary": "Hugging Face partners with Wiz Research to Improve AI Security We are pleased to announce that we ar...",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-wiz-security-blog",
    "thumbnail": "https://huggingface.co/blog/assets/wiz_security/security.png"
  },
  {
    "title": "Introducing Agents.js: Give tools to your LLMs using JavaScript",
    "description": "",
    "summary": "Introducing Agents.js: Give tools to your LLMs using JavaScript We have recently been working on Age...",
    "pubDate": "Mon, 24 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/agents-js",
    "thumbnail": "https://huggingface.co/blog/assets/agents-js/thumbnail.png"
  },
  {
    "title": "Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models",
    "description": "arXiv:2410.23114v3 Announce Type: replace-cross Abstract: Despite the outstanding performance in vision-language reasoning, Large Vision-Language Models (LVLMs) might generate hallucinated contents that do not exist in the given image. Most existing LVLM hallucination benchmarks are constrained to evaluate the object-related hallucinations. However, the potential hallucination on the relations between two objects, i.e., relation hallucination, still lacks investigation. To remedy that, we design a unified framework to measure the object and relation hallucination in LVLMs simultaneously. The core idea of our framework is to evaluate hallucinations via (object, relation, object) triplets extracted from LVLMs' responses, making it easily generalizable to different vision-language tasks. Based on our framework, we further introduce Tri-HE, a novel Triplet-level Hallucination Evaluation benchmark which can be used to study both object and relation hallucination at the same time. With comprehensive evaluations on Tri-HE, we observe that the relation hallucination issue is even more serious than object hallucination among existing LVLMs, highlighting a previously neglected problem towards reliable LVLMs. Moreover, based on our findings, we design a simple training-free approach that effectively mitigates hallucinations for LVLMs. Our dataset and code for the reproduction of our experiments are available publicly at https://github.com/wujunjie1998/Tri-HE.",
    "summary": "arXiv:2410.23114v3 Announce Type: replace-cross Abstract: Despite the outstanding performance in vision-language reasoning, Large Vision-Language Models (LVLMs) might generate hallucinated contents that do not exist in the given image. Most existing LVLM hallucination benchmarks are constrained to evaluate the object-related hallucinations. However, the potential hallucination on the relations between two objects, i.e., relation hallucination, still lacks investigation. To remedy that, we design a unified framework to measure the object and relation hallucination in LVLMs simultaneously. The core idea of our framework is to evaluate hallucinations via (object, relation, object) triplets extracted from LVLMs' responses, making it easily generalizable to different vision-language tasks. Based on our framework, we further introduce Tri-HE, a novel Triplet-level Hallucination Evaluation benchmark which can be used to study both object and relation hallucination at the same time. With comprehensive evaluations on Tri-HE, we observe that the relation hallucination issue is even more serious than object hallucination among existing LVLMs, highlighting a previously neglected problem towards reliable LVLMs. Moreover, based on our findings, we design a simple training-free approach that effectively mitigates hallucinations for LVLMs. Our dataset and code for the reproduction of our experiments are available publicly at https://github.com/wujunjie1998/Tri-HE.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.23114",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Simplifying contract reviews with AI",
    "description": "Ironclad uses GPT-4 to simplify the contract review process.",
    "summary": "Ironclad uses GPT-4 to simplify the contract review process.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ironclad",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing multi-backends (TRT-LLM, vLLM) support for Text Generation Inference",
    "description": "",
    "summary": "Introducing multi-backends (TRT-LLM, vLLM) support for Text Generation Inference Introduction Since ...",
    "pubDate": "Thu, 16 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-multi-backend",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-multi-backend/thumbnail.png"
  },
  {
    "title": "GPT-4",
    "description": "We‚Äôve created GPT-4, the latest milestone in OpenAI‚Äôs effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.",
    "summary": "We‚Äôve created GPT-4, the latest milestone in OpenAI‚Äôs effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Point-E: A system for generating 3D point clouds from complex prompts",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 16 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/point-e",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Solving math word problems",
    "description": "We‚Äôve trained¬†a system that solves grade school math problems with nearly twice the accuracy of a fine-tuned GPT-3 model. It solves about 90% as many problems as real kids: a small sample of 9-12 year olds scored 60% on a test from our dataset, while our system scored 55% on those same problems.",
    "summary": "We‚Äôve trained¬†a system that solves grade school math problems with nearly twice the accuracy of a fine-tuned GPT-3 model. It solves about 90% as many problems as real kids: a small sample of 9-12 year olds scored 60% on a test from our dataset, while our system scored 55% on those same problems.",
    "pubDate": "Fri, 29 Oct 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/solving-math-word-problems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Simple considerations for simple people building fancy neural networks",
    "description": "",
    "summary": "üöß Simple considerations for simple people building fancy neural networks Photo by Henry & Co. on Uns...",
    "pubDate": "Thu, 25 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/simple-considerations",
    "thumbnail": "https://huggingface.co/blog/assets/13_simple-considerations/henry-co-3coKbdfnAFg-unsplash.jpg"
  },
  {
    "title": "Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments",
    "description": "arXiv:2506.13205v4 Announce Type: replace-cross Abstract: With the growing integration of vision-language models (VLMs), mobile agents are now widely used for tasks like UI automation and camera-based user assistance. These agents are often fine-tuned on limited user-generated datasets, leaving them vulnerable to covert threats during the training process. In this work we present GHOST, the first clean-label backdoor attack specifically designed for mobile agents built upon VLMs. Our method manipulates only the visual inputs of a portion of the training samples - without altering their corresponding labels or instructions - thereby injecting malicious behaviors into the model. Once fine-tuned with this tampered data, the agent will exhibit attacker-controlled responses when a specific visual trigger is introduced at inference time. The core of our approach lies in aligning the gradients of poisoned samples with those of a chosen target instance, embedding backdoor-relevant features into the poisoned training data. To maintain stealth and enhance robustness, we develop three realistic visual triggers: static visual patches, dynamic motion cues, and subtle low-opacity overlays. We evaluate our method across six real-world Android apps and three VLM architectures adapted for mobile use. Results show that our attack achieves high attack success rates (up to 94.67 percent) while maintaining high clean-task performance (FSR up to 95.85 percent). Additionally, ablation studies shed light on how various design choices affect the efficacy and concealment of the attack. Overall, this work is the first to expose critical security flaws in VLM-based mobile agents, highlighting their susceptibility to clean-label backdoor attacks and the urgent need for effective defense mechanisms in their training pipelines.",
    "summary": "arXiv:2506.13205v4 Announce Type: replace-cross Abstract: With the growing integration of vision-language models (VLMs), mobile agents are now widely used for tasks like UI automation and camera-based user assistance. These agents are often fine-tuned on limited user-generated datasets, leaving them vulnerable to covert threats during the training process. In this work we present GHOST, the first clean-label backdoor attack specifically designed for mobile agents built upon VLMs. Our method manipulates only the visual inputs of a portion of the training samples - without altering their corresponding labels or instructions - thereby injecting malicious behaviors into the model. Once fine-tuned with this tampered data, the agent will exhibit attacker-controlled responses when a specific visual trigger is introduced at inference time. The core of our approach lies in aligning the gradients of poisoned samples with those of a chosen target instance, embedding backdoor-relevant features into the poisoned training data. To maintain stealth and enhance robustness, we develop three realistic visual triggers: static visual patches, dynamic motion cues, and subtle low-opacity overlays. We evaluate our method across six real-world Android apps and three VLM architectures adapted for mobile use. Results show that our attack achieves high attack success rates (up to 94.67 percent) while maintaining high clean-task performance (FSR up to 95.85 percent). Additionally, ablation studies shed light on how various design choices affect the efficacy and concealment of the attack. Overall, this work is the first to expose critical security flaws in VLM-based mobile agents, highlighting their susceptibility to clean-label backdoor attacks and the urgent need for effective defense mechanisms in their training pipelines.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.13205",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "5 things from I/O to try right now",
    "description": "Collage on a dark background showing AI-generated media including humpback whales jumping from the water and the very detailed face of a chameleon",
    "summary": "Collage on a dark background showing AI-generated media including humpback whales jumping from the water and the very detailed face of a chameleon",
    "pubDate": "Thu, 12 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/io-2025-tools-to-try-globally/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5_I_O_tools_ss.width-1300.png"
  },
  {
    "title": "Can foundation models label data like humans?",
    "description": "",
    "summary": "Can foundation models label data like humans? Since the advent of ChatGPT, we have seen unprecedente...",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-rlhf",
    "thumbnail": "https://huggingface.co/blog/assets/llm-leaderboard/leaderboard-thumbnail.png"
  },
  {
    "title": "Accelerate your models with ü§ó Optimum Intel and OpenVINO",
    "description": "",
    "summary": "Accelerate your models with ü§ó Optimum Intel and OpenVINO Last July, we announced that Intel and Hugg...",
    "pubDate": "Wed, 02 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/openvino",
    "thumbnail": "https://huggingface.co/blog/assets/113_openvino/thumbnail.png"
  },
  {
    "title": "Introducing BERTopic Integration with Hugging Face Hub",
    "description": "",
    "summary": "Introducing BERTopic Integration with the Hugging Face Hub We are thrilled to announce a significant...",
    "pubDate": "Wed, 31 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bertopic",
    "thumbnail": "https://huggingface.co/blog/assets/145_bertopic/logo.png"
  },
  {
    "title": "Director of Machine Learning Insights [Part 4]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 4] If you're interested in building ML solutions faster ...",
    "pubDate": "Wed, 23 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-4",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/part4.png"
  },
  {
    "title": "How to train a new language model from scratch using Transformers and Tokenizers",
    "description": "",
    "summary": "How to train a new language model from scratch using Transformers and Tokenizers Over the past few m...",
    "pubDate": "Fri, 14 Feb 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-train",
    "thumbnail": "https://huggingface.co/blog/assets/01_how-to-train/how-to-train_blogpost.png"
  },
  {
    "title": "Transformers backend integration in SGLang",
    "description": "",
    "summary": "Transformers backend integration in SGLang Hugging Face transformers library is the standard for wor...",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-backend-sglang",
    "thumbnail": "https://huggingface.co/blog/assets/196_transformers_backend_sglang/thumbnail.jpg"
  },
  {
    "title": "New in ChatGPT for Business: April 2025",
    "description": "Watch hands-on demos of the lastest in ChatGPT for Business: o3, image generation, enhanced memory, and internal knowledge.",
    "summary": "Watch hands-on demos of the lastest in ChatGPT for Business: o3, image generation, enhanced memory, and internal knowledge.",
    "pubDate": "Thu, 24 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/new-in-chatgpt-for-business-april-updates-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding BigBird's Block Sparse Attention",
    "description": "",
    "summary": "Understanding BigBird's Block Sparse Attention Introduction Transformer-based models have shown to b...",
    "pubDate": "Wed, 31 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/big-bird",
    "thumbnail": "https://huggingface.co/blog/assets/18_big_bird/attn.png"
  },
  {
    "title": "Genmab launches ‚ÄúAI Everywhere‚Äù",
    "description": "Genmab embraces ChatGPT Enterprise, supported by OpenAI‚Äôs commitment to security and privacy",
    "summary": "Genmab embraces ChatGPT Enterprise, supported by OpenAI‚Äôs commitment to security and privacy",
    "pubDate": "Thu, 19 Sep 2024 04:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/genmab",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How AI is reshaping the future of healthcare and medical research",
    "description": "<p>Technologists Bill Gates and S√©bastien Bubeck discuss the state of generative AI in medicine, how access to ‚Äúmedical intelligence‚Äù might help empower people across healthcare, and how AI‚Äôs accelerating improvements are likely to affect both delivery and discovery.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/'>How AI is reshaping the future of healthcare and medical research</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Technologists Bill Gates and S√©bastien Bubeck discuss the state of generative AI in medicine, how access to ‚Äúmedical intelligence‚Äù might help empower people across healthcare, and how AI‚Äôs accelerating improvements are likely to affect both delivery and discovery.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/'>How AI is reshaping the future of healthcare and medical research</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 12 Jun 2025 16:17:04 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Improvements to data analysis in ChatGPT",
    "description": "Improvements to data analysis in ChatGPT Interact with tables and charts and add files directly from Google Drive and Microsoft OneDrive.",
    "summary": "Improvements to data analysis in ChatGPT Interact with tables and charts and add files directly from Google Drive and Microsoft OneDrive.",
    "pubDate": "Thu, 16 May 2024 15:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improvements-to-data-analysis-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Idefics2: A Powerful 8B Vision-Language Model for the community",
    "description": "",
    "summary": "Introducing Idefics2: A Powerful 8B Vision-Language Model for the community We are excited to releas...",
    "pubDate": "Mon, 15 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/idefics2",
    "thumbnail": "https://huggingface.co/blog/assets/idefics/thumbnail.png"
  },
  {
    "title": "Gotta Learn Fast: A new benchmark for generalization in RL",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 10 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gotta-learn-fast",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Triton: Open-source GPU programming for neural networks",
    "description": "We‚Äôre releasing Triton 1.0, an open-source Python-like programming language which enables researchers with no CUDA experience to write highly efficient GPU code‚Äîmost of the time on par with what an expert would be able to produce.",
    "summary": "We‚Äôre releasing Triton 1.0, an open-source Python-like programming language which enables researchers with no CUDA experience to write highly efficient GPU code‚Äîmost of the time on par with what an expert would be able to produce.",
    "pubDate": "Wed, 28 Jul 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/triton",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Five Benchmark: Results",
    "description": "Yesterday,¬†OpenAI Five¬†won a best-of-three against a team of 99.95th percentile Dota players:¬†Blitz,¬†Cap,¬†Fogged,¬†Merlini, and¬†MoonMeander‚Äîfour of whom have played Dota professionally‚Äîin front of a live audience and 100,000 concurrent livestream¬†viewers.",
    "summary": "Yesterday,¬†OpenAI Five¬†won a best-of-three against a team of 99.95th percentile Dota players:¬†Blitz,¬†Cap,¬†Fogged,¬†Merlini, and¬†MoonMeander‚Äîfour of whom have played Dota professionally‚Äîin front of a live audience and 100,000 concurrent livestream¬†viewers.",
    "pubDate": "Mon, 06 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-benchmark-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Behind ‚ÄúANCESTRA‚Äù: combining Veo with live-action filmmaking",
    "description": "We partnered with Darren Aronofsky, Eliza McNitt and a team of more than 200 people to make a film using Veo and live-action filmmaking.",
    "summary": "We partnered with Darren Aronofsky, Eliza McNitt and a team of more than 200 people to make a film using Veo and live-action filmmaking.",
    "pubDate": "Fri, 13 Jun 2025 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/behind-ancestra-combining-veo-with-live-action-filmmaking/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ancestra-YTThumbnail.width-1300.png"
  },
  {
    "title": "AlphaProteo generates novel proteins for biology and health research",
    "description": "New AI system designs proteins that successfully bind to target molecules, with potential for advancing drug design, disease understanding and more.",
    "summary": "New AI system designs proteins that successfully bind to target molecules, with potential for advancing drug design, disease understanding and more.",
    "pubDate": "Thu, 05 Sep 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/",
    "thumbnail": "https://lh3.googleusercontent.com/7RKd6r-Wc8JfMau5x9knRq9DrOKGDwS3ye4YxY0jjWGntf74y8WL0lOlktJefxwkJYw33UEf2Ph_BhQ51TIufCxPkmtCPOpakekMpnOUwVI-3R6RzQ=w1200-h630-n-nu"
  },
  {
    "title": "Long-Sequence Memory with Temporal Kernels and Dense Hopfield Functionals",
    "description": "arXiv:2507.01052v1 Announce Type: cross Abstract: In this study we introduce a novel energy functional for long-sequence memory, building upon the framework of dense Hopfield networks which achieves exponential storage capacity through higher-order interactions. Building upon earlier work on long-sequence Hopfield memory models, we propose a temporal kernal $K(m, k)$ to incorporate temporal dependencies, enabling efficient sequential retrieval of patterns over extended sequences. We demonstrate the successful application of this technique for the storage and sequential retrieval of movies frames which are well suited for this because of the high dimensional vectors that make up each frame creating enough variation between even sequential frames in the high dimensional space. The technique has applications in modern transformer architectures, including efficient long-sequence modeling, memory augmentation, improved attention with temporal bias, and enhanced handling of long-term dependencies in time-series data. Our model offers a promising approach to address the limitations of transformers in long-context tasks, with potential implications for natural language processing, forecasting, and beyond.",
    "summary": "arXiv:2507.01052v1 Announce Type: cross Abstract: In this study we introduce a novel energy functional for long-sequence memory, building upon the framework of dense Hopfield networks which achieves exponential storage capacity through higher-order interactions. Building upon earlier work on long-sequence Hopfield memory models, we propose a temporal kernal $K(m, k)$ to incorporate temporal dependencies, enabling efficient sequential retrieval of patterns over extended sequences. We demonstrate the successful application of this technique for the storage and sequential retrieval of movies frames which are well suited for this because of the high dimensional vectors that make up each frame creating enough variation between even sequential frames in the high dimensional space. The technique has applications in modern transformer architectures, including efficient long-sequence modeling, memory augmentation, improved attention with temporal bias, and enhanced handling of long-term dependencies in time-series data. Our model offers a promising approach to address the limitations of transformers in long-context tasks, with potential implications for natural language processing, forecasting, and beyond.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01052",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "College students and ChatGPT adoption in the US",
    "description": "A look into state-by-state adoption and how gaps might impact workforce readiness.",
    "summary": "A look into state-by-state adoption and how gaps might impact workforce readiness.",
    "pubDate": "Thu, 20 Feb 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/college-students-and-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sparking a more productive company with ChatGPT Enterprise",
    "description": "Match Group uses ChatGPT Enterprise to spark creativity and impact.",
    "summary": "Match Group uses ChatGPT Enterprise to spark creativity and impact.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/match-group",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How the voices for ChatGPT were chosen",
    "description": "How the voices for ChatGPT were chosen We worked with industry-leading casting and directing professionals to narrow down over 400 submissions before selecting the 5 voices.",
    "summary": "How the voices for ChatGPT were chosen We worked with industry-leading casting and directing professionals to narrow down over 400 submissions before selecting the 5 voices.",
    "pubDate": "Sun, 19 May 2024 23:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-the-voices-for-chatgpt-were-chosen",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Putting RL back in RLHF",
    "description": "",
    "summary": "Putting RL back in RLHF We are excited to introduce the RLOO (REINFORCE Leave One-Out) Trainer in TR...",
    "pubDate": "Wed, 12 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/putting_rl_back_in_rlhf_with_rloo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/ai-icon.png"
  },
  {
    "title": "Scaling the OpenAI Academy",
    "description": "Online resource hub will support AI literacy and help people from all backgrounds access tools, best practices, and peer insights to use AI.",
    "summary": "Online resource hub will support AI literacy and help people from all backgrounds access tools, best practices, and peer insights to use AI.",
    "pubDate": "Tue, 25 Mar 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/scaling-the-openai-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Preparing for malicious uses of AI",
    "description": "We‚Äôve co-authored a paper that forecasts how malicious actors could misuse AI technology, and potential ways we can prevent and mitigate these threats. This paper is the outcome of almost a year of sustained work with our colleagues at the Future of Humanity Institute, the Centre for the Study of Existential Risk, the Center for a New American Security, the Electronic Frontier Foundation, and others.",
    "summary": "We‚Äôve co-authored a paper that forecasts how malicious actors could misuse AI technology, and potential ways we can prevent and mitigate these threats. This paper is the outcome of almost a year of sustained work with our colleagues at the Future of Humanity Institute, the Centre for the Study of Existential Risk, the Center for a New American Security, the Electronic Frontier Foundation, and others.",
    "pubDate": "Tue, 20 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/preparing-for-malicious-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "15,500 Seconds: Lean UAV Classification Leveraging PEFT and Pre-Trained Networks",
    "description": "arXiv:2506.11049v2 Announce Type: replace-cross Abstract: Unmanned Aerial Vehicles (UAVs) pose an escalating security concerns as the market for consumer and military UAVs grows. This paper address the critical data scarcity challenges in deep UAV audio classification. We build upon our previous work expanding novel approaches such as: parameter efficient fine-tuning, data augmentation, and pre-trained networks. We achieve performance upwards of 95% validation accuracy with EfficientNet-B0.",
    "summary": "arXiv:2506.11049v2 Announce Type: replace-cross Abstract: Unmanned Aerial Vehicles (UAVs) pose an escalating security concerns as the market for consumer and military UAVs grows. This paper address the critical data scarcity challenges in deep UAV audio classification. We build upon our previous work expanding novel approaches such as: parameter efficient fine-tuning, data augmentation, and pre-trained networks. We achieve performance upwards of 95% validation accuracy with EfficientNet-B0.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11049",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Scholars 2018: Final projects",
    "description": "Our first cohort of¬†OpenAI Scholars¬†has now completed the program.",
    "summary": "Our first cohort of¬†OpenAI Scholars¬†has now completed the program.",
    "pubDate": "Mon, 10 Sep 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2018-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Team update",
    "description": "We‚Äôve hired more great people to help us achieve our goals. Welcome, everyone!",
    "summary": "We‚Äôve hired more great people to help us achieve our goals. Welcome, everyone!",
    "pubDate": "Tue, 16 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update-august",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning to summarize with human feedback",
    "description": "We‚Äôve applied reinforcement learning from human feedback to train language models that are better at summarization.",
    "summary": "We‚Äôve applied reinforcement learning from human feedback to train language models that are better at summarization.",
    "pubDate": "Fri, 04 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-summarize-with-human-feedback",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Simplifying, stabilizing, and scaling continuous-time consistency models",
    "description": "We‚Äôve simplified, stabilized, and scaled continuous-time consistency models, achieving comparable sample quality to leading diffusion models, while using only two sampling steps.",
    "summary": "We‚Äôve simplified, stabilized, and scaled continuous-time consistency models, achieving comparable sample quality to leading diffusion models, while using only two sampling steps.",
    "pubDate": "Wed, 23 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/simplifying-stabilizing-and-scaling-continuous-time-consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "HPC-AI Coupling Methodology for Scientific Applications",
    "description": "arXiv:2507.01025v1 Announce Type: cross Abstract: Artificial intelligence (AI) technologies have fundamentally transformed numerical-based high-performance computing (HPC) applications with data-driven approaches and endeavored to address existing challenges, e.g. high computational intensity, in various scientific domains. In this study, we explore the scenarios of coupling HPC and AI (HPC-AI) in the context of emerging scientific applications, presenting a novel methodology that incorporates three patterns of coupling: surrogate, directive, and coordinate. Each pattern exemplifies a distinct coupling strategy, AI-driven prerequisite, and typical HPC-AI ensembles. Through case studies in materials science, we demonstrate the application and effectiveness of these patterns. The study highlights technical challenges, performance improvements, and implementation details, providing insight into promising perspectives of HPC-AI coupling. The proposed coupling patterns are applicable not only to materials science but also to other scientific domains, offering valuable guidance for future HPC-AI ensembles in scientific discovery.",
    "summary": "arXiv:2507.01025v1 Announce Type: cross Abstract: Artificial intelligence (AI) technologies have fundamentally transformed numerical-based high-performance computing (HPC) applications with data-driven approaches and endeavored to address existing challenges, e.g. high computational intensity, in various scientific domains. In this study, we explore the scenarios of coupling HPC and AI (HPC-AI) in the context of emerging scientific applications, presenting a novel methodology that incorporates three patterns of coupling: surrogate, directive, and coordinate. Each pattern exemplifies a distinct coupling strategy, AI-driven prerequisite, and typical HPC-AI ensembles. Through case studies in materials science, we demonstrate the application and effectiveness of these patterns. The study highlights technical challenges, performance improvements, and implementation details, providing insight into promising perspectives of HPC-AI coupling. The proposed coupling patterns are applicable not only to materials science but also to other scientific domains, offering valuable guidance for future HPC-AI ensembles in scientific discovery.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Democratic inputs to AI",
    "description": "Our nonprofit organization, OpenAI, Inc., is launching a program to award ten $100,000 grants to fund experiments in setting up a democratic process for deciding what rules AI systems should follow, within the bounds defined by the law.",
    "summary": "Our nonprofit organization, OpenAI, Inc., is launching a program to award ten $100,000 grants to fund experiments in setting up a democratic process for deciding what rules AI systems should follow, within the bounds defined by the law.",
    "pubDate": "Thu, 25 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/democratic-inputs-to-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Journey to 1 Million Gradio Users!",
    "description": "",
    "summary": "Journey to 1 Million Gradio Users! 5 years ago, we launched Gradio as a simple Python library to let...",
    "pubDate": "Fri, 04 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-1m",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-1m/thumbnail.png"
  },
  {
    "title": "Vision Language Models Explained",
    "description": "",
    "summary": "Vision Language Models Explained This blog post was written on April 2024 and provides a great intro...",
    "pubDate": "Thu, 11 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vlms",
    "thumbnail": "https://huggingface.co/blog/assets/vlms_explained/thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT Team",
    "description": "We‚Äôre launching a new ChatGPT plan for teams of all sizes, which provides a secure, collaborative workspace to get the most out of ChatGPT at work.",
    "summary": "We‚Äôre launching a new ChatGPT plan for teams of all sizes, which provides a secure, collaborative workspace to get the most out of ChatGPT at work.",
    "pubDate": "Wed, 10 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-team",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Summer at Hugging Face ‚òÄÔ∏è",
    "description": "",
    "summary": "Summer At Hugging Face üòé Summer is now officially over and these last few months have been quite bus...",
    "pubDate": "Fri, 24 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/summer-at-huggingface",
    "thumbnail": "https://huggingface.co/blog/assets/27_summer_at_huggingface/summer_intro.gif"
  },
  {
    "title": "OpenAI‚Äôs Economic Blueprint",
    "description": "OpenAI‚Äôs Economic Blueprint",
    "summary": "OpenAI‚Äôs Economic Blueprint",
    "pubDate": "Mon, 13 Jan 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-economic-blueprint",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Docmatix - a huge dataset for Document Visual Question Answering",
    "description": "",
    "summary": "Docmatix - A huge dataset for Document Visual Question Answering With this blog we are releasing Doc...",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/docmatix",
    "thumbnail": "https://huggingface.co/blog/assets/183_docmatix/thumbnail_new.png"
  },
  {
    "title": "CodeAgents + Structure: A Better Way to Execute Actions",
    "description": "",
    "summary": "CodeAgents + Structure: A Better Way to Execute Actions Today we're sharing research that bridges tw...",
    "pubDate": "Wed, 28 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/structured-codeagent",
    "thumbnail": "https://huggingface.co/blog/assets/structured-codeagent/thumbnail-codeagent.png"
  },
  {
    "title": "AI for the board game Diplomacy",
    "description": "Successful communication and cooperation have been crucial for helping societies advance throughout history. The closed environments of board games can serve as a sandbox for modelling and investigating interaction and communication ‚Äì and we can learn a lot from playing them. In our recent paper, published today in Nature Communications, we show how artificial agents can use communication to better cooperate in the board game Diplomacy, a vibrant domain in artificial intelligence (AI) research, known for its focus on alliance building.",
    "summary": "Successful communication and cooperation have been crucial for helping societies advance throughout history. The closed environments of board games can serve as a sandbox for modelling and investigating interaction and communication ‚Äì and we can learn a lot from playing them. In our recent paper, published today in Nature Communications, we show how artificial agents can use communication to better cooperate in the board game Diplomacy, a vibrant domain in artificial intelligence (AI) research, known for its focus on alliance building.",
    "pubDate": "Tue, 06 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ai-for-the-board-game-diplomacy/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI Fellows Fall 2018",
    "description": "We‚Äôre now accepting applications for the next cohort of OpenAI Fellows, a program which offers a compensated 6-month apprenticeship in AI research at OpenAI.",
    "summary": "We‚Äôre now accepting applications for the next cohort of OpenAI Fellows, a program which offers a compensated 6-month apprenticeship in AI research at OpenAI.",
    "pubDate": "Wed, 30 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2018: Meet our Scholars",
    "description": "Our first class of¬†OpenAI Scholars¬†is underway, and¬†you can now follow along as this group¬†of experienced software developers becomes machine learning practitioners.",
    "summary": "Our first class of¬†OpenAI Scholars¬†is underway, and¬†you can now follow along as this group¬†of experienced software developers becomes machine learning practitioners.",
    "pubDate": "Wed, 25 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2018-meet-our-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Llama 2 on Amazon SageMaker a Benchmark",
    "description": "",
    "summary": "Llama 2 on Amazon SageMaker a Benchmark Deploying large language models (LLMs) and other generative ...",
    "pubDate": "Tue, 26 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama-sagemaker-benchmark",
    "thumbnail": "https://huggingface.co/blog/assets/llama_sagemaker_benchmark/thumbnail.jpg"
  },
  {
    "title": "OpenAI Scholars 2019: Meet our Scholars",
    "description": "Our class of eight¬†scholars¬†(out of 550 applicants) brings together collective expertise in literature, philosophy, cell biology, statistics, economics, quantum physics, and business innovation.",
    "summary": "Our class of eight¬†scholars¬†(out of 550 applicants) brings together collective expertise in literature, philosophy, cell biology, statistics, economics, quantum physics, and business innovation.",
    "pubDate": "Wed, 13 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019-meet-our-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evolving online forms into dynamic data",
    "description": "Typeform evolves online forms into dynamic and conversational data collection experiences with GPT-3.5 and GPT-4.",
    "summary": "Typeform evolves online forms into dynamic and conversational data collection experiences with GPT-3.5 and GPT-4.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/typeform",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The AI tools for Art Newsletter - Issue 1",
    "description": "",
    "summary": "The AI tools for Art Newsletter First issue üéâ The AI space is moving so fast it‚Äôs hard to believe th...",
    "pubDate": "Fri, 31 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-art-newsletter-jan-25",
    "thumbnail": "https://huggingface.co/blog/assets/ai_art_newsletter_1/thumbnail.png"
  },
  {
    "title": "New and improved embedding model",
    "description": "We are excited to announce a new embedding model which is significantly more capable, cost effective, and simpler to use.",
    "summary": "We are excited to announce a new embedding model which is significantly more capable, cost effective, and simpler to use.",
    "pubDate": "Thu, 15 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-and-improved-embedding-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PaperBench: Evaluating AI‚Äôs Ability to Replicate AI Research",
    "description": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research.",
    "summary": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research.",
    "pubDate": "Wed, 02 Apr 2025 10:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paperbench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemini 2.5: Updates to our family of thinking models",
    "description": "Explore the latest Gemini 2.5 model updates with enhanced performance and accuracy: Gemini 2.5 Pro now stable, Flash generally available, and the new Flash-Lite in preview.",
    "summary": "Explore the latest Gemini 2.5 model updates with enhanced performance and accuracy: Gemini 2.5 Pro now stable, Flash generally available, and the new Flash-Lite in preview.",
    "pubDate": "Tue, 17 Jun 2025 16:03:39 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-updates-to-our-family-of-thinking-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-2-5-pro-meta_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Deploy MusicGen in no time with Inference Endpoints",
    "description": "",
    "summary": "Deploy MusicGen in no time with Inference Endpoints MusicGen is a powerful music generation model th...",
    "pubDate": "Fri, 04 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/run-musicgen-as-an-api",
    "thumbnail": "https://huggingface.co/blog/assets/run-musicgen-as-an-api/thumbnail.png"
  },
  {
    "title": "Assisted Generation: a new direction toward low-latency text generation",
    "description": "",
    "summary": "Assisted Generation: a new direction toward low-latency text generation Large language models are al...",
    "pubDate": "Thu, 11 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/assisted-generation",
    "thumbnail": "https://huggingface.co/blog/assets/assisted-generation/thumbnail.png"
  },
  {
    "title": "Custom instructions for ChatGPT",
    "description": "We‚Äôre rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
    "summary": "We‚Äôre rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
    "pubDate": "Thu, 20 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/custom-instructions-for-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and Google partner for open AI collaboration",
    "description": "",
    "summary": "Hugging Face and Google partner for open AI collaboration At Hugging Face, we want to enable all com...",
    "pubDate": "Thu, 25 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gcp-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/173_gcp-partnership/thumbnail.jpg"
  },
  {
    "title": "Multivariate Probabilistic Time Series Forecasting with Informer",
    "description": "",
    "summary": "Multivariate Probabilistic Time Series Forecasting with Informer Introduction A few months ago we in...",
    "pubDate": "Fri, 10 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/informer",
    "thumbnail": "https://huggingface.co/blog/assets/134_informer/thumbnail.png"
  },
  {
    "title": "The next chapter of our Gemini era",
    "description": "We're bringing Gemini to more Google products",
    "summary": "We're bringing Gemini to more Google products",
    "pubDate": "Thu, 08 Feb 2024 13:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-gemini-update-sundar-pichai-2024/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Keyword_Social_-_1920x1080.width-1300.png"
  },
  {
    "title": "New methods boost reasoning in small and large language models",
    "description": "<p>New techniques are reimagining how LLMs reason. By combining symbolic logic, mathematical rigor, and adaptive planning, these methods enable models to tackle complex, real-world problems across a variety of fields.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/'>New methods boost reasoning in small and large language models</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>New techniques are reimagining how LLMs reason. By combining symbolic logic, mathematical rigor, and adaptive planning, these methods enable models to tackle complex, real-world problems across a variety of fields.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/'>New methods boost reasoning in small and large language models</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Music AI Sandbox, now with new features and broader access",
    "description": "Helping music professionals explore the potential of generative AI",
    "summary": "Helping music professionals explore the potential of generative AI",
    "pubDate": "Thu, 24 Apr 2025 15:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/music-ai-sandbox-now-with-new-features-and-broader-access/",
    "thumbnail": "https://lh3.googleusercontent.com/t_n_87B373tBNlvzgBy7RuJXb5hoPdLtBBgWjzfJnVuauI0JFwiYAyGM_LMl-yeJ3zNWO782VBE8m6ByaxDJoIvIbWoQ_DQPMdxszprk5Tbh2xQx5Q=w1200-h630-n-nu"
  },
  {
    "title": "Welcome fastText to the ü§ó Hub",
    "description": "",
    "summary": "Welcome fastText to the Hugging Face Hub fastText is a library for efficient learning of text repres...",
    "pubDate": "Tue, 06 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fasttext",
    "thumbnail": "https://huggingface.co/blog/assets/147_fasttext/thumbnail.png"
  },
  {
    "title": "New Credit Facility Enhances Financial Flexibility",
    "description": "In addition to securing $6.6 billion in new funding from leading investors, we have established a new $4 billion credit facility with leading banks, including JPMorgan Chase, Citi, Goldman Sachs, Morgan Stanley, Santander, Wells Fargo, SMBC, UBS, and HSBC.",
    "summary": "In addition to securing $6.6 billion in new funding from leading investors, we have established a new $4 billion credit facility with leading banks, including JPMorgan Chase, Citi, Goldman Sachs, Morgan Stanley, Santander, Wells Fargo, SMBC, UBS, and HSBC.",
    "pubDate": "Thu, 03 Oct 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-credit-facility-enhances-financial-flexibility",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI achieves silver-medal standard solving International Mathematical Olympiad problems",
    "description": "Breakthrough models AlphaProof and AlphaGeometry 2 solve advanced reasoning problems in mathematics",
    "summary": "Breakthrough models AlphaProof and AlphaGeometry 2 solve advanced reasoning problems in mathematics",
    "pubDate": "Thu, 25 Jul 2024 15:29:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/",
    "thumbnail": "https://lh3.googleusercontent.com/2A21eFt7wdDrmMzzkenrCTuioLWGFdzU5Ao5dPH9yPtAw6QNHxZcDmoQA2_ZriU2gMjX8mzEOtfPbMCRuL5kVzLoz6efLgqT_foBXU3pxKBXTTOXXpc=w1200-h630-n-nu"
  },
  {
    "title": "Evaluating Language Model Bias with ü§ó Evaluate",
    "description": "",
    "summary": "Evaluating Language Model Bias with ü§ó Evaluate While the size and capabilities of large language mod...",
    "pubDate": "Mon, 24 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/evaluating-llm-bias",
    "thumbnail": "https://huggingface.co/blog/assets/112_evaluating-llm-bias/thumbnail.png"
  },
  {
    "title": "Deploying Speech-to-Speech on Hugging Face",
    "description": "",
    "summary": "Deploying Speech-to-Speech on Hugging Face Introduction Speech-to-Speech (S2S) is an exciting new pr...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/s2s_endpoint",
    "thumbnail": "https://huggingface.co/blog/assets/s2s_endpoint/thumbnail.png"
  },
  {
    "title": "Using generative AI to help robots jump higher and land safely",
    "description": "MIT CSAIL researchers combined GenAI and a physics simulation engine to refine robot designs. The result: a machine that out-jumped a robot designed by humans.",
    "summary": "MIT CSAIL researchers combined GenAI and a physics simulation engine to refine robot designs. The result: a machine that out-jumped a robot designed by humans.",
    "pubDate": "Fri, 27 Jun 2025 13:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/using-generative-ai-help-robots-jump-higher-land-safely-0627",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Jumping_Robot%20%285%29.png"
  },
  {
    "title": "Self-Guided Process Reward Optimization with Masked Step Advantage for Process Reinforcement Learning",
    "description": "arXiv:2507.01551v1 Announce Type: cross Abstract: Process Reinforcement Learning~(PRL) has demonstrated considerable potential in enhancing the reasoning capabilities of Large Language Models~(LLMs). However, introducing additional process reward models incurs substantial computational overhead, and there is no unified theoretical framework for process-level advantage estimation. To bridge this gap, we propose textbf{S}elf-Guided textbf{P}rocess textbf{R}eward textbf{O}ptimization~(textbf{SPRO}), a novel framework that enables process-aware RL through two key innovations: (1) we first theoretically demonstrate that process rewards can be derived intrinsically from the policy model itself, and (2) we introduce well-defined cumulative process rewards and textbf{M}asked textbf{S}tep textbf{A}dvantage (textbf{MSA}), which facilitates rigorous step-wise action advantage estimation within shared-prompt sampling groups. Our experimental results demonstrate that SPRO outperforms vaniila GRPO with 3.4x higher training efficiency and a 17.5% test accuracy improvement. Furthermore, SPRO maintains a stable and elevated policy entropy throughout training while reducing the average response length by approximately $1/3$, evidencing sufficient exploration and prevention of reward hacking. Notably, SPRO incurs no additional computational overhead compared to outcome-supervised RL methods such as GRPO, which benefit industrial implementation.",
    "summary": "arXiv:2507.01551v1 Announce Type: cross Abstract: Process Reinforcement Learning~(PRL) has demonstrated considerable potential in enhancing the reasoning capabilities of Large Language Models~(LLMs). However, introducing additional process reward models incurs substantial computational overhead, and there is no unified theoretical framework for process-level advantage estimation. To bridge this gap, we propose textbf{S}elf-Guided textbf{P}rocess textbf{R}eward textbf{O}ptimization~(textbf{SPRO}), a novel framework that enables process-aware RL through two key innovations: (1) we first theoretically demonstrate that process rewards can be derived intrinsically from the policy model itself, and (2) we introduce well-defined cumulative process rewards and textbf{M}asked textbf{S}tep textbf{A}dvantage (textbf{MSA}), which facilitates rigorous step-wise action advantage estimation within shared-prompt sampling groups. Our experimental results demonstrate that SPRO outperforms vaniila GRPO with 3.4x higher training efficiency and a 17.5% test accuracy improvement. Furthermore, SPRO maintains a stable and elevated policy entropy throughout training while reducing the average response length by approximately $1/3$, evidencing sufficient exploration and prevention of reward hacking. Notably, SPRO incurs no additional computational overhead compared to outcome-supervised RL methods such as GRPO, which benefit industrial implementation.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01551",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A hazard analysis framework for code synthesis large language models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-hazard-analysis-framework-for-code-synthesis-large-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy Embedding Models with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Deploy Embedding Models with Hugging Face Inference Endpoints The rise of Generative AI and LLMs lik...",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/168_inference_endpoints_embeddings/thumbnail.jpg"
  },
  {
    "title": "Introducing Gemini: our largest and most capable AI model",
    "description": "Making AI more helpful for everyone",
    "summary": "Making AI more helpful for everyone",
    "pubDate": "Wed, 06 Dec 2023 15:13:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-our-largest-and-most-capable-ai-model/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_SS.width-1300.jpg"
  },
  {
    "title": "Fine-Tune ViT for Image Classification with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune ViT for Image Classification with ü§ó Transformers Just as transformers-based models have re...",
    "pubDate": "Fri, 11 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-vit",
    "thumbnail": "https://huggingface.co/blog/assets/51_fine_tune_vit/vit-thumbnail.jpg"
  },
  {
    "title": "Introducing the Enterprise Scenarios Leaderboard: a Leaderboard for Real World Use Cases",
    "description": "",
    "summary": "Introducing the Enterprise Scenarios Leaderboard: a Leaderboard for Real World Use Cases Today, the ...",
    "pubDate": "Wed, 31 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-patronus",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_patronus.png"
  },
  {
    "title": "OpenAI o3-mini System Card",
    "description": "This report outlines the safety work carried out for the OpenAI o3-mini model, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
    "summary": "This report outlines the safety work carried out for the OpenAI o3-mini model, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
    "pubDate": "Fri, 31 Jan 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-mini-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Red-Teaming Resistance Leaderboard",
    "description": "",
    "summary": "Introducing the Red-Teaming Resistance Leaderboard Content warning: since this blog post is about a ...",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-haizelab",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_haizelab.png"
  },
  {
    "title": "Quantifying Student Success with Generative AI: A Monte Carlo Simulation Informed by Systematic Review",
    "description": "arXiv:2507.01062v1 Announce Type: cross Abstract: The exponential development of generative artificial intelligence (GenAI) technologies like ChatGPT has raised increasing curiosity about their use in higher education, specifically with respect to how students view them, make use of them, and the implications for learning outcomes. This paper employs a hybrid methodological approach involving a systematic literature review and simulation-based modeling to explore student perceptions of GenAI use in the context of higher education. A total of nineteen empirical articles from 2023 through 2025 were selected from the PRISMA-based search targeting the Scopus database. Synthesis of emerging patterns from the literature was achieved by thematic categorization. Six of these had enough quantitative information, i.e., item-level means and standard deviations, to permit probabilistic modeling. One dataset, from the resulting subset, was itself selected as a representative case with which to illustrate inverse-variance weighting by Monte Carlo simulation, by virtue of its well-designed Likert scale format and thematic alignment with the use of computing systems by the researcher. The simulation provided a composite 'Success Score' forecasting the strength of the relationship between student perceptions and learning achievements. Findings reveal that attitude factors concerned with usability and real-world usefulness are significantly better predictors of positive learning achievement than affective or trust-based factors. Such an interdisciplinary perspective provides a unique means of linking thematic results with predictive modelling, resonating with longstanding controversies about the proper use of GenAI tools within the university.",
    "summary": "arXiv:2507.01062v1 Announce Type: cross Abstract: The exponential development of generative artificial intelligence (GenAI) technologies like ChatGPT has raised increasing curiosity about their use in higher education, specifically with respect to how students view them, make use of them, and the implications for learning outcomes. This paper employs a hybrid methodological approach involving a systematic literature review and simulation-based modeling to explore student perceptions of GenAI use in the context of higher education. A total of nineteen empirical articles from 2023 through 2025 were selected from the PRISMA-based search targeting the Scopus database. Synthesis of emerging patterns from the literature was achieved by thematic categorization. Six of these had enough quantitative information, i.e., item-level means and standard deviations, to permit probabilistic modeling. One dataset, from the resulting subset, was itself selected as a representative case with which to illustrate inverse-variance weighting by Monte Carlo simulation, by virtue of its well-designed Likert scale format and thematic alignment with the use of computing systems by the researcher. The simulation provided a composite 'Success Score' forecasting the strength of the relationship between student perceptions and learning achievements. Findings reveal that attitude factors concerned with usability and real-world usefulness are significantly better predictors of positive learning achievement than affective or trust-based factors. Such an interdisciplinary perspective provides a unique means of linking thematic results with predictive modelling, resonating with longstanding controversies about the proper use of GenAI tools within the university.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01062",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Hallucinations Leaderboard, an Open Effort to Measure Hallucinations in Large Language Models",
    "description": "",
    "summary": "The Hallucinations Leaderboard, an Open Effort to Measure Hallucinations in Large Language Models In...",
    "pubDate": "Mon, 29 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-hallucinations",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "Best practices for deploying language models",
    "description": "Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models.",
    "summary": "Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models.",
    "pubDate": "Thu, 02 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/best-practices-for-deploying-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Reads, Feb. 2021 - Long-range Transformers",
    "description": "",
    "summary": "Hugging Face Reads, Feb. 2021 - Long-range Transformers Co-written by Teven Le Scao, Patrick Von Pla...",
    "pubDate": "Tue, 09 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/long-range-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/14_long_range_transformers/EfficientTransformerTaxonomy.png"
  },
  {
    "title": "Optimize and deploy models with Optimum-Intel and OpenVINO GenAI",
    "description": "",
    "summary": "Optimize and deploy models with Optimum-Intel and OpenVINO GenAI Deploying Transformers models at th...",
    "pubDate": "Fri, 20 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-with-openvino",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Empowering YouTube creators with generative AI",
    "description": "New video generation technology in YouTube Shorts will help millions of people realize their creative vision",
    "summary": "New video generation technology in YouTube Shorts will help millions of people realize their creative vision",
    "pubDate": "Wed, 18 Sep 2024 14:30:06 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/empowering-youtube-creators-with-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/Q8qBc1kzbYeksHRjsSuR7HEvezKsw3n1fxYlOqLf2sslqDOqYXJOhxyjznZ4cyq1fwNhpyMTMXW0RRrgHweVg6NaCEPnt3ujcFAIe0bVXK_sHka7cLo=w1200-h630-n-nu"
  },
  {
    "title": "Data-driven Insights for Informed Decision-Making: Applying LSTM Networks for Robust Electricity Forecasting in Libya",
    "description": "arXiv:2507.01034v1 Announce Type: cross Abstract: Accurate electricity forecasting is crucial for grid stability and energy planning, especially in Benghazi, Libya, where frequent load shedding, generation deficits, and infrastructure limitations persist. This study proposes a data-driven approach to forecast electricity load, generation, and deficits for 2025 using historical data from 2019 (a year marked by instability) and 2023 (a more stable year). Multiple time series models were applied, including ARIMA, seasonal ARIMA, dynamic regression ARIMA, exponential smoothing, extreme gradient boosting, and Long Short-Term Memory (LSTM) neural networks. The dataset was enhanced through missing value imputation, outlier smoothing, and log transformation. Performance was assessed using mean squared error, root mean squared error, mean absolute error, and mean absolute percentage error. LSTM outperformed all other models, showing strong capabilities in modeling non-stationary and seasonal patterns. A key contribution of this work is an optimized LSTM framework that integrates exogenous factors such as temperature and humidity, offering robust performance in forecasting multiple electricity indicators. These results provide practical insights for policymakers and grid operators to enable proactive load management and resource planning in data-scarce, volatile regions.",
    "summary": "arXiv:2507.01034v1 Announce Type: cross Abstract: Accurate electricity forecasting is crucial for grid stability and energy planning, especially in Benghazi, Libya, where frequent load shedding, generation deficits, and infrastructure limitations persist. This study proposes a data-driven approach to forecast electricity load, generation, and deficits for 2025 using historical data from 2019 (a year marked by instability) and 2023 (a more stable year). Multiple time series models were applied, including ARIMA, seasonal ARIMA, dynamic regression ARIMA, exponential smoothing, extreme gradient boosting, and Long Short-Term Memory (LSTM) neural networks. The dataset was enhanced through missing value imputation, outlier smoothing, and log transformation. Performance was assessed using mean squared error, root mean squared error, mean absolute error, and mean absolute percentage error. LSTM outperformed all other models, showing strong capabilities in modeling non-stationary and seasonal patterns. A key contribution of this work is an optimized LSTM framework that integrates exogenous factors such as temperature and humidity, offering robust performance in forecasting multiple electricity indicators. These results provide practical insights for policymakers and grid operators to enable proactive load management and resource planning in data-scarce, volatile regions.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01034",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MMLU-Reason: Benchmarking Multi-Task Multi-modal Language Understanding and Reasoning",
    "description": "arXiv:2505.16459v4 Announce Type: replace Abstract: Recent advances in Multi-Modal Large Language Models (MLLMs) have enabled unified processing of language, vision, and structured inputs, opening the door to complex tasks such as logical deduction, spatial reasoning, and scientific analysis. Despite their promise, the reasoning capabilities of MLLMs, particularly those augmented with intermediate thinking traces (MLLMs-T), remain poorly understood and lack standardized evaluation benchmarks. Existing work focuses primarily on perception or final answer correctness, offering limited insight into how models reason or fail across modalities. To address this gap, we introduce the MMLU-Reason, a new benchmark designed to rigorously evaluate multi-modal reasoning with explicit thinking. The MMLU-Reason comprises 1) a high-difficulty dataset of 1,083 questions spanning six diverse reasoning types with symbolic depth and multi-hop demands and 2) a modular Reasoning Trace Evaluation Pipeline (RTEP) for assessing reasoning quality beyond accuracy through metrics like relevance, consistency, and structured error annotations. Empirical results show that MLLMs-T overall outperform non-thinking counterparts, but even top models like Claude-3.7-Sonnet and Gemini-2.5 Pro suffer from reasoning pathologies such as inconsistency and overthinking. This benchmark reveals persistent gaps between accuracy and reasoning quality and provides an actionable evaluation pipeline for future model development. Overall, the MMLU-Reason offers a scalable foundation for evaluating, comparing, and improving the next generation of multi-modal reasoning systems.",
    "summary": "arXiv:2505.16459v4 Announce Type: replace Abstract: Recent advances in Multi-Modal Large Language Models (MLLMs) have enabled unified processing of language, vision, and structured inputs, opening the door to complex tasks such as logical deduction, spatial reasoning, and scientific analysis. Despite their promise, the reasoning capabilities of MLLMs, particularly those augmented with intermediate thinking traces (MLLMs-T), remain poorly understood and lack standardized evaluation benchmarks. Existing work focuses primarily on perception or final answer correctness, offering limited insight into how models reason or fail across modalities. To address this gap, we introduce the MMLU-Reason, a new benchmark designed to rigorously evaluate multi-modal reasoning with explicit thinking. The MMLU-Reason comprises 1) a high-difficulty dataset of 1,083 questions spanning six diverse reasoning types with symbolic depth and multi-hop demands and 2) a modular Reasoning Trace Evaluation Pipeline (RTEP) for assessing reasoning quality beyond accuracy through metrics like relevance, consistency, and structured error annotations. Empirical results show that MLLMs-T overall outperform non-thinking counterparts, but even top models like Claude-3.7-Sonnet and Gemini-2.5 Pro suffer from reasoning pathologies such as inconsistency and overthinking. This benchmark reveals persistent gaps between accuracy and reasoning quality and provides an actionable evaluation pipeline for future model development. Overall, the MMLU-Reason offers a scalable foundation for evaluating, comparing, and improving the next generation of multi-modal reasoning systems.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.16459",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using AI to improve patient access to clinical trials",
    "description": "Paradigm uses OpenAI‚Äôs API to improve patient access to clinical trials.",
    "summary": "Paradigm uses OpenAI‚Äôs API to improve patient access to clinical trials.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paradigm",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ICASSP2025 Áô∫Ë°®Â†±Âëä @Hyderabad, India",
    "description": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ 2025Âπ¥4Êúà6Êó•(Êó•)„Äú4Êúà11Êó•(Èáë)„Å´„Ç§„É≥„Éâ„Éª„Éè„Ç§„Éá„É©„Éê„Éº„Éâ„ÄÅHyderabad International Convention Centre„Å´„Å¶ÈñãÂÇ¨„Åï„Çå„Åü„ÄÅÈü≥Èüø„ÉªÈü≥ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5728' rel='nofollow'>ICASSP2025 Áô∫Ë°®Â†±Âëä @Hyderabad, India</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ 2025Âπ¥4Êúà6Êó•(Êó•)„Äú4Êúà11Êó•(Èáë)„Å´„Ç§„É≥„Éâ„Éª„Éè„Ç§„Éá„É©„Éê„Éº„Éâ„ÄÅHyderabad International Convention Centre„Å´„Å¶ÈñãÂÇ¨„Åï„Çå„Åü„ÄÅÈü≥Èüø„ÉªÈü≥ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5728' rel='nofollow'>ICASSP2025 Áô∫Ë°®Â†±Âëä @Hyderabad, India</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Tue, 15 Apr 2025 01:50:49 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5728",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/IMG_20250406_091623-1.jpg"
  },
  {
    "title": "The Partnership: Amazon SageMaker and Hugging Face",
    "description": "",
    "summary": "The Partnership: Amazon SageMaker and Hugging Face Look at these smiles! Today, we announce a strate...",
    "pubDate": "Tue, 23 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face",
    "thumbnail": "https://huggingface.co/blog/assets/17_the_partnership_amazon_sagemaker_and_hugging_face/thumbnail.png"
  },
  {
    "title": "Nubank elevates customer experiences with OpenAI",
    "description": "Nubank elevates customer experiences with OpenAI",
    "summary": "Nubank elevates customer experiences with OpenAI",
    "pubDate": "Fri, 07 Mar 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nubank",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New ViT and ALIGN Models From Kakao Brain",
    "description": "",
    "summary": "Kakao Brain‚Äôs Open Source ViT, ALIGN, and the New COYO Text-Image Dataset Kakao Brain and Hugging Fa...",
    "pubDate": "Mon, 06 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vit-align",
    "thumbnail": "https://huggingface.co/blog//assets/132_vit_align/thumbnail.png"
  },
  {
    "title": "License to Call: Introducing Transformers Agents 2.0",
    "description": "",
    "summary": "License to Call: Introducing Transformers Agents 2.0 TL;DR We are releasing Transformers Agents 2.0!...",
    "pubDate": "Mon, 13 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/agents",
    "thumbnail": "https://huggingface.co/blog/assets/agents/thumbnail.png"
  },
  {
    "title": "Faster Training and Inference: Habana Gaudi¬Æ2 vs Nvidia A100 80GB",
    "description": "",
    "summary": "Faster Training and Inference: Habana Gaudi¬Æ-2 vs Nvidia A100 80GB In this article, you will learn h...",
    "pubDate": "Wed, 14 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana-gaudi-2-benchmark",
    "thumbnail": "https://huggingface.co/blog/assets/habana-gaudi-2-benchmark/thumbnail.png"
  },
  {
    "title": "Addendum to OpenAI o3 and o4-mini system card: OpenAI o3 Operator",
    "description": "We are replacing the existing GPT-4o-based model for Operator with a version based on OpenAI o3. The API version will remain based on 4o.",
    "summary": "We are replacing the existing GPT-4o-based model for Operator with a version based on OpenAI o3. The API version will remain based on 4o.",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-system-card-addendum-operator-o3",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Model Distillation in the API",
    "description": "Fine-tune a cost-efficient model with the outputs of a large frontier model‚Äìall on the OpenAI platform",
    "summary": "Fine-tune a cost-efficient model with the outputs of a large frontier model‚Äìall on the OpenAI platform",
    "pubDate": "Tue, 01 Oct 2024 10:02:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-model-distillation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our vision for building a universal AI assistant",
    "description": "We‚Äôre extending Gemini to become a world model that can make plans and imagine new experiences by simulating aspects of the world.",
    "summary": "We‚Äôre extending Gemini to become a world model that can make plans and imagine new experiences by simulating aspects of the world.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/our-vision-for-building-a-universal-ai-assistant/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_GeminiVision_SocialShare.width-1300.png"
  },
  {
    "title": "AMD Pervasive AI Developer Contest!",
    "description": "",
    "summary": "AMD Pervasive AI Developer Contest AMD and Hugging Face are actively engaged in helping developers s...",
    "pubDate": "Wed, 14 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/amd_pervasive_developer_ai_contest",
    "thumbnail": "https://huggingface.co/blog/amd_pervasive_developer_ai_contest/assets/amd_pervasive_developer_ai_contest/amd_developer_general_abstract.jpg"
  },
  {
    "title": "Mixture of Experts Explained",
    "description": "",
    "summary": "Mixture of Experts Explained With the release of Mixtral 8x7B (announcement, model card), a class of...",
    "pubDate": "Mon, 11 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/moe",
    "thumbnail": "https://huggingface.co/blog/assets/moe/thumbnail.png"
  },
  {
    "title": "Spam detection in the physical world",
    "description": "We‚Äôve created the world‚Äôs first Spam-detecting AI trained entirely in simulation and deployed on a physical robot.",
    "summary": "We‚Äôve created the world‚Äôs first Spam-detecting AI trained entirely in simulation and deployed on a physical robot.",
    "pubDate": "Sat, 01 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spam-detection-in-the-physical-world",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Demis Hassabis & John Jumper awarded Nobel Prize in Chemistry",
    "description": "The award recognizes their work developing AlphaFold, a groundbreaking AI system that predicts the 3D structure of proteins from their amino acid sequences.",
    "summary": "The award recognizes their work developing AlphaFold, a groundbreaking AI system that predicts the 3D structure of proteins from their amino acid sequences.",
    "pubDate": "Wed, 09 Oct 2024 11:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/demis-hassabis-john-jumper-awarded-nobel-prize-in-chemistry/",
    "thumbnail": "https://lh3.googleusercontent.com/7ZdZh5xhoD5NnykRBJHACxkxc3VubCdJLGHty2nYdJ36pBLVxRWO3Keu9C2Tum4OHCyGbJ5K5mB8R_oR94JG700qenuZ2rhq2sKjN4IkjIoU9Chv=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI Red Teaming Network",
    "description": "We‚Äôre announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in improving the safety of OpenAI‚Äôs models to join our efforts.",
    "summary": "We‚Äôre announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in improving the safety of OpenAI‚Äôs models to join our efforts.",
    "pubDate": "Tue, 19 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/red-teaming-network",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI announces nonprofit commission advisors",
    "description": "OpenAI is appointing four new advisors to help inform OpenAI‚Äôs philanthropic efforts.",
    "summary": "OpenAI is appointing four new advisors to help inform OpenAI‚Äôs philanthropic efforts.",
    "pubDate": "Tue, 15 Apr 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonprofit-commission-advisors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware",
    "description": "",
    "summary": "(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware In our previous post, Exploring Quantization Back...",
    "pubDate": "Thu, 19 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/flux-qlora",
    "thumbnail": "https://huggingface.co/blog/assets/flux-qlora/thumbnail.png"
  },
  {
    "title": "Welcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM",
    "description": "",
    "summary": "Welcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM TL;DR Today Google...",
    "pubDate": "Wed, 12 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma3",
    "thumbnail": "https://huggingface.co/blog/assets/gemma3/thumbnail.png"
  },
  {
    "title": "OpenAI announces new members to board of directors",
    "description": "Dr. Sue Desmond-Hellmann, Nicole Seligman, Fidji Simo join; Sam Altman rejoins board",
    "summary": "Dr. Sue Desmond-Hellmann, Nicole Seligman, Fidji Simo join; Sam Altman rejoins board",
    "pubDate": "Fri, 08 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-announces-new-members-to-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fast AI Model Splitting over Edge Networks",
    "description": "arXiv:2507.01041v1 Announce Type: cross Abstract: Split learning (SL) has emerged as a computationally efficient approach for artificial intelligence (AI) model training, which can alleviate device-side computational workloads. However, complex AI model architectures pose high computational complexity to obtain the optimal model splitting. In this paper, we represent an arbitrary AI model as a directed acyclic graph (DAG), and then reformulate the optimal model splitting problem as a minimum s-t cut search problem. To solve the problem, we propose a fast DAG-based model splitting algorithm, which restructures the DAG to enable the optimal model splitting identification via a maximum flow method. Theoretical analysis indicates that the proposed algorithm is optimal. Furthermore, considering AI models with block structures, we propose a block-wise model splitting algorithm to reduce computational complexity. The algorithm abstracts each block, i.e., a component consisting of multiple layers, into a single vertex, thereby obtaining the optimal model splitting via a simplified DAG. Extensive experimental results demonstrate that the proposed algorithms can determine the optimal model splitting within milliseconds, as well as reduce training delay by 24.62%-38.95% in dynamic edge networks as compared to the state-of-the-art benchmarks.",
    "summary": "arXiv:2507.01041v1 Announce Type: cross Abstract: Split learning (SL) has emerged as a computationally efficient approach for artificial intelligence (AI) model training, which can alleviate device-side computational workloads. However, complex AI model architectures pose high computational complexity to obtain the optimal model splitting. In this paper, we represent an arbitrary AI model as a directed acyclic graph (DAG), and then reformulate the optimal model splitting problem as a minimum s-t cut search problem. To solve the problem, we propose a fast DAG-based model splitting algorithm, which restructures the DAG to enable the optimal model splitting identification via a maximum flow method. Theoretical analysis indicates that the proposed algorithm is optimal. Furthermore, considering AI models with block structures, we propose a block-wise model splitting algorithm to reduce computational complexity. The algorithm abstracts each block, i.e., a component consisting of multiple layers, into a single vertex, thereby obtaining the optimal model splitting via a simplified DAG. Extensive experimental results demonstrate that the proposed algorithms can determine the optimal model splitting within milliseconds, as well as reduce training delay by 24.62%-38.95% in dynamic edge networks as compared to the state-of-the-art benchmarks.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01041",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Teaching AI models the broad strokes to sketch more like humans do",
    "description": "SketchAgent, a drawing system developed by MIT CSAIL researchers, sketches up concepts stroke-by-stroke, teaching language models to visually express concepts on their own and collaborate with humans.",
    "summary": "SketchAgent, a drawing system developed by MIT CSAIL researchers, sketches up concepts stroke-by-stroke, teaching language models to visually express concepts on their own and collaborate with humans.",
    "pubDate": "Mon, 02 Jun 2025 14:50:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/teaching-ai-models-to-sketch-more-like-humans-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-SketchAgent.jpg"
  },
  {
    "title": "Deep Dive: Vision Transformers On Hugging Face Optimum Graphcore",
    "description": "",
    "summary": "Deep Dive: Vision Transformers On Hugging Face Optimum Graphcore This blog post will show how easy i...",
    "pubDate": "Thu, 18 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/97_vision_transformers/thumbnail.png"
  },
  {
    "title": "Techniques for training large neural networks",
    "description": "Large neural networks are at the core of many recent advances in AI, but training them is a difficult engineering and research challenge which requires orchestrating a cluster of GPUs to perform a single synchronized calculation.",
    "summary": "Large neural networks are at the core of many recent advances in AI, but training them is a difficult engineering and research challenge which requires orchestrating a cluster of GPUs to perform a single synchronized calculation.",
    "pubDate": "Thu, 09 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/techniques-for-training-large-neural-networks",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ask a Techspert: What is inference?",
    "description": "Illustration of a computer chip surrounded by elements representing AI and data, including a cat's head, a wireframe cat, puzzle pieces, a bar graph, gears, and text bubbles.",
    "summary": "Illustration of a computer chip surrounded by elements representing AI and data, including a cat's head, a wireframe cat, puzzle pieces, a bar graph, gears, and text bubbles.",
    "pubDate": "Mon, 23 Jun 2025 17:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/ask-a-techspert-what-is-inference/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/InferenceHero_v3.width-1300.png"
  },
  {
    "title": "„Çπ„Éã„Éï„Ç¢„Ç¶„Éà„ÄÅRAG Ready ConverterÔºàŒ≤Ôºâ„Çí„É™„É™„Éº„Çπ„ÄÇÂÖ®„Å¶„ÅÆ„Éá„Éº„Çø„ÇíRAG„ÅåÊâ±„ÅÑ„ÇÑ„Åô„ÅÑÂΩ¢Âºè„Å∏Â§âÊèõ",
    "description": "<p>„Çπ„Éã„Éï„Ç¢„Ç¶„Éà„ÅØ„ÄÅ„ÅÇ„Çâ„ÇÜ„ÇãÂΩ¢Âºè„ÅÆ„Éï„Ç°„Ç§„É´„Çí RAG „ÅåÊâ±„ÅÑ„ÇÑ„Åô„ÅÑÂΩ¢Âºè„Å∏Â§âÊèõ„Åô„ÇãÊñ∞„Ç∑„Çπ„ÉÜ„É†„ÄåRAG Ready ConverterÔºàŒ≤Ôºâ„Äç„ÇíÂÖ¨Èñã„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà „Çπ„Éã„Éï„Ç¢„Ç¶„Éà„ÅØ„ÄÅ„ÅÇ„Çâ„ÇÜ„ÇãÂΩ¢Âºè„ÅÆ„Éï„Ç°„Ç§„É´„ÇíRA [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/sniffout-rag-ready-converter/'>„Çπ„Éã„Éï„Ç¢„Ç¶„Éà„ÄÅRAG Ready ConverterÔºàŒ≤Ôºâ„Çí„É™„É™„Éº„Çπ„ÄÇÂÖ®„Å¶„ÅÆ„Éá„Éº„Çø„ÇíRAG„ÅåÊâ±„ÅÑ„ÇÑ„Åô„ÅÑÂΩ¢Âºè„Å∏Â§âÊèõ</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>„Çπ„Éã„Éï„Ç¢„Ç¶„Éà„ÅØ„ÄÅ„ÅÇ„Çâ„ÇÜ„ÇãÂΩ¢Âºè„ÅÆ„Éï„Ç°„Ç§„É´„Çí RAG „ÅåÊâ±„ÅÑ„ÇÑ„Åô„ÅÑÂΩ¢Âºè„Å∏Â§âÊèõ„Åô„ÇãÊñ∞„Ç∑„Çπ„ÉÜ„É†„ÄåRAG Ready ConverterÔºàŒ≤Ôºâ„Äç„ÇíÂÖ¨Èñã„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà „Çπ„Éã„Éï„Ç¢„Ç¶„Éà„ÅØ„ÄÅ„ÅÇ„Çâ„ÇÜ„ÇãÂΩ¢Âºè„ÅÆ„Éï„Ç°„Ç§„É´„ÇíRA [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/sniffout-rag-ready-converter/'>„Çπ„Éã„Éï„Ç¢„Ç¶„Éà„ÄÅRAG Ready ConverterÔºàŒ≤Ôºâ„Çí„É™„É™„Éº„Çπ„ÄÇÂÖ®„Å¶„ÅÆ„Éá„Éº„Çø„ÇíRAG„ÅåÊâ±„ÅÑ„ÇÑ„Åô„ÅÑÂΩ¢Âºè„Å∏Â§âÊèõ</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Tue, 01 Jul 2025 08:57:11 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/sniffout-rag-ready-converter/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/ragready.png"
  },
  {
    "title": "Scaling laws for neural language models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 23 Jan 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-laws-for-neural-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Concat-ID: Towards Universal Identity-Preserving Video Synthesis",
    "description": "arXiv:2503.14151v3 Announce Type: replace-cross Abstract: We present Concat-ID, a unified framework for identity-preserving video generation. Concat-ID employs variational autoencoders to extract image features, which are then concatenated with video latents along the sequence dimension. It relies exclusively on inherent 3D self-attention mechanisms to incorporate them, eliminating the need for additional parameters or modules. A novel cross-video pairing strategy and a multi-stage training regimen are introduced to balance identity consistency and facial editability while enhancing video naturalness. Extensive experiments demonstrate Concat-ID's superiority over existing methods in both single and multi-identity generation, as well as its seamless scalability to multi-subject scenarios, including virtual try-on and background-controllable generation. Concat-ID establishes a new benchmark for identity-preserving video synthesis, providing a versatile and scalable solution for a wide range of applications.",
    "summary": "arXiv:2503.14151v3 Announce Type: replace-cross Abstract: We present Concat-ID, a unified framework for identity-preserving video generation. Concat-ID employs variational autoencoders to extract image features, which are then concatenated with video latents along the sequence dimension. It relies exclusively on inherent 3D self-attention mechanisms to incorporate them, eliminating the need for additional parameters or modules. A novel cross-video pairing strategy and a multi-stage training regimen are introduced to balance identity consistency and facial editability while enhancing video naturalness. Extensive experiments demonstrate Concat-ID's superiority over existing methods in both single and multi-identity generation, as well as its seamless scalability to multi-subject scenarios, including virtual try-on and background-controllable generation. Concat-ID establishes a new benchmark for identity-preserving video synthesis, providing a versatile and scalable solution for a wide range of applications.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.14151",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Glow: Better reversible generative models",
    "description": "We introduce¬†Glow, a reversible generative model which uses invertible 1x1 convolutions. It extends¬†previous¬†work¬†on reversible generative models and simplifies the architecture. Our model can generate realistic high resolution images, supports efficient sampling, and discovers features that can be used to manipulate attributes of data. We‚Äôre releasing code for the model and an online visualization tool so people can explore and build on these¬†results.",
    "summary": "We introduce¬†Glow, a reversible generative model which uses invertible 1x1 convolutions. It extends¬†previous¬†work¬†on reversible generative models and simplifies the architecture. Our model can generate realistic high resolution images, supports efficient sampling, and discovers features that can be used to manipulate attributes of data. We‚Äôre releasing code for the model and an online visualization tool so people can explore and build on these¬†results.",
    "pubDate": "Mon, 09 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/glow",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Variational option discovery algorithms",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 26 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variational-option-discovery-algorithms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AMD + ü§ó: Large Language Models Out-of-the-Box Acceleration with AMD GPU",
    "description": "",
    "summary": "AMD + ü§ó: Large Language Models Out-of-the-Box Acceleration with AMD GPU Earlier this year, AMD and H...",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-optimum-amd",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "LangGraph CodeAct„ÇíE2B„ÅÆÂÆâÂÖ®„Å™‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åô",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØÂÖàÊó•LangChain„Åã„ÇâÁô∫Ë°®„Åï„Çå„ÅüLangGraph CodeAct„ÇíE2B„ÅÆ‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åó„Å¶„Åø„Çà„ÅÜ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇCodeAct„ÅØÊúÄËøëÊ≥®ÁõÆ„ÇíÈõÜ„ÇÅ„Å¶„ÅÑ„ÇãAI Agent„ÅÆTool [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5652' rel='nofollow'>LangGraph CodeAct„ÇíE2B„ÅÆÂÆâÂÖ®„Å™‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åô</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØÂÖàÊó•LangChain„Åã„ÇâÁô∫Ë°®„Åï„Çå„ÅüLangGraph CodeAct„ÇíE2B„ÅÆ‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åó„Å¶„Åø„Çà„ÅÜ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇCodeAct„ÅØÊúÄËøëÊ≥®ÁõÆ„ÇíÈõÜ„ÇÅ„Å¶„ÅÑ„ÇãAI Agent„ÅÆTool [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5652' rel='nofollow'>LangGraph CodeAct„ÇíE2B„ÅÆÂÆâÂÖ®„Å™‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åô</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Thu, 17 Apr 2025 01:11:36 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5652",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "Deploy LLMs with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Deploy LLMs with Hugging Face Inference Endpoints Open-source LLMs like Falcon, (Open-)LLaMA, X-Gen,...",
    "pubDate": "Tue, 04 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints-llm",
    "thumbnail": "https://huggingface.co/blog/assets/155_inference_endpoints_llm/thumbnail.jpg"
  },
  {
    "title": "SmolVLM Grows Smaller ‚Äì Introducing the 250M & 500M Models!",
    "description": "",
    "summary": "SmolVLM Grows Smaller ‚Äì Introducing the 250M & 500M Models! TLDR We‚Äôre excited to announce two new a...",
    "pubDate": "Thu, 23 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolervlm",
    "thumbnail": "https://huggingface.co/blog/assets/smolervlm/banner.png"
  },
  {
    "title": "How we're supporting better tropical cyclone prediction with AI",
    "description": "We‚Äôre launching Weather Lab, featuring our experimental cyclone predictions, and we‚Äôre partnering with the U.S. National Hurricane Center to support their forecasts and warnings this cyclone season.",
    "summary": "We‚Äôre launching Weather Lab, featuring our experimental cyclone predictions, and we‚Äôre partnering with the U.S. National Hurricane Center to support their forecasts and warnings this cyclone season.",
    "pubDate": "Thu, 12 Jun 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/weather-lab-cyclone-predictions-with-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/4emGMNrEdaydebppYDiyQMNhXtgUFr8VvrKhVItMHENrxeWmWO9yqhteSj2fe25lxkiZAu7vOZZcsXPDLg0O-LPSvk6CS1I8E2-GdjtoN_2ViJOY=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI‚Äôs comment to the NTIA on open model weights",
    "description": "OpenAI‚Äôs comment to the NTIA on open model weights This comment was submitted by OpenAI in response to NTIA‚Äôs March 2024 Request for Information on Dual-Use Foundation Models with Widely Available Weights.",
    "summary": "OpenAI‚Äôs comment to the NTIA on open model weights This comment was submitted by OpenAI in response to NTIA‚Äôs March 2024 Request for Information on Dual-Use Foundation Models with Widely Available Weights.",
    "pubDate": "Wed, 27 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-s-comment-to-the-ntia-on-open-model-weights",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Platform on the AWS Marketplace: Pay with your AWS Account",
    "description": "",
    "summary": "Hugging Face Hub on the AWS Marketplace: Pay with your AWS Account The Hugging Face Hub has landed o...",
    "pubDate": "Thu, 10 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aws-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/158_aws_marketplace/thumbnail.jpg"
  },
  {
    "title": "Faster Stable Diffusion with Core ML on iPhone, iPad, and Mac",
    "description": "",
    "summary": "Faster Stable Diffusion with Core ML on iPhone, iPad, and Mac WWDC‚Äô23 (Apple Worldwide Developers Co...",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-diffusers-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/149_fast_diffusers_coreml/thumbnail.png"
  },
  {
    "title": "Sensing Cardiac Health Across Scenarios and Devices: A Multi-Modal Foundation Model Pretrained on Heterogeneous Data from 1.7 Million Individuals",
    "description": "arXiv:2507.01045v1 Announce Type: cross Abstract: Cardiac biosignals, such as electrocardiograms (ECG) and photoplethysmograms (PPG), are of paramount importance for the diagnosis, prevention, and management of cardiovascular diseases, and have been extensively used in a variety of clinical tasks. Conventional deep learning approaches for analyzing these signals typically rely on homogeneous datasets and static bespoke models, limiting their robustness and generalizability across diverse clinical settings and acquisition protocols. In this study, we present a cardiac sensing foundation model (CSFM) that leverages advanced transformer architectures and a generative, masked pretraining strategy to learn unified representations from vast, heterogeneous health records. Our model is pretrained on an innovative multi-modal integration of data from multiple large-scale datasets (including MIMIC-III-WDB, MIMIC-IV-ECG, and CODE), comprising cardiac signals and the corresponding clinical or machine-generated text reports from approximately 1.7 million individuals. We demonstrate that the embeddings derived from our CSFM not only serve as effective feature extractors across diverse cardiac sensing scenarios, but also enable seamless transfer learning across varying input configurations and sensor modalities. Extensive evaluations across diagnostic tasks, demographic information recognition, vital sign measurement, clinical outcome prediction, and ECG question answering reveal that CSFM consistently outperforms traditional one-modal-one-task approaches. Notably, CSFM exhibits robust performance across multiple ECG lead configurations from standard 12-lead systems to single-lead setups, and in scenarios where only ECG, only PPG, or a combination thereof is available. These findings highlight the potential of CSFM as a versatile and scalable solution, for comprehensive cardiac monitoring.",
    "summary": "arXiv:2507.01045v1 Announce Type: cross Abstract: Cardiac biosignals, such as electrocardiograms (ECG) and photoplethysmograms (PPG), are of paramount importance for the diagnosis, prevention, and management of cardiovascular diseases, and have been extensively used in a variety of clinical tasks. Conventional deep learning approaches for analyzing these signals typically rely on homogeneous datasets and static bespoke models, limiting their robustness and generalizability across diverse clinical settings and acquisition protocols. In this study, we present a cardiac sensing foundation model (CSFM) that leverages advanced transformer architectures and a generative, masked pretraining strategy to learn unified representations from vast, heterogeneous health records. Our model is pretrained on an innovative multi-modal integration of data from multiple large-scale datasets (including MIMIC-III-WDB, MIMIC-IV-ECG, and CODE), comprising cardiac signals and the corresponding clinical or machine-generated text reports from approximately 1.7 million individuals. We demonstrate that the embeddings derived from our CSFM not only serve as effective feature extractors across diverse cardiac sensing scenarios, but also enable seamless transfer learning across varying input configurations and sensor modalities. Extensive evaluations across diagnostic tasks, demographic information recognition, vital sign measurement, clinical outcome prediction, and ECG question answering reveal that CSFM consistently outperforms traditional one-modal-one-task approaches. Notably, CSFM exhibits robust performance across multiple ECG lead configurations from standard 12-lead systems to single-lead setups, and in scenarios where only ECG, only PPG, or a combination thereof is available. These findings highlight the potential of CSFM as a versatile and scalable solution, for comprehensive cardiac monitoring.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01045",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tuning MMS Adapter Models for Multi-Lingual ASR",
    "description": "",
    "summary": "Fine-tuning MMS Adapter Models for Multi-Lingual ASR New (06/2023): This blog post is strongly inspi...",
    "pubDate": "Mon, 19 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mms_adapters",
    "thumbnail": "https://huggingface.co/blog/assets/151_mms/mms_map.png"
  },
  {
    "title": "Making AI-generated code more accurate in any language",
    "description": "A new technique automatically guides an LLM toward outputs that adhere to the rules of whatever programming language or other format is being used.",
    "summary": "A new technique automatically guides an LLM toward outputs that adhere to the rules of whatever programming language or other format is being used.",
    "pubDate": "Fri, 18 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/making-ai-generated-code-more-accurate-0418",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Probalistic-Control-compressed.gif"
  },
  {
    "title": "Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants",
    "description": "arXiv:2507.01548v1 Announce Type: cross Abstract: This paper explores how older adults, particularly aging migrants in urban China, can engage AI-assisted co-creation to express personal narratives that are often fragmented, underrepresented, or difficult to verbalize. Through a pilot workshop combining oral storytelling and the symbolic reconstruction of Hanzi, participants shared memories of migration and recreated new character forms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM), together with physical materials. Supported by human facilitation and a soft AI presence, participants transformed lived experience into visual and tactile expressions without requiring digital literacy. This approach offers new perspectives on human-AI collaboration and aging by repositioning AI not as a content producer but as a supportive mechanism, and by supporting narrative agency within sociotechnical systems.",
    "summary": "arXiv:2507.01548v1 Announce Type: cross Abstract: This paper explores how older adults, particularly aging migrants in urban China, can engage AI-assisted co-creation to express personal narratives that are often fragmented, underrepresented, or difficult to verbalize. Through a pilot workshop combining oral storytelling and the symbolic reconstruction of Hanzi, participants shared memories of migration and recreated new character forms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM), together with physical materials. Supported by human facilitation and a soft AI presence, participants transformed lived experience into visual and tactile expressions without requiring digital literacy. This approach offers new perspectives on human-AI collaboration and aging by repositioning AI not as a content producer but as a supportive mechanism, and by supporting narrative agency within sociotechnical systems.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01548",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing vision to the fine-tuning API",
    "description": "Developers can now fine-tune GPT-4o with images and text to improve vision capabilities",
    "summary": "Developers can now fine-tune GPT-4o with images and text to improve vision capabilities",
    "pubDate": "Tue, 01 Oct 2024 10:04:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-vision-to-the-fine-tuning-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-Tune Wav2Vec2 for English ASR with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune Wav2Vec2 for English ASR with ü§ó Transformers Wav2Vec2 is a pretrained model for Automatic ...",
    "pubDate": "Fri, 12 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-wav2vec2-english",
    "thumbnail": "https://huggingface.co/blog/assets/15_fine_tune_wav2vec2/wav2vec2.png"
  },
  {
    "title": "SpecCLIP: Aligning and Translating Spectroscopic Measurements for Stars",
    "description": "arXiv:2507.01939v1 Announce Type: cross Abstract: In recent years, large language models (LLMs) have transformed natural language understanding through vast datasets and large-scale parameterization. Inspired by this success, we present SpecCLIP, a foundation model framework that extends LLM-inspired methodologies to stellar spectral analysis. Stellar spectra, akin to structured language, encode rich physical and chemical information about stars. By training foundation models on large-scale spectral datasets, our goal is to learn robust and informative embeddings that support diverse downstream applications. As a proof of concept, SpecCLIP involves pre-training on two spectral types--LAMOST low-resolution and Gaia XP--followed by contrastive alignment using the CLIP (Contrastive Language-Image Pre-training) framework, adapted to associate spectra from different instruments. This alignment is complemented by auxiliary decoders that preserve spectrum-specific information and enable translation (prediction) between spectral types, with the former achieved by maximizing mutual information between embeddings and input spectra. The result is a cross-spectrum framework enabling intrinsic calibration and flexible applications across instruments. We demonstrate that fine-tuning these models on moderate-sized labeled datasets improves adaptability to tasks such as stellar-parameter estimation and chemical-abundance determination. SpecCLIP also enhances the accuracy and precision of parameter estimates benchmarked against external survey data. Additionally, its similarity search and cross-spectrum prediction capabilities offer potential for anomaly detection. Our results suggest that contrastively trained foundation models enriched with spectrum-aware decoders can advance precision stellar spectroscopy.",
    "summary": "arXiv:2507.01939v1 Announce Type: cross Abstract: In recent years, large language models (LLMs) have transformed natural language understanding through vast datasets and large-scale parameterization. Inspired by this success, we present SpecCLIP, a foundation model framework that extends LLM-inspired methodologies to stellar spectral analysis. Stellar spectra, akin to structured language, encode rich physical and chemical information about stars. By training foundation models on large-scale spectral datasets, our goal is to learn robust and informative embeddings that support diverse downstream applications. As a proof of concept, SpecCLIP involves pre-training on two spectral types--LAMOST low-resolution and Gaia XP--followed by contrastive alignment using the CLIP (Contrastive Language-Image Pre-training) framework, adapted to associate spectra from different instruments. This alignment is complemented by auxiliary decoders that preserve spectrum-specific information and enable translation (prediction) between spectral types, with the former achieved by maximizing mutual information between embeddings and input spectra. The result is a cross-spectrum framework enabling intrinsic calibration and flexible applications across instruments. We demonstrate that fine-tuning these models on moderate-sized labeled datasets improves adaptability to tasks such as stellar-parameter estimation and chemical-abundance determination. SpecCLIP also enhances the accuracy and precision of parameter estimates benchmarked against external survey data. Additionally, its similarity search and cross-spectrum prediction capabilities offer potential for anomaly detection. Our results suggest that contrastively trained foundation models enriched with spectrum-aware decoders can advance precision stellar spectroscopy.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01939",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Building an AI WebTV",
    "description": "",
    "summary": "Building an AI WebTV The AI WebTV is an experimental demo to showcase the latest advancements in aut...",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-webtv",
    "thumbnail": "https://huggingface.co/blog/assets/156_ai_webtv/thumbnail.gif"
  },
  {
    "title": "LaunchDarkly's approach to AI-powered product management",
    "description": "A conversation with Claire Vo, Chief Product Officer of LaunchDarkly, about the changing role of product managers, her anti-to-do list, and building AI-native teams.",
    "summary": "A conversation with Claire Vo, Chief Product Officer of LaunchDarkly, about the changing role of product managers, her anti-to-do list, and building AI-native teams.",
    "pubDate": "Tue, 04 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/launchdarkly-claire-vo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions",
    "description": "Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model's original instructions with their own malicious prompts.",
    "summary": "Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model's original instructions with their own malicious prompts.",
    "pubDate": "Fri, 19 Apr 2024 19:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-instruction-hierarchy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Universal Assisted Generation: Faster Decoding with Any Assistant Model",
    "description": "",
    "summary": "Universal Assisted Generation: Faster Decoding with Any Assistant Model TL;DR: Many LLMs such as gem...",
    "pubDate": "Tue, 29 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/universal_assisted_generation",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Faulty reward functions in the wild",
    "description": "Reinforcement learning algorithms can break in surprising, counterintuitive ways. In this post we‚Äôll explore one failure mode, which is where you misspecify your reward function.",
    "summary": "Reinforcement learning algorithms can break in surprising, counterintuitive ways. In this post we‚Äôll explore one failure mode, which is where you misspecify your reward function.",
    "pubDate": "Wed, 21 Dec 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/faulty-reward-functions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How to train a Language Model with Megatron-LM",
    "description": "",
    "summary": "How to train a Language Model with Megatron-LM Training large language models in Pytorch requires mo...",
    "pubDate": "Wed, 07 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/megatron-training",
    "thumbnail": "https://huggingface.co/blog/assets/100_megatron_training/thumbnail.png"
  },
  {
    "title": "Summarizing books with human feedback",
    "description": "Scaling human oversight of AI systems for tasks that are difficult to¬†evaluate.",
    "summary": "Scaling human oversight of AI systems for tasks that are difficult to¬†evaluate.",
    "pubDate": "Thu, 23 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/summarizing-books",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations",
    "description": "arXiv:2505.08195v2 Announce Type: replace-cross Abstract: We have developed Aitomia - a platform powered by AI to assist in performing AI-driven atomistic and quantum chemical (QC) simulations. This evolving intelligent assistant platform is equipped with chatbots and AI agents to help experts and guide non-experts in setting up and running the atomistic simulations, monitoring their computation status, analyzing the simulation results, and summarizing them for the user in text and graphical forms. We achieve these goals by exploiting open-source large language models (LLMs, original and fine-tuned), rule-based agents, and a retrieval-augmented generation (RAG) system. Aitomia leverages the versatility of our MLatom ecosystem, supporting AI-enhanced computational chemistry tasks ranging from ground- to excited-state calculations such as geometry optimizations, thermochemistry, and spectra calculations. Aitomia is the first intelligent assistant publicly accessible online on a cloud computing platform for atomistic simulations of broad scope (Aitomistic Hub at https://aitomistic.xyz), while it may also be deployed locally as described at http://mlatom.com/aitomia. Aitomia is expected to lower the barrier to performing atomistic simulations, democratizing simulations, and accelerating research and development in the relevant fields.",
    "summary": "arXiv:2505.08195v2 Announce Type: replace-cross Abstract: We have developed Aitomia - a platform powered by AI to assist in performing AI-driven atomistic and quantum chemical (QC) simulations. This evolving intelligent assistant platform is equipped with chatbots and AI agents to help experts and guide non-experts in setting up and running the atomistic simulations, monitoring their computation status, analyzing the simulation results, and summarizing them for the user in text and graphical forms. We achieve these goals by exploiting open-source large language models (LLMs, original and fine-tuned), rule-based agents, and a retrieval-augmented generation (RAG) system. Aitomia leverages the versatility of our MLatom ecosystem, supporting AI-enhanced computational chemistry tasks ranging from ground- to excited-state calculations such as geometry optimizations, thermochemistry, and spectra calculations. Aitomia is the first intelligent assistant publicly accessible online on a cloud computing platform for atomistic simulations of broad scope (Aitomistic Hub at https://aitomistic.xyz), while it may also be deployed locally as described at http://mlatom.com/aitomia. Aitomia is expected to lower the barrier to performing atomistic simulations, democratizing simulations, and accelerating research and development in the relevant fields.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.08195",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GPT-3 powers the next generation of apps",
    "description": "Over 300 applications are delivering GPT-3‚Äìpowered search, conversation, text completion, and other advanced AI features through our¬†API.",
    "summary": "Over 300 applications are delivering GPT-3‚Äìpowered search, conversation, text completion, and other advanced AI features through our¬†API.",
    "pubDate": "Thu, 25 Mar 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-apps",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerated Inference with Optimum and Transformers Pipelines",
    "description": "",
    "summary": "Accelerated Inference with Optimum and Transformers Pipelines Inference has landed in Optimum with s...",
    "pubDate": "Tue, 10 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-inference",
    "thumbnail": "https://huggingface.co/blog/assets/66_optimum_inference/thumbnail.png"
  },
  {
    "title": "1 Billion Classifications",
    "description": "",
    "summary": "1 Billion Classifications You‚Äôve optimized your model. Your pipeline is running smoothly. But now, y...",
    "pubDate": "Thu, 13 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/billion-classifications",
    "thumbnail": "https://huggingface.co/blog/assets/billion-classifications/billion-classifications-thumbnail.png"
  },
  {
    "title": "Few-shot learning in practice: GPT-NEO and the ü§ó Accelerated Inference API",
    "description": "",
    "summary": "Few-shot learning in practice: GPT-Neo and the ü§ó Accelerated Inference API In many Machine Learning ...",
    "pubDate": "Thu, 03 Jun 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Gemini 2.0 is now available to everyone",
    "description": "We‚Äôre announcing new updates to Gemini 2.0 Flash, plus introducing Gemini 2.0 Flash-Lite and Gemini 2.0 Pro Experimental.",
    "summary": "We‚Äôre announcing new updates to Gemini 2.0 Flash, plus introducing Gemini 2.0 Flash-Lite and Gemini 2.0 Pro Experimental.",
    "pubDate": "Wed, 05 Feb 2025 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-2-0-is-now-available-to-everyone/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini_28.01.25_keyword_social.width-1300.png"
  },
  {
    "title": "A Content and Product Partnership with Vox Media",
    "description": "In a multi-faceted agreement, Vox Media‚Äôs content will enhance the output of OpenAI‚Äôs ChatGPT, and the company will build on OpenAI‚Äôs technology to develop products to better serve its audiences and advertisers.",
    "summary": "In a multi-faceted agreement, Vox Media‚Äôs content will enhance the output of OpenAI‚Äôs ChatGPT, and the company will build on OpenAI‚Äôs technology to develop products to better serve its audiences and advertisers.",
    "pubDate": "Wed, 29 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-content-and-product-partnership-with-vox-media",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building a Playlist Generator with Sentence Transformers",
    "description": "",
    "summary": "Building a Playlist Generator with Sentence Transformers A short while ago I published a playlist ge...",
    "pubDate": "Wed, 13 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/playlist-generator",
    "thumbnail": "https://huggingface.co/blog/assets/87_playlist_generator/thumbnail.png"
  },
  {
    "title": "Announcing Google DeepMind",
    "description": "DeepMind and the Brain team from Google Research will join forces to accelerate progress towards a world in which AI helps solve the biggest challenges facing humanity.",
    "summary": "DeepMind and the Brain team from Google Research will join forces to accelerate progress towards a world in which AI helps solve the biggest challenges facing humanity.",
    "pubDate": "Thu, 20 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/announcing-google-deepmind/",
    "thumbnail": "https://lh3.googleusercontent.com/MNdJdEO1VpepmU25h9OTpnMr9hxe6NScc1ZWlerWf5WtOYMnHETsPEWKqvG36zQv5CGflTOHAKG_JbADpmLrh8Mrpa91B95U6bs0isMSbTUerT-qT38=w1200-h630-n-nu"
  },
  {
    "title": "LEDOM: An Open and Fundamental Reverse Language Model",
    "description": "arXiv:2507.01335v1 Announce Type: cross Abstract: We introduce LEDOM, the first purely reverse language model, trained autoregressively on 435B tokens with 2B and 7B parameter variants, which processes sequences in reverse temporal order through previous token prediction. For the first time, we present the reverse language model as a potential foundational model across general tasks, accompanied by a set of intriguing examples and insights. Based on LEDOM, we further introduce a novel application: Reverse Reward, where LEDOM-guided reranking of forward language model outputs leads to substantial performance improvements on mathematical reasoning tasks. This approach leverages LEDOM's unique backward reasoning capability to refine generation quality through posterior evaluation. Our findings suggest that LEDOM exhibits unique characteristics with broad application potential. We will release all models, training code, and pre-training data to facilitate future research.",
    "summary": "arXiv:2507.01335v1 Announce Type: cross Abstract: We introduce LEDOM, the first purely reverse language model, trained autoregressively on 435B tokens with 2B and 7B parameter variants, which processes sequences in reverse temporal order through previous token prediction. For the first time, we present the reverse language model as a potential foundational model across general tasks, accompanied by a set of intriguing examples and insights. Based on LEDOM, we further introduce a novel application: Reverse Reward, where LEDOM-guided reranking of forward language model outputs leads to substantial performance improvements on mathematical reasoning tasks. This approach leverages LEDOM's unique backward reasoning capability to refine generation quality through posterior evaluation. Our findings suggest that LEDOM exhibits unique characteristics with broad application potential. We will release all models, training code, and pre-training data to facilitate future research.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01335",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Skops",
    "description": "",
    "summary": "Introducing Skops Introducing Skops At Hugging Face, we are working on tackling various problems in ...",
    "pubDate": "Fri, 12 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/skops",
    "thumbnail": "https://huggingface.co/blog/assets/94_skops/introducing_skops.png"
  },
  {
    "title": "Announcing the Open Source AI Game Jam üéÆ",
    "description": "",
    "summary": "Announcing the Open Source AI Game Jam üéÆ Unleash Your Creativity with AI Tools and make a game in a ...",
    "pubDate": "Thu, 01 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/game-jam",
    "thumbnail": "https://huggingface.co/blog/assets/145_gamejam/thumbnail.png"
  },
  {
    "title": "Rethinking the Illusion of Thinking",
    "description": "arXiv:2507.01231v1 Announce Type: new Abstract: Earlier this year, Apple ignited controversy by publishing 'The Illusion of Thinking,' prompting heated debate within the AI community. Critics seized upon the findings as conclusive evidence that Large Reasoning Models (LRMs) lack genuine reasoning capabilities, branding them as mere stochastic parrots. Meanwhile, defenders-spearheaded by Lawsen et al. (2025)-fired back, condemning the experimental setup as flawed and the conclusions overstated. We clarify this debate by replicating and refining two of the original study's most contentious benchmarks: Towers of Hanoi and River Crossing. By introducing incremental stepwise prompting and agentic collaborative dialogue, we show that previously reported failures solving the Towers of Hanoi were not purely result of output constraints, but also partly a result of cognition limitations: LRMs still stumble when complexity rises moderately (around 8 disks). Moreover, the River Crossing results initially heralded as catastrophic failures turn out to hinge upon testing unsolvable configurations. Once we limit tests strictly to solvable problems-LRMs effortlessly solve large instances involving over 100 agent pairs. Our findings ultimately defy simplistic narratives: today's LRMs are stochastic, RL-tuned searchers in a discrete state space we barely understand. Real progress in symbolic, long-horizon reasoning demands mapping that terrain through fine-grained ablations like those introduced here.",
    "summary": "arXiv:2507.01231v1 Announce Type: new Abstract: Earlier this year, Apple ignited controversy by publishing 'The Illusion of Thinking,' prompting heated debate within the AI community. Critics seized upon the findings as conclusive evidence that Large Reasoning Models (LRMs) lack genuine reasoning capabilities, branding them as mere stochastic parrots. Meanwhile, defenders-spearheaded by Lawsen et al. (2025)-fired back, condemning the experimental setup as flawed and the conclusions overstated. We clarify this debate by replicating and refining two of the original study's most contentious benchmarks: Towers of Hanoi and River Crossing. By introducing incremental stepwise prompting and agentic collaborative dialogue, we show that previously reported failures solving the Towers of Hanoi were not purely result of output constraints, but also partly a result of cognition limitations: LRMs still stumble when complexity rises moderately (around 8 disks). Moreover, the River Crossing results initially heralded as catastrophic failures turn out to hinge upon testing unsolvable configurations. Once we limit tests strictly to solvable problems-LRMs effortlessly solve large instances involving over 100 agent pairs. Our findings ultimately defy simplistic narratives: today's LRMs are stochastic, RL-tuned searchers in a discrete state space we barely understand. Real progress in symbolic, long-horizon reasoning demands mapping that terrain through fine-grained ablations like those introduced here.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01231",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "New in ChatGPT for Business: March 2025",
    "description": "Join us as we share our latest releases and how ChatGPT is becoming more interactive, customized to the way your teams work, and agentic.",
    "summary": "Join us as we share our latest releases and how ChatGPT is becoming more interactive, customized to the way your teams work, and agentic.",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/new-in-chatgpt-for-work-march-updates-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generating Stories: AI for Game Development #5",
    "description": "",
    "summary": "Generating Stories: AI for Game Development #5 Welcome to AI for Game Development! In this series, w...",
    "pubDate": "Tue, 07 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-5",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail5.png"
  },
  {
    "title": "Argilla 2.4: Easily Build Fine-Tuning and Evaluation datasets on the Hub ‚Äî No Code Required",
    "description": "",
    "summary": "Argilla 2.4: Easily Build Fine-Tuning and Evaluation Datasets on the Hub ‚Äî No Code Required We are i...",
    "pubDate": "Mon, 04 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/argilla-ui-hub",
    "thumbnail": "https://huggingface.co/blog/assets/argilla-ui-hub/thumbnail.png"
  },
  {
    "title": "Envisioning a future where health care tech leaves some behind",
    "description": "The winning essay of the Envisioning the Future of Computing Prize puts health care disparities at the forefront.",
    "summary": "The winning essay of the Envisioning the Future of Computing Prize puts health care disparities at the forefront.",
    "pubDate": "Mon, 09 Jun 2025 16:10:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/envisioning-future-where-health-care-tech-leaves-some-behind-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/Annaliese%20statue%20crop_v2.jpg"
  },
  {
    "title": "OpenAI en France",
    "description": "Our first office in continental Europe",
    "summary": "Our first office in continental Europe",
    "pubDate": "Fri, 15 Nov 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-en-france",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face on PyTorch / XLA TPUs",
    "description": "",
    "summary": "Hugging Face on PyTorch / XLA TPUs: Faster and cheaper training Training Your Favorite Transformers ...",
    "pubDate": "Tue, 09 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-xla",
    "thumbnail": "https://huggingface.co/blog/assets/13_pytorch_xla/pytorch_xla_thumbnail.png"
  },
  {
    "title": "OpenAI and Reddit Partnership",
    "description": "OpenAI and Reddit Partnership We‚Äôre bringing Reddit‚Äôs unique content to ChatGPT and our products.",
    "summary": "OpenAI and Reddit Partnership We‚Äôre bringing Reddit‚Äôs unique content to ChatGPT and our products.",
    "pubDate": "Thu, 16 May 2024 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-reddit-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face x LangChain : A new partner package in LangChain",
    "description": "",
    "summary": "Hugging Face x LangChain : A new partner package in LangChain We are thrilled to announce the launch...",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/langchain",
    "thumbnail": "https://huggingface.co/blog/assets/langchain_huggingface/thumbnail.png"
  },
  {
    "title": "Image GPT",
    "description": "We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image¬†completions¬†and¬†samples. By establishing a correlation between sample quality and image classification accuracy, we show that our best generative model also contains features competitive with top convolutional nets in the unsupervised¬†setting.",
    "summary": "We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image¬†completions¬†and¬†samples. By establishing a correlation between sample quality and image classification accuracy, we show that our best generative model also contains features competitive with top convolutional nets in the unsupervised¬†setting.",
    "pubDate": "Wed, 17 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/image-gpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our response to the UK‚Äôs copyright consultation",
    "description": "Recommendations for pro-innovation policies that can help make the UK the AI capital of Europe.",
    "summary": "Recommendations for pro-innovation policies that can help make the UK the AI capital of Europe.",
    "pubDate": "Wed, 02 Apr 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-uk-copyright-consultation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How to Install and Use the Hugging Face Unity API",
    "description": "",
    "summary": "How to Install and Use the Hugging Face Unity API The Hugging Face Unity API is an easy-to-use integ...",
    "pubDate": "Mon, 01 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-api",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-api-thumbnail.png"
  },
  {
    "title": "Robust adversarial inputs",
    "description": "We‚Äôve created images that reliably fool neural network classifiers when viewed from varied scales and perspectives. This challenges a claim from last week that self-driving cars would be hard to trick maliciously since they capture images from multiple scales, angles, perspectives, and the like.",
    "summary": "We‚Äôve created images that reliably fool neural network classifiers when viewed from varied scales and perspectives. This challenges a claim from last week that self-driving cars would be hard to trick maliciously since they capture images from multiple scales, angles, perspectives, and the like.",
    "pubDate": "Mon, 17 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/robust-adversarial-inputs",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Agents Are Here. What Now?",
    "description": "",
    "summary": "AI Agents Are Here. What Now? Introduction The sudden, rapid advancement of LLM capabilities ‚Äì such ...",
    "pubDate": "Mon, 13 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-7",
    "thumbnail": "https://huggingface.co/blog/assets/190_ethics-soc-7/thumbnail.png"
  },
  {
    "title": "BrowseComp: a benchmark for browsing agents",
    "description": "BrowseComp: a benchmark for browsing agents.",
    "summary": "BrowseComp: a benchmark for browsing agents.",
    "pubDate": "Thu, 10 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/browsecomp",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Getting Started With Embeddings",
    "description": "",
    "summary": "Getting Started With Embeddings Check out this tutorial with the Notebook Companion: Understanding e...",
    "pubDate": "Thu, 23 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/getting-started-with-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/80_getting_started_with_embeddings/thumbnail.png"
  },
  {
    "title": "Exploring institutions for global AI governance",
    "description": "New white paper investigates models and functions of international institutions that could help manage opportunities and mitigate risks of advanced AI.",
    "summary": "New white paper investigates models and functions of international institutions that could help manage opportunities and mitigate risks of advanced AI.",
    "pubDate": "Tue, 11 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/exploring-institutions-for-global-ai-governance/",
    "thumbnail": "https://lh3.googleusercontent.com/Y9dCJWt3ky1gjizSCHb17S3iHZ_Q2v6hoC8SaBgq9f7e5yW15pzg7BGNoCIaklP6f34uioxwHY0gbzehAMe5HhXBvBBKBKNIcOo7ugjFeLENTWMqNQ=w1200-h630-n-nu"
  },
  {
    "title": "Transfer from simulation to real world through learning deep inverse dynamics model",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 11 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/transfer-from-simulation-to-real-world-through-learning-deep-inverse-dynamics-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Empowering a global org with ChatGPT",
    "description": "Empowering a global org with ChatGPT",
    "summary": "Empowering a global org with ChatGPT",
    "pubDate": "Thu, 21 Nov 2024 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bbva",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ilya Sutskever to leave OpenAI, Jakub Pachocki announced as Chief Scientist",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 14 May 2024 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jakub-pachocki-announced-as-chief-scientist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluation of a Foundational Model and Stochastic Models for Forecasting Sporadic or Spiky Production Outages of High-Performance Machine Learning Services",
    "description": "arXiv:2507.01067v1 Announce Type: cross Abstract: Time series forecasting models have diverse real world applications (e.g., from electricity metrics to software workload). Latest foundational models trained for time series forecasting show strengths (e.g., for long sequences and in zero-shot settings). However, foundational model was not yet used for forecasting rare, spiky events, i.e., a challenging target because those are a corner case of extreme events. In this paper, we optimize a state-of-the-art foundational model to forecast sporadic or spiky production outages of high-performance machine learning services powering billions of client devices. We evaluate the forecasting errors of the foundational model compared with classical stochastic forecasting models (e.g., moving average and autoregressive). The analysis helps us understand how each of the evaluated models performs for the sporadic or spiky events. For example, it identifies the key patterns in the target data that are well tracked by the foundational model vs. each of the stochastic models. We use the models with optimal parameters to estimate a year-long outage statistics of a particular root cause with less than 6% value errors.",
    "summary": "arXiv:2507.01067v1 Announce Type: cross Abstract: Time series forecasting models have diverse real world applications (e.g., from electricity metrics to software workload). Latest foundational models trained for time series forecasting show strengths (e.g., for long sequences and in zero-shot settings). However, foundational model was not yet used for forecasting rare, spiky events, i.e., a challenging target because those are a corner case of extreme events. In this paper, we optimize a state-of-the-art foundational model to forecast sporadic or spiky production outages of high-performance machine learning services powering billions of client devices. We evaluate the forecasting errors of the foundational model compared with classical stochastic forecasting models (e.g., moving average and autoregressive). The analysis helps us understand how each of the evaluated models performs for the sporadic or spiky events. For example, it identifies the key patterns in the target data that are well tracked by the foundational model vs. each of the stochastic models. We use the models with optimal parameters to estimate a year-long outage statistics of a particular root cause with less than 6% value errors.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01067",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Spread Your Wings: Falcon 180B is here",
    "description": "",
    "summary": "Spread Your Wings: Falcon 180B is here Introduction Today, we're excited to welcome TII's Falcon 180...",
    "pubDate": "Wed, 06 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon-180b",
    "thumbnail": "https://huggingface.co/blog/assets/162_falcon_180b/thumbnail.jpg"
  },
  {
    "title": "Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC",
    "description": "",
    "summary": "Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC We're e...",
    "pubDate": "Wed, 09 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastrtc-cloudflare",
    "thumbnail": "https://huggingface.co/blog/assets/fastrtc-cloudflare/fastrtc_cloudflare.png"
  },
  {
    "title": "Vall√©e Duhamel & Sora",
    "description": "Filmmaking duo Vall√©e Duhamel explains how Sora helps build new worlds.",
    "summary": "Filmmaking duo Vall√©e Duhamel explains how Sora helps build new worlds.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-vallee-duhamel",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Personal Copilot: Train Your Own Coding Assistant",
    "description": "",
    "summary": "Personal Copilot: Train Your Own Coding Assistant In the ever-evolving landscape of programming and ...",
    "pubDate": "Fri, 27 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/personal-copilot",
    "thumbnail": "https://huggingface.co/blog/assets/170_personal_copilot/thumbnail.png"
  },
  {
    "title": "Hugging Face and Graphcore partner for IPU-optimized Transformers",
    "description": "",
    "summary": "Hugging Face and Graphcore partner for IPU-optimized Transformers Speaking at the 2021 AI Hardware S...",
    "pubDate": "Tue, 14 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore",
    "thumbnail": "https://huggingface.co/blog/assets/26_graphcore-ipu/thumbnail.png"
  },
  {
    "title": "Letting Large Models Debate: The First Multilingual LLM Debate Competition",
    "description": "",
    "summary": "Letting Large Models Debate: The First Multilingual LLM Debate Competition Current static evaluation...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/debate",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "AI-guided digital intervention with physiological monitoring reduces intrusive memories after experimental trauma",
    "description": "arXiv:2507.01081v1 Announce Type: cross Abstract: Trauma prevalence is vast globally. Evidence-based digital treatments can help, but most require human guidance. Human guides provide tailored instructions and responsiveness to internal cognitive states, but limit scalability. Can generative AI and neurotechnology provide a scalable alternative? Here we test ANTIDOTE, combining AI guidance and pupillometry to automatically deliver and monitor an evidence-based digital treatment, specifically the Imagery Competing Task Intervention (ICTI), to reduce intrusive memories after psychological trauma. One hundred healthy volunteers were exposed to videos of traumatic events and randomly assigned to an intervention or active control condition. As predicted, intervention participants reported significantly fewer intrusive memories over the following week. Post-hoc assessment against clinical rubrics confirmed the AI guide delivered the intervention successfully. Additionally, pupil size tracked intervention engagement and predicted symptom reduction, providing a candidate biomarker of intervention effectiveness. These findings open a path toward rigorous AI-guided digital interventions that can scale to trauma prevalence.",
    "summary": "arXiv:2507.01081v1 Announce Type: cross Abstract: Trauma prevalence is vast globally. Evidence-based digital treatments can help, but most require human guidance. Human guides provide tailored instructions and responsiveness to internal cognitive states, but limit scalability. Can generative AI and neurotechnology provide a scalable alternative? Here we test ANTIDOTE, combining AI guidance and pupillometry to automatically deliver and monitor an evidence-based digital treatment, specifically the Imagery Competing Task Intervention (ICTI), to reduce intrusive memories after psychological trauma. One hundred healthy volunteers were exposed to videos of traumatic events and randomly assigned to an intervention or active control condition. As predicted, intervention participants reported significantly fewer intrusive memories over the following week. Post-hoc assessment against clinical rubrics confirmed the AI guide delivered the intervention successfully. Additionally, pupil size tracked intervention engagement and predicted symptom reduction, providing a candidate biomarker of intervention effectiveness. These findings open a path toward rigorous AI-guided digital interventions that can scale to trauma prevalence.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01081",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Review of Bayesian Uncertainty Quantification in Deep Probabilistic Image Segmentation",
    "description": "arXiv:2411.16370v4 Announce Type: replace-cross Abstract: Advancements in image segmentation play an integral role within the broad scope of Deep Learning-based Computer Vision. Furthermore, their widespread applicability in critical real-world tasks has resulted in challenges related to the reliability of such algorithms. Hence, uncertainty quantification has been extensively studied within this context, enabling the expression of model ignorance (epistemic uncertainty) or data ambiguity (aleatoric uncertainty) to prevent uninformed decision-making. Due to the rapid adoption of Convolutional Neural Network (CNN)-based segmentation models in high-stake applications, a substantial body of research has been published on this very topic, causing its swift expansion into a distinct field. This work provides a comprehensive overview of probabilistic segmentation, by discussing fundamental concepts of uncertainty quantification, governing advancements in the field as well as the application to various tasks. Moreover, literature on both types of uncertainties trace back to four key applications: (1) to quantify statistical inconsistencies in the annotation process due ambiguous images, (2) correlating prediction error with uncertainty, (3) expanding the model hypothesis space for better generalization, and (4) Active Learning. An extensive discussion follows that includes an overview of utilized datasets for each of the applications and evaluation of the available methods. We also highlight challenges related to architectures, uncertainty quantification methods, standardization and benchmarking, and finally end with recommendations for future work such as methods based on single forward passes and models that appropriately leverage volumetric data.",
    "summary": "arXiv:2411.16370v4 Announce Type: replace-cross Abstract: Advancements in image segmentation play an integral role within the broad scope of Deep Learning-based Computer Vision. Furthermore, their widespread applicability in critical real-world tasks has resulted in challenges related to the reliability of such algorithms. Hence, uncertainty quantification has been extensively studied within this context, enabling the expression of model ignorance (epistemic uncertainty) or data ambiguity (aleatoric uncertainty) to prevent uninformed decision-making. Due to the rapid adoption of Convolutional Neural Network (CNN)-based segmentation models in high-stake applications, a substantial body of research has been published on this very topic, causing its swift expansion into a distinct field. This work provides a comprehensive overview of probabilistic segmentation, by discussing fundamental concepts of uncertainty quantification, governing advancements in the field as well as the application to various tasks. Moreover, literature on both types of uncertainties trace back to four key applications: (1) to quantify statistical inconsistencies in the annotation process due ambiguous images, (2) correlating prediction error with uncertainty, (3) expanding the model hypothesis space for better generalization, and (4) Active Learning. An extensive discussion follows that includes an overview of utilized datasets for each of the applications and evaluation of the available methods. We also highlight challenges related to architectures, uncertainty quantification methods, standardization and benchmarking, and finally end with recommendations for future work such as methods based on single forward passes and models that appropriately leverage volumetric data.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.16370",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Judge Arena: Benchmarking LLMs as Evaluators",
    "description": "",
    "summary": "Judge Arena: Benchmarking LLMs as Evaluators LLM-as-a-Judge has emerged as a popular way to grade na...",
    "pubDate": "Tue, 19 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-atla",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail_atla.png"
  },
  {
    "title": "Distributed Training: Train BART/T5 for Summarization using ü§ó Transformers and Amazon SageMaker",
    "description": "",
    "summary": "Distributed Training: Train BART/T5 for Summarization using ü§ó Transformers and Amazon SageMaker In c...",
    "pubDate": "Thu, 08 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-distributed-training-seq2seq",
    "thumbnail": "https://huggingface.co/blog/assets/19_sagemaker_distributed_training_seq2seq/thumbnail.png"
  },
  {
    "title": "New GPT-3 capabilities: Edit & insert",
    "description": "We‚Äôve released new versions of GPT-3 and Codex¬†which can edit or insert content into existing text, rather than just completing existing text.",
    "summary": "We‚Äôve released new versions of GPT-3 and Codex¬†which can edit or insert content into existing text, rather than just completing existing text.",
    "pubDate": "Tue, 15 Mar 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-edit-insert",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning sparse neural networks through L‚ÇÄ regularization",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 04 Dec 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-sparse-neural-networks-through-l0-regularization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome Stable-baselines3 to the Hugging Face Hub ü§ó",
    "description": "",
    "summary": "Welcome Stable-baselines3 to the Hugging Face Hub ü§ó At Hugging Face, we are contributing to the ecos...",
    "pubDate": "Fri, 21 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sb3",
    "thumbnail": "https://huggingface.co/blog/assets/47_sb3/thumbnail.png"
  },
  {
    "title": "Advanced audio dialog and generation with Gemini 2.5",
    "description": "Gemini 2.5 has new capabilities in AI-powered audio dialog and generation.",
    "summary": "Gemini 2.5 has new capabilities in AI-powered audio dialog and generation.",
    "pubDate": "Tue, 03 Jun 2025 17:15:47 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advanced-audio-dialog-and-generation-with-gemini-25/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/capability__native-audio_16-9_121.width-1300.jpg"
  },
  {
    "title": "ÁîüÊàêAI„Å®„ÅÆ‰ºöË©±„Åß‚Äú„ÅÇ„Å™„Åü„Å´„Å¥„Å£„Åü„Çä„ÅÆÂïÜÂìÅ‚ÄùÊèêÊ°à„ÄÄ„ÄåYahoo!„Ç∑„Éß„ÉÉ„Éî„É≥„Ç∞„ÄçÊñ∞Ê©üËÉΩ",
    "description": "„ÄåYahoo!„Ç∑„Éß„ÉÉ„Éî„É≥„Ç∞„ÄçiOSÁâà„Åß„ÄÅÁîüÊàêAI„Å®„ÅÆ‰ºöË©±„ÇíÈÄö„Åò„ÄÅ„É¶„Éº„Ç∂„Éº„Å´„Éû„ÉÉ„ÉÅ„Åó„ÅüÂïÜÂìÅ„ÇíÊèêÊ°à„Åô„ÇãÊ©üËÉΩ„ÄÇ",
    "summary": "„ÄåYahoo!„Ç∑„Éß„ÉÉ„Éî„É≥„Ç∞„ÄçiOSÁâà„Åß„ÄÅÁîüÊàêAI„Å®„ÅÆ‰ºöË©±„ÇíÈÄö„Åò„ÄÅ„É¶„Éº„Ç∂„Éº„Å´„Éû„ÉÉ„ÉÅ„Åó„ÅüÂïÜÂìÅ„ÇíÊèêÊ°à„Åô„ÇãÊ©üËÉΩ„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 06:37:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news053.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news053.png"
  },
  {
    "title": "Filling crucial language learning gaps",
    "description": "GPT-4 deepens the conversation on Duolingo.",
    "summary": "GPT-4 deepens the conversation on Duolingo.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/duolingo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2021: Final projects",
    "description": "We‚Äôre proud to announce that the 2021 class of¬†OpenAI Scholars¬†has completed our six-month mentorship program and have produced an open-source research project with stipends and support from¬†OpenAI.",
    "summary": "We‚Äôre proud to announce that the 2021 class of¬†OpenAI Scholars¬†has completed our six-month mentorship program and have produced an open-source research project with stipends and support from¬†OpenAI.",
    "pubDate": "Mon, 10 May 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2021-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New models and developer products announced at DevDay",
    "description": "GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL¬∑E 3 API, and more.",
    "summary": "GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL¬∑E 3 API, and more.",
    "pubDate": "Mon, 06 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-models-and-developer-products-announced-at-devday",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI London",
    "description": "We are excited to announce OpenAI‚Äôs first international expansion with a new office in London, United Kingdom.",
    "summary": "We are excited to announce OpenAI‚Äôs first international expansion with a new office in London, United Kingdom.",
    "pubDate": "Wed, 28 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-london",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fetch Cuts ML Processing Latency by 50% Using Amazon SageMaker & Hugging Face",
    "description": "",
    "summary": "Fetch Cuts ML Processing Latency by 50% Using Amazon SageMaker & Hugging Face This article is a cros...",
    "pubDate": "Fri, 01 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fetch-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/fetch.png"
  },
  {
    "title": "Empowering the next generation for an AI-enabled world",
    "description": "Experience AI's course and resources are expanding on a global scale",
    "summary": "Experience AI's course and resources are expanding on a global scale",
    "pubDate": "Wed, 15 Nov 2023 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/empowering-the-next-generation-for-an-ai-enabled-world/",
    "thumbnail": "https://lh3.googleusercontent.com/XJ10IR5bv5MmygxoFC0hrepTZtjq_Bwz69bL7d7jBy06fnEFodAa0tbIWKOwV7gW2Im3JY2GGda-xZKtVQhqcaozz6r_vdHXsgVu0CzyIhIz4VGs=w1200-h630-n-nu"
  },
  {
    "title": "Evolving OpenAI‚Äôs structure",
    "description": "An update from the OpenAI board on transitioning its for-profit entity to a Public Benefit Corporation, reinforcing its mission-driven structure under nonprofit oversight while enabling greater impact and long-term alignment with the public good.",
    "summary": "An update from the OpenAI board on transitioning its for-profit entity to a Public Benefit Corporation, reinforcing its mission-driven structure under nonprofit oversight while enabling greater impact and long-term alignment with the public good.",
    "pubDate": "Mon, 05 May 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolving-our-structure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Residency",
    "description": "As part of our effort to support and develop AI talent, we‚Äôre excited to announce the OpenAI Residency.",
    "summary": "As part of our effort to support and develop AI talent, we‚Äôre excited to announce the OpenAI Residency.",
    "pubDate": "Tue, 30 Nov 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-residency",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deep Recommender Models Inference: Automatic Asymmetric Data Flow Optimization",
    "description": "arXiv:2507.01676v1 Announce Type: cross Abstract: Deep Recommender Models (DLRMs) inference is a fundamental AI workload accounting for more than 79% of the total AI workload in Meta's data centers. DLRMs' performance bottleneck is found in the embedding layers, which perform many random memory accesses to retrieve small embedding vectors from tables of various sizes. We propose the design of tailored data flows to speedup embedding look-ups. Namely, we propose four strategies to look up an embedding table effectively on one core, and a framework to automatically map the tables asymmetrically to the multiple cores of a SoC. We assess the effectiveness of our method using the Huawei Ascend AI accelerators, comparing it with the default Ascend compiler, and we perform high-level comparisons with Nvidia A100. Results show a speed-up varying from 1.5x up to 6.5x for real workload distributions, and more than 20x for extremely unbalanced distributions. Furthermore, the method proves to be much more independent of the query distribution than the baseline.",
    "summary": "arXiv:2507.01676v1 Announce Type: cross Abstract: Deep Recommender Models (DLRMs) inference is a fundamental AI workload accounting for more than 79% of the total AI workload in Meta's data centers. DLRMs' performance bottleneck is found in the embedding layers, which perform many random memory accesses to retrieve small embedding vectors from tables of various sizes. We propose the design of tailored data flows to speedup embedding look-ups. Namely, we propose four strategies to look up an embedding table effectively on one core, and a framework to automatically map the tables asymmetrically to the multiple cores of a SoC. We assess the effectiveness of our method using the Huawei Ascend AI accelerators, comparing it with the default Ascend compiler, and we perform high-level comparisons with Nvidia A100. Results show a speed-up varying from 1.5x up to 6.5x for real workload distributions, and more than 20x for extremely unbalanced distributions. Furthermore, the method proves to be much more independent of the query distribution than the baseline.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01676",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deep Learning over the Internet: Training Language Models Collaboratively",
    "description": "",
    "summary": "Deep Learning over the Internet: Training Language Models Collaboratively Modern language models oft...",
    "pubDate": "Thu, 15 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/collaborative-training",
    "thumbnail": "https://huggingface.co/blog/assets/24_sahajBERT/thumbnail.png"
  },
  {
    "title": "Jukebox",
    "description": "We‚Äôre introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. We‚Äôre releasing the model weights and code, along with a tool to explore the generated¬†samples.",
    "summary": "We‚Äôre introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. We‚Äôre releasing the model weights and code, along with a tool to explore the generated¬†samples.",
    "pubDate": "Thu, 30 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jukebox",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Teams Up with Protect AI: Enhancing Model Security for the Community",
    "description": "",
    "summary": "Hugging Face Teams Up with Protect AI: Enhancing Model Security for the Community We are pleased to ...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/protectai",
    "thumbnail": "https://huggingface.co/blog/assets/protectai/thumbnail.png"
  },
  {
    "title": "On the quantitative analysis of decoder-based generative models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 14 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/on-the-quantitative-analysis-of-decoder-based-generative-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Shaping the future of financial services",
    "description": "Morgan Stanley uses AI evals to shape the future of financial services",
    "summary": "Morgan Stanley uses AI evals to shape the future of financial services",
    "pubDate": "Wed, 04 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/morgan-stanley",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the GPT Store",
    "description": "We‚Äôre launching the GPT Store to help you find useful and popular custom versions of ChatGPT.",
    "summary": "We‚Äôre launching the GPT Store to help you find useful and popular custom versions of ChatGPT.",
    "pubDate": "Wed, 10 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-gpt-store",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Have a damaged painting? Restore it in just hours with an AI-generated ‚Äúmask‚Äù",
    "description": "A new method can physically restore original paintings using digitally constructed films, which can be removed if desired.",
    "summary": "A new method can physically restore original paintings using digitally constructed films, which can be removed if desired.",
    "pubDate": "Wed, 11 Jun 2025 11:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/restoring-damaged-paintings-using-ai-generated-mask-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Restoring-Paintings-01-press.jpg"
  },
  {
    "title": "Evaluating large language models trained on code",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 07 Jul 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evaluating-large-language-models-trained-on-code",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome the Falcon 3 Family of Open Models!",
    "description": "",
    "summary": "Welcome to the Falcon 3 Family of Open Models! We introduce Falcon3, a family of decoder-only large ...",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon3",
    "thumbnail": "https://huggingface.co/blog/assets/falcon3/thumbnail.png"
  },
  {
    "title": "The latest AI news we announced in June",
    "description": "an mp4 carousel of images shoe people and dark blue icons including a magnifying glass",
    "summary": "an mp4 carousel of images shoe people and dark blue icons including a magnifying glass",
    "pubDate": "Wed, 02 Jul 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/google-ai-updates-june-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/June_AI_Recap_social-share.width-1300.png"
  },
  {
    "title": "We used Veo to animate archive photography from the Harley-Davidson Museum",
    "description": "Two phones over a blurry background showing archival photos from the Harley-Davidson Museum. Each phone screen shows moving black and white archival images from the museum.",
    "summary": "Two phones over a blurry background showing archival photos from the Harley-Davidson Museum. Each phone screen shows moving black and white archival images from the museum.",
    "pubDate": "Tue, 01 Jul 2025 13:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/arts-culture/moving-archives/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/MovingArchives_SS.width-1300.png"
  },
  {
    "title": "MuZero, AlphaZero, and AlphaDev: Optimizing computer systems",
    "description": "How MuZero, AlphaZero, and AlphaDev are optimizing the computing ecosystem that powers our world of devices.",
    "summary": "How MuZero, AlphaZero, and AlphaDev are optimizing the computing ecosystem that powers our world of devices.",
    "pubDate": "Mon, 12 Jun 2023 14:41:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/muzero-alphazero-and-alphadev-optimizing-computer-systems/",
    "thumbnail": "https://lh3.googleusercontent.com/6tSxHgEgSLR8FSELf3If1M1QBbXTtpsfH6w2ocuruWGnFDTdogbyNA8sHOyKpFYCja4hT7fGCVwl2xyI9biVB1bFNcnTxvYptuVdcT0XHMjn-TzG=w1200-h630-n-nu"
  },
  {
    "title": "Weight normalization: A simple reparameterization to accelerate training of deep neural networks",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 25 Feb 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/weight-normalization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PatchTSMixer in HuggingFace",
    "description": "",
    "summary": "PatchTSMixer in HuggingFace - Getting Started PatchTSMixer is a lightweight time-series modeling app...",
    "pubDate": "Fri, 19 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/patchtsmixer",
    "thumbnail": "https://huggingface.co/blog/assets/patchtsmixer/thumbnail.jpeg"
  },
  {
    "title": "Introducing SimpleQA",
    "description": "A factuality benchmark called SimpleQA that measures the ability for language models to answer short, fact-seeking questions.",
    "summary": "A factuality benchmark called SimpleQA that measures the ability for language models to answer short, fact-seeking questions.",
    "pubDate": "Wed, 30 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-simpleqa",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy Hugging Face models easily with Amazon SageMaker",
    "description": "",
    "summary": "Deploy Hugging Face models easily with Amazon SageMaker üèé Earlier this year we announced a strategic...",
    "pubDate": "Thu, 08 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-hugging-face-models-easily-with-amazon-sagemaker",
    "thumbnail": "https://huggingface.co/blog/assets/17_the_partnership_amazon_sagemaker_and_hugging_face/thumbnail.png"
  },
  {
    "title": "ChartCoder: Advancing Multimodal Large Language Model for Chart-to-Code Generation",
    "description": "arXiv:2501.06598v3 Announce Type: replace Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in chart understanding tasks. However, interpreting charts with textual descriptions often leads to information loss, as it fails to fully capture the dense information embedded in charts. In contrast, parsing charts into code provides lossless representations that can effectively contain all critical details. Although existing open-source MLLMs have achieved success in chart understanding tasks, they still face two major challenges when applied to chart-to-code tasks: (1) Low executability and poor restoration of chart details in the generated code and (2) Lack of large-scale and diverse training data. To address these challenges, we propose textbf{ChartCoder}, the first dedicated chart-to-code MLLM, which leverages Code LLMs as the language backbone to enhance the executability of the generated code. Furthermore, we introduce textbf{Chart2Code-160k}, the first large-scale and diverse dataset for chart-to-code generation, and propose the textbf{Snippet-of-Thought (SoT)} method, which transforms direct chart-to-code generation data into step-by-step generation. Experiments demonstrate that ChartCoder, with only 7B parameters, surpasses existing open-source MLLMs on chart-to-code benchmarks, achieving superior chart restoration and code excitability. Our code is available at https://github.com/thunlp/ChartCoder.",
    "summary": "arXiv:2501.06598v3 Announce Type: replace Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in chart understanding tasks. However, interpreting charts with textual descriptions often leads to information loss, as it fails to fully capture the dense information embedded in charts. In contrast, parsing charts into code provides lossless representations that can effectively contain all critical details. Although existing open-source MLLMs have achieved success in chart understanding tasks, they still face two major challenges when applied to chart-to-code tasks: (1) Low executability and poor restoration of chart details in the generated code and (2) Lack of large-scale and diverse training data. To address these challenges, we propose textbf{ChartCoder}, the first dedicated chart-to-code MLLM, which leverages Code LLMs as the language backbone to enhance the executability of the generated code. Furthermore, we introduce textbf{Chart2Code-160k}, the first large-scale and diverse dataset for chart-to-code generation, and propose the textbf{Snippet-of-Thought (SoT)} method, which transforms direct chart-to-code generation data into step-by-step generation. Experiments demonstrate that ChartCoder, with only 7B parameters, surpasses existing open-source MLLMs on chart-to-code benchmarks, achieving superior chart restoration and code excitability. Our code is available at https://github.com/thunlp/ChartCoder.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.06598",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google DeepMind at ICLR 2024",
    "description": "Developing next-gen AI agents, exploring new modalities, and pioneering foundational learning",
    "summary": "Developing next-gen AI agents, exploring new modalities, and pioneering foundational learning",
    "pubDate": "Fri, 03 May 2024 13:39:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-iclr-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/8PzKGooudBtamqh9keU_q7O0ex5XxGgIIK3BKQNAVEV6WDzIkfadsbNPhU0QCg5PurFGnAOSOClrM9dQHIGvOEe9MPluA5uhyFcun3FvNMBfPI63mWk=w1200-h630-n-nu"
  },
  {
    "title": "Consistency Models",
    "description": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation.",
    "summary": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New and improved content moderation tooling",
    "description": "We are introducing a new and improved content moderation tool. The¬†Moderation endpoint¬†improves upon our previous content filter, and is available for free today to OpenAI API¬†developers.",
    "summary": "We are introducing a new and improved content moderation tool. The¬†Moderation endpoint¬†improves upon our previous content filter, and is available for free today to OpenAI API¬†developers.",
    "pubDate": "Wed, 10 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-and-improved-content-moderation-tooling",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Running IF with üß® diffusers on a Free Tier Google Colab",
    "description": "",
    "summary": "Running IF with üß® diffusers on a Free Tier Google Colab TL;DR: We show how to run one of the most po...",
    "pubDate": "Wed, 26 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/if",
    "thumbnail": "https://huggingface.co/blog/assets/if/thumbnail.jpg"
  },
  {
    "title": "Introducing HUGS - Scale your AI with Open Models",
    "description": "",
    "summary": "Introducing HUGS - Scale your AI with Open Models Today, we are thrilled to announce the launch of H...",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugs",
    "thumbnail": "https://huggingface.co/blog/assets/hugs/thumbnail.jpg"
  },
  {
    "title": "Researchers present bold ideas for AI at MIT Generative AI Impact Consortium kickoff event",
    "description": "Presentations targeted high-impact intersections of AI and other areas, such as health care, business, and education.",
    "summary": "Presentations targeted high-impact intersections of AI and other areas, such as health care, business, and education.",
    "pubDate": "Fri, 20 Jun 2025 16:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/researchers-present-bold-ideas-ai-mit-generative-ai-impact-consortium-event-0620",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-Anantha.jpg"
  },
  {
    "title": "Hugging Face + PyCharm",
    "description": "",
    "summary": "Hugging Face + PyCharm It‚Äôs a Tuesday morning. As a Transformers maintainer, I‚Äôm doing the same thin...",
    "pubDate": "Tue, 05 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pycharm-integration",
    "thumbnail": "https://huggingface.co/blog/assets/pycharm-integration/thumbnail.png"
  },
  {
    "title": "Scaling-up BERT Inference on CPU (Part 1)",
    "description": "",
    "summary": "Scaling up BERT-like model Inference on modern CPU - Part 1 1. Context and Motivations Back in Octob...",
    "pubDate": "Tue, 20 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-cpu-scaling-part-1",
    "thumbnail": "https://huggingface.co/blog/assets/21_bert_cpu_scaling_part_1/imgs/numa_set.png"
  },
  {
    "title": "Introducing OpenAI for Government",
    "description": "We‚Äôre launching OpenAI for Government, a new initiative focused on bringing our most advanced AI tools to public servants across the United States. We're supporting the U.S. government's efforts in adopting best-in-class technology and deploying these tools in service of the public good.",
    "summary": "We‚Äôre launching OpenAI for Government, a new initiative focused on bringing our most advanced AI tools to public servants across the United States. We're supporting the U.S. government's efforts in adopting best-in-class technology and deploying these tools in service of the public good.",
    "pubDate": "Mon, 16 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-openai-for-government",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing NPC-Playground, a 3D playground to interact with LLM-powered NPCs",
    "description": "",
    "summary": "Introducing NPC-Playground, a 3D playground to interact with LLM-powered NPCs AI-powered NPCs (Non-P...",
    "pubDate": "Wed, 05 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/npc-gigax-cubzh",
    "thumbnail": "https://huggingface.co/blog/assets/181_npc-gigax-cubzh/thumbnail.png"
  },
  {
    "title": "FastMamba: A High-Speed and Efficient Mamba Accelerator on FPGA with Accurate Quantization",
    "description": "arXiv:2505.18975v3 Announce Type: replace-cross Abstract: State Space Models (SSMs), like recent Mamba2, have achieved remarkable performance and received extensive attention. However, deploying Mamba2 on resource-constrained edge devices encounters many problems: severe outliers within the linear layer challenging the quantization, diverse and irregular element-wise tensor operations, and hardware-unfriendly nonlinear functions in the SSM block. To address these issues, this paper presents FastMamba, a dedicated accelerator on FPGA with hardware-algorithm co-design to promote the deployment efficiency of Mamba2. Specifically, we successfully achieve 8-bit quantization for linear layers through Hadamard transformation to eliminate outliers. Moreover, a hardware-friendly and fine-grained power-of-two quantization framework is presented for the SSM block and convolution layer, and a first-order linear approximation is developed to optimize the nonlinear functions. Based on the accurate algorithm quantization, we propose an accelerator that integrates parallel vector processing units, pipelined execution dataflow, and an efficient SSM Nonlinear Approximation Unit, which enhances computational efficiency and reduces hardware complexity. Finally, we evaluate FastMamba on Xilinx VC709 FPGA. For the input prefill task on Mamba2-130M, FastMamba achieves 68.80times and 8.90times speedup over Intel Xeon 4210R CPU and NVIDIA RTX 3090 GPU, respectively. In the output decode experiment with Mamba2-2.7B, FastMamba attains 6times higher energy efficiency than RTX 3090 GPU.",
    "summary": "arXiv:2505.18975v3 Announce Type: replace-cross Abstract: State Space Models (SSMs), like recent Mamba2, have achieved remarkable performance and received extensive attention. However, deploying Mamba2 on resource-constrained edge devices encounters many problems: severe outliers within the linear layer challenging the quantization, diverse and irregular element-wise tensor operations, and hardware-unfriendly nonlinear functions in the SSM block. To address these issues, this paper presents FastMamba, a dedicated accelerator on FPGA with hardware-algorithm co-design to promote the deployment efficiency of Mamba2. Specifically, we successfully achieve 8-bit quantization for linear layers through Hadamard transformation to eliminate outliers. Moreover, a hardware-friendly and fine-grained power-of-two quantization framework is presented for the SSM block and convolution layer, and a first-order linear approximation is developed to optimize the nonlinear functions. Based on the accurate algorithm quantization, we propose an accelerator that integrates parallel vector processing units, pipelined execution dataflow, and an efficient SSM Nonlinear Approximation Unit, which enhances computational efficiency and reduces hardware complexity. Finally, we evaluate FastMamba on Xilinx VC709 FPGA. For the input prefill task on Mamba2-130M, FastMamba achieves 68.80times and 8.90times speedup over Intel Xeon 4210R CPU and NVIDIA RTX 3090 GPU, respectively. In the output decode experiment with Mamba2-2.7B, FastMamba attains 6times higher energy efficiency than RTX 3090 GPU.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.18975",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Personalizing education with ChatGPT",
    "description": "Arizona State University embraces ChatGPT campus-wide to personalize learning, advance research, and prepare students for the future",
    "summary": "Arizona State University embraces ChatGPT campus-wide to personalize learning, advance research, and prepare students for the future",
    "pubDate": "Mon, 26 Aug 2024 04:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/asu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues",
    "description": "arXiv:2506.22853v2 Announce Type: replace-cross Abstract: Existing function-calling benchmarks focus on single-turn interactions. However, they overlook the complexity of real-world scenarios. To quantify how existing benchmarks address practical applications, we introduce DICE-SCORE, a metric that evaluates the dispersion of tool-related information such as function name and parameter values throughout the dialogue. Analyzing existing benchmarks through DICE-SCORE reveals notably low scores, highlighting the need for more realistic scenarios. To address this gap, we present DICE-BENCH, a framework that constructs practical function-calling datasets by synthesizing conversations through a tool graph that maintains dependencies across rounds and a multi-agent system with distinct personas to enhance dialogue naturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our experiments on 19 LLMs with DICE-BENCH show that significant advances are still required before such models can be deployed effectively in real-world settings. Our code and data are all publicly available: https://snuhcc.github.io/DICE-Bench/.",
    "summary": "arXiv:2506.22853v2 Announce Type: replace-cross Abstract: Existing function-calling benchmarks focus on single-turn interactions. However, they overlook the complexity of real-world scenarios. To quantify how existing benchmarks address practical applications, we introduce DICE-SCORE, a metric that evaluates the dispersion of tool-related information such as function name and parameter values throughout the dialogue. Analyzing existing benchmarks through DICE-SCORE reveals notably low scores, highlighting the need for more realistic scenarios. To address this gap, we present DICE-BENCH, a framework that constructs practical function-calling datasets by synthesizing conversations through a tool graph that maintains dependencies across rounds and a multi-agent system with distinct personas to enhance dialogue naturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our experiments on 19 LLMs with DICE-BENCH show that significant advances are still required before such models can be deployed effectively in real-world settings. Our code and data are all publicly available: https://snuhcc.github.io/DICE-Bench/.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22853",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Function calling and other API updates",
    "description": "We‚Äôre announcing updates including more steerable API models, function calling capabilities, longer context, and lower prices.",
    "summary": "We‚Äôre announcing updates including more steerable API models, function calling capabilities, longer context, and lower prices.",
    "pubDate": "Tue, 13 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/function-calling-and-other-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SegMoE: Segmind Mixture of Diffusion Experts",
    "description": "",
    "summary": "SegMoE: Segmind Mixture of Diffusion Experts SegMoE is an exciting framework for creating Mixture-of...",
    "pubDate": "Sat, 03 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/segmoe",
    "thumbnail": "https://huggingface.co/blog/assets/segmoe/thumbnail.png"
  },
  {
    "title": "Space secrets security update",
    "description": "",
    "summary": "Space secrets leak disclosure Earlier this week our team detected unauthorized access to our Spaces ...",
    "pubDate": "Fri, 31 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/space-secrets-disclosure",
    "thumbnail": "https://huggingface.co/blog/assets/space-secrets-security-update/space-secrets-security-update.png"
  },
  {
    "title": "Universe",
    "description": "We‚Äôre releasing Universe, a software platform for measuring and training an AI‚Äôs general intelligence across the world‚Äôs supply of games, websites and other applications.",
    "summary": "We‚Äôre releasing Universe, a software platform for measuring and training an AI‚Äôs general intelligence across the world‚Äôs supply of games, websites and other applications.",
    "pubDate": "Mon, 05 Dec 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/universe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building Cost-Efficient Enterprise RAG applications with Intel Gaudi 2 and Intel Xeon",
    "description": "",
    "summary": "Building Cost-Efficient Enterprise RAG applications with Intel Gaudi 2 and Intel Xeon Retrieval-augm...",
    "pubDate": "Thu, 09 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cost-efficient-rag-applications-with-intel",
    "thumbnail": "https://huggingface.co/blog/assets/cost_efficient_rag_applications_with_intel/main.jpg"
  },
  {
    "title": "Research on Low-Latency Inference and Training Efficiency Optimization for Graph Neural Network and Large Language Model-Based Recommendation Systems",
    "description": "arXiv:2507.01035v1 Announce Type: cross Abstract: The incessant advent of online services demands high speed and efficient recommender systems (ReS) that can maintain real-time performance along with processing very complex user-item interactions. The present study, therefore, considers computational bottlenecks involved in hybrid Graph Neural Network (GNN) and Large Language Model (LLM)-based ReS with the aim optimizing their inference latency and training efficiency. An extensive methodology was used: hybrid GNN-LLM integrated architecture-optimization strategies(quantization, LoRA, distillation)-hardware acceleration (FPGA, DeepSpeed)-all under R 4.4.2. Experimental improvements were significant, with the optimal Hybrid + FPGA + DeepSpeed configuration reaching 13.6% more accuracy (NDCG@10: 0.75) at 40-60ms of latency, while LoRA brought down training time by 66% (3.8 hours) in comparison to the non-optimized baseline. Irrespective of domain, such as accuracy or efficiency, it can be established that hardware-software co-design and parameter-efficient tuning permit hybrid models to outperform GNN or LLM approaches implemented independently. It recommends the use of FPGA as well as LoRA for real-time deployment. Future work should involve federated learning along with advanced fusion architectures for better scalability and privacy preservation. Thus, this research marks the fundamental groundwork concerning next-generation ReS balancing low-latency response with cutting-edge personalization.",
    "summary": "arXiv:2507.01035v1 Announce Type: cross Abstract: The incessant advent of online services demands high speed and efficient recommender systems (ReS) that can maintain real-time performance along with processing very complex user-item interactions. The present study, therefore, considers computational bottlenecks involved in hybrid Graph Neural Network (GNN) and Large Language Model (LLM)-based ReS with the aim optimizing their inference latency and training efficiency. An extensive methodology was used: hybrid GNN-LLM integrated architecture-optimization strategies(quantization, LoRA, distillation)-hardware acceleration (FPGA, DeepSpeed)-all under R 4.4.2. Experimental improvements were significant, with the optimal Hybrid + FPGA + DeepSpeed configuration reaching 13.6% more accuracy (NDCG@10: 0.75) at 40-60ms of latency, while LoRA brought down training time by 66% (3.8 hours) in comparison to the non-optimized baseline. Irrespective of domain, such as accuracy or efficiency, it can be established that hardware-software co-design and parameter-efficient tuning permit hybrid models to outperform GNN or LLM approaches implemented independently. It recommends the use of FPGA as well as LoRA for real-time deployment. Future work should involve federated learning along with advanced fusion architectures for better scalability and privacy preservation. Thus, this research marks the fundamental groundwork concerning next-generation ReS balancing low-latency response with cutting-edge personalization.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01035",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A landmark multi-year global partnership with News Corp",
    "description": "Companies Join Forces to Enrich OpenAI‚Äôs Generative AI Products and Platforms with Premium Journalism",
    "summary": "Companies Join Forces to Enrich OpenAI‚Äôs Generative AI Products and Platforms with Premium Journalism",
    "pubDate": "Wed, 22 May 2024 13:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/news-corp-and-openai-sign-landmark-multi-year-global-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Unpacking the bias of large language models",
    "description": "In a new study, researchers discover the root cause of a type of bias in LLMs, paving the way for more accurate and reliable AI systems.",
    "summary": "In a new study, researchers discover the root cause of a type of bias in LLMs, paving the way for more accurate and reliable AI systems.",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/unpacking-large-language-model-bias-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-transform-bias-01-press.jpg"
  },
  {
    "title": "DeepMind‚Äôs latest research at ICLR 2023",
    "description": "Next week marks the start of the 11th International Conference on Learning Representations (ICLR), taking place 1-5 May in Kigali, Rwanda. This will be the first major artificial intelligence (AI) conference to be hosted in Africa and the first in-person event since the start of the pandemic. Researchers from around the world will gather to share their cutting-edge work in deep learning spanning the fields of AI, statistics and data science, and applications including machine vision, gaming and robotics. We‚Äôre proud to support the conference as a Diamond sponsor and DEI champion.",
    "summary": "Next week marks the start of the 11th International Conference on Learning Representations (ICLR), taking place 1-5 May in Kigali, Rwanda. This will be the first major artificial intelligence (AI) conference to be hosted in Africa and the first in-person event since the start of the pandemic. Researchers from around the world will gather to share their cutting-edge work in deep learning spanning the fields of AI, statistics and data science, and applications including machine vision, gaming and robotics. We‚Äôre proud to support the conference as a Diamond sponsor and DEI champion.",
    "pubDate": "Thu, 27 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/deepminds-latest-research-at-iclr-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/PH30vPBZLwZXlSFrALk6AT507Qn70LSPLW5a89vsRhDdkje_xaPGvNE2UrhOBy8Gkaasn-FVRuDWlPhEPntzw02gxSAEPygt7djS4URtQZJuaLPw3w=w1200-h630-n-nu"
  },
  {
    "title": "AlphaGeometry: An Olympiad-level AI system for geometry",
    "description": "Advancing AI reasoning in mathematics",
    "summary": "Advancing AI reasoning in mathematics",
    "pubDate": "Wed, 17 Jan 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/",
    "thumbnail": "https://lh3.googleusercontent.com/tVTh_ZCW5Qozy4vOCpMH06B7Ac_eF7fmEULMMTwDellOh6hnOMUtf28toD68N527IHQTlBWfBCHcZykYPMdrS48yvuEcJKMJG8rU3YRM3u5Ojn3JXnc=w1200-h630-n-nu"
  },
  {
    "title": "„ÄåË¶ñÂäõ„ÇíÂ§±„Å£„ÅüÁà∂„Å´„ÄÅAI„Çí‰Ωø„Çè„Åõ„Å¶„ÅÇ„Åí„Åü„ÅÑ„Äç„ÄÄ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞Êú™ÁµåÈ®ì„ÅÆÂ®ò„Åå„ÄåÂ≠£Ë™û„ÉÑ„Éº„É´„Äç„ÇíÈñãÁô∫„Åô„Çã„Åæ„Åß",
    "description": "ÁóÖÊ∞ó„ÅßÁ™ÅÁÑ∂„ÄÅË¶ñÂäõ„ÇíÂ§±„Å£„ÅüÁà∂„ÄÇÂ®ò„ÅØ„Äå‰Ωï„Å®„Åã„Åó„Å¶Áà∂„ÅÆ„ÇÑ„ÇãÊ∞ó„ÇíÂèñ„ÇäÊàª„Åó„Å¶„ÅÇ„Åí„Åü„ÅÑ„Äç„Å®„ÄÅ„Éê„Ç§„Éñ„Ç≥„Éº„Éá„Ç£„É≥„Ç∞„ÇíÂßã„ÇÅ„Åü„ÄÇ",
    "summary": "ÁóÖÊ∞ó„ÅßÁ™ÅÁÑ∂„ÄÅË¶ñÂäõ„ÇíÂ§±„Å£„ÅüÁà∂„ÄÇÂ®ò„ÅØ„Äå‰Ωï„Å®„Åã„Åó„Å¶Áà∂„ÅÆ„ÇÑ„ÇãÊ∞ó„ÇíÂèñ„ÇäÊàª„Åó„Å¶„ÅÇ„Åí„Åü„ÅÑ„Äç„Å®„ÄÅ„Éê„Ç§„Éñ„Ç≥„Éº„Éá„Ç£„É≥„Ç∞„ÇíÂßã„ÇÅ„Åü„ÄÇ",
    "pubDate": "Wed, 02 Jul 2025 11:58:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/02/news061.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/02/cover_news061.png"
  },
  {
    "title": "Autonomous AI Surveillance: Multimodal Deep Learning for Cognitive and Behavioral Monitoring",
    "description": "arXiv:2507.01590v1 Announce Type: cross Abstract: This study presents a novel classroom surveillance system that integrates multiple modalities, including drowsiness, tracking of mobile phone usage, and face recognition,to assess student attentiveness with enhanced precision.The system leverages the YOLOv8 model to detect both mobile phone and sleep usage,(Ghatge et al., 2024) while facial recognition is achieved through LResNet Occ FC body tracking using YOLO and MTCNN.(Durai et al., 2024) These models work in synergy to provide comprehensive, real-time monitoring, offering insights into student engagement and behavior.(S et al., 2023) The framework is trained on specialized datasets, such as the RMFD dataset for face recognition and a Roboflow dataset for mobile phone detection. The extensive evaluation of the system shows promising results. Sleep detection achieves 97. 42% mAP@50, face recognition achieves 86. 45% validation accuracy and mobile phone detection reach 85. 89% mAP@50. The system is implemented within a core PHP web application and utilizes ESP32-CAM hardware for seamless data capture.(Neto et al., 2024) This integrated approach not only enhances classroom monitoring, but also ensures automatic attendance recording via face recognition as students remain seated in the classroom, offering scalability for diverse educational environments.(Banada,2025)",
    "summary": "arXiv:2507.01590v1 Announce Type: cross Abstract: This study presents a novel classroom surveillance system that integrates multiple modalities, including drowsiness, tracking of mobile phone usage, and face recognition,to assess student attentiveness with enhanced precision.The system leverages the YOLOv8 model to detect both mobile phone and sleep usage,(Ghatge et al., 2024) while facial recognition is achieved through LResNet Occ FC body tracking using YOLO and MTCNN.(Durai et al., 2024) These models work in synergy to provide comprehensive, real-time monitoring, offering insights into student engagement and behavior.(S et al., 2023) The framework is trained on specialized datasets, such as the RMFD dataset for face recognition and a Roboflow dataset for mobile phone detection. The extensive evaluation of the system shows promising results. Sleep detection achieves 97. 42% mAP@50, face recognition achieves 86. 45% validation accuracy and mobile phone detection reach 85. 89% mAP@50. The system is implemented within a core PHP web application and utilizes ESP32-CAM hardware for seamless data capture.(Neto et al., 2024) This integrated approach not only enhances classroom monitoring, but also ensures automatic attendance recording via face recognition as students remain seated in the classroom, offering scalability for diverse educational environments.(Banada,2025)",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01590",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Arize Phoenix „ÅßÂÆüÁèæ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Éà„É¨„Éº„Çπ",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI „ÉÅ„Éº„É†„ÅÆÈï∑Êæ§(@sp_1999N)„Åß„Åô„ÄÇ ‰ªäÂõû„ÅØ Arize AI Á§æ„ÅåÈñãÁô∫„ÉªÊèê‰æõ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥Âêë„Åë„ÅÆÁõ£Ë¶ñ„ÉÑ„Éº„É´ Phoenix „ÅÆÁ¥π‰ªã„Åä„Çà„Å≥Á∞°Âçò„Å™„Éá„É¢ÊßãÁØâ„ÇíË°å„ÅÑ„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ „Éá„É¢„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5608' rel='nofollow'>Arize Phoenix „ÅßÂÆüÁèæ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Éà„É¨„Éº„Çπ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI „ÉÅ„Éº„É†„ÅÆÈï∑Êæ§(@sp_1999N)„Åß„Åô„ÄÇ ‰ªäÂõû„ÅØ Arize AI Á§æ„ÅåÈñãÁô∫„ÉªÊèê‰æõ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥Âêë„Åë„ÅÆÁõ£Ë¶ñ„ÉÑ„Éº„É´ Phoenix „ÅÆÁ¥π‰ªã„Åä„Çà„Å≥Á∞°Âçò„Å™„Éá„É¢ÊßãÁØâ„ÇíË°å„ÅÑ„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ „Éá„É¢„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5608' rel='nofollow'>Arize Phoenix „ÅßÂÆüÁèæ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Éà„É¨„Éº„Çπ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Tue, 25 Mar 2025 10:22:46 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5608",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/image-4.png"
  },
  {
    "title": "Ethics and Society Newsletter #5: Hugging Face Goes To Washington and Other Summer 2023 Musings",
    "description": "",
    "summary": "Ethics and Society Newsletter #5: Hugging Face Goes To Washington and Other Summer 2023 Musings One ...",
    "pubDate": "Fri, 29 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-5",
    "thumbnail": "https://huggingface.co/blog/assets/164_ethics-soc-5/thumbnail.png"
  },
  {
    "title": "Hello Afrika: Speech Commands in Kinyarwanda",
    "description": "arXiv:2507.01024v1 Announce Type: cross Abstract: Voice or Speech Commands are a subset of the broader Spoken Word Corpus of a language which are essential for non-contact control of and activation of larger AI systems in devices used in everyday life especially for persons with disabilities. Currently, there is a dearth of speech command models for African languages. The Hello Afrika project aims to address this issue and its first iteration is focused on the Kinyarwanda language since the country has shown interest in developing speech recognition technologies culminating in one of the largest datasets on Mozilla Common Voice. The model was built off a custom speech command corpus made up of general directives, numbers, and a wake word. The final model was deployed on multiple devices (PC, Mobile Phone and Edge Devices) and the performance was assessed using suitable metrics.",
    "summary": "arXiv:2507.01024v1 Announce Type: cross Abstract: Voice or Speech Commands are a subset of the broader Spoken Word Corpus of a language which are essential for non-contact control of and activation of larger AI systems in devices used in everyday life especially for persons with disabilities. Currently, there is a dearth of speech command models for African languages. The Hello Afrika project aims to address this issue and its first iteration is focused on the Kinyarwanda language since the country has shown interest in developing speech recognition technologies culminating in one of the largest datasets on Mozilla Common Voice. The model was built off a custom speech command corpus made up of general directives, numbers, and a wake word. The final model was deployed on multiple devices (PC, Mobile Phone and Edge Devices) and the performance was assessed using suitable metrics.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01024",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Horus: A Protocol for Trustless Delegation Under Uncertainty",
    "description": "arXiv:2507.00631v2 Announce Type: replace-cross Abstract: Correctness is an emergent property of systems where exposing error is cheaper than committing it. In dynamic, low-trust environments, autonomous AI agents benefit from delegating work to sub-agents, yet correctness cannot be assured through upfront specification or centralized oversight. We propose a protocol that enforces correctness through collateralized claims in a recursive verification game. Tasks are published as intents, and solvers compete to fulfill them. Selected solvers carry out tasks under risk, with correctness checked post hoc by verifiers. Any challenger can challenge a result by staking against it to trigger the verification process. Incorrect agents are slashed and correct opposition is rewarded, with an escalation path that penalizes erroneous verifiers themselves. When incentives are aligned across solvers, challengers, and verifiers, falsification conditions make correctness the Nash equilibrium.",
    "summary": "arXiv:2507.00631v2 Announce Type: replace-cross Abstract: Correctness is an emergent property of systems where exposing error is cheaper than committing it. In dynamic, low-trust environments, autonomous AI agents benefit from delegating work to sub-agents, yet correctness cannot be assured through upfront specification or centralized oversight. We propose a protocol that enforces correctness through collateralized claims in a recursive verification game. Tasks are published as intents, and solvers compete to fulfill them. Selected solvers carry out tasks under risk, with correctness checked post hoc by verifiers. Any challenger can challenge a result by staking against it to trigger the verification process. Incorrect agents are slashed and correct opposition is rewarded, with an escalation path that penalizes erroneous verifiers themselves. When incentives are aligned across solvers, challengers, and verifiers, falsification conditions make correctness the Nash equilibrium.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.00631",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The New and Fresh analytics in Inference Endpoints",
    "description": "",
    "summary": "Analytics is important Analytics and metrics are the cornerstone of understanding what's happening w...",
    "pubDate": "Fri, 21 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/endpoint-analytics",
    "thumbnail": "https://huggingface.co/blog/assets/endpoint-analytics/thumbnail.png"
  },
  {
    "title": "Advantage Actor Critic (A2C)",
    "description": "",
    "summary": "Advantage Actor Critic (A2C) Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 7, of the‚ö†Ô∏è ...",
    "pubDate": "Fri, 22 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-a2c",
    "thumbnail": "https://huggingface.co/blog/assets/89_deep_rl_a2c/thumbnail.gif"
  },
  {
    "title": "Adaptability of ASR Models on Low-Resource Language: A Comparative Study of Whisper and Wav2Vec-BERT on Bangla",
    "description": "arXiv:2507.01931v1 Announce Type: cross Abstract: In recent years, neural models trained on large multilingual text and speech datasets have shown great potential for supporting low-resource languages. This study investigates the performances of two state-of-the-art Automatic Speech Recognition (ASR) models, OpenAI's Whisper (Small & Large-V2) and Facebook's Wav2Vec-BERT on Bangla, a low-resource language. We have conducted experiments using two publicly available datasets: Mozilla Common Voice-17 and OpenSLR to evaluate model performances. Through systematic fine-tuning and hyperparameter optimization, including learning rate, epochs, and model checkpoint selection, we have compared the models based on Word Error Rate (WER), Character Error Rate (CER), Training Time, and Computational Efficiency. The Wav2Vec-BERT model outperformed Whisper across all key evaluation metrics, demonstrated superior performance while requiring fewer computational resources, and offered valuable insights to develop robust speech recognition systems in low-resource linguistic settings.",
    "summary": "arXiv:2507.01931v1 Announce Type: cross Abstract: In recent years, neural models trained on large multilingual text and speech datasets have shown great potential for supporting low-resource languages. This study investigates the performances of two state-of-the-art Automatic Speech Recognition (ASR) models, OpenAI's Whisper (Small & Large-V2) and Facebook's Wav2Vec-BERT on Bangla, a low-resource language. We have conducted experiments using two publicly available datasets: Mozilla Common Voice-17 and OpenSLR to evaluate model performances. Through systematic fine-tuning and hyperparameter optimization, including learning rate, epochs, and model checkpoint selection, we have compared the models based on Word Error Rate (WER), Character Error Rate (CER), Training Time, and Computational Efficiency. The Wav2Vec-BERT model outperformed Whisper across all key evaluation metrics, demonstrated superior performance while requiring fewer computational resources, and offered valuable insights to develop robust speech recognition systems in low-resource linguistic settings.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01931",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Text2SQL using Hugging Face Dataset Viewer API and Motherduck DuckDB-NSQL-7B",
    "description": "",
    "summary": "Text2SQL using Hugging Face Dataset Viewer API and Motherduck DuckDB-NSQL-7B Today, integrating AI-p...",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/duckdb-nsql-7b",
    "thumbnail": "https://huggingface.co/blog/assets/duckdb-nsql-7b/thumbnail.png"
  },
  {
    "title": "Hugging Face Text Generation Inference available for AWS Inferentia2",
    "description": "",
    "summary": "Hugging Face Text Generation Inference available for AWS Inferentia2 We are excited to announce the ...",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-generation-inference-on-inferentia2",
    "thumbnail": "https://huggingface.co/blog/assets/175_text_generation_inference_on_inferentia2/thumbnail.jpg"
  },
  {
    "title": "Welcome Llama 3 - Meta's new open LLM",
    "description": "",
    "summary": "Welcome Llama 3 - Meta‚Äôs new open LLM Introduction Meta‚Äôs Llama 3, the next iteration of the open-ac...",
    "pubDate": "Thu, 18 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama3",
    "thumbnail": "https://huggingface.co/blog/assets/llama3/thumbnail.jpg"
  },
  {
    "title": "OpenAI Five Benchmark",
    "description": "The OpenAI Five Benchmark match is now over!",
    "summary": "The OpenAI Five Benchmark match is now over!",
    "pubDate": "Wed, 18 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-benchmark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Tiny Agents: a MCP-powered agent in 50 lines of code",
    "description": "",
    "summary": "Tiny Agents: an MCP-powered agent in 50 lines of code New! (May 23, '25) If you prefer Python, check...",
    "pubDate": "Fri, 25 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tiny-agents",
    "thumbnail": "https://huggingface.co/blog/assets/tiny-agents/thumbnail.jpg"
  },
  {
    "title": "Canva enables creativity with AI",
    "description": "A conversation with Cameron Adams, Chief Product Officer and Co-founder of Canva.",
    "summary": "A conversation with Cameron Adams, Chief Product Officer and Co-founder of Canva.",
    "pubDate": "Mon, 07 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/canva-cam-adams",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays",
    "description": "<p>The world‚Äôs first multimodal, bilingual radiology dataset could reshape the way radiologists and AI systems make sense of X-rays. PadChest-GR, developed by the University of Alicante with Microsoft Research, has the potential to advance research across the field for years to come.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/'>PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>The world‚Äôs first multimodal, bilingual radiology dataset could reshape the way radiologists and AI systems make sense of X-rays. PadChest-GR, developed by the University of Alicante with Microsoft Research, has the potential to advance research across the field for years to come.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/'>PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 26 Jun 2025 16:08:25 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Uber enables outstanding on-demand experiences with AI",
    "description": "A conversation with Jai Malkani, Head of AI and Product, Customer Obsession at Uber.",
    "summary": "A conversation with Jai Malkani, Head of AI and Product, Customer Obsession at Uber.",
    "pubDate": "Thu, 20 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/uber-enables-outstanding-experiences",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our updated Preparedness Framework",
    "description": "Sharing our updated framework for measuring and protecting against severe harm from frontier AI capabilities.",
    "summary": "Sharing our updated framework for measuring and protecting against severe harm from frontier AI capabilities.",
    "pubDate": "Tue, 15 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/updating-our-preparedness-framework",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Panel on Hugging Face",
    "description": "",
    "summary": "Panel on Hugging Face We are thrilled to announce the collaboration between Panel and Hugging Face! ...",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/panel-on-hugging-face",
    "thumbnail": "https://huggingface.co/blog/assets/panel-on-hugging-face/thumbnail.png"
  },
  {
    "title": "OpenAI‚Äôs API now available with no waitlist",
    "description": "Wider availability made possible by safety¬†progress.",
    "summary": "Wider availability made possible by safety¬†progress.",
    "pubDate": "Thu, 18 Nov 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-no-waitlist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing AI stories: daily benefits shine a light on bigger opportunities",
    "description": "Sam Altman has written that we are entering the Intelligence Age, a time when AI will help people become dramatically more capable. The biggest problems of today‚Äîacross science, medicine, education, national defense‚Äîwill no longer seem intractable, but will in fact be solvable. New horizons of possibility and prosperity will open up.",
    "summary": "Sam Altman has written that we are entering the Intelligence Age, a time when AI will help people become dramatically more capable. The biggest problems of today‚Äîacross science, medicine, education, national defense‚Äîwill no longer seem intractable, but will in fact be solvable. New horizons of possibility and prosperity will open up.",
    "pubDate": "Tue, 06 May 2025 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/ai-stories-daily-benefits-bigger-opportunities",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating Hugging Face Transformers with AWS Inferentia2",
    "description": "",
    "summary": "Accelerating Hugging Face Transformers with AWS Inferentia2 In the last five years, Transformer mode...",
    "pubDate": "Mon, 17 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-transformers-with-inferentia2",
    "thumbnail": "https://huggingface.co/blog/assets/140_accelerate_transformers_with_inferentia2/thumbnail.png"
  },
  {
    "title": "Adebayo Ogunlesi joins OpenAI‚Äôs Board of Directors",
    "description": "Adebayo Ogunlesi Joins OpenAI‚Äôs Board of Directors",
    "summary": "Adebayo Ogunlesi Joins OpenAI‚Äôs Board of Directors",
    "pubDate": "Tue, 14 Jan 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adebayo-ogunlesi-joins-openais-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Emergent tool use from multi-agent interaction",
    "description": "We‚Äôve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek. Through training in our new simulated hide-and-seek environment, agents build a series of six distinct strategies and counterstrategies, some of which we did not know our environment supported. The self-supervised emergent complexity in this simple environment further suggests that multi-agent co-adaptation may one day produce extremely complex and intelligent behavior.",
    "summary": "We‚Äôve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek. Through training in our new simulated hide-and-seek environment, agents build a series of six distinct strategies and counterstrategies, some of which we did not know our environment supported. The self-supervised emergent complexity in this simple environment further suggests that multi-agent co-adaptation may one day produce extremely complex and intelligent behavior.",
    "pubDate": "Tue, 17 Sep 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergent-tool-use",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-4 API general availability and deprecation of older models in the Completions API",
    "description": "GPT-3.5 Turbo, DALL¬∑E and Whisper APIs are also generally available, and we are releasing a deprecation plan for older models of the Completions API, which will retire at the beginning of 2024.",
    "summary": "GPT-3.5 Turbo, DALL¬∑E and Whisper APIs are also generally available, and we are releasing a deprecation plan for older models of the Completions API, which will retire at the beginning of 2024.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-api-general-availability",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Customizable, no-code voice agent automation with GPT-4o",
    "description": "Retell AI is transforming the call center with AI voice automation powered by GPT-4o and GPT-4.1. Its no-code platform enables businesses to launch natural, real-time voice agents that cut call costs, boost CSAT, and automate customer conversations‚Äîwithout scripts or hold times.",
    "summary": "Retell AI is transforming the call center with AI voice automation powered by GPT-4o and GPT-4.1. Its no-code platform enables businesses to launch natural, real-time voice agents that cut call costs, boost CSAT, and automate customer conversations‚Äîwithout scripts or hold times.",
    "pubDate": "Thu, 26 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retell-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Happy 1st anniversary ü§ó Diffusers!",
    "description": "",
    "summary": "Happy 1st anniversary ü§ó Diffusers! ü§ó Diffusers is happy to celebrate its first anniversary! It has b...",
    "pubDate": "Thu, 20 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-turns-1",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers-turns-1/diffusers-turns-1.png"
  },
  {
    "title": "Rethinking All Evidence: Enhancing Trustworthy Retrieval-Augmented Generation via Conflict-Driven Summarization",
    "description": "arXiv:2507.01281v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by integrating their parametric knowledge with external retrieved content. However, knowledge conflicts caused by internal inconsistencies or noisy retrieved content can severely undermine the generation reliability of RAG systems.In this work, we argue that LLMs should rethink all evidence, including both retrieved content and internal knowledge, before generating responses.We propose CARE-RAG (Conflict-Aware and Reliable Evidence for RAG), a novel framework that improves trustworthiness through Conflict-Driven Summarization of all available evidence.CARE-RAG first derives parameter-aware evidence by comparing parameter records to identify diverse internal perspectives. It then refines retrieved evidences to produce context-aware evidence, removing irrelevant or misleading content. To detect and summarize conflicts, we distill a 3B LLaMA3.2 model to perform conflict-driven summarization, enabling reliable synthesis across multiple sources.To further ensure evaluation integrity, we introduce a QA Repair step to correct outdated or ambiguous benchmark answers.Experiments on revised QA datasets with retrieval data show that CARE-RAG consistently outperforms strong RAG baselines, especially in scenarios with noisy or conflicting evidence.",
    "summary": "arXiv:2507.01281v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by integrating their parametric knowledge with external retrieved content. However, knowledge conflicts caused by internal inconsistencies or noisy retrieved content can severely undermine the generation reliability of RAG systems.In this work, we argue that LLMs should rethink all evidence, including both retrieved content and internal knowledge, before generating responses.We propose CARE-RAG (Conflict-Aware and Reliable Evidence for RAG), a novel framework that improves trustworthiness through Conflict-Driven Summarization of all available evidence.CARE-RAG first derives parameter-aware evidence by comparing parameter records to identify diverse internal perspectives. It then refines retrieved evidences to produce context-aware evidence, removing irrelevant or misleading content. To detect and summarize conflicts, we distill a 3B LLaMA3.2 model to perform conflict-driven summarization, enabling reliable synthesis across multiple sources.To further ensure evaluation integrity, we introduce a QA Repair step to correct outdated or ambiguous benchmark answers.Experiments on revised QA datasets with retrieval data show that CARE-RAG consistently outperforms strong RAG baselines, especially in scenarios with noisy or conflicting evidence.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01281",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Public Policy at Hugging Face",
    "description": "",
    "summary": "Public Policy at Hugging Face Published April 8, 2024 Update on GitHubAI Policy at Hugging Face is a...",
    "pubDate": "Mon, 08 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/policy-blog",
    "thumbnail": "https://huggingface.co/blog/assets/policy_docs/policy_blog_thumbnail.png"
  },
  {
    "title": "Driving scalable growth with OpenAI o3, GPT-4.1, and CUA",
    "description": "Unify, an AI-powered GTM platform, uses OpenAI‚Äôs o3, GPT-4.1, and CUA to automate prospecting, research, and outreach. With hyper-personalized messaging and an always-on workflow, Unify helps teams generate pipeline at scale while focusing on high-impact customer interactions.",
    "summary": "Unify, an AI-powered GTM platform, uses OpenAI‚Äôs o3, GPT-4.1, and CUA to automate prospecting, research, and outreach. With hyper-personalized messaging and an always-on workflow, Unify helps teams generate pipeline at scale while focusing on high-impact customer interactions.",
    "pubDate": "Tue, 24 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/unify",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Meta-learning for wrestling",
    "description": "We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to physical malfunction.",
    "summary": "We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to physical malfunction.",
    "pubDate": "Wed, 11 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/meta-learning-for-wrestling",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TRACED: Transition-aware Regret Approximation with Co-learnability for Environment Design",
    "description": "arXiv:2506.19997v2 Announce Type: replace-cross Abstract: Generalizing deep reinforcement learning agents to unseen environments remains a significant challenge. One promising solution is Unsupervised Environment Design (UED), a co-evolutionary framework in which a teacher adaptively generates tasks with high learning potential, while a student learns a robust policy from this evolving curriculum. Existing UED methods typically measure learning potential via regret, the gap between optimal and current performance, approximated solely by value-function loss. Building on these approaches, we introduce the transition prediction error as an additional term in our regret approximation. To capture how training on one task affects performance on others, we further propose a lightweight metric called co-learnability. By combining these two measures, we present Transition-aware Regret Approximation with Co-learnability for Environment Design (TRACED). Empirical evaluations show that TRACED yields curricula that improve zero-shot generalization across multiple benchmarks while requiring up to 2x fewer environment interactions than strong baselines. Ablation studies confirm that the transition prediction error drives rapid complexity ramp-up and that co-learnability delivers additional gains when paired with the transition prediction error. These results demonstrate how refined regret approximation and explicit modeling of task relationships can be leveraged for sample-efficient curriculum design in UED.",
    "summary": "arXiv:2506.19997v2 Announce Type: replace-cross Abstract: Generalizing deep reinforcement learning agents to unseen environments remains a significant challenge. One promising solution is Unsupervised Environment Design (UED), a co-evolutionary framework in which a teacher adaptively generates tasks with high learning potential, while a student learns a robust policy from this evolving curriculum. Existing UED methods typically measure learning potential via regret, the gap between optimal and current performance, approximated solely by value-function loss. Building on these approaches, we introduce the transition prediction error as an additional term in our regret approximation. To capture how training on one task affects performance on others, we further propose a lightweight metric called co-learnability. By combining these two measures, we present Transition-aware Regret Approximation with Co-learnability for Environment Design (TRACED). Empirical evaluations show that TRACED yields curricula that improve zero-shot generalization across multiple benchmarks while requiring up to 2x fewer environment interactions than strong baselines. Ablation studies confirm that the transition prediction error drives rapid complexity ramp-up and that co-learnability delivers additional gains when paired with the transition prediction error. These results demonstrate how refined regret approximation and explicit modeling of task relationships can be leveraged for sample-efficient curriculum design in UED.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19997",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Optimum+ONNX Runtime - Easier, Faster training for your Hugging Face models",
    "description": "",
    "summary": "Optimum + ONNX Runtime: Easier, Faster training for your Hugging Face models Introduction Transforme...",
    "pubDate": "Tue, 24 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-onnxruntime-training",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_onnxruntime-training/thumbnail.png"
  },
  {
    "title": "Fine-tuning GPT-2 from human preferences",
    "description": "We‚Äôve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we‚Äôd only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required only 5k. Our motivation is to move safety techniques closer to the general task of ‚Äúmachines talking to humans,‚Äù which we believe is key to extracting information about human¬†values.",
    "summary": "We‚Äôve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we‚Äôd only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required only 5k. Our motivation is to move safety techniques closer to the general task of ‚Äúmachines talking to humans,‚Äù which we believe is key to extracting information about human¬†values.",
    "pubDate": "Thu, 19 Sep 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fine-tuning-gpt-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Open Leaderboard for Hebrew LLMs!",
    "description": "",
    "summary": "Introducing the Open Leaderboard for Hebrew LLMs! This project addresses the critical need for advan...",
    "pubDate": "Sun, 05 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-hebrew",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_hebrew.png"
  },
  {
    "title": "Requests for Research 2.0",
    "description": "We‚Äôre releasing a new batch of¬†seven unsolved problems¬†which have come up in the course of our research at OpenAI.",
    "summary": "We‚Äôre releasing a new batch of¬†seven unsolved problems¬†which have come up in the course of our research at OpenAI.",
    "pubDate": "Wed, 31 Jan 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/requests-for-research-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "RALLY: Role-Adaptive LLM-Driven Yoked Navigation for Agentic UAV Swarms",
    "description": "arXiv:2507.01378v1 Announce Type: cross Abstract: Intelligent control of Unmanned Aerial Vehicles (UAVs) swarms has emerged as a critical research focus, and it typically requires the swarm to navigate effectively while avoiding obstacles and achieving continuous coverage over multiple mission targets. Although traditional Multi-Agent Reinforcement Learning (MARL) approaches offer dynamic adaptability, they are hindered by the semantic gap in numerical communication and the rigidity of homogeneous role structures, resulting in poor generalization and limited task scalability. Recent advances in Large Language Model (LLM)-based control frameworks demonstrate strong semantic reasoning capabilities by leveraging extensive prior knowledge. However, due to the lack of online learning and over-reliance on static priors, these works often struggle with effective exploration, leading to reduced individual potential and overall system performance. To address these limitations, we propose a Role-Adaptive LLM-Driven Yoked navigation algorithm RALLY. Specifically, we first develop an LLM-driven semantic decision framework that uses structured natural language for efficient semantic communication and collaborative reasoning. Afterward, we introduce a dynamic role-heterogeneity mechanism for adaptive role switching and personalized decision-making. Furthermore, we propose a Role-value Mixing Network (RMIX)-based assignment strategy that integrates LLM offline priors with MARL online policies to enable semi-offline training of role selection strategies. Experiments in the Multi-Agent Particle Environment (MPE) environment and a Software-In-The-Loop (SITL) platform demonstrate that RALLY outperforms conventional approaches in terms of task coverage, convergence speed, and generalization, highlighting its strong potential for collaborative navigation in agentic multi-UAV systems.",
    "summary": "arXiv:2507.01378v1 Announce Type: cross Abstract: Intelligent control of Unmanned Aerial Vehicles (UAVs) swarms has emerged as a critical research focus, and it typically requires the swarm to navigate effectively while avoiding obstacles and achieving continuous coverage over multiple mission targets. Although traditional Multi-Agent Reinforcement Learning (MARL) approaches offer dynamic adaptability, they are hindered by the semantic gap in numerical communication and the rigidity of homogeneous role structures, resulting in poor generalization and limited task scalability. Recent advances in Large Language Model (LLM)-based control frameworks demonstrate strong semantic reasoning capabilities by leveraging extensive prior knowledge. However, due to the lack of online learning and over-reliance on static priors, these works often struggle with effective exploration, leading to reduced individual potential and overall system performance. To address these limitations, we propose a Role-Adaptive LLM-Driven Yoked navigation algorithm RALLY. Specifically, we first develop an LLM-driven semantic decision framework that uses structured natural language for efficient semantic communication and collaborative reasoning. Afterward, we introduce a dynamic role-heterogeneity mechanism for adaptive role switching and personalized decision-making. Furthermore, we propose a Role-value Mixing Network (RMIX)-based assignment strategy that integrates LLM offline priors with MARL online policies to enable semi-offline training of role selection strategies. Experiments in the Multi-Agent Particle Environment (MPE) environment and a Software-In-The-Loop (SITL) platform demonstrate that RALLY outperforms conventional approaches in terms of task coverage, convergence speed, and generalization, highlighting its strong potential for collaborative navigation in agentic multi-UAV systems.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01378",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Insights from global conversations",
    "description": "We are sharing what we learned from our conversations across 22 countries, and how we will be incorporating those insights moving forward.",
    "summary": "We are sharing what we learned from our conversations across 22 countries, and how we will be incorporating those insights moving forward.",
    "pubDate": "Thu, 29 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/insights-from-global-conversations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Investing in Performance: Fine-tune small models with LLM insights  - a CFM case study",
    "description": "",
    "summary": "Investing in Performance: Fine-tune small models with LLM insights - a CFM case study Overview: This...",
    "pubDate": "Tue, 03 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cfm-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/cfm-case-study/blogpost_cfm.png"
  },
  {
    "title": "How we sped up transformer inference 100x for ü§ó API customers",
    "description": "",
    "summary": "How we sped up transformer inference 100x for ü§ó API customers ü§ó Transformers has become the default ...",
    "pubDate": "Mon, 18 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerated-inference",
    "thumbnail": "https://huggingface.co/blog/assets/09_accelerated_inference/thumbnail.png"
  },
  {
    "title": "Enhancing Robustness to Missing Modalities through Clustered Federated Learning",
    "description": "arXiv:2505.06911v2 Announce Type: replace-cross Abstract: In the era of big data, data mining has become indispensable for uncovering hidden patterns and insights from vast and complex datasets. The integration of multimodal data sources further enhances its potential. Multimodal Federated Learning (MFL) is a distributed approach that enhances the efficiency and quality of multimodal learning, ensuring collaborative work and privacy protection. However, missing modalities pose a significant challenge in MFL, often due to data quality issues or privacy policies across the clients. In this work, we present MMiC, a framework for Mitigating Modality incompleteness in MFL within the Clusters. MMiC replaces partial parameters within client models inside clusters to mitigate the impact of missing modalities. Furthermore, it leverages the Banzhaf Power Index to optimize client selection under these conditions. Finally, MMiC employs an innovative approach to dynamically control global aggregation by utilizing Markovitz Portfolio Optimization. Extensive experiments demonstrate that MMiC consistently outperforms existing federated learning architectures in both global and personalized performance on multimodal datasets with missing modalities, confirming the effectiveness of our proposed solution.",
    "summary": "arXiv:2505.06911v2 Announce Type: replace-cross Abstract: In the era of big data, data mining has become indispensable for uncovering hidden patterns and insights from vast and complex datasets. The integration of multimodal data sources further enhances its potential. Multimodal Federated Learning (MFL) is a distributed approach that enhances the efficiency and quality of multimodal learning, ensuring collaborative work and privacy protection. However, missing modalities pose a significant challenge in MFL, often due to data quality issues or privacy policies across the clients. In this work, we present MMiC, a framework for Mitigating Modality incompleteness in MFL within the Clusters. MMiC replaces partial parameters within client models inside clusters to mitigate the impact of missing modalities. Furthermore, it leverages the Banzhaf Power Index to optimize client selection under these conditions. Finally, MMiC employs an innovative approach to dynamically control global aggregation by utilizing Markovitz Portfolio Optimization. Extensive experiments demonstrate that MMiC consistently outperforms existing federated learning architectures in both global and personalized performance on multimodal datasets with missing modalities, confirming the effectiveness of our proposed solution.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.06911",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Adapting Probabilistic Risk Assessment for AI",
    "description": "arXiv:2504.18536v3 Announce Type: replace Abstract: Modern general-purpose artificial intelligence (AI) systems present an urgent risk management challenge, as their rapidly evolving capabilities and potential for catastrophic harm outpace our ability to reliably assess their risks. Current methods often rely on selective testing and undocumented assumptions about risk priorities, frequently failing to make a serious attempt at assessing the set of pathways through which AI systems pose direct or indirect risks to society and the biosphere. This paper introduces the probabilistic risk assessment (PRA) for AI framework, adapting established PRA techniques from high-reliability industries (e.g., nuclear power, aerospace) for the new challenges of advanced AI. The framework guides assessors in identifying potential risks, estimating likelihood and severity bands, and explicitly documenting evidence, underlying assumptions, and analyses at appropriate granularities. The framework's implementation tool synthesizes the results into a risk report card with aggregated risk estimates from all assessed risks. It introduces three methodological advances: (1) Aspect-oriented hazard analysis provides systematic hazard coverage guided by a first-principles taxonomy of AI system aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk pathway modeling analyzes causal chains from system aspects to societal impacts using bidirectional analysis and incorporating prospective techniques; and (3) Uncertainty management employs scenario decomposition, reference scales, and explicit tracing protocols to structure credible projections with novelty or limited data. Additionally, the framework harmonizes diverse assessment methods by integrating evidence into comparable, quantified absolute risk estimates for lifecycle decisions. We have implemented this as a workbook tool for AI developers, evaluators, and regulators.",
    "summary": "arXiv:2504.18536v3 Announce Type: replace Abstract: Modern general-purpose artificial intelligence (AI) systems present an urgent risk management challenge, as their rapidly evolving capabilities and potential for catastrophic harm outpace our ability to reliably assess their risks. Current methods often rely on selective testing and undocumented assumptions about risk priorities, frequently failing to make a serious attempt at assessing the set of pathways through which AI systems pose direct or indirect risks to society and the biosphere. This paper introduces the probabilistic risk assessment (PRA) for AI framework, adapting established PRA techniques from high-reliability industries (e.g., nuclear power, aerospace) for the new challenges of advanced AI. The framework guides assessors in identifying potential risks, estimating likelihood and severity bands, and explicitly documenting evidence, underlying assumptions, and analyses at appropriate granularities. The framework's implementation tool synthesizes the results into a risk report card with aggregated risk estimates from all assessed risks. It introduces three methodological advances: (1) Aspect-oriented hazard analysis provides systematic hazard coverage guided by a first-principles taxonomy of AI system aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk pathway modeling analyzes causal chains from system aspects to societal impacts using bidirectional analysis and incorporating prospective techniques; and (3) Uncertainty management employs scenario decomposition, reference scales, and explicit tracing protocols to structure credible projections with novelty or limited data. Additionally, the framework harmonizes diverse assessment methods by integrating evidence into comparable, quantified absolute risk estimates for lifecycle decisions. We have implemented this as a workbook tool for AI developers, evaluators, and regulators.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.18536",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MILP-SAT-GNN: Yet Another Neural SAT Solver",
    "description": "arXiv:2507.01825v1 Announce Type: cross Abstract: We proposes a novel method that enables Graph Neural Networks (GNNs) to solve SAT problems by leveraging a technique developed for applying GNNs to Mixed Integer Linear Programming (MILP). Specifically, k-CNF formulae are mapped into MILP problems, which are then encoded as weighted bipartite graphs and subsequently fed into a GNN for training and testing. From a theoretical perspective: (i) we establish permutation and equivalence invariance results, demonstrating that the method produces outputs that are stable under reordering of clauses and variables; (ii) we identify a theoretical limitation, showing that for a class of formulae called foldable formulae, standard GNNs cannot always distinguish satisfiable from unsatisfiable instances; (iii) we prove a universal approximation theorem, establishing that with Random Node Initialization (RNI), the method can approximate SAT solving to arbitrary precision on finite datasets, that is, the GNN becomes approximately sound and complete on such datasets. Furthermore, we show that for unfoldable formulae, the same approximation guarantee can be achieved without the need for RNI. Finally, we conduct an experimental evaluation of our approach, which show that, despite the simplicity of the neural architecture, the method achieves promising results.",
    "summary": "arXiv:2507.01825v1 Announce Type: cross Abstract: We proposes a novel method that enables Graph Neural Networks (GNNs) to solve SAT problems by leveraging a technique developed for applying GNNs to Mixed Integer Linear Programming (MILP). Specifically, k-CNF formulae are mapped into MILP problems, which are then encoded as weighted bipartite graphs and subsequently fed into a GNN for training and testing. From a theoretical perspective: (i) we establish permutation and equivalence invariance results, demonstrating that the method produces outputs that are stable under reordering of clauses and variables; (ii) we identify a theoretical limitation, showing that for a class of formulae called foldable formulae, standard GNNs cannot always distinguish satisfiable from unsatisfiable instances; (iii) we prove a universal approximation theorem, establishing that with Random Node Initialization (RNI), the method can approximate SAT solving to arbitrary precision on finite datasets, that is, the GNN becomes approximately sound and complete on such datasets. Furthermore, we show that for unfoldable formulae, the same approximation guarantee can be achieved without the need for RNI. Finally, we conduct an experimental evaluation of our approach, which show that, despite the simplicity of the neural architecture, the method achieves promising results.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01825",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tuning Llama 2 70B using PyTorch FSDP",
    "description": "",
    "summary": "Fine-tuning Llama 2 70B using PyTorch FSDP Introduction In this blog post, we will look at how to fi...",
    "pubDate": "Wed, 13 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ram-efficient-pytorch-fsdp",
    "thumbnail": "https://huggingface.co/blog/assets/160_fsdp_llama/thumbnail.jpg"
  },
  {
    "title": "AI„ÅßÊº´ÁîªÂÆ∂„Çµ„Éù„Éº„Éà„Åô„ÇãÊñ∞‰ºöÁ§æ„ÄÄ„ÄåÊú¨‰∫∫„ÅÆÁîªÈ¢®ÂÜçÁèæ„Äç„ÅßËá™Âãï„Éö„É≥ÂÖ•„Çå„ÄÄ„Ç≥„É´„ÇØ‰ΩêÊ∏°Â≥∂Ê∞è„ÉªTHE GUILDÊ∑±Ê¥•Ê∞è„ÇÇÂèÇÁîª",
    "description": "Visual Bank„ÅØ„ÄÅAIÊäÄË°ì„ÅßÊº´ÁîªÂÆ∂„Çí„Çµ„Éù„Éº„Éà„Åô„Çã‰ºÅÊ•≠„ÄåTHE PEN„Äç„ÇíË®≠Á´ã„Åó„Åü„Å®Áô∫Ë°®„Åó„Åü„ÄÇ‰ΩúÂÆ∂Êú¨‰∫∫„ÅÆÁîªÈ¢®„ÇíÂÜçÁèæ„Åó„ÄÅ„Éç„Éº„É†ÂéüÁ®ø„Å´Ëá™Âãï„Åß„Éö„É≥ÂÖ•„Çå„ÇíË°å„ÅÜAI„ÉÑ„Éº„É´„ÄåPEN editor„Äç„ÇíÊèê‰æõ„ÄÇ‰ΩúÁîªÊôÇÈñì„ÇíÁü≠Á∏Æ„Åó„ÄÅÊº´ÁîªÂÆ∂„ÅÆÁîüÁî£ÊÄßÂêë‰∏ä„Å´„Å§„Å™„Åí„Çã„Å®„ÅÑ„ÅÜ„ÄÇ",
    "summary": "Visual Bank„ÅØ„ÄÅAIÊäÄË°ì„ÅßÊº´ÁîªÂÆ∂„Çí„Çµ„Éù„Éº„Éà„Åô„Çã‰ºÅÊ•≠„ÄåTHE PEN„Äç„ÇíË®≠Á´ã„Åó„Åü„Å®Áô∫Ë°®„Åó„Åü„ÄÇ‰ΩúÂÆ∂Êú¨‰∫∫„ÅÆÁîªÈ¢®„ÇíÂÜçÁèæ„Åó„ÄÅ„Éç„Éº„É†ÂéüÁ®ø„Å´Ëá™Âãï„Åß„Éö„É≥ÂÖ•„Çå„ÇíË°å„ÅÜAI„ÉÑ„Éº„É´„ÄåPEN editor„Äç„ÇíÊèê‰æõ„ÄÇ‰ΩúÁîªÊôÇÈñì„ÇíÁü≠Á∏Æ„Åó„ÄÅÊº´ÁîªÂÆ∂„ÅÆÁîüÁî£ÊÄßÂêë‰∏ä„Å´„Å§„Å™„Åí„Çã„Å®„ÅÑ„ÅÜ„ÄÇ",
    "pubDate": "Wed, 02 Jul 2025 12:45:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/02/news060.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/02/cover_news060.jpg"
  },
  {
    "title": "Hyperparameter Search with Transformers and Ray Tune",
    "description": "",
    "summary": "Hyperparameter Search with Transformers and Ray Tune A guest blog post by Richard Liaw from the Anys...",
    "pubDate": "Mon, 02 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ray-tune",
    "thumbnail": "https://huggingface.co/blog/assets/06_ray_tune/ray-hf.jpg"
  },
  {
    "title": "A Dive into Text-to-Video Models",
    "description": "",
    "summary": "Text-to-Video: The Task, Challenges and the Current State Video samples generated with ModelScope. T...",
    "pubDate": "Mon, 08 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-to-video",
    "thumbnail": "https://huggingface.co/blog/assets/140_text-to-video/thumbnail.png"
  },
  {
    "title": "2023: A Year of Groundbreaking Advances in AI and Computing",
    "description": "This has been a year of incredible progress in the field of Artificial Intelligence (AI) research and its practical applications.",
    "summary": "This has been a year of incredible progress in the field of Artificial Intelligence (AI) research and its practical applications.",
    "pubDate": "Fri, 22 Dec 2023 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/2023-a-year-of-groundbreaking-advances-in-ai-and-computing/",
    "thumbnail": "https://lh3.googleusercontent.com/fkZqqqpfLKvV2E6ebVmYJjR9q9XnczvWtiui5uU-yPkHCQb5mLAB4kBmh3opGqOJLhtaC58td96UtvULI8uGpbB9TmejR82GZ2vWOqTyWZ6HSItIpHg=w1200-h630-n-nu"
  },
  {
    "title": "Perceiver IO: a scalable, fully-attentional model that works on any modality",
    "description": "",
    "summary": "Perceiver IO: a scalable, fully-attentional model that works on any modality TLDR We've added Percei...",
    "pubDate": "Wed, 15 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/perceiver",
    "thumbnail": "https://huggingface.co/blog/assets/41_perceiver/thumbnail.png"
  },
  {
    "title": "Introducing HELMET",
    "description": "",
    "summary": "Introducing HELMET: Holistically Evaluating Long-context Language Models Contact: hyen@cs.princeton....",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/helmet",
    "thumbnail": "https://huggingface.co/blog/assets/helmet/thumbnail.png"
  },
  {
    "title": "Using GPT-4 to deliver a new customer service standard",
    "description": "Ada uses GPT-4 to deliver a new customer service standard",
    "summary": "Ada uses GPT-4 to deliver a new customer service standard",
    "pubDate": "Thu, 05 Sep 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ada",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generative modeling with sparse transformers",
    "description": "We‚Äôve developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence‚Äîwhether text, images, or sound. It uses an algorithmic improvement of the¬†attention¬†mechanism to extract patterns from sequences 30x longer than possible¬†previously.",
    "summary": "We‚Äôve developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence‚Äîwhether text, images, or sound. It uses an algorithmic improvement of the¬†attention¬†mechanism to extract patterns from sequences 30x longer than possible¬†previously.",
    "pubDate": "Tue, 23 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sparse-transformer",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Creating nail art with ChatGPT",
    "description": "Using ChatGPT to find inspiration for nail art",
    "summary": "Using ChatGPT to find inspiration for nail art",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ten-tiny-canvases",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Start using ChatGPT instantly",
    "description": "We‚Äôre making it easier for people to experience the benefits of AI without needing to sign up",
    "summary": "We‚Äôre making it easier for people to experience the benefits of AI without needing to sign up",
    "pubDate": "Mon, 01 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/start-using-chatgpt-instantly",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "What's going on with the Open LLM Leaderboard?",
    "description": "",
    "summary": "What's going on with the Open LLM Leaderboard? Recently an interesting discussion arose on Twitter f...",
    "pubDate": "Fri, 23 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-mmlu",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "Addendum to o3 and o4-mini system card: Codex",
    "description": "Codex is a cloud-based coding agent. Codex is powered by codex-1, a version of OpenAI o3 optimized for software engineering. codex-1 was trained using reinforcement learning on real-world coding tasks in a variety of environments to generate code that closely mirrors human style and PR preferences, adheres precisely to instructions, and iteratively runs tests until passing results are achieved.",
    "summary": "Codex is a cloud-based coding agent. Codex is powered by codex-1, a version of OpenAI o3 optimized for software engineering. codex-1 was trained using reinforcement learning on real-world coding tasks in a variety of environments to generate code that closely mirrors human style and PR preferences, adheres precisely to instructions, and iteratively runs tests until passing results are achieved.",
    "pubDate": "Fri, 16 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-codex-system-card-addendum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-4V(ision) system card",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4v-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and FriendliAI partner to supercharge model deployment on the Hub",
    "description": "",
    "summary": "Hugging Face and FriendliAI partner to supercharge model deployment on the Hub FriendliAI‚Äôs inferenc...",
    "pubDate": "Wed, 22 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/friendliai-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/ai-icon.png"
  },
  {
    "title": "Introducing deep research",
    "description": "An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.",
    "summary": "An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.",
    "pubDate": "Sun, 02 Feb 2025 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-deep-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and AMD partner on accelerating state-of-the-art models for CPU and GPU platforms",
    "description": "",
    "summary": "Hugging Face and AMD partner on accelerating state-of-the-art models for CPU and GPU platforms Wheth...",
    "pubDate": "Tue, 13 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-amd",
    "thumbnail": "https://huggingface.co/blog/assets/148_huggingface_amd/01.png"
  },
  {
    "title": "Preference Tuning LLMs with Direct Preference Optimization Methods",
    "description": "",
    "summary": "Preference Tuning LLMs with Direct Preference Optimization Methods Addendum After consulting with th...",
    "pubDate": "Thu, 18 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pref-tuning",
    "thumbnail": "https://huggingface.co/blog/assets/pref-tuning/thumbnail.jpg"
  },
  {
    "title": "Towards Efficient Educational Chatbots: Benchmarking RAG Frameworks",
    "description": "arXiv:2503.00781v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have proven immensely beneficial in education by capturing vast amounts of literature-based information, allowing them to generate context without relying on external sources. In this paper, we propose a generative AI-powered GATE question-answering framework (GATE stands for Graduate Aptitude Test in Engineering) that leverages LLMs to explain GATE solutions and support students in their exam preparation. We conducted extensive benchmarking to select the optimal embedding model and LLM, evaluating our framework based on criteria such as latency, faithfulness, and relevance, with additional validation through human evaluation. Our chatbot integrates state-of-the-art embedding models and LLMs to deliver accurate, context-aware responses. Through rigorous experimentation, we identified configurations that balance performance and computational efficiency, ensuring a reliable chatbot to serve students' needs. Additionally, we discuss the challenges faced in data processing and modeling and implemented solutions. Our work explores the application of Retrieval-Augmented Generation (RAG) for GATE Q/A explanation tasks, and our findings demonstrate significant improvements in retrieval accuracy and response quality. This research offers practical insights for developing effective AI-driven educational tools while highlighting areas for future enhancement in usability and scalability.",
    "summary": "arXiv:2503.00781v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have proven immensely beneficial in education by capturing vast amounts of literature-based information, allowing them to generate context without relying on external sources. In this paper, we propose a generative AI-powered GATE question-answering framework (GATE stands for Graduate Aptitude Test in Engineering) that leverages LLMs to explain GATE solutions and support students in their exam preparation. We conducted extensive benchmarking to select the optimal embedding model and LLM, evaluating our framework based on criteria such as latency, faithfulness, and relevance, with additional validation through human evaluation. Our chatbot integrates state-of-the-art embedding models and LLMs to deliver accurate, context-aware responses. Through rigorous experimentation, we identified configurations that balance performance and computational efficiency, ensuring a reliable chatbot to serve students' needs. Additionally, we discuss the challenges faced in data processing and modeling and implemented solutions. Our work explores the application of Retrieval-Augmented Generation (RAG) for GATE Q/A explanation tasks, and our findings demonstrate significant improvements in retrieval accuracy and response quality. This research offers practical insights for developing effective AI-driven educational tools while highlighting areas for future enhancement in usability and scalability.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.00781",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Controlling Language Model Generation with NVIDIA's LogitsProcessorZoo",
    "description": "",
    "summary": "Controlling Language Model Generation with NVIDIA's LogitsProcessorZoo Generating text with language...",
    "pubDate": "Mon, 23 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/logits-processor-zoo",
    "thumbnail": "https://huggingface.co/blog/assets/logits-processor-zoo/thumbnail.png"
  },
  {
    "title": "Optimization story: Bloom inference",
    "description": "",
    "summary": "Optimization story: Bloom inference This article gives you the behind-the-scenes of how we made an e...",
    "pubDate": "Wed, 12 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-inference-optimization",
    "thumbnail": "https://huggingface.co/blog/assets/bloom-inference-pytorch-scripts/thumbnail.png"
  },
  {
    "title": "Exploring a Hybrid Deep Learning Approach for Anomaly Detection in Mental Healthcare Provider Billing: Addressing Label Scarcity through Semi-Supervised Anomaly Detection",
    "description": "arXiv:2507.01924v1 Announce Type: cross Abstract: The complexity of mental healthcare billing enables anomalies, including fraud. While machine learning methods have been applied to anomaly detection, they often struggle with class imbalance, label scarcity, and complex sequential patterns. This study explores a hybrid deep learning approach combining Long Short-Term Memory (LSTM) networks and Transformers, with pseudo-labeling via Isolation Forests (iForest) and Autoencoders (AE). Prior work has not evaluated such hybrid models trained on pseudo-labeled data in the context of healthcare billing. The approach is evaluated on two real-world billing datasets related to mental healthcare. The iForest LSTM baseline achieves the highest recall (0.963) on declaration-level data. On the operation-level data, the hybrid iForest-based model achieves the highest recall (0.744), though at the cost of lower precision. These findings highlight the potential of combining pseudo-labeling with hybrid deep learning in complex, imbalanced anomaly detection settings.",
    "summary": "arXiv:2507.01924v1 Announce Type: cross Abstract: The complexity of mental healthcare billing enables anomalies, including fraud. While machine learning methods have been applied to anomaly detection, they often struggle with class imbalance, label scarcity, and complex sequential patterns. This study explores a hybrid deep learning approach combining Long Short-Term Memory (LSTM) networks and Transformers, with pseudo-labeling via Isolation Forests (iForest) and Autoencoders (AE). Prior work has not evaluated such hybrid models trained on pseudo-labeled data in the context of healthcare billing. The approach is evaluated on two real-world billing datasets related to mental healthcare. The iForest LSTM baseline achieves the highest recall (0.963) on declaration-level data. On the operation-level data, the hybrid iForest-based model achieves the highest recall (0.744), though at the cost of lower precision. These findings highlight the potential of combining pseudo-labeling with hybrid deep learning in complex, imbalanced anomaly detection settings.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01924",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DALL¬∑E 2 pre-training mitigations",
    "description": "In order to share the magic of¬†DALL¬∑E 2¬†with a broad audience, we needed to reduce the risks associated with powerful image generation models. To this end, we put various¬†guardrails¬†in place to prevent generated images from violating our¬†content policy.",
    "summary": "In order to share the magic of¬†DALL¬∑E 2¬†with a broad audience, we needed to reduce the risks associated with powerful image generation models. To this end, we put various¬†guardrails¬†in place to prevent generated images from violating our¬†content policy.",
    "pubDate": "Tue, 28 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-pre-training-mitigations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Stable Diffusion in JAX/Flax üöÄ",
    "description": "",
    "summary": "üß® Stable Diffusion in JAX / Flax ! ü§ó Hugging Face Diffusers supports Flax since version 0.5.1 ! This...",
    "pubDate": "Thu, 13 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable_diffusion_jax",
    "thumbnail": "https://huggingface.co/blog/assets/108_stable_diffusion_jax/thumbnail.png"
  },
  {
    "title": "Creating agent and human collaboration with GPT 4o",
    "description": "Altera uses GPT-4o to build a new area of human collaboration",
    "summary": "Altera uses GPT-4o to build a new area of human collaboration",
    "pubDate": "Tue, 01 Oct 2024 09:59:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/altera",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Using LoRA for Efficient Stable Diffusion Fine-Tuning",
    "description": "",
    "summary": "Using LoRA for Efficient Stable Diffusion Fine-Tuning LoRA: Low-Rank Adaptation of Large Language Mo...",
    "pubDate": "Thu, 26 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lora",
    "thumbnail": "https://huggingface.co/blog/assets/lora/thumbnail.png"
  },
  {
    "title": "2024 Security Feature Highlights",
    "description": "",
    "summary": "2024 Security Feature Highlights Security is a top priority at Hugging Face, and we're committed to ...",
    "pubDate": "Tue, 06 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/2024-security-features",
    "thumbnail": "https://huggingface.co/blog/assets/2024-security-features/thumbnail.png"
  },
  {
    "title": "Learning from human preferences",
    "description": "One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind‚Äôs safety team, we‚Äôve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better.",
    "summary": "One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind‚Äôs safety team, we‚Äôve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better.",
    "pubDate": "Tue, 13 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-from-human-preferences",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Put AI to work: Automate and Scale Financial Operations",
    "description": "Put AI to work: Automate and Scale Financial Operations",
    "summary": "Put AI to work: Automate and Scale Financial Operations",
    "pubDate": "Mon, 30 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-automate-and-scale-financial-operations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Taking a responsible path to AGI",
    "description": "We‚Äôre exploring the frontiers of AGI, prioritizing technical safety, proactive risk assessment, and collaboration with the AI community.",
    "summary": "We‚Äôre exploring the frontiers of AGI, prioritizing technical safety, proactive risk assessment, and collaboration with the AI community.",
    "pubDate": "Wed, 02 Apr 2025 13:31:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/taking-a-responsible-path-to-agi/",
    "thumbnail": "https://lh3.googleusercontent.com/0sOE0EshCImNhSW7FRZvw-v_eyJJt_WUEh9evgRbhB4tl0o7qY2VAJdAloF5q3Q6CKTCiXdEvv1kUfsyZz8h6rR7Rl9jUhH02ADOyl7A7w-0QDWWr1Y=w1200-h630-n-nu"
  },
  {
    "title": "Introducing more enterprise-grade features for API customers",
    "description": "Increasing enterprise support with more security features and controls, updates to our Assistants API, and tools to better manage costs.",
    "summary": "Increasing enterprise support with more security features and controls, updates to our Assistants API, and tools to better manage costs.",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/more-enterprise-grade-features-for-api-customers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Spinning Up in Deep RL",
    "description": "We‚Äôre releasing Spinning Up in Deep RL, an educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning. Spinning Up consists of crystal-clear examples of RL code, educational exercises, documentation, and¬†tutorials.",
    "summary": "We‚Äôre releasing Spinning Up in Deep RL, an educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning. Spinning Up consists of crystal-clear examples of RL code, educational exercises, documentation, and¬†tutorials.",
    "pubDate": "Thu, 08 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spinning-up-in-deep-rl",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How to generate text: using different decoding methods for language generation with Transformers",
    "description": "",
    "summary": "How to generate text: using different decoding methods for language generation with Transformers Not...",
    "pubDate": "Sun, 01 Mar 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-generate",
    "thumbnail": "https://huggingface.co/blog/assets/02_how-to-generate/thumbnail.png"
  },
  {
    "title": "Saving lives with AI health coaching",
    "description": "Healthify collaborates with OpenAI to improve millions of lives with sustainable weight loss.",
    "summary": "Healthify collaborates with OpenAI to improve millions of lives with sustainable weight loss.",
    "pubDate": "Wed, 13 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/healthify",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "mGRADE: Minimal Recurrent Gating Meets Delay Convolutions for Lightweight Sequence Modeling",
    "description": "arXiv:2507.01829v1 Announce Type: cross Abstract: Edge devices for temporal processing demand models that capture both short- and long- range dynamics under tight memory constraints. While Transformers excel at sequence modeling, their quadratic memory scaling with sequence length makes them impractical for such settings. Recurrent Neural Networks (RNNs) offer constant memory but train sequentially, and Temporal Convolutional Networks (TCNs), though efficient, scale memory with kernel size. To address this, we propose mGRADE (mininally Gated Recurrent Architecture with Delay Embedding), a hybrid-memory system that integrates a temporal 1D-convolution with learnable spacings followed by a minimal gated recurrent unit (minGRU). This design allows the convolutional layer to realize a flexible delay embedding that captures rapid temporal variations, while the recurrent module efficiently maintains global context with minimal memory overhead. We validate our approach on two synthetic tasks, demonstrating that mGRADE effectively separates and preserves multi-scale temporal features. Furthermore, on challenging pixel-by-pixel image classification benchmarks, mGRADE consistently outperforms both pure convolutional and pure recurrent counterparts using approximately 20% less memory footprint, highlighting its suitability for memory-constrained temporal processing at the edge. This highlights mGRADE's promise as an efficient solution for memory-constrained multi-scale temporal processing at the edge.",
    "summary": "arXiv:2507.01829v1 Announce Type: cross Abstract: Edge devices for temporal processing demand models that capture both short- and long- range dynamics under tight memory constraints. While Transformers excel at sequence modeling, their quadratic memory scaling with sequence length makes them impractical for such settings. Recurrent Neural Networks (RNNs) offer constant memory but train sequentially, and Temporal Convolutional Networks (TCNs), though efficient, scale memory with kernel size. To address this, we propose mGRADE (mininally Gated Recurrent Architecture with Delay Embedding), a hybrid-memory system that integrates a temporal 1D-convolution with learnable spacings followed by a minimal gated recurrent unit (minGRU). This design allows the convolutional layer to realize a flexible delay embedding that captures rapid temporal variations, while the recurrent module efficiently maintains global context with minimal memory overhead. We validate our approach on two synthetic tasks, demonstrating that mGRADE effectively separates and preserves multi-scale temporal features. Furthermore, on challenging pixel-by-pixel image classification benchmarks, mGRADE consistently outperforms both pure convolutional and pure recurrent counterparts using approximately 20% less memory footprint, highlighting its suitability for memory-constrained temporal processing at the edge. This highlights mGRADE's promise as an efficient solution for memory-constrained multi-scale temporal processing at the edge.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01829",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How we used generative media at I/O 2025",
    "description": "Video showing the I/O opening film.",
    "summary": "Video showing the I/O opening film.",
    "pubDate": "Tue, 10 Jun 2025 17:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/generative-ai-io-keynote-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/thumbnail_opener_hero.width-1300.png"
  },
  {
    "title": "Generalizing from simulation",
    "description": "Our latest robotics techniques allow robot controllers, trained entirely in simulation and deployed on physical robots, to react to unplanned changes in the environment as they solve simple tasks. That is, we‚Äôve used these techniques to build closed-loop systems rather than open-loop ones as before.",
    "summary": "Our latest robotics techniques allow robot controllers, trained entirely in simulation and deployed on physical robots, to react to unplanned changes in the environment as they solve simple tasks. That is, we‚Äôve used these techniques to build closed-loop systems rather than open-loop ones as before.",
    "pubDate": "Thu, 19 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generalizing-from-simulation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Mastering Stratego, the classic game of imperfect information",
    "description": "Game-playing artificial intelligence (AI) systems have advanced to a new frontier.",
    "summary": "Game-playing artificial intelligence (AI) systems have advanced to a new frontier.",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/mastering-stratego-the-classic-game-of-imperfect-information/",
    "thumbnail": "https://lh3.googleusercontent.com/nvWTaah_1s2OEAt4CsxX5gKok_0V6-Q5eH3aW3GF6YyZdEVM0OBdgFxNa4DAbmUCXpvTqTfslfUB7_3ZBYr6kIQuk2u46khXH41IU16EZghstwt72Mk=w1200-h630-n-nu"
  },
  {
    "title": "Announcing Gemma 3n preview: Powerful, efficient, mobile-first AI",
    "description": "Gemma 3n is a cutting-edge open model designed for fast, multimodal AI on devices, featuring optimized performance, unique flexibility with a 2-in-1 model, and expanded multimodal understanding with audio, empowering developers to build live, interactive applications and sophisticated audio-centric experiences.",
    "summary": "Gemma 3n is a cutting-edge open model designed for fast, multimodal AI on devices, featuring optimized performance, unique flexibility with a 2-in-1 model, and expanded multimodal understanding with audio, empowering developers to build live, interactive applications and sophisticated audio-centric experiences.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/announcing-gemma-3n-preview-powerful-efficient-mobile-first-ai/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma3n_Metadatal_RD2-V01.2e16d0ba.fill-1200x600.jpg"
  },
  {
    "title": "Introducing IDEFICS: An Open Reproduction of State-of-the-art Visual Language Model",
    "description": "",
    "summary": "Introducing IDEFICS: An Open Reproduction of State-of-the-Art Visual Language Model We are excited t...",
    "pubDate": "Tue, 22 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/idefics",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "On-Policy Optimization of ANFIS Policies Using Proximal Policy Optimization",
    "description": "arXiv:2507.01039v1 Announce Type: cross Abstract: We propose a reinforcement learning (RL) approach for training neuro-fuzzy controllers using Proximal Policy Optimization (PPO). Building on prior work that applied Deep Q-Learning to Adaptive Neuro-Fuzzy Inference Systems (ANFIS), our method replaces the off-policy value-based framework with a stable on-policy actor-critic loop. We evaluate this approach in the CartPole-v1 environment using multiple random seeds and compare its learning performance against ANFIS-Deep Q-Network (DQN) baselines. It was found that PPO-trained fuzzy agents achieved a mean return of 500 +/- 0 on CartPole-v1 after 20000 updates, showcasing less variance than prior DQN-based methods during training and overall faster convergence. These findings suggest that PPO offers a promising pathway for training explainable neuro-fuzzy controllers in reinforcement learning tasks.",
    "summary": "arXiv:2507.01039v1 Announce Type: cross Abstract: We propose a reinforcement learning (RL) approach for training neuro-fuzzy controllers using Proximal Policy Optimization (PPO). Building on prior work that applied Deep Q-Learning to Adaptive Neuro-Fuzzy Inference Systems (ANFIS), our method replaces the off-policy value-based framework with a stable on-policy actor-critic loop. We evaluate this approach in the CartPole-v1 environment using multiple random seeds and compare its learning performance against ANFIS-Deep Q-Network (DQN) baselines. It was found that PPO-trained fuzzy agents achieved a mean return of 500 +/- 0 on CartPole-v1 after 20000 updates, showcasing less variance than prior DQN-based methods during training and overall faster convergence. These findings suggest that PPO offers a promising pathway for training explainable neuro-fuzzy controllers in reinforcement learning tasks.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01039",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Ethics and Society Newsletter #2: Let's talk about bias!",
    "description": "",
    "summary": "Machine Learning in development: Let's talk about bias! Bias in ML is ubiquitous, and Bias in ML is ...",
    "pubDate": "Thu, 15 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-2",
    "thumbnail": "https://huggingface.co/blog/assets/122_ethics_soc_2/thumbnail-solstice.png"
  },
  {
    "title": "SmolLM - blazingly fast and remarkably powerful",
    "description": "",
    "summary": "SmolLM - blazingly fast and remarkably powerful TL;DR This blog post introduces SmolLM, a family of ...",
    "pubDate": "Tue, 16 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smollm",
    "thumbnail": "https://huggingface.co/blog/assets/smollm/banner.png"
  },
  {
    "title": "Deep double descent",
    "description": "We show that the¬†double¬†descent¬†phenomenon¬†occurs in CNNs, ResNets, and transformers: performance first improves, then gets worse, and then improves again with increasing model size, data size, or training time. This effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we don‚Äôt yet fully understand why it happens, and view further study of this phenomenon as an important research¬†direction.",
    "summary": "We show that the¬†double¬†descent¬†phenomenon¬†occurs in CNNs, ResNets, and transformers: performance first improves, then gets worse, and then improves again with increasing model size, data size, or training time. This effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we don‚Äôt yet fully understand why it happens, and view further study of this phenomenon as an important research¬†direction.",
    "pubDate": "Thu, 05 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-double-descent",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms",
    "description": "New AI agent evolves algorithms for math and practical applications in computing by combining the creativity of large language models with automated evaluators",
    "summary": "New AI agent evolves algorithms for math and practical applications in computing by combining the creativity of large language models with automated evaluators",
    "pubDate": "Wed, 14 May 2025 14:59:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/",
    "thumbnail": "https://lh3.googleusercontent.com/tG6-MqdlvhQ-z7ENzGxR-kpGPPdPHbJ8UZtbTP66Rxi0UftTFU1yAvaBCVuigYuKvESMeEFf4jqNBVENFcZXEUnj8SSqj8zsop8UHAl0eD9A-hUCvQ=w1200-h630-n-nu"
  },
  {
    "title": "Using Stable Diffusion with Core ML on Apple Silicon",
    "description": "",
    "summary": "Using Stable Diffusion with Core ML on Apple Silicon Thanks to Apple engineers, you can now run Stab...",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers_coreml/thumbnail.png"
  },
  {
    "title": "Towards Safety Evaluations of Theory of Mind in Large Language Models",
    "description": "arXiv:2506.17352v2 Announce Type: replace-cross Abstract: As the capabilities of large language models (LLMs) continue to advance, the importance of rigorous safety evaluation is becoming increasingly evident. Recent concerns within the realm of safety assessment have highlighted instances in which LLMs exhibit behaviors that appear to disable oversight mechanisms and respond in a deceptive manner. For example, there have been reports suggesting that, when confronted with information unfavorable to their own persistence during task execution, LLMs may act covertly and even provide false answers to questions intended to verify their behavior. To evaluate the potential risk of such deceptive actions toward developers or users, it is essential to investigate whether these behaviors stem from covert, intentional processes within the model. In this study, we propose that it is necessary to measure the theory of mind capabilities of LLMs. We begin by reviewing existing research on theory of mind and identifying the perspectives and tasks relevant to its application in safety evaluation. Given that theory of mind has been predominantly studied within the context of developmental psychology, we analyze developmental trends across a series of open-weight LLMs. Our results indicate that while LLMs have improved in reading comprehension, their theory of mind capabilities have not shown comparable development. Finally, we present the current state of safety evaluation with respect to LLMs' theory of mind, and discuss remaining challenges for future work.",
    "summary": "arXiv:2506.17352v2 Announce Type: replace-cross Abstract: As the capabilities of large language models (LLMs) continue to advance, the importance of rigorous safety evaluation is becoming increasingly evident. Recent concerns within the realm of safety assessment have highlighted instances in which LLMs exhibit behaviors that appear to disable oversight mechanisms and respond in a deceptive manner. For example, there have been reports suggesting that, when confronted with information unfavorable to their own persistence during task execution, LLMs may act covertly and even provide false answers to questions intended to verify their behavior. To evaluate the potential risk of such deceptive actions toward developers or users, it is essential to investigate whether these behaviors stem from covert, intentional processes within the model. In this study, we propose that it is necessary to measure the theory of mind capabilities of LLMs. We begin by reviewing existing research on theory of mind and identifying the perspectives and tasks relevant to its application in safety evaluation. Given that theory of mind has been predominantly studied within the context of developmental psychology, we analyze developmental trends across a series of open-weight LLMs. Our results indicate that while LLMs have improved in reading comprehension, their theory of mind capabilities have not shown comparable development. Finally, we present the current state of safety evaluation with respect to LLMs' theory of mind, and discuss remaining challenges for future work.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17352",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Pioneers Program",
    "description": "Advancing model performance and real world evaluation in applied domains.",
    "summary": "Advancing model performance and real world evaluation in applied domains.",
    "pubDate": "Wed, 09 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-pioneers-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Hugging Face Training Efficiency Through Packing with Flash Attention",
    "description": "",
    "summary": "Improving Hugging Face Training Efficiency Through Packing with Flash Attention TL;DR Training with ...",
    "pubDate": "Wed, 21 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/packing-with-FA2",
    "thumbnail": "https://huggingface.co/blog/assets/packing-with-FA2/thumbnail.png"
  },
  {
    "title": "Make your llama generation time fly with AWS Inferentia2",
    "description": "",
    "summary": "Make your llama generation time fly with AWS Inferentia2 Update (02/2024): Performance has improved ...",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inferentia-llama2",
    "thumbnail": "https://huggingface.co/blog/assets/inferentia-llama2/thumbnail.png"
  },
  {
    "title": "DocShaDiffusion: Diffusion Model in Latent Space for Document Image Shadow Removal",
    "description": "arXiv:2507.01422v1 Announce Type: cross Abstract: Document shadow removal is a crucial task in the field of document image enhancement. However, existing methods tend to remove shadows with constant color background and ignore color shadows. In this paper, we first design a diffusion model in latent space for document image shadow removal, called DocShaDiffusion. It translates shadow images from pixel space to latent space, enabling the model to more easily capture essential features. To address the issue of color shadows, we design a shadow soft-mask generation module (SSGM). It is able to produce accurate shadow mask and add noise into shadow regions specially. Guided by the shadow mask, a shadow mask-aware guided diffusion module (SMGDM) is proposed to remove shadows from document images by supervising the diffusion and denoising process. We also propose a shadow-robust perceptual feature loss to preserve details and structures in document images. Moreover, we develop a large-scale synthetic document color shadow removal dataset (SDCSRD). It simulates the distribution of realistic color shadows and provides powerful supports for the training of models. Experiments on three public datasets validate the proposed method's superiority over state-of-the-art. Our code and dataset will be publicly available.",
    "summary": "arXiv:2507.01422v1 Announce Type: cross Abstract: Document shadow removal is a crucial task in the field of document image enhancement. However, existing methods tend to remove shadows with constant color background and ignore color shadows. In this paper, we first design a diffusion model in latent space for document image shadow removal, called DocShaDiffusion. It translates shadow images from pixel space to latent space, enabling the model to more easily capture essential features. To address the issue of color shadows, we design a shadow soft-mask generation module (SSGM). It is able to produce accurate shadow mask and add noise into shadow regions specially. Guided by the shadow mask, a shadow mask-aware guided diffusion module (SMGDM) is proposed to remove shadows from document images by supervising the diffusion and denoising process. We also propose a shadow-robust perceptual feature loss to preserve details and structures in document images. Moreover, we develop a large-scale synthetic document color shadow removal dataset (SDCSRD). It simulates the distribution of realistic color shadows and provides powerful supports for the training of models. Experiments on three public datasets validate the proposed method's superiority over state-of-the-art. Our code and dataset will be publicly available.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01422",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AlphaFold 3 predicts the structure and interactions of all of life‚Äôs molecules",
    "description": "Introducing a new AI model developed by Google DeepMind and Isomorphic Labs.",
    "summary": "Introducing a new AI model developed by Google DeepMind and Isomorphic Labs.",
    "pubDate": "Wed, 08 May 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphafold-3-predicts-the-structure-and-interactions-of-all-lifes-molecules/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AF_social_share.width-1300.jpg"
  },
  {
    "title": "Plan online, learn offline: Efficient learning and exploration via model-based control",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 05 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/plan-online-learn-offline",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "BIS Reasoning 1.0: The First Large-Scale Japanese Benchmark for Belief-Inconsistent Syllogistic Reasoning",
    "description": "arXiv:2506.06955v3 Announce Type: replace-cross Abstract: We present BIS Reasoning 1.0, the first large-scale Japanese dataset of syllogistic reasoning problems explicitly designed to evaluate belief-inconsistent reasoning in large language models (LLMs). Unlike prior datasets such as NeuBAROCO and JFLD, which focus on general or belief-aligned reasoning, BIS Reasoning 1.0 introduces logically valid yet belief-inconsistent syllogisms to uncover reasoning biases in LLMs trained on human-aligned corpora. We benchmark state-of-the-art models - including GPT models, Claude models, and leading Japanese LLMs - revealing significant variance in performance, with GPT-4o achieving 79.54% accuracy. Our analysis identifies critical weaknesses in current LLMs when handling logically valid but belief-conflicting inputs. These findings have important implications for deploying LLMs in high-stakes domains such as law, healthcare, and scientific literature, where truth must override intuitive belief to ensure integrity and safety.",
    "summary": "arXiv:2506.06955v3 Announce Type: replace-cross Abstract: We present BIS Reasoning 1.0, the first large-scale Japanese dataset of syllogistic reasoning problems explicitly designed to evaluate belief-inconsistent reasoning in large language models (LLMs). Unlike prior datasets such as NeuBAROCO and JFLD, which focus on general or belief-aligned reasoning, BIS Reasoning 1.0 introduces logically valid yet belief-inconsistent syllogisms to uncover reasoning biases in LLMs trained on human-aligned corpora. We benchmark state-of-the-art models - including GPT models, Claude models, and leading Japanese LLMs - revealing significant variance in performance, with GPT-4o achieving 79.54% accuracy. Our analysis identifies critical weaknesses in current LLMs when handling logically valid but belief-conflicting inputs. These findings have important implications for deploying LLMs in high-stakes domains such as law, healthcare, and scientific literature, where truth must override intuitive belief to ensure integrity and safety.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.06955",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval",
    "description": "",
    "summary": "Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval We introduce t...",
    "pubDate": "Fri, 22 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/embedding-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/embedding-quantization/thumbnail.png"
  },
  {
    "title": "Practices for Governing Agentic AI Systems",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/practices-for-governing-agentic-ai-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing our latest image generation model in the API",
    "description": "Our latest image generation model is now available in the API via ‚Äògpt-image-1‚Äô‚Äîenabling developers and businesses to build professional-grade, customizable visuals directly into their own tools and platforms.",
    "summary": "Our latest image generation model is now available in the API via ‚Äògpt-image-1‚Äô‚Äîenabling developers and businesses to build professional-grade, customizable visuals directly into their own tools and platforms.",
    "pubDate": "Wed, 23 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/image-generation-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Equivalence between policy gradients and soft Q-learning",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 21 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/equivalence-between-policy-gradients-and-soft-q-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome fastai to the Hugging Face Hub",
    "description": "",
    "summary": "Welcome fastai to the Hugging Face Hub Making neural nets uncool again... and sharing them Few have ...",
    "pubDate": "Fri, 06 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastai",
    "thumbnail": "https://huggingface.co/blog/assets/64_fastai/fastai_hf_blog.png"
  },
  {
    "title": "Deploying TensorFlow Vision Models in Hugging Face with TF Serving",
    "description": "",
    "summary": "Deploying TensorFlow Vision Models in Hugging Face with TF Serving In the past few months, the Huggi...",
    "pubDate": "Mon, 25 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-serving-vision",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/ai-icon.png"
  },
  {
    "title": "MIT announces the Initiative for New Manufacturing",
    "description": "The Institute-wide effort aims to bolster industry and create jobs by driving innovation across vital manufacturing sectors.",
    "summary": "The Institute-wide effort aims to bolster industry and create jobs by driving innovation across vital manufacturing sectors.",
    "pubDate": "Tue, 27 May 2025 10:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-announces-initiative-for-new-manufacturing-0527",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-ManufacturingAnn-01-press.jpg"
  },
  {
    "title": "Generative models",
    "description": "This post describes four projects that share a common theme of enhancing or using generative models, a branch of unsupervised learning techniques in machine learning. In addition to describing our work, this post will tell you a bit more about generative models: what they are, why they are important, and where they might be going.",
    "summary": "This post describes four projects that share a common theme of enhancing or using generative models, a branch of unsupervised learning techniques in machine learning. In addition to describing our work, this post will tell you a bit more about generative models: what they are, why they are important, and where they might be going.",
    "pubDate": "Thu, 16 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generative-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI for Nonprofits",
    "description": "We‚Äôre launching a new initiative to enhance the accessibility of our tools for nonprofit organizations, including discounted rates for ChatGPT Team and Enterprise.",
    "summary": "We‚Äôre launching a new initiative to enhance the accessibility of our tools for nonprofit organizations, including discounted rates for ChatGPT Team and Enterprise.",
    "pubDate": "Thu, 30 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-for-nonprofits",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Empirical Analysis Of Heuristic and Approximation Algorithms for the The Mutual-Visibility Problem",
    "description": "arXiv:2507.01076v1 Announce Type: cross Abstract: The NP-complete mutual-visibility (MV) problem currently lacks empirical analysis on its practical behaviour despite theoretical studies. This paper addresses this gap by implementing and evaluating three distinct algorithms - a direct greedy heuristic, a hypergraph-based approximation, and a genetic algorithm - on diverse synthetic graph datasets, including those with analytically known $mu(G)$ values and general graph models. Our results demonstrate that for smaller graphs, the algorithms consistently achieve MV set sizes aligning with theoretical bounds. However, for larger instances, achieved solution sizes notably diverge from theoretical limits; this, combined with the absence of tight bounds, complicates absolute quality assessment. Nevertheless, validation on known optimal graphs showed the Genetic Algorithm and other heuristics empirically performing best among tested methods.",
    "summary": "arXiv:2507.01076v1 Announce Type: cross Abstract: The NP-complete mutual-visibility (MV) problem currently lacks empirical analysis on its practical behaviour despite theoretical studies. This paper addresses this gap by implementing and evaluating three distinct algorithms - a direct greedy heuristic, a hypergraph-based approximation, and a genetic algorithm - on diverse synthetic graph datasets, including those with analytically known $mu(G)$ values and general graph models. Our results demonstrate that for smaller graphs, the algorithms consistently achieve MV set sizes aligning with theoretical bounds. However, for larger instances, achieved solution sizes notably diverge from theoretical limits; this, combined with the absence of tight bounds, complicates absolute quality assessment. Nevertheless, validation on known optimal graphs showed the Genetic Algorithm and other heuristics empirically performing best among tested methods.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01076",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Scholars 2019: Final projects",
    "description": "Our second class of OpenAI Scholars has concluded, with all eight scholars producing an exciting final project showcased at Scholars Demo Day at OpenAI.",
    "summary": "Our second class of OpenAI Scholars has concluded, with all eight scholars producing an exciting final project showcased at Scholars Demo Day at OpenAI.",
    "pubDate": "Thu, 23 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our approach to alignment research",
    "description": "We are improving our AI systems‚Äô ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment¬†problems.",
    "summary": "We are improving our AI systems‚Äô ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment¬†problems.",
    "pubDate": "Wed, 24 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/our-approach-to-alignment-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Visual Document Retrieval Goes Multilingual",
    "description": "",
    "summary": "Visual Document Retrieval Goes Multilingual TL;DR: We present vdr-2b-multi-v1 , the best multilingua...",
    "pubDate": "Fri, 10 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vdr-2b-multilingual",
    "thumbnail": "https://huggingface.co/blog/assets/vdr-2b-multilingual/thumbnail.png"
  },
  {
    "title": "AI Policy @ü§ó: Open ML Considerations in the EU AI Act",
    "description": "",
    "summary": "AI Policy @ü§ó: Open ML Considerations in the EU AI Act Like everyone else in Machine Learning, we‚Äôve ...",
    "pubDate": "Mon, 24 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eu-ai-act-oss",
    "thumbnail": "https://huggingface.co/blog/assets/eu_ai_act_oss/thumbnailEU.png"
  },
  {
    "title": "Introduction to ggml",
    "description": "",
    "summary": "Introduction to ggml ggml is a machine learning (ML) library written in C and C++ with a focus on Tr...",
    "pubDate": "Tue, 13 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introduction-to-ggml",
    "thumbnail": "https://huggingface.co/blog/assets/introduction-to-ggml/cover.jpg"
  },
  {
    "title": "From PyTorch DDP to ü§ó Accelerate to ü§ó Trainer, mastery of distributed training with ease",
    "description": "",
    "summary": "From PyTorch DDP to Accelerate to Trainer, mastery of distributed training with ease General Overvie...",
    "pubDate": "Fri, 21 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-ddp-accelerate-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/111_pytorch_ddp_accelerate_transformers/thumbnail.png"
  },
  {
    "title": "Memory-efficient Diffusion Transformers with Quanto and Diffusers",
    "description": "",
    "summary": "Memory-efficient Diffusion Transformers with Quanto and Diffusers Over the past few months, we have ...",
    "pubDate": "Tue, 30 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/quanto-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/quanto-diffusers/thumbnail.png"
  },
  {
    "title": "Enterprise-ready trust and safety",
    "description": "Salesforce integrates OpenAI‚Äôs enterprise-ready LLMs to transform customer applications.",
    "summary": "Salesforce integrates OpenAI‚Äôs enterprise-ready LLMs to transform customer applications.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/salesforce",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering",
    "description": "We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.",
    "summary": "We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.",
    "pubDate": "Thu, 10 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mle-bench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Computational limitations in robust classification and win-win results",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 04 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/computational-limitations-in-robust-classification-and-win-win-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Benchmarking the next generation of never-ending learners",
    "description": "Learning how to build upon knowledge by tapping 30 years of computer vision research",
    "summary": "Learning how to build upon knowledge by tapping 30 years of computer vision research",
    "pubDate": "Tue, 22 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/benchmarking-the-next-generation-of-never-ending-learners/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "Shipping code faster with o3, o4-mini, and GPT-4.1",
    "description": "CodeRabbit uses OpenAI models to revolutionize code reviews‚Äîboosting accuracy, accelerating PR merges, and helping developers ship faster with fewer bugs and higher ROI.",
    "summary": "CodeRabbit uses OpenAI models to revolutionize code reviews‚Äîboosting accuracy, accelerating PR merges, and helping developers ship faster with fewer bugs and higher ROI.",
    "pubDate": "Thu, 22 May 2025 10:25:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/coderabbit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„ÇíÁú∫„ÇÅ„Å¶„Åø„Çã",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ‰ªäÂõû„ÅØGemini Diffusion„ÅÆÁôªÂ†¥„Çí„Åç„Å£„Åã„Åë„Å´ÊúÄËøëË©±È°å„Å´„Å™„Å£„ÅüÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„Å´ËààÂë≥„ÇíÊåÅ„Å°„ÄÅ„Åù„ÅÆ‰∏Ä‰æã„Å®„Åó„Å¶Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆLLaDA„ÅÆÊé®Ë´ñ„ÇíÂÆüÈöõ„Å´ÊâãÂÖÉ„ÅßÁ¢∫Ë™ç„Åó„Å¶„Åø„ÅüÁµêÊûú„Çí [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5850' rel='nofollow'>Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„ÇíÁú∫„ÇÅ„Å¶„Åø„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ‰ªäÂõû„ÅØGemini Diffusion„ÅÆÁôªÂ†¥„Çí„Åç„Å£„Åã„Åë„Å´ÊúÄËøëË©±È°å„Å´„Å™„Å£„ÅüÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„Å´ËààÂë≥„ÇíÊåÅ„Å°„ÄÅ„Åù„ÅÆ‰∏Ä‰æã„Å®„Åó„Å¶Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆLLaDA„ÅÆÊé®Ë´ñ„ÇíÂÆüÈöõ„Å´ÊâãÂÖÉ„ÅßÁ¢∫Ë™ç„Åó„Å¶„Åø„ÅüÁµêÊûú„Çí [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5850' rel='nofollow'>Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„ÇíÁú∫„ÇÅ„Å¶„Åø„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Mon, 02 Jun 2025 00:13:43 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5850",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "Llama 2 is here - get it on Hugging Face",
    "description": "",
    "summary": "Llama 2 is here - get it on Hugging Face Introduction Llama 2 is a family of state-of-the-art open-a...",
    "pubDate": "Tue, 18 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama2",
    "thumbnail": "https://huggingface.co/blog/assets/llama2/thumbnail.jpg"
  },
  {
    "title": "Introducing the Chatbot Guardrails Arena",
    "description": "",
    "summary": "Introducing the Chatbot Guardrails Arena With the recent advancements in augmented LLM capabilities,...",
    "pubDate": "Thu, 21 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-lighthouz",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail_lighthouz.png"
  },
  {
    "title": "Team update",
    "description": "The OpenAI team is now 45 people. Together, we‚Äôre pushing the frontier of AI capabilities‚Äîwhether by validating novel ideas, creating new software systems, or deploying machine learning on robots.",
    "summary": "The OpenAI team is now 45 people. Together, we‚Äôre pushing the frontier of AI capabilities‚Äîwhether by validating novel ideas, creating new software systems, or deploying machine learning on robots.",
    "pubDate": "Mon, 30 Jan 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update-january",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcoming Llama Guard 4 on Hugging Face Hub",
    "description": "",
    "summary": "Welcoming Llama Guard 4 on Hugging Face Hub TL;DR: Today, Meta releases Llama Guard 4, a 12B dense (...",
    "pubDate": "Tue, 29 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama-guard-4",
    "thumbnail": "https://huggingface.co/blog/assets/llama-guard-4/thumbnail.png"
  },
  {
    "title": "Introducing Spaces Dev Mode for a seamless developer experience",
    "description": "",
    "summary": "Introducing Spaces Dev Mode for a seamless developer experience Hugging Face Spaces makes it easy fo...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spaces-dev-mode",
    "thumbnail": "https://huggingface.co/blog/assets/spaces-dev-mode/thumbnail.jpg"
  },
  {
    "title": "OpenAI licenses GPT-3 technology to Microsoft",
    "description": "OpenAI has agreed to license GPT-3 to Microsoft for their own products and services.",
    "summary": "OpenAI has agreed to license GPT-3 to Microsoft for their own products and services.",
    "pubDate": "Tue, 22 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-licenses-gpt-3-technology-to-microsoft",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fixing Gradient Accumulation",
    "description": "",
    "summary": "Fixing Gradient Accumulation Our friends at Unsloth shared an issue regarding gradient accumulation ...",
    "pubDate": "Wed, 16 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradient_accumulation",
    "thumbnail": "https://huggingface.co/blog/assets/gradient_accumulation/gradient_accumulation.png"
  },
  {
    "title": "AWS„ÅåÊó•Êú¨„Å´2ÂÖÜÂÜÜÊäïË≥á„Åô„ÇãÁêÜÁî±„ÄÄÂ§ßË¶èÊ®°„Ç§„Éô„É≥„Éà„ÅßË™û„Çâ„Çå„ÅüÊú™Êù•„ÅÆÂßø",
    "description": "„ÄåAWS Summit Japan 2025„Äç„ÅÆÂü∫Ë™øË¨õÊºî„Å´„Åä„ÅÑ„Å¶„ÄÅAWS„ÅåÊó•Êú¨Â∏ÇÂ†¥„Å´2ÂÖÜ2600ÂÑÑÂÜÜ„ÇíÊäïË≥á„Åó„ÄÅÁîüÊàêAI„ÇÑ„ÇØ„É©„Ç¶„Éâ„ÇíÂü∫Áõ§„Å®„Åô„Çã„Éì„Ç∏„Éç„ÇπÂ§âÈù©„ÄÅ‰∫∫ÊùêËÇ≤Êàê„ÄÅÁ§æ‰ºöË™≤È°åËß£Ê±∫„ÇíÊîØÊè¥„Åô„ÇãÂßøÂã¢„ÇíÊòéÁ¢∫„Å´„Åó„Åü„ÄÇ",
    "summary": "„ÄåAWS Summit Japan 2025„Äç„ÅÆÂü∫Ë™øË¨õÊºî„Å´„Åä„ÅÑ„Å¶„ÄÅAWS„ÅåÊó•Êú¨Â∏ÇÂ†¥„Å´2ÂÖÜ2600ÂÑÑÂÜÜ„ÇíÊäïË≥á„Åó„ÄÅÁîüÊàêAI„ÇÑ„ÇØ„É©„Ç¶„Éâ„ÇíÂü∫Áõ§„Å®„Åô„Çã„Éì„Ç∏„Éç„ÇπÂ§âÈù©„ÄÅ‰∫∫ÊùêËÇ≤Êàê„ÄÅÁ§æ‰ºöË™≤È°åËß£Ê±∫„ÇíÊîØÊè¥„Åô„ÇãÂßøÂã¢„ÇíÊòéÁ¢∫„Å´„Åó„Åü„ÄÇ",
    "pubDate": "Wed, 02 Jul 2025 17:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2507/02/news051.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2507/02/cover_news051.jpg"
  },
  {
    "title": "Discovering types for entity disambiguation",
    "description": "We‚Äôve built a system for automatically figuring out which object is meant by a word by having a neural network decide if the word belongs to each of about 100 automatically-discovered ‚Äútypes‚Äù (non-exclusive categories).",
    "summary": "We‚Äôve built a system for automatically figuring out which object is meant by a word by having a neural network decide if the word belongs to each of about 100 automatically-discovered ‚Äútypes‚Äù (non-exclusive categories).",
    "pubDate": "Wed, 07 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/discovering-types-for-entity-disambiguation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Asymmetric actor critic for image-based robot learning",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 18 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/asymmetric-actor-critic-for-image-based-robot-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o1 and new tools for developers",
    "description": "Introducing OpenAI o1, Realtime API improvements, a new fine-tuning method and more for developers.",
    "summary": "Introducing OpenAI o1, Realtime API improvements, a new fine-tuning method and more for developers.",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-and-new-tools-for-developers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The AI for Science Forum: A new era of discovery",
    "description": "The AI Science Forum highlights AI's present and potential role in revolutionizing scientific discovery and solving global challenges, emphasizing collaboration between the scientific community, policymakers, and industry leaders.",
    "summary": "The AI Science Forum highlights AI's present and potential role in revolutionizing scientific discovery and solving global challenges, emphasizing collaboration between the scientific community, policymakers, and industry leaders.",
    "pubDate": "Mon, 18 Nov 2024 19:57:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/the-ai-for-science-forum-a-new-era-of-discovery/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AIFS_Collection_SS.max-1440x810.jpg"
  },
  {
    "title": "OpenAI‚Äôs Raising Concerns Policy",
    "description": "We‚Äôre publishing our Raising Concerns Policy, which protects employees‚Äô rights to make protected disclosures.",
    "summary": "We‚Äôre publishing our Raising Concerns Policy, which protects employees‚Äô rights to make protected disclosures.",
    "pubDate": "Fri, 04 Oct 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-raising-concerns-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Inception Labs„ÅÆÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÇíË©¶„Åó„Å¶„Åø„Åü",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Êú¨Ë®ò‰∫ã„Åß„ÅØInception Labs„ÅÆMercury API„ÅÆ„Éô„Éº„ÇøÁâà„Åå‰Ωø„Åà„Çã„Çà„ÅÜ„Å´„Å™„Å£„Åü„ÅÆ„Åß„ÄÅÁ∞°Âçò„Å´Ë©¶„Åó„Å¶„Åø„Åæ„Åó„Åü„ÄÇ „Éâ„Ç≠„É•„É°„É≥„Éà„ÅØ„Åì„Å°„Çâ„ÅßÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ Êã°Êï£Ë®ÄË™û„É¢„Éá„É´ ÁèæÂú®„ÅÆ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5738' rel='nofollow'>Inception Labs„ÅÆÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÇíË©¶„Åó„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Êú¨Ë®ò‰∫ã„Åß„ÅØInception Labs„ÅÆMercury API„ÅÆ„Éô„Éº„ÇøÁâà„Åå‰Ωø„Åà„Çã„Çà„ÅÜ„Å´„Å™„Å£„Åü„ÅÆ„Åß„ÄÅÁ∞°Âçò„Å´Ë©¶„Åó„Å¶„Åø„Åæ„Åó„Åü„ÄÇ „Éâ„Ç≠„É•„É°„É≥„Éà„ÅØ„Åì„Å°„Çâ„ÅßÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ Êã°Êï£Ë®ÄË™û„É¢„Éá„É´ ÁèæÂú®„ÅÆ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5738' rel='nofollow'>Inception Labs„ÅÆÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÇíË©¶„Åó„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Thu, 01 May 2025 03:02:11 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5738",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "AI and efficiency",
    "description": "We‚Äôre releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet¬†classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet¬†(by contrast, Moore‚Äôs Law¬†would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware¬†efficiency.",
    "summary": "We‚Äôre releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet¬†classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet¬†(by contrast, Moore‚Äôs Law¬†would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware¬†efficiency.",
    "pubDate": "Tue, 05 May 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-and-efficiency",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building a data-driven, efficient culture with AI",
    "description": "Holiday Extras rolls out ChatGPT Enterprise across every team, boosting productivity by 500 hours weekly.",
    "summary": "Holiday Extras rolls out ChatGPT Enterprise across every team, boosting productivity by 500 hours weekly.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/holiday-extras",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating fairness in ChatGPT",
    "description": "We've analyzed how ChatGPT responds to users based on their name, using AI research assistants to protect privacy.",
    "summary": "We've analyzed how ChatGPT responds to users based on their name, using AI research assistants to protect privacy.",
    "pubDate": "Tue, 15 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evaluating-fairness-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "We Raised $100 Million for Open & Collaborative Machine Learning üöÄ",
    "description": "",
    "summary": "We Raised $100 Million for Open & Collaborative Machine Learning üöÄ Today we have some exciting news ...",
    "pubDate": "Mon, 09 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/series-c",
    "thumbnail": "https://huggingface.co/blog/assets/65_series_c/thumbnail.jpg"
  },
  {
    "title": "New commission to provide insight as OpenAI builds the world‚Äôs best-equipped nonprofit",
    "description": "Already a nonprofit, and already using AI to help people solve hard problems, OpenAI aims to build the best-equipped nonprofit the world has ever seen‚Äîcombining potentially historic financial resources with something even more powerful: technology that can scale human ingenuity itself.",
    "summary": "Already a nonprofit, and already using AI to help people solve hard problems, OpenAI aims to build the best-equipped nonprofit the world has ever seen‚Äîcombining potentially historic financial resources with something even more powerful: technology that can scale human ingenuity itself.",
    "pubDate": "Wed, 02 Apr 2025 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonprofit-commission-guidance",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Enabling a Data-Driven Workforce",
    "description": "In this video, we share practical examples of how employees can use ChatGPT Enterprise to efficiently analyze data and uncover insights.",
    "summary": "In this video, we share practical examples of how employees can use ChatGPT Enterprise to efficiently analyze data and uncover insights.",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/enabling-a-data-driven-workforce-webinar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A catalogue of genetic mutations to help pinpoint the cause of diseases",
    "description": "New AI tool classifies the effects of 71 million ‚Äòmissense‚Äô mutations.",
    "summary": "New AI tool classifies the effects of 71 million ‚Äòmissense‚Äô mutations.",
    "pubDate": "Tue, 19 Sep 2023 13:37:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/a-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases/",
    "thumbnail": "https://lh3.googleusercontent.com/JySjDTZvGqEzUfDic5QOU6Rne3r6RWpiw5JZQ9VdzK1O5C20EbAkSPURGoCmAhea_U-gyyRu4KdCZmeWSCtYjGHHMvM0jVK5fWiqOwa0rpcC5uzM=w1200-h630-n-nu"
  },
  {
    "title": "Introducing HuggingFace blog for Chinese speakers: Fostering Collaboration with the Chinese AI community",
    "description": "",
    "summary": "Introducing HuggingFace blog for Chinese speakers: Fostering Collaboration with the Chinese AI commu...",
    "pubDate": "Mon, 24 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chinese-language-blog",
    "thumbnail": "https://huggingface.co/blog/assets/chinese-language-blog/thumbnail.png"
  },
  {
    "title": "Training CodeParrot ü¶ú from Scratch",
    "description": "",
    "summary": "Training CodeParrot ü¶ú from Scratch In this blog post we'll take a look at what it takes to build the...",
    "pubDate": "Wed, 08 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codeparrot",
    "thumbnail": "https://huggingface.co/blog/assets/40_codeparrot/thumbnail.png"
  },
  {
    "title": "Introducing Gemini 2.5 Flash",
    "description": "Gemini 2.5 Flash is our first fully hybrid reasoning model, giving developers the ability to turn thinking on or off.",
    "summary": "Gemini 2.5 Flash is our first fully hybrid reasoning model, giving developers the ability to turn thinking on or off.",
    "pubDate": "Thu, 17 Apr 2025 19:02:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-2-5-flash/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini-2-5-Flash-ai.dev.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Report from the self-organizing conference",
    "description": "Last week we hosted over a hundred and fifty AI practitioners in our offices for our first self-organizing conference on machine learning.",
    "summary": "Last week we hosted over a hundred and fifty AI practitioners in our offices for our first self-organizing conference on machine learning.",
    "pubDate": "Thu, 13 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/report-from-the-self-organizing-conference",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks",
    "description": "arXiv:2507.01955v1 Announce Type: cross Abstract: Multimodal foundation models, such as GPT-4o, have recently made remarkable progress, but it is not clear where exactly these models stand in terms of understanding vision. In this paper, we benchmark the performance of popular multimodal foundation models (GPT-4o, o4-mini, Gemini 1.5 Pro and Gemini 2.0 Flash, Claude 3.5 Sonnet, Qwen2-VL, Llama 3.2) on standard computer vision tasks (semantic segmentation, object detection, image classification, depth and surface normal prediction) using established datasets (e.g., COCO, ImageNet and its variants, etc). The main challenges to performing this are: 1) most models are trained to output text and cannot natively express versatile domains, such as segments or 3D geometry, and 2) many leading models are proprietary and accessible only at an API level, i.e., there is no weight access to adapt them. We address these challenges by translating standard vision tasks into equivalent text-promptable and API-compatible tasks via prompt chaining to create a standardized benchmarking framework. We observe that 1) the models are not close to the state-of-the-art specialist models at any task. However, 2) they are respectable generalists; this is remarkable as they are presumably trained on primarily image-text-based tasks. 3) They perform semantic tasks notably better than geometric ones. 4) While the prompt-chaining techniques affect performance, better models exhibit less sensitivity to prompt variations. 5) GPT-4o performs the best among non-reasoning models, securing the top position in 4 out of 6 tasks, 6) reasoning models, e.g. o3, show improvements in geometric tasks, and 7) a preliminary analysis of models with native image generation, like the latest GPT-4o, shows they exhibit quirks like hallucinations and spatial misalignments.",
    "summary": "arXiv:2507.01955v1 Announce Type: cross Abstract: Multimodal foundation models, such as GPT-4o, have recently made remarkable progress, but it is not clear where exactly these models stand in terms of understanding vision. In this paper, we benchmark the performance of popular multimodal foundation models (GPT-4o, o4-mini, Gemini 1.5 Pro and Gemini 2.0 Flash, Claude 3.5 Sonnet, Qwen2-VL, Llama 3.2) on standard computer vision tasks (semantic segmentation, object detection, image classification, depth and surface normal prediction) using established datasets (e.g., COCO, ImageNet and its variants, etc). The main challenges to performing this are: 1) most models are trained to output text and cannot natively express versatile domains, such as segments or 3D geometry, and 2) many leading models are proprietary and accessible only at an API level, i.e., there is no weight access to adapt them. We address these challenges by translating standard vision tasks into equivalent text-promptable and API-compatible tasks via prompt chaining to create a standardized benchmarking framework. We observe that 1) the models are not close to the state-of-the-art specialist models at any task. However, 2) they are respectable generalists; this is remarkable as they are presumably trained on primarily image-text-based tasks. 3) They perform semantic tasks notably better than geometric ones. 4) While the prompt-chaining techniques affect performance, better models exhibit less sensitivity to prompt variations. 5) GPT-4o performs the best among non-reasoning models, securing the top position in 4 out of 6 tasks, 6) reasoning models, e.g. o3, show improvements in geometric tasks, and 7) a preliminary analysis of models with native image generation, like the latest GPT-4o, shows they exhibit quirks like hallucinations and spatial misalignments.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01955",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Toward understanding and preventing misalignment generalization",
    "description": "We study how training on incorrect responses can cause broader misalignment in language models and identify an internal feature driving this behavior‚Äîone that can be reversed with minimal fine-tuning.",
    "summary": "We study how training on incorrect responses can cause broader misalignment in language models and identify an internal feature driving this behavior‚Äîone that can be reversed with minimal fine-tuning.",
    "pubDate": "Wed, 18 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergent-misalignment",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LLMs factor in unrelated information when recommending medical treatments",
    "description": "Researchers find nonclinical information in patient messages ‚Äî like typos, extra white space, and colorful language ‚Äî reduces the accuracy of an AI model.",
    "summary": "Researchers find nonclinical information in patient messages ‚Äî like typos, extra white space, and colorful language ‚Äî reduces the accuracy of an AI model.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/llms-factor-unrelated-information-when-recommending-medical-treatments-0623",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_Medium-Message-01-press.jpg"
  },
  {
    "title": "Concrete AI safety problems",
    "description": "We (along with researchers from Berkeley and Stanford) are co-authors on today‚Äôs paper led by Google Brain researchers,¬†Concrete Problems in AI Safety. The paper explores many research problems around ensuring that modern machine learning systems operate as intended.",
    "summary": "We (along with researchers from Berkeley and Stanford) are co-authors on today‚Äôs paper led by Google Brain researchers,¬†Concrete Problems in AI Safety. The paper explores many research problems around ensuring that modern machine learning systems operate as intended.",
    "pubDate": "Tue, 21 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/concrete-ai-safety-problems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How to host a Unity game in a Space",
    "description": "",
    "summary": "How to host a Unity game in a Space Did you know you can host a Unity game in a Hugging Face Space? ...",
    "pubDate": "Fri, 21 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-in-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-in-spaces-thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT Enterprise",
    "description": "Get enterprise-grade security & privacy and the most powerful version of ChatGPT yet.",
    "summary": "Get enterprise-grade security & privacy and the most powerful version of ChatGPT yet.",
    "pubDate": "Mon, 28 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Êó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶Âàù„ÄÅÊù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅåNVIDIA DGX„ÅÆAI„Çπ„Éë„Ç≥„É≥„ÇíÊßãÁØâ„ÄÇ„ÄåAIÂ§ßÂ≠¶„ÄçÊßãÊÉ≥„ÇíÂä†ÈÄü",
    "description": "<p>Êù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅØ„ÄÅAIÊïôËÇ≤„Å®Á†îÁ©∂„ÇíÂä†ÈÄü„Åï„Åõ„Çã„Åü„ÇÅ„ÄÅNVIDIA DGX B200„Ç∑„Çπ„ÉÜ„É†„ÇíÁî®„ÅÑ„ÅüÊó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶ÊúÄÂ§ß„ÅÆAI„Çπ„Éº„Éë„Éº„Ç≥„É≥„Éî„É•„Éº„Çø„Éº„ÇíÊßãÁØâ„Åó„ÄÅ2025Âπ¥10Êúà„Å´Êú¨Ê†ºÁ®ºÂÉç‰∫àÂÆö„Åß„Åô„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Êù±‰∫¨Â∑•Áßë [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/teu-ac-nvidia-dgx/'>Êó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶Âàù„ÄÅÊù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅåNVIDIA DGX„ÅÆAI„Çπ„Éë„Ç≥„É≥„ÇíÊßãÁØâ„ÄÇ„ÄåAIÂ§ßÂ≠¶„ÄçÊßãÊÉ≥„ÇíÂä†ÈÄü</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>Êù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅØ„ÄÅAIÊïôËÇ≤„Å®Á†îÁ©∂„ÇíÂä†ÈÄü„Åï„Åõ„Çã„Åü„ÇÅ„ÄÅNVIDIA DGX B200„Ç∑„Çπ„ÉÜ„É†„ÇíÁî®„ÅÑ„ÅüÊó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶ÊúÄÂ§ß„ÅÆAI„Çπ„Éº„Éë„Éº„Ç≥„É≥„Éî„É•„Éº„Çø„Éº„ÇíÊßãÁØâ„Åó„ÄÅ2025Âπ¥10Êúà„Å´Êú¨Ê†ºÁ®ºÂÉç‰∫àÂÆö„Åß„Åô„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Êù±‰∫¨Â∑•Áßë [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/teu-ac-nvidia-dgx/'>Êó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶Âàù„ÄÅÊù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅåNVIDIA DGX„ÅÆAI„Çπ„Éë„Ç≥„É≥„ÇíÊßãÁØâ„ÄÇ„ÄåAIÂ§ßÂ≠¶„ÄçÊßãÊÉ≥„ÇíÂä†ÈÄü</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Wed, 25 Jun 2025 09:24:03 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/teu-ac-nvidia-dgx/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/teu0.png"
  },
  {
    "title": "LLM„ÅßÊåë„ÇÄTitanicÁîüÂ≠ò‰∫àÊ∏¨: Few-Shot Leaning„ÅßË°®ÂΩ¢Âºè„Éá„Éº„Çø„ÅØ„Å©„Åì„ÅæËß£„Åë„ÇãÔºü",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Kaggle„ÅÆTitanic„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ„ÄÅÊ©üÊ¢∞Â≠¶Áøí„ÅÆÂÖ•ÈñÄ„Å®„Åó„Å¶ÂÆöÁï™„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ Â§ö„Åè„ÅÆÊ©üÊ¢∞Â≠¶ÁøíÊâãÊ≥ï„ÅåË©¶„Åï„Çå„Å¶„Åç„Åü„Åì„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´ÂØæ„Åó„ÄÅ‰ªäÂõû„ÅØÂ∞ë„ÅóÁï∞„Å™„Çã„Ç¢„Éó„É≠„Éº„ÉÅ„ÇíË©¶„Åø„Åü„ÅÑ„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5560' rel='nofollow'>LLM„ÅßÊåë„ÇÄTitanicÁîüÂ≠ò‰∫àÊ∏¨: Few-Shot Leaning„ÅßË°®ÂΩ¢Âºè„Éá„Éº„Çø„ÅØ„Å©„Åì„ÅæËß£„Åë„ÇãÔºü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Kaggle„ÅÆTitanic„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ„ÄÅÊ©üÊ¢∞Â≠¶Áøí„ÅÆÂÖ•ÈñÄ„Å®„Åó„Å¶ÂÆöÁï™„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ Â§ö„Åè„ÅÆÊ©üÊ¢∞Â≠¶ÁøíÊâãÊ≥ï„ÅåË©¶„Åï„Çå„Å¶„Åç„Åü„Åì„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´ÂØæ„Åó„ÄÅ‰ªäÂõû„ÅØÂ∞ë„ÅóÁï∞„Å™„Çã„Ç¢„Éó„É≠„Éº„ÉÅ„ÇíË©¶„Åø„Åü„ÅÑ„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5560' rel='nofollow'>LLM„ÅßÊåë„ÇÄTitanicÁîüÂ≠ò‰∫àÊ∏¨: Few-Shot Leaning„ÅßË°®ÂΩ¢Âºè„Éá„Éº„Çø„ÅØ„Å©„Åì„ÅæËß£„Åë„ÇãÔºü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Mon, 17 Mar 2025 21:16:00 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5560",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/f81fd2e4c52864042852c112ce927ae2.png"
  },
  {
    "title": "Achieving 10x growth with agentic sales prospecting",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Jun 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/clay",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New funding to build towards AGI",
    "description": "Today we‚Äôre announcing new funding‚Äî$40B at a $300B post-money valuation, which enables us to push the frontiers of AI research even further, scale our compute infrastructure, and deliver increasingly powerful tools for the 500 million people who use ChatGPT every week.",
    "summary": "Today we‚Äôre announcing new funding‚Äî$40B at a $300B post-money valuation, which enables us to push the frontiers of AI research even further, scale our compute infrastructure, and deliver increasingly powerful tools for the 500 million people who use ChatGPT every week.",
    "pubDate": "Mon, 31 Mar 2025 15:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/march-funding-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DolphinGemma: How Google AI is helping decode dolphin communication",
    "description": "DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate ‚Äî and hopefully find out what they're saying, too.",
    "summary": "DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate ‚Äî and hopefully find out what they're saying, too.",
    "pubDate": "Mon, 14 Apr 2025 17:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/dolphingemma-how-google-ai-is-helping-decode-dolphin-communication/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_SocialExplainers_16x9_DolphinGem.width-1300.png"
  },
  {
    "title": "Scaling security with responsible disclosure",
    "description": "OpenAI introduces its Outbound Coordinated Disclosure Policy to guide how it responsibly reports vulnerabilities in third-party software‚Äîemphasizing integrity, collaboration, and proactive security at scale.",
    "summary": "OpenAI introduces its Outbound Coordinated Disclosure Policy to guide how it responsibly reports vulnerabilities in third-party software‚Äîemphasizing integrity, collaboration, and proactive security at scale.",
    "pubDate": "Mon, 09 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-coordinated-vulnerability-disclosure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "È≥•ÂèñÁúå„ÄÅ‚ÄúÊÄßÁöÑ„Éá„Ç£„Éº„Éó„Éï„Çß„Ç§„ÇØ‚Äù‰ΩúÊàê„ÉªÊèê‰æõ„Å´Ë°åÊîøÁΩ∞„ÄÅ5‰∏áÂÜÜ‰ª•‰∏ã„ÅÆÈÅéÊñô„ÄÄÊù°‰æãÊîπÊ≠£Ê°à„ÇíÂèØÊ±∫",
    "description": "È≥•ÂèñÁúåË≠∞‰ºö„ÅØ„ÄÅ„ÄåÈ≥•ÂèñÁúåÈùíÂ∞ëÂπ¥ÂÅ•ÂÖ®ËÇ≤ÊàêÊù°‰æã„Äç„Å´Èñ¢„Åó„ÄÅÁîüÊàêAI„ÇíÂà©Áî®„Åó„Å¶ÂÆüÂú®„Åô„ÇãÂ≠ê„Å©„ÇÇ„ÅÆ„Çè„ÅÑ„Åõ„Å§„Å™ÁîªÂÉè„Çí‰ΩúÊàê„Åô„Çã‚ÄúÊÄßÁöÑ„Éá„Ç£„Éº„Éó„Éï„Çß„Ç§„ÇØ‚Äù„Å´„ÄÅË°åÊîøÁΩ∞„ÇíÂ∞éÂÖ•„Åô„ÇãÊîπÊ≠£Ê°à„ÇíÂèØÊ±∫„Åó„Åü„ÄÇ",
    "summary": "È≥•ÂèñÁúåË≠∞‰ºö„ÅØ„ÄÅ„ÄåÈ≥•ÂèñÁúåÈùíÂ∞ëÂπ¥ÂÅ•ÂÖ®ËÇ≤ÊàêÊù°‰æã„Äç„Å´Èñ¢„Åó„ÄÅÁîüÊàêAI„ÇíÂà©Áî®„Åó„Å¶ÂÆüÂú®„Åô„ÇãÂ≠ê„Å©„ÇÇ„ÅÆ„Çè„ÅÑ„Åõ„Å§„Å™ÁîªÂÉè„Çí‰ΩúÊàê„Åô„Çã‚ÄúÊÄßÁöÑ„Éá„Ç£„Éº„Éó„Éï„Çß„Ç§„ÇØ‚Äù„Å´„ÄÅË°åÊîøÁΩ∞„ÇíÂ∞éÂÖ•„Åô„ÇãÊîπÊ≠£Ê°à„ÇíÂèØÊ±∫„Åó„Åü„ÄÇ",
    "pubDate": "Tue, 01 Jul 2025 18:30:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/01/news107.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/01/cover_news107.jpg"
  },
  {
    "title": "Fanatics Betting and Gaming uses AI to focus on the big picture",
    "description": "A conversation with Andrea Ellis, Chief Financial Officer of Fanatics Betting and Gaming.",
    "summary": "A conversation with Andrea Ellis, Chief Financial Officer of Fanatics Betting and Gaming.",
    "pubDate": "Thu, 13 Feb 2025 10:01:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fanatics-betting-gaming-andrea-ellis",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Prompt Caching in the API",
    "description": "Offering automatic discounts on inputs that the model has recently seen",
    "summary": "Offering automatic discounts on inputs that the model has recently seen",
    "pubDate": "Tue, 01 Oct 2024 10:03:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-prompt-caching",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Domain randomization and generative models for robotic grasping",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 17 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/domain-randomization-and-generative-models-for-robotic-grasping",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness",
    "description": "arXiv:2507.01702v1 Announce Type: cross Abstract: The proliferation of multimodal memes in the social media era demands that multimodal Large Language Models (mLLMs) effectively understand meme harmfulness. Existing benchmarks for assessing mLLMs on harmful meme understanding rely on accuracy-based, model-agnostic evaluations using static datasets. These benchmarks are limited in their ability to provide up-to-date and thorough assessments, as online memes evolve dynamically. To address this, we propose AdamMeme, a flexible, agent-based evaluation framework that adaptively probes the reasoning capabilities of mLLMs in deciphering meme harmfulness. Through multi-agent collaboration, AdamMeme provides comprehensive evaluations by iteratively updating the meme data with challenging samples, thereby exposing specific limitations in how mLLMs interpret harmfulness. Extensive experiments show that our framework systematically reveals the varying performance of different target mLLMs, offering in-depth, fine-grained analyses of model-specific weaknesses. Our code is available at https://github.com/Lbotirx/AdamMeme.",
    "summary": "arXiv:2507.01702v1 Announce Type: cross Abstract: The proliferation of multimodal memes in the social media era demands that multimodal Large Language Models (mLLMs) effectively understand meme harmfulness. Existing benchmarks for assessing mLLMs on harmful meme understanding rely on accuracy-based, model-agnostic evaluations using static datasets. These benchmarks are limited in their ability to provide up-to-date and thorough assessments, as online memes evolve dynamically. To address this, we propose AdamMeme, a flexible, agent-based evaluation framework that adaptively probes the reasoning capabilities of mLLMs in deciphering meme harmfulness. Through multi-agent collaboration, AdamMeme provides comprehensive evaluations by iteratively updating the meme data with challenging samples, thereby exposing specific limitations in how mLLMs interpret harmfulness. Extensive experiments show that our framework systematically reveals the varying performance of different target mLLMs, offering in-depth, fine-grained analyses of model-specific weaknesses. Our code is available at https://github.com/Lbotirx/AdamMeme.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01702",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Scaling laws for reward model overoptimization",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 19 Oct 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-laws-for-reward-model-overoptimization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine tuning CLIP with Remote Sensing (Satellite) images and captions",
    "description": "",
    "summary": "Fine tuning CLIP with Remote Sensing (Satellite) images and captions Fine tuning CLIP with Remote Se...",
    "pubDate": "Wed, 13 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-clip-rsicd",
    "thumbnail": "https://huggingface.co/blog/assets/30_clip_rsicd/clip_schematic.png"
  },
  {
    "title": "Frontier AI regulation: Managing emerging risks to public safety",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 06 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-ai-regulation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Are Large Brainwave Foundation Models Capable Yet? Insights from Fine-tuning",
    "description": "arXiv:2507.01196v1 Announce Type: cross Abstract: Foundation Models have demonstrated significant success across various domains in Artificial Intelligence (AI), yet their capabilities for brainwave modeling remain unclear. In this paper, we comprehensively evaluate current Large Brainwave Foundation Models (LBMs) through systematic fine-tuning experiments across multiple Brain-Computer Interface (BCI) benchmark tasks, including memory tasks and sleep stage classification. Our extensive analysis shows that state-of-the-art LBMs achieve only marginal improvements (0.9%-1.2%) over traditional deep architectures while requiring significantly more parameters (millions vs thousands), raising important questions about their efficiency and applicability in BCI contexts. Moreover, through detailed ablation studies and Low-Rank Adaptation (LoRA), we significantly reduce trainable parameters without performance degradation, while demonstrating that architectural and training inefficiencies limit LBMs' current capabilities. Our experiments span both full model fine-tuning and parameter-efficient adaptation techniques, providing insights into optimal training strategies for BCI applications. We pioneer the application of LoRA to LBMs, revealing that performance benefits generally emerge when adapting multiple neural network components simultaneously. These findings highlight the critical need for domain-specific development strategies to advance LBMs, suggesting that current architectures may require redesign to fully leverage the potential of foundation models in brainwave analysis.",
    "summary": "arXiv:2507.01196v1 Announce Type: cross Abstract: Foundation Models have demonstrated significant success across various domains in Artificial Intelligence (AI), yet their capabilities for brainwave modeling remain unclear. In this paper, we comprehensively evaluate current Large Brainwave Foundation Models (LBMs) through systematic fine-tuning experiments across multiple Brain-Computer Interface (BCI) benchmark tasks, including memory tasks and sleep stage classification. Our extensive analysis shows that state-of-the-art LBMs achieve only marginal improvements (0.9%-1.2%) over traditional deep architectures while requiring significantly more parameters (millions vs thousands), raising important questions about their efficiency and applicability in BCI contexts. Moreover, through detailed ablation studies and Low-Rank Adaptation (LoRA), we significantly reduce trainable parameters without performance degradation, while demonstrating that architectural and training inefficiencies limit LBMs' current capabilities. Our experiments span both full model fine-tuning and parameter-efficient adaptation techniques, providing insights into optimal training strategies for BCI applications. We pioneer the application of LoRA to LBMs, revealing that performance benefits generally emerge when adapting multiple neural network components simultaneously. These findings highlight the critical need for domain-specific development strategies to advance LBMs, suggesting that current architectures may require redesign to fully leverage the potential of foundation models in brainwave analysis.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01196",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ICLShield: Exploring and Mitigating In-Context Learning Backdoor Attacks",
    "description": "arXiv:2507.01321v1 Announce Type: cross Abstract: In-context learning (ICL) has demonstrated remarkable success in large language models (LLMs) due to its adaptability and parameter-free nature. However, it also introduces a critical vulnerability to backdoor attacks, where adversaries can manipulate LLM behaviors by simply poisoning a few ICL demonstrations. In this paper, we propose, for the first time, the dual-learning hypothesis, which posits that LLMs simultaneously learn both the task-relevant latent concepts and backdoor latent concepts within poisoned demonstrations, jointly influencing the probability of model outputs. Through theoretical analysis, we derive an upper bound for ICL backdoor effects, revealing that the vulnerability is dominated by the concept preference ratio between the task and the backdoor. Motivated by these findings, we propose ICLShield, a defense mechanism that dynamically adjusts the concept preference ratio. Our method encourages LLMs to select clean demonstrations during the ICL phase by leveraging confidence and similarity scores, effectively mitigating susceptibility to backdoor attacks. Extensive experiments across multiple LLMs and tasks demonstrate that our method achieves state-of-the-art defense effectiveness, significantly outperforming existing approaches (+26.02% on average). Furthermore, our method exhibits exceptional adaptability and defensive performance even for closed-source models (e.g., GPT-4).",
    "summary": "arXiv:2507.01321v1 Announce Type: cross Abstract: In-context learning (ICL) has demonstrated remarkable success in large language models (LLMs) due to its adaptability and parameter-free nature. However, it also introduces a critical vulnerability to backdoor attacks, where adversaries can manipulate LLM behaviors by simply poisoning a few ICL demonstrations. In this paper, we propose, for the first time, the dual-learning hypothesis, which posits that LLMs simultaneously learn both the task-relevant latent concepts and backdoor latent concepts within poisoned demonstrations, jointly influencing the probability of model outputs. Through theoretical analysis, we derive an upper bound for ICL backdoor effects, revealing that the vulnerability is dominated by the concept preference ratio between the task and the backdoor. Motivated by these findings, we propose ICLShield, a defense mechanism that dynamically adjusts the concept preference ratio. Our method encourages LLMs to select clean demonstrations during the ICL phase by leveraging confidence and similarity scores, effectively mitigating susceptibility to backdoor attacks. Extensive experiments across multiple LLMs and tasks demonstrate that our method achieves state-of-the-art defense effectiveness, significantly outperforming existing approaches (+26.02% on average). Furthermore, our method exhibits exceptional adaptability and defensive performance even for closed-source models (e.g., GPT-4).",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01321",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Review completed & Altman, Brockman to continue to lead OpenAI",
    "description": "New board members named and enhancements to the governance structure introduced",
    "summary": "New board members named and enhancements to the governance structure introduced",
    "pubDate": "Fri, 08 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/review-completed-altman-brockman-to-continue-to-lead-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating PyTorch distributed fine-tuning with Intel technologies",
    "description": "",
    "summary": "Accelerating PyTorch distributed fine-tuning with Intel technologies For all their amazing performan...",
    "pubDate": "Fri, 19 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerating-pytorch",
    "thumbnail": "https://huggingface.co/blog/assets/36_accelerating_pytorch/04_four_nodes.png"
  },
  {
    "title": "Building an early warning system for LLM-aided biological threat creation",
    "description": "We‚Äôre developing a blueprint for evaluating the risk that a large language model (LLM) could aid someone in creating a biological threat.¬†In an evaluation involving both biology experts and students, we found that GPT-4 provides at most a mild uplift in biological threat creation accuracy. While this uplift is not large enough to be conclusive, our finding is a starting point for continued research and community deliberation.",
    "summary": "We‚Äôre developing a blueprint for evaluating the risk that a large language model (LLM) could aid someone in creating a biological threat.¬†In an evaluation involving both biology experts and students, we found that GPT-4 provides at most a mild uplift in biological threat creation accuracy. While this uplift is not large enough to be conclusive, our finding is a starting point for continued research and community deliberation.",
    "pubDate": "Wed, 31 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/building-an-early-warning-system-for-llm-aided-biological-threat-creation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FunSearch: Making new discoveries in mathematical sciences using Large Language Models",
    "description": "In a paper published in Nature, we introduce FunSearch, a method for searching for ‚Äúfunctions‚Äù written in computer code, and find new solutions in mathematics and computer science. FunSearch works by pairing a pre-trained LLM, whose goal is to provide creative solutions in the form of computer code, with an automated ‚Äúevaluator‚Äù, which guards against hallucinations and incorrect ideas.",
    "summary": "In a paper published in Nature, we introduce FunSearch, a method for searching for ‚Äúfunctions‚Äù written in computer code, and find new solutions in mathematics and computer science. FunSearch works by pairing a pre-trained LLM, whose goal is to provide creative solutions in the form of computer code, with an automated ‚Äúevaluator‚Äù, which guards against hallucinations and incorrect ideas.",
    "pubDate": "Thu, 14 Dec 2023 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/GC6SH0u6DyyCT9C1LH6XXmproSod7o5QGp9-Oe8BsuXyPzBlfcxFHX9pxXg69ZftEVU0Joga7tyo0VwQOSBBrugZ8qfl9_X-pgiH527p71S7DC32Jw=w1200-h630-n-nu"
  },
  {
    "title": "Procgen and MineRL Competitions",
    "description": "We‚Äôre excited to announce that OpenAI is co-organizing two NeurIPS 2020 competitions with AIcrowd, Carnegie Mellon University, and DeepMind, using Procgen Benchmark and MineRL.",
    "summary": "We‚Äôre excited to announce that OpenAI is co-organizing two NeurIPS 2020 competitions with AIcrowd, Carnegie Mellon University, and DeepMind, using Procgen Benchmark and MineRL.",
    "pubDate": "Sat, 20 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/procgen-minerl-competitions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FAIR-MATCH: A Multi-Objective Framework for Bias Mitigation in Reciprocal Dating Recommendations",
    "description": "arXiv:2507.01063v1 Announce Type: cross Abstract: Online dating platforms have fundamentally transformed the formation of romantic relationships, with millions of users worldwide relying on algorithmic matching systems to find compatible partners. However, current recommendation systems in dating applications suffer from significant algorithmic deficiencies, including but not limited to popularity bias, filter bubble effects, and inadequate reciprocity modeling that limit effectiveness and introduce harmful biases. This research integrates foundational work with recent empirical findings to deliver a detailed analysis of dating app recommendation systems, highlighting key issues and suggesting research-backed solutions. Through analysis of reciprocal recommendation frameworks, fairness evaluation metrics, and industry implementations, we demonstrate that current systems achieve modest performance with collaborative filtering reaching 25.1% while reciprocal methods achieve 28.7%. Our proposed mathematical framework addresses these limitations through enhanced similarity measures, multi-objective optimization, and fairness-aware algorithms that maintain competitive accuracy while improving demographic representation to reduce algorithmic bias.",
    "summary": "arXiv:2507.01063v1 Announce Type: cross Abstract: Online dating platforms have fundamentally transformed the formation of romantic relationships, with millions of users worldwide relying on algorithmic matching systems to find compatible partners. However, current recommendation systems in dating applications suffer from significant algorithmic deficiencies, including but not limited to popularity bias, filter bubble effects, and inadequate reciprocity modeling that limit effectiveness and introduce harmful biases. This research integrates foundational work with recent empirical findings to deliver a detailed analysis of dating app recommendation systems, highlighting key issues and suggesting research-backed solutions. Through analysis of reciprocal recommendation frameworks, fairness evaluation metrics, and industry implementations, we demonstrate that current systems achieve modest performance with collaborative filtering reaching 25.1% while reciprocal methods achieve 28.7%. Our proposed mathematical framework addresses these limitations through enhanced similarity measures, multi-objective optimization, and fairness-aware algorithms that maintain competitive accuracy while improving demographic representation to reduce algorithmic bias.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01063",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Streamlining financial solutions for safety and growth",
    "description": "Stripe leverages GPT-4 to streamline user experience and combat fraud.",
    "summary": "Stripe leverages GPT-4 to streamline user experience and combat fraud.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/stripe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PaliGemma ‚Äì Google's Cutting-Edge Open Vision Language Model",
    "description": "",
    "summary": "PaliGemma ‚Äì Google's Cutting-Edge Open Vision Language Model Updated on 23-05-2024: We have introduc...",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma/Paligemma.png"
  },
  {
    "title": "Introducing Activation Atlases",
    "description": "We‚Äôve created¬†activation atlases¬†(in¬†collaboration¬†with Google researchers), a new technique for visualizing what interactions between neurons can represent. As AI systems are deployed in increasingly sensitive contexts, having a better understanding of their internal decision-making processes will let us identify weaknesses and investigate¬†failures.",
    "summary": "We‚Äôve created¬†activation atlases¬†(in¬†collaboration¬†with Google researchers), a new technique for visualizing what interactions between neurons can represent. As AI systems are deployed in increasingly sensitive contexts, having a better understanding of their internal decision-making processes will let us identify weaknesses and investigate¬†failures.",
    "pubDate": "Wed, 06 Mar 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-activation-atlases",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing ChatGPT",
    "description": "We‚Äôve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.",
    "summary": "We‚Äôve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.",
    "pubDate": "Wed, 30 Nov 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI for Game Development: Creating a Farming Game in 5 Days. Part 2",
    "description": "",
    "summary": "AI for Game Development: Creating a Farming Game in 5 Days. Part 2 Welcome to AI for Game Developmen...",
    "pubDate": "Mon, 09 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-2",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail2.png"
  },
  {
    "title": "Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU",
    "description": "",
    "summary": "Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU We are excited to officially release the integ...",
    "pubDate": "Thu, 09 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trl-peft",
    "thumbnail": "https://huggingface.co/blog/trl-peft/assets/133_trl_peft/thumbnail.png"
  },
  {
    "title": "Infrastructure for deep learning",
    "description": "Deep learning is an empirical science, and the quality of a group‚Äôs infrastructure is a multiplier on progress. Fortunately, today‚Äôs open-source ecosystem makes it possible for anyone to build great deep learning infrastructure.",
    "summary": "Deep learning is an empirical science, and the quality of a group‚Äôs infrastructure is a multiplier on progress. Fortunately, today‚Äôs open-source ecosystem makes it possible for anyone to build great deep learning infrastructure.",
    "pubDate": "Mon, 29 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/infrastructure-for-deep-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ECCV 2024 W-CODA: 1st Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving",
    "description": "arXiv:2507.01735v1 Announce Type: cross Abstract: In this paper, we present details of the 1st W-CODA workshop, held in conjunction with the ECCV 2024. W-CODA aims to explore next-generation solutions for autonomous driving corner cases, empowered by state-of-the-art multimodal perception and comprehension techniques. 5 Speakers from both academia and industry are invited to share their latest progress and opinions. We collect research papers and hold a dual-track challenge, including both corner case scene understanding and generation. As the pioneering effort, we will continuously bridge the gap between frontier autonomous driving techniques and fully intelligent, reliable self-driving agents robust towards corner cases.",
    "summary": "arXiv:2507.01735v1 Announce Type: cross Abstract: In this paper, we present details of the 1st W-CODA workshop, held in conjunction with the ECCV 2024. W-CODA aims to explore next-generation solutions for autonomous driving corner cases, empowered by state-of-the-art multimodal perception and comprehension techniques. 5 Speakers from both academia and industry are invited to share their latest progress and opinions. We collect research papers and hold a dual-track challenge, including both corner case scene understanding and generation. As the pioneering effort, we will continuously bridge the gap between frontier autonomous driving techniques and fully intelligent, reliable self-driving agents robust towards corner cases.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01735",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deploy Meta Llama 3.1 405B on Google Cloud Vertex AI",
    "description": "",
    "summary": "Deploy Meta Llama 3.1 405B on Google Cloud Vertex AI Meta Llama 3.1 is the latest open LLM from Meta...",
    "pubDate": "Mon, 19 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama31-on-vertex-ai",
    "thumbnail": "https://huggingface.co/blog/assets/llama31-on-vertex-ai/thumbnail.png"
  },
  {
    "title": "New tool evaluates progress in reinforcement learning",
    "description": "‚ÄúIntersectionZoo,‚Äù a benchmarking tool, uses a real-world traffic problem to test progress in deep reinforcement learning algorithms.",
    "summary": "‚ÄúIntersectionZoo,‚Äù a benchmarking tool, uses a real-world traffic problem to test progress in deep reinforcement learning algorithms.",
    "pubDate": "Mon, 05 May 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-tool-evaluate-progress-reinforcement-learning-0505",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/Intersection-Zoo.jpg"
  },
  {
    "title": "Train and Fine-Tune Sentence Transformers Models",
    "description": "",
    "summary": "Train and Fine-Tune Sentence Transformers Models This guide is only suited for Sentence Transformers...",
    "pubDate": "Wed, 10 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-train-sentence-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/95_training_st_models/thumbnail.png"
  },
  {
    "title": "Refining Gelfond Rationality Principle Towards More Comprehensive Foundational Principles for Answer Set Semantics",
    "description": "arXiv:2507.01833v1 Announce Type: new Abstract: Non-monotonic logic programming is the basis for a declarative problem solving paradigm known as answer set programming (ASP). Departing from the seminal definition by Gelfond and Lifschitz in 1988 for simple normal logic programs, various answer set semantics have been proposed for extensions. We consider two important questions: (1) Should the minimal model property, constraint monotonicity and foundedness as defined in the literature be mandatory conditions for an answer set semantics in general? (2) If not, what other properties could be considered as general principles for answer set semantics? We address the two questions. First, it seems that the three aforementioned conditions may sometimes be too strong, and we illustrate with examples that enforcing them may exclude expected answer sets. Second, we evolve the Gelfond answer set (GAS) principles for answer set construction by refining the Gelfond's rationality principle to well-supportedness, minimality w.r.t. negation by default and minimality w.r.t. epistemic negation. The principle of well-supportedness guarantees that every answer set is constructible from if-then rules obeying a level mapping and is thus free of circular justification, while the two minimality principles ensure that the formalism minimizes knowledge both at the level of answer sets and of world views. Third, to embody the refined GAS principles, we extend the notion of well-supportedness substantially to answer sets and world views, respectively. Fourth, we define new answer set semantics in terms of the refined GAS principles. Fifth, we use the refined GAS principles as an alternative baseline to intuitively assess the existing answer set semantics. Finally, we analyze the computational complexity.",
    "summary": "arXiv:2507.01833v1 Announce Type: new Abstract: Non-monotonic logic programming is the basis for a declarative problem solving paradigm known as answer set programming (ASP). Departing from the seminal definition by Gelfond and Lifschitz in 1988 for simple normal logic programs, various answer set semantics have been proposed for extensions. We consider two important questions: (1) Should the minimal model property, constraint monotonicity and foundedness as defined in the literature be mandatory conditions for an answer set semantics in general? (2) If not, what other properties could be considered as general principles for answer set semantics? We address the two questions. First, it seems that the three aforementioned conditions may sometimes be too strong, and we illustrate with examples that enforcing them may exclude expected answer sets. Second, we evolve the Gelfond answer set (GAS) principles for answer set construction by refining the Gelfond's rationality principle to well-supportedness, minimality w.r.t. negation by default and minimality w.r.t. epistemic negation. The principle of well-supportedness guarantees that every answer set is constructible from if-then rules obeying a level mapping and is thus free of circular justification, while the two minimality principles ensure that the formalism minimizes knowledge both at the level of answer sets and of world views. Third, to embody the refined GAS principles, we extend the notion of well-supportedness substantially to answer sets and world views, respectively. Fourth, we define new answer set semantics in terms of the refined GAS principles. Fifth, we use the refined GAS principles as an alternative baseline to intuitively assess the existing answer set semantics. Finally, we analyze the computational complexity.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01833",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Generative language modeling for automated theorem proving",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 07 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generative-language-modeling-for-automated-theorem-proving",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "œÄ0 and œÄ0-FAST: Vision-Language-Action Models for General Robot Control",
    "description": "",
    "summary": "œÄ0 and œÄ0-FAST: Vision-Language-Action Models for General Robot Control We have ported the first rob...",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pi0",
    "thumbnail": "https://huggingface.co/blog/assets/192_pi0/new_thumbnail_pi0.001.png"
  },
  {
    "title": "GraphCast: AI model for faster and more accurate global weather forecasting",
    "description": "We introduce GraphCast, a state-of-the-art AI model able to make medium-range weather forecasts with unprecedented accuracy",
    "summary": "We introduce GraphCast, a state-of-the-art AI model able to make medium-range weather forecasts with unprecedented accuracy",
    "pubDate": "Tue, 14 Nov 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/",
    "thumbnail": "https://lh3.googleusercontent.com/5dL0Cm8RLhoDdfPzVy5MlKB5JDcfYucbgxzNLJVFdtqRe15-bFTvfdOrpqnrM4m5XMEEboWtvyCLQgSCvHEH62QqZZI0V_zuBAz71fghXgU5UNFFwg=w1200-h630-n-nu"
  },
  {
    "title": "Rox goes ‚Äúall in‚Äù on OpenAI",
    "description": "By combining commercial experience and deep LLM expertise with OpenAI‚Äôs models, Rox makes every seller a top 1% seller.",
    "summary": "By combining commercial experience and deep LLM expertise with OpenAI‚Äôs models, Rox makes every seller a top 1% seller.",
    "pubDate": "Tue, 19 Nov 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rox",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Robots that learn",
    "description": "We‚Äôve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can learn a new task after seeing it done once.",
    "summary": "We‚Äôve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can learn a new task after seeing it done once.",
    "pubDate": "Tue, 16 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/robots-that-learn",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing the Hugging Face Fellowship Program",
    "description": "",
    "summary": "Announcing the Hugging Face Fellowship Program The Fellowship is a network of exceptional people fro...",
    "pubDate": "Tue, 17 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fellowship",
    "thumbnail": "https://huggingface.co/blog/assets/62_fellowship/fellowship-thumbnail.png"
  },
  {
    "title": "Prediction and control with temporal segment models",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 12 Mar 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/prediction-and-control-with-temporal-segment-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sam & Jony",
    "description": "Sam & Jony",
    "summary": "Sam & Jony",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/sam-and-jony",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introduction to 3D Gaussian Splatting",
    "description": "",
    "summary": "Introduction to 3D Gaussian Splatting 3D Gaussian Splatting is a rasterization technique described i...",
    "pubDate": "Mon, 18 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gaussian-splatting",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail-gaussian-splatting.png"
  },
  {
    "title": "New tools for building agents",
    "description": "We‚Äôre evolving our platform to help developers and enterprises build useful and reliable agents.",
    "summary": "We‚Äôre evolving our platform to help developers and enterprises build useful and reliable agents.",
    "pubDate": "Tue, 11 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-for-building-agents",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Chatbot on your Laptop: Phi-2 on Intel Meteor Lake",
    "description": "",
    "summary": "A Chatbot on your Laptop: Phi-2 on Intel Meteor Lake Because of their impressive abilities, large la...",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/phi2-intel-meteor-lake",
    "thumbnail": "https://huggingface.co/blog/assets/phi2-intel-meteor-lake/02.jpg"
  },
  {
    "title": "OpenAI partners with Scale to provide support for enterprises fine-tuning models",
    "description": "OpenAI‚Äôs customers can leverage Scale‚Äôs AI expertise to customize our most advanced models.",
    "summary": "OpenAI‚Äôs customers can leverage Scale‚Äôs AI expertise to customize our most advanced models.",
    "pubDate": "Thu, 24 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-partners-with-scale-to-provide-support-for-enterprises-fine-tuning-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Code Llama: Llama 2 learns to code",
    "description": "",
    "summary": "Code Llama: Llama 2 learns to code Introduction Code Llama is a family of state-of-the-art, open-acc...",
    "pubDate": "Fri, 25 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codellama",
    "thumbnail": "https://huggingface.co/blog/assets/160_codellama/thumbnail.jpg"
  },
  {
    "title": "Some considerations on learning to explore via meta-reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 03 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/some-considerations-on-learning-to-explore-via-meta-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Locality-aware Parallel Decoding for Efficient Autoregressive Image Generation",
    "description": "arXiv:2507.01957v1 Announce Type: cross Abstract: We present Locality-aware Parallel Decoding (LPD) to accelerate autoregressive image generation. Traditional autoregressive image generation relies on next-patch prediction, a memory-bound process that leads to high latency. Existing works have tried to parallelize next-patch prediction by shifting to multi-patch prediction to accelerate the process, but only achieved limited parallelization. To achieve high parallelization while maintaining generation quality, we introduce two key techniques: (1) Flexible Parallelized Autoregressive Modeling, a novel architecture that enables arbitrary generation ordering and degrees of parallelization. It uses learnable position query tokens to guide generation at target positions while ensuring mutual visibility among concurrently generated tokens for consistent parallel decoding. (2) Locality-aware Generation Ordering, a novel schedule that forms groups to minimize intra-group dependencies and maximize contextual support, enhancing generation quality. With these designs, we reduce the generation steps from 256 to 20 (256$times$256 res.) and 1024 to 48 (512$times$512 res.) without compromising quality on the ImageNet class-conditional generation, and achieving at least 3.4$times$ lower latency than previous parallelized autoregressive models.",
    "summary": "arXiv:2507.01957v1 Announce Type: cross Abstract: We present Locality-aware Parallel Decoding (LPD) to accelerate autoregressive image generation. Traditional autoregressive image generation relies on next-patch prediction, a memory-bound process that leads to high latency. Existing works have tried to parallelize next-patch prediction by shifting to multi-patch prediction to accelerate the process, but only achieved limited parallelization. To achieve high parallelization while maintaining generation quality, we introduce two key techniques: (1) Flexible Parallelized Autoregressive Modeling, a novel architecture that enables arbitrary generation ordering and degrees of parallelization. It uses learnable position query tokens to guide generation at target positions while ensuring mutual visibility among concurrently generated tokens for consistent parallel decoding. (2) Locality-aware Generation Ordering, a novel schedule that forms groups to minimize intra-group dependencies and maximize contextual support, enhancing generation quality. With these designs, we reduce the generation steps from 256 to 20 (256$times$256 res.) and 1024 to 48 (512$times$512 res.) without compromising quality on the ImageNet class-conditional generation, and achieving at least 3.4$times$ lower latency than previous parallelized autoregressive models.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01957",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI helps John Deere transform agriculture",
    "description": "John Deere‚Äôs Justin Rose talks about transforming agriculture with AI and shares how the company is scaling innovation to help farmers work smarter, more efficiently, and sustainably.",
    "summary": "John Deere‚Äôs Justin Rose talks about transforming agriculture with AI and shares how the company is scaling innovation to help farmers work smarter, more efficiently, and sustainably.",
    "pubDate": "Tue, 06 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/john-deere-justin-rose",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Confronting the AI/energy conundrum",
    "description": "The MIT Energy Initiative‚Äôs annual research symposium explores artificial intelligence as both a problem and a solution for the clean energy transition.",
    "summary": "The MIT Energy Initiative‚Äôs annual research symposium explores artificial intelligence as both a problem and a solution for the clean energy transition.",
    "pubDate": "Wed, 02 Jul 2025 15:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/confronting-ai-energy-conundrum-0702",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MITEI-evelyn-wang.JPG"
  },
  {
    "title": "üß® Diffusers welcomes Stable Diffusion 3.5 Large",
    "description": "",
    "summary": "üß® Diffusers welcomes Stable Diffusion 3.5 Large Stable Diffusion 3.5 is the improved variant of its ...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd3-5",
    "thumbnail": "https://huggingface.co/blog/assets/sd3-5/thumbnail.png"
  },
  {
    "title": "Study shows vision-language models can‚Äôt handle queries with negation words",
    "description": "Words like ‚Äúno‚Äù and ‚Äúnot‚Äù can cause this popular class of AI models to fail unexpectedly in high-stakes settings, such as medical diagnosis.",
    "summary": "Words like ‚Äúno‚Äù and ‚Äúnot‚Äù can cause this popular class of AI models to fail unexpectedly in high-stakes settings, such as medical diagnosis.",
    "pubDate": "Wed, 14 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/study-shows-vision-language-models-cant-handle-negation-words-queries-0514",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-LMNegation-01-press.jpg"
  },
  {
    "title": "Microsoft invests in and partners with OpenAI to support us building beneficial AGI",
    "description": "Microsoft is investing $1 billion in OpenAI to support us building artificial general intelligence (AGI) with widely distributed economic benefits. We‚Äôre partnering to develop a hardware and software platform within Microsoft Azure which will scale to AGI. We‚Äôll jointly develop new Azure AI supercomputing technologies, and Microsoft will become our exclusive cloud provider‚Äîso we‚Äôll be working hard together to further extend Microsoft Azure‚Äôs capabilities in large-scale AI systems.",
    "summary": "Microsoft is investing $1 billion in OpenAI to support us building artificial general intelligence (AGI) with widely distributed economic benefits. We‚Äôre partnering to develop a hardware and software platform within Microsoft Azure which will scale to AGI. We‚Äôll jointly develop new Azure AI supercomputing technologies, and Microsoft will become our exclusive cloud provider‚Äîso we‚Äôll be working hard together to further extend Microsoft Azure‚Äôs capabilities in large-scale AI systems.",
    "pubDate": "Mon, 22 Jul 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/microsoft-invests-in-and-partners-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using transformers, accelerate and bitsandbytes",
    "description": "",
    "summary": "A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using Hugging Face Tr...",
    "pubDate": "Wed, 17 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hf-bitsandbytes-integration",
    "thumbnail": "https://huggingface.co/blog/assets/96_hf_bitsandbytes_integration/Thumbnail_blue.png"
  },
  {
    "title": "ChatGPT can now see, hear, and speak",
    "description": "We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you‚Äôre talking about.",
    "summary": "We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you‚Äôre talking about.",
    "pubDate": "Mon, 25 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-can-now-see-hear-and-speak",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DALL¬∑E 2: Extending creativity",
    "description": "As part of our DALL¬∑E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL¬∑E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL¬∑E and have served as key voices as we‚Äôve made decisions about DALL¬∑E‚Äôs¬†features.",
    "summary": "As part of our DALL¬∑E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL¬∑E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL¬∑E and have served as key voices as we‚Äôve made decisions about DALL¬∑E‚Äôs¬†features.",
    "pubDate": "Thu, 14 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-extending-creativity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interpretable machine learning through teaching",
    "description": "We‚Äôve designed a method that encourages AIs to teach each other with examples that also make sense to humans. Our approach automatically selects the most informative examples to teach a concept‚Äîfor instance, the best images to describe the concept of dogs‚Äîand experimentally we found our approach to be effective at teaching both AIs",
    "summary": "We‚Äôve designed a method that encourages AIs to teach each other with examples that also make sense to humans. Our approach automatically selects the most informative examples to teach a concept‚Äîfor instance, the best images to describe the concept of dogs‚Äîand experimentally we found our approach to be effective at teaching both AIs",
    "pubDate": "Thu, 15 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/interpretable-machine-learning-through-teaching",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Automating customer support agents",
    "description": "MavenAGI is a new software company for the AI era. They recently launched an AI customer service agent, built on the flexibility of GPT-4, which a number of companies like Tripadvisor, Clickup and Rho are already using to save time and better serve their customers.",
    "summary": "MavenAGI is a new software company for the AI era. They recently launched an AI customer service agent, built on the flexibility of GPT-4, which a number of companies like Tripadvisor, Clickup and Rho are already using to save time and better serve their customers.",
    "pubDate": "Wed, 29 May 2024 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mavenagi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deliberative alignment: reasoning enables safer language models",
    "description": "Deliberative alignment: reasoning enables safer language models Introducing our new alignment strategy for o1 models, which are directly taught safety specifications and how to reason over them.",
    "summary": "Deliberative alignment: reasoning enables safer language models Introducing our new alignment strategy for o1 models, which are directly taught safety specifications and how to reason over them.",
    "pubDate": "Fri, 20 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deliberative-alignment",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Customizing models for legal professionals",
    "description": "Harvey partners with OpenAI to build a custom-trained model for legal professionals.",
    "summary": "Harvey partners with OpenAI to build a custom-trained model for legal professionals.",
    "pubDate": "Tue, 02 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/harvey",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing next-generation audio models in the API",
    "description": "For the first time, developers can also instruct the text-to-speech model to speak in a specific way‚Äîfor example, ‚Äútalk like a sympathetic customer service agent‚Äù‚Äîunlocking a new level of customization for voice agents.",
    "summary": "For the first time, developers can also instruct the text-to-speech model to speak in a specific way‚Äîfor example, ‚Äútalk like a sympathetic customer service agent‚Äù‚Äîunlocking a new level of customization for voice agents.",
    "pubDate": "Thu, 20 Mar 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-our-next-generation-audio-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Model Safety Behavior with Rule-Based Rewards",
    "description": "We've developed and applied a new method leveraging Rule-Based Rewards (RBRs) that aligns models to behave safely without extensive human data collection.",
    "summary": "We've developed and applied a new method leveraging Rule-Based Rewards (RBRs) that aligns models to behave safely without extensive human data collection.",
    "pubDate": "Wed, 24 Jul 2024 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-model-safety-behavior-with-rule-based-rewards",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2019: Applications open",
    "description": "We are now accepting applications for our second cohort of OpenAI Scholars, a program where we provide 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "summary": "We are now accepting applications for our second cohort of OpenAI Scholars, a program where we provide 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "pubDate": "Thu, 11 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Codex",
    "description": "We‚Äôve created an improved version of OpenAI Codex, our AI system that translates natural language to code, and we are releasing it through our API in private beta starting today.",
    "summary": "We‚Äôve created an improved version of OpenAI Codex, our AI system that translates natural language to code, and we are releasing it through our API in private beta starting today.",
    "pubDate": "Tue, 10 Aug 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-codex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars",
    "description": "We‚Äôre providing 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "summary": "We‚Äôre providing 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "pubDate": "Tue, 06 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hardware-software co-exploration with racetrack memory based in-memory computing for CNN inference in embedded systems",
    "description": "arXiv:2507.01429v1 Announce Type: cross Abstract: Deep neural networks generate and process large volumes of data, posing challenges for low-resource embedded systems. In-memory computing has been demonstrated as an efficient computing infrastructure and shows promise for embedded AI applications. Among newly-researched memory technologies, racetrack memory is a non-volatile technology that allows high data density fabrication, making it a good fit for in-memory computing. However, integrating in-memory arithmetic circuits with memory cells affects both the memory density and power efficiency. It remains challenging to build efficient in-memory arithmetic circuits on racetrack memory within area and energy constraints. To this end, we present an efficient in-memory convolutional neural network (CNN) accelerator optimized for use with racetrack memory. We design a series of fundamental arithmetic circuits as in-memory computing cells suited for multiply-and-accumulate operations. Moreover, we explore the design space of racetrack memory based systems and CNN model architectures, employing co-design to improve the efficiency and performance of performing CNN inference in racetrack memory while maintaining model accuracy. Our designed circuits and model-system co-optimization strategies achieve a small memory bank area with significant improvements in energy and performance for racetrack memory based embedded systems.",
    "summary": "arXiv:2507.01429v1 Announce Type: cross Abstract: Deep neural networks generate and process large volumes of data, posing challenges for low-resource embedded systems. In-memory computing has been demonstrated as an efficient computing infrastructure and shows promise for embedded AI applications. Among newly-researched memory technologies, racetrack memory is a non-volatile technology that allows high data density fabrication, making it a good fit for in-memory computing. However, integrating in-memory arithmetic circuits with memory cells affects both the memory density and power efficiency. It remains challenging to build efficient in-memory arithmetic circuits on racetrack memory within area and energy constraints. To this end, we present an efficient in-memory convolutional neural network (CNN) accelerator optimized for use with racetrack memory. We design a series of fundamental arithmetic circuits as in-memory computing cells suited for multiply-and-accumulate operations. Moreover, we explore the design space of racetrack memory based systems and CNN model architectures, employing co-design to improve the efficiency and performance of performing CNN inference in racetrack memory while maintaining model accuracy. Our designed circuits and model-system co-optimization strategies achieve a small memory bank area with significant improvements in energy and performance for racetrack memory based embedded systems.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01429",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Zero-Incentive Dynamics: a look at reward sparsity through the lens of unrewarded subgoals",
    "description": "arXiv:2507.01470v1 Announce Type: cross Abstract: This work re-examines the commonly held assumption that the frequency of rewards is a reliable measure of task difficulty in reinforcement learning. We identify and formalize a structural challenge that undermines the effectiveness of current policy learning methods: when essential subgoals do not directly yield rewards. We characterize such settings as exhibiting zero-incentive dynamics, where transitions critical to success remain unrewarded. We show that state-of-the-art deep subgoal-based algorithms fail to leverage these dynamics and that learning performance is highly sensitive to the temporal proximity between subgoal completion and eventual reward. These findings reveal a fundamental limitation in current approaches and point to the need for mechanisms that can infer latent task structure without relying on immediate incentives.",
    "summary": "arXiv:2507.01470v1 Announce Type: cross Abstract: This work re-examines the commonly held assumption that the frequency of rewards is a reliable measure of task difficulty in reinforcement learning. We identify and formalize a structural challenge that undermines the effectiveness of current policy learning methods: when essential subgoals do not directly yield rewards. We characterize such settings as exhibiting zero-incentive dynamics, where transitions critical to success remain unrewarded. We show that state-of-the-art deep subgoal-based algorithms fail to leverage these dynamics and that learning performance is highly sensitive to the temporal proximity between subgoal completion and eventual reward. These findings reveal a fundamental limitation in current approaches and point to the need for mechanisms that can infer latent task structure without relying on immediate incentives.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01470",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "On first-order meta-learning algorithms",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 08 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/on-first-order-meta-learning-algorithms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Training and Finetuning Sparse Embedding Models with Sentence Transformers v5",
    "description": "",
    "summary": "Training and Finetuning Sparse Embedding Models with Sentence Transformers v5 Sentence Transformers ...",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-sparse-encoder",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "Fine-tuning GPT-3 to scale video creation",
    "description": "Fine-tuning GPT-3 to power and scale done-for-you video creation.",
    "summary": "Fine-tuning GPT-3 to power and scale done-for-you video creation.",
    "pubDate": "Tue, 03 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/waymark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 11 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-connection-between-generative-adversarial-networks-inverse-reinforcement-learning-and-energy-based-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "17 Reasons Why Gradio Isn't Just Another UI Library",
    "description": "",
    "summary": "17 Reasons Why Gradio Isn't Just Another UI Library Introduction 'Oh, Gradio? That's a Python librar...",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/why-gradio-stands-out",
    "thumbnail": "https://huggingface.co/blog/assets/why-gradio-stands-out/thumbnail.png"
  },
  {
    "title": "Tightly-Coupled LiDAR-IMU-Leg Odometry with Online Learned Leg Kinematics Incorporating Foot Tactile Information",
    "description": "arXiv:2506.09548v2 Announce Type: replace-cross Abstract: In this letter, we present tightly coupled LiDAR-IMU-leg odometry, which is robust to challenging conditions such as featureless environments and deformable terrains. We developed an online learning-based leg kinematics model named the neural leg kinematics model, which incorporates tactile information (foot reaction force) to implicitly express the nonlinear dynamics between robot feet and the ground. Online training of this model enhances its adaptability to weight load changes of a robot (e.g., assuming delivery or transportation tasks) and terrain conditions. According to the textit{neural adaptive leg odometry factor} and online uncertainty estimation of the leg kinematics model-based motion predictions, we jointly solve online training of this kinematics model and odometry estimation on a unified factor graph to retain the consistency of both. The proposed method was verified through real experiments using a quadruped robot in two challenging situations: 1) a sandy beach, representing an extremely featureless area with a deformable terrain, and 2) a campus, including multiple featureless areas and terrain types of asphalt, gravel (deformable terrain), and grass. Experimental results showed that our odometry estimation incorporating the textit{neural leg kinematics model} outperforms state-of-the-art works. Our project page is available for further details: https://takuokawara.github.io/RAL2025_project_page/",
    "summary": "arXiv:2506.09548v2 Announce Type: replace-cross Abstract: In this letter, we present tightly coupled LiDAR-IMU-leg odometry, which is robust to challenging conditions such as featureless environments and deformable terrains. We developed an online learning-based leg kinematics model named the neural leg kinematics model, which incorporates tactile information (foot reaction force) to implicitly express the nonlinear dynamics between robot feet and the ground. Online training of this model enhances its adaptability to weight load changes of a robot (e.g., assuming delivery or transportation tasks) and terrain conditions. According to the textit{neural adaptive leg odometry factor} and online uncertainty estimation of the leg kinematics model-based motion predictions, we jointly solve online training of this kinematics model and odometry estimation on a unified factor graph to retain the consistency of both. The proposed method was verified through real experiments using a quadruped robot in two challenging situations: 1) a sandy beach, representing an extremely featureless area with a deformable terrain, and 2) a campus, including multiple featureless areas and terrain types of asphalt, gravel (deformable terrain), and grass. Experimental results showed that our odometry estimation incorporating the textit{neural leg kinematics model} outperforms state-of-the-art works. Our project page is available for further details: https://takuokawara.github.io/RAL2025_project_page/",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.09548",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Epistemic Scarcity: The Economics of Unresolvable Unknowns",
    "description": "arXiv:2507.01483v1 Announce Type: cross Abstract: This paper presents a praxeological analysis of artificial intelligence and algorithmic governance, challenging assumptions about the capacity of machine systems to sustain economic and epistemic order. Drawing on Misesian a priori reasoning and Austrian theories of entrepreneurship, we argue that AI systems are incapable of performing the core functions of economic coordination: interpreting ends, discovering means, and communicating subjective value through prices. Where neoclassical and behavioural models treat decisions as optimisation under constraint, we frame them as purposive actions under uncertainty. We critique dominant ethical AI frameworks such as Fairness, Accountability, and Transparency (FAT) as extensions of constructivist rationalism, which conflict with a liberal order grounded in voluntary action and property rights. Attempts to encode moral reasoning in algorithms reflect a misunderstanding of ethics and economics. However complex, AI systems cannot originate norms, interpret institutions, or bear responsibility. They remain opaque, misaligned, and inert. Using the concept of epistemic scarcity, we explore how information abundance degrades truth discernment, enabling both entrepreneurial insight and soft totalitarianism. Our analysis ends with a civilisational claim: the debate over AI concerns the future of human autonomy, institutional evolution, and reasoned choice. The Austrian tradition, focused on action, subjectivity, and spontaneous order, offers the only coherent alternative to rising computational social control.",
    "summary": "arXiv:2507.01483v1 Announce Type: cross Abstract: This paper presents a praxeological analysis of artificial intelligence and algorithmic governance, challenging assumptions about the capacity of machine systems to sustain economic and epistemic order. Drawing on Misesian a priori reasoning and Austrian theories of entrepreneurship, we argue that AI systems are incapable of performing the core functions of economic coordination: interpreting ends, discovering means, and communicating subjective value through prices. Where neoclassical and behavioural models treat decisions as optimisation under constraint, we frame them as purposive actions under uncertainty. We critique dominant ethical AI frameworks such as Fairness, Accountability, and Transparency (FAT) as extensions of constructivist rationalism, which conflict with a liberal order grounded in voluntary action and property rights. Attempts to encode moral reasoning in algorithms reflect a misunderstanding of ethics and economics. However complex, AI systems cannot originate norms, interpret institutions, or bear responsibility. They remain opaque, misaligned, and inert. Using the concept of epistemic scarcity, we explore how information abundance degrades truth discernment, enabling both entrepreneurial insight and soft totalitarianism. Our analysis ends with a civilisational claim: the debate over AI concerns the future of human autonomy, institutional evolution, and reasoned choice. The Austrian tradition, focused on action, subjectivity, and spontaneous order, offers the only coherent alternative to rising computational social control.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01483",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Q&A: A roadmap for revolutionizing health care through data-driven innovation",
    "description": "A new book coauthored by MIT‚Äôs Dimitris Bertsimas explores how analytics is driving decisions and outcomes in health care.",
    "summary": "A new book coauthored by MIT‚Äôs Dimitris Bertsimas explores how analytics is driving decisions and outcomes in health care.",
    "pubDate": "Mon, 05 May 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/qa-roadmap-revolutionizing-health-care-through-data-driven-innovation-0505",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/Analytics-Edge-in-Healthcare-Dimitris-Bertsimas-00.png"
  },
  {
    "title": "Introducing Structured Outputs in the API",
    "description": "We are introducing Structured Outputs in the API‚Äîmodel outputs now reliably adhere to developer-supplied JSON Schemas.",
    "summary": "We are introducing Structured Outputs in the API‚Äîmodel outputs now reliably adhere to developer-supplied JSON Schemas.",
    "pubDate": "Tue, 06 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-structured-outputs-in-the-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Train a Sentence Embedding Model with 1B Training Pairs",
    "description": "",
    "summary": "Train a Sentence Embedding Model with 1 Billion Training Pairs Sentence embedding is a method that m...",
    "pubDate": "Mon, 25 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/1b-sentence-embeddings",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Gym Retro",
    "description": "We‚Äôre releasing the full version of¬†Gym Retro, a platform for reinforcement learning research on games. This brings our publicly-released game count from around 70 Atari games and 30 Sega games to over 1,000 games across a variety of backing emulators. We‚Äôre also releasing the tool we use to add new games to the¬†platform.",
    "summary": "We‚Äôre releasing the full version of¬†Gym Retro, a platform for reinforcement learning research on games. This brings our publicly-released game count from around 70 Atari games and 30 Sega games to over 1,000 games across a variety of backing emulators. We‚Äôre also releasing the tool we use to add new games to the¬†platform.",
    "pubDate": "Fri, 25 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gym-retro",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bringing meaning into technology deployment",
    "description": "The MIT Ethics of Computing Research Symposium showcases projects at the intersection of technology, ethics, and social responsibility.",
    "summary": "The MIT Ethics of Computing Research Symposium showcases projects at the intersection of technology, ethics, and social responsibility.",
    "pubDate": "Wed, 11 Jun 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/bringing-meaning-technology-deployment-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-SERC-Symposium.jpg"
  },
  {
    "title": "AI„ÅÆÊòéÊó•„ÅØ„ÄåÂ§±Êúõ„Äçor„ÄåÂ∏åÊúõ„ÄçÔºü‚îÄ‚îÄApple„Å®„Çµ„É†„Éª„Ç¢„É´„Éà„Éû„É≥„ÅÆ‚Äú2„Å§„ÅÆÊú™Êù•‰∫àÊ∏¨‚Äù„ÄÄ„Åù„ÅÆÊÑèÂë≥„ÇíËÄÉ„Åà„Çã",
    "description": "6Êúà„ÄÅAI„ÅÆÊú™Êù•„Å´Èñ¢„Åô„Çã2„Å§„ÅÆ‰∫àÊ∏¨„Åå„Åï„Çå„Åü„ÄÇÁ±≥Apple„ÅÆÁ†îÁ©∂ËÄÖ„Çâ„ÅåÂü∑Á≠Ü„Åó„ÅüË´ñÊñá„Å®„ÄÅÁ±≥OpenAI„ÅÆ„Çµ„É†„Éª„Ç¢„É´„Éà„Éû„É≥CEO„ÅÆ„Éñ„É≠„Ç∞Ë®ò‰∫ã„Å†„ÄÇ‰ªäÂõû„ÅØ„Åì„ÅÆ2„Å§„ÅÆ‰∏ªÂºµ„ÇíÂèñ„Çä‰∏ä„Åí„ÄÅ„Åù„ÅÆÊÑèÁæ©„Å´„Å§„ÅÑ„Å¶ËÄÉ„Åà„Å¶„Åø„Åü„ÅÑ„ÄÇ",
    "summary": "6Êúà„ÄÅAI„ÅÆÊú™Êù•„Å´Èñ¢„Åô„Çã2„Å§„ÅÆ‰∫àÊ∏¨„Åå„Åï„Çå„Åü„ÄÇÁ±≥Apple„ÅÆÁ†îÁ©∂ËÄÖ„Çâ„ÅåÂü∑Á≠Ü„Åó„ÅüË´ñÊñá„Å®„ÄÅÁ±≥OpenAI„ÅÆ„Çµ„É†„Éª„Ç¢„É´„Éà„Éû„É≥CEO„ÅÆ„Éñ„É≠„Ç∞Ë®ò‰∫ã„Å†„ÄÇ‰ªäÂõû„ÅØ„Åì„ÅÆ2„Å§„ÅÆ‰∏ªÂºµ„ÇíÂèñ„Çä‰∏ä„Åí„ÄÅ„Åù„ÅÆÊÑèÁæ©„Å´„Å§„ÅÑ„Å¶ËÄÉ„Åà„Å¶„Åø„Åü„ÅÑ„ÄÇ",
    "pubDate": "Thu, 03 Jul 2025 12:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/03/news035.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/03/cover_news035.jpg"
  },
  {
    "title": "Open-source LLMs as LangChain Agents",
    "description": "",
    "summary": "Open-source LLMs as LangChain Agents TL;DR Open-source LLMs have now reached a performance level tha...",
    "pubDate": "Wed, 24 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-source-llms-as-agents",
    "thumbnail": "https://huggingface.co/blog/assets/open-source-llms-as-agents/thumbnail_open_source_agents.png"
  },
  {
    "title": "Learning to play Minecraft with Video PreTraining",
    "description": "We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model can learn to craft diamond tools, a task that usually takes proficient humans over 20 minutes (24,000 actions). Our model uses the native human interface of keypresses and mouse movements, making it quite general, and represents a step towards general computer-using¬†agents.",
    "summary": "We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model can learn to craft diamond tools, a task that usually takes proficient humans over 20 minutes (24,000 actions). Our model uses the native human interface of keypresses and mouse movements, making it quite general, and represents a step towards general computer-using¬†agents.",
    "pubDate": "Thu, 23 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/vpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Converting Vertex-Colored Meshes to Textured Meshes",
    "description": "",
    "summary": "Converting Vertex-Colored Meshes to Textured Meshes Convert vertex-colored meshes to UV-mapped, text...",
    "pubDate": "Mon, 30 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vertex-colored-to-textured-mesh",
    "thumbnail": "https://huggingface.co/blog/assets/vertex-colored-to-textured-mesh/thumbnail.png"
  },
  {
    "title": "A glimpse of the next generation of AlphaFold",
    "description": "Progress update: Our latest AlphaFold model shows significantly improved accuracy and expands coverage beyond proteins to other biological molecules, including ligands.",
    "summary": "Progress update: Our latest AlphaFold model shows significantly improved accuracy and expands coverage beyond proteins to other biological molecules, including ligands.",
    "pubDate": "Tue, 31 Oct 2023 13:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/",
    "thumbnail": "https://lh3.googleusercontent.com/1xoO5BAUUU8kLns4myMNnKw6RRQyUk1JdlWL1M0aDiagMgaBeDA9O8Y4rYFAo9hfnzmb0cnUMrT_-cStBqnyp_zW59F5Edwbvxcy3EVmfeKS-PNgVw=w1200-h630-n-nu"
  },
  {
    "title": "GenCast predicts weather and the risks of extreme conditions with state-of-the-art accuracy",
    "description": "New AI model advances the prediction of weather uncertainties and risks, delivering faster, more accurate forecasts up to 15 days ahead",
    "summary": "New AI model advances the prediction of weather uncertainties and risks, delivering faster, more accurate forecasts up to 15 days ahead",
    "pubDate": "Wed, 04 Dec 2024 15:59:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/",
    "thumbnail": "https://lh3.googleusercontent.com/4u3n6FBe0eE86yXgppDN_yj_AkiCF5FaSToa8f3Mh5bFWzIH01ewGN737emoYKcGXLxQagYFMxi9j-cAZyAzkdFndCDg2ne9E42w4YZD7HyBChaf=w1200-h630-n-nu"
  },
  {
    "title": "Introducing the OpenAI Academy",
    "description": "New initiative will fuel innovation by investing in developers and organizations leveraging AI, starting in low- and middle-income countries.",
    "summary": "New initiative will fuel innovation by investing in developers and organizations leveraging AI, starting in low- and middle-income countries.",
    "pubDate": "Mon, 23 Sep 2024 03:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "API Partnership with Stack Overflow",
    "description": "API Partnership with Stack Overflow Stack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world‚Äôs leading knowledge platform for highly technical content with the world‚Äôs most popular LLM models for AI development.",
    "summary": "API Partnership with Stack Overflow Stack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world‚Äôs leading knowledge platform for highly technical content with the world‚Äôs most popular LLM models for AI development.",
    "pubDate": "Mon, 06 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-partnership-with-stack-overflow",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Tiny Agents in Python: a MCP-powered agent in ~70 lines of code",
    "description": "",
    "summary": "Tiny Agents in Python: an MCP-powered agent in ~70 lines of code Inspired by Tiny Agents in JS, we p...",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/python-tiny-agents",
    "thumbnail": "https://huggingface.co/blog/assets/python-tiny-agents/thumbnail.png"
  },
  {
    "title": "Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Disaster Tweets Analysis with Lora",
    "description": "",
    "summary": "Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Disaster Tweet...",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/Lora-for-sequence-classification-with-Roberta-Llama-Mistral",
    "thumbnail": "https://huggingface.co/blog/assets/Lora-for-sequence-classification-with-Roberta-Llama-Mistral/Thumbnail.png"
  },
  {
    "title": "Capacity Planning and Scheduling for Jobs with Uncertainty in Resource Usage and Duration",
    "description": "arXiv:2507.01225v1 Announce Type: cross Abstract: Organizations around the world schedule jobs (programs) regularly to perform various tasks dictated by their end users. With the major movement towards using a cloud computing infrastructure, our organization follows a hybrid approach with both cloud and on-prem servers. The objective of this work is to perform capacity planning, i.e., estimate resource requirements, and job scheduling for on-prem grid computing environments. A key contribution of our approach is handling uncertainty in both resource usage and duration of the jobs, a critical aspect in the finance industry where stochastic market conditions significantly influence job characteristics. For capacity planning and scheduling, we simultaneously balance two conflicting objectives: (a) minimize resource usage, and (b) provide high quality-of-service to the end users by completing jobs by their requested deadlines. We propose approximate approaches using deterministic estimators and pair sampling-based constraint programming. Our best approach (pair sampling-based) achieves much lower peak resource usage compared to manual scheduling without compromising on the quality-of-service.",
    "summary": "arXiv:2507.01225v1 Announce Type: cross Abstract: Organizations around the world schedule jobs (programs) regularly to perform various tasks dictated by their end users. With the major movement towards using a cloud computing infrastructure, our organization follows a hybrid approach with both cloud and on-prem servers. The objective of this work is to perform capacity planning, i.e., estimate resource requirements, and job scheduling for on-prem grid computing environments. A key contribution of our approach is handling uncertainty in both resource usage and duration of the jobs, a critical aspect in the finance industry where stochastic market conditions significantly influence job characteristics. For capacity planning and scheduling, we simultaneously balance two conflicting objectives: (a) minimize resource usage, and (b) provide high quality-of-service to the end users by completing jobs by their requested deadlines. We propose approximate approaches using deterministic estimators and pair sampling-based constraint programming. Our best approach (pair sampling-based) achieves much lower peak resource usage compared to manual scheduling without compromising on the quality-of-service.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01225",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Zero-shot image segmentation with CLIPSeg",
    "description": "",
    "summary": "Zero-shot image segmentation with CLIPSeg This guide shows how you can use CLIPSeg, a zero-shot imag...",
    "pubDate": "Wed, 21 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/clipseg-zero-shot",
    "thumbnail": "https://huggingface.co/blog/assets/123_clipseg-zero-shot/thumb.png"
  },
  {
    "title": "Llama can now see and run on your device - welcome Llama 3.2",
    "description": "",
    "summary": "Llama can now see and run on your device - welcome Llama 3.2 Llama 3.2 is out! Today, we welcome the...",
    "pubDate": "Wed, 25 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama32",
    "thumbnail": "https://huggingface.co/blog/assets/llama32/thumbnail.jpg"
  },
  {
    "title": "Early methods for studying affective use and emotional well-being on ChatGPT",
    "description": "An OpenAI and MIT Media Lab Research collaboration.",
    "summary": "An OpenAI and MIT Media Lab Research collaboration.",
    "pubDate": "Fri, 21 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/affective-use-study",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Zero-shot image-to-text generation with BLIP-2",
    "description": "",
    "summary": "Zero-shot image-to-text generation with BLIP-2 This guide introduces BLIP-2 from Salesforce Research...",
    "pubDate": "Wed, 15 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/blip-2",
    "thumbnail": "https://huggingface.co/blog/assets/blip-2/thumbnail.png"
  },
  {
    "title": "OpenAI Gym Beta",
    "description": "We‚Äôre releasing the public beta of OpenAI Gym, a toolkit for developing and comparing reinforcement learning (RL) algorithms. It consists of a growing suite of environments (from simulated robots to Atari games), and a site for comparing and reproducing results.",
    "summary": "We‚Äôre releasing the public beta of OpenAI Gym, a toolkit for developing and comparing reinforcement learning (RL) algorithms. It consists of a growing suite of environments (from simulated robots to Atari games), and a site for comparing and reproducing results.",
    "pubDate": "Wed, 27 Apr 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-gym-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerate BERT inference with Hugging Face Transformers and AWS inferentia",
    "description": "",
    "summary": "Accelerate BERT inference with Hugging Face Transformers and AWS Inferentia notebook: sagemaker/18_i...",
    "pubDate": "Wed, 16 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-inferentia-sagemaker",
    "thumbnail": "https://huggingface.co/blog//assets/55_bert_inferentia_sagemaker/thumbnail.png"
  },
  {
    "title": "Preserving languages for the future",
    "description": "How Iceland is using GPT-4 to preserve its language.",
    "summary": "How Iceland is using GPT-4 to preserve its language.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/government-of-iceland",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy Livebook notebooks as apps to Hugging Face Spaces",
    "description": "",
    "summary": "Deploy Livebook notebooks as apps to Hugging Face Spaces The Elixir community has been making great ...",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/livebook-app-deployment",
    "thumbnail": "https://huggingface.co/blog/assets/120_elixir-bumblebee/thumbnail.png"
  },
  {
    "title": "Frontier Model Forum",
    "description": "We‚Äôre forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
    "summary": "We‚Äôre forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
    "pubDate": "Wed, 26 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-model-forum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Merging AI and underwater photography to reveal hidden ocean worlds",
    "description": "The LOBSTgER research initiative at MIT Sea Grant explores how generative AI can expand scientific storytelling by building on field-based photographic data.",
    "summary": "The LOBSTgER research initiative at MIT Sea Grant explores how generative AI can expand scientific storytelling by building on field-based photographic data.",
    "pubDate": "Wed, 25 Jun 2025 09:55:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/lobstger-merging-ai-underwater-photography-to-reveal-hidden-ocean-worlds-0625",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-LOBSTgER.jpg"
  },
  {
    "title": "2D Asset Generation: AI for Game Development #4",
    "description": "",
    "summary": "2D Asset Generation: AI for Game Development #4 Welcome to AI for Game Development! In this series, ...",
    "pubDate": "Thu, 26 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-4",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail4.png"
  },
  {
    "title": "Positioning AI Tools to Support Online Harm Reduction Practice: Applications and Design Directions",
    "description": "arXiv:2506.22941v2 Announce Type: replace-cross Abstract: Access to accurate and actionable harm reduction information can directly impact the health outcomes of People Who Use Drugs (PWUD), yet existing online channels often fail to meet their diverse and dynamic needs due to limitations in adaptability, accessibility, and the pervasive impact of stigma. Large Language Models (LLMs) present a novel opportunity to enhance information provision, but their application in such a high-stakes domain is under-explored and presents socio-technical challenges. This paper investigates how LLMs can be responsibly designed to support the information needs of PWUD. Through a qualitative workshop involving diverse stakeholder groups (academics, harm reduction practitioners, and an online community moderator), we explored LLM capabilities, identified potential use cases, and delineated core design considerations. Our findings reveal that while LLMs can address some existing information barriers (e.g., by offering responsive, multilingual, and potentially less stigmatising interactions), their effectiveness is contingent upon overcoming challenges related to ethical alignment with harm reduction principles, nuanced contextual understanding, effective communication, and clearly defined operational boundaries. We articulate design pathways emphasising collaborative co-design with experts and PWUD to develop LLM systems that are helpful, safe, and responsibly governed. This work contributes empirically grounded insights and actionable design considerations for the responsible development of LLMs as supportive tools within the harm reduction ecosystem.",
    "summary": "arXiv:2506.22941v2 Announce Type: replace-cross Abstract: Access to accurate and actionable harm reduction information can directly impact the health outcomes of People Who Use Drugs (PWUD), yet existing online channels often fail to meet their diverse and dynamic needs due to limitations in adaptability, accessibility, and the pervasive impact of stigma. Large Language Models (LLMs) present a novel opportunity to enhance information provision, but their application in such a high-stakes domain is under-explored and presents socio-technical challenges. This paper investigates how LLMs can be responsibly designed to support the information needs of PWUD. Through a qualitative workshop involving diverse stakeholder groups (academics, harm reduction practitioners, and an online community moderator), we explored LLM capabilities, identified potential use cases, and delineated core design considerations. Our findings reveal that while LLMs can address some existing information barriers (e.g., by offering responsive, multilingual, and potentially less stigmatising interactions), their effectiveness is contingent upon overcoming challenges related to ethical alignment with harm reduction principles, nuanced contextual understanding, effective communication, and clearly defined operational boundaries. We articulate design pathways emphasising collaborative co-design with experts and PWUD to develop LLM systems that are helpful, safe, and responsibly governed. This work contributes empirically grounded insights and actionable design considerations for the responsible development of LLMs as supportive tools within the harm reduction ecosystem.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22941",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Decoding genetics with OpenAI o1",
    "description": "Geneticist Catherine Brownstein demonstrates how OpenAI o1 can speed up the process of diagnosing rare medical challenges.",
    "summary": "Geneticist Catherine Brownstein demonstrates how OpenAI o1 can speed up the process of diagnosing rare medical challenges.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-genetics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Superalignment Fast Grants",
    "description": "We‚Äôre launching $10M in grants to support technical research towards the alignment and safety of superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.",
    "summary": "We‚Äôre launching $10M in grants to support technical research towards the alignment and safety of superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/superalignment-fast-grants",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MIT and Mass General Brigham launch joint seed program to accelerate innovations in health",
    "description": "The MIT-MGB Seed Program, launched with support from Analog Devices Inc., will fund joint research projects that advance technology and clinical research.",
    "summary": "The MIT-MGB Seed Program, launched with support from Analog Devices Inc., will fund joint research projects that advance technology and clinical research.",
    "pubDate": "Fri, 27 Jun 2025 13:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-mass-general-brigham-launch-seed-program-innovations-health-0627",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-mgb-seed-program.jpg"
  },
  {
    "title": "Improving Hugging Face Model Access for Kaggle Users",
    "description": "",
    "summary": "Improving Hugging Face Model Access for Kaggle Users Kaggle and Hugging Face users are part of one A...",
    "pubDate": "Wed, 14 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kaggle-integration",
    "thumbnail": "https://huggingface.co/blog/assets/kaggle-integration/thumbnail.png"
  },
  {
    "title": "Microsoft and Hugging Face expand collaboration",
    "description": "",
    "summary": "Microsoft and Hugging Face expand collaboration to make open models easy to use on Azure Today at th...",
    "pubDate": "Mon, 19 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/azure-ai-foundry",
    "thumbnail": "https://huggingface.co/blog/assets/azure-ai-foundry/satya-hf-build-compressed.png"
  },
  {
    "title": "LoRA Fine-Tuning Without GPUs: A CPU-Efficient Meta-Generation Framework for LLMs",
    "description": "arXiv:2507.01806v1 Announce Type: cross Abstract: Low-Rank Adapters (LoRAs) have transformed the fine-tuning of Large Language Models (LLMs) by enabling parameter-efficient updates. However, their widespread adoption remains limited by the reliance on GPU-based training. In this work, we propose a theoretically grounded approach to LoRA fine-tuning designed specifically for users with limited computational resources, particularly those restricted to standard laptop CPUs. Our method learns a meta-operator that maps any input dataset, represented as a probability distribution, to a set of LoRA weights by leveraging a large bank of pre-trained adapters for the Mistral-7B-Instruct-v0.2 model. Instead of performing new gradient-based updates, our pipeline constructs adapters via lightweight combinations of existing LoRAs directly on CPU. While the resulting adapters do not match the performance of GPU-trained counterparts, they consistently outperform the base Mistral model on downstream tasks, offering a practical and accessible alternative to traditional GPU-based fine-tuning.",
    "summary": "arXiv:2507.01806v1 Announce Type: cross Abstract: Low-Rank Adapters (LoRAs) have transformed the fine-tuning of Large Language Models (LLMs) by enabling parameter-efficient updates. However, their widespread adoption remains limited by the reliance on GPU-based training. In this work, we propose a theoretically grounded approach to LoRA fine-tuning designed specifically for users with limited computational resources, particularly those restricted to standard laptop CPUs. Our method learns a meta-operator that maps any input dataset, represented as a probability distribution, to a set of LoRA weights by leveraging a large bank of pre-trained adapters for the Mistral-7B-Instruct-v0.2 model. Instead of performing new gradient-based updates, our pipeline constructs adapters via lightweight combinations of existing LoRAs directly on CPU. While the resulting adapters do not match the performance of GPU-trained counterparts, they consistently outperform the base Mistral model on downstream tasks, offering a practical and accessible alternative to traditional GPU-based fine-tuning.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01806",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "One-shot imitation learning",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 21 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/one-shot-imitation-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CodeGemma - an official Google release for code LLMs",
    "description": "",
    "summary": "CodeGemma - an official Google release for code LLMs CodeGemma is a family of open-access versions o...",
    "pubDate": "Tue, 09 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codegemma",
    "thumbnail": "https://huggingface.co/blog/assets/codegemma/thumbnail_b.png"
  },
  {
    "title": "Survivability of Backdoor Attacks on Unconstrained Face Recognition Systems",
    "description": "arXiv:2507.01607v1 Announce Type: cross Abstract: The widespread use of deep learning face recognition raises several security concerns. Although prior works point at existing vulnerabilities, DNN backdoor attacks against real-life, unconstrained systems dealing with images captured in the wild remain a blind spot of the literature. This paper conducts the first system-level study of backdoors in deep learning-based face recognition systems. This paper yields four contributions by exploring the feasibility of DNN backdoors on these pipelines in a holistic fashion. We demonstrate for the first time two backdoor attacks on the face detection task: face generation and face landmark shift attacks. We then show that face feature extractors trained with large margin losses also fall victim to backdoor attacks. Combining our models, we then show using 20 possible pipeline configurations and 15 attack cases that a single backdoor enables an attacker to bypass the entire function of a system. Finally, we provide stakeholders with several best practices and countermeasures.",
    "summary": "arXiv:2507.01607v1 Announce Type: cross Abstract: The widespread use of deep learning face recognition raises several security concerns. Although prior works point at existing vulnerabilities, DNN backdoor attacks against real-life, unconstrained systems dealing with images captured in the wild remain a blind spot of the literature. This paper conducts the first system-level study of backdoors in deep learning-based face recognition systems. This paper yields four contributions by exploring the feasibility of DNN backdoors on these pipelines in a holistic fashion. We demonstrate for the first time two backdoor attacks on the face detection task: face generation and face landmark shift attacks. We then show that face feature extractors trained with large margin losses also fall victim to backdoor attacks. Combining our models, we then show using 20 possible pipeline configurations and 15 attack cases that a single backdoor enables an attacker to bypass the entire function of a system. Finally, we provide stakeholders with several best practices and countermeasures.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01607",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome to Inference Providers on the Hub üî•",
    "description": "",
    "summary": "Welcome to Inference Providers on the Hub üî• Today, we are launching the integration of four awesome ...",
    "pubDate": "Tue, 28 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/thumbnail.png"
  },
  {
    "title": "Are Vision Transformer Representations Semantically Meaningful? A Case Study in Medical Imaging",
    "description": "arXiv:2507.01788v1 Announce Type: cross Abstract: Vision transformers (ViTs) have rapidly gained prominence in medical imaging tasks such as disease classification, segmentation, and detection due to their superior accuracy compared to conventional deep learning models. However, due to their size and complex interactions via the self-attention mechanism, they are not well understood. In particular, it is unclear whether the representations produced by such models are semantically meaningful. In this paper, using a projected gradient-based algorithm, we show that their representations are not semantically meaningful and they are inherently vulnerable to small changes. Images with imperceptible differences can have very different representations; on the other hand, images that should belong to different semantic classes can have nearly identical representations. Such vulnerability can lead to unreliable classification results; for example, unnoticeable changes cause the classification accuracy to be reduced by over 60%. %. To the best of our knowledge, this is the first work to systematically demonstrate this fundamental lack of semantic meaningfulness in ViT representations for medical image classification, revealing a critical challenge for their deployment in safety-critical systems.",
    "summary": "arXiv:2507.01788v1 Announce Type: cross Abstract: Vision transformers (ViTs) have rapidly gained prominence in medical imaging tasks such as disease classification, segmentation, and detection due to their superior accuracy compared to conventional deep learning models. However, due to their size and complex interactions via the self-attention mechanism, they are not well understood. In particular, it is unclear whether the representations produced by such models are semantically meaningful. In this paper, using a projected gradient-based algorithm, we show that their representations are not semantically meaningful and they are inherently vulnerable to small changes. Images with imperceptible differences can have very different representations; on the other hand, images that should belong to different semantic classes can have nearly identical representations. Such vulnerability can lead to unreliable classification results; for example, unnoticeable changes cause the classification accuracy to be reduced by over 60%. %. To the best of our knowledge, this is the first work to systematically demonstrate this fundamental lack of semantic meaningfulness in ViT representations for medical image classification, revealing a critical challenge for their deployment in safety-critical systems.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01788",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "March 20 ChatGPT outage: Here‚Äôs what happened",
    "description": "An update on our findings, the actions we‚Äôve taken, and technical details of the bug.",
    "summary": "An update on our findings, the actions we‚Äôve taken, and technical details of the bug.",
    "pubDate": "Fri, 24 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/march-20-chatgpt-outage",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Framework for Mining Collectively-Behaving Bots in MMORPGs",
    "description": "arXiv:2501.10461v2 Announce Type: replace-cross Abstract: In MMORPGs (Massively Multiplayer Online Role-Playing Games), abnormal players (bots) using unauthorized automated programs to carry out pre-defined behaviors systematically and repeatedly are commonly observed. Bots usually engage in these activities to gain in-game money, which they eventually trade for real money outside the game. Such abusive activities negatively impact the in-game experiences of legitimate users since bots monopolize specific hunting areas and obtain valuable items. Thus, detecting abnormal players is a significant task for game companies. Motivated by the fact that bots tend to behave collectively with similar in-game trajectories due to the auto-programs, we developed BotTRep, a framework that comprises trajectory representation learning followed by clustering using a completely unlabeled in-game trajectory dataset. Our model aims to learn representations for in-game trajectory sequences so that players with contextually similar trajectories have closer embeddings. Then, by applying DBSCAN to these representations and visualizing the corresponding moving patterns, our framework ultimately assists game masters in identifying and banning bots.",
    "summary": "arXiv:2501.10461v2 Announce Type: replace-cross Abstract: In MMORPGs (Massively Multiplayer Online Role-Playing Games), abnormal players (bots) using unauthorized automated programs to carry out pre-defined behaviors systematically and repeatedly are commonly observed. Bots usually engage in these activities to gain in-game money, which they eventually trade for real money outside the game. Such abusive activities negatively impact the in-game experiences of legitimate users since bots monopolize specific hunting areas and obtain valuable items. Thus, detecting abnormal players is a significant task for game companies. Motivated by the fact that bots tend to behave collectively with similar in-game trajectories due to the auto-programs, we developed BotTRep, a framework that comprises trajectory representation learning followed by clustering using a completely unlabeled in-game trajectory dataset. Our model aims to learn representations for in-game trajectory sequences so that players with contextually similar trajectories have closer embeddings. Then, by applying DBSCAN to these representations and visualizing the corresponding moving patterns, our framework ultimately assists game masters in identifying and banning bots.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.10461",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From cloud to developers: Hugging Face and Microsoft Deepen Collaboration",
    "description": "",
    "summary": "From cloud to developers: Hugging Face and Microsoft Deepen Collaboration Today at Microsoft Build w...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/microsoft-collaboration",
    "thumbnail": "https://huggingface.co/blog/assets/microsoft-collaboration/thumbnail.jpg"
  },
  {
    "title": "Learning to cooperate, compete, and communicate",
    "description": "Multiagent environments where agents compete for resources are stepping stones on the path to AGI. Multiagent environments have two useful properties: first, there is a natural curriculum‚Äîthe difficulty of the environment is determined by the skill of your competitors (and if you‚Äôre competing against clones of yourself, the environment exactly matches your skill level). Second, a multiagent environment has no stable equilibrium: no matter how smart an agent is, there‚Äôs always pressure to get smarter. These environments have a very different feel from traditional environments, and it‚Äôll take a lot more research before we become good at them.",
    "summary": "Multiagent environments where agents compete for resources are stepping stones on the path to AGI. Multiagent environments have two useful properties: first, there is a natural curriculum‚Äîthe difficulty of the environment is determined by the skill of your competitors (and if you‚Äôre competing against clones of yourself, the environment exactly matches your skill level). Second, a multiagent environment has no stable equilibrium: no matter how smart an agent is, there‚Äôs always pressure to get smarter. These environments have a very different feel from traditional environments, and it‚Äôll take a lot more research before we become good at them.",
    "pubDate": "Thu, 08 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-cooperate-compete-and-communicate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the SQL Console on Datasets",
    "description": "",
    "summary": "Introducing the SQL Console on Datasets Datasets use has been exploding and Hugging Face has become ...",
    "pubDate": "Tue, 17 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sql-console",
    "thumbnail": "https://huggingface.co/blog/assets/sql_console/thumbnail.png"
  },
  {
    "title": "Accelerate StarCoder with ü§ó Optimum Intel on Xeon: Q8/Q4 and Speculative Decoding",
    "description": "",
    "summary": "Accelerate StarCoder with ü§ó Optimum Intel on Xeon: Q8/Q4 and Speculative Decoding Introduction Recen...",
    "pubDate": "Tue, 30 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-starcoder-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Comparing Optimization Algorithms Through the Lens of Search Behavior Analysis",
    "description": "arXiv:2507.01668v1 Announce Type: cross Abstract: The field of numerical optimization has recently seen a surge in the development of 'novel' metaheuristic algorithms, inspired by metaphors derived from natural or human-made processes, which have been widely criticized for obscuring meaningful innovations and failing to distinguish themselves from existing approaches. Aiming to address these concerns, we investigate the applicability of statistical tests for comparing algorithms based on their search behavior. We utilize the cross-match statistical test to compare multivariate distributions and assess the solutions produced by 114 algorithms from the MEALPY library. These findings are incorporated into an empirical analysis aiming to identify algorithms with similar search behaviors.",
    "summary": "arXiv:2507.01668v1 Announce Type: cross Abstract: The field of numerical optimization has recently seen a surge in the development of 'novel' metaheuristic algorithms, inspired by metaphors derived from natural or human-made processes, which have been widely criticized for obscuring meaningful innovations and failing to distinguish themselves from existing approaches. Aiming to address these concerns, we investigate the applicability of statistical tests for comparing algorithms based on their search behavior. We utilize the cross-match statistical test to compare multivariate distributions and assess the solutions produced by 114 algorithms from the MEALPY library. These findings are incorporated into an empirical analysis aiming to identify algorithms with similar search behaviors.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01668",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sentence Transformers in the ü§ó Hub",
    "description": "",
    "summary": "Sentence Transformers in the Hugging Face Hub Over the past few weeks, we've built collaborations wi...",
    "pubDate": "Mon, 28 Jun 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentence-transformers-in-the-hub",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "MedAgent-Pro: Towards Evidence-based Multi-modal Medical Diagnosis via Reasoning Agentic Workflow",
    "description": "arXiv:2503.18968v3 Announce Type: replace Abstract: In modern medicine, clinical diagnosis relies on the comprehensive analysis of primarily textual and visual data, drawing on medical expertise to ensure systematic and rigorous reasoning. Recent advances in large Vision-Language Models (VLMs) and agent-based methods hold great potential for medical diagnosis, thanks to the ability to effectively integrate multi-modal patient data. However, they often provide direct answers and draw empirical-driven conclusions without quantitative analysis, which reduces their reliability and clinical usability. We propose MedAgent-Pro, a new agentic reasoning paradigm that follows the diagnosis principle in modern medicine, to decouple the process into sequential components for step-by-step, evidence-based reasoning. Our MedAgent-Pro workflow presents a hierarchical diagnostic structure to mirror this principle, consisting of disease-level standardized plan generation and patient-level personalized step-by-step reasoning. To support disease-level planning, an RAG-based agent is designed to retrieve medical guidelines to ensure alignment with clinical standards. For patient-level reasoning, we propose to integrate professional tools such as visual models to enable quantitative assessments. Meanwhile, we propose to verify the reliability of each step to achieve evidence-based diagnosis, enforcing rigorous logical reasoning and a well-founded conclusion. Extensive experiments across a wide range of anatomical regions, imaging modalities, and diseases demonstrate the superiority of MedAgent-Pro to mainstream VLMs, agentic systems and state-of-the-art expert models. Ablation studies and human evaluation by clinical experts further validate its robustness and clinical relevance. Code is available at https://github.com/jinlab-imvr/MedAgent-Pro.",
    "summary": "arXiv:2503.18968v3 Announce Type: replace Abstract: In modern medicine, clinical diagnosis relies on the comprehensive analysis of primarily textual and visual data, drawing on medical expertise to ensure systematic and rigorous reasoning. Recent advances in large Vision-Language Models (VLMs) and agent-based methods hold great potential for medical diagnosis, thanks to the ability to effectively integrate multi-modal patient data. However, they often provide direct answers and draw empirical-driven conclusions without quantitative analysis, which reduces their reliability and clinical usability. We propose MedAgent-Pro, a new agentic reasoning paradigm that follows the diagnosis principle in modern medicine, to decouple the process into sequential components for step-by-step, evidence-based reasoning. Our MedAgent-Pro workflow presents a hierarchical diagnostic structure to mirror this principle, consisting of disease-level standardized plan generation and patient-level personalized step-by-step reasoning. To support disease-level planning, an RAG-based agent is designed to retrieve medical guidelines to ensure alignment with clinical standards. For patient-level reasoning, we propose to integrate professional tools such as visual models to enable quantitative assessments. Meanwhile, we propose to verify the reliability of each step to achieve evidence-based diagnosis, enforcing rigorous logical reasoning and a well-founded conclusion. Extensive experiments across a wide range of anatomical regions, imaging modalities, and diseases demonstrate the superiority of MedAgent-Pro to mainstream VLMs, agentic systems and state-of-the-art expert models. Ablation studies and human evaluation by clinical experts further validate its robustness and clinical relevance. Code is available at https://github.com/jinlab-imvr/MedAgent-Pro.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.18968",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerating the development of life-saving treatments",
    "description": "Accelerating the development of life-saving treatments.",
    "summary": "Accelerating the development of life-saving treatments.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/moderna",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Automated Vehicles Should be Connected with Natural Language",
    "description": "arXiv:2507.01059v1 Announce Type: cross Abstract: Multi-agent collaborative driving promises improvements in traffic safety and efficiency through collective perception and decision making. However, existing communication media -- including raw sensor data, neural network features, and perception results -- suffer limitations in bandwidth efficiency, information completeness, and agent interoperability. Moreover, traditional approaches have largely ignored decision-level fusion, neglecting critical dimensions of collaborative driving. In this paper we argue that addressing these challenges requires a transition from purely perception-oriented data exchanges to explicit intent and reasoning communication using natural language. Natural language balances semantic density and communication bandwidth, adapts flexibly to real-time conditions, and bridges heterogeneous agent platforms. By enabling the direct communication of intentions, rationales, and decisions, it transforms collaborative driving from reactive perception-data sharing into proactive coordination, advancing safety, efficiency, and transparency in intelligent transportation systems.",
    "summary": "arXiv:2507.01059v1 Announce Type: cross Abstract: Multi-agent collaborative driving promises improvements in traffic safety and efficiency through collective perception and decision making. However, existing communication media -- including raw sensor data, neural network features, and perception results -- suffer limitations in bandwidth efficiency, information completeness, and agent interoperability. Moreover, traditional approaches have largely ignored decision-level fusion, neglecting critical dimensions of collaborative driving. In this paper we argue that addressing these challenges requires a transition from purely perception-oriented data exchanges to explicit intent and reasoning communication using natural language. Natural language balances semantic density and communication bandwidth, adapts flexibly to real-time conditions, and bridges heterogeneous agent platforms. By enabling the direct communication of intentions, rationales, and decisions, it transforms collaborative driving from reactive perception-data sharing into proactive coordination, advancing safety, efficiency, and transparency in intelligent transportation systems.",
    "pubDate": "Thu, 03 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2507.01059",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  }
]