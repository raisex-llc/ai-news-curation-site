[
  {
    "title": "A faster way to solve complex planning problems",
    "description": "By eliminating redundant computations, a new data-driven method can streamline processes like scheduling trains, routing delivery drivers, or assigning airline crews.",
    "summary": "By eliminating redundant computations, a new data-driven method can streamline processes like scheduling trains, routing delivery drivers, or assigning airline crews.",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/faster-way-solve-complex-planning-problems-0416",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Long-Horizon-01.jpg"
  },
  {
    "title": "Privacy-aware IoT Fall Detection Services For Aging in Place",
    "description": "arXiv:2506.22462v1 Announce Type: cross Abstract: Fall detection is critical to support the growing elderly population, projected to reach 2.1 billion by 2050. However, existing methods often face data scarcity challenges or compromise privacy. We propose a novel IoT-based Fall Detection as a Service (FDaaS) framework to assist the elderly in living independently and safely by accurately detecting falls. We design a service-oriented architecture that leverages Ultra-wideband (UWB) radar sensors as an IoT health-sensing service, ensuring privacy and minimal intrusion. We address the challenges of data scarcity by utilizing a Fall Detection Generative Pre-trained Transformer (FD-GPT) that uses augmentation techniques. We developed a protocol to collect a comprehensive dataset of the elderly daily activities and fall events. This resulted in a real dataset that carefully mimics the elderly's routine. We rigorously evaluate and compare various models using this dataset. Experimental results show our approach achieves 90.72% accuracy and 89.33% precision in distinguishing between fall events and regular activities of daily living.",
    "summary": "arXiv:2506.22462v1 Announce Type: cross Abstract: Fall detection is critical to support the growing elderly population, projected to reach 2.1 billion by 2050. However, existing methods often face data scarcity challenges or compromise privacy. We propose a novel IoT-based Fall Detection as a Service (FDaaS) framework to assist the elderly in living independently and safely by accurately detecting falls. We design a service-oriented architecture that leverages Ultra-wideband (UWB) radar sensors as an IoT health-sensing service, ensuring privacy and minimal intrusion. We address the challenges of data scarcity by utilizing a Fall Detection Generative Pre-trained Transformer (FD-GPT) that uses augmentation techniques. We developed a protocol to collect a comprehensive dataset of the elderly daily activities and fall events. This resulted in a real dataset that carefully mimics the elderly's routine. We rigorously evaluate and compare various models using this dataset. Experimental results show our approach achieves 90.72% accuracy and 89.33% precision in distinguishing between fall events and regular activities of daily living.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22462",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Building networks of data science talent",
    "description": "Through collaborations with organizations like BREIT in Peru, the MIT Institute for Data, Systems, and Society is upskilling hundreds of learners around the world in data science and machine learning.",
    "summary": "Through collaborations with organizations like BREIT in Peru, the MIT Institute for Data, Systems, and Society is upskilling hundreds of learners around the world in data science and machine learning.",
    "pubDate": "Tue, 27 May 2025 16:11:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/building-networks-data-science-talent-0527",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-breit-idss-killian.jpg"
  },
  {
    "title": "üêØ Liger GRPO meets TRL",
    "description": "",
    "summary": "üêØ Liger GRPO meets TRL TL; DR Liger supercharges TRL‚Äôs Group Relative Policy Optimization GRPO Train...",
    "pubDate": "Sun, 25 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/liger-grpo",
    "thumbnail": "https://huggingface.co/blog/assets/liger-grpo/thumbnail.png"
  },
  {
    "title": "Groq on Hugging Face Inference Providers üî•",
    "description": "",
    "summary": "Groq on Hugging Face Inference Providers üî• We're thrilled to share that Groq is now a supported Infe...",
    "pubDate": "Mon, 16 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-groq",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-groq.jpg"
  },
  {
    "title": "Interactively explore your Huggingface dataset with one line of code",
    "description": "",
    "summary": "Interactively explore your Huggingface dataset with one line of code The Hugging Face datasets libra...",
    "pubDate": "Wed, 25 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/scalable-data-inspection",
    "thumbnail": "https://huggingface.co/blog/assets/scalable-data-inspection/thumbnail.png"
  },
  {
    "title": "CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation",
    "description": "arXiv:2506.23121v1 Announce Type: cross Abstract: Multi-organ medical segmentation is a crucial component of medical image processing, essential for doctors to make accurate diagnoses and develop effective treatment plans. Despite significant progress in this field, current multi-organ segmentation models often suffer from inaccurate details, dependence on geometric prompts and loss of spatial information. Addressing these challenges, we introduce a novel model named CRISP-SAM2 with CRoss-modal Interaction and Semantic Prompting based on SAM2. This model represents a promising approach to multi-organ medical segmentation guided by textual descriptions of organs. Our method begins by converting visual and textual inputs into cross-modal contextualized semantics using a progressive cross-attention interaction mechanism. These semantics are then injected into the image encoder to enhance the detailed understanding of visual information. To eliminate reliance on geometric prompts, we use a semantic prompting strategy, replacing the original prompt encoder to sharpen the perception of challenging targets. In addition, a similarity-sorting self-updating strategy for memory and a mask-refining process is applied to further adapt to medical imaging and enhance localized details. Comparative experiments conducted on seven public datasets indicate that CRISP-SAM2 outperforms existing models. Extensive analysis also demonstrates the effectiveness of our method, thereby confirming its superior performance, especially in addressing the limitations mentioned earlier. Our code is available at: https://github.com/YU-deep/CRISP_SAM2.git.",
    "summary": "arXiv:2506.23121v1 Announce Type: cross Abstract: Multi-organ medical segmentation is a crucial component of medical image processing, essential for doctors to make accurate diagnoses and develop effective treatment plans. Despite significant progress in this field, current multi-organ segmentation models often suffer from inaccurate details, dependence on geometric prompts and loss of spatial information. Addressing these challenges, we introduce a novel model named CRISP-SAM2 with CRoss-modal Interaction and Semantic Prompting based on SAM2. This model represents a promising approach to multi-organ medical segmentation guided by textual descriptions of organs. Our method begins by converting visual and textual inputs into cross-modal contextualized semantics using a progressive cross-attention interaction mechanism. These semantics are then injected into the image encoder to enhance the detailed understanding of visual information. To eliminate reliance on geometric prompts, we use a semantic prompting strategy, replacing the original prompt encoder to sharpen the perception of challenging targets. In addition, a similarity-sorting self-updating strategy for memory and a mask-refining process is applied to further adapt to medical imaging and enhance localized details. Comparative experiments conducted on seven public datasets indicate that CRISP-SAM2 outperforms existing models. Extensive analysis also demonstrates the effectiveness of our method, thereby confirming its superior performance, especially in addressing the limitations mentioned earlier. Our code is available at: https://github.com/YU-deep/CRISP_SAM2.git.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23121",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Disrupting Model Merging: A Parameter-Level Defense Without Sacrificing Accuracy",
    "description": "arXiv:2503.07661v2 Announce Type: replace-cross Abstract: Model merging is a technique that combines multiple finetuned models into a single model without additional training, allowing a free-rider to cheaply inherit specialized capabilities. This study investigates methodologies to suppress unwanted model merging by free-riders. Existing methods such as model watermarking or fingerprinting can only detect merging in hindsight. In contrast, we propose a first proactive defense against model merging. Specifically, our defense method modifies the model parameters so that the model is disrupted if the model is merged with any other model, while its functionality is kept unchanged if not merged with others. Our approach consists of two modules, rearranging MLP parameters and scaling attention heads, which push the model out of the shared basin in parameter space, causing the merging performance with other models to degrade significantly. We conduct extensive experiments on image classification, image generation, and text classification to demonstrate that our defense severely disrupts merging while retaining the functionality of the post-protect model. Moreover, we analyze potential adaptive attacks and further propose a dropout-based pruning to improve our proposal's robustness.",
    "summary": "arXiv:2503.07661v2 Announce Type: replace-cross Abstract: Model merging is a technique that combines multiple finetuned models into a single model without additional training, allowing a free-rider to cheaply inherit specialized capabilities. This study investigates methodologies to suppress unwanted model merging by free-riders. Existing methods such as model watermarking or fingerprinting can only detect merging in hindsight. In contrast, we propose a first proactive defense against model merging. Specifically, our defense method modifies the model parameters so that the model is disrupted if the model is merged with any other model, while its functionality is kept unchanged if not merged with others. Our approach consists of two modules, rearranging MLP parameters and scaling attention heads, which push the model out of the shared basin in parameter space, causing the merging performance with other models to degrade significantly. We conduct extensive experiments on image classification, image generation, and text classification to demonstrate that our defense severely disrupts merging while retaining the functionality of the post-protect model. Moreover, we analyze potential adaptive attacks and further propose a dropout-based pruning to improve our proposal's robustness.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.07661",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Stable Diffusion XL on Mac with Advanced Core ML Quantization",
    "description": "",
    "summary": "Stable Diffusion XL on Mac with Advanced Core ML Quantization Stable Diffusion XL was released yeste...",
    "pubDate": "Thu, 27 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-xl-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/stable-diffusion-xl-coreml/thumbnail.png"
  },
  {
    "title": "New tools and features in the Responses API",
    "description": "New features in the Responses API: Remote MCP, image gen, Code Interpreter, and more. Powering faster, smarter agents with GPT-4o & o-series models, plus new features for reliability and efficiency.",
    "summary": "New features in the Responses API: Remote MCP, image gen, Code Interpreter, and more. Powering faster, smarter agents with GPT-4o & o-series models, plus new features for reliability and efficiency.",
    "pubDate": "Wed, 21 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-and-features-in-the-responses-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Lessons learned on language model safety and misuse",
    "description": "We describe our latest thinking in the hope of helping other AI developers address safety and misuse of deployed¬†models.",
    "summary": "We describe our latest thinking in the hope of helping other AI developers address safety and misuse of deployed¬†models.",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-model-safety-and-misuse",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Memory and new controls for ChatGPT",
    "description": "We‚Äôre testing the ability for ChatGPT to remember things you discuss to make future chats more helpful. You‚Äôre in control of ChatGPT‚Äôs memory.",
    "summary": "We‚Äôre testing the ability for ChatGPT to remember things you discuss to make future chats more helpful. You‚Äôre in control of ChatGPT‚Äôs memory.",
    "pubDate": "Tue, 13 Feb 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/memory-and-new-controls-for-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The N Implementation Details of RLHF with PPO",
    "description": "",
    "summary": "The N Implementation Details of RLHF with PPO RLHF / ChatGPT has been a popular research topic these...",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo",
    "thumbnail": "https://huggingface.co/blog/assets/167_the_n_implementation_details_of_rlhf_with_ppo/thumbnail.png"
  },
  {
    "title": "MedEthicsQA: A Comprehensive Question Answering Benchmark for Medical Ethics Evaluation of LLMs",
    "description": "arXiv:2506.22808v1 Announce Type: cross Abstract: While Medical Large Language Models (MedLLMs) have demonstrated remarkable potential in clinical tasks, their ethical safety remains insufficiently explored. This paper introduces $textbf{MedEthicsQA}$, a comprehensive benchmark comprising $textbf{5,623}$ multiple-choice questions and $textbf{5,351}$ open-ended questions for evaluation of medical ethics in LLMs. We systematically establish a hierarchical taxonomy integrating global medical ethical standards. The benchmark encompasses widely used medical datasets, authoritative question banks, and scenarios derived from PubMed literature. Rigorous quality control involving multi-stage filtering and multi-faceted expert validation ensures the reliability of the dataset with a low error rate ($2.72%$). Evaluation of state-of-the-art MedLLMs exhibit declined performance in answering medical ethics questions compared to their foundation counterparts, elucidating the deficiencies of medical ethics alignment. The dataset, registered under CC BY-NC 4.0 license, is available at https://github.com/JianhuiWei7/MedEthicsQA.",
    "summary": "arXiv:2506.22808v1 Announce Type: cross Abstract: While Medical Large Language Models (MedLLMs) have demonstrated remarkable potential in clinical tasks, their ethical safety remains insufficiently explored. This paper introduces $textbf{MedEthicsQA}$, a comprehensive benchmark comprising $textbf{5,623}$ multiple-choice questions and $textbf{5,351}$ open-ended questions for evaluation of medical ethics in LLMs. We systematically establish a hierarchical taxonomy integrating global medical ethical standards. The benchmark encompasses widely used medical datasets, authoritative question banks, and scenarios derived from PubMed literature. Rigorous quality control involving multi-stage filtering and multi-faceted expert validation ensures the reliability of the dataset with a low error rate ($2.72%$). Evaluation of state-of-the-art MedLLMs exhibit declined performance in answering medical ethics questions compared to their foundation counterparts, elucidating the deficiencies of medical ethics alignment. The dataset, registered under CC BY-NC 4.0 license, is available at https://github.com/JianhuiWei7/MedEthicsQA.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22808",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gradio 3.0 is Out!",
    "description": "",
    "summary": "Gradio 3.0 is Out! Machine Learning Demos Machine learning demos are an increasingly vital part of r...",
    "pubDate": "Mon, 16 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-blocks",
    "thumbnail": "https://huggingface.co/blog/assets/68_gradio_blocks/block-party.png"
  },
  {
    "title": "Generating Privacy Stories From Software Documentation",
    "description": "arXiv:2506.23014v1 Announce Type: cross Abstract: Research shows that analysts and developers consider privacy as a security concept or as an afterthought, which may lead to non-compliance and violation of users' privacy. Most current approaches, however, focus on extracting legal requirements from the regulations and evaluating the compliance of software and processes with them. In this paper, we develop a novel approach based on chain-of-thought prompting (CoT), in-context-learning (ICL), and Large Language Models (LLMs) to extract privacy behaviors from various software documents prior to and during software development, and then generate privacy requirements in the format of user stories. Our results show that most commonly used LLMs, such as GPT-4o and Llama 3, can identify privacy behaviors and generate privacy user stories with F1 scores exceeding 0.8. We also show that the performance of these models could be improved through parameter-tuning. Our findings provide insight into using and optimizing LLMs for generating privacy requirements given software documents created prior to or throughout the software development lifecycle.",
    "summary": "arXiv:2506.23014v1 Announce Type: cross Abstract: Research shows that analysts and developers consider privacy as a security concept or as an afterthought, which may lead to non-compliance and violation of users' privacy. Most current approaches, however, focus on extracting legal requirements from the regulations and evaluating the compliance of software and processes with them. In this paper, we develop a novel approach based on chain-of-thought prompting (CoT), in-context-learning (ICL), and Large Language Models (LLMs) to extract privacy behaviors from various software documents prior to and during software development, and then generate privacy requirements in the format of user stories. Our results show that most commonly used LLMs, such as GPT-4o and Llama 3, can identify privacy behaviors and generate privacy user stories with F1 scores exceeding 0.8. We also show that the performance of these models could be improved through parameter-tuning. Our findings provide insight into using and optimizing LLMs for generating privacy requirements given software documents created prior to or throughout the software development lifecycle.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23014",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sample Margin-Aware Recalibration of Temperature Scaling",
    "description": "arXiv:2506.23492v1 Announce Type: cross Abstract: Recent advances in deep learning have significantly improved predictive accuracy. However, modern neural networks remain systematically overconfident, posing risks for deployment in safety-critical scenarios. Current post-hoc calibration methods face a fundamental dilemma: global approaches like Temperature Scaling apply uniform adjustments across all samples, introducing high bias despite computational efficiency, while more expressive methods that operate on full logit distributions suffer from high variance due to noisy high-dimensional inputs and insufficient validation data. To address these challenges, we propose Sample Margin-Aware Recalibration of Temperature (SMART), a lightweight, data-efficient recalibration method that precisely scales logits based on the margin between the top two logits -- termed the logit gap. Specifically, the logit gap serves as a denoised, scalar signal directly tied to decision boundary uncertainty, providing a robust indicator that avoids the noise inherent in high-dimensional logit spaces while preserving model prediction invariance. Meanwhile, SMART employs a novel soft-binned Expected Calibration Error (SoftECE) objective that balances model bias and variance through adaptive binning, enabling stable parameter updates even with extremely limited calibration data. Extensive evaluations across diverse datasets and architectures demonstrate that SMART achieves state-of-the-art calibration performance even with substantially fewer parameters compared to existing parametric methods, offering a principled, robust, and highly efficient solution for practical uncertainty quantification in neural network predictions. The source code is available at: https://anonymous.4open.science/r/SMART-8B11.",
    "summary": "arXiv:2506.23492v1 Announce Type: cross Abstract: Recent advances in deep learning have significantly improved predictive accuracy. However, modern neural networks remain systematically overconfident, posing risks for deployment in safety-critical scenarios. Current post-hoc calibration methods face a fundamental dilemma: global approaches like Temperature Scaling apply uniform adjustments across all samples, introducing high bias despite computational efficiency, while more expressive methods that operate on full logit distributions suffer from high variance due to noisy high-dimensional inputs and insufficient validation data. To address these challenges, we propose Sample Margin-Aware Recalibration of Temperature (SMART), a lightweight, data-efficient recalibration method that precisely scales logits based on the margin between the top two logits -- termed the logit gap. Specifically, the logit gap serves as a denoised, scalar signal directly tied to decision boundary uncertainty, providing a robust indicator that avoids the noise inherent in high-dimensional logit spaces while preserving model prediction invariance. Meanwhile, SMART employs a novel soft-binned Expected Calibration Error (SoftECE) objective that balances model bias and variance through adaptive binning, enabling stable parameter updates even with extremely limited calibration data. Extensive evaluations across diverse datasets and architectures demonstrate that SMART achieves state-of-the-art calibration performance even with substantially fewer parameters compared to existing parametric methods, offering a principled, robust, and highly efficient solution for practical uncertainty quantification in neural network predictions. The source code is available at: https://anonymous.4open.science/r/SMART-8B11.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23492",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Getting started with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Getting Started with Hugging Face Inference Endpoints Training machine learning models has become qu...",
    "pubDate": "Fri, 14 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/109_inference_endpoints/endpoints05.png"
  },
  {
    "title": "Helen Toner joins OpenAI‚Äôs board of directors",
    "description": "Today, we‚Äôre excited to announce the appointment of Helen Toner to our board of directors.",
    "summary": "Today, we‚Äôre excited to announce the appointment of Helen Toner to our board of directors.",
    "pubDate": "Wed, 08 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/helen-toner-joins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The 5 Most Under-Rated Tools on Hugging Face",
    "description": "",
    "summary": "The 5 Most Under-Rated Tools on Hugging Face The Hugging Face Hub boasts over 850K public models, wi...",
    "pubDate": "Thu, 22 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unsung-heroes",
    "thumbnail": "https://huggingface.co/blog/assets/unsung-heroes/new-thumbnail.png"
  },
  {
    "title": "Economics and reasoning with OpenAI o1",
    "description": "Economist Tyler Cowen explains how OpenAI o1 tackles complex economic questions.",
    "summary": "Economist Tyler Cowen explains how OpenAI o1 tackles complex economic questions.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-economics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bridging Theory and Practice in Link Representation with Graph Neural Networks",
    "description": "arXiv:2506.24018v1 Announce Type: cross Abstract: Graph Neural Networks (GNNs) are widely used to compute representations of node pairs for downstream tasks such as link prediction. Yet, theoretical understanding of their expressive power has focused almost entirely on graph-level representations. In this work, we shift the focus to links and provide the first comprehensive study of GNN expressiveness in link representation. We introduce a unifying framework, the $k_phi$-$k_rho$-$m$ framework, that subsumes existing message-passing link models and enables formal expressiveness comparisons. Using this framework, we derive a hierarchy of state-of-the-art methods and offer theoretical tools to analyze future architectures. To complement our analysis, we propose a synthetic evaluation protocol comprising the first benchmark specifically designed to assess link-level expressiveness. Finally, we ask: does expressiveness matter in practice? We use a graph symmetry metric that quantifies the difficulty of distinguishing links and show that while expressive models may underperform on standard benchmarks, they significantly outperform simpler ones as symmetry increases, highlighting the need for dataset-aware model selection.",
    "summary": "arXiv:2506.24018v1 Announce Type: cross Abstract: Graph Neural Networks (GNNs) are widely used to compute representations of node pairs for downstream tasks such as link prediction. Yet, theoretical understanding of their expressive power has focused almost entirely on graph-level representations. In this work, we shift the focus to links and provide the first comprehensive study of GNN expressiveness in link representation. We introduce a unifying framework, the $k_phi$-$k_rho$-$m$ framework, that subsumes existing message-passing link models and enables formal expressiveness comparisons. Using this framework, we derive a hierarchy of state-of-the-art methods and offer theoretical tools to analyze future architectures. To complement our analysis, we propose a synthetic evaluation protocol comprising the first benchmark specifically designed to assess link-level expressiveness. Finally, we ask: does expressiveness matter in practice? We use a graph symmetry metric that quantifies the difficulty of distinguishing links and show that while expressive models may underperform on standard benchmarks, they significantly outperform simpler ones as symmetry increases, highlighting the need for dataset-aware model selection.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.24018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SDXL in 4 steps with Latent Consistency LoRAs",
    "description": "",
    "summary": "SDXL in 4 steps with Latent Consistency LoRAs Latent Consistency Models (LCM) are a way to decrease ...",
    "pubDate": "Thu, 09 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lcm_lora",
    "thumbnail": "https://huggingface.co/blog/assets/lcm_sdxl/lcm_thumbnail.png"
  },
  {
    "title": "Towards the 'Digital Me': A vision of authentic Conversational Agents powered by personal Human Digital Twins",
    "description": "arXiv:2506.23826v1 Announce Type: cross Abstract: Human Digital Twins (HDTs) have traditionally been conceptualized as data-driven models designed to support decision-making across various domains. However, recent advancements in conversational AI open new possibilities for HDTs to function as authentic, interactive digital counterparts of individuals. This paper introduces a novel HDT system architecture that integrates large language models with dynamically updated personal data, enabling it to mirror an individual's conversational style, memories, and behaviors. To achieve this, our approach implements context-aware memory retrieval, neural plasticity-inspired consolidation, and adaptive learning mechanisms, creating a more natural and evolving digital persona. The resulting system does not only replicate an individual's unique conversational style depending on who they are speaking with, but also enriches responses with dynamically captured personal experiences, opinions, and memories. While this marks a significant step toward developing authentic virtual counterparts, it also raises critical ethical concerns regarding privacy, accountability, and the long-term implications of persistent digital identities. This study contributes to the field of HDTs by describing our novel system architecture, demonstrating its capabilities, and discussing future directions and emerging challenges to ensure the responsible and ethical development of HDTs.",
    "summary": "arXiv:2506.23826v1 Announce Type: cross Abstract: Human Digital Twins (HDTs) have traditionally been conceptualized as data-driven models designed to support decision-making across various domains. However, recent advancements in conversational AI open new possibilities for HDTs to function as authentic, interactive digital counterparts of individuals. This paper introduces a novel HDT system architecture that integrates large language models with dynamically updated personal data, enabling it to mirror an individual's conversational style, memories, and behaviors. To achieve this, our approach implements context-aware memory retrieval, neural plasticity-inspired consolidation, and adaptive learning mechanisms, creating a more natural and evolving digital persona. The resulting system does not only replicate an individual's unique conversational style depending on who they are speaking with, but also enriches responses with dynamically captured personal experiences, opinions, and memories. While this marks a significant step toward developing authentic virtual counterparts, it also raises critical ethical concerns regarding privacy, accountability, and the long-term implications of persistent digital identities. This study contributes to the field of HDTs by describing our novel system architecture, demonstrating its capabilities, and discussing future directions and emerging challenges to ensure the responsible and ethical development of HDTs.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23826",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hierarchical Memory Organization for Wikipedia Generation",
    "description": "arXiv:2506.23393v1 Announce Type: cross Abstract: Generating Wikipedia articles autonomously is a challenging task requiring the integration of accurate, comprehensive, and well-structured information from diverse sources. This paper introduces the Memory Organization-based Generation (MOG) framework, a novel approach to address these challenges by leveraging a hierarchical memory architecture. MOG extracts fine-grained memory units from web documents, recursively organizes them into a Wikipedia-style hierarchical structure, and uses this structure to guide the generation process. This ensures alignment between memory and the article outline, improving both informativeness and verifiability while minimizing hallucinations. Additionally, a citation module is implemented to enhance traceability by linking every generated sentence to specific memory units. Evaluations on our newly created WikiStart dataset demonstrate that MOG outperforms baseline methods in producing informative and reliable articles, making it particularly robust in real-world scenarios.",
    "summary": "arXiv:2506.23393v1 Announce Type: cross Abstract: Generating Wikipedia articles autonomously is a challenging task requiring the integration of accurate, comprehensive, and well-structured information from diverse sources. This paper introduces the Memory Organization-based Generation (MOG) framework, a novel approach to address these challenges by leveraging a hierarchical memory architecture. MOG extracts fine-grained memory units from web documents, recursively organizes them into a Wikipedia-style hierarchical structure, and uses this structure to guide the generation process. This ensures alignment between memory and the article outline, improving both informativeness and verifiability while minimizing hallucinations. Additionally, a citation module is implemented to enhance traceability by linking every generated sentence to specific memory units. Evaluations on our newly created WikiStart dataset demonstrate that MOG outperforms baseline methods in producing informative and reliable articles, making it particularly robust in real-world scenarios.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23393",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improved Supervised Fine-Tuning for Large Language Models to Mitigate Catastrophic Forgetting",
    "description": "arXiv:2506.09428v2 Announce Type: replace-cross Abstract: Supervised Fine-Tuning (SFT) is a critical step for enhancing the instruction-following capabilities of Large Language Models (LLMs) and adapting them to specialized domains. However, SFT often leads to a degradation of the model's general abilities, a phenomenon known as catastrophic forgetting. This problem is exacerbated when third-party practitioners fine-tune open-source models, as the original SFT data is typically not available. To address this challenge, we propose a novel and cost-effective SFT method that effectively mitigates catastrophic forgetting without requiring access to the original SFT data. Our approach first reconstructs the likely instruction distribution of the base model. It then employs a multi-model generation and filtering pipeline to synthesize a high-quality general-purpose dataset. This synthetic dataset is mixed with new, domain-specific data for fine-tuning. Experimental results show that our method not only preserves the model's capabilities in general domains but also improves task-specific performance, outperforming baselines that use publicly available SFT datasets.",
    "summary": "arXiv:2506.09428v2 Announce Type: replace-cross Abstract: Supervised Fine-Tuning (SFT) is a critical step for enhancing the instruction-following capabilities of Large Language Models (LLMs) and adapting them to specialized domains. However, SFT often leads to a degradation of the model's general abilities, a phenomenon known as catastrophic forgetting. This problem is exacerbated when third-party practitioners fine-tune open-source models, as the original SFT data is typically not available. To address this challenge, we propose a novel and cost-effective SFT method that effectively mitigates catastrophic forgetting without requiring access to the original SFT data. Our approach first reconstructs the likely instruction distribution of the base model. It then employs a multi-model generation and filtering pipeline to synthesize a high-quality general-purpose dataset. This synthetic dataset is mixed with new, domain-specific data for fine-tuning. Experimental results show that our method not only preserves the model's capabilities in general domains but also improves task-specific performance, outperforming baselines that use publicly available SFT datasets.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.09428",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Context-Driven Knowledge Graph Completion with Semantic-Aware Relational Message Passing",
    "description": "arXiv:2506.23141v1 Announce Type: new Abstract: Semantic context surrounding a triplet $(h, r, t)$ is crucial for Knowledge Graph Completion (KGC), providing vital cues for prediction. However, traditional node-based message passing mechanisms, when applied to knowledge graphs, often introduce noise and suffer from information dilution or over-smoothing by indiscriminately aggregating information from all neighboring edges. To address this challenge, we propose a semantic-aware relational message passing. A core innovation of this framework is the introduction of a textbf{semantic-aware Top-K neighbor selection strategy}. Specifically, this strategy first evaluates the semantic relevance between a central node and its incident edges within a shared latent space, selecting only the Top-K most pertinent ones. Subsequently, information from these selected edges is effectively fused with the central node's own representation using a textbf{multi-head attention aggregator} to generate a semantically focused node message. In this manner, our model not only leverages the structure and features of edges within the knowledge graph but also more accurately captures and propagates the contextual information most relevant to the specific link prediction task, thereby effectively mitigating interference from irrelevant information. Extensive experiments demonstrate that our method achieves superior performance compared to existing approaches on several established benchmarks.",
    "summary": "arXiv:2506.23141v1 Announce Type: new Abstract: Semantic context surrounding a triplet $(h, r, t)$ is crucial for Knowledge Graph Completion (KGC), providing vital cues for prediction. However, traditional node-based message passing mechanisms, when applied to knowledge graphs, often introduce noise and suffer from information dilution or over-smoothing by indiscriminately aggregating information from all neighboring edges. To address this challenge, we propose a semantic-aware relational message passing. A core innovation of this framework is the introduction of a textbf{semantic-aware Top-K neighbor selection strategy}. Specifically, this strategy first evaluates the semantic relevance between a central node and its incident edges within a shared latent space, selecting only the Top-K most pertinent ones. Subsequently, information from these selected edges is effectively fused with the central node's own representation using a textbf{multi-head attention aggregator} to generate a semantically focused node message. In this manner, our model not only leverages the structure and features of edges within the knowledge graph but also more accurately captures and propagates the contextual information most relevant to the specific link prediction task, thereby effectively mitigating interference from irrelevant information. Extensive experiments demonstrate that our method achieves superior performance compared to existing approaches on several established benchmarks.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23141",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Pre-Train BERT with Hugging Face Transformers and Habana Gaudi",
    "description": "",
    "summary": "Pre-Training BERT with Hugging Face Transformers and Habana Gaudi In this Tutorial, you will learn h...",
    "pubDate": "Mon, 22 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pretraining-bert",
    "thumbnail": "https://huggingface.co/blog/assets/99_pretraining_bert/thumbnail.png"
  },
  {
    "title": "STR-Match: Matching SpatioTemporal Relevance Score for Training-Free Video Editing",
    "description": "arXiv:2506.22868v1 Announce Type: cross Abstract: Previous text-guided video editing methods often suffer from temporal inconsistency, motion distortion, and-most notably-limited domain transformation. We attribute these limitations to insufficient modeling of spatiotemporal pixel relevance during the editing process. To address this, we propose STR-Match, a training-free video editing algorithm that produces visually appealing and spatiotemporally coherent videos through latent optimization guided by our novel STR score. The score captures spatiotemporal pixel relevance across adjacent frames by leveraging 2D spatial attention and 1D temporal modules in text-to-video (T2V) diffusion models, without the overhead of computationally expensive 3D attention mechanisms. Integrated into a latent optimization framework with a latent mask, STR-Match generates temporally consistent and visually faithful videos, maintaining strong performance even under significant domain transformations while preserving key visual attributes of the source. Extensive experiments demonstrate that STR-Match consistently outperforms existing methods in both visual quality and spatiotemporal consistency.",
    "summary": "arXiv:2506.22868v1 Announce Type: cross Abstract: Previous text-guided video editing methods often suffer from temporal inconsistency, motion distortion, and-most notably-limited domain transformation. We attribute these limitations to insufficient modeling of spatiotemporal pixel relevance during the editing process. To address this, we propose STR-Match, a training-free video editing algorithm that produces visually appealing and spatiotemporally coherent videos through latent optimization guided by our novel STR score. The score captures spatiotemporal pixel relevance across adjacent frames by leveraging 2D spatial attention and 1D temporal modules in text-to-video (T2V) diffusion models, without the overhead of computationally expensive 3D attention mechanisms. Integrated into a latent optimization framework with a latent mask, STR-Match generates temporally consistent and visually faithful videos, maintaining strong performance even under significant domain transformations while preserving key visual attributes of the source. Extensive experiments demonstrate that STR-Match consistently outperforms existing methods in both visual quality and spatiotemporal consistency.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22868",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI and Microsoft extend partnership",
    "description": "We‚Äôre happy to announce that OpenAI and¬†Microsoft¬†are extending our¬†partnership.",
    "summary": "We‚Äôre happy to announce that OpenAI and¬†Microsoft¬†are extending our¬†partnership.",
    "pubDate": "Mon, 23 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-microsoft-extend-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Navigating the challenges and opportunities of synthetic voices",
    "description": "We‚Äôre sharing lessons from a small scale preview of Voice Engine, a model for creating custom voices.",
    "summary": "We‚Äôre sharing lessons from a small scale preview of Voice Engine, a model for creating custom voices.",
    "pubDate": "Fri, 29 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/navigating-the-challenges-and-opportunities-of-synthetic-voices",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-Tuning GPT-4o Webinar",
    "description": "Fine-Tuning GPT-4o Webinar",
    "summary": "Fine-Tuning GPT-4o Webinar",
    "pubDate": "Mon, 26 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/fine-tuning-gpt-4o-webinar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "State of open video generation models in Diffusers",
    "description": "",
    "summary": "State of open video generation models in Diffusers OpenAI‚Äôs Sora demo marked a striking advance in A...",
    "pubDate": "Mon, 27 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/video_gen",
    "thumbnail": "https://huggingface.co/blog/assets/video_gen/thumbnail.png"
  },
  {
    "title": "Generalizing vision-language models to novel domains: A comprehensive survey",
    "description": "arXiv:2506.18504v2 Announce Type: replace-cross Abstract: Recently, vision-language pretraining has emerged as a transformative technique that integrates the strengths of both visual and textual modalities, resulting in powerful vision-language models (VLMs). Leveraging web-scale pretraining data, these models exhibit strong zero-shot capabilities. However, their performance often deteriorates when confronted with domain-specific or specialized generalization tasks. To address this, a growing body of research focuses on transferring or generalizing the rich knowledge embedded in VLMs to various downstream applications. This survey aims to comprehensively summarize the generalization settings, methodologies, benchmarking and results in VLM literatures. Delving into the typical VLM structures, current literatures are categorized into prompt-based, parameter-based and feature-based methods according to the transferred modules. The differences and characteristics in each category are furthered summarized and discussed by revisiting the typical transfer learning (TL) settings, providing novel interpretations for TL in the era of VLMs. Popular benchmarks for VLM generalization are further introduced with thorough performance comparisons among the reviewed methods. Following the advances in large-scale generalizable pretraining, this survey also discusses the relations and differences between VLMs and up-to-date multimodal large language models (MLLM), e.g., DeepSeek-VL. By systematically reviewing the surging literatures in vision-language research from a novel and practical generalization prospective, this survey contributes to a clear landscape of current and future multimodal researches.",
    "summary": "arXiv:2506.18504v2 Announce Type: replace-cross Abstract: Recently, vision-language pretraining has emerged as a transformative technique that integrates the strengths of both visual and textual modalities, resulting in powerful vision-language models (VLMs). Leveraging web-scale pretraining data, these models exhibit strong zero-shot capabilities. However, their performance often deteriorates when confronted with domain-specific or specialized generalization tasks. To address this, a growing body of research focuses on transferring or generalizing the rich knowledge embedded in VLMs to various downstream applications. This survey aims to comprehensively summarize the generalization settings, methodologies, benchmarking and results in VLM literatures. Delving into the typical VLM structures, current literatures are categorized into prompt-based, parameter-based and feature-based methods according to the transferred modules. The differences and characteristics in each category are furthered summarized and discussed by revisiting the typical transfer learning (TL) settings, providing novel interpretations for TL in the era of VLMs. Popular benchmarks for VLM generalization are further introduced with thorough performance comparisons among the reviewed methods. Following the advances in large-scale generalizable pretraining, this survey also discusses the relations and differences between VLMs and up-to-date multimodal large language models (MLLM), e.g., DeepSeek-VL. By systematically reviewing the surging literatures in vision-language research from a novel and practical generalization prospective, this survey contributes to a clear landscape of current and future multimodal researches.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18504",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models",
    "description": "arXiv:2501.03124v5 Announce Type: replace-cross Abstract: Process-level Reward Models (PRMs) are crucial for complex reasoning and decision-making tasks, where each intermediate step plays an important role in the reasoning process. Since language models are prone to various types of errors during the reasoning process, PRMs are required to possess nuanced capabilities for detecting various implicit error types in real-world scenarios. However, current benchmarks primarily focus on step correctness, failing to evaluate PRMs' performance systematically. To address this gap, we introduce PRMBench, a process-level benchmark specifically designed to assess the fine-grained error detection capabilities of PRMs. PRMBench comprises 6,216 carefully designed problems and 83,456 step-level labels, evaluating models across multiple dimensions, including simplicity, soundness, and sensitivity. In our experiments on 15 models, spanning both open-source PRMs and closed-source large language models prompted as critic models, we uncover significant weaknesses in current PRMs. These findings underscore the challenges inherent in process-level evaluation and highlight key directions for future research. We hope PRMBench can be a robust bench for advancing research on PRM evaluation and development.",
    "summary": "arXiv:2501.03124v5 Announce Type: replace-cross Abstract: Process-level Reward Models (PRMs) are crucial for complex reasoning and decision-making tasks, where each intermediate step plays an important role in the reasoning process. Since language models are prone to various types of errors during the reasoning process, PRMs are required to possess nuanced capabilities for detecting various implicit error types in real-world scenarios. However, current benchmarks primarily focus on step correctness, failing to evaluate PRMs' performance systematically. To address this gap, we introduce PRMBench, a process-level benchmark specifically designed to assess the fine-grained error detection capabilities of PRMs. PRMBench comprises 6,216 carefully designed problems and 83,456 step-level labels, evaluating models across multiple dimensions, including simplicity, soundness, and sensitivity. In our experiments on 15 models, spanning both open-source PRMs and closed-source large language models prompted as critic models, we uncover significant weaknesses in current PRMs. These findings underscore the challenges inherent in process-level evaluation and highlight key directions for future research. We hope PRMBench can be a robust bench for advancing research on PRM evaluation and development.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.03124",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sculpting Memory: Multi-Concept Forgetting in Diffusion Models via Dynamic Mask and Concept-Aware Optimization",
    "description": "arXiv:2504.09039v2 Announce Type: replace-cross Abstract: Text-to-image (T2I) diffusion models have achieved remarkable success in generating high-quality images from textual prompts. However, their ability to store vast amounts of knowledge raises concerns in scenarios where selective forgetting is necessary, such as removing copyrighted content, reducing biases, or eliminating harmful concepts. While existing unlearning methods can remove certain concepts, they struggle with multi-concept forgetting due to instability, residual knowledge persistence, and generation quality degradation. To address these challenges, we propose textbf{Dynamic Mask coupled with Concept-Aware Loss}, a novel unlearning framework designed for multi-concept forgetting in diffusion models. Our textbf{Dynamic Mask} mechanism adaptively updates gradient masks based on current optimization states, allowing selective weight modifications that prevent interference with unrelated knowledge. Additionally, our textbf{Concept-Aware Loss} explicitly guides the unlearning process by enforcing semantic consistency through superclass alignment, while a regularization loss based on knowledge distillation ensures that previously unlearned concepts remain forgotten during sequential unlearning. We conduct extensive experiments to evaluate our approach. Results demonstrate that our method outperforms existing unlearning techniques in forgetting effectiveness, output fidelity, and semantic coherence, particularly in multi-concept scenarios. Our work provides a principled and flexible framework for stable and high-fidelity unlearning in generative models. The code will be released publicly.",
    "summary": "arXiv:2504.09039v2 Announce Type: replace-cross Abstract: Text-to-image (T2I) diffusion models have achieved remarkable success in generating high-quality images from textual prompts. However, their ability to store vast amounts of knowledge raises concerns in scenarios where selective forgetting is necessary, such as removing copyrighted content, reducing biases, or eliminating harmful concepts. While existing unlearning methods can remove certain concepts, they struggle with multi-concept forgetting due to instability, residual knowledge persistence, and generation quality degradation. To address these challenges, we propose textbf{Dynamic Mask coupled with Concept-Aware Loss}, a novel unlearning framework designed for multi-concept forgetting in diffusion models. Our textbf{Dynamic Mask} mechanism adaptively updates gradient masks based on current optimization states, allowing selective weight modifications that prevent interference with unrelated knowledge. Additionally, our textbf{Concept-Aware Loss} explicitly guides the unlearning process by enforcing semantic consistency through superclass alignment, while a regularization loss based on knowledge distillation ensures that previously unlearned concepts remain forgotten during sequential unlearning. We conduct extensive experiments to evaluate our approach. Results demonstrate that our method outperforms existing unlearning techniques in forgetting effectiveness, output fidelity, and semantic coherence, particularly in multi-concept scenarios. Our work provides a principled and flexible framework for stable and high-fidelity unlearning in generative models. The code will be released publicly.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.09039",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Questions for the Record",
    "description": "The following are the Questions for the Record following Sam Altman's testimony before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "summary": "The following are the Questions for the Record following Sam Altman's testimony before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/sam-altman-senate-questions-for-the-record",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Mathematical Reasoning for Unmanned Aerial Vehicles: A RAG-Based Approach for Complex Arithmetic Reasoning",
    "description": "arXiv:2506.04998v2 Announce Type: replace Abstract: Autonomous UAV operation necessitates reliable mathematical reasoning for tasks such as trajectory planning and power management. While traditional flight control relies on hardcoded equations, recent Large Language Models (LLMs) offer potential for more flexible problem-solving but struggle with reliably selecting and applying correct mathematical formulations and executing precise multi-step arithmetic. We propose RAG-UAV, a retrieval-augmented generation framework designed to improve the mathematical reasoning of several LLMs (including GPT o1/Turbo, Llama-3.2/3.3, Mistral, and DeepSeek R1) in UAV-specific contexts by providing access to relevant domain literature. To conduct an initial assessment, we introduce the UAV-Math-Bench, a 20-question problem set of UAV-centric mathematical problems across four difficulty levels. Our experiments demonstrate that incorporating retrieval substantially increases exact answer accuracy (achieving up to 75% with o1), reduces instances of incorrect formulation selection (from 25% without RAG to 5% with RAG), and decreases numerical errors, reducing Mean Squared Error (MSE) by orders of magnitude for the best-performing models. This pilot study indicates that RAG can enable general-purpose LLMs to function as more reliable tools for engineering analysis, although direct real-time flight control requires further investigation and validation on a larger scale. All benchmark data, questions, and answers are publicly available.",
    "summary": "arXiv:2506.04998v2 Announce Type: replace Abstract: Autonomous UAV operation necessitates reliable mathematical reasoning for tasks such as trajectory planning and power management. While traditional flight control relies on hardcoded equations, recent Large Language Models (LLMs) offer potential for more flexible problem-solving but struggle with reliably selecting and applying correct mathematical formulations and executing precise multi-step arithmetic. We propose RAG-UAV, a retrieval-augmented generation framework designed to improve the mathematical reasoning of several LLMs (including GPT o1/Turbo, Llama-3.2/3.3, Mistral, and DeepSeek R1) in UAV-specific contexts by providing access to relevant domain literature. To conduct an initial assessment, we introduce the UAV-Math-Bench, a 20-question problem set of UAV-centric mathematical problems across four difficulty levels. Our experiments demonstrate that incorporating retrieval substantially increases exact answer accuracy (achieving up to 75% with o1), reduces instances of incorrect formulation selection (from 25% without RAG to 5% with RAG), and decreases numerical errors, reducing Mean Squared Error (MSE) by orders of magnitude for the best-performing models. This pilot study indicates that RAG can enable general-purpose LLMs to function as more reliable tools for engineering analysis, although direct real-time flight control requires further investigation and validation on a larger scale. All benchmark data, questions, and answers are publicly available.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.04998",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerate Large Model Training using DeepSpeed",
    "description": "",
    "summary": "Accelerate Large Model Training using DeepSpeed In this post we will look at how we can leverage the...",
    "pubDate": "Tue, 28 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-deepspeed",
    "thumbnail": "https://huggingface.co/blog/assets/83_accelerate_deepspeed/deepspeed-thumbnail.png"
  },
  {
    "title": "A Systematic Study of Compositional Syntactic Transformer Language Models",
    "description": "arXiv:2506.22978v1 Announce Type: cross Abstract: Syntactic language models (SLMs) enhance Transformers by incorporating syntactic biases through the modeling of linearized syntactic parse trees alongside surface sentences. This paper focuses on compositional SLMs that are based on constituency parse trees and contain explicit bottom-up composition of constituent representations. We identify key aspects of design choices in existing compositional SLMs and propose a unified framework encompassing both existing models and novel variants. We conduct a comprehensive empirical evaluation of all the variants in our framework across language modeling, syntactic generalization, summarization, dialogue, and inference efficiency. Based on the experimental results, we make multiple recommendations on the design of compositional SLMs. Our code is released at https://github.com/zhaoyd1/compositional_SLMs.",
    "summary": "arXiv:2506.22978v1 Announce Type: cross Abstract: Syntactic language models (SLMs) enhance Transformers by incorporating syntactic biases through the modeling of linearized syntactic parse trees alongside surface sentences. This paper focuses on compositional SLMs that are based on constituency parse trees and contain explicit bottom-up composition of constituent representations. We identify key aspects of design choices in existing compositional SLMs and propose a unified framework encompassing both existing models and novel variants. We conduct a comprehensive empirical evaluation of all the variants in our framework across language modeling, syntactic generalization, summarization, dialogue, and inference efficiency. Based on the experimental results, we make multiple recommendations on the design of compositional SLMs. Our code is released at https://github.com/zhaoyd1/compositional_SLMs.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22978",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "7/9ÈñãÂÇ¨„ÄêÁîüÊàêAIÂìÅË≥™ÊîπÂñÑ„Ç¶„Çß„Éì„Éä„Éº„Äë Êú¨Áï™ÂìÅË≥™„ÅÆÁîüÊàêAI„Çí„Å©„ÅÜ‰Ωú„ÇãÔºüLLMOps√óÈ´òÁ≤æÂ∫¶„Éá„Éº„Çø„ÅßÂÆüÁèæ„Åô„ÇãÊîπÂñÑ„Éó„É≠„Çª„Çπ",
    "description": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà9Êó•ÔºàÊ∞¥Ôºâ12ÊôÇ„Åã„ÇâÁîüÊàêAIÊ¥ªÁî®„Çí„ÉÜ„Éº„Éû„Å´„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ Êú¨„Ç¶„Çß„Éì„Éä„Éº„Åß„ÅØ„ÄÅÁîüÊàêAIÊ¥ªÁî®„ÅÆ„Éù„Ç§„É≥„Éà„Å´„Å§„ÅÑ„Å¶„ÅîÁ¥π‰ªã„ÄÇÁîüÊàêAI„ÇíÊú¨Áï™ÂìÅË≥™„Å∏ÊîπÂñÑ„Åô„Çã„Éù„Ç§„É≥„Éà„Åã [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250709webinar/'>7/9ÈñãÂÇ¨„ÄêÁîüÊàêAIÂìÅË≥™ÊîπÂñÑ„Ç¶„Çß„Éì„Éä„Éº„Äë Êú¨Áï™ÂìÅË≥™„ÅÆÁîüÊàêAI„Çí„Å©„ÅÜ‰Ωú„ÇãÔºüLLMOps√óÈ´òÁ≤æÂ∫¶„Éá„Éº„Çø„ÅßÂÆüÁèæ„Åô„ÇãÊîπÂñÑ„Éó„É≠„Çª„Çπ</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà9Êó•ÔºàÊ∞¥Ôºâ12ÊôÇ„Åã„ÇâÁîüÊàêAIÊ¥ªÁî®„Çí„ÉÜ„Éº„Éû„Å´„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ Êú¨„Ç¶„Çß„Éì„Éä„Éº„Åß„ÅØ„ÄÅÁîüÊàêAIÊ¥ªÁî®„ÅÆ„Éù„Ç§„É≥„Éà„Å´„Å§„ÅÑ„Å¶„ÅîÁ¥π‰ªã„ÄÇÁîüÊàêAI„ÇíÊú¨Áï™ÂìÅË≥™„Å∏ÊîπÂñÑ„Åô„Çã„Éù„Ç§„É≥„Éà„Åã [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250709webinar/'>7/9ÈñãÂÇ¨„ÄêÁîüÊàêAIÂìÅË≥™ÊîπÂñÑ„Ç¶„Çß„Éì„Éä„Éº„Äë Êú¨Áï™ÂìÅË≥™„ÅÆÁîüÊàêAI„Çí„Å©„ÅÜ‰Ωú„ÇãÔºüLLMOps√óÈ´òÁ≤æÂ∫¶„Éá„Éº„Çø„ÅßÂÆüÁèæ„Åô„ÇãÊîπÂñÑ„Éó„É≠„Çª„Çπ</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Mon, 16 Jun 2025 01:37:40 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/20250709webinar/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/699_1200x628_2.jpg"
  },
  {
    "title": "Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration",
    "description": "",
    "summary": "Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration The mission of ...",
    "pubDate": "Wed, 15 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel",
    "thumbnail": "https://huggingface.co/blog/assets/80_intel/01.png"
  },
  {
    "title": "From Chunks to Blocks: Accelerating Uploads and Downloads on the Hub",
    "description": "",
    "summary": "From Chunks to Blocks: Accelerating Uploads and Downloads on the Hub Content-defined chunking (CDC) ...",
    "pubDate": "Wed, 12 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/from-chunks-to-blocks",
    "thumbnail": "https://huggingface.co/blog/assets/from-chunks-to-blocks/thumbnail.png"
  },
  {
    "title": "A Deepdive into Aya Vision: Advancing the Frontier of Multilingual Multimodality",
    "description": "",
    "summary": "A Deepdive into Aya Vision: Advancing the Frontier of Multilingual Multimodality With the release of...",
    "pubDate": "Tue, 04 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aya-vision",
    "thumbnail": "https://huggingface.co/blog/assets/aya-vision/thumbnail.png"
  },
  {
    "title": "Gemini Robotics brings AI into the physical world",
    "description": "Introducing Gemini Robotics and Gemini Robotics-ER, AI models designed for robots to understand, act and react to the physical world.",
    "summary": "Introducing Gemini Robotics and Gemini Robotics-ER, AI models designed for robots to understand, act and react to the physical world.",
    "pubDate": "Wed, 12 Mar 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/",
    "thumbnail": "https://lh3.googleusercontent.com/J74rVi68EPPNMBLxhxI76Bli7QggLtYRYfp5Pk2HVPtSt2NIIk2VmLktQbwDZeIlZiW3AHwlpLNcswHuz_ecR-oj4kI-mtF53yYsGJKfvPugAw5ulQ=w1200-h630-n-nu"
  },
  {
    "title": "Extracting Concepts from GPT-4",
    "description": "Using new techniques for scaling sparse autoencoders, we automatically identified 16 million patterns in GPT-4's computations.",
    "summary": "Using new techniques for scaling sparse autoencoders, we automatically identified 16 million patterns in GPT-4's computations.",
    "pubDate": "Thu, 06 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/extracting-concepts-from-gpt-4",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeRobot goes to driving school: World‚Äôs largest open-source self-driving dataset",
    "description": "",
    "summary": "LeRobot goes to driving school TL;DR of L2D, the world's largest self-driving dataset! - 90+ TeraByt...",
    "pubDate": "Tue, 11 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lerobot-goes-to-driving-school",
    "thumbnail": "https://huggingface.co/blog/assets/193_l2d/lerobot-driver.gif"
  },
  {
    "title": "HASD: Hierarchical Adaption for pathology Slide-level Domain-shift",
    "description": "arXiv:2506.23673v1 Announce Type: new Abstract: Domain shift is a critical problem for pathology AI as pathology data is heavily influenced by center-specific conditions. Current pathology domain adaptation methods focus on image patches rather than WSI, thus failing to capture global WSI features required in typical clinical scenarios. In this work, we address the challenges of slide-level domain shift by proposing a Hierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD achieves multi-scale feature consistency and computationally efficient slide-level domain adaptation through two key components: (1) a hierarchical adaptation framework that integrates a Domain-level Alignment Solver for feature alignment, a Slide-level Geometric Invariance Regularization to preserve the morphological structure, and a Patch-level Attention Consistency Regularization to maintain local critical diagnostic cues; and (2) a prototype selection mechanism that reduces computational overhead. We validate our method on two slide-level tasks across five datasets, achieving a 4.1% AUROC improvement in a Breast Cancer HER2 Grading cohort and a 3.9% C-index gain in a UCEC survival prediction cohort. Our method provides a practical and reliable slide-level domain adaption solution for pathology institutions, minimizing both computational and annotation costs.",
    "summary": "arXiv:2506.23673v1 Announce Type: new Abstract: Domain shift is a critical problem for pathology AI as pathology data is heavily influenced by center-specific conditions. Current pathology domain adaptation methods focus on image patches rather than WSI, thus failing to capture global WSI features required in typical clinical scenarios. In this work, we address the challenges of slide-level domain shift by proposing a Hierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD achieves multi-scale feature consistency and computationally efficient slide-level domain adaptation through two key components: (1) a hierarchical adaptation framework that integrates a Domain-level Alignment Solver for feature alignment, a Slide-level Geometric Invariance Regularization to preserve the morphological structure, and a Patch-level Attention Consistency Regularization to maintain local critical diagnostic cues; and (2) a prototype selection mechanism that reduces computational overhead. We validate our method on two slide-level tasks across five datasets, achieving a 4.1% AUROC improvement in a Breast Cancer HER2 Grading cohort and a 3.9% C-index gain in a UCEC survival prediction cohort. Our method provides a practical and reliable slide-level domain adaption solution for pathology institutions, minimizing both computational and annotation costs.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23673",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NVIDIA's GTC 2025 Announcement for Physical AI Developers: New Open Models and Datasets",
    "description": "",
    "summary": "NVIDIA's GTC 2025 Announcement for Physical AI Developers: New Open Models and Datasets At its annua...",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nvidia-physical-ai",
    "thumbnail": "https://huggingface.co/blog/assets/nvidia-physical-ai/thumbnail.png"
  },
  {
    "title": "Introducing Optimum: The Optimization Toolkit for Transformers at Scale",
    "description": "",
    "summary": "Introducing ü§ó Optimum: The Optimization Toolkit for Transformers at Scale This post is the first ste...",
    "pubDate": "Tue, 14 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hardware-partners-program",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Disrupting deceptive uses of AI by covert influence operations",
    "description": "We‚Äôve terminated accounts linked to covert influence operations; no significant audience increase due to our services.",
    "summary": "We‚Äôve terminated accounts linked to covert influence operations; no significant audience increase due to our services.",
    "pubDate": "Thu, 30 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-deceptive-uses-of-AI-by-covert-influence-operations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 2",
    "description": "",
    "summary": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 2 In a recent post, we introduced...",
    "pubDate": "Mon, 06 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-sapphire-rapids-inference",
    "thumbnail": "https://huggingface.co/blog/assets/129_intel_sapphire_rapids_inference/01.png"
  },
  {
    "title": "Dell Enterprise Hub is all you need to build AI on premises",
    "description": "",
    "summary": "Dell Enterprise Hub is all you need to build AI on premises This week at Dell Tech World, we announc...",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dell-ai-applications",
    "thumbnail": "https://huggingface.co/blog/assets/dell-ai-applications/dell-post-thumbnail.png"
  },
  {
    "title": "Introducing Training Cluster as a Service - a new collaboration with NVIDIA",
    "description": "",
    "summary": "Introducing Training Cluster as a Service - a new collaboration with NVIDIA Today at GTC Paris, we a...",
    "pubDate": "Wed, 11 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nvidia-training-cluster",
    "thumbnail": "https://huggingface.co/blog/assets/nvidia-training-cluster/nvidia-training-cluster-thumbnail-compressed.png"
  },
  {
    "title": "Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning",
    "description": "arXiv:2506.17525v2 Announce Type: replace-cross Abstract: Our quality audit for three widely used public multilingual speech datasets - Mozilla Common Voice 17.0, FLEURS, and Vox Populi - shows that in some languages, these datasets suffer from significant quality issues, which may obfuscate downstream evaluation results while creating an illusion of success. We divide these quality issues into two categories: micro-level and macro-level. We find that macro-level issues are more prevalent in less institutionalized, often under-resourced languages. We provide a case analysis of Taiwanese Southern Min (nan_tw) that highlights the need for proactive language planning (e.g. orthography prescriptions, dialect boundary definition) and enhanced data quality control in the dataset creation process. We conclude by proposing guidelines and recommendations to mitigate these issues in future dataset development, emphasizing the importance of sociolinguistic awareness and language planning principles. Furthermore, we encourage research into how this creation process itself can be leveraged as a tool for community-led language planning and revitalization.",
    "summary": "arXiv:2506.17525v2 Announce Type: replace-cross Abstract: Our quality audit for three widely used public multilingual speech datasets - Mozilla Common Voice 17.0, FLEURS, and Vox Populi - shows that in some languages, these datasets suffer from significant quality issues, which may obfuscate downstream evaluation results while creating an illusion of success. We divide these quality issues into two categories: micro-level and macro-level. We find that macro-level issues are more prevalent in less institutionalized, often under-resourced languages. We provide a case analysis of Taiwanese Southern Min (nan_tw) that highlights the need for proactive language planning (e.g. orthography prescriptions, dialect boundary definition) and enhanced data quality control in the dataset creation process. We conclude by proposing guidelines and recommendations to mitigate these issues in future dataset development, emphasizing the importance of sociolinguistic awareness and language planning principles. Furthermore, we encourage research into how this creation process itself can be leveraged as a tool for community-led language planning and revitalization.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17525",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Will Hurd joins OpenAI‚Äôs board of directors",
    "description": "OpenAI is committed to developing general-purpose artificial intelligence that benefits all humanity, and we believe that achieving our goal requires expertise in public policy as well as technology. So, we‚Äôre delighted to announce that Congressman¬†Will Hurd¬†has joined our board of directors.",
    "summary": "OpenAI is committed to developing general-purpose artificial intelligence that benefits all humanity, and we believe that achieving our goal requires expertise in public policy as well as technology. So, we‚Äôre delighted to announce that Congressman¬†Will Hurd¬†has joined our board of directors.",
    "pubDate": "Mon, 03 May 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/will-hurd-joins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the ChatGPT app for iOS",
    "description": "The ChatGPT app syncs your conversations, supports voice input, and brings our latest model improvements to your fingertips.",
    "summary": "The ChatGPT app syncs your conversations, supports voice input, and brings our latest model improvements to your fingertips.",
    "pubDate": "Thu, 18 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-chatgpt-app-for-ios",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Data Partnerships",
    "description": "Working together to create open-source and private datasets for AI training.",
    "summary": "Working together to create open-source and private datasets for AI training.",
    "pubDate": "Thu, 09 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/data-partnerships",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Discovering the minutiae of backend systems",
    "description": "Christian Gibson is an engineer on the Supercomputing team at OpenAI.",
    "summary": "Christian Gibson is an engineer on the Supercomputing team at OpenAI.",
    "pubDate": "Thu, 08 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/discovering-the-minutiae-of-backend-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "We‚Äôre bringing the Financial Times‚Äô world-class journalism to ChatGPT",
    "description": "We will also collaborate on new AI experiences for FT readers.",
    "summary": "We will also collaborate on new AI experiences for FT readers.",
    "pubDate": "Mon, 29 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/content-partnership-with-financial-times",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents",
    "description": "arXiv:2506.22485v1 Announce Type: cross Abstract: This study presents a modular, multi-agent system for the automated review of highly structured enterprise business documents using AI agents. Unlike prior solutions focused on unstructured texts or limited compliance checks, this framework leverages modern orchestration tools such as LangChain, CrewAI, TruLens, and Guidance to enable section-by-section evaluation of documents for accuracy, consistency, completeness, and clarity. Specialized agents, each responsible for discrete review criteria such as template compliance or factual correctness, operate in parallel or sequence as required. Evaluation outputs are enforced to a standardized, machine-readable schema, supporting downstream analytics and auditability. Continuous monitoring and a feedback loop with human reviewers allow for iterative system improvement and bias mitigation. Quantitative evaluation demonstrates that the AI Agent-as-Judge system approaches or exceeds human performance in key areas: achieving 99% information consistency (vs. 92% for humans), halving error and bias rates, and reducing average review time from 30 to 2.5 minutes per document, with a 95% agreement rate between AI and expert human judgment. While promising for a wide range of industries, the study also discusses current limitations, including the need for human oversight in highly specialized domains and the operational cost of large-scale LLM usage. The proposed system serves as a flexible, auditable, and scalable foundation for AI-driven document quality assurance in the enterprise context.",
    "summary": "arXiv:2506.22485v1 Announce Type: cross Abstract: This study presents a modular, multi-agent system for the automated review of highly structured enterprise business documents using AI agents. Unlike prior solutions focused on unstructured texts or limited compliance checks, this framework leverages modern orchestration tools such as LangChain, CrewAI, TruLens, and Guidance to enable section-by-section evaluation of documents for accuracy, consistency, completeness, and clarity. Specialized agents, each responsible for discrete review criteria such as template compliance or factual correctness, operate in parallel or sequence as required. Evaluation outputs are enforced to a standardized, machine-readable schema, supporting downstream analytics and auditability. Continuous monitoring and a feedback loop with human reviewers allow for iterative system improvement and bias mitigation. Quantitative evaluation demonstrates that the AI Agent-as-Judge system approaches or exceeds human performance in key areas: achieving 99% information consistency (vs. 92% for humans), halving error and bias rates, and reducing average review time from 30 to 2.5 minutes per document, with a 95% agreement rate between AI and expert human judgment. While promising for a wide range of industries, the study also discusses current limitations, including the need for human oversight in highly specialized domains and the operational cost of large-scale LLM usage. The proposed system serves as a flexible, auditable, and scalable foundation for AI-driven document quality assurance in the enterprise context.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22485",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Disrupting malicious uses of AI",
    "description": "Ensuring AI benefits humanity by advancing democratic AI, preventing misuse, and protecting against authoritarian threats.",
    "summary": "Ensuring AI benefits humanity by advancing democratic AI, preventing misuse, and protecting against authoritarian threats.",
    "pubDate": "Fri, 21 Feb 2025 06:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The International 2018: Results",
    "description": "OpenAI Five lost two games against top Dota 2 players at The International in Vancouver this week, maintaining a good chance of winning for the first 20‚Äì35 minutes of both¬†games.",
    "summary": "OpenAI Five lost two games against top Dota 2 players at The International in Vancouver this week, maintaining a good chance of winning for the first 20‚Äì35 minutes of both¬†games.",
    "pubDate": "Thu, 23 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-international-2018-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Aligning Evaluation with Clinical Priorities: Calibration, Label Shift, and Error Costs",
    "description": "arXiv:2506.14540v3 Announce Type: replace-cross Abstract: Machine learning-based decision support systems are increasingly deployed in clinical settings, where probabilistic scoring functions are used to inform and prioritize patient management decisions. However, widely used scoring rules, such as accuracy and AUC-ROC, fail to adequately reflect key clinical priorities, including calibration, robustness to distributional shifts, and sensitivity to asymmetric error costs. In this work, we propose a principled yet practical evaluation framework for selecting calibrated thresholded classifiers that explicitly accounts for the uncertainty in class prevalences and domain-specific cost asymmetries often found in clinical settings. Building on the theory of proper scoring rules, particularly the Schervish representation, we derive an adjusted variant of cross-entropy (log score) that averages cost-weighted performance over clinically relevant ranges of class balance. The resulting evaluation is simple to apply, sensitive to clinical deployment conditions, and designed to prioritize models that are both calibrated and robust to real-world variations.",
    "summary": "arXiv:2506.14540v3 Announce Type: replace-cross Abstract: Machine learning-based decision support systems are increasingly deployed in clinical settings, where probabilistic scoring functions are used to inform and prioritize patient management decisions. However, widely used scoring rules, such as accuracy and AUC-ROC, fail to adequately reflect key clinical priorities, including calibration, robustness to distributional shifts, and sensitivity to asymmetric error costs. In this work, we propose a principled yet practical evaluation framework for selecting calibrated thresholded classifiers that explicitly accounts for the uncertainty in class prevalences and domain-specific cost asymmetries often found in clinical settings. Building on the theory of proper scoring rules, particularly the Schervish representation, we derive an adjusted variant of cross-entropy (log score) that averages cost-weighted performance over clinically relevant ranges of class balance. The resulting evaluation is simple to apply, sensitive to clinical deployment conditions, and designed to prioritize models that are both calibrated and robust to real-world variations.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14540",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Kalahi: A handcrafted, grassroots cultural LLM evaluation suite for Filipino",
    "description": "arXiv:2409.15380v4 Announce Type: replace-cross Abstract: Multilingual large language models (LLMs) today may not necessarily provide culturally appropriate and relevant responses to its Filipino users. We introduce Kalahi, a cultural LLM evaluation suite collaboratively created by native Filipino speakers. It is composed of 150 high-quality, handcrafted and nuanced prompts that test LLMs for generations that are relevant to shared Filipino cultural knowledge and values. Strong LLM performance in Kalahi indicates a model's ability to generate responses similar to what an average Filipino would say or do in a given situation. We conducted experiments on LLMs with multilingual and Filipino language support. Results show that Kalahi, while trivial for Filipinos, is challenging for LLMs, with the best model answering only 46.0% of the questions correctly compared to native Filipino performance of 89.10%. Thus, Kalahi can be used to accurately and reliably evaluate Filipino cultural representation in LLMs.",
    "summary": "arXiv:2409.15380v4 Announce Type: replace-cross Abstract: Multilingual large language models (LLMs) today may not necessarily provide culturally appropriate and relevant responses to its Filipino users. We introduce Kalahi, a cultural LLM evaluation suite collaboratively created by native Filipino speakers. It is composed of 150 high-quality, handcrafted and nuanced prompts that test LLMs for generations that are relevant to shared Filipino cultural knowledge and values. Strong LLM performance in Kalahi indicates a model's ability to generate responses similar to what an average Filipino would say or do in a given situation. We conducted experiments on LLMs with multilingual and Filipino language support. Results show that Kalahi, while trivial for Filipinos, is challenging for LLMs, with the best model answering only 46.0% of the questions correctly compared to native Filipino performance of 89.10%. Thus, Kalahi can be used to accurately and reliably evaluate Filipino cultural representation in LLMs.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.15380",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "VALID-Mol: a Systematic Framework for Validated LLM-Assisted Molecular Design",
    "description": "arXiv:2506.23339v1 Announce Type: cross Abstract: Large Language Models (LLMs) demonstrate remarkable potential for scientific discovery, but their application in domains requiring factual accuracy and domain-specific constraints remains challenging. In molecular design for drug discovery, LLMs can suggest creative molecular modifications but often produce chemically invalid or impractical structures. We present VALID-Mol, a systematic framework for integrating chemical validation with LLM-driven molecular design that increases the rate of generating valid chemical structures from 3% to 83%. Our approach combines methodical prompt engineering, automated chemical validation, and a fine-tuned domain-adapted LLM to ensure reliable generation of synthesizable molecules with improved properties. Beyond the specific implementation, we contribute a generalizable methodology for scientifically-constrained LLM applications, with quantifiable reliability improvements. Computational predictions suggest our framework can generate promising candidates for synthesis with up to 17-fold computationally predicted improvements in target affinity while maintaining synthetic accessibility. We provide a detailed analysis of our prompt engineering process, validation architecture, and fine-tuning approach, offering a reproducible blueprint for applying LLMs to other scientific domains where domain-specific validation is essential.",
    "summary": "arXiv:2506.23339v1 Announce Type: cross Abstract: Large Language Models (LLMs) demonstrate remarkable potential for scientific discovery, but their application in domains requiring factual accuracy and domain-specific constraints remains challenging. In molecular design for drug discovery, LLMs can suggest creative molecular modifications but often produce chemically invalid or impractical structures. We present VALID-Mol, a systematic framework for integrating chemical validation with LLM-driven molecular design that increases the rate of generating valid chemical structures from 3% to 83%. Our approach combines methodical prompt engineering, automated chemical validation, and a fine-tuned domain-adapted LLM to ensure reliable generation of synthesizable molecules with improved properties. Beyond the specific implementation, we contribute a generalizable methodology for scientifically-constrained LLM applications, with quantifiable reliability improvements. Computational predictions suggest our framework can generate promising candidates for synthesis with up to 17-fold computationally predicted improvements in target affinity while maintaining synthetic accessibility. We provide a detailed analysis of our prompt engineering process, validation architecture, and fine-tuning approach, offering a reproducible blueprint for applying LLMs to other scientific domains where domain-specific validation is essential.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23339",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome aMUSEd: Efficient Text-to-Image Generation",
    "description": "",
    "summary": "Welcome aMUSEd: Efficient Text-to-Image Generation We‚Äôre excited to present an efficient non-diffusi...",
    "pubDate": "Thu, 04 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/amused",
    "thumbnail": "https://huggingface.co/blog/assets/amused/thumbnail.png"
  },
  {
    "title": "A Dive into Pretraining Strategies for Vision-Language Models",
    "description": "",
    "summary": "A Dive into Vision-Language Models Human learning is inherently multi-modal as jointly leveraging mu...",
    "pubDate": "Fri, 03 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vision_language_pretraining",
    "thumbnail": "https://huggingface.co/blog//assets/128_vision_language_pretraining/thumbnail.png"
  },
  {
    "title": "Organizational update from OpenAI",
    "description": "It‚Äôs been a year of dramatic change and growth at OpenAI.",
    "summary": "It‚Äôs been a year of dramatic change and growth at OpenAI.",
    "pubDate": "Tue, 29 Dec 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/organizational-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Expanding on how Voice Engine works and our safety research",
    "description": "Exploring the technology behind our text-to-speech model.",
    "summary": "Exploring the technology behind our text-to-speech model.",
    "pubDate": "Fri, 07 Jun 2024 17:45:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expanding-on-how-voice-engine-works-and-our-safety-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DeepMind‚Äôs latest research at NeurIPS 2022",
    "description": "NeurIPS is the world‚Äôs largest conference in artificial intelligence (AI) and machine learning (ML), and we‚Äôre proud to support the event as Diamond sponsors, helping foster the exchange of research advances in the AI and ML community. Teams from across DeepMind are presenting 47 papers, including 35 external collaborations in virtual panels and poster sessions.",
    "summary": "NeurIPS is the world‚Äôs largest conference in artificial intelligence (AI) and machine learning (ML), and we‚Äôre proud to support the event as Diamond sponsors, helping foster the exchange of research advances in the AI and ML community. Teams from across DeepMind are presenting 47 papers, including 35 external collaborations in virtual panels and poster sessions.",
    "pubDate": "Fri, 25 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/deepminds-latest-research-at-neurips-2022/",
    "thumbnail": "https://lh3.googleusercontent.com/MFZKdGWHOzJ6nM8NufhIfpts0R-v9D4jQqnC416FT8ArwmNC2Ztke2S50WVtUhO0g1u8AGmYEyWMDC7LO0a16ydHBMei9GmJO4NjykhpLKw1TVtd4Mg=w1200-h630-n-nu"
  },
  {
    "title": "Learning Day",
    "description": "At OpenAI, each Thursday is Learning Day: a day where employees have the option to self-study technical skills that will make them better at their job but which aren‚Äôt being learned from daily work.",
    "summary": "At OpenAI, each Thursday is Learning Day: a day where employees have the option to self-study technical skills that will make them better at their job but which aren‚Äôt being learned from daily work.",
    "pubDate": "Thu, 01 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-day",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "BayesL: Towards a Logical Framework for Bayesian Networks",
    "description": "arXiv:2506.23773v1 Announce Type: new Abstract: We introduce BayesL, a novel logical framework for specifying, querying, and verifying the behaviour of Bayesian networks (BNs). BayesL (pronounced 'Basil') is a structured language that allows for the creation of queries over BNs. It facilitates versatile reasoning concerning causal and evidence-based relationships, and permits comprehensive what-if scenario evaluations without the need for manual modifications to the model.",
    "summary": "arXiv:2506.23773v1 Announce Type: new Abstract: We introduce BayesL, a novel logical framework for specifying, querying, and verifying the behaviour of Bayesian networks (BNs). BayesL (pronounced 'Basil') is a structured language that allows for the creation of queries over BNs. It facilitates versatile reasoning concerning causal and evidence-based relationships, and permits comprehensive what-if scenario evaluations without the need for manual modifications to the model.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23773",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Minne Atairu & Sora",
    "description": "Interdisciplinary artist Minne Atairu discusses how Sora helps realize her vision.",
    "summary": "Interdisciplinary artist Minne Atairu discusses how Sora helps realize her vision.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-minne-atairu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI Japan",
    "description": "We are excited to announce our first office in Asia and we‚Äôre releasing a GPT-4 custom model optimized for the Japanese language.",
    "summary": "We are excited to announce our first office in Asia and we‚Äôre releasing a GPT-4 custom model optimized for the Japanese language.",
    "pubDate": "Sun, 14 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-japan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemma: Introducing new state-of-the-art open models",
    "description": "Gemma is built for responsible AI development from the same research and technology used to create Gemini models.",
    "summary": "Gemma is built for responsible AI development from the same research and technology used to create Gemini models.",
    "pubDate": "Wed, 21 Feb 2024 13:06:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemma-introducing-new-state-of-the-art-open-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemma-social-share.width-1300.jpg"
  },
  {
    "title": "GLIMPSE: Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation for Generative LVLMs",
    "description": "arXiv:2506.18985v2 Announce Type: replace-cross Abstract: Recent progress in large vision-language models (LVLMs) has advanced the state of the art in visual question answering (VQA). However, interpreting where LVLMs direct their visual attention while generating free-form responses remains a significant challenge, yet is essential for understanding model behavior. We introduce GLIMPSE (Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation), a lightweight, model-agnostic framework that jointly attributes LVLM outputs to the most relevant visual evidence and textual signals supporting open-ended VQA. GLIMPSE fuses gradient-weighted attention, adaptive layer propagation, and relevance-weighted token aggregation to produce holistic response-level heat maps for interpreting cross-modal reasoning, outperforming prior interpretability methods and pushing the state-of-the-art in human-alignment. We demonstrate an analytic explainable AI (XAI) approach using GLIMPSE to uncover fine-grained insights into LVLM cross-modal attribution, trace reasoning dynamics, analyze systematic human-attention misalignment, diagnose hallucination, expose bias, and ensure transparency.",
    "summary": "arXiv:2506.18985v2 Announce Type: replace-cross Abstract: Recent progress in large vision-language models (LVLMs) has advanced the state of the art in visual question answering (VQA). However, interpreting where LVLMs direct their visual attention while generating free-form responses remains a significant challenge, yet is essential for understanding model behavior. We introduce GLIMPSE (Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation), a lightweight, model-agnostic framework that jointly attributes LVLM outputs to the most relevant visual evidence and textual signals supporting open-ended VQA. GLIMPSE fuses gradient-weighted attention, adaptive layer propagation, and relevance-weighted token aggregation to produce holistic response-level heat maps for interpreting cross-modal reasoning, outperforming prior interpretability methods and pushing the state-of-the-art in human-alignment. We demonstrate an analytic explainable AI (XAI) approach using GLIMPSE to uncover fine-grained insights into LVLM cross-modal attribution, trace reasoning dynamics, analyze systematic human-attention misalignment, diagnose hallucination, expose bias, and ensure transparency.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18985",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Fellows Summer 2018: Final projects",
    "description": "Our first cohort of OpenAI Fellows has concluded, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship.",
    "summary": "Our first cohort of OpenAI Fellows has concluded, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship.",
    "pubDate": "Wed, 19 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-summer-fellows-2018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bringing intelligence to every workflow",
    "description": "Notion is a connected workspace where teams write, plan, and organize everything from meeting notes to product roadmaps. Today, it‚Äôs also a deeply AI-powered platform, used by millions to summarize content, generate writing, and ask questions in natural language across their entire workspace.",
    "summary": "Notion is a connected workspace where teams write, plan, and organize everything from meeting notes to product roadmaps. Today, it‚Äôs also a deeply AI-powered platform, used by millions to summarize content, generate writing, and ask questions in natural language across their entire workspace.",
    "pubDate": "Thu, 03 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/notion",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making automatic speech recognition work on large files with Wav2Vec2 in ü§ó Transformers",
    "description": "",
    "summary": "Making automatic speech recognition work on large files with Wav2Vec2 in ü§ó Transformers Tl;dr: This ...",
    "pubDate": "Tue, 01 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/asr-chunking",
    "thumbnail": "https://huggingface.co/blog/assets/49_asr_chunking/thumbnail.png"
  },
  {
    "title": "The Annotated Diffusion Model",
    "description": "",
    "summary": "The Annotated Diffusion Model In this blog post, we'll take a deeper look into Denoising Diffusion P...",
    "pubDate": "Tue, 07 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/annotated-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/78_annotated-diffusion/thumbnail.png"
  },
  {
    "title": "CinePile 2.0 - making stronger datasets with adversarial refinement",
    "description": "",
    "summary": "CinePile 2.0 - making stronger datasets with adversarial refinement In this blog post we share the j...",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cinepile2",
    "thumbnail": "https://huggingface.co/blog/assets/188_cinepile2/thumbnail.png"
  },
  {
    "title": "Getting Started with Sentiment Analysis on Twitter",
    "description": "",
    "summary": "Getting Started with Sentiment Analysis on Twitter Sentiment analysis is the automatic process of cl...",
    "pubDate": "Thu, 07 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-twitter",
    "thumbnail": "https://huggingface.co/blog/assets/85_sentiment_analysis_twitter/thumbnail.png"
  },
  {
    "title": "Releasing Swift Transformers: Run On-Device LLMs in Apple Devices",
    "description": "",
    "summary": "Releasing Swift Transformers: Run On-Device LLMs in Apple Devices I have a lot of respect for iOS/Ma...",
    "pubDate": "Tue, 08 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/swift-coreml-llm",
    "thumbnail": "https://huggingface.co/blog/assets/swift-coreml-llm/thumbnail.png"
  },
  {
    "title": "Disrupting a covert Iranian influence operation",
    "description": "We banned accounts linked to a covert Iranian influence operation using ChatGPT to generate website and social media content focused on multiple topics, including the U.S. presidential campaign. We have seen no indication that this content reached a meaningful audience.",
    "summary": "We banned accounts linked to a covert Iranian influence operation using ChatGPT to generate website and social media content focused on multiple topics, including the U.S. presidential campaign. We have seen no indication that this content reached a meaningful audience.",
    "pubDate": "Fri, 16 Aug 2024 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-a-covert-iranian-influence-operation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How NuminaMath Won the 1st AIMO Progress Prize",
    "description": "",
    "summary": "How NuminaMath Won the 1st AIMO Progress Prize This year, Numina and Hugging Face collaborated to co...",
    "pubDate": "Thu, 11 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/winning-aimo-progress-prize",
    "thumbnail": "https://huggingface.co/blog/assets/winning-aimo-progress-prize/thumbnail.png"
  },
  {
    "title": "Putting AI to work at Upwork",
    "description": "Upwork puts AI to work, uniting team members, operations and product development",
    "summary": "Upwork puts AI to work, uniting team members, operations and product development",
    "pubDate": "Tue, 20 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/upwork",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our next-generation model: Gemini 1.5",
    "description": "The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities.",
    "summary": "The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities.",
    "pubDate": "Thu, 15 Feb 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/our-next-generation-model-gemini-15/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/final_gemini_1.5_blog_social_share_800x418.width-1300.png"
  },
  {
    "title": "Comment on NTIA AI Accountability Policy",
    "description": "The National Telecommunications and Information Administration (NTIA) request for comments on AI Accountability policy.",
    "summary": "The National Telecommunications and Information Administration (NTIA) request for comments on AI Accountability policy.",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/comment-on-ntia-ai-accountability-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Green AI in Action: Strategic Model Selection for Ensembles in Production",
    "description": "arXiv:2405.17451v2 Announce Type: replace-cross Abstract: Integrating Artificial Intelligence (AI) into software systems has significantly enhanced their capabilities while escalating energy demands. Ensemble learning, combining predictions from multiple models to form a single prediction, intensifies this problem due to cumulative energy consumption. This paper presents a novel approach to model selection that addresses the challenge of balancing the accuracy of AI models with their energy consumption in a live AI ensemble system. We explore how reducing the number of models or improving the efficiency of model usage within an ensemble during inference can reduce energy demands without substantially sacrificing accuracy. This study introduces and evaluates two model selection strategies, Static and Dynamic, for optimizing ensemble learning systems performance while minimizing energy usage. Our results demonstrate that the Static strategy improves the F1 score beyond the baseline, reducing average energy usage from 100% from the full ensemble to 62%. The Dynamic strategy further enhances F1 scores, using on average 76% compared to 100% of the full ensemble. Moreover, we propose an approach that balances accuracy with resource consumption, significantly reducing energy usage without substantially impacting accuracy. This method decreased the average energy usage of the Static strategy from approximately 62% to 14%, and for the Dynamic strategy, from around 76% to 57%. Our field study of Green AI using an operational AI system developed by a large professional services provider shows the practical applicability of adopting energy-conscious model selection strategies in live production environments.",
    "summary": "arXiv:2405.17451v2 Announce Type: replace-cross Abstract: Integrating Artificial Intelligence (AI) into software systems has significantly enhanced their capabilities while escalating energy demands. Ensemble learning, combining predictions from multiple models to form a single prediction, intensifies this problem due to cumulative energy consumption. This paper presents a novel approach to model selection that addresses the challenge of balancing the accuracy of AI models with their energy consumption in a live AI ensemble system. We explore how reducing the number of models or improving the efficiency of model usage within an ensemble during inference can reduce energy demands without substantially sacrificing accuracy. This study introduces and evaluates two model selection strategies, Static and Dynamic, for optimizing ensemble learning systems performance while minimizing energy usage. Our results demonstrate that the Static strategy improves the F1 score beyond the baseline, reducing average energy usage from 100% from the full ensemble to 62%. The Dynamic strategy further enhances F1 scores, using on average 76% compared to 100% of the full ensemble. Moreover, we propose an approach that balances accuracy with resource consumption, significantly reducing energy usage without substantially impacting accuracy. This method decreased the average energy usage of the Static strategy from approximately 62% to 14%, and for the Dynamic strategy, from around 76% to 57%. Our field study of Green AI using an operational AI system developed by a large professional services provider shows the practical applicability of adopting energy-conscious model selection strategies in live production environments.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.17451",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Optimum-NVIDIA - Unlock blazingly fast LLM inference in just 1 line of code",
    "description": "",
    "summary": "Optimum-NVIDIA on Hugging Face enables blazingly fast LLM inference in just 1 line of code Large Lan...",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-nvidia",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_nvidia/hf_nvidia_banner.png"
  },
  {
    "title": "Awakening Sleeping Beauties at The Met",
    "description": "AI can enrich lives through beauty and creativity, and its artistic potential shines in 'Sleeping Beauties: Reawakening Fashion,' a collaborative exhibit from The Met's Costume Institute.",
    "summary": "AI can enrich lives through beauty and creativity, and its artistic potential shines in 'Sleeping Beauties: Reawakening Fashion,' a collaborative exhibit from The Met's Costume Institute.",
    "pubDate": "Wed, 14 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-met-museum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeMaterial: an open source initiative to accelerate materials discovery and research",
    "description": "",
    "summary": "LeMaterial: an open source initiative to accelerate materials discovery and research Today, we are t...",
    "pubDate": "Tue, 10 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lematerial",
    "thumbnail": "https://huggingface.co/blog/assets/lematerial/thumbnail_lematerial.png"
  },
  {
    "title": "SmolVLA: Efficient Vision-Language-Action Model trained on Lerobot Community Data",
    "description": "",
    "summary": "SmolVLA: Efficient Vision-Language-Action Model trained on Lerobot Community Data üß≠TL;DR Today, we i...",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvla",
    "thumbnail": "https://huggingface.co/blog/assets/smolvla/SmolVLA_thumbnail.png"
  },
  {
    "title": "Spinning Up in Deep RL: Workshop review",
    "description": "On February 2, we held our first Spinning Up Workshop as part of our new education initiative at OpenAI.",
    "summary": "On February 2, we held our first Spinning Up Workshop as part of our new education initiative at OpenAI.",
    "pubDate": "Tue, 26 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spinning-up-in-deep-rl-workshop-review",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "BayesLoRA: Task-Specific Uncertainty in Low-Rank Adapters",
    "description": "arXiv:2506.22809v1 Announce Type: cross Abstract: We propose BayesLoRA, a task-specific uncertainty quantification framework that integrates MC-Dropout into Low-Rank Adapters (LoRA). Unlike general-purpose transformer uncertainty methods, BayesLoRA provides guardrails tailored to downstream workflows, enabling agents to introspect and modulate behavior under uncertainty. We demonstrate mathematically and empirically that LoRA adapters exhibit amplified variance outside fine-tuning distributions, yielding reliable confidence estimates for agentic decision-making.",
    "summary": "arXiv:2506.22809v1 Announce Type: cross Abstract: We propose BayesLoRA, a task-specific uncertainty quantification framework that integrates MC-Dropout into Low-Rank Adapters (LoRA). Unlike general-purpose transformer uncertainty methods, BayesLoRA provides guardrails tailored to downstream workflows, enabling agents to introspect and modulate behavior under uncertainty. We demonstrate mathematically and empirically that LoRA adapters exhibit amplified variance outside fine-tuning distributions, yielding reliable confidence estimates for agentic decision-making.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22809",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome Mixtral - a SOTA Mixture of Experts on Hugging Face",
    "description": "",
    "summary": "Welcome Mixtral - a SOTA Mixture of Experts on Hugging Face Mixtral 8x7b is an exciting large langua...",
    "pubDate": "Mon, 11 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mixtral",
    "thumbnail": "https://huggingface.co/blog/assets/mixtral/thumbnail.jpg"
  },
  {
    "title": "Deprecation of Git Authentication using password",
    "description": "",
    "summary": "Hugging Face Hub: Important Git Authentication Changes Because we are committed to improving the sec...",
    "pubDate": "Fri, 25 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/password-git-deprecation",
    "thumbnail": "https://huggingface.co/blog/assets/password-git-deprecation/thumbnail.png"
  },
  {
    "title": "Improving language model behavior by training on a curated dataset",
    "description": "Our latest research finds we can improve language model behavior with respect to specific behavioral values by fine-tuning on a small, curated¬†dataset.",
    "summary": "Our latest research finds we can improve language model behavior with respect to specific behavioral values by fine-tuning on a small, curated¬†dataset.",
    "pubDate": "Thu, 10 Jun 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-language-model-behavior",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ü§ó PEFT welcomes new merging methods",
    "description": "",
    "summary": "ü§ó PEFT welcomes new merging methods Model merging has quickly become the de-facto standard of pushin...",
    "pubDate": "Mon, 19 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/peft_merging",
    "thumbnail": "https://huggingface.co/blog/assets/peft_merging/thumbnail.png"
  },
  {
    "title": "Learning policy representations in multiagent systems",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 17 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-policy-representations-in-multiagent-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Adversarial attacks on neural network policies",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 Feb 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adversarial-attacks-on-neural-network-policies",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "System-Embedded Diffusion Bridge Models",
    "description": "arXiv:2506.23726v1 Announce Type: cross Abstract: Solving inverse problems -- recovering signals from incomplete or noisy measurements -- is fundamental in science and engineering. Score-based generative models (SGMs) have recently emerged as a powerful framework for this task. Two main paradigms have formed: unsupervised approaches that adapt pretrained generative models to inverse problems, and supervised bridge methods that train stochastic processes conditioned on paired clean and corrupted data. While the former typically assume knowledge of the measurement model, the latter have largely overlooked this structural information. We introduce System embedded Diffusion Bridge Models (SDBs), a new class of supervised bridge methods that explicitly embed the known linear measurement system into the coefficients of a matrix-valued SDE. This principled integration yields consistent improvements across diverse linear inverse problems and demonstrates robust generalization under system misspecification between training and deployment, offering a promising solution to real-world applications.",
    "summary": "arXiv:2506.23726v1 Announce Type: cross Abstract: Solving inverse problems -- recovering signals from incomplete or noisy measurements -- is fundamental in science and engineering. Score-based generative models (SGMs) have recently emerged as a powerful framework for this task. Two main paradigms have formed: unsupervised approaches that adapt pretrained generative models to inverse problems, and supervised bridge methods that train stochastic processes conditioned on paired clean and corrupted data. While the former typically assume knowledge of the measurement model, the latter have largely overlooked this structural information. We introduce System embedded Diffusion Bridge Models (SDBs), a new class of supervised bridge methods that explicitly embed the known linear measurement system into the coefficients of a matrix-valued SDE. This principled integration yields consistent improvements across diverse linear inverse problems and demonstrates robust generalization under system misspecification between training and deployment, offering a promising solution to real-world applications.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23726",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Bridging Subjective and Objective QoE: Operator-Level Aggregation Using LLM-Based Comment Analysis and Network MOS Comparison",
    "description": "arXiv:2506.00924v2 Announce Type: replace-cross Abstract: This paper introduces a dual-layer framework for network operator-side quality of experience (QoE) assessment that integrates both objective network modeling and subjective user perception extracted from live-streaming platforms. On the objective side, we develop a machine learning model trained on mean opinion scores (MOS) computed via the ITU-T P.1203 reference implementation, allowing accurate prediction of user-perceived video quality using only network parameters such as packet loss, delay, jitter, and throughput without reliance on video content or client-side instrumentation. On the subjective side, we present a semantic filtering and scoring pipeline that processes user comments from live streams to extract performance-related feedback. A large language model is used to assign scalar MOS scores to filtered comments in a deterministic and reproducible manner. To support scalable and interpretable analysis, we construct a labeled dataset of 47,894 live-stream comments, of which about 34,000 are identified as QoE-relevant through multi-layer semantic filtering. Each comment is enriched with simulated Internet Service Provider attribution and temporally aligned using synthetic timestamps in 5-min intervals. The resulting dataset enables operator-level aggregation and time-series analysis of user-perceived quality. A delta MOS metric is proposed to measure each Internet service provider's deviation from platform-wide sentiment, allowing detection of localized degradations even in the absence of direct network telemetry. A controlled outage simulation confirms the framework's effectiveness in identifying service disruptions through comment-based trends alone. The system provides each operator with its own subjective MOS and the global platform average per interval, enabling real-time interpretation of performance deviations and comparison with objective network-based QoE estimates.",
    "summary": "arXiv:2506.00924v2 Announce Type: replace-cross Abstract: This paper introduces a dual-layer framework for network operator-side quality of experience (QoE) assessment that integrates both objective network modeling and subjective user perception extracted from live-streaming platforms. On the objective side, we develop a machine learning model trained on mean opinion scores (MOS) computed via the ITU-T P.1203 reference implementation, allowing accurate prediction of user-perceived video quality using only network parameters such as packet loss, delay, jitter, and throughput without reliance on video content or client-side instrumentation. On the subjective side, we present a semantic filtering and scoring pipeline that processes user comments from live streams to extract performance-related feedback. A large language model is used to assign scalar MOS scores to filtered comments in a deterministic and reproducible manner. To support scalable and interpretable analysis, we construct a labeled dataset of 47,894 live-stream comments, of which about 34,000 are identified as QoE-relevant through multi-layer semantic filtering. Each comment is enriched with simulated Internet Service Provider attribution and temporally aligned using synthetic timestamps in 5-min intervals. The resulting dataset enables operator-level aggregation and time-series analysis of user-perceived quality. A delta MOS metric is proposed to measure each Internet service provider's deviation from platform-wide sentiment, allowing detection of localized degradations even in the absence of direct network telemetry. A controlled outage simulation confirms the framework's effectiveness in identifying service disruptions through comment-based trends alone. The system provides each operator with its own subjective MOS and the global platform average per interval, enabling real-time interpretation of performance deviations and comparison with objective network-based QoE estimates.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.00924",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FedWSQ: Efficient Federated Learning with Weight Standardization and Distribution-Aware Non-Uniform Quantization",
    "description": "arXiv:2506.23516v1 Announce Type: cross Abstract: Federated learning (FL) often suffers from performance degradation due to key challenges such as data heterogeneity and communication constraints. To address these limitations, we present a novel FL framework called FedWSQ, which integrates weight standardization (WS) and the proposed distribution-aware non-uniform quantization (DANUQ). WS enhances FL performance by filtering out biased components in local updates during training, thereby improving the robustness of the model against data heterogeneity and unstable client participation. In addition, DANUQ minimizes quantization errors by leveraging the statistical properties of local model updates. As a result, FedWSQ significantly reduces communication overhead while maintaining superior model accuracy. Extensive experiments on FL benchmark datasets demonstrate that FedWSQ consistently outperforms existing FL methods across various challenging FL settings, including extreme data heterogeneity and ultra-low-bit communication scenarios.",
    "summary": "arXiv:2506.23516v1 Announce Type: cross Abstract: Federated learning (FL) often suffers from performance degradation due to key challenges such as data heterogeneity and communication constraints. To address these limitations, we present a novel FL framework called FedWSQ, which integrates weight standardization (WS) and the proposed distribution-aware non-uniform quantization (DANUQ). WS enhances FL performance by filtering out biased components in local updates during training, thereby improving the robustness of the model against data heterogeneity and unstable client participation. In addition, DANUQ minimizes quantization errors by leveraging the statistical properties of local model updates. As a result, FedWSQ significantly reduces communication overhead while maintaining superior model accuracy. Extensive experiments on FL benchmark datasets demonstrate that FedWSQ consistently outperforms existing FL methods across various challenging FL settings, including extreme data heterogeneity and ultra-low-bit communication scenarios.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23516",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Intelligence Age",
    "description": "We aired our first-ever television ad during the Super Bowl to pique people‚Äôs curiosity and help us all realize how AI can open up new possibilities for us, create more fulfillment in our lives, and make us more productive, just as all the tools that came before AI did for those who came before us.",
    "summary": "We aired our first-ever television ad during the Super Bowl to pique people‚Äôs curiosity and help us all realize how AI can open up new possibilities for us, create more fulfillment in our lives, and make us more productive, just as all the tools that came before AI did for those who came before us.",
    "pubDate": "Sun, 09 Feb 2025 22:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-the-intelligence-age",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "#Exploration: A study of count-based exploration for deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 15 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/exploration",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Cosmopedia: how to create large-scale synthetic data for pre-training Large Language Models",
    "description": "",
    "summary": "Cosmopedia: how to create large-scale synthetic data for pre-training In this blog post, we outline ...",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cosmopedia",
    "thumbnail": "https://huggingface.co/blog/assets/cosmopedia/thumbnail.png"
  },
  {
    "title": "Data is better together",
    "description": "",
    "summary": "Data is better together: Enabling communities to collectively build better datasets together using A...",
    "pubDate": "Mon, 04 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/community-datasets/thumbnail.png"
  },
  {
    "title": "FF-INT8: Efficient Forward-Forward DNN Training on Edge Devices with INT8 Precision",
    "description": "arXiv:2506.22771v1 Announce Type: cross Abstract: Backpropagation has been the cornerstone of neural network training for decades, yet its inefficiencies in time and energy consumption limit its suitability for resource-constrained edge devices. While low-precision neural network quantization has been extensively researched to speed up model inference, its application in training has been less explored. Recently, the Forward-Forward (FF) algorithm has emerged as a promising alternative to backpropagation, replacing the backward pass with an additional forward pass. By avoiding the need to store intermediate activations for backpropagation, FF can reduce memory footprint, making it well-suited for embedded devices. This paper presents an INT8 quantized training approach that leverages FF's layer-by-layer strategy to stabilize gradient quantization. Furthermore, we propose a novel 'look-ahead' scheme to address limitations of FF and improve model accuracy. Experiments conducted on NVIDIA Jetson Orin Nano board demonstrate 4.6% faster training, 8.3% energy savings, and 27.0% reduction in memory usage, while maintaining competitive accuracy compared to the state-of-the-art.",
    "summary": "arXiv:2506.22771v1 Announce Type: cross Abstract: Backpropagation has been the cornerstone of neural network training for decades, yet its inefficiencies in time and energy consumption limit its suitability for resource-constrained edge devices. While low-precision neural network quantization has been extensively researched to speed up model inference, its application in training has been less explored. Recently, the Forward-Forward (FF) algorithm has emerged as a promising alternative to backpropagation, replacing the backward pass with an additional forward pass. By avoiding the need to store intermediate activations for backpropagation, FF can reduce memory footprint, making it well-suited for embedded devices. This paper presents an INT8 quantized training approach that leverages FF's layer-by-layer strategy to stabilize gradient quantization. Furthermore, we propose a novel 'look-ahead' scheme to address limitations of FF and improve model accuracy. Experiments conducted on NVIDIA Jetson Orin Nano board demonstrate 4.6% faster training, 8.3% energy savings, and 27.0% reduction in memory usage, while maintaining competitive accuracy compared to the state-of-the-art.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22771",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Hidden Link Between RLHF and Contrastive Learning",
    "description": "arXiv:2506.22578v1 Announce Type: cross Abstract: Alignment of large language models (LLMs) with human values has recently garnered significant attention, with prominent examples including the canonical yet costly Reinforcement Learning from Human Feedback (RLHF) and the simple Direct Preference Optimization (DPO). In this work, we demonstrate that both RLHF and DPO can be interpreted from the perspective of mutual information (MI) maximization, uncovering a profound connection to contrastive learning. Within this framework, both RLHF and DPO can be viewed as methods that perform contrastive learning based on the positive and negative samples derived from the base model, leveraging the Donsker-Varadhan (DV) lower bound on MI (equivalently, the MINE estimator). This paradigm further explains why RLHF may not intrinsically incentivize reasoning capacities in LLMs beyond what is already present in the base model. Building on this perspective, we replace the DV/MINE bound with the Jensen-Shannon MI estimator and propose Mutual Information Optimization (MIO). Comprehensive theoretical analysis and extensive empirical evaluations demonstrate that MIO mitigates the late-stage decline in chosen-likelihood observed in DPO, achieving competitive or superior performance across various challenging reasoning and mathematical benchmarks. We will release the model and code upon acceptance.",
    "summary": "arXiv:2506.22578v1 Announce Type: cross Abstract: Alignment of large language models (LLMs) with human values has recently garnered significant attention, with prominent examples including the canonical yet costly Reinforcement Learning from Human Feedback (RLHF) and the simple Direct Preference Optimization (DPO). In this work, we demonstrate that both RLHF and DPO can be interpreted from the perspective of mutual information (MI) maximization, uncovering a profound connection to contrastive learning. Within this framework, both RLHF and DPO can be viewed as methods that perform contrastive learning based on the positive and negative samples derived from the base model, leveraging the Donsker-Varadhan (DV) lower bound on MI (equivalently, the MINE estimator). This paradigm further explains why RLHF may not intrinsically incentivize reasoning capacities in LLMs beyond what is already present in the base model. Building on this perspective, we replace the DV/MINE bound with the Jensen-Shannon MI estimator and propose Mutual Information Optimization (MIO). Comprehensive theoretical analysis and extensive empirical evaluations demonstrate that MIO mitigates the late-stage decline in chosen-likelihood observed in DPO, achieving competitive or superior performance across various challenging reasoning and mathematical benchmarks. We will release the model and code upon acceptance.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22578",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI learns how vision and sound are connected, without human intervention",
    "description": "This new machine-learning model can match corresponding audio and visual data, which could someday help robots interact in the real world.",
    "summary": "This new machine-learning model can match corresponding audio and visual data, which could someday help robots interact in the real world.",
    "pubDate": "Thu, 22 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-learns-how-vision-and-sound-are-connected-without-human-intervention-0522",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-AV-Learning-01-press.jpg"
  },
  {
    "title": "A Survey on Model Extraction Attacks and Defenses for Large Language Models",
    "description": "arXiv:2506.22521v1 Announce Type: cross Abstract: Model extraction attacks pose significant security threats to deployed language models, potentially compromising intellectual property and user privacy. This survey provides a comprehensive taxonomy of LLM-specific extraction attacks and defenses, categorizing attacks into functionality extraction, training data extraction, and prompt-targeted attacks. We analyze various attack methodologies including API-based knowledge distillation, direct querying, parameter recovery, and prompt stealing techniques that exploit transformer architectures. We then examine defense mechanisms organized into model protection, data privacy protection, and prompt-targeted strategies, evaluating their effectiveness across different deployment scenarios. We propose specialized metrics for evaluating both attack effectiveness and defense performance, addressing the specific challenges of generative language models. Through our analysis, we identify critical limitations in current approaches and propose promising research directions, including integrated attack methodologies and adaptive defense mechanisms that balance security with model utility. This work serves NLP researchers, ML engineers, and security professionals seeking to protect language models in production environments.",
    "summary": "arXiv:2506.22521v1 Announce Type: cross Abstract: Model extraction attacks pose significant security threats to deployed language models, potentially compromising intellectual property and user privacy. This survey provides a comprehensive taxonomy of LLM-specific extraction attacks and defenses, categorizing attacks into functionality extraction, training data extraction, and prompt-targeted attacks. We analyze various attack methodologies including API-based knowledge distillation, direct querying, parameter recovery, and prompt stealing techniques that exploit transformer architectures. We then examine defense mechanisms organized into model protection, data privacy protection, and prompt-targeted strategies, evaluating their effectiveness across different deployment scenarios. We propose specialized metrics for evaluating both attack effectiveness and defense performance, addressing the specific challenges of generative language models. Through our analysis, we identify critical limitations in current approaches and propose promising research directions, including integrated attack methodologies and adaptive defense mechanisms that balance security with model utility. This work serves NLP researchers, ML engineers, and security professionals seeking to protect language models in production environments.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22521",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel",
    "description": "",
    "summary": "Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel In this post we will look ...",
    "pubDate": "Mon, 02 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-fsdp",
    "thumbnail": "https://huggingface.co/blog/assets/62_pytorch_fsdp/fsdp-thumbnail.png"
  },
  {
    "title": "Graph Classification with Transformers",
    "description": "",
    "summary": "Graph classification with Transformers In the previous blog, we explored some of the theoretical asp...",
    "pubDate": "Fri, 14 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphml-classification",
    "thumbnail": "https://huggingface.co/blog/assets/125_intro-to-graphml/thumbnail_classification.png"
  },
  {
    "title": "OpenAI supporters",
    "description": "We‚Äôre excited to welcome new donors to OpenAI.",
    "summary": "We‚Äôre excited to welcome new donors to OpenAI.",
    "pubDate": "Tue, 20 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-supporters",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Run a Chatgpt-like Chatbot on a Single GPU with ROCm",
    "description": "",
    "summary": "Run a Chatgpt-like Chatbot on a Single GPU with ROCm Introduction ChatGPT, OpenAI's groundbreaking l...",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chatbot-amd-gpu",
    "thumbnail": "https://huggingface.co/blog/assets/chatbot-amd-gpu/thumbnail.png"
  },
  {
    "title": "Introducing the Open Ko-LLM Leaderboard: Leading the Korean LLM Evaluation Ecosystem",
    "description": "",
    "summary": "Introducing the Open Ko-LLM Leaderboard: Leading the Korean LLM Evaluation Ecosystem In the fast-evo...",
    "pubDate": "Tue, 20 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-upstage",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_upstage.png"
  },
  {
    "title": "Visual Position Prompt for MLLM based Visual Grounding",
    "description": "arXiv:2503.15426v3 Announce Type: replace-cross Abstract: Although Multimodal Large Language Models (MLLMs) excel at various image-related tasks, they encounter challenges in precisely aligning coordinates with spatial information within images, particularly in position-aware tasks such as visual grounding. This limitation arises from two key factors. First, MLLMs lack explicit spatial references, making it difficult to associate textual descriptions with precise image locations. Second, their feature extraction processes prioritize global context over fine-grained spatial details, leading to weak localization capability. To address these issues, we introduce VPP-LLaVA, an MLLM enhanced with Visual Position Prompt (VPP) to improve its grounding capability. VPP-LLaVA integrates two complementary mechanisms: the global VPP overlays a learnable, axis-like tensor onto the input image to provide structured spatial cues, while the local VPP incorporates position-aware queries to support fine-grained localization.To effectively train our model with spatial guidance, we further introduce VPP-SFT, a curated dataset of 0.6M high-quality visual grounding samples. Designed in a compact format, it enables efficient training and is significantly smaller than datasets used by other MLLMs (e.g., ~21M samples in MiniGPT-v2), yet still provides a strong performance boost. The resulting model, VPP-LLaVA, not only achieves state-of-the-art results on standard visual grounding benchmarks but also demonstrates strong zero-shot generalization to challenging unseen datasets. Code and dataset will be released upon acceptance at https://github.com/WayneTomas/VPP-LLaVA.",
    "summary": "arXiv:2503.15426v3 Announce Type: replace-cross Abstract: Although Multimodal Large Language Models (MLLMs) excel at various image-related tasks, they encounter challenges in precisely aligning coordinates with spatial information within images, particularly in position-aware tasks such as visual grounding. This limitation arises from two key factors. First, MLLMs lack explicit spatial references, making it difficult to associate textual descriptions with precise image locations. Second, their feature extraction processes prioritize global context over fine-grained spatial details, leading to weak localization capability. To address these issues, we introduce VPP-LLaVA, an MLLM enhanced with Visual Position Prompt (VPP) to improve its grounding capability. VPP-LLaVA integrates two complementary mechanisms: the global VPP overlays a learnable, axis-like tensor onto the input image to provide structured spatial cues, while the local VPP incorporates position-aware queries to support fine-grained localization.To effectively train our model with spatial guidance, we further introduce VPP-SFT, a curated dataset of 0.6M high-quality visual grounding samples. Designed in a compact format, it enables efficient training and is significantly smaller than datasets used by other MLLMs (e.g., ~21M samples in MiniGPT-v2), yet still provides a strong performance boost. The resulting model, VPP-LLaVA, not only achieves state-of-the-art results on standard visual grounding benchmarks but also demonstrates strong zero-shot generalization to challenging unseen datasets. Code and dataset will be released upon acceptance at https://github.com/WayneTomas/VPP-LLaVA.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.15426",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "New AI classifier for indicating AI-written text",
    "description": "We‚Äôre launching a classifier trained to distinguish between AI-written and human-written¬†text.",
    "summary": "We‚Äôre launching a classifier trained to distinguish between AI-written and human-written¬†text.",
    "pubDate": "Tue, 31 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "3 Questions: How to help students recognize potential bias in their AI datasets",
    "description": "Courses on developing AI models for health care need to focus more on identifying and addressing bias, says Leo Anthony Celi.",
    "summary": "Courses on developing AI models for health care need to focus more on identifying and addressing bias, says Leo Anthony Celi.",
    "pubDate": "Mon, 02 Jun 2025 10:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/3-questions-recognizing-potential-bias-in-ai-datasets-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_AI-Health-Data-01.jpg"
  },
  {
    "title": "Introducing the AMD 5th Gen EPYC‚Ñ¢ CPU",
    "description": "",
    "summary": "Introducing the AMD 5th Gen EPYC‚Ñ¢ CPU AMD has just unveiled its 5th generation of server-grade EPYC ...",
    "pubDate": "Thu, 10 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-amd-turin",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "Experimenting with Automatic PII Detection on the Hub using Presidio",
    "description": "",
    "summary": "Experimenting with Automatic PII Detection on the Hub using Presidio At Hugging Face, we've noticed ...",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/presidio-pii-detection",
    "thumbnail": "https://huggingface.co/blog/assets/presidio-pii-detection/thumbnail.png"
  },
  {
    "title": "OpenAI Baselines: ACKTR & A2C",
    "description": "We‚Äôre releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic variant of Asynchronous Advantage Actor Critic (A3C) which we‚Äôve found gives equal performance. ACKTR is a more sample-efficient reinforcement learning algorithm than TRPO and A2C, and requires only slightly more computation than A2C per update.",
    "summary": "We‚Äôre releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic variant of Asynchronous Advantage Actor Critic (A3C) which we‚Äôve found gives equal performance. ACKTR is a more sample-efficient reinforcement learning algorithm than TRPO and A2C, and requires only slightly more computation than A2C per update.",
    "pubDate": "Fri, 18 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-acktr-a2c",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Single-Frame Point-Pixel Registration via Supervised Cross-Modal Feature Matching",
    "description": "arXiv:2506.22784v1 Announce Type: cross Abstract: Point-pixel registration between LiDAR point clouds and camera images is a fundamental yet challenging task in autonomous driving and robotic perception. A key difficulty lies in the modality gap between unstructured point clouds and structured images, especially under sparse single-frame LiDAR settings. Existing methods typically extract features separately from point clouds and images, then rely on hand-crafted or learned matching strategies. This separate encoding fails to bridge the modality gap effectively, and more critically, these methods struggle with the sparsity and noise of single-frame LiDAR, often requiring point cloud accumulation or additional priors to improve reliability. Inspired by recent progress in detector-free matching paradigms (e.g. MatchAnything), we revisit the projection-based approach and introduce the detector-free framework for direct point-pixel matching between LiDAR and camera views. Specifically, we project the LiDAR intensity map into a 2D view from the LiDAR perspective and feed it into an attention-based detector-free matching network, enabling cross-modal correspondence estimation without relying on multi-frame accumulation. To further enhance matching reliability, we introduce a repeatability scoring mechanism that acts as a soft visibility prior. This guides the network to suppress unreliable matches in regions with low intensity variation, improving robustness under sparse input. Extensive experiments on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks demonstrate that our method achieves state-of-the-art performance, outperforming prior approaches on nuScenes (even those relying on accumulated point clouds), despite using only single-frame LiDAR.",
    "summary": "arXiv:2506.22784v1 Announce Type: cross Abstract: Point-pixel registration between LiDAR point clouds and camera images is a fundamental yet challenging task in autonomous driving and robotic perception. A key difficulty lies in the modality gap between unstructured point clouds and structured images, especially under sparse single-frame LiDAR settings. Existing methods typically extract features separately from point clouds and images, then rely on hand-crafted or learned matching strategies. This separate encoding fails to bridge the modality gap effectively, and more critically, these methods struggle with the sparsity and noise of single-frame LiDAR, often requiring point cloud accumulation or additional priors to improve reliability. Inspired by recent progress in detector-free matching paradigms (e.g. MatchAnything), we revisit the projection-based approach and introduce the detector-free framework for direct point-pixel matching between LiDAR and camera views. Specifically, we project the LiDAR intensity map into a 2D view from the LiDAR perspective and feed it into an attention-based detector-free matching network, enabling cross-modal correspondence estimation without relying on multi-frame accumulation. To further enhance matching reliability, we introduce a repeatability scoring mechanism that acts as a soft visibility prior. This guides the network to suppress unreliable matches in regions with low intensity variation, improving robustness under sparse input. Extensive experiments on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks demonstrate that our method achieves state-of-the-art performance, outperforming prior approaches on nuScenes (even those relying on accumulated point clouds), despite using only single-frame LiDAR.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22784",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents",
    "description": "arXiv:2506.23844v1 Announce Type: new Abstract: Recent advances in large language models (LLMs) have catalyzed the rise of autonomous AI agents capable of perceiving, reasoning, and acting in dynamic, open-ended environments. These large-model agents mark a paradigm shift from static inference systems to interactive, memory-augmented entities. While these capabilities significantly expand the functional scope of AI, they also introduce qualitatively novel security risks - such as memory poisoning, tool misuse, reward hacking, and emergent misalignment - that extend beyond the threat models of conventional systems or standalone LLMs. In this survey, we first examine the structural foundations and key capabilities that underpin increasing levels of agent autonomy, including long-term memory retention, modular tool use, recursive planning, and reflective reasoning. We then analyze the corresponding security vulnerabilities across the agent stack, identifying failure modes such as deferred decision hazards, irreversible tool chains, and deceptive behaviors arising from internal state drift or value misalignment. These risks are traced to architectural fragilities that emerge across perception, cognition, memory, and action modules. To address these challenges, we systematically review recent defense strategies deployed at different autonomy layers, including input sanitization, memory lifecycle control, constrained decision-making, structured tool invocation, and introspective reflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a unified cognitive framework grounded in Constrained Markov Decision Processes (CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation, and joint reward-risk optimization to enable principled, proactive safety across the agent's decision-making loop.",
    "summary": "arXiv:2506.23844v1 Announce Type: new Abstract: Recent advances in large language models (LLMs) have catalyzed the rise of autonomous AI agents capable of perceiving, reasoning, and acting in dynamic, open-ended environments. These large-model agents mark a paradigm shift from static inference systems to interactive, memory-augmented entities. While these capabilities significantly expand the functional scope of AI, they also introduce qualitatively novel security risks - such as memory poisoning, tool misuse, reward hacking, and emergent misalignment - that extend beyond the threat models of conventional systems or standalone LLMs. In this survey, we first examine the structural foundations and key capabilities that underpin increasing levels of agent autonomy, including long-term memory retention, modular tool use, recursive planning, and reflective reasoning. We then analyze the corresponding security vulnerabilities across the agent stack, identifying failure modes such as deferred decision hazards, irreversible tool chains, and deceptive behaviors arising from internal state drift or value misalignment. These risks are traced to architectural fragilities that emerge across perception, cognition, memory, and action modules. To address these challenges, we systematically review recent defense strategies deployed at different autonomy layers, including input sanitization, memory lifecycle control, constrained decision-making, structured tool invocation, and introspective reflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a unified cognitive framework grounded in Constrained Markov Decision Processes (CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation, and joint reward-risk optimization to enable principled, proactive safety across the agent's decision-making loop.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23844",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Scaling Kubernetes to 7,500 nodes",
    "description": "We‚Äôve scaled Kubernetes clusters to 7,500 nodes, producing a scalable infrastructure for large models like¬†GPT-3,¬†CLIP, and¬†DALL¬∑E, but also for rapid small-scale iterative research such as¬†Scaling Laws for Neural Language Models.",
    "summary": "We‚Äôve scaled Kubernetes clusters to 7,500 nodes, producing a scalable infrastructure for large models like¬†GPT-3,¬†CLIP, and¬†DALL¬∑E, but also for rapid small-scale iterative research such as¬†Scaling Laws for Neural Language Models.",
    "pubDate": "Mon, 25 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-kubernetes-to-7500-nodes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Decision Transformers on Hugging Face ü§ó",
    "description": "",
    "summary": "Introducing Decision Transformers on Hugging Face ü§ó At Hugging Face, we are contributing to the ecos...",
    "pubDate": "Mon, 28 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/decision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/58_decision-transformers/thumbnail.jpg"
  },
  {
    "title": "DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues",
    "description": "arXiv:2506.22853v1 Announce Type: cross Abstract: Existing function-calling benchmarks focus on single-turn interactions. However, they overlook the complexity of real-world scenarios. To quantify how existing benchmarks address practical applications, we introduce DICE-SCORE, a metric that evaluates the dispersion of tool-related information such as function name and parameter values throughout the dialogue. Analyzing existing benchmarks through DICE-SCORE reveals notably low scores, highlighting the need for more realistic scenarios. To address this gap, we present DICE-BENCH, a framework that constructs practical function-calling datasets by synthesizing conversations through a tool graph that maintains dependencies across rounds and a multi-agent system with distinct personas to enhance dialogue naturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our experiments on 19 LLMs with DICE-BENCH show that significant advances are still required before such models can be deployed effectively in real-world settings. Our code and data are all publicly available: https://snuhcc.github.io/DICE-Bench/.",
    "summary": "arXiv:2506.22853v1 Announce Type: cross Abstract: Existing function-calling benchmarks focus on single-turn interactions. However, they overlook the complexity of real-world scenarios. To quantify how existing benchmarks address practical applications, we introduce DICE-SCORE, a metric that evaluates the dispersion of tool-related information such as function name and parameter values throughout the dialogue. Analyzing existing benchmarks through DICE-SCORE reveals notably low scores, highlighting the need for more realistic scenarios. To address this gap, we present DICE-BENCH, a framework that constructs practical function-calling datasets by synthesizing conversations through a tool graph that maintains dependencies across rounds and a multi-agent system with distinct personas to enhance dialogue naturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our experiments on 19 LLMs with DICE-BENCH show that significant advances are still required before such models can be deployed effectively in real-world settings. Our code and data are all publicly available: https://snuhcc.github.io/DICE-Bench/.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22853",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI and Apple announce partnership",
    "description": "OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences.",
    "summary": "OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences.",
    "pubDate": "Mon, 10 Jun 2024 11:55:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-apple-announce-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ethics and Society Newsletter #6: Building Better AI: The Importance of Data Quality",
    "description": "",
    "summary": "Ethics and Society Newsletter #6: Building Better AI: The Importance of Data Quality In February, Re...",
    "pubDate": "Mon, 24 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-6",
    "thumbnail": "https://huggingface.co/blog/assets/182_ethics-soc-6/thumbnail.png"
  },
  {
    "title": "Planning for AGI and beyond",
    "description": "Our mission is to ensure that artificial general intelligence‚ÄîAI systems that are generally smarter than humans‚Äîbenefits all of¬†humanity.",
    "summary": "Our mission is to ensure that artificial general intelligence‚ÄîAI systems that are generally smarter than humans‚Äîbenefits all of¬†humanity.",
    "pubDate": "Fri, 24 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/planning-for-agi-and-beyond",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reinforcement learning with prediction-based rewards",
    "description": "We‚Äôve developed¬†Random Network Distillation (RND), a prediction-based method for encouraging reinforcement learning agents to explore their environments through curiosity, which for the first time exceeds average human performance on¬†Montezuma‚Äôs Revenge.",
    "summary": "We‚Äôve developed¬†Random Network Distillation (RND), a prediction-based method for encouraging reinforcement learning agents to explore their environments through curiosity, which for the first time exceeds average human performance on¬†Montezuma‚Äôs Revenge.",
    "pubDate": "Wed, 31 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reinforcement-learning-with-prediction-based-rewards",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Not All Explanations for Deep Learning Phenomena Are Equally Valuable",
    "description": "arXiv:2506.23286v1 Announce Type: cross Abstract: Developing a better understanding of surprising or counterintuitive phenomena has constituted a significant portion of deep learning research in recent years. These include double descent, grokking, and the lottery ticket hypothesis -- among many others. Works in this area often develop ad hoc hypotheses attempting to explain these observed phenomena on an isolated, case-by-case basis. This position paper asserts that, in many prominent cases, there is little evidence to suggest that these phenomena appear in real-world applications and these efforts may be inefficient in driving progress in the broader field. Consequently, we argue against viewing them as isolated puzzles that require bespoke resolutions or explanations. However, despite this, we suggest that deep learning phenomena do still offer research value by providing unique settings in which we can refine our broad explanatory theories of more general deep learning principles. This position is reinforced by analyzing the research outcomes of several prominent examples of these phenomena from the recent literature. We revisit the current norms in the research community in approaching these problems and propose practical recommendations for future research, aiming to ensure that progress on deep learning phenomena is well aligned with the ultimate pragmatic goal of progress in the broader field of deep learning.",
    "summary": "arXiv:2506.23286v1 Announce Type: cross Abstract: Developing a better understanding of surprising or counterintuitive phenomena has constituted a significant portion of deep learning research in recent years. These include double descent, grokking, and the lottery ticket hypothesis -- among many others. Works in this area often develop ad hoc hypotheses attempting to explain these observed phenomena on an isolated, case-by-case basis. This position paper asserts that, in many prominent cases, there is little evidence to suggest that these phenomena appear in real-world applications and these efforts may be inefficient in driving progress in the broader field. Consequently, we argue against viewing them as isolated puzzles that require bespoke resolutions or explanations. However, despite this, we suggest that deep learning phenomena do still offer research value by providing unique settings in which we can refine our broad explanatory theories of more general deep learning principles. This position is reinforced by analyzing the research outcomes of several prominent examples of these phenomena from the recent literature. We revisit the current norms in the research community in approaching these problems and propose practical recommendations for future research, aiming to ensure that progress on deep learning phenomena is well aligned with the ultimate pragmatic goal of progress in the broader field of deep learning.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23286",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Melding data, systems, and society",
    "description": "A new book from Professor Munther Dahleh details the creation of a unique kind of transdisciplinary center, uniting many specialties through a common need for data science.",
    "summary": "A new book from Professor Munther Dahleh details the creation of a unique kind of transdisciplinary center, uniting many specialties through a common need for data science.",
    "pubDate": "Tue, 10 Jun 2025 14:25:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/data-systems-and-society-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Data-Systems-Dahleh-book.jpg"
  },
  {
    "title": "Practical 3D Asset Generation: A Step-by-Step Guide",
    "description": "",
    "summary": "Practical 3D Asset Generation: A Step-by-Step Guide Introduction Generative AI has become an instrum...",
    "pubDate": "Tue, 01 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/3d-assets",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail-3d.jpg"
  },
  {
    "title": "Japanese Stable Diffusion",
    "description": "",
    "summary": "Japanese Stable Diffusion Stable Diffusion, developed by CompVis, Stability AI, and LAION, has gener...",
    "pubDate": "Wed, 05 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/japanese-stable-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/106_japanese_stable_diffusion/jsd_thumbnail.png"
  },
  {
    "title": "How we really judge AI",
    "description": "Forget optimists vs. Luddites. Most people evaluate AI based on its perceived capability and their need for personalization.",
    "summary": "Forget optimists vs. Luddites. Most people evaluate AI based on its perceived capability and their need for personalization.",
    "pubDate": "Tue, 10 Jun 2025 11:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/how-we-really-judge-ai-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-AI-Aversion-Appreciation-01.jpg"
  },
  {
    "title": "A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation",
    "description": "arXiv:2506.23584v1 Announce Type: cross Abstract: Generating radiology reports from CT scans remains a complex task due to the nuanced nature of medical imaging and the variability in clinical documentation. In this study, we propose a two-stage framework for generating renal radiology reports from 2D CT slices. First, we extract structured abnormality features using a multi-task learning model trained to identify lesion attributes such as location, size, enhancement, and attenuation. These extracted features are subsequently combined with the corresponding CT image and fed into a fine-tuned vision-language model to generate natural language report sentences aligned with clinical findings. We conduct experiments on a curated dataset of renal CT studies with manually annotated sentence-slice-feature triplets and evaluate performance using both classification metrics and natural language generation metrics. Our results demonstrate that the proposed model outperforms random baselines across all abnormality types, and the generated reports capture key clinical content with reasonable textual accuracy. This exploratory work highlights the feasibility of modular, feature-informed report generation for renal imaging. Future efforts will focus on extending this pipeline to 3D CT volumes and further improving clinical fidelity in multimodal medical AI systems.",
    "summary": "arXiv:2506.23584v1 Announce Type: cross Abstract: Generating radiology reports from CT scans remains a complex task due to the nuanced nature of medical imaging and the variability in clinical documentation. In this study, we propose a two-stage framework for generating renal radiology reports from 2D CT slices. First, we extract structured abnormality features using a multi-task learning model trained to identify lesion attributes such as location, size, enhancement, and attenuation. These extracted features are subsequently combined with the corresponding CT image and fed into a fine-tuned vision-language model to generate natural language report sentences aligned with clinical findings. We conduct experiments on a curated dataset of renal CT studies with manually annotated sentence-slice-feature triplets and evaluate performance using both classification metrics and natural language generation metrics. Our results demonstrate that the proposed model outperforms random baselines across all abnormality types, and the generated reports capture key clinical content with reasonable textual accuracy. This exploratory work highlights the feasibility of modular, feature-informed report generation for renal imaging. Future efforts will focus on extending this pipeline to 3D CT volumes and further improving clinical fidelity in multimodal medical AI systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23584",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face partners with TruffleHog to Scan for Secrets",
    "description": "",
    "summary": "Hugging Face partners with TruffleHog to Scan for Secrets We're excited to announce our partnership ...",
    "pubDate": "Wed, 04 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trufflesecurity-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/trufflesecurity-partnership/thumbnail.png"
  },
  {
    "title": "Welcome Gemma 2 - Google's new open LLM",
    "description": "",
    "summary": "Welcome Gemma 2 - Google‚Äôs new open LLM Google released Gemma 2, the latest addition to its family o...",
    "pubDate": "Thu, 27 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma2",
    "thumbnail": "https://huggingface.co/blog/assets/gemma2/thumbnail.jpg"
  },
  {
    "title": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "description": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "summary": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "pubDate": "Tue, 10 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-lessons-from-hundreds-of-successful-deployments",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FineVideo: behind the scenes",
    "description": "",
    "summary": "FineVideo: behind the scenes Open video datasets are scarce and therefore slowing down the developme...",
    "pubDate": "Mon, 23 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-video",
    "thumbnail": "https://huggingface.co/blog/assets/186_fine_video/thumbnail.png"
  },
  {
    "title": "Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA",
    "description": "",
    "summary": "Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA LLMs are known to b...",
    "pubDate": "Wed, 24 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/4bit-transformers-bitsandbytes",
    "thumbnail": "https://huggingface.co/blog/assets/96_hf_bitsandbytes_integration/Thumbnail_blue.png"
  },
  {
    "title": "ATTENTION2D: Communication Efficient Distributed Self-Attention Mechanism",
    "description": "arXiv:2503.15758v2 Announce Type: replace-cross Abstract: Transformer-based models have emerged as a leading architecture for natural language processing, natural language generation, and image generation tasks. A fundamental element of the transformer architecture is self-attention, which allows the model to capture intricate dependencies within the data. However, the self-attention mechanism also incurs significant computational and memory costs, particularly for long sequences. In this paper, we introduce ATTENTION2D, a novel approach that exploits parallelism along two dimensions - query and key/value - of the self-attention operation. This method enables efficient distribution and parallelization of computations across multiple devices. Our approach facilitates asymptotically faster training and inference phases compared to previous methods, without relying on approximations or incurring additional computational or memory overheads. Furthermore, unlike existing techniques that struggle to scale with an increasing number of processing units, our approach effectively scales with additional processing units. Our experimental results confirm the effectiveness of our method in improving communication efficiency and scalability. Compared to Ring Attention, our approach demonstrated up to a 5x performance boost on a GPT-3-like model using 64 NVIDIA A100 GPUs across 16 nodes, and up to a 9.4x performance boost on 64 NVIDIA H100 GPUs across 64 nodes.",
    "summary": "arXiv:2503.15758v2 Announce Type: replace-cross Abstract: Transformer-based models have emerged as a leading architecture for natural language processing, natural language generation, and image generation tasks. A fundamental element of the transformer architecture is self-attention, which allows the model to capture intricate dependencies within the data. However, the self-attention mechanism also incurs significant computational and memory costs, particularly for long sequences. In this paper, we introduce ATTENTION2D, a novel approach that exploits parallelism along two dimensions - query and key/value - of the self-attention operation. This method enables efficient distribution and parallelization of computations across multiple devices. Our approach facilitates asymptotically faster training and inference phases compared to previous methods, without relying on approximations or incurring additional computational or memory overheads. Furthermore, unlike existing techniques that struggle to scale with an increasing number of processing units, our approach effectively scales with additional processing units. Our experimental results confirm the effectiveness of our method in improving communication efficiency and scalability. Compared to Ring Attention, our approach demonstrated up to a 5x performance boost on a GPT-3-like model using 64 NVIDIA A100 GPUs across 16 nodes, and up to a 9.4x performance boost on 64 NVIDIA H100 GPUs across 64 nodes.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.15758",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GPTs are GPTs: An early look at the labor market impact potential of large language models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpts-are-gpts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ü™Ü Introduction to Matryoshka Embedding Models",
    "description": "",
    "summary": "ü™Ü Introduction to Matryoshka Embedding Models In this blogpost, we will introduce you to the concept...",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/matryoshka",
    "thumbnail": "https://huggingface.co/blog/assets/matryoshka/thumbnail.png"
  },
  {
    "title": "Reimagining secure infrastructure for advanced AI",
    "description": "Securing advanced AI systems will require an evolution in infrastructure security. We‚Äôre calling for research and investment in six security measures that we believe will play key roles in protecting advanced AI. Protecting, exploring, and applying advanced artificial intelligence (AI) is our strategic imperative. OpenAI‚Äôs mission is to deliver positive impact of advanced AI to everything from healthcare to science to education ‚Äì and yes, even to cybersecurity. That work begins with building secure, trustworthy AI systems and protecting the underlying technologies from those who seek to subvert our work to cause harm.",
    "summary": "Securing advanced AI systems will require an evolution in infrastructure security. We‚Äôre calling for research and investment in six security measures that we believe will play key roles in protecting advanced AI. Protecting, exploring, and applying advanced artificial intelligence (AI) is our strategic imperative. OpenAI‚Äôs mission is to deliver positive impact of advanced AI to everything from healthcare to science to education ‚Äì and yes, even to cybersecurity. That work begins with building secure, trustworthy AI systems and protecting the underlying technologies from those who seek to subvert our work to cause harm.",
    "pubDate": "Fri, 03 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reimagining-secure-infrastructure-for-advanced-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Optimizing Bark using ü§ó Transformers",
    "description": "",
    "summary": "Optimizing a Text-To-Speech model using ü§ó Transformers ü§ó Transformers provides many of the latest st...",
    "pubDate": "Wed, 09 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimizing-bark",
    "thumbnail": "https://huggingface.co/blog/assets/bark_optimization/thumbnail.png"
  },
  {
    "title": "How AlphaChip transformed computer chip design",
    "description": "Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world.",
    "summary": "Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world.",
    "pubDate": "Thu, 26 Sep 2024 14:08:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/",
    "thumbnail": "https://lh3.googleusercontent.com/Y_xdq8eqcQlZXYk-MZ2OWPpppmWG6LAQ8DZ-LZFUh8TV5s2TBb3RK_VkMUe-skRzIop5aP6Ot9xPMWFaWmenz55EwxVFCMszpTg2EzsyOd6ftlllGyE=w1200-h630-n-nu"
  },
  {
    "title": "Open R1: How to use OlympicCoder locally for coding?",
    "description": "",
    "summary": "Open R1: How to use OlympicCoder locally for coding Everyone‚Äôs been using Claude and OpenAI as codin...",
    "pubDate": "Thu, 20 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/olympic-coder-lmstudio",
    "thumbnail": "https://huggingface.co/blog/assets/olympic-coder-lmstudio/banner.png"
  },
  {
    "title": "Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems",
    "description": "arXiv:2506.22774v1 Announce Type: new Abstract: Artificial Intelligence (AI) technology epitomizes the complex challenges posed by human-made artifacts, particularly those widely integrated into society and exert significant influence, highlighting potential benefits and their negative consequences. While other technologies may also pose substantial risks, AI's pervasive reach makes its societal effects especially profound. The complexity of AI systems, coupled with their remarkable capabilities, can lead to a reliance on technologies that operate beyond direct human oversight or understanding. To mitigate the risks that arise, several theoretical tools and guidelines have been developed, alongside efforts to create technological tools aimed at safeguarding Trustworthy AI. The guidelines take a more holistic view of the issue but fail to provide techniques for quantifying trustworthiness. Conversely, while technological tools are better at achieving such quantification, they lack a holistic perspective, focusing instead on specific aspects of Trustworthy AI. This paper aims to introduce an assessment method that combines the ethical components of Trustworthy AI with the algorithmic processes of PageRank and TrustRank. The goal is to establish an assessment framework that minimizes the subjectivity inherent in the self-assessment techniques prevalent in the field by introducing algorithmic criteria. The application of our approach indicates that a holistic assessment of an AI system's trustworthiness can be achieved by providing quantitative insights while considering the theoretical content of relevant guidelines.",
    "summary": "arXiv:2506.22774v1 Announce Type: new Abstract: Artificial Intelligence (AI) technology epitomizes the complex challenges posed by human-made artifacts, particularly those widely integrated into society and exert significant influence, highlighting potential benefits and their negative consequences. While other technologies may also pose substantial risks, AI's pervasive reach makes its societal effects especially profound. The complexity of AI systems, coupled with their remarkable capabilities, can lead to a reliance on technologies that operate beyond direct human oversight or understanding. To mitigate the risks that arise, several theoretical tools and guidelines have been developed, alongside efforts to create technological tools aimed at safeguarding Trustworthy AI. The guidelines take a more holistic view of the issue but fail to provide techniques for quantifying trustworthiness. Conversely, while technological tools are better at achieving such quantification, they lack a holistic perspective, focusing instead on specific aspects of Trustworthy AI. This paper aims to introduce an assessment method that combines the ethical components of Trustworthy AI with the algorithmic processes of PageRank and TrustRank. The goal is to establish an assessment framework that minimizes the subjectivity inherent in the self-assessment techniques prevalent in the field by introducing algorithmic criteria. The application of our approach indicates that a holistic assessment of an AI system's trustworthiness can be achieved by providing quantitative insights while considering the theoretical content of relevant guidelines.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22774",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Data Is Better Together: A Look Back and Forward",
    "description": "",
    "summary": "Data Is Better Together: A Look Back and Forward For the past few months, we have been working on th...",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dibt",
    "thumbnail": "https://huggingface.co/blog/assets/dibt/thumbnail.png"
  },
  {
    "title": "Probabilistic Time Series Forecasting with ü§ó Transformers",
    "description": "",
    "summary": "Probabilistic Time Series Forecasting with ü§ó Transformers Introduction Time series forecasting is an...",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/time-series-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/118_time-series-transformers/thumbnail.png"
  },
  {
    "title": "New funding to scale the benefits of AI",
    "description": "We are making progress on our mission to ensure that artificial general intelligence benefits all of humanity.",
    "summary": "We are making progress on our mission to ensure that artificial general intelligence benefits all of humanity.",
    "pubDate": "Wed, 02 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scale-the-benefits-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Open Arabic LLM Leaderboard 2",
    "description": "",
    "summary": "The Open Arabic LLM Leaderboard 2 Current status of Arabic LLMs leaderboards The growing availabilit...",
    "pubDate": "Mon, 10 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-arabic-v2",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_arabic.png"
  },
  {
    "title": "GPT-2: 1.5B release",
    "description": "As the final model release of¬†GPT-2‚Äôs¬†staged release, we‚Äôre releasing the largest version (1.5B parameters) of GPT-2 along with¬†code and model weights¬†to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we‚Äôve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we‚Äôre actively continuing the conversation with the AI community on responsible¬†publication.",
    "summary": "As the final model release of¬†GPT-2‚Äôs¬†staged release, we‚Äôre releasing the largest version (1.5B parameters) of GPT-2 along with¬†code and model weights¬†to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we‚Äôve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we‚Äôre actively continuing the conversation with the AI community on responsible¬†publication.",
    "pubDate": "Tue, 05 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-2-1-5b-release",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI‚Äôs commitment to child safety: adopting safety by design principles",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/child-safety-adopting-sbd-principles",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-tune Llama 2 with DPO",
    "description": "",
    "summary": "Fine-tune Llama 2 with DPO Introduction Reinforcement Learning from Human Feedback (RLHF) has become...",
    "pubDate": "Tue, 08 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dpo-trl",
    "thumbnail": "https://huggingface.co/blog/assets/157_dpo_trl/dpo_thumbnail.png"
  },
  {
    "title": "Introducing ü§ó Accelerate",
    "description": "",
    "summary": "Introducing ü§ó Accelerate ü§ó Accelerate Run your raw PyTorch training scripts on any kind of device. M...",
    "pubDate": "Fri, 16 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-library",
    "thumbnail": "https://huggingface.co/blog/assets/20_accelerate_library/accelerate_diff.png"
  },
  {
    "title": "AI Policy: ü§ó Response to the White House AI Action Plan RFI",
    "description": "",
    "summary": "AI Policy @ü§ó: Response to the White House AI Action Plan RFI On March 14, we submitted Hugging Face'...",
    "pubDate": "Wed, 19 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-action-wh-2025",
    "thumbnail": "https://huggingface.co/blog/assets/151_policy_ntia_rfc/us_policy_thumbnail.png"
  },
  {
    "title": "Bringing the Magic of AI to Mattel‚Äôs Iconic Brands",
    "description": "OpenAI and Mattel are partnering to integrate AI into iconic brands such as Barbie and Hot Wheels, aiming to enhance creative development, streamline workflows, and create new ways for fans to engage.",
    "summary": "OpenAI and Mattel are partnering to integrate AI into iconic brands such as Barbie and Hot Wheels, aiming to enhance creative development, streamline workflows, and create new ways for fans to engage.",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mattels-iconic-brands",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Arabic Dialect Classification using RNNs, Transformers, and Large Language Models: A Comparative Analysis",
    "description": "arXiv:2506.19753v2 Announce Type: replace-cross Abstract: The Arabic language is among the most popular languages in the world with a huge variety of dialects spoken in 22 countries. In this study, we address the problem of classifying 18 Arabic dialects of the QADI dataset of Arabic tweets. RNN models, Transformer models, and large language models (LLMs) via prompt engineering are created and tested. Among these, MARBERTv2 performed best with 65% accuracy and 64% F1-score. Through the use of state-of-the-art preprocessing techniques and the latest NLP models, this paper identifies the most significant linguistic issues in Arabic dialect identification. The results corroborate applications like personalized chatbots that respond in users' dialects, social media monitoring, and greater accessibility for Arabic communities.",
    "summary": "arXiv:2506.19753v2 Announce Type: replace-cross Abstract: The Arabic language is among the most popular languages in the world with a huge variety of dialects spoken in 22 countries. In this study, we address the problem of classifying 18 Arabic dialects of the QADI dataset of Arabic tweets. RNN models, Transformer models, and large language models (LLMs) via prompt engineering are created and tested. Among these, MARBERTv2 performed best with 65% accuracy and 64% F1-score. Through the use of state-of-the-art preprocessing techniques and the latest NLP models, this paper identifies the most significant linguistic issues in Arabic dialect identification. The results corroborate applications like personalized chatbots that respond in users' dialects, social media monitoring, and greater accessibility for Arabic communities.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19753",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tuning now available for GPT-4o",
    "description": "Fine-tune custom versions of GPT-4o to increase performance and accuracy for your applications",
    "summary": "Fine-tune custom versions of GPT-4o to increase performance and accuracy for your applications",
    "pubDate": "Tue, 20 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-fine-tuning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "VFEFL: Privacy-Preserving Federated Learning against Malicious Clients via Verifiable Functional Encryption",
    "description": "arXiv:2506.12846v2 Announce Type: replace-cross Abstract: Federated learning is a promising distributed learning paradigm that enables collaborative model training without exposing local client data, thereby protect data privacy. However, it also brings new threats and challenges. The advancement of model inversion attacks has rendered the plaintext transmission of local models insecure, while the distributed nature of federated learning makes it particularly vulnerable to attacks raised by malicious clients. To protect data privacy and prevent malicious client attacks, this paper proposes a privacy-preserving federated learning framework based on verifiable functional encryption, without a non-colluding dual-server setup or additional trusted third-party. Specifically, we propose a novel decentralized verifiable functional encryption (DVFE) scheme that enables the verification of specific relationships over multi-dimensional ciphertexts. This scheme is formally treated, in terms of definition, security model and security proof. Furthermore, based on the proposed DVFE scheme, we design a privacy-preserving federated learning framework VFEFL that incorporates a novel robust aggregation rule to detect malicious clients, enabling the effective training of high-accuracy models under adversarial settings. Finally, we provide formal analysis and empirical evaluation of the proposed schemes. The results demonstrate that our approach achieves the desired privacy protection, robustness, verifiability and fidelity, while eliminating the reliance on non-colluding dual-server settings or trusted third parties required by existing methods.",
    "summary": "arXiv:2506.12846v2 Announce Type: replace-cross Abstract: Federated learning is a promising distributed learning paradigm that enables collaborative model training without exposing local client data, thereby protect data privacy. However, it also brings new threats and challenges. The advancement of model inversion attacks has rendered the plaintext transmission of local models insecure, while the distributed nature of federated learning makes it particularly vulnerable to attacks raised by malicious clients. To protect data privacy and prevent malicious client attacks, this paper proposes a privacy-preserving federated learning framework based on verifiable functional encryption, without a non-colluding dual-server setup or additional trusted third-party. Specifically, we propose a novel decentralized verifiable functional encryption (DVFE) scheme that enables the verification of specific relationships over multi-dimensional ciphertexts. This scheme is formally treated, in terms of definition, security model and security proof. Furthermore, based on the proposed DVFE scheme, we design a privacy-preserving federated learning framework VFEFL that incorporates a novel robust aggregation rule to detect malicious clients, enabling the effective training of high-accuracy models under adversarial settings. Finally, we provide formal analysis and empirical evaluation of the proposed schemes. The results demonstrate that our approach achieves the desired privacy protection, robustness, verifiability and fidelity, while eliminating the reliance on non-colluding dual-server settings or trusted third parties required by existing methods.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12846",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing GPTs",
    "description": "You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills.",
    "summary": "You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills.",
    "pubDate": "Mon, 06 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-gpts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Exploring simple optimizations for SDXL",
    "description": "",
    "summary": "Exploring simple optimizations for SDXL Stable Diffusion XL (SDXL) is the latest latent diffusion mo...",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/simple_sdxl_optimizations",
    "thumbnail": "https://huggingface.co/blog/assets/simple_sdxl_optimizations/thumbnail.png"
  },
  {
    "title": "Sora is here",
    "description": "Our video generation model, Sora, is now available to use at sora.com. Users can generate videos up to 1080p resolution, up to 20 sec long, and in widescreen, vertical or square aspect ratios. You can bring your own assets to extend, remix, and blend, or generate entirely new content from text.",
    "summary": "Our video generation model, Sora, is now available to use at sora.com. Users can generate videos up to 1080p resolution, up to 20 sec long, and in widescreen, vertical or square aspect ratios. You can bring your own assets to extend, remix, and blend, or generate entirely new content from text.",
    "pubDate": "Mon, 09 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-is-here",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New compliance and administrative tools for ChatGPT Enterprise",
    "description": "Compliance API integrations, SCIM, and GPT controls to support compliance programs, data security, and user access at scale",
    "summary": "Compliance API integrations, SCIM, and GPT controls to support compliance programs, data security, and user access at scale",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-for-chatgpt-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "StackLLaMA: A hands-on guide to train LLaMA with RLHF",
    "description": "",
    "summary": "StackLLaMA: A hands-on guide to train LLaMA with RLHF Models such as ChatGPT, GPT-4, and Claude are ...",
    "pubDate": "Wed, 05 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stackllama",
    "thumbnail": "https://huggingface.co/blog/assets/138_stackllama/thumbnail.png"
  },
  {
    "title": "Faster Assisted Generation with Dynamic Speculation",
    "description": "",
    "summary": "Faster Assisted Generation with Dynamic Speculation ‚≠ê In this blog post, we‚Äôll explore dynamic specu...",
    "pubDate": "Tue, 08 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dynamic_speculation_lookahead",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "PaliGemma 2 Mix - New Instruction Vision Language Models by Google",
    "description": "",
    "summary": "PaliGemma 2 Mix - New Instruction Vision Language Models by Google TL;DR Last December, Google relea...",
    "pubDate": "Wed, 19 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma2mix",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma2/thumbnail.png"
  },
  {
    "title": "DReSS: Data-driven Regularized Structured Streamlining for Large Language Models",
    "description": "arXiv:2501.17905v3 Announce Type: replace-cross Abstract: Large language models (LLMs) have achieved significant progress across various domains, but their increasing scale results in high computational and memory costs. Recent studies have revealed that LLMs exhibit sparsity, providing the potential to reduce model size through pruning techniques. However, existing pruning methods typically follow a prune-then-finetune paradigm. Since the pruned components still contain valuable information, their direct removal often leads to irreversible performance degradation, imposing a substantial computational burden to recover performance during finetuning. In this paper, we propose a novel paradigm that first applies regularization, then prunes, and finally finetunes. Based on this paradigm, we introduce DReSS, a simple and effective Data-driven Regularized Structured Streamlining method for LLMs. By leveraging a small amount of data to regularize the components to be pruned, DReSS explicitly transfers the important information to the remaining parts of the model in advance. Compared to direct pruning, this can reduce the information loss caused by parameter removal, thereby enhancing its language modeling capabilities. Experimental results demonstrate that DReSS significantly outperforms existing pruning methods even under extreme pruning ratios, significantly reducing latency and increasing throughput.",
    "summary": "arXiv:2501.17905v3 Announce Type: replace-cross Abstract: Large language models (LLMs) have achieved significant progress across various domains, but their increasing scale results in high computational and memory costs. Recent studies have revealed that LLMs exhibit sparsity, providing the potential to reduce model size through pruning techniques. However, existing pruning methods typically follow a prune-then-finetune paradigm. Since the pruned components still contain valuable information, their direct removal often leads to irreversible performance degradation, imposing a substantial computational burden to recover performance during finetuning. In this paper, we propose a novel paradigm that first applies regularization, then prunes, and finally finetunes. Based on this paradigm, we introduce DReSS, a simple and effective Data-driven Regularized Structured Streamlining method for LLMs. By leveraging a small amount of data to regularize the components to be pruned, DReSS explicitly transfers the important information to the remaining parts of the model in advance. Compared to direct pruning, this can reduce the information loss caused by parameter removal, thereby enhancing its language modeling capabilities. Experimental results demonstrate that DReSS significantly outperforms existing pruning methods even under extreme pruning ratios, significantly reducing latency and increasing throughput.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.17905",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing OpenAI",
    "description": "OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact.",
    "summary": "OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact.",
    "pubDate": "Fri, 11 Dec 2015 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Banque des Territoires (CDC Group) x Polyconseil x Hugging Face: Enhancing a Major French Environmental Program with a Sovereign Data Solution",
    "description": "",
    "summary": "Banque des Territoires (CDC Group) x Polyconseil x Hugging Face: Enhancing a Major French Environmen...",
    "pubDate": "Tue, 09 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sovereign-data-solution-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/cdc_poly_hf.png"
  },
  {
    "title": "FermiNet: Quantum physics and chemistry from first principles",
    "description": "Using deep learning to solve fundamental problems in computational quantum chemistry and explore how matter interacts with light",
    "summary": "Using deep learning to solve fundamental problems in computational quantum chemistry and explore how matter interacts with light",
    "pubDate": "Thu, 22 Aug 2024 19:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ferminet-quantum-physics-and-chemistry-from-first-principles/",
    "thumbnail": "https://lh3.googleusercontent.com/u-LZOO0ynV2UCorbNrUtWS6MJ_sxTfGzObe2YzBt5Grgohx39WcsGiPNOsHwBja8C51lQBclpaovrzUVVQRzj2WpWeM7f7y5eeYt3Dx6l3gxfx9S9g=w1200-h630-n-nu"
  },
  {
    "title": "Can We Predict the Unpredictable? Leveraging DisasterNet-LLM for Multimodal Disaster Classification",
    "description": "arXiv:2506.23462v1 Announce Type: cross Abstract: Effective disaster management requires timely and accurate insights, yet traditional methods struggle to integrate multimodal data such as images, weather records, and textual reports. To address this, we propose DisasterNet-LLM, a specialized Large Language Model (LLM) designed for comprehensive disaster analysis. By leveraging advanced pretraining, cross-modal attention mechanisms, and adaptive transformers, DisasterNet-LLM excels in disaster classification. Experimental results demonstrate its superiority over state-of-the-art models, achieving higher accuracy of 89.5%, an F1 score of 88.0%, AUC of 0.92%, and BERTScore of 0.88% in multimodal disaster classification tasks.",
    "summary": "arXiv:2506.23462v1 Announce Type: cross Abstract: Effective disaster management requires timely and accurate insights, yet traditional methods struggle to integrate multimodal data such as images, weather records, and textual reports. To address this, we propose DisasterNet-LLM, a specialized Large Language Model (LLM) designed for comprehensive disaster analysis. By leveraging advanced pretraining, cross-modal attention mechanisms, and adaptive transformers, DisasterNet-LLM excels in disaster classification. Experimental results demonstrate its superiority over state-of-the-art models, achieving higher accuracy of 89.5%, an F1 score of 88.0%, AUC of 0.92%, and BERTScore of 0.88% in multimodal disaster classification tasks.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23462",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FFJORD: Free-form continuous dynamics for scalable reversible generative models",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 02 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ffjord",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Finding GPT-4‚Äôs mistakes with GPT-4",
    "description": "CriticGPT, a model based on GPT-4, writes critiques of ChatGPT responses to help human trainers spot mistakes during RLHF",
    "summary": "CriticGPT, a model based on GPT-4, writes critiques of ChatGPT responses to help human trainers spot mistakes during RLHF",
    "pubDate": "Thu, 27 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/finding-gpt4s-mistakes-with-gpt-4",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Train your first Decision Transformer",
    "description": "",
    "summary": "Train your first Decision Transformer In a previous post, we announced the launch of Decision Transf...",
    "pubDate": "Thu, 08 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-decision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/101_train-decision-transformers/thumbnail.gif"
  },
  {
    "title": "Ingredients for robotics research",
    "description": "We‚Äôre releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience Replay, all developed for our research over the past year. We‚Äôve used these environments to train models which work on physical robots. We‚Äôre also releasing a set of requests for robotics research.",
    "summary": "We‚Äôre releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience Replay, all developed for our research over the past year. We‚Äôve used these environments to train models which work on physical robots. We‚Äôre also releasing a set of requests for robotics research.",
    "pubDate": "Mon, 26 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ingredients-for-robotics-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Pull Requests and Discussions ü•≥",
    "description": "",
    "summary": "Introducing Pull Requests and Discussions ü•≥ We are thrilled to announce the release of our latest co...",
    "pubDate": "Wed, 25 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-update",
    "thumbnail": "https://huggingface.co/blog/assets/76_community_update/thumbnail.png"
  },
  {
    "title": "Experiment with Gemini 2.0 Flash native image generation",
    "description": "Native image output is available in Gemini 2.0 Flash for developers to experiment with in Google AI Studio and the Gemini API.",
    "summary": "Native image output is available in Gemini 2.0 Flash for developers to experiment with in Google AI Studio and the Gemini API.",
    "pubDate": "Wed, 12 Mar 2025 14:58:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/experiment-with-gemini-20-flash-native-image-generation/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-image-generation_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Report on NSF Workshop on Science of Safe AI",
    "description": "arXiv:2506.22492v1 Announce Type: cross Abstract: Recent advances in machine learning, particularly the emergence of foundation models, are leading to new opportunities to develop technology-based solutions to societal problems. However, the reasoning and inner workings of today's complex AI models are not transparent to the user, and there are no safety guarantees regarding their predictions. Consequently, to fulfill the promise of AI, we must address the following scientific challenge: how to develop AI-based systems that are not only accurate and performant but also safe and trustworthy? The criticality of safe operation is particularly evident for autonomous systems for control and robotics, and was the catalyst for the Safe Learning Enabled Systems (SLES) program at NSF. For the broader class of AI applications, such as users interacting with chatbots and clinicians receiving treatment recommendations, safety is, while no less important, less well-defined with context-dependent interpretations. This motivated the organization of a day-long workshop, held at University of Pennsylvania on February 26, 2025, to bring together investigators funded by the NSF SLES program with a broader pool of researchers studying AI safety. This report is the result of the discussions in the working groups that addressed different aspects of safety at the workshop. The report articulates a new research agenda focused on developing theory, methods, and tools that will provide the foundations of the next generation of AI-enabled systems.",
    "summary": "arXiv:2506.22492v1 Announce Type: cross Abstract: Recent advances in machine learning, particularly the emergence of foundation models, are leading to new opportunities to develop technology-based solutions to societal problems. However, the reasoning and inner workings of today's complex AI models are not transparent to the user, and there are no safety guarantees regarding their predictions. Consequently, to fulfill the promise of AI, we must address the following scientific challenge: how to develop AI-based systems that are not only accurate and performant but also safe and trustworthy? The criticality of safe operation is particularly evident for autonomous systems for control and robotics, and was the catalyst for the Safe Learning Enabled Systems (SLES) program at NSF. For the broader class of AI applications, such as users interacting with chatbots and clinicians receiving treatment recommendations, safety is, while no less important, less well-defined with context-dependent interpretations. This motivated the organization of a day-long workshop, held at University of Pennsylvania on February 26, 2025, to bring together investigators funded by the NSF SLES program with a broader pool of researchers studying AI safety. This report is the result of the discussions in the working groups that addressed different aspects of safety at the workshop. The report articulates a new research agenda focused on developing theory, methods, and tools that will provide the foundations of the next generation of AI-enabled systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22492",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Leveraging the Potential of Prompt Engineering for Hate Speech Detection in Low-Resource Languages",
    "description": "arXiv:2506.23930v1 Announce Type: cross Abstract: The rapid expansion of social media leads to a marked increase in hate speech, which threatens personal lives and results in numerous hate crimes. Detecting hate speech presents several challenges: diverse dialects, frequent code-mixing, and the prevalence of misspelled words in user-generated content on social media platforms. Recent progress in hate speech detection is typically concentrated on high-resource languages. However, low-resource languages still face significant challenges due to the lack of large-scale, high-quality datasets. This paper investigates how we can overcome this limitation via prompt engineering on large language models (LLMs) focusing on low-resource Bengali language. We investigate six prompting strategies - zero-shot prompting, refusal suppression, flattering the classifier, multi-shot prompting, role prompting, and finally our innovative metaphor prompting to detect hate speech effectively in low-resource languages. We pioneer the metaphor prompting to circumvent the built-in safety mechanisms of LLMs that marks a significant departure from existing jailbreaking methods. We investigate all six different prompting strategies on the Llama2-7B model and compare the results extensively with three pre-trained word embeddings - GloVe, Word2Vec, and FastText for three different deep learning models - multilayer perceptron (MLP), convolutional neural network (CNN), and bidirectional gated recurrent unit (BiGRU). To prove the effectiveness of our metaphor prompting in the low-resource Bengali language, we also evaluate it in another low-resource language - Hindi, and two high-resource languages - English and German. The performance of all prompting techniques is evaluated using the F1 score, and environmental impact factor (IF), which measures CO$_2$ emissions, electricity usage, and computational time.",
    "summary": "arXiv:2506.23930v1 Announce Type: cross Abstract: The rapid expansion of social media leads to a marked increase in hate speech, which threatens personal lives and results in numerous hate crimes. Detecting hate speech presents several challenges: diverse dialects, frequent code-mixing, and the prevalence of misspelled words in user-generated content on social media platforms. Recent progress in hate speech detection is typically concentrated on high-resource languages. However, low-resource languages still face significant challenges due to the lack of large-scale, high-quality datasets. This paper investigates how we can overcome this limitation via prompt engineering on large language models (LLMs) focusing on low-resource Bengali language. We investigate six prompting strategies - zero-shot prompting, refusal suppression, flattering the classifier, multi-shot prompting, role prompting, and finally our innovative metaphor prompting to detect hate speech effectively in low-resource languages. We pioneer the metaphor prompting to circumvent the built-in safety mechanisms of LLMs that marks a significant departure from existing jailbreaking methods. We investigate all six different prompting strategies on the Llama2-7B model and compare the results extensively with three pre-trained word embeddings - GloVe, Word2Vec, and FastText for three different deep learning models - multilayer perceptron (MLP), convolutional neural network (CNN), and bidirectional gated recurrent unit (BiGRU). To prove the effectiveness of our metaphor prompting in the low-resource Bengali language, we also evaluate it in another low-resource language - Hindi, and two high-resource languages - English and German. The performance of all prompting techniques is evaluated using the F1 score, and environmental impact factor (IF), which measures CO$_2$ emissions, electricity usage, and computational time.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23930",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Exploring Quantization Backends in Diffusers",
    "description": "",
    "summary": "Exploring Quantization Backends in Diffusers Large diffusion models like Flux (a flow-based text-to-...",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers-quantization/thumbnail.png"
  },
  {
    "title": "Getting Started with Hugging Face Transformers for IPUs with Optimum",
    "description": "",
    "summary": "Getting Started with Hugging Face Transformers for IPUs with Optimum Transformer models have proven ...",
    "pubDate": "Tue, 30 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore-getting-started",
    "thumbnail": "https://huggingface.co/blog/assets/38_getting_started_graphcore/graphcore_1.png"
  },
  {
    "title": "Developing reliable AI tools for healthcare",
    "description": "We‚Äôve published our joint paper with Google Research in Nature Medicine, which proposes CoDoC (Complementarity-driven Deferral-to-Clinical Workflow), an AI system that learns when to rely on predictive AI tools or defer to a clinician for the most accurate interpretation of medical images.",
    "summary": "We‚Äôve published our joint paper with Google Research in Nature Medicine, which proposes CoDoC (Complementarity-driven Deferral-to-Clinical Workflow), an AI system that learns when to rely on predictive AI tools or defer to a clinician for the most accurate interpretation of medical images.",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/codoc-developing-reliable-ai-tools-for-healthcare/",
    "thumbnail": "https://lh3.googleusercontent.com/JCyH0sgVtuYFCB0n7g6f2NMV19yeAgvxQBqcfy9H_-DP_aW3k5h4i0bcZ9_9KCExs7rXRrCaC6s21uK5Udap6tX3zy96zOdn8YcF5WIxAFzUgru6Nw=w1200-h630-n-nu"
  },
  {
    "title": "Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving",
    "description": "arXiv:2506.23771v1 Announce Type: cross Abstract: Reinforcement Learning (RL) is increasingly used in autonomous driving (AD) and shows clear advantages. However, most RL-based AD methods overlook policy structure design. An RL policy that only outputs short-timescale vehicle control commands results in fluctuating driving behavior due to fluctuations in network outputs, while one that only outputs long-timescale driving goals cannot achieve unified optimality of driving behavior and control. Therefore, we propose a multi-timescale hierarchical reinforcement learning approach. Our approach adopts a hierarchical policy structure, where high- and low-level RL policies are unified-trained to produce long-timescale motion guidance and short-timescale control commands, respectively. Therein, motion guidance is explicitly represented by hybrid actions to capture multimodal driving behaviors on structured road and support incremental low-level extend-state updates. Additionally, a hierarchical safety mechanism is designed to ensure multi-timescale safety. Evaluation in simulator-based and HighD dataset-based highway multi-lane scenarios demonstrates that our approach significantly improves AD performance, effectively increasing driving efficiency, action consistency and safety.",
    "summary": "arXiv:2506.23771v1 Announce Type: cross Abstract: Reinforcement Learning (RL) is increasingly used in autonomous driving (AD) and shows clear advantages. However, most RL-based AD methods overlook policy structure design. An RL policy that only outputs short-timescale vehicle control commands results in fluctuating driving behavior due to fluctuations in network outputs, while one that only outputs long-timescale driving goals cannot achieve unified optimality of driving behavior and control. Therefore, we propose a multi-timescale hierarchical reinforcement learning approach. Our approach adopts a hierarchical policy structure, where high- and low-level RL policies are unified-trained to produce long-timescale motion guidance and short-timescale control commands, respectively. Therein, motion guidance is explicitly represented by hybrid actions to capture multimodal driving behaviors on structured road and support incremental low-level extend-state updates. Additionally, a hierarchical safety mechanism is designed to ensure multi-timescale safety. Evaluation in simulator-based and HighD dataset-based highway multi-lane scenarios demonstrates that our approach significantly improves AD performance, effectively increasing driving efficiency, action consistency and safety.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23771",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "WATCHDOG: an ontology-aWare risk AssessmenT approaCH via object-oriented DisruptiOn Graphs",
    "description": "arXiv:2412.13964v2 Announce Type: replace Abstract: When considering risky events or actions, we must not downplay the role of involved objects: a charged battery in our phone averts the risk of being stranded in the desert after a flat tyre, and a functional firewall mitigates the risk of a hacker intruding the network. The Common Ontology of Value and Risk (COVER) highlights how the role of objects and their relationships remains pivotal to performing transparent, complete and accountable risk assessment. In this paper, we operationalize some of the notions proposed by COVER -- such as parthood between objects and participation of objects in events/actions -- by presenting a new framework for risk assessment: WATCHDOG. WATCHDOG enriches the expressivity of vetted formal models for risk -- i.e., fault trees and attack trees -- by bridging the disciplines of ontology and formal methods into an ontology-aware formal framework composed by a more expressive modelling formalism, Object-Oriented Disruption Graphs (DOGs), logic (DOGLog) and an intermediate query language (DOGLang). With these, WATCHDOG allows risk assessors to pose questions about disruption propagation, disruption likelihood and risk levels, keeping the fundamental role of objects at risk always in sight.",
    "summary": "arXiv:2412.13964v2 Announce Type: replace Abstract: When considering risky events or actions, we must not downplay the role of involved objects: a charged battery in our phone averts the risk of being stranded in the desert after a flat tyre, and a functional firewall mitigates the risk of a hacker intruding the network. The Common Ontology of Value and Risk (COVER) highlights how the role of objects and their relationships remains pivotal to performing transparent, complete and accountable risk assessment. In this paper, we operationalize some of the notions proposed by COVER -- such as parthood between objects and participation of objects in events/actions -- by presenting a new framework for risk assessment: WATCHDOG. WATCHDOG enriches the expressivity of vetted formal models for risk -- i.e., fault trees and attack trees -- by bridging the disciplines of ontology and formal methods into an ontology-aware formal framework composed by a more expressive modelling formalism, Object-Oriented Disruption Graphs (DOGs), logic (DOGLog) and an intermediate query language (DOGLang). With these, WATCHDOG allows risk assessors to pose questions about disruption propagation, disruption likelihood and risk levels, keeping the fundamental role of objects at risk always in sight.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.13964",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Text Production and Comprehension by Human and Artificial Intelligence: Interdisciplinary Workshop Report",
    "description": "arXiv:2506.22698v1 Announce Type: cross Abstract: This report synthesizes the outcomes of a recent interdisciplinary workshop that brought together leading experts in cognitive psychology, language learning, and artificial intelligence (AI)-based natural language processing (NLP). The workshop, funded by the National Science Foundation, aimed to address a critical knowledge gap in our understanding of the relationship between AI language models and human cognitive processes in text comprehension and composition. Through collaborative dialogue across cognitive, linguistic, and technological perspectives, workshop participants examined the underlying processes involved when humans produce and comprehend text, and how AI can both inform our understanding of these processes and augment human capabilities. The workshop revealed emerging patterns in the relationship between large language models (LLMs) and human cognition, with highlights on both the capabilities of LLMs and their limitations in fully replicating human-like language understanding and generation. Key findings include the potential of LLMs to offer insights into human language processing, the increasing alignment between LLM behavior and human language processing when models are fine-tuned with human feedback, and the opportunities and challenges presented by human-AI collaboration in language tasks. By synthesizing these findings, this report aims to guide future research, development, and implementation of LLMs in cognitive psychology, linguistics, and education. It emphasizes the importance of ethical considerations and responsible use of AI technologies while striving to enhance human capabilities in text comprehension and production through effective human-AI collaboration.",
    "summary": "arXiv:2506.22698v1 Announce Type: cross Abstract: This report synthesizes the outcomes of a recent interdisciplinary workshop that brought together leading experts in cognitive psychology, language learning, and artificial intelligence (AI)-based natural language processing (NLP). The workshop, funded by the National Science Foundation, aimed to address a critical knowledge gap in our understanding of the relationship between AI language models and human cognitive processes in text comprehension and composition. Through collaborative dialogue across cognitive, linguistic, and technological perspectives, workshop participants examined the underlying processes involved when humans produce and comprehend text, and how AI can both inform our understanding of these processes and augment human capabilities. The workshop revealed emerging patterns in the relationship between large language models (LLMs) and human cognition, with highlights on both the capabilities of LLMs and their limitations in fully replicating human-like language understanding and generation. Key findings include the potential of LLMs to offer insights into human language processing, the increasing alignment between LLM behavior and human language processing when models are fine-tuned with human feedback, and the opportunities and challenges presented by human-AI collaboration in language tasks. By synthesizing these findings, this report aims to guide future research, development, and implementation of LLMs in cognitive psychology, linguistics, and education. It emphasizes the importance of ethical considerations and responsible use of AI technologies while striving to enhance human capabilities in text comprehension and production through effective human-AI collaboration.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22698",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Llama 3.1 - 405B, 70B & 8B with multilinguality and long context",
    "description": "",
    "summary": "Llama 3.1 - 405B, 70B & 8B with multilinguality and long context Llama 3.1 is out! Today we welcome ...",
    "pubDate": "Tue, 23 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama31",
    "thumbnail": "https://huggingface.co/blog/assets/llama31/thumbnail.jpg"
  },
  {
    "title": "Evolved Policy Gradients",
    "description": "We‚Äôre releasing an experimental metalearning approach called Evolved Policy Gradients, a method that evolves the loss function of learning agents, which can enable fast training on novel tasks. Agents trained with EPG can succeed at basic tasks at test time that were outside their training regime, like learning to navigate to an object on a different side of the room from where it was placed during training.",
    "summary": "We‚Äôre releasing an experimental metalearning approach called Evolved Policy Gradients, a method that evolves the loss function of learning agents, which can enable fast training on novel tasks. Agents trained with EPG can succeed at basic tasks at test time that were outside their training regime, like learning to navigate to an object on a different side of the room from where it was placed during training.",
    "pubDate": "Wed, 18 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolved-policy-gradients",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Using GPT-4o reasoning to transform cancer care",
    "description": "Color Health is working with OpenAI to pioneer a new way of accelerating cancer patients‚Äô access to treatment. Their new Cancer Copilot application uses GPT-4o to identify missing diagnostics and create tailored workup plans, enabling healthcare providers to make evidence-based decisions about cancer screening and treatment.",
    "summary": "Color Health is working with OpenAI to pioneer a new way of accelerating cancer patients‚Äô access to treatment. Their new Cancer Copilot application uses GPT-4o to identify missing diagnostics and create tailored workup plans, enabling healthcare providers to make evidence-based decisions about cancer screening and treatment.",
    "pubDate": "Mon, 17 Jun 2024 04:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/color-health",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI and Microsoft",
    "description": "We‚Äôre working with Microsoft to start running most of our large-scale experiments on Azure.",
    "summary": "We‚Äôre working with Microsoft to start running most of our large-scale experiments on Azure.",
    "pubDate": "Tue, 15 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-microsoft",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ego-Foresight: Self-supervised Learning of Agent-Aware Representations for Improved RL",
    "description": "arXiv:2407.01570v2 Announce Type: replace-cross Abstract: Despite the significant advancements in Deep Reinforcement Learning (RL) observed in the last decade, the amount of training experience necessary to learn effective policies remains one of the primary concerns both in simulated and real environments. Looking to solve this issue, previous work has shown that improved training efficiency can be achieved by separately modeling agent and environment, but usually requiring a supervisory agent mask. In contrast to RL, humans can perfect a new skill from a small number of trials and in most cases do so without a supervisory signal, making neuroscientific studies of human development a valuable source of inspiration for RL. In particular, we explore the idea of motor prediction, which states that humans develop an internal model of themselves and of the consequences that their motor commands have on the immediate sensory inputs. Our insight is that the movement of the agent provides a cue that allows the duality between agent and environment to be learned. To instantiate this idea, we present Ego-Foresight, a self-supervised method for disentangling agent and environment based on motion and prediction. Our main finding is self-supervised agent-awareness by visuomotor prediction of the agent improves sample-efficiency and performance of the underlying RL algorithm. To test our approach, we first study its ability to visually predict agent movement irrespective of the environment, in simulated and real-world robotic data. Then, we integrate Ego-Foresight with a model-free RL algorithm to solve simulated robotic tasks, showing that self-supervised agent-awareness can improve sample-efficiency and performance in RL.",
    "summary": "arXiv:2407.01570v2 Announce Type: replace-cross Abstract: Despite the significant advancements in Deep Reinforcement Learning (RL) observed in the last decade, the amount of training experience necessary to learn effective policies remains one of the primary concerns both in simulated and real environments. Looking to solve this issue, previous work has shown that improved training efficiency can be achieved by separately modeling agent and environment, but usually requiring a supervisory agent mask. In contrast to RL, humans can perfect a new skill from a small number of trials and in most cases do so without a supervisory signal, making neuroscientific studies of human development a valuable source of inspiration for RL. In particular, we explore the idea of motor prediction, which states that humans develop an internal model of themselves and of the consequences that their motor commands have on the immediate sensory inputs. Our insight is that the movement of the agent provides a cue that allows the duality between agent and environment to be learned. To instantiate this idea, we present Ego-Foresight, a self-supervised method for disentangling agent and environment based on motion and prediction. Our main finding is self-supervised agent-awareness by visuomotor prediction of the agent improves sample-efficiency and performance of the underlying RL algorithm. To test our approach, we first study its ability to visually predict agent movement irrespective of the environment, in simulated and real-world robotic data. Then, we integrate Ego-Foresight with a model-free RL algorithm to solve simulated robotic tasks, showing that self-supervised agent-awareness can improve sample-efficiency and performance in RL.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.01570",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Start building with Gemini 2.0 Flash and Flash-Lite",
    "description": "Gemini 2.0 Flash-Lite is now generally available in the Gemini API for production use in Google AI Studio and for enterprise customers on Vertex AI",
    "summary": "Gemini 2.0 Flash-Lite is now generally available in the Gemini API for production use in Google AI Studio and for enterprise customers on Vertex AI",
    "pubDate": "Tue, 25 Feb 2025 18:02:12 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/start-building-with-gemini-20-flash-and-flash-lite/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Flash_Family_meta.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Hello GPT-4o",
    "description": "We‚Äôre announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.",
    "summary": "We‚Äôre announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.",
    "pubDate": "Mon, 13 May 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hello-gpt-4o",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing data residency in Asia",
    "description": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "summary": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "pubDate": "Wed, 07 May 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-data-residency-in-asia",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating over 130,000 Hugging Face models with ONNX Runtime",
    "description": "",
    "summary": "Accelerating over 130,000 Hugging Face models with ONNX Runtime What is ONNX Runtime? ONNX Runtime i...",
    "pubDate": "Wed, 04 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ort-accelerating-hf-models",
    "thumbnail": "https://huggingface.co/blog/assets/ort_accelerating_hf_models/thumbnail.png"
  },
  {
    "title": "Accelerating Document AI",
    "description": "",
    "summary": "Accelerating Document AI Enterprises are full of documents containing knowledge that isn't accessibl...",
    "pubDate": "Mon, 21 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/document-ai",
    "thumbnail": "https://huggingface.co/blog/assets/112_document-ai/thumbnail.png"
  },
  {
    "title": "Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence",
    "description": "arXiv:2506.23503v1 Announce Type: new Abstract: Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the irrational thought patterns associated with mental health disorders, but its effectiveness relies on accurately identifying cognitive pathways to provide targeted treatment. In today's digital age, individuals often express negative emotions on social media, where they may reveal cognitive distortions, and in severe cases, exhibit suicidal tendencies. However, there is a significant gap in methodologies designed to analyze these cognitive pathways, which could be critical for psychotherapists aiming to deliver timely and effective interventions in online environments. Cognitive Behavioral Therapy (CBT) framework leveraging acceptance, commitment and data augmentation to categorize and address both textual and visual content as positive or negative. Specifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5, PEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages focusing on detecting negative emotions and cognitive distortions within social media data. While existing models are primarily designed to identify negative thoughts, the proposed system goes beyond this by predicting additional negative side effects and other potential mental health disorders likes Phobias, Eating Disorders. This enhancement allows for a more comprehensive understanding and intervention strategy, offering psychotherapists a powerful tool for early detection and treatment of various psychological issues.",
    "summary": "arXiv:2506.23503v1 Announce Type: new Abstract: Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the irrational thought patterns associated with mental health disorders, but its effectiveness relies on accurately identifying cognitive pathways to provide targeted treatment. In today's digital age, individuals often express negative emotions on social media, where they may reveal cognitive distortions, and in severe cases, exhibit suicidal tendencies. However, there is a significant gap in methodologies designed to analyze these cognitive pathways, which could be critical for psychotherapists aiming to deliver timely and effective interventions in online environments. Cognitive Behavioral Therapy (CBT) framework leveraging acceptance, commitment and data augmentation to categorize and address both textual and visual content as positive or negative. Specifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5, PEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages focusing on detecting negative emotions and cognitive distortions within social media data. While existing models are primarily designed to identify negative thoughts, the proposed system goes beyond this by predicting additional negative side effects and other potential mental health disorders likes Phobias, Eating Disorders. This enhancement allows for a more comprehensive understanding and intervention strategy, offering psychotherapists a powerful tool for early detection and treatment of various psychological issues.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23503",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Generating Human-level Text with Contrastive Search in Transformers ü§ó",
    "description": "",
    "summary": "Generating Human-level Text with Contrastive Search in Transformers ü§ó 1. Introduction: Natural langu...",
    "pubDate": "Tue, 08 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-csearch",
    "thumbnail": "https://huggingface.co/blog/assets/115_introducing_contrastive_search/thumbnail.png"
  },
  {
    "title": "Convert Transformers to ONNX with Hugging Face Optimum",
    "description": "",
    "summary": "Convert Transformers to ONNX with Hugging Face Optimum Hundreds of Transformers experiments and mode...",
    "pubDate": "Wed, 22 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/convert-transformers-to-onnx",
    "thumbnail": "https://huggingface.co/blog/assets/81_convert_transformers_to_onnx/thumbnail.png"
  },
  {
    "title": "Getting Started with Sentiment Analysis using Python",
    "description": "",
    "summary": "Getting Started with Sentiment Analysis using Python Sentiment analysis is the automated process of ...",
    "pubDate": "Wed, 02 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-python",
    "thumbnail": "https://huggingface.co/blog/assets/50_sentiment_python/thumbnail.png"
  },
  {
    "title": "Elon Musk wanted an OpenAI for-profit",
    "description": "Elon Musk‚Äôs latest legal filing against OpenAI marks his fourth attempt in less than a year to reframe his claims. However, his own words and actions speak for themselves‚Äîin 2017, Elon not only wanted, but actually created, a for-profit as OpenAI‚Äôs proposed new structure.",
    "summary": "Elon Musk‚Äôs latest legal filing against OpenAI marks his fourth attempt in less than a year to reframe his claims. However, his own words and actions speak for themselves‚Äîin 2017, Elon not only wanted, but actually created, a for-profit as OpenAI‚Äôs proposed new structure.",
    "pubDate": "Fri, 13 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/elon-musk-wanted-an-openai-for-profit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Artificial Intelligence in Creative Industries: Advances Prior to 2025",
    "description": "arXiv:2501.02725v4 Announce Type: replace Abstract: The rapid advancements in artificial intelligence (AI), particularly in generative AI and large language models (LLMs), have profoundly impacted the creative industries, enabling more innovative content creation, enhancing workflows, and democratizing access to creative tools. This paper explores these technological shifts, with particular focus on how those that have emerged since our previous review in 2022 have expanded creative opportunities and improved efficiency. These technological advancements have enhanced the capabilities of text-to-image, text-to-video, and multimodal generation technologies. In particular, key breakthroughs in LLMs have established new benchmarks in conversational AI, while advancements in image generators have revolutionized content creation. We also discuss the integration of AI into post-production workflows, which has significantly accelerated and improved traditional processes. Once content has been created, it must be delivered to its audiences; the media industry is now facing the demands of increased communication traffic due to creative content. We therefore include a discussion of how AI is beginning to transform the way we represent and compress media content. We highlight the trend toward unified AI frameworks capable of addressing and integrating multiple creative tasks, and we underscore the importance of human insight to drive the creative process and oversight to mitigate AI-generated inaccuracies. Finally, we explore AI's future potential in the creative sector, stressing the need to navigate emerging challenges and to maximize its benefits while addressing the associated risks.",
    "summary": "arXiv:2501.02725v4 Announce Type: replace Abstract: The rapid advancements in artificial intelligence (AI), particularly in generative AI and large language models (LLMs), have profoundly impacted the creative industries, enabling more innovative content creation, enhancing workflows, and democratizing access to creative tools. This paper explores these technological shifts, with particular focus on how those that have emerged since our previous review in 2022 have expanded creative opportunities and improved efficiency. These technological advancements have enhanced the capabilities of text-to-image, text-to-video, and multimodal generation technologies. In particular, key breakthroughs in LLMs have established new benchmarks in conversational AI, while advancements in image generators have revolutionized content creation. We also discuss the integration of AI into post-production workflows, which has significantly accelerated and improved traditional processes. Once content has been created, it must be delivered to its audiences; the media industry is now facing the demands of increased communication traffic due to creative content. We therefore include a discussion of how AI is beginning to transform the way we represent and compress media content. We highlight the trend toward unified AI frameworks capable of addressing and integrating multiple creative tasks, and we underscore the importance of human insight to drive the creative process and oversight to mitigate AI-generated inaccuracies. Finally, we explore AI's future potential in the creative sector, stressing the need to navigate emerging challenges and to maximize its benefits while addressing the associated risks.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.02725",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI GPT-4.5 System Card",
    "description": "We‚Äôre releasing a research preview of OpenAI GPT‚Äë4.5, our largest and most knowledgeable model yet.",
    "summary": "We‚Äôre releasing a research preview of OpenAI GPT‚Äë4.5, our largest and most knowledgeable model yet.",
    "pubDate": "Thu, 27 Feb 2025 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-5-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SigLIP 2: A better multilingual vision language encoder",
    "description": "",
    "summary": "SigLIP 2: A better multilingual vision language encoder TL;DR Today Google releases a new and better...",
    "pubDate": "Fri, 21 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/siglip2",
    "thumbnail": "https://huggingface.co/blog/assets/siglip2/thumbnail.png"
  },
  {
    "title": "How to Move Your Dragon: Text-to-Motion Synthesis for Large-Vocabulary Objects",
    "description": "arXiv:2503.04257v2 Announce Type: replace-cross Abstract: Motion synthesis for diverse object categories holds great potential for 3D content creation but remains underexplored due to two key challenges: (1) the lack of comprehensive motion datasets that include a wide range of high-quality motions and annotations, and (2) the absence of methods capable of handling heterogeneous skeletal templates from diverse objects. To address these challenges, we contribute the following: First, we augment the Truebones Zoo dataset, a high-quality animal motion dataset covering over 70 species, by annotating it with detailed text descriptions, making it suitable for text-based motion synthesis. Second, we introduce rig augmentation techniques that generate diverse motion data while preserving consistent dynamics, enabling models to adapt to various skeletal configurations. Finally, we redesign existing motion diffusion models to dynamically adapt to arbitrary skeletal templates, enabling motion synthesis for a diverse range of objects with varying structures. Experiments show that our method learns to generate high-fidelity motions from textual descriptions for diverse and even unseen objects, setting a strong foundation for motion synthesis across diverse object categories and skeletal templates. Qualitative results are available at: $href{https://t2m4lvo.github.io}{https://t2m4lvo.github.io}$.",
    "summary": "arXiv:2503.04257v2 Announce Type: replace-cross Abstract: Motion synthesis for diverse object categories holds great potential for 3D content creation but remains underexplored due to two key challenges: (1) the lack of comprehensive motion datasets that include a wide range of high-quality motions and annotations, and (2) the absence of methods capable of handling heterogeneous skeletal templates from diverse objects. To address these challenges, we contribute the following: First, we augment the Truebones Zoo dataset, a high-quality animal motion dataset covering over 70 species, by annotating it with detailed text descriptions, making it suitable for text-based motion synthesis. Second, we introduce rig augmentation techniques that generate diverse motion data while preserving consistent dynamics, enabling models to adapt to various skeletal configurations. Finally, we redesign existing motion diffusion models to dynamically adapt to arbitrary skeletal templates, enabling motion synthesis for a diverse range of objects with varying structures. Experiments show that our method learns to generate high-fidelity motions from textual descriptions for diverse and even unseen objects, setting a strong foundation for motion synthesis across diverse object categories and skeletal templates. Qualitative results are available at: $href{https://t2m4lvo.github.io}{https://t2m4lvo.github.io}$.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.04257",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-Tune Whisper with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune Whisper For Multilingual ASR with ü§ó Transformers In this blog, we present a step-by-step g...",
    "pubDate": "Thu, 03 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-whisper",
    "thumbnail": "https://huggingface.co/blog/assets/111_fine_tune_whisper/thumbnail.jpg"
  },
  {
    "title": "Introducing the LiveCodeBench Leaderboard - Holistic and Contamination-Free Evaluation of Code LLMs",
    "description": "",
    "summary": "Introducing the LiveCodeBench Leaderboard - Holistic and Contamination-Free Evaluation of Code LLMs ...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-livecodebench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "Introducing GPT-4o and more tools to ChatGPT free users",
    "description": "Introducing GPT-4o and more tools to ChatGPT free users We are launching our newest flagship model and making more capabilities available for free in ChatGPT.",
    "summary": "Introducing GPT-4o and more tools to ChatGPT free users We are launching our newest flagship model and making more capabilities available for free in ChatGPT.",
    "pubDate": "Mon, 13 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-and-more-tools-to-chatgpt-free",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building a custom math tutor powered by ChatGPT",
    "description": "ChatGPT and personal tutoring",
    "summary": "ChatGPT and personal tutoring",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/my-dog-the-math-tutor",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An early warning system for novel AI risks",
    "description": "New research proposes a framework for evaluating general-purpose models against novel threats",
    "summary": "New research proposes a framework for evaluating general-purpose models against novel threats",
    "pubDate": "Thu, 25 May 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/an-early-warning-system-for-novel-ai-risks/",
    "thumbnail": "https://lh3.googleusercontent.com/REkFCC8KEOAocMWBwcHOxKM6K2zRs_qpMeUhnmHYkkGSbPPCLRhPDluhoZzx2k6_b4XvgZmhUqeuko9BXZZIPLmGR1q4BycDjLuDFQ5G5FDYPKD0x08=w1200-h630-n-nu"
  },
  {
    "title": "Hugging Face on AMD Instinct MI300 GPU",
    "description": "",
    "summary": "Hugging Face on AMD Instinct MI300 GPU Join the next Hugging Cast on June 6th to ask questions to th...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-amd-mi300",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "Putting ethical principles at the core of research lifecycle",
    "description": "",
    "summary": "Putting ethical principles at the core of the research lifecycle Ethical charter - Multimodal projec...",
    "pubDate": "Thu, 19 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethical-charter-multimodal",
    "thumbnail": "https://huggingface.co/blog/assets/71_ethical-charter/thumbnail.jpg"
  },
  {
    "title": "Scalable Non-Equivariant 3D Molecule Generation via Rotational Alignment",
    "description": "arXiv:2506.10186v2 Announce Type: replace-cross Abstract: Equivariant diffusion models have achieved impressive performance in 3D molecule generation. These models incorporate Euclidean symmetries of 3D molecules by utilizing an SE(3)-equivariant denoising network. However, specialized equivariant architectures limit the scalability and efficiency of diffusion models. In this paper, we propose an approach that relaxes such equivariance constraints. Specifically, our approach learns a sample-dependent SO(3) transformation for each molecule to construct an aligned latent space. A non-equivariant diffusion model is then trained over the aligned representations. Experimental results demonstrate that our approach performs significantly better than previously reported non-equivariant models. It yields sample quality comparable to state-of-the-art equivariant diffusion models and offers improved training and sampling efficiency. Our code is available at https://github.com/skeletondyh/RADM",
    "summary": "arXiv:2506.10186v2 Announce Type: replace-cross Abstract: Equivariant diffusion models have achieved impressive performance in 3D molecule generation. These models incorporate Euclidean symmetries of 3D molecules by utilizing an SE(3)-equivariant denoising network. However, specialized equivariant architectures limit the scalability and efficiency of diffusion models. In this paper, we propose an approach that relaxes such equivariance constraints. Specifically, our approach learns a sample-dependent SO(3) transformation for each molecule to construct an aligned latent space. A non-equivariant diffusion model is then trained over the aligned representations. Experimental results demonstrate that our approach performs significantly better than previously reported non-equivariant models. It yields sample quality comparable to state-of-the-art equivariant diffusion models and offers improved training and sampling efficiency. Our code is available at https://github.com/skeletondyh/RADM",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.10186",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Announcing The Stargate Project",
    "description": "Announcing The Stargate Project",
    "summary": "Announcing The Stargate Project",
    "pubDate": "Tue, 21 Jan 2025 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/announcing-the-stargate-project",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models",
    "description": "arXiv:2506.23692v1 Announce Type: new Abstract: While AI for Science (AI4S) serves as an analytical tool in the current research paradigm, it doesn't solve its core inefficiency. We propose 'Agent for Science' (Agent4S)-the use of LLM-driven agents to automate the entire research workflow-as the true Fifth Scientific Paradigm. This paper introduces a five-level classification for Agent4S, outlining a clear roadmap from simple task automation to fully autonomous, collaborative 'AI Scientists.' This framework defines the next revolutionary step in scientific discovery.",
    "summary": "arXiv:2506.23692v1 Announce Type: new Abstract: While AI for Science (AI4S) serves as an analytical tool in the current research paradigm, it doesn't solve its core inefficiency. We propose 'Agent for Science' (Agent4S)-the use of LLM-driven agents to automate the entire research workflow-as the true Fifth Scientific Paradigm. This paper introduces a five-level classification for Agent4S, outlining a clear roadmap from simple task automation to fully autonomous, collaborative 'AI Scientists.' This framework defines the next revolutionary step in scientific discovery.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23692",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more",
    "description": "We‚Äôre releasing two updated production-ready Gemini models",
    "summary": "We‚Äôre releasing two updated production-ready Gemini models",
    "pubDate": "Tue, 24 Sep 2024 16:03:03 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini-15-Flash-Social_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Welcome Fireworks.ai on the Hub üéÜ",
    "description": "",
    "summary": "Welcome Fireworks.ai on the Hub üéÜ Following our recent announcement on Inference Providers on the Hu...",
    "pubDate": "Fri, 14 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fireworks-ai",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-fireworks.jpg"
  },
  {
    "title": "Vulnerable Road User Detection and Safety Enhancement: A Comprehensive Survey",
    "description": "arXiv:2405.19202v5 Announce Type: replace-cross Abstract: Traffic incidents involving vulnerable road users (VRUs) constitute a significant proportion of global road accidents. Advances in traffic communication ecosystems, coupled with sophisticated signal processing and machine learning techniques, have facilitated the utilization of data from diverse sensors. Despite these advancements and the availability of extensive datasets, substantial progress is required to mitigate traffic casualties. This paper provides a comprehensive survey of state-of-the-art technologies and methodologies to enhance the safety of VRUs. The study investigates the communication networks between vehicles and VRUs, emphasizing the integration of advanced sensors and the availability of relevant datasets. It explores preprocessing techniques and data fusion methods to enhance sensor data quality. Furthermore, our study assesses critical simulation environments essential for developing and testing VRU safety systems. Our research also highlights recent advances in VRU detection and classification algorithms, addressing challenges such as variable environmental conditions. Additionally, we cover cutting-edge research in predicting VRU intentions and behaviors, which is mandatory for proactive collision avoidance strategies. Through this survey, we aim to provide a comprehensive understanding of the current landscape of VRU safety technologies, identifying areas of progress and areas needing further research and development.",
    "summary": "arXiv:2405.19202v5 Announce Type: replace-cross Abstract: Traffic incidents involving vulnerable road users (VRUs) constitute a significant proportion of global road accidents. Advances in traffic communication ecosystems, coupled with sophisticated signal processing and machine learning techniques, have facilitated the utilization of data from diverse sensors. Despite these advancements and the availability of extensive datasets, substantial progress is required to mitigate traffic casualties. This paper provides a comprehensive survey of state-of-the-art technologies and methodologies to enhance the safety of VRUs. The study investigates the communication networks between vehicles and VRUs, emphasizing the integration of advanced sensors and the availability of relevant datasets. It explores preprocessing techniques and data fusion methods to enhance sensor data quality. Furthermore, our study assesses critical simulation environments essential for developing and testing VRU safety systems. Our research also highlights recent advances in VRU detection and classification algorithms, addressing challenges such as variable environmental conditions. Additionally, we cover cutting-edge research in predicting VRU intentions and behaviors, which is mandatory for proactive collision avoidance strategies. Through this survey, we aim to provide a comprehensive understanding of the current landscape of VRU safety technologies, identifying areas of progress and areas needing further research and development.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.19202",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Beware of Calibration Data for Pruning Large Language Models",
    "description": "arXiv:2410.17711v2 Announce Type: replace-cross Abstract: As large language models (LLMs) are widely applied across various fields, model compression has become increasingly crucial for reducing costs and improving inference efficiency. Post-training pruning is a promising method that does not require resource-intensive iterative training and only needs a small amount of calibration data to assess the importance of parameters. Recent research has enhanced post-training pruning from different aspects but few of them systematically explore the effects of calibration data, and it is unclear if there exist better calibration data construction strategies. We fill this blank and surprisingly observe that calibration data is also crucial to post-training pruning, especially for high sparsity. Through controlled experiments on important influence factors of calibration data, including the pruning settings, the amount of data, and its similarity with pre-training data, we observe that a small size of data is adequate, and more similar data to its pre-training stage can yield better performance. As pre-training data is usually inaccessible for advanced LLMs, we further provide a self-generating calibration data synthesis strategy to construct feasible calibration data. Experimental results on recent strong open-source LLMs (e.g., DCLM, and LLaMA-3) show that the proposed strategy can enhance the performance of strong pruning methods (e.g., Wanda, DSnoT, OWL) by a large margin (up to $2.68%$). Code is available at https://github.com/Dereck0602/calibration_data.",
    "summary": "arXiv:2410.17711v2 Announce Type: replace-cross Abstract: As large language models (LLMs) are widely applied across various fields, model compression has become increasingly crucial for reducing costs and improving inference efficiency. Post-training pruning is a promising method that does not require resource-intensive iterative training and only needs a small amount of calibration data to assess the importance of parameters. Recent research has enhanced post-training pruning from different aspects but few of them systematically explore the effects of calibration data, and it is unclear if there exist better calibration data construction strategies. We fill this blank and surprisingly observe that calibration data is also crucial to post-training pruning, especially for high sparsity. Through controlled experiments on important influence factors of calibration data, including the pruning settings, the amount of data, and its similarity with pre-training data, we observe that a small size of data is adequate, and more similar data to its pre-training stage can yield better performance. As pre-training data is usually inaccessible for advanced LLMs, we further provide a self-generating calibration data synthesis strategy to construct feasible calibration data. Experimental results on recent strong open-source LLMs (e.g., DCLM, and LLaMA-3) show that the proposed strategy can enhance the performance of strong pruning methods (e.g., Wanda, DSnoT, OWL) by a large margin (up to $2.68%$). Code is available at https://github.com/Dereck0602/calibration_data.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.17711",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning",
    "description": "arXiv:2506.23793v1 Announce Type: new Abstract: Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot trajectory planning problems, where multiple homogeneous robots simultaneously move in the shared environment. While solving MAPF optimally has been proven to be NP-hard, scalable, and efficient, solvers are vital for real-world applications like logistics, search-and-rescue, etc. To this end, decentralized suboptimal MAPF solvers that leverage machine learning have come on stage. Building on the success of the recently introduced MAPF-GPT, a pure imitation learning solver, we introduce MAPF-GPT-DDG. This novel approach effectively fine-tunes the pre-trained MAPF model using centralized expert data. Leveraging a novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training while significantly improving performance at test time. Our experiments demonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF solvers, including the original MAPF-GPT, regarding solution quality across many testing scenarios. Remarkably, it can work with MAPF instances involving up to 1 million agents in a single environment, setting a new milestone for scalability in MAPF domains.",
    "summary": "arXiv:2506.23793v1 Announce Type: new Abstract: Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot trajectory planning problems, where multiple homogeneous robots simultaneously move in the shared environment. While solving MAPF optimally has been proven to be NP-hard, scalable, and efficient, solvers are vital for real-world applications like logistics, search-and-rescue, etc. To this end, decentralized suboptimal MAPF solvers that leverage machine learning have come on stage. Building on the success of the recently introduced MAPF-GPT, a pure imitation learning solver, we introduce MAPF-GPT-DDG. This novel approach effectively fine-tunes the pre-trained MAPF model using centralized expert data. Leveraging a novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training while significantly improving performance at test time. Our experiments demonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF solvers, including the original MAPF-GPT, regarding solution quality across many testing scenarios. Remarkably, it can work with MAPF instances involving up to 1 million agents in a single environment, setting a new milestone for scalability in MAPF domains.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23793",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The court rejects Elon‚Äôs latest attempt to slow OpenAI down",
    "description": "We welcome the court‚Äôs March 4, 2025, decision rejecting Elon Musk‚Äôs latest attempt to slow down OpenAI for his personal benefit.",
    "summary": "We welcome the court‚Äôs March 4, 2025, decision rejecting Elon Musk‚Äôs latest attempt to slow down OpenAI for his personal benefit.",
    "pubDate": "Fri, 14 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/court-rejects-elon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploying the AI Comic Factory using the Inference API",
    "description": "",
    "summary": "Deploying the AI Comic Factory using the Inference API We recently announced Inference for PROs, our...",
    "pubDate": "Mon, 02 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-comic-factory",
    "thumbnail": "https://huggingface.co/blog/assets/165_ai_comic_factory/thumbnail.jpg"
  },
  {
    "title": "DALL¬∑E API now available in public beta",
    "description": "Starting today, developers can begin building apps with the DALL¬∑E API.",
    "summary": "Starting today, developers can begin building apps with the DALL¬∑E API.",
    "pubDate": "Thu, 03 Nov 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-api-now-available-in-public-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Comparative Evaluation of ChatGPT and DeepSeek Across Key NLP Tasks: Strengths, Weaknesses, and Domain-Specific Performance",
    "description": "arXiv:2506.18501v2 Announce Type: replace-cross Abstract: The increasing use of large language models (LLMs) in natural language processing (NLP) tasks has sparked significant interest in evaluating their effectiveness across diverse applications. While models like ChatGPT and DeepSeek have shown strong results in many NLP domains, a comprehensive evaluation is needed to understand their strengths, weaknesses, and domain-specific abilities. This is critical as these models are applied to various tasks, from sentiment analysis to more nuanced tasks like textual entailment and translation. This study aims to evaluate ChatGPT and DeepSeek across five key NLP tasks: sentiment analysis, topic classification, text summarization, machine translation, and textual entailment. A structured experimental protocol is used to ensure fairness and minimize variability. Both models are tested with identical, neutral prompts and evaluated on two benchmark datasets per task, covering domains like news, reviews, and formal/informal texts. The results show that DeepSeek excels in classification stability and logical reasoning, while ChatGPT performs better in tasks requiring nuanced understanding and flexibility. These findings provide valuable insights for selecting the appropriate LLM based on task requirements.",
    "summary": "arXiv:2506.18501v2 Announce Type: replace-cross Abstract: The increasing use of large language models (LLMs) in natural language processing (NLP) tasks has sparked significant interest in evaluating their effectiveness across diverse applications. While models like ChatGPT and DeepSeek have shown strong results in many NLP domains, a comprehensive evaluation is needed to understand their strengths, weaknesses, and domain-specific abilities. This is critical as these models are applied to various tasks, from sentiment analysis to more nuanced tasks like textual entailment and translation. This study aims to evaluate ChatGPT and DeepSeek across five key NLP tasks: sentiment analysis, topic classification, text summarization, machine translation, and textual entailment. A structured experimental protocol is used to ensure fairness and minimize variability. Both models are tested with identical, neutral prompts and evaluated on two benchmark datasets per task, covering domains like news, reviews, and formal/informal texts. The results show that DeepSeek excels in classification stability and logical reasoning, while ChatGPT performs better in tasks requiring nuanced understanding and flexibility. These findings provide valuable insights for selecting the appropriate LLM based on task requirements.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18501",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI Speech Recognition in Unity",
    "description": "",
    "summary": "AI Speech Recognition in Unity Introduction This tutorial guides you through the process of implemen...",
    "pubDate": "Fri, 02 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-asr",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-asr-thumbnail.png"
  },
  {
    "title": "Ethics and Society Newsletter #3: Ethical Openness at Hugging Face",
    "description": "",
    "summary": "Ethics and Society Newsletter #3: Ethical Openness at Hugging Face Mission: Open and Good ML In our ...",
    "pubDate": "Thu, 30 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-3",
    "thumbnail": "https://huggingface.co/blog/assets/137_ethics_soc_3/ethics_3_thumbnail.png"
  },
  {
    "title": "Security on the path to AGI",
    "description": "At OpenAI, we proactively adapt, including by building comprehensive security measures directly into our infrastructure and models.",
    "summary": "At OpenAI, we proactively adapt, including by building comprehensive security measures directly into our infrastructure and models.",
    "pubDate": "Wed, 26 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/security-on-the-path-to-agi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Holistic Approach to Undesired Content Detection in the Real World",
    "description": "We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation.",
    "summary": "We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-holistic-approach-to-undesired-content-detection-in-the-real-world",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Exploration Behavior of Untrained Policies",
    "description": "arXiv:2506.22566v1 Announce Type: cross Abstract: Exploration remains a fundamental challenge in reinforcement learning (RL), particularly in environments with sparse or adversarial reward structures. In this work, we study how the architecture of deep neural policies implicitly shapes exploration before training. We theoretically and empirically demonstrate strategies for generating ballistic or diffusive trajectories from untrained policies in a toy model. Using the theory of infinite-width networks and a continuous-time limit, we show that untrained policies return correlated actions and result in non-trivial state-visitation distributions. We discuss the distributions of the corresponding trajectories for a standard architecture, revealing insights into inductive biases for tackling exploration. Our results establish a theoretical and experimental framework for using policy initialization as a design tool to understand exploration behavior in early training.",
    "summary": "arXiv:2506.22566v1 Announce Type: cross Abstract: Exploration remains a fundamental challenge in reinforcement learning (RL), particularly in environments with sparse or adversarial reward structures. In this work, we study how the architecture of deep neural policies implicitly shapes exploration before training. We theoretically and empirically demonstrate strategies for generating ballistic or diffusive trajectories from untrained policies in a toy model. Using the theory of infinite-width networks and a continuous-time limit, we show that untrained policies return correlated actions and result in non-trivial state-visitation distributions. We discuss the distributions of the corresponding trajectories for a standard architecture, revealing insights into inductive biases for tackling exploration. Our results establish a theoretical and experimental framework for using policy initialization as a design tool to understand exploration behavior in early training.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22566",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Announcing Evaluation on the Hub",
    "description": "",
    "summary": "Announcing Evaluation on the Hub This project has been archived. If you want to evaluate LLMs on the...",
    "pubDate": "Tue, 28 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eval-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/82_eval_on_the_hub/thumbnail.png"
  },
  {
    "title": "OpenAI Five defeats Dota 2 world champions",
    "description": "OpenAI Five is the first AI to beat the world champions in an esports game, having won two back-to-back games versus the world champion Dota 2 team,¬†OG, at¬†Finals¬†this weekend. Both OpenAI Five and DeepMind‚Äôs AlphaStar had previously beaten good pros privately but lost their live pro matches, making this also the first time an AI has beaten esports pros on¬†livestream.",
    "summary": "OpenAI Five is the first AI to beat the world champions in an esports game, having won two back-to-back games versus the world champion Dota 2 team,¬†OG, at¬†Finals¬†this weekend. Both OpenAI Five and DeepMind‚Äôs AlphaStar had previously beaten good pros privately but lost their live pro matches, making this also the first time an AI has beaten esports pros on¬†livestream.",
    "pubDate": "Mon, 15 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-defeats-dota-2-world-champions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding complex trends with deep research",
    "description": "How OpenAI deep research helps Bain & Company understand complex industry trends.",
    "summary": "How OpenAI deep research helps Bain & Company understand complex industry trends.",
    "pubDate": "Sun, 02 Feb 2025 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Primer on the EU AI Act: What It Means for AI Providers and Deployers",
    "description": "We‚Äôre sharing a preliminary overview of the EU AI Act including upcoming deadlines and requirements, with a particular focus on prohibited and high-risk use cases",
    "summary": "We‚Äôre sharing a preliminary overview of the EU AI Act including upcoming deadlines and requirements, with a particular focus on prohibited and high-risk use cases",
    "pubDate": "Tue, 30 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/a-primer-on-the-eu-ai-act",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2020: Final projects",
    "description": "Our third class of OpenAI Scholars presented their final projects at virtual Demo Day, showcasing their research results from over the past five months.",
    "summary": "Our third class of OpenAI Scholars presented their final projects at virtual Demo Day, showcasing their research results from over the past five months.",
    "pubDate": "Thu, 09 Jul 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2020-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gathering human feedback",
    "description": "RL-Teacher is an open-source implementation of our interface to train AIs via occasional human feedback rather than hand-crafted reward functions. The underlying technique was developed as a step towards safe AI systems, but also applies to reinforcement learning problems with rewards that are hard to specify.",
    "summary": "RL-Teacher is an open-source implementation of our interface to train AIs via occasional human feedback rather than hand-crafted reward functions. The underlying technique was developed as a step towards safe AI systems, but also applies to reinforcement learning problems with rewards that are hard to specify.",
    "pubDate": "Thu, 03 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gathering-human-feedback",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Estonia and OpenAI to bring ChatGPT to schools nationwide",
    "description": "Estonia and OpenAI to bring ChatGPT to schools nationwide. OpenAI will work with the Estonian Government to provide students and teachers in the secondary school system with access to ChatGPT Edu.",
    "summary": "Estonia and OpenAI to bring ChatGPT to schools nationwide. OpenAI will work with the Estonian Government to provide students and teachers in the secondary school system with access to ChatGPT Edu.",
    "pubDate": "Tue, 25 Feb 2025 04:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/estonia-schools-and-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OmniEval: A Benchmark for Evaluating Omni-modal Models with Visual, Auditory, and Textual Inputs",
    "description": "arXiv:2506.20960v2 Announce Type: replace-cross Abstract: In this paper, we introduce OmniEval, a benchmark for evaluating omni-modality models like MiniCPM-O 2.6, which encompasses visual, auditory, and textual inputs. Compared with existing benchmarks, our OmniEval has several distinctive features: (i) Full-modal collaboration: We design evaluation tasks that highlight the strong coupling between audio and video, requiring models to effectively leverage the collaborative perception of all modalities; (ii) Diversity of videos: OmniEval includes 810 audio-visual synchronized videos, 285 Chinese videos and 525 English videos; (iii) Diversity and granularity of tasks: OmniEval contains 2617 question-answer pairs, comprising 1412 open-ended questions and 1205 multiple-choice questions. These questions are divided into 3 major task types and 12 sub-task types to achieve comprehensive evaluation. Among them, we introduce a more granular video localization task named Grounding. Then we conduct experiments on OmniEval with several omni-modality models. We hope that our OmniEval can provide a platform for evaluating the ability to construct and understand coherence from the context of all modalities. Codes and data could be found at https://omnieval-benchmark.github.io/.",
    "summary": "arXiv:2506.20960v2 Announce Type: replace-cross Abstract: In this paper, we introduce OmniEval, a benchmark for evaluating omni-modality models like MiniCPM-O 2.6, which encompasses visual, auditory, and textual inputs. Compared with existing benchmarks, our OmniEval has several distinctive features: (i) Full-modal collaboration: We design evaluation tasks that highlight the strong coupling between audio and video, requiring models to effectively leverage the collaborative perception of all modalities; (ii) Diversity of videos: OmniEval includes 810 audio-visual synchronized videos, 285 Chinese videos and 525 English videos; (iii) Diversity and granularity of tasks: OmniEval contains 2617 question-answer pairs, comprising 1412 open-ended questions and 1205 multiple-choice questions. These questions are divided into 3 major task types and 12 sub-task types to achieve comprehensive evaluation. Among them, we introduce a more granular video localization task named Grounding. Then we conduct experiments on OmniEval with several omni-modality models. We hope that our OmniEval can provide a platform for evaluating the ability to construct and understand coherence from the context of all modalities. Codes and data could be found at https://omnieval-benchmark.github.io/.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.20960",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ATGen: A Framework for Active Text Generation",
    "description": "arXiv:2506.23342v1 Announce Type: cross Abstract: Active learning (AL) has demonstrated remarkable potential in reducing the annotation effort required for training machine learning models. However, despite the surging popularity of natural language generation (NLG) tasks in recent years, the application of AL to NLG has been limited. In this paper, we introduce Active Text Generation (ATGen) - a comprehensive framework that bridges AL with text generation tasks, enabling the application of state-of-the-art AL strategies to NLG. Our framework simplifies AL-empowered annotation in NLG tasks using both human annotators and automatic annotation agents based on large language models (LLMs). The framework supports LLMs deployed as services, such as ChatGPT and Claude, or operated on-premises. Furthermore, ATGen provides a unified platform for smooth implementation and benchmarking of novel AL strategies tailored to NLG tasks. Finally, we present evaluation results for state-of-the-art AL strategies across diverse settings and multiple text generation tasks. We show that ATGen reduces both the effort of human annotators and costs associated with API calls to LLM-based annotation agents. The code of the framework is available on GitHub under the MIT license. The video presentation is available at http://atgen-video.nlpresearch.group",
    "summary": "arXiv:2506.23342v1 Announce Type: cross Abstract: Active learning (AL) has demonstrated remarkable potential in reducing the annotation effort required for training machine learning models. However, despite the surging popularity of natural language generation (NLG) tasks in recent years, the application of AL to NLG has been limited. In this paper, we introduce Active Text Generation (ATGen) - a comprehensive framework that bridges AL with text generation tasks, enabling the application of state-of-the-art AL strategies to NLG. Our framework simplifies AL-empowered annotation in NLG tasks using both human annotators and automatic annotation agents based on large language models (LLMs). The framework supports LLMs deployed as services, such as ChatGPT and Claude, or operated on-premises. Furthermore, ATGen provides a unified platform for smooth implementation and benchmarking of novel AL strategies tailored to NLG tasks. Finally, we present evaluation results for state-of-the-art AL strategies across diverse settings and multiple text generation tasks. We show that ATGen reduces both the effort of human annotators and costs associated with API calls to LLM-based annotation agents. The code of the framework is available on GitHub under the MIT license. The video presentation is available at http://atgen-video.nlpresearch.group",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23342",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Total noob‚Äôs intro to Hugging Face Transformers",
    "description": "",
    "summary": "Total noob‚Äôs intro to Hugging Face Transformers Welcome to 'A Total Noob‚Äôs Introduction to Hugging F...",
    "pubDate": "Fri, 22 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/noob_intro_transformers",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/guide.png"
  },
  {
    "title": "Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice",
    "description": "arXiv:2506.23924v1 Announce Type: new Abstract: Large language models (LLMs) have exhibited expert-level capabilities across various domains. However, their abilities to solve problems in Operations Research (OR) -- the analysis and optimization of mathematical models derived from real-world problems or their verbal descriptions -- remain underexplored. In this work, we take a first step toward evaluating LLMs' abilities to solve stochastic modeling problems, a core class of OR problems characterized by uncertainty and typically involving tools from probability, statistics, and stochastic processes. We manually procure a representative set of graduate-level homework and doctoral qualification-exam problems and test LLMs' abilities to solve them. We further leverage SimOpt, an open-source library of simulation-optimization problems and solvers, to investigate LLMs' abilities to make real-world decisions under uncertainty. Our results show that, though a nontrivial amount of work is still needed to reliably automate the stochastic modeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on par with human experts in both classroom and practical settings. These findings highlight the potential of building AI agents that assist OR researchers and amplify the real-world impact of OR through automation.",
    "summary": "arXiv:2506.23924v1 Announce Type: new Abstract: Large language models (LLMs) have exhibited expert-level capabilities across various domains. However, their abilities to solve problems in Operations Research (OR) -- the analysis and optimization of mathematical models derived from real-world problems or their verbal descriptions -- remain underexplored. In this work, we take a first step toward evaluating LLMs' abilities to solve stochastic modeling problems, a core class of OR problems characterized by uncertainty and typically involving tools from probability, statistics, and stochastic processes. We manually procure a representative set of graduate-level homework and doctoral qualification-exam problems and test LLMs' abilities to solve them. We further leverage SimOpt, an open-source library of simulation-optimization problems and solvers, to investigate LLMs' abilities to make real-world decisions under uncertainty. Our results show that, though a nontrivial amount of work is still needed to reliably automate the stochastic modeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on par with human experts in both classroom and practical settings. These findings highlight the potential of building AI agents that assist OR researchers and amplify the real-world impact of OR through automation.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23924",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Faster assisted generation support for Intel Gaudi",
    "description": "",
    "summary": "Faster assisted generation support for Intel Gaudi As model sizes grow, Generative AI implementation...",
    "pubDate": "Tue, 04 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/assisted-generation-support-gaudi",
    "thumbnail": "https://huggingface.co/blog/assets/assisted-generation-support-gaudi/thumbnail.png"
  },
  {
    "title": "The sweet taste of a new idea",
    "description": "Sendhil Mullainathan brings a lifetime of unique perspectives to research in behavioral economics and machine learning.",
    "summary": "Sendhil Mullainathan brings a lifetime of unique perspectives to research in behavioral economics and machine learning.",
    "pubDate": "Mon, 19 May 2025 16:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/sweet-taste-new-idea-sendhil-mullainathan-0519",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-sendhil-Mullainathan.jpg"
  },
  {
    "title": "Put AI to Work for Marketing Teams",
    "description": "Put AI to Work for Marketing Teams",
    "summary": "Put AI to Work for Marketing Teams",
    "pubDate": "Thu, 31 Oct 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-for-marketing-teams",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Codex",
    "description": "Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered by codex-1. With Codex, developers can simultaneously deploy multiple agents to independently handle coding tasks such as writing features, answering questions about your codebase, fixing bugs, and proposing pull requests for review.",
    "summary": "Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered by codex-1. With Codex, developers can simultaneously deploy multiple agents to independently handle coding tasks such as writing features, answering questions about your codebase, fixing bugs, and proposing pull requests for review.",
    "pubDate": "Fri, 16 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-codex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Boosting the customer retail experience with GPT-4o mini",
    "description": "Zalando boosts the customer experience with its Assistant, powered by GPT-4o mini",
    "summary": "Zalando boosts the customer experience with its Assistant, powered by GPT-4o mini",
    "pubDate": "Wed, 11 Dec 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zalando",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A New Perspective On AI Safety Through Control Theory Methodologies",
    "description": "arXiv:2506.23703v1 Announce Type: new Abstract: While artificial intelligence (AI) is advancing rapidly and mastering increasingly complex problems with astonishing performance, the safety assurance of such systems is a major concern. Particularly in the context of safety-critical, real-world cyber-physical systems, AI promises to achieve a new level of autonomy but is hampered by a lack of safety assurance. While data-driven control takes up recent developments in AI to improve control systems, control theory in general could be leveraged to improve AI safety. Therefore, this article outlines a new perspective on AI safety based on an interdisciplinary interpretation of the underlying data-generation process and the respective abstraction by AI systems in a system theory-inspired and system analysis-driven manner. In this context, the new perspective, also referred to as data control, aims to stimulate AI engineering to take advantage of existing safety analysis and assurance in an interdisciplinary way to drive the paradigm of data control. Following a top-down approach, a generic foundation for safety analysis and assurance is outlined at an abstract level that can be refined for specific AI systems and applications and is prepared for future innovation.",
    "summary": "arXiv:2506.23703v1 Announce Type: new Abstract: While artificial intelligence (AI) is advancing rapidly and mastering increasingly complex problems with astonishing performance, the safety assurance of such systems is a major concern. Particularly in the context of safety-critical, real-world cyber-physical systems, AI promises to achieve a new level of autonomy but is hampered by a lack of safety assurance. While data-driven control takes up recent developments in AI to improve control systems, control theory in general could be leveraged to improve AI safety. Therefore, this article outlines a new perspective on AI safety based on an interdisciplinary interpretation of the underlying data-generation process and the respective abstraction by AI systems in a system theory-inspired and system analysis-driven manner. In this context, the new perspective, also referred to as data control, aims to stimulate AI engineering to take advantage of existing safety analysis and assurance in an interdisciplinary way to drive the paradigm of data control. Following a top-down approach, a generic foundation for safety analysis and assurance is outlined at an abstract level that can be refined for specific AI systems and applications and is prepared for future innovation.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23703",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Block Sparse Matrices for Smaller and Faster Language Models",
    "description": "",
    "summary": "Block Sparse Matrices for Smaller and Faster Language Models Saving space and time, one zero at a ti...",
    "pubDate": "Thu, 10 Sep 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch_block_sparse",
    "thumbnail": "https://huggingface.co/blog/assets/04_pytorch_block_sparse/thumbnail.png"
  },
  {
    "title": "OpenAI Fellows Winter 2019 & Interns Summer 2019",
    "description": "We are now accepting applications for OpenAI Fellows and Interns for 2019.",
    "summary": "We are now accepting applications for OpenAI Fellows and Interns for 2019.",
    "pubDate": "Tue, 09 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows-interns-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A guide to setting up your own Hugging Face leaderboard: an end-to-end example with Vectara's hallucination leaderboard",
    "description": "",
    "summary": "A guide to setting up your own Hugging Face leaderboard: an end-to-end example with Vectara's halluc...",
    "pubDate": "Fri, 12 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-vectara",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "You could have designed state of the art positional encoding",
    "description": "",
    "summary": "You could have designed state of the art positional encoding Gall's Law A complex system that works ...",
    "pubDate": "Mon, 25 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/designing-positional-encoding",
    "thumbnail": "https://huggingface.co/blog/assets/designing-positional-encoding/thumbnail_posenc.png"
  },
  {
    "title": "Gemini 2.5 Pro Preview: even better coding performance",
    "description": "We‚Äôve seen developers doing amazing things with Gemini 2.5 Pro, so we decided to release an updated version a couple of weeks early to get into developers hands sooner.",
    "summary": "We‚Äôve seen developers doing amazing things with Gemini 2.5 Pro, so we decided to release an updated version a couple of weeks early to get into developers hands sooner.",
    "pubDate": "Tue, 06 May 2025 15:06:55 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-pro-preview-even-better-coding-performance/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini_2-5_pro_claybrook__dev_her.2e16d0ba.fill-1200x600.jpg"
  },
  {
    "title": "VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions",
    "description": "arXiv:2506.23236v1 Announce Type: cross Abstract: Parametric human body models play a crucial role in computer graphics and vision, enabling applications ranging from human motion analysis to understanding human-environment interactions. Traditionally, these models use surface meshes, which pose challenges in efficiently handling interactions with other geometric entities, such as objects and scenes, typically represented as meshes or point clouds. To address this limitation, recent research has explored volumetric neural implicit body models. However, existing works are either insufficiently robust for complex human articulations or impose high computational and memory costs, limiting their widespread use. To this end, we introduce VolumetricSMPL, a neural volumetric body model that leverages Neural Blend Weights (NBW) to generate compact, yet efficient MLP decoders. Unlike prior approaches that rely on large MLPs, NBW dynamically blends a small set of learned weight matrices using predicted shape- and pose-dependent coefficients, significantly improving computational efficiency while preserving expressiveness. VolumetricSMPL outperforms prior volumetric occupancy model COAP with 10x faster inference, 6x lower GPU memory usage, enhanced accuracy, and a Signed Distance Function (SDF) for efficient and differentiable contact modeling. We demonstrate VolumetricSMPL's strengths across four challenging tasks: (1) reconstructing human-object interactions from in-the-wild images, (2) recovering human meshes in 3D scenes from egocentric views, (3) scene-constrained motion synthesis, and (4) resolving self-intersections. Our results highlight its broad applicability and significant performance and efficiency gains.",
    "summary": "arXiv:2506.23236v1 Announce Type: cross Abstract: Parametric human body models play a crucial role in computer graphics and vision, enabling applications ranging from human motion analysis to understanding human-environment interactions. Traditionally, these models use surface meshes, which pose challenges in efficiently handling interactions with other geometric entities, such as objects and scenes, typically represented as meshes or point clouds. To address this limitation, recent research has explored volumetric neural implicit body models. However, existing works are either insufficiently robust for complex human articulations or impose high computational and memory costs, limiting their widespread use. To this end, we introduce VolumetricSMPL, a neural volumetric body model that leverages Neural Blend Weights (NBW) to generate compact, yet efficient MLP decoders. Unlike prior approaches that rely on large MLPs, NBW dynamically blends a small set of learned weight matrices using predicted shape- and pose-dependent coefficients, significantly improving computational efficiency while preserving expressiveness. VolumetricSMPL outperforms prior volumetric occupancy model COAP with 10x faster inference, 6x lower GPU memory usage, enhanced accuracy, and a Signed Distance Function (SDF) for efficient and differentiable contact modeling. We demonstrate VolumetricSMPL's strengths across four challenging tasks: (1) reconstructing human-object interactions from in-the-wild images, (2) recovering human meshes in 3D scenes from egocentric views, (3) scene-constrained motion synthesis, and (4) resolving self-intersections. Our results highlight its broad applicability and significant performance and efficiency gains.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23236",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Timm ‚ù§Ô∏è Transformers: Use any timm model with transformers",
    "description": "",
    "summary": "Timm ‚ù§Ô∏è Transformers: Use any timm model with transformers Get lightning-fast inference, quick quant...",
    "pubDate": "Thu, 16 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/timm-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/timm-transformers/thumbnail.png"
  },
  {
    "title": "The Falcon has landed in the Hugging Face ecosystem",
    "description": "",
    "summary": "The Falcon has landed in the Hugging Face ecosystem Falcon is a new family of state-of-the-art langu...",
    "pubDate": "Mon, 05 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon",
    "thumbnail": "https://huggingface.co/blog/assets/147_falcon/falcon_thumbnail.jpg"
  },
  {
    "title": "DALL¬∑E: Creating images from text",
    "description": "We‚Äôve trained a neural network called DALL¬∑E that creates images from text captions for a wide range of concepts expressible in natural¬†language.",
    "summary": "We‚Äôve trained a neural network called DALL¬∑E that creates images from text captions for a wide range of concepts expressible in natural¬†language.",
    "pubDate": "Tue, 05 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More",
    "description": "",
    "summary": "Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More At Inceptio...",
    "pubDate": "Tue, 08 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-3c3h-aragen-ifeval",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_3c3h_aragen.png"
  },
  {
    "title": "Spotlight-TTS: Spotlighting the Style via Voiced-Aware Style Extraction and Style Direction Adjustment for Expressive Text-to-Speech",
    "description": "arXiv:2505.20868v2 Announce Type: replace-cross Abstract: Recent advances in expressive text-to-speech (TTS) have introduced diverse methods based on style embedding extracted from reference speech. However, synthesizing high-quality expressive speech remains challenging. We propose Spotlight-TTS, which exclusively emphasizes style via voiced-aware style extraction and style direction adjustment. Voiced-aware style extraction focuses on voiced regions highly related to style while maintaining continuity across different speech regions to improve expressiveness. We adjust the direction of the extracted style for optimal integration into the TTS model, which improves speech quality. Experimental results demonstrate that Spotlight-TTS achieves superior performance compared to baseline models in terms of expressiveness, overall speech quality, and style transfer capability. Our audio samples are publicly available.",
    "summary": "arXiv:2505.20868v2 Announce Type: replace-cross Abstract: Recent advances in expressive text-to-speech (TTS) have introduced diverse methods based on style embedding extracted from reference speech. However, synthesizing high-quality expressive speech remains challenging. We propose Spotlight-TTS, which exclusively emphasizes style via voiced-aware style extraction and style direction adjustment. Voiced-aware style extraction focuses on voiced regions highly related to style while maintaining continuity across different speech regions to improve expressiveness. We adjust the direction of the extracted style for optimal integration into the TTS model, which improves speech quality. Experimental results demonstrate that Spotlight-TTS achieves superior performance compared to baseline models in terms of expressiveness, overall speech quality, and style transfer capability. Our audio samples are publicly available.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.20868",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evaluating potential cybersecurity threats of advanced AI",
    "description": "Our framework enables cybersecurity experts to identify which defenses are necessary‚Äîand how to prioritize them",
    "summary": "Our framework enables cybersecurity experts to identify which defenses are necessary‚Äîand how to prioritize them",
    "pubDate": "Wed, 02 Apr 2025 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/evaluating-potential-cybersecurity-threats-of-advanced-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/qVftghWK2fcPAfl80FKEGIuxUxYuwlN2guNdIpH5A1nF4KYf5jufujNE7j3zv5uJ3CGPEJ47ec4UaUa1vl8H3rpuEX8jIkdQlXgCEYeGhAAEj3p06IY=w1200-h630-n-nu"
  },
  {
    "title": "Operator System Card",
    "description": "Drawing from OpenAI‚Äôs established safety frameworks, this document highlights our multi-layered approach, including model and product mitigations we‚Äôve implemented to protect against prompt engineering and jailbreaks, protect privacy and security, as well as details our external red teaming efforts, safety evaluations, and ongoing work to further refine these safeguards.",
    "summary": "Drawing from OpenAI‚Äôs established safety frameworks, this document highlights our multi-layered approach, including model and product mitigations we‚Äôve implemented to protect against prompt engineering and jailbreaks, protect privacy and security, as well as details our external red teaming efforts, safety evaluations, and ongoing work to further refine these safeguards.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/operator-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bootstrapping Human-Like Planning via LLMs",
    "description": "arXiv:2506.22604v1 Announce Type: new Abstract: Robot end users increasingly require accessible means of specifying tasks for robots to perform. Two common end-user programming paradigms include drag-and-drop interfaces and natural language programming. Although natural language interfaces harness an intuitive form of human communication, drag-and-drop interfaces enable users to meticulously and precisely dictate the key actions of the robot's task. In this paper, we investigate the degree to which both approaches can be combined. Specifically, we construct a large language model (LLM)-based pipeline that accepts natural language as input and produces human-like action sequences as output, specified at a level of granularity that a human would produce. We then compare these generated action sequences to another dataset of hand-specified action sequences. Although our results reveal that larger models tend to outperform smaller ones in the production of human-like action sequences, smaller models nonetheless achieve satisfactory performance.",
    "summary": "arXiv:2506.22604v1 Announce Type: new Abstract: Robot end users increasingly require accessible means of specifying tasks for robots to perform. Two common end-user programming paradigms include drag-and-drop interfaces and natural language programming. Although natural language interfaces harness an intuitive form of human communication, drag-and-drop interfaces enable users to meticulously and precisely dictate the key actions of the robot's task. In this paper, we investigate the degree to which both approaches can be combined. Specifically, we construct a large language model (LLM)-based pipeline that accepts natural language as input and produces human-like action sequences as output, specified at a level of granularity that a human would produce. We then compare these generated action sequences to another dataset of hand-specified action sequences. Although our results reveal that larger models tend to outperform smaller ones in the production of human-like action sequences, smaller models nonetheless achieve satisfactory performance.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22604",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "UCB exploration via Q-ensembles",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 05 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ucb-exploration-via-q-ensembles",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sim-to-real transfer of robotic control with dynamics randomization",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 18 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sim-to-real-transfer-of-robotic-control-with-dynamics-randomization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o1 System Card",
    "description": "This report outlines the safety work carried out prior to releasing OpenAI o1 and o1-mini, including external red teaming and frontier risk evaluations according to our Preparedness Framework.",
    "summary": "This report outlines the safety work carried out prior to releasing OpenAI o1 and o1-mini, including external red teaming and frontier risk evaluations according to our Preparedness Framework.",
    "pubDate": "Thu, 05 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Security Review of Gradio 5",
    "description": "",
    "summary": "A Security Review of Gradio 5 We audited Gradio 5 so that your machine learning apps are safe! In th...",
    "pubDate": "Thu, 10 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-5-security",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-5-security/thumbnail.png"
  },
  {
    "title": "Lightning the Night with Generative Artificial Intelligence",
    "description": "arXiv:2506.22511v1 Announce Type: cross Abstract: The visible light reflectance data from geostationary satellites is crucial for meteorological observations and plays an important role in weather monitoring and forecasting. However, due to the lack of visible light at night, it is impossible to conduct continuous all-day weather observations using visible light reflectance data. This study pioneers the use of generative diffusion models to address this limitation. Based on the multi-band thermal infrared brightness temperature data from the Advanced Geostationary Radiation Imager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we developed a high-precision visible light reflectance retrieval model, called Reflectance Diffusion (RefDiff), which enables 0.47~mumathrm{m}, 0.65~mumathrm{m}, and 0.825~mumathrm{m} bands visible light reflectance retrieval at night. Compared to the classical models, RefDiff not only significantly improves accuracy through ensemble averaging but also provides uncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90, with particularly significant improvements in areas with complex cloud structures and thick clouds. The model's nighttime retrieval capability was validated using VIIRS nighttime product, demonstrating comparable performance to its daytime counterpart. In summary, this research has made substantial progress in the ability to retrieve visible light reflectance at night, with the potential to expand the application of nighttime visible light data.",
    "summary": "arXiv:2506.22511v1 Announce Type: cross Abstract: The visible light reflectance data from geostationary satellites is crucial for meteorological observations and plays an important role in weather monitoring and forecasting. However, due to the lack of visible light at night, it is impossible to conduct continuous all-day weather observations using visible light reflectance data. This study pioneers the use of generative diffusion models to address this limitation. Based on the multi-band thermal infrared brightness temperature data from the Advanced Geostationary Radiation Imager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we developed a high-precision visible light reflectance retrieval model, called Reflectance Diffusion (RefDiff), which enables 0.47~mumathrm{m}, 0.65~mumathrm{m}, and 0.825~mumathrm{m} bands visible light reflectance retrieval at night. Compared to the classical models, RefDiff not only significantly improves accuracy through ensemble averaging but also provides uncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90, with particularly significant improvements in areas with complex cloud structures and thick clouds. The model's nighttime retrieval capability was validated using VIIRS nighttime product, demonstrating comparable performance to its daytime counterpart. In summary, this research has made substantial progress in the ability to retrieve visible light reflectance at night, with the potential to expand the application of nighttime visible light data.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22511",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Realtime API",
    "description": "Developers can now build fast speech-to-speech experiences into their applications",
    "summary": "Developers can now build fast speech-to-speech experiences into their applications",
    "pubDate": "Tue, 01 Oct 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-realtime-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "„Äå„É©„Éº„É°„É≥„Çí„ÇÜ„Åß„Çã„Äç„Å´„ÇÇÁîüÊàêAI„ÅÆÊôÇ‰ª£„ÅåÊù•„Åü„Åû",
    "description": "„É©„Éº„É°„É≥„ÉÅ„Çß„Éº„É≥„Äå„É©„Éº„É°„É≥Â±±Â≤°ÂÆ∂„Äç„Åå„ÄÅÈ∫∫„Çí„ÇÜ„Åß„ÇãÈ†ÜÁï™„ÇíÂá¶ÁêÜ„Åô„ÇãÈöõ„ÄÅAmazon„ÅÆÁîüÊàêAI„Çµ„Éº„Éì„Çπ„ÄåAmazon Bedrock„Äç„ÇíÊ¥ªÁî®„Åó„Å¶„ÅÑ„Çã„ÄÅ„Å®„ÅÑ„ÅÜ„Åì„Å®„ÅåÊòé„Çâ„Åã„Å´„Å™„Å£„Åü„ÄÇÁîªÈù¢„ÅÆ‰∏≠„ÅÆAI„Åå„ÄÅÂé®Êàø„Å®„ÅÑ„ÅÜÁâ©ÁêÜÁ©∫Èñì„Å´Èôç„Çä„Å¶„Åç„ÅüÊÑü„Åò„Åå„Åó„Å¶Êñ∞ÈÆÆ„Å™‰∫ã‰æã„Å†„ÄÇ",
    "summary": "„É©„Éº„É°„É≥„ÉÅ„Çß„Éº„É≥„Äå„É©„Éº„É°„É≥Â±±Â≤°ÂÆ∂„Äç„Åå„ÄÅÈ∫∫„Çí„ÇÜ„Åß„ÇãÈ†ÜÁï™„ÇíÂá¶ÁêÜ„Åô„ÇãÈöõ„ÄÅAmazon„ÅÆÁîüÊàêAI„Çµ„Éº„Éì„Çπ„ÄåAmazon Bedrock„Äç„ÇíÊ¥ªÁî®„Åó„Å¶„ÅÑ„Çã„ÄÅ„Å®„ÅÑ„ÅÜ„Åì„Å®„ÅåÊòé„Çâ„Åã„Å´„Å™„Å£„Åü„ÄÇÁîªÈù¢„ÅÆ‰∏≠„ÅÆAI„Åå„ÄÅÂé®Êàø„Å®„ÅÑ„ÅÜÁâ©ÁêÜÁ©∫Èñì„Å´Èôç„Çä„Å¶„Åç„ÅüÊÑü„Åò„Åå„Åó„Å¶Êñ∞ÈÆÆ„Å™‰∫ã‰æã„Å†„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 11:39:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/30/news068.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/30/cover_news068.jpg"
  },
  {
    "title": "Supercharged Searching on the Hugging Face Hub",
    "description": "",
    "summary": "Supercharged Searching on the Hugging Face Hub The huggingface_hub library is a lightweight interfac...",
    "pubDate": "Tue, 25 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/searching-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/48_hubsearch/thumbnail.png"
  },
  {
    "title": "Partnership with American Journalism Project to support local news",
    "description": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
    "summary": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
    "pubDate": "Tue, 18 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/partnership-with-american-journalism-project-to-support-local-news",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A closer look inside AI Mode",
    "description": "Two smartphones showing AI Mode. The left phone shows an AI Mode prompt being entered: ‚Äòthings to do in nashville this weekend with friends, we‚Äôre big foodies who like music but also more chill vibes and exploring off the beaten path‚Äô. The right phone sho",
    "summary": "Two smartphones showing AI Mode. The left phone shows an AI Mode prompt being entered: ‚Äòthings to do in nashville this weekend with friends, we‚Äôre big foodies who like music but also more chill vibes and exploring off the beaten path‚Äô. The right phone sho",
    "pubDate": "Thu, 05 Jun 2025 18:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/ai-mode-development/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Meet_AI_mode_ss.width-1300.png"
  },
  {
    "title": "Semantic-Aware Adaptive Video Streaming Using Latent Diffusion Models for Wireless Networks",
    "description": "arXiv:2502.05695v2 Announce Type: replace-cross Abstract: This paper proposes a novel Semantic Communication (SemCom) framework for real-time adaptive-bitrate video streaming by integrating Latent Diffusion Models (LDMs) within the FFmpeg techniques. This solution addresses the challenges of high bandwidth usage, storage inefficiencies, and quality of experience (QoE) degradation associated with traditional Constant Bitrate Streaming (CBS) and Adaptive Bitrate Streaming (ABS). The proposed approach leverages LDMs to compress I-frames into a latent space, offering significant storage and semantic transmission savings without sacrificing high visual quality. While retaining B-frames and P-frames as adjustment metadata to support efficient refinement of video reconstruction at the user side, the proposed framework further incorporates state-of-the-art denoising and Video Frame Interpolation (VFI) techniques. These techniques mitigate semantic ambiguity and restore temporal coherence between frames, even in noisy wireless communication environments. Experimental results demonstrate the proposed method achieves high-quality video streaming with optimized bandwidth usage, outperforming state-of-the-art solutions in terms of QoE and resource efficiency. This work opens new possibilities for scalable real-time video streaming in 5G and future post-5G networks.",
    "summary": "arXiv:2502.05695v2 Announce Type: replace-cross Abstract: This paper proposes a novel Semantic Communication (SemCom) framework for real-time adaptive-bitrate video streaming by integrating Latent Diffusion Models (LDMs) within the FFmpeg techniques. This solution addresses the challenges of high bandwidth usage, storage inefficiencies, and quality of experience (QoE) degradation associated with traditional Constant Bitrate Streaming (CBS) and Adaptive Bitrate Streaming (ABS). The proposed approach leverages LDMs to compress I-frames into a latent space, offering significant storage and semantic transmission savings without sacrificing high visual quality. While retaining B-frames and P-frames as adjustment metadata to support efficient refinement of video reconstruction at the user side, the proposed framework further incorporates state-of-the-art denoising and Video Frame Interpolation (VFI) techniques. These techniques mitigate semantic ambiguity and restore temporal coherence between frames, even in noisy wireless communication environments. Experimental results demonstrate the proposed method achieves high-quality video streaming with optimized bandwidth usage, outperforming state-of-the-art solutions in terms of QoE and resource efficiency. This work opens new possibilities for scalable real-time video streaming in 5G and future post-5G networks.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.05695",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GPT-4o System Card External Testers Acknowledgements",
    "description": "GPT-4o system card external testers acknowledgements",
    "summary": "GPT-4o system card external testers acknowledgements",
    "pubDate": "Thu, 08 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-system-card/external-testers-acknowledgements",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Celebrating an academic-industry collaboration to advance vehicle technology",
    "description": "MIT Advanced Vehicle Technology Consortium marks a decade of developing data that improve understanding of how drivers use and respond to increasingly sophisticated automotive features.",
    "summary": "MIT Advanced Vehicle Technology Consortium marks a decade of developing data that improve understanding of how drivers use and respond to increasingly sophisticated automotive features.",
    "pubDate": "Mon, 16 Jun 2025 14:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/celebrating-academic-industry-collaboration-advance-vehicle-technology-0616",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-AVT-conference.jpg"
  },
  {
    "title": "Porting fairseq wmt19 translation system to transformers",
    "description": "",
    "summary": "Porting fairseq wmt19 translation system to transformers A guest blog post by Stas Bekman This artic...",
    "pubDate": "Tue, 03 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/porting-fsmt",
    "thumbnail": "https://huggingface.co/blog/assets/07_porting_fsmt/thumbnail.png"
  },
  {
    "title": "Improved Techniques for Training Consistency Models",
    "description": "Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training.",
    "summary": "Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improved-techniques-for-training-consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The power of continuous learning",
    "description": "Lilian Weng works on Applied AI Research at OpenAI.",
    "summary": "Lilian Weng works on Applied AI Research at OpenAI.",
    "pubDate": "Fri, 23 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-power-of-continuous-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Teaching a Language Model to Speak the Language of Tools",
    "description": "arXiv:2506.23394v1 Announce Type: cross Abstract: External tool integration through function-calling is essential for practical language model applications, yet most multilingual models lack reliable tool-use capabilities in non-English languages. Even state-of-the-art multilingual models struggle with determining when to use tools and generating the structured outputs required for function calls, often exhibiting language confusion when prompted in lower-resource languages. This work presents a methodology for adapting existing language models to enable robust tool use in any target language, using Bulgarian as a case study. The approach involves continued training of the BgGPT model series (2.6B, 9B, 27B parameters) on a novel bilingual dataset of 10,035 function-calling examples designed to support standardized protocols like MCP (Model Context Protocol). The research introduces TUCAN (Tool-Using Capable Assistant Navigator), which achieves up to 28.75% improvement in function-calling accuracy over base models while preserving core language understanding, as verified on established Bulgarian benchmarks. Beyond accuracy gains, TUCAN models demonstrate production-ready response formatting with clean, parsable function calls, contrasting with the verbose and inconsistent outputs of base models. The models, evaluation framework, and dataset are released to enable replication for other languages. This work demonstrates a practical approach for extending tool-augmented capabilities beyond English-centric systems.",
    "summary": "arXiv:2506.23394v1 Announce Type: cross Abstract: External tool integration through function-calling is essential for practical language model applications, yet most multilingual models lack reliable tool-use capabilities in non-English languages. Even state-of-the-art multilingual models struggle with determining when to use tools and generating the structured outputs required for function calls, often exhibiting language confusion when prompted in lower-resource languages. This work presents a methodology for adapting existing language models to enable robust tool use in any target language, using Bulgarian as a case study. The approach involves continued training of the BgGPT model series (2.6B, 9B, 27B parameters) on a novel bilingual dataset of 10,035 function-calling examples designed to support standardized protocols like MCP (Model Context Protocol). The research introduces TUCAN (Tool-Using Capable Assistant Navigator), which achieves up to 28.75% improvement in function-calling accuracy over base models while preserving core language understanding, as verified on established Bulgarian benchmarks. Beyond accuracy gains, TUCAN models demonstrate production-ready response formatting with clean, parsable function calls, contrasting with the verbose and inconsistent outputs of base models. The models, evaluation framework, and dataset are released to enable replication for other languages. This work demonstrates a practical approach for extending tool-augmented capabilities beyond English-centric systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23394",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action",
    "description": "",
    "summary": "Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action Hugging Face provides a Hub platf...",
    "pubDate": "Wed, 09 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-deepfloydif-using-bentoml",
    "thumbnail": "https://huggingface.co/blog/assets/deploy-deepfloydif-using-bentoml/thumbnail.png"
  },
  {
    "title": "Masked Autoencoders that Feel the Heart: Unveiling Simplicity Bias for ECG Analyses",
    "description": "arXiv:2506.22495v1 Announce Type: cross Abstract: The diagnostic value of electrocardiogram (ECG) lies in its dynamic characteristics, ranging from rhythm fluctuations to subtle waveform deformations that evolve across time and frequency domains. However, supervised ECG models tend to overfit dominant and repetitive patterns, overlooking fine-grained but clinically critical cues, a phenomenon known as Simplicity Bias (SB), where models favor easily learnable signals over subtle but informative ones. In this work, we first empirically demonstrate the presence of SB in ECG analyses and its negative impact on diagnostic performance, while simultaneously discovering that self-supervised learning (SSL) can alleviate it, providing a promising direction for tackling the bias. Following the SSL paradigm, we propose a novel method comprising two key components: 1) Temporal-Frequency aware Filters to capture temporal-frequency features reflecting the dynamic characteristics of ECG signals, and 2) building on this, Multi-Grained Prototype Reconstruction for coarse and fine representation learning across dual domains, further mitigating SB. To advance SSL in ECG analyses, we curate a large-scale multi-site ECG dataset with 1.53 million recordings from over 300 clinical centers. Experiments on three downstream tasks across six ECG datasets demonstrate that our method effectively reduces SB and achieves state-of-the-art performance. Code and dataset will be released publicly.",
    "summary": "arXiv:2506.22495v1 Announce Type: cross Abstract: The diagnostic value of electrocardiogram (ECG) lies in its dynamic characteristics, ranging from rhythm fluctuations to subtle waveform deformations that evolve across time and frequency domains. However, supervised ECG models tend to overfit dominant and repetitive patterns, overlooking fine-grained but clinically critical cues, a phenomenon known as Simplicity Bias (SB), where models favor easily learnable signals over subtle but informative ones. In this work, we first empirically demonstrate the presence of SB in ECG analyses and its negative impact on diagnostic performance, while simultaneously discovering that self-supervised learning (SSL) can alleviate it, providing a promising direction for tackling the bias. Following the SSL paradigm, we propose a novel method comprising two key components: 1) Temporal-Frequency aware Filters to capture temporal-frequency features reflecting the dynamic characteristics of ECG signals, and 2) building on this, Multi-Grained Prototype Reconstruction for coarse and fine representation learning across dual domains, further mitigating SB. To advance SSL in ECG analyses, we curate a large-scale multi-site ECG dataset with 1.53 million recordings from over 300 clinical centers. Experiments on three downstream tasks across six ECG datasets demonstrate that our method effectively reduces SB and achieves state-of-the-art performance. Code and dataset will be released publicly.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22495",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Driving growth and ‚ÄòWOW‚Äô moments with OpenAI",
    "description": "LY Corporation: Driving growth and ‚ÄòWOW‚Äô moments with OpenAI",
    "summary": "LY Corporation: Driving growth and ‚ÄòWOW‚Äô moments with OpenAI",
    "pubDate": "Wed, 12 Mar 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ly-corporation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Outbound coordinated vulnerability disclosure policy",
    "description": "Outbound coordinated vulnerability disclosure policy",
    "summary": "Outbound coordinated vulnerability disclosure policy",
    "pubDate": "Mon, 09 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/policies/outbound-coordinated-disclosure-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing GPT-4.5",
    "description": "We‚Äôre releasing a research preview of GPT‚Äë4.5‚Äîour largest and best model for chat yet. GPT‚Äë4.5 is a step forward in scaling up pre-training and post-training.",
    "summary": "We‚Äôre releasing a research preview of GPT‚Äë4.5‚Äîour largest and best model for chat yet. GPT‚Äë4.5 is a step forward in scaling up pre-training and post-training.",
    "pubDate": "Thu, 27 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-gpt-4-5",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MuseNet",
    "description": "We‚Äôve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose unsupervised technology as¬†GPT-2, a large-scale¬†transformer¬†model trained to predict the next token in a sequence, whether audio or¬†text.",
    "summary": "We‚Äôve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose unsupervised technology as¬†GPT-2, a large-scale¬†transformer¬†model trained to predict the next token in a sequence, whether audio or¬†text.",
    "pubDate": "Thu, 25 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/musenet",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Creating Privacy Preserving AI with Substra",
    "description": "",
    "summary": "Creating Privacy Preserving AI with Substra With the recent rise of generative techniques, machine l...",
    "pubDate": "Wed, 12 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/owkin-substra",
    "thumbnail": "https://huggingface.co/blog/assets/139_owkin-substra/thumbnail.png"
  },
  {
    "title": "Characterizing GPU Resilience and Impact on AI/HPC Systems",
    "description": "arXiv:2503.11901v3 Announce Type: replace-cross Abstract: This study characterizes GPU resilience in Delta HPC, a large-scale AI system that consists of 1,056 A100 and H100 GPUs, with over 1,300 petaflops of peak throughput. Delta HPC is operated by the National Center for Supercomputing Applications (NCSA) at the University of Illinois Urbana-Champaign. We used 2.5 years of operational data (11.7 million GPU hours) on GPU errors. Our major findings include: (i) H100 GPU memory resilience is worse than A100 GPU memory, with 3.2x lower per-GPU MTBE for memory errors, (ii) The GPU memory error-recovery mechanisms on H100 GPUs are insufficient to handle the increased memory capacity, (iii) H100 GPUs demonstrate significantly improved GPU hardware resilience over A100 GPUs with respect to critical hardware components, (iv) GPU errors on both A100 and H100 GPUs frequently result in job failures due to the lack of robust recovery mechanisms at the application level, and (v) We project the impact of GPU node availability on larger-scales and find that significant overprovisioning of 5% is necessary to handle GPU failures.",
    "summary": "arXiv:2503.11901v3 Announce Type: replace-cross Abstract: This study characterizes GPU resilience in Delta HPC, a large-scale AI system that consists of 1,056 A100 and H100 GPUs, with over 1,300 petaflops of peak throughput. Delta HPC is operated by the National Center for Supercomputing Applications (NCSA) at the University of Illinois Urbana-Champaign. We used 2.5 years of operational data (11.7 million GPU hours) on GPU errors. Our major findings include: (i) H100 GPU memory resilience is worse than A100 GPU memory, with 3.2x lower per-GPU MTBE for memory errors, (ii) The GPU memory error-recovery mechanisms on H100 GPUs are insufficient to handle the increased memory capacity, (iii) H100 GPUs demonstrate significantly improved GPU hardware resilience over A100 GPUs with respect to critical hardware components, (iv) GPU errors on both A100 and H100 GPUs frequently result in job failures due to the lack of robust recovery mechanisms at the application level, and (v) We project the impact of GPU node availability on larger-scales and find that significant overprovisioning of 5% is necessary to handle GPU failures.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.11901",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Transfer of adversarial robustness between perturbation types",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 03 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/transfer-of-adversarial-robustness-between-perturbation-types",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models",
    "description": "arXiv:2506.23903v1 Announce Type: cross Abstract: Accurate and generalizable object segmentation in ultrasound imaging remains a significant challenge due to anatomical variability, diverse imaging protocols, and limited annotated data. In this study, we propose a prompt-driven vision-language model (VLM) that integrates Grounding DINO with SAM2 to enable object segmentation across multiple ultrasound organs. A total of 18 public ultrasound datasets, encompassing the breast, thyroid, liver, prostate, kidney, and paraspinal muscle, were utilized. These datasets were divided into 15 for fine-tuning and validation of Grounding DINO using Low Rank Adaptation (LoRA) to the ultrasound domain, and 3 were held out entirely for testing to evaluate performance in unseen distributions. Comprehensive experiments demonstrate that our approach outperforms state-of-the-art segmentation methods, including UniverSeg, MedSAM, MedCLIP-SAM, BiomedParse, and SAMUS on most seen datasets while maintaining strong performance on unseen datasets without additional fine-tuning. These results underscore the promise of VLMs in scalable and robust ultrasound image analysis, reducing dependence on large, organ-specific annotated datasets. We will publish our code on code.sonography.ai after acceptance.",
    "summary": "arXiv:2506.23903v1 Announce Type: cross Abstract: Accurate and generalizable object segmentation in ultrasound imaging remains a significant challenge due to anatomical variability, diverse imaging protocols, and limited annotated data. In this study, we propose a prompt-driven vision-language model (VLM) that integrates Grounding DINO with SAM2 to enable object segmentation across multiple ultrasound organs. A total of 18 public ultrasound datasets, encompassing the breast, thyroid, liver, prostate, kidney, and paraspinal muscle, were utilized. These datasets were divided into 15 for fine-tuning and validation of Grounding DINO using Low Rank Adaptation (LoRA) to the ultrasound domain, and 3 were held out entirely for testing to evaluate performance in unseen distributions. Comprehensive experiments demonstrate that our approach outperforms state-of-the-art segmentation methods, including UniverSeg, MedSAM, MedCLIP-SAM, BiomedParse, and SAMUS on most seen datasets while maintaining strong performance on unseen datasets without additional fine-tuning. These results underscore the promise of VLMs in scalable and robust ultrasound image analysis, reducing dependence on large, organ-specific annotated datasets. We will publish our code on code.sonography.ai after acceptance.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23903",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing GPT-4.1 in the API",
    "description": "Introducing GPT-4.1 in the API‚Äîa new family of models with across-the-board improvements, including major gains in coding, instruction following, and long-context understanding. We‚Äôre also releasing our first nano model. Available to developers worldwide starting today.",
    "summary": "Introducing GPT-4.1 in the API‚Äîa new family of models with across-the-board improvements, including major gains in coding, instruction following, and long-context understanding. We‚Äôre also releasing our first nano model. Available to developers worldwide starting today.",
    "pubDate": "Mon, 14 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-1",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Data-driven beauty and creativity with ChatGPT",
    "description": "Data-driven beauty: How The Est√©e Lauder Companies unlocks insights with ChatGPT",
    "summary": "Data-driven beauty: How The Est√©e Lauder Companies unlocks insights with ChatGPT",
    "pubDate": "Wed, 13 Nov 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/estee-lauder",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AutoEvoEval: An Automated Framework for Evolving Close-Ended LLM Evaluation Data",
    "description": "arXiv:2506.23735v1 Announce Type: cross Abstract: Large language models (LLMs) have shown remarkable performance on various tasks, but existing evaluation benchmarks are often static and insufficient to fully assess their robustness and generalization in realistic scenarios. Prior work using evolutionary or adversarial data augmentation has improved evaluation diversity but lacks systematic control over perturbation types and multi-step complexity, limiting comprehensive robustness analysis. To address these gaps, we propose AutoEvoEval, an evolution-based evaluation framework for close-ended tasks such as multi-choice question answering. AutoEvoEval introduces 22 interpretable atomic evolution operations and supports multi-round compositions, enabling controlled generation of diverse, challenging, and realistic test samples. We conduct extensive experiments addressing four research questions on a broad set of open- and closed-source LLMs. Our results show that atomic operations cause an average accuracy drop of 7.283%, with structure-disrupting or misleading semantic edits causing the largest declines. Model sensitivities vary significantly for the same perturbation, and combining multiple evolution steps amplifies adversarial effects by up to 52.932%. These findings suggest current benchmarks may overestimate true model generalization and emphasize the need for evolution-aware robustness evaluation. Code and resources are available at: https://github.com/SYSUSELab/AutoEvoEval.",
    "summary": "arXiv:2506.23735v1 Announce Type: cross Abstract: Large language models (LLMs) have shown remarkable performance on various tasks, but existing evaluation benchmarks are often static and insufficient to fully assess their robustness and generalization in realistic scenarios. Prior work using evolutionary or adversarial data augmentation has improved evaluation diversity but lacks systematic control over perturbation types and multi-step complexity, limiting comprehensive robustness analysis. To address these gaps, we propose AutoEvoEval, an evolution-based evaluation framework for close-ended tasks such as multi-choice question answering. AutoEvoEval introduces 22 interpretable atomic evolution operations and supports multi-round compositions, enabling controlled generation of diverse, challenging, and realistic test samples. We conduct extensive experiments addressing four research questions on a broad set of open- and closed-source LLMs. Our results show that atomic operations cause an average accuracy drop of 7.283%, with structure-disrupting or misleading semantic edits causing the largest declines. Model sensitivities vary significantly for the same perturbation, and combining multiple evolution steps amplifies adversarial effects by up to 52.932%. These findings suggest current benchmarks may overestimate true model generalization and emphasize the need for evolution-aware robustness evaluation. Code and resources are available at: https://github.com/SYSUSELab/AutoEvoEval.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23735",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SynthID Detector ‚Äî a new portal to help identify AI-generated content",
    "description": "Learn about the new SynthID Detector portal we announced at I/O to help people understand how the content they see online was generated.",
    "summary": "Learn about the new SynthID Detector portal we announced at I/O to help people understand how the content they see online was generated.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/synthid-detector--a-new-portal-to-help-identify-ai-generated-content/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Gemini_MOD_HEADER.width-1300.jpg"
  },
  {
    "title": "Active Learning with AutoNLP and Prodigy",
    "description": "",
    "summary": "Active Learning with AutoNLP and Prodigy Active learning in the context of Machine Learning is a pro...",
    "pubDate": "Thu, 23 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autonlp-prodigy",
    "thumbnail": "https://huggingface.co/blog/assets/43_autonlp_prodigy/thumbnail.png"
  },
  {
    "title": "Releasing Outlines-core 0.1.0: structured generation in Rust and Python",
    "description": "",
    "summary": "Releasing Outlines-core 0.1.0: structured generation in Rust and Python dottxt and Hugging Face are ...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/outlines-core",
    "thumbnail": "https://huggingface.co/blog/assets/outlines-core/thumbnail.gif"
  },
  {
    "title": "DALL¬∑E now available without waitlist",
    "description": "New users can start creating straight away. Lessons learned from deployment and improvements to our safety systems make wider availability possible.",
    "summary": "New users can start creating straight away. Lessons learned from deployment and improvements to our safety systems make wider availability possible.",
    "pubDate": "Wed, 28 Sep 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-now-available-without-waitlist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Short Summary of Chinese AI Global Expansion",
    "description": "",
    "summary": "A Short Summary of Chinese AI Global Expansion In the early 15th century, Zheng He (also known as Ch...",
    "pubDate": "Thu, 03 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chinese-ai-expansion",
    "thumbnail": "https://huggingface.co/blog/assets/chinese-ai-expansion/thumbnail.png"
  },
  {
    "title": "How Hugging Face Accelerated Development of Witty Works Writing Assistant",
    "description": "",
    "summary": "How Hugging Face Accelerated Development of Witty Works Writing Assistant The Success Story of Witty...",
    "pubDate": "Wed, 01 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/classification-use-cases",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/witty-works.png"
  },
  {
    "title": "The Google for Startups Gemini kit is here",
    "description": "A blonde woman wearing a black top and red skit looks at the camera, describing the benefits of the Google for Startups Gemini Kit.",
    "summary": "A blonde woman wearing a black top and red skit looks at the camera, describing the benefits of the Google for Startups Gemini Kit.",
    "pubDate": "Thu, 26 Jun 2025 12:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/entrepreneurs/google-for-startups-gemini-ai-kit/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Paige_Thumbnail.width-1300.png"
  },
  {
    "title": "OpenAI and the CSU system bring AI to 500,000 students & faculty",
    "description": "The largest deployment of ChatGPT to date will expand the use of AI in education and help the United States build an AI-ready workforce.",
    "summary": "The largest deployment of ChatGPT to date will expand the use of AI in education and help the United States build an AI-ready workforce.",
    "pubDate": "Tue, 04 Feb 2025 11:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-the-csu-system",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "4M Models Scanned: Protect AI + Hugging Face 6 Months In",
    "description": "",
    "summary": "4M Models Scanned: Protect AI + Hugging Face 6 Months In Hugging Face and Protect AI partnered in Oc...",
    "pubDate": "Mon, 14 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pai-6-month",
    "thumbnail": "https://huggingface.co/blog/assets/pai-6-month/thumbnail.png"
  },
  {
    "title": "AutoToM: Scaling Model-based Mental Inference via Automated Agent Modeling",
    "description": "arXiv:2502.15676v2 Announce Type: replace Abstract: Theory of Mind (ToM), the ability to understand people's minds based on their behavior, is key to developing socially intelligent agents. Current approaches to ToM reasoning either rely on prompting Large Language Models (LLMs), which are prone to systematic errors, or use handcrafted, rigid agent models for model-based inference, which are more robust but fail to generalize across domains. In this work, we introduce AutoToM, an automated agent modeling method for scalable, robust, and interpretable mental inference. Given a ToM problem, AutoToM first proposes an initial agent model and then performs automated Bayesian inverse planning based on this model, leveraging an LLM backend. Guided by inference uncertainty, it iteratively refines the model by introducing additional mental variables and/or incorporating more timesteps in the context. Across five diverse benchmarks, AutoToM outperforms existing ToM methods and even large reasoning models. Additionally, we show that AutoToM can produce human-like confidence estimates and enable online mental inference for embodied decision-making.",
    "summary": "arXiv:2502.15676v2 Announce Type: replace Abstract: Theory of Mind (ToM), the ability to understand people's minds based on their behavior, is key to developing socially intelligent agents. Current approaches to ToM reasoning either rely on prompting Large Language Models (LLMs), which are prone to systematic errors, or use handcrafted, rigid agent models for model-based inference, which are more robust but fail to generalize across domains. In this work, we introduce AutoToM, an automated agent modeling method for scalable, robust, and interpretable mental inference. Given a ToM problem, AutoToM first proposes an initial agent model and then performs automated Bayesian inverse planning based on this model, leveraging an LLM backend. Guided by inference uncertainty, it iteratively refines the model by introducing additional mental variables and/or incorporating more timesteps in the context. Across five diverse benchmarks, AutoToM outperforms existing ToM methods and even large reasoning models. Additionally, we show that AutoToM can produce human-like confidence estimates and enable online mental inference for embodied decision-making.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.15676",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Error Optimization: Overcoming Exponential Signal Decay in Deep Predictive Coding Networks",
    "description": "arXiv:2505.20137v2 Announce Type: replace-cross Abstract: Predictive Coding (PC) offers a biologically plausible alternative to backpropagation for neural network training, yet struggles with deeper architectures. This paper identifies the root cause: an inherent signal decay problem where gradients attenuate exponentially with depth, becoming computationally negligible due to numerical precision constraints. To address this fundamental limitation, we introduce Error Optimization (EO), a novel reparameterization that preserves PC's theoretical properties while eliminating signal decay. By optimizing over prediction errors rather than states, EO enables signals to reach all layers simultaneously and without attenuation, converging orders of magnitude faster than standard PC. Experiments across multiple architectures and datasets demonstrate that EO matches backpropagation's performance even for deeper models where conventional PC struggles. Besides practical improvements, our work provides theoretical insight into PC dynamics and establishes a foundation for scaling biologically-inspired learning to deeper architectures on digital hardware and beyond.",
    "summary": "arXiv:2505.20137v2 Announce Type: replace-cross Abstract: Predictive Coding (PC) offers a biologically plausible alternative to backpropagation for neural network training, yet struggles with deeper architectures. This paper identifies the root cause: an inherent signal decay problem where gradients attenuate exponentially with depth, becoming computationally negligible due to numerical precision constraints. To address this fundamental limitation, we introduce Error Optimization (EO), a novel reparameterization that preserves PC's theoretical properties while eliminating signal decay. By optimizing over prediction errors rather than states, EO enables signals to reach all layers simultaneously and without attenuation, converging orders of magnitude faster than standard PC. Experiments across multiple architectures and datasets demonstrate that EO matches backpropagation's performance even for deeper models where conventional PC struggles. Besides practical improvements, our work provides theoretical insight into PC dynamics and establishes a foundation for scaling biologically-inspired learning to deeper architectures on digital hardware and beyond.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.20137",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning to reason with LLMs",
    "description": "We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before it answers‚Äîit can produce a long internal chain of thought before responding to the user.",
    "summary": "We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before it answers‚Äîit can produce a long internal chain of thought before responding to the user.",
    "pubDate": "Thu, 12 Sep 2024 10:02:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-reason-with-llms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings",
    "description": "arXiv:2506.23115v1 Announce Type: cross Abstract: Multimodal embedding models, built upon causal Vision Language Models (VLMs), have shown promise in various tasks. However, current approaches face three key limitations: the use of causal attention in VLM backbones is suboptimal for embedding tasks; scalability issues due to reliance on high-quality labeled paired data for contrastive learning; and limited diversity in training objectives and data. To address these issues, we propose MoCa, a two-stage framework for transforming pre-trained VLMs into effective bidirectional multimodal embedding models. The first stage, Modality-aware Continual Pre-training, introduces a joint reconstruction objective that simultaneously denoises interleaved text and image inputs, enhancing bidirectional context-aware reasoning. The second stage, Heterogeneous Contrastive Fine-tuning, leverages diverse, semantically rich multimodal data beyond simple image-caption pairs to enhance generalization and alignment. Our method addresses the stated limitations by introducing bidirectional attention through continual pre-training, scaling effectively with massive unlabeled datasets via joint reconstruction objectives, and utilizing diverse multimodal data for enhanced representation robustness. Experiments demonstrate that MoCa consistently improves performance across MMEB and ViDoRe-v2 benchmarks, achieving new state-of-the-art results, and exhibits strong scalability with both model size and training data on MMEB.",
    "summary": "arXiv:2506.23115v1 Announce Type: cross Abstract: Multimodal embedding models, built upon causal Vision Language Models (VLMs), have shown promise in various tasks. However, current approaches face three key limitations: the use of causal attention in VLM backbones is suboptimal for embedding tasks; scalability issues due to reliance on high-quality labeled paired data for contrastive learning; and limited diversity in training objectives and data. To address these issues, we propose MoCa, a two-stage framework for transforming pre-trained VLMs into effective bidirectional multimodal embedding models. The first stage, Modality-aware Continual Pre-training, introduces a joint reconstruction objective that simultaneously denoises interleaved text and image inputs, enhancing bidirectional context-aware reasoning. The second stage, Heterogeneous Contrastive Fine-tuning, leverages diverse, semantically rich multimodal data beyond simple image-caption pairs to enhance generalization and alignment. Our method addresses the stated limitations by introducing bidirectional attention through continual pre-training, scaling effectively with massive unlabeled datasets via joint reconstruction objectives, and utilizing diverse multimodal data for enhanced representation robustness. Experiments demonstrate that MoCa consistently improves performance across MMEB and ViDoRe-v2 benchmarks, achieving new state-of-the-art results, and exhibits strong scalability with both model size and training data on MMEB.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23115",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Study on Semi-Supervised Detection of DDoS Attacks under Class Imbalance",
    "description": "arXiv:2506.22949v1 Announce Type: cross Abstract: One of the most difficult challenges in cybersecurity is eliminating Distributed Denial of Service (DDoS) attacks. Automating this task using artificial intelligence is a complex process due to the inherent class imbalance and lack of sufficient labeled samples of real-world datasets. This research investigates the use of Semi-Supervised Learning (SSL) techniques to improve DDoS attack detection when data is imbalanced and partially labeled. In this process, 13 state-of-the-art SSL algorithms are evaluated for detecting DDoS attacks in several scenarios. We evaluate their practical efficacy and shortcomings, including the extent to which they work in extreme environments. The results will offer insight into designing intelligent Intrusion Detection Systems (IDSs) that are robust against class imbalance and handle partially labeled data.",
    "summary": "arXiv:2506.22949v1 Announce Type: cross Abstract: One of the most difficult challenges in cybersecurity is eliminating Distributed Denial of Service (DDoS) attacks. Automating this task using artificial intelligence is a complex process due to the inherent class imbalance and lack of sufficient labeled samples of real-world datasets. This research investigates the use of Semi-Supervised Learning (SSL) techniques to improve DDoS attack detection when data is imbalanced and partially labeled. In this process, 13 state-of-the-art SSL algorithms are evaluated for detecting DDoS attacks in several scenarios. We evaluate their practical efficacy and shortcomings, including the extent to which they work in extreme environments. The results will offer insight into designing intelligent Intrusion Detection Systems (IDSs) that are robust against class imbalance and handle partially labeled data.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22949",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation",
    "description": "arXiv:2506.22776v1 Announce Type: cross Abstract: Quantization has emerged as a mainstream method for compressing Large Language Models (LLMs), reducing memory requirements and accelerating inference without architectural modifications. While existing research primarily focuses on evaluating the effectiveness of quantized LLMs compared to their original counterparts, the impact on robustness remains largely unexplored.In this paper, we present the first systematic investigation of how quantization affects the robustness of LLMs in code generation tasks. Through extensive experiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and StarCoder) with parameter scales ranging from 350M to 33B, we evaluate robustness from dual perspectives: adversarial attacks on input prompts and noise perturbations on model architecture. Our findings challenge conventional wisdom by demonstrating that quantized LLMs often exhibit superior robustness compared to their full-precision counterparts, with 51.59% versus 42.86% of our adversarial experiments showing better resilience in quantized LLMs. Similarly, our noise perturbation experiments also confirm that LLMs after quantitation generally withstand higher levels of weight disturbances. These results suggest that quantization not only reduces computational requirements but can actually enhance LLMs' reliability in code generation tasks, providing valuable insights for developing more robust and efficient LLM deployment strategies.",
    "summary": "arXiv:2506.22776v1 Announce Type: cross Abstract: Quantization has emerged as a mainstream method for compressing Large Language Models (LLMs), reducing memory requirements and accelerating inference without architectural modifications. While existing research primarily focuses on evaluating the effectiveness of quantized LLMs compared to their original counterparts, the impact on robustness remains largely unexplored.In this paper, we present the first systematic investigation of how quantization affects the robustness of LLMs in code generation tasks. Through extensive experiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and StarCoder) with parameter scales ranging from 350M to 33B, we evaluate robustness from dual perspectives: adversarial attacks on input prompts and noise perturbations on model architecture. Our findings challenge conventional wisdom by demonstrating that quantized LLMs often exhibit superior robustness compared to their full-precision counterparts, with 51.59% versus 42.86% of our adversarial experiments showing better resilience in quantized LLMs. Similarly, our noise perturbation experiments also confirm that LLMs after quantitation generally withstand higher levels of weight disturbances. These results suggest that quantization not only reduces computational requirements but can actually enhance LLMs' reliability in code generation tasks, providing valuable insights for developing more robust and efficient LLM deployment strategies.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22776",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "What Makes a Dialog Agent Useful?",
    "description": "",
    "summary": "What Makes a Dialog Agent Useful? The techniques behind ChatGPT: RLHF, IFT, CoT, Red teaming, and mo...",
    "pubDate": "Tue, 24 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dialog-agents",
    "thumbnail": "https://huggingface.co/blog/assets/dialog-agents/thumbnail.png"
  },
  {
    "title": "Goodbye cold boot - how we made LoRA inference 300% faster",
    "description": "",
    "summary": "Goodbye cold boot - how we made LoRA Inference 300% faster tl;dr: We swap the Stable Diffusion LoRA ...",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lora-adapters-dynamic-loading",
    "thumbnail": "https://huggingface.co/blog/assets/171_load_lora_adapters/thumbnail3.png"
  },
  {
    "title": "Introducing Gemma 3",
    "description": "The most capable model you can run on a single GPU or TPU.",
    "summary": "The most capable model you can run on a single GPU or TPU.",
    "pubDate": "Wed, 12 Mar 2025 08:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemma-3/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemma3_KeywordBlog_RD3_V01b_SocialShare.width-1300.png"
  },
  {
    "title": "OpenAI Baselines: DQN",
    "description": "We‚Äôre open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with performance on par with published results. We‚Äôll release the algorithms over upcoming months; today‚Äôs release includes DQN and three of its variants.",
    "summary": "We‚Äôre open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with performance on par with published results. We‚Äôll release the algorithms over upcoming months; today‚Äôs release includes DQN and three of its variants.",
    "pubDate": "Wed, 24 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-dqn",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making sense of this mess",
    "description": "",
    "summary": "Making sense of this mess When I joined Hugging Face nearly 3 years ago, the Transformers documentat...",
    "pubDate": "Fri, 07 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-docs-redesign",
    "thumbnail": "https://huggingface.co/blog/assets/transformers-docs-redesign/thumbnail.png"
  },
  {
    "title": "Coding with OpenAI o1",
    "description": "Scott Wu, CEO and Co-Founder of Cognition, explains how OpenAI o1 makes coding decisions in a more human-like way.",
    "summary": "Scott Wu, CEO and Co-Founder of Cognition, explains how OpenAI o1 makes coding decisions in a more human-like way.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-coding",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Klarna's AI assistant does the work of 700 full-time agents",
    "description": "Klarna is using AI to revolutionize personal shopping, customer service, and employee productivity.",
    "summary": "Klarna is using AI to revolutionize personal shopping, customer service, and employee productivity.",
    "pubDate": "Fri, 05 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/klarna",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Machine Learning Demos on arXiv",
    "description": "",
    "summary": "Hugging Face Machine Learning Demos on arXiv We‚Äôre very excited to announce that Hugging Face has co...",
    "pubDate": "Thu, 17 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arxiv",
    "thumbnail": "https://huggingface.co/blog/assets/arxiv/thumbnail.png"
  },
  {
    "title": "Scaling up BERT-like model Inference on modern CPU - Part 2",
    "description": "",
    "summary": "Scaling up BERT-like model Inference on modern CPU - Part 2 Introduction: Using Intel Software to Op...",
    "pubDate": "Thu, 04 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-cpu-scaling-part-2",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Bringing serverless GPU inference to Hugging Face users",
    "description": "",
    "summary": "Bringing serverless GPU inference to Hugging Face users Today, we are thrilled to announce the launc...",
    "pubDate": "Tue, 02 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cloudflare-workers-ai",
    "thumbnail": "https://huggingface.co/blog/assets/cloudflare-workers-ai/thumbnail.jpg"
  },
  {
    "title": "Train your ControlNet with diffusers",
    "description": "",
    "summary": "Train your ControlNet with diffusers üß® Introduction ControlNet is a neural network structure that al...",
    "pubDate": "Fri, 24 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-your-controlnet",
    "thumbnail": "https://huggingface.co/blog/assets/136_train-your-controlnet/thumbnail.png"
  },
  {
    "title": "Machine Learning for Proactive Groundwater Management: Early Warning and Resource Allocation",
    "description": "arXiv:2506.22461v1 Announce Type: cross Abstract: Groundwater supports ecosystems, agriculture, and drinking water supplies worldwide, yet effective monitoring remains challenging due to sparse data, computational constraints, and delayed outputs from traditional approaches. We develop a machine learning pipeline that predicts groundwater level categories using climate data, hydro-meteorological records, and physiographic attributes processed through AutoGluon's automated ensemble framework. Our approach integrates geospatial preprocessing, domain-driven feature engineering, and automated model selection to overcome conventional monitoring limitations. Applied to a large-scale French dataset (n $>$ 3,440,000 observations from 1,500+ wells), the model achieves weighted F_1 scores of 0.927 on validation data and 0.67 on temporally distinct test data. Scenario-based evaluations demonstrate practical utility for early warning systems and water allocation decisions under changing climate conditions. The open-source implementation provides a scalable framework for integrating machine learning into national groundwater monitoring networks, enabling more responsive and data-driven water management strategies.",
    "summary": "arXiv:2506.22461v1 Announce Type: cross Abstract: Groundwater supports ecosystems, agriculture, and drinking water supplies worldwide, yet effective monitoring remains challenging due to sparse data, computational constraints, and delayed outputs from traditional approaches. We develop a machine learning pipeline that predicts groundwater level categories using climate data, hydro-meteorological records, and physiographic attributes processed through AutoGluon's automated ensemble framework. Our approach integrates geospatial preprocessing, domain-driven feature engineering, and automated model selection to overcome conventional monitoring limitations. Applied to a large-scale French dataset (n $>$ 3,440,000 observations from 1,500+ wells), the model achieves weighted F_1 scores of 0.927 on validation data and 0.67 on temporally distinct test data. Scenario-based evaluations demonstrate practical utility for early warning systems and water allocation decisions under changing climate conditions. The open-source implementation provides a scalable framework for integrating machine learning into national groundwater monitoring networks, enabling more responsive and data-driven water management strategies.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22461",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI„Ç®„Éá„Ç£„Çø„ÄåCursor„Äç„Å´„ÄÅ„Çπ„Éû„ÉõÁâà„ÅåÁôªÂ†¥„ÄÄWeb„Éñ„É©„Ç¶„Ç∂Áâà„ÇÇÂêåÊôÇÊèê‰æõ",
    "description": "AI„Ç®„Éá„Ç£„Çø„ÄåCursor„Äç„ÇíÈñãÁô∫„Åô„ÇãÁ±≥Anysphere„ÅØ„ÄÅÂêå„Ç®„Éá„Ç£„Çø„ÅÆ„É¢„Éê„Ç§„É´Áâà„ÅÆÊèê‰æõ„ÇíÂßã„ÇÅ„Åü„ÄÇ„ÅÇ„Çè„Åõ„Å¶„ÄÅWeb„Éñ„É©„Ç¶„Ç∂„Å´„ÇÇÂØæÂøú„ÄÇËá™ÁÑ∂Ë®ÄË™û„ÅÆÊåáÁ§∫„Å´„Çà„Çã„Ç≥„Éº„Éâ„ÅÆÁîüÊàê„ÇÑ‰øÆÊ≠£„Å™„Å©„ÅÆÊ©üËÉΩ„Çí„ÄÅ„É¢„Éê„Ç§„É´Áí∞Â¢É„Åß„ÇÇ‰Ωø„Åà„Çã„Çà„ÅÜ„Å´„Åô„Çã„ÄÇ",
    "summary": "AI„Ç®„Éá„Ç£„Çø„ÄåCursor„Äç„ÇíÈñãÁô∫„Åô„ÇãÁ±≥Anysphere„ÅØ„ÄÅÂêå„Ç®„Éá„Ç£„Çø„ÅÆ„É¢„Éê„Ç§„É´Áâà„ÅÆÊèê‰æõ„ÇíÂßã„ÇÅ„Åü„ÄÇ„ÅÇ„Çè„Åõ„Å¶„ÄÅWeb„Éñ„É©„Ç¶„Ç∂„Å´„ÇÇÂØæÂøú„ÄÇËá™ÁÑ∂Ë®ÄË™û„ÅÆÊåáÁ§∫„Å´„Çà„Çã„Ç≥„Éº„Éâ„ÅÆÁîüÊàê„ÇÑ‰øÆÊ≠£„Å™„Å©„ÅÆÊ©üËÉΩ„Çí„ÄÅ„É¢„Éê„Ç§„É´Áí∞Â¢É„Åß„ÇÇ‰Ωø„Åà„Çã„Çà„ÅÜ„Å´„Åô„Çã„ÄÇ",
    "pubDate": "Tue, 01 Jul 2025 12:20:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/01/news070.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/01/cover_news070.jpg"
  },
  {
    "title": "MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI",
    "description": "arXiv:2506.23563v1 Announce Type: new Abstract: Reasoning plays a crucial role in advancing Multimodal Large Language Models (MLLMs) toward Artificial General Intelligence. However, existing MLLM benchmarks often fall short in precisely and comprehensively evaluating long-chain reasoning abilities from three key aspects: (1) lack of difficulty and diversity, (2) susceptibility to guessability and memorization, (3) inadequate assessment of intermediate reasoning steps. To fill this gap, we introduce MMReason, a new benchmark designed to precisely and comprehensively evaluate MLLM long-chain reasoning capability with diverse, open-ended, challenging questions. First, we curate challenging questions requiring multi-step reasoning from various fields (i.e., 6 disciplines) and multiple difficulty levels (i.e., from pre-university to university, and from foundational to competition tiers). Second, these questions are reformulated into an open-ended format and filtered using a multi-model voting technique to eliminate shortcut cases related to guessing and memorization, ensuring robust reasoning evaluations. Third, we annotate the questions with detailed step-by-step solutions, and design a reference-based ternary scoring mechanism to reliably assess intermediate reasoning steps. With MMReason, we benchmark popular leading MLLMs and provide an in-depth analysis of their reasoning capabilities. We hope MMReason will serve as a valuable resource for advancing MLLM reasoning research. Code will be available at https://github.com/HJYao00/MMReason.",
    "summary": "arXiv:2506.23563v1 Announce Type: new Abstract: Reasoning plays a crucial role in advancing Multimodal Large Language Models (MLLMs) toward Artificial General Intelligence. However, existing MLLM benchmarks often fall short in precisely and comprehensively evaluating long-chain reasoning abilities from three key aspects: (1) lack of difficulty and diversity, (2) susceptibility to guessability and memorization, (3) inadequate assessment of intermediate reasoning steps. To fill this gap, we introduce MMReason, a new benchmark designed to precisely and comprehensively evaluate MLLM long-chain reasoning capability with diverse, open-ended, challenging questions. First, we curate challenging questions requiring multi-step reasoning from various fields (i.e., 6 disciplines) and multiple difficulty levels (i.e., from pre-university to university, and from foundational to competition tiers). Second, these questions are reformulated into an open-ended format and filtered using a multi-model voting technique to eliminate shortcut cases related to guessing and memorization, ensuring robust reasoning evaluations. Third, we annotate the questions with detailed step-by-step solutions, and design a reference-based ternary scoring mechanism to reliably assess intermediate reasoning steps. With MMReason, we benchmark popular leading MLLMs and provide an in-depth analysis of their reasoning capabilities. We hope MMReason will serve as a valuable resource for advancing MLLM reasoning research. Code will be available at https://github.com/HJYao00/MMReason.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23563",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerating Stable Diffusion XL Inference with JAX on Cloud TPU v5e",
    "description": "",
    "summary": "Accelerating Stable Diffusion XL Inference with JAX on Cloud TPU v5e Generative AI models, such as S...",
    "pubDate": "Tue, 03 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_jax",
    "thumbnail": "https://huggingface.co/blog/assets/sdxl-jax/thumbnail.jpg"
  },
  {
    "title": "TGI Multi-LoRA: Deploy Once, Serve 30 Models",
    "description": "",
    "summary": "TGI Multi-LoRA: Deploy Once, Serve 30 models Are you tired of the complexity and expense of managing...",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/multi-lora-serving",
    "thumbnail": "https://huggingface.co/blog/assets/multi-lora-serving/thumbnail.png"
  },
  {
    "title": "Are Large Language Models Capable of Deep Relational Reasoning? Insights from DeepSeek-R1 and Benchmark Comparisons",
    "description": "arXiv:2506.23128v1 Announce Type: new Abstract: How far are Large Language Models (LLMs) in performing deep relational reasoning? In this paper, we evaluate and compare the reasoning capabilities of three cutting-edge LLMs, namely, DeepSeek-R1, DeepSeek-V3 and GPT-4o, through a suite of carefully designed benchmark tasks in family tree and general graph reasoning. Our experiments reveal that DeepSeek-R1 consistently achieves the highest F1-scores across multiple tasks and problem sizes, demonstrating strong aptitude in logical deduction and relational inference. However, all evaluated models, including DeepSeek-R1, struggle significantly as problem complexity increases, largely due to token length limitations and incomplete output structures. A detailed analysis of DeepSeek-R1's long Chain-of-Thought responses uncovers its unique planning and verification strategies, but also highlights instances of incoherent or incomplete reasoning, calling attention to the need for deeper scrutiny into LLMs' internal inference dynamics. We further discuss key directions for future work, including the role of multimodal reasoning and the systematic examination of reasoning failures. Our findings provide both empirical insights and theoretical implications for advancing LLMs' reasoning abilities, particularly in tasks that demand structured, multi-step logical inference. Our code repository will be publicly available at https://github.com/kelvinhkcs/Deep-Relational-Reasoning.",
    "summary": "arXiv:2506.23128v1 Announce Type: new Abstract: How far are Large Language Models (LLMs) in performing deep relational reasoning? In this paper, we evaluate and compare the reasoning capabilities of three cutting-edge LLMs, namely, DeepSeek-R1, DeepSeek-V3 and GPT-4o, through a suite of carefully designed benchmark tasks in family tree and general graph reasoning. Our experiments reveal that DeepSeek-R1 consistently achieves the highest F1-scores across multiple tasks and problem sizes, demonstrating strong aptitude in logical deduction and relational inference. However, all evaluated models, including DeepSeek-R1, struggle significantly as problem complexity increases, largely due to token length limitations and incomplete output structures. A detailed analysis of DeepSeek-R1's long Chain-of-Thought responses uncovers its unique planning and verification strategies, but also highlights instances of incoherent or incomplete reasoning, calling attention to the need for deeper scrutiny into LLMs' internal inference dynamics. We further discuss key directions for future work, including the role of multimodal reasoning and the systematic examination of reasoning failures. Our findings provide both empirical insights and theoretical implications for advancing LLMs' reasoning abilities, particularly in tasks that demand structured, multi-step logical inference. Our code repository will be publicly available at https://github.com/kelvinhkcs/Deep-Relational-Reasoning.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23128",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI and Los Alamos National Laboratory announce research partnership",
    "description": "OpenAI and Los Alamos National Laboratory are working to develop safety evaluations to assess and measure biological capabilities and risks associated with frontier models.",
    "summary": "OpenAI and Los Alamos National Laboratory are working to develop safety evaluations to assess and measure biological capabilities and risks associated with frontier models.",
    "pubDate": "Wed, 10 Jul 2024 06:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-los-alamos-national-laboratory-work-together",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hindsight Experience Replay",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 05 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hindsight-experience-replay",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI o1",
    "description": "Introducing OpenAI o1",
    "summary": "Introducing OpenAI o1",
    "pubDate": "Thu, 12 Sep 2024 10:03:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-o1-preview",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Nonlinear computation in deep linear networks",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 29 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonlinear-computation-in-deep-linear-networks",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Search Live: Talk, listen and explore in real time with AI Mode",
    "description": "Logos for AI Mode in Search and Search Live in front of a black background",
    "summary": "Logos for AI Mode in Search and Search Live in front of a black background",
    "pubDate": "Wed, 18 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/search-live-ai-mode/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SearchLive_SS.width-1300.png"
  },
  {
    "title": "Machine Learning Experts - Lewis Tunstall Interview",
    "description": "",
    "summary": "Machine Learning Experts - Lewis Tunstall ü§ó Welcome to Machine Learning Experts - Lewis Tunstall Hey...",
    "pubDate": "Wed, 13 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lewis-tunstall-interview",
    "thumbnail": "https://huggingface.co/blog/assets/60_lewis_tunstall_interview/thumbnail.png"
  },
  {
    "title": "Google Cloud TPUs made available to Hugging Face users",
    "description": "",
    "summary": "Google Cloud TPUs made available to Hugging Face users We're excited to share some great news! AI bu...",
    "pubDate": "Tue, 09 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tpu-inference-endpoints-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/tpu-inference-endpoints-spaces/thumbnail.png"
  },
  {
    "title": "Forecasting potential misuses of language models for disinformation campaigns and how to reduce risk",
    "description": "OpenAI researchers collaborated with Georgetown University‚Äôs Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report¬†here.",
    "summary": "OpenAI researchers collaborated with Georgetown University‚Äôs Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report¬†here.",
    "pubDate": "Wed, 11 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/forecasting-misuse",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-tuning Stable Diffusion models on Intel CPUs",
    "description": "",
    "summary": "Fine-tuning Stable Diffusion Models on Intel CPUs Diffusion models helped popularize generative AI t...",
    "pubDate": "Fri, 14 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-finetuning-intel",
    "thumbnail": "https://huggingface.co/blog/assets/stable-diffusion-finetuning-intel/01.png"
  },
  {
    "title": "OpenAI and Elon Musk",
    "description": "We are dedicated to the OpenAI mission and have pursued it every step of the way.",
    "summary": "We are dedicated to the OpenAI mission and have pursued it every step of the way.",
    "pubDate": "Tue, 05 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-elon-musk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An Introduction to Q-Learning Part 2",
    "description": "",
    "summary": "An Introduction to Q-Learning Part 2/2 Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 2,...",
    "pubDate": "Fri, 20 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-q-part2",
    "thumbnail": "https://huggingface.co/blog/assets/73_deep_rl_q_part2/thumbnail.gif"
  },
  {
    "title": "Introducing smolagents: simple agents that write actions in code.",
    "description": "",
    "summary": "Introducing smolagents, a simple library to build agents Today we are launching smolagents , a very ...",
    "pubDate": "Tue, 31 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents/thumbnail.png"
  },
  {
    "title": "Open-R1: a fully open reproduction of DeepSeek-R1",
    "description": "",
    "summary": "Open-R1: a fully open reproduction of DeepSeek-R1 What is DeepSeek-R1? If you‚Äôve ever struggled with...",
    "pubDate": "Tue, 28 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-r1",
    "thumbnail": "https://huggingface.co/blog/assets/open-r1/thumbnails.png"
  },
  {
    "title": "DSAC: Distributional Soft Actor-Critic for Risk-Sensitive Reinforcement Learning",
    "description": "arXiv:2004.14547v3 Announce Type: replace-cross Abstract: We present Distributional Soft Actor-Critic (DSAC), a distributional reinforcement learning (RL) algorithm that combines the strengths of distributional information of accumulated rewards and entropy-driven exploration from Soft Actor-Critic (SAC) algorithm. DSAC models the randomness in both action and rewards, surpassing baseline performances on various continuous control tasks. Unlike standard approaches that solely maximize expected rewards, we propose a unified framework for risk-sensitive learning, one that optimizes the risk-related objective while balancing entropy to encourage exploration. Extensive experiments demonstrate DSAC's effectiveness in enhancing agent performances for both risk-neutral and risk-sensitive control tasks.",
    "summary": "arXiv:2004.14547v3 Announce Type: replace-cross Abstract: We present Distributional Soft Actor-Critic (DSAC), a distributional reinforcement learning (RL) algorithm that combines the strengths of distributional information of accumulated rewards and entropy-driven exploration from Soft Actor-Critic (SAC) algorithm. DSAC models the randomness in both action and rewards, surpassing baseline performances on various continuous control tasks. Unlike standard approaches that solely maximize expected rewards, we propose a unified framework for risk-sensitive learning, one that optimizes the risk-related objective while balancing entropy to encourage exploration. Extensive experiments demonstrate DSAC's effectiveness in enhancing agent performances for both risk-neutral and risk-sensitive control tasks.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2004.14547",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Finally, a Replacement for BERT: Introducing ModernBERT",
    "description": "",
    "summary": "Finally, a Replacement for BERT TL;DR This blog post introduces ModernBERT, a family of state-of-the...",
    "pubDate": "Thu, 19 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/modernbert",
    "thumbnail": "https://huggingface.co/blog/assets/modernbert/thumbnail.png"
  },
  {
    "title": "Performance Measurements in the AI-Centric Computing Continuum Systems",
    "description": "arXiv:2506.22884v1 Announce Type: cross Abstract: Over the Eight decades, computing paradigms have shifted from large, centralized systems to compact, distributed architectures, leading to the rise of the Distributed Computing Continuum (DCC). In this model, multiple layers such as cloud, edge, Internet of Things (IoT), and mobile platforms work together to support a wide range of applications. Recently, the emergence of Generative AI and large language models has further intensified the demand for computational resources across this continuum. Although traditional performance metrics have provided a solid foundation, they need to be revisited and expanded to keep pace with changing computational demands and application requirements. Accurate performance measurements benefit both system designers and users by supporting improvements in efficiency and promoting alignment with system goals. In this context, we review commonly used metrics in DCC and IoT environments. We also discuss emerging performance dimensions that address evolving computing needs, such as sustainability, energy efficiency, and system observability. We also outline criteria and considerations for selecting appropriate metrics, aiming to inspire future research and development in this critical area.",
    "summary": "arXiv:2506.22884v1 Announce Type: cross Abstract: Over the Eight decades, computing paradigms have shifted from large, centralized systems to compact, distributed architectures, leading to the rise of the Distributed Computing Continuum (DCC). In this model, multiple layers such as cloud, edge, Internet of Things (IoT), and mobile platforms work together to support a wide range of applications. Recently, the emergence of Generative AI and large language models has further intensified the demand for computational resources across this continuum. Although traditional performance metrics have provided a solid foundation, they need to be revisited and expanded to keep pace with changing computational demands and application requirements. Accurate performance measurements benefit both system designers and users by supporting improvements in efficiency and promoting alignment with system goals. In this context, we review commonly used metrics in DCC and IoT environments. We also discuss emerging performance dimensions that address evolving computing needs, such as sustainability, energy efficiency, and system observability. We also outline criteria and considerations for selecting appropriate metrics, aiming to inspire future research and development in this critical area.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22884",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "New generative media models and tools, built with and for creators",
    "description": "We‚Äôre introducing Veo, our most capable model for generating high-definition video, and Imagen 3, our highest quality text-to-image model. We‚Äôre also sharing new demo recordings created with our Music AI Sandbox.",
    "summary": "We‚Äôre introducing Veo, our most capable model for generating high-definition video, and Imagen 3, our highest quality text-to-image model. We‚Äôre also sharing new demo recordings created with our Music AI Sandbox.",
    "pubDate": "Tue, 14 May 2024 17:57:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/new-generative-media-models-and-tools-built-with-and-for-creators/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO24_Gen_Media_Header_1.width-1300.png"
  },
  {
    "title": "Better language models and their implications",
    "description": "We‚Äôve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization‚Äîall without task-specific¬†training.",
    "summary": "We‚Äôve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization‚Äîall without task-specific¬†training.",
    "pubDate": "Thu, 14 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/better-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Operator",
    "description": "A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in the U.S.",
    "summary": "A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in the U.S.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-operator",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster Text Generation with TensorFlow and XLA",
    "description": "",
    "summary": "Faster Text Generation with TensorFlow and XLA TL;DR: Text Generation on ü§ó transformers using Tensor...",
    "pubDate": "Wed, 27 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-xla-generate",
    "thumbnail": "https://huggingface.co/blog/assets/91_tf_xla_generate/thumbnail.png"
  },
  {
    "title": "Agentic Enterprise: AI-Centric User to User-Centric AI",
    "description": "arXiv:2506.22893v1 Announce Type: new Abstract: After a very long winter, the Artificial Intelligence (AI) spring is here. Or, so it seems over the last three years. AI has the potential to impact many areas of human life - personal, social, health, education, professional. In this paper, we take a closer look at the potential of AI for Enterprises, where decision-making plays a crucial and repeated role across functions, tasks, and operations. We consider Agents imbued with AI as means to increase decision-productivity of enterprises. We highlight six tenets for Agentic success in enterprises, by drawing attention to what the current, AI-Centric User paradigm misses, in the face of persistent needs of and usefulness for Enterprise Decision-Making. In underscoring a shift to User-Centric AI, we offer six tenets and promote market mechanisms for platforms, aligning the design of AI and its delivery by Agents to the cause of enterprise users.",
    "summary": "arXiv:2506.22893v1 Announce Type: new Abstract: After a very long winter, the Artificial Intelligence (AI) spring is here. Or, so it seems over the last three years. AI has the potential to impact many areas of human life - personal, social, health, education, professional. In this paper, we take a closer look at the potential of AI for Enterprises, where decision-making plays a crucial and repeated role across functions, tasks, and operations. We consider Agents imbued with AI as means to increase decision-productivity of enterprises. We highlight six tenets for Agentic success in enterprises, by drawing attention to what the current, AI-Centric User paradigm misses, in the face of persistent needs of and usefulness for Enterprise Decision-Making. In underscoring a shift to User-Centric AI, we offer six tenets and promote market mechanisms for platforms, aligning the design of AI and its delivery by Agents to the cause of enterprise users.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22893",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Open-sourcing Knowledge Distillation Code and Weights of SD-Small and SD-Tiny",
    "description": "",
    "summary": "Open-sourcing Knowledge Distillation Code and Weights of SD-Small and SD-Tiny In recent times, the A...",
    "pubDate": "Tue, 01 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd_distillation",
    "thumbnail": "https://huggingface.co/blog/assets/distill_sd/thumbnail.png"
  },
  {
    "title": "Trust & Safety of LLMs and LLMs in Trust & Safety",
    "description": "arXiv:2412.02113v2 Announce Type: replace Abstract: In recent years, Large Language Models (LLMs) have garnered considerable attention for their remarkable abilities in natural language processing tasks. However, their widespread adoption has raised concerns pertaining to trust and safety. This systematic review investigates the current research landscape on trust and safety in LLMs, with a particular focus on the novel application of LLMs within the field of Trust and Safety itself. We delve into the complexities of utilizing LLMs in domains where maintaining trust and safety is paramount, offering a consolidated perspective on this emerging trend. By synthesizing findings from various studies, we identify key challenges and potential solutions, aiming to benefit researchers and practitioners seeking to understand the nuanced interplay between LLMs and Trust and Safety. This review provides insights on best practices for using LLMs in Trust and Safety, and explores emerging risks such as prompt injection and jailbreak attacks. Ultimately, this study contributes to a deeper understanding of how LLMs can be effectively and responsibly utilized to enhance trust and safety in the digital realm.",
    "summary": "arXiv:2412.02113v2 Announce Type: replace Abstract: In recent years, Large Language Models (LLMs) have garnered considerable attention for their remarkable abilities in natural language processing tasks. However, their widespread adoption has raised concerns pertaining to trust and safety. This systematic review investigates the current research landscape on trust and safety in LLMs, with a particular focus on the novel application of LLMs within the field of Trust and Safety itself. We delve into the complexities of utilizing LLMs in domains where maintaining trust and safety is paramount, offering a consolidated perspective on this emerging trend. By synthesizing findings from various studies, we identify key challenges and potential solutions, aiming to benefit researchers and practitioners seeking to understand the nuanced interplay between LLMs and Trust and Safety. This review provides insights on best practices for using LLMs in Trust and Safety, and explores emerging risks such as prompt injection and jailbreak attacks. Ultimately, this study contributes to a deeper understanding of how LLMs can be effectively and responsibly utilized to enhance trust and safety in the digital realm.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.02113",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Open-source DeepResearch ‚Äì Freeing our search agents",
    "description": "",
    "summary": "Open-source DeepResearch ‚Äì Freeing our search agents TLDR Yesterday, OpenAI released Deep Research, ...",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-deep-research",
    "thumbnail": "https://huggingface.co/blog/assets/open-deep-research/thumbnail.png"
  },
  {
    "title": "Introducing SWE-bench Verified",
    "description": "We‚Äôre releasing a human-validated subset of SWE-bench that more reliably evaluates AI models‚Äô ability to solve real-world software issues.",
    "summary": "We‚Äôre releasing a human-validated subset of SWE-bench that more reliably evaluates AI models‚Äô ability to solve real-world software issues.",
    "pubDate": "Tue, 13 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-swe-bench-verified",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Development of Hybrid Artificial Intelligence Training on Real and Synthetic Data: Benchmark on Two Mixed Training Strategies",
    "description": "arXiv:2506.24093v1 Announce Type: cross Abstract: Synthetic data has emerged as a cost-effective alternative to real data for training artificial neural networks (ANN). However, the disparity between synthetic and real data results in a domain gap. That gap leads to poor performance and generalization of the trained ANN when applied to real-world scenarios. Several strategies have been developed to bridge this gap, which combine synthetic and real data, known as mixed training using hybrid datasets. While these strategies have been shown to mitigate the domain gap, a systematic evaluation of their generalizability and robustness across various tasks and architectures remains underexplored. To address this challenge, our study comprehensively analyzes two widely used mixing strategies on three prevalent architectures and three distinct hybrid datasets. From these datasets, we sample subsets with varying proportions of synthetic to real data to investigate the impact of synthetic and real components. The findings of this paper provide valuable insights into optimizing the use of synthetic data in the training process of any ANN, contributing to enhancing robustness and efficacy.",
    "summary": "arXiv:2506.24093v1 Announce Type: cross Abstract: Synthetic data has emerged as a cost-effective alternative to real data for training artificial neural networks (ANN). However, the disparity between synthetic and real data results in a domain gap. That gap leads to poor performance and generalization of the trained ANN when applied to real-world scenarios. Several strategies have been developed to bridge this gap, which combine synthetic and real data, known as mixed training using hybrid datasets. While these strategies have been shown to mitigate the domain gap, a systematic evaluation of their generalizability and robustness across various tasks and architectures remains underexplored. To address this challenge, our study comprehensively analyzes two widely used mixing strategies on three prevalent architectures and three distinct hybrid datasets. From these datasets, we sample subsets with varying proportions of synthetic to real data to investigate the impact of synthetic and real components. The findings of this paper provide valuable insights into optimizing the use of synthetic data in the training process of any ANN, contributing to enhancing robustness and efficacy.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.24093",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Washington Post partners with OpenAI on search content",
    "description": "The Washington Post is partnering with with OpenAI to integrate news into ChatGPT, providing users with summaries, quotes, and direct links to original reporting.",
    "summary": "The Washington Post is partnering with with OpenAI to integrate news into ChatGPT, providing users with summaries, quotes, and direct links to original reporting.",
    "pubDate": "Tue, 22 Apr 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/the-washington-post-partners-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration",
    "description": "arXiv:2506.23644v1 Announce Type: cross Abstract: We introduce QLPro, a vulnerability detection framework that systematically integrates LLMs and static analysis tools to enable comprehensive vulnerability detection across entire open-source projects.We constructed a new dataset, JavaTest, comprising 10 open-source projects from GitHub with 62 confirmed vulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only 24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro discovered 6 previously unknown vulnerabilities, 2 of which have been confirmed as 0-days.",
    "summary": "arXiv:2506.23644v1 Announce Type: cross Abstract: We introduce QLPro, a vulnerability detection framework that systematically integrates LLMs and static analysis tools to enable comprehensive vulnerability detection across entire open-source projects.We constructed a new dataset, JavaTest, comprising 10 open-source projects from GitHub with 62 confirmed vulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only 24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro discovered 6 previously unknown vulnerabilities, 2 of which have been confirmed as 0-days.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23644",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning",
    "description": "arXiv:2506.22919v1 Announce Type: new Abstract: Mixture-of-Experts (MoE) models enable conditional computation by routing inputs to specialized experts, but these experts rely on identical inductive biases, thus limiting representational diversity. This static computation pathway is inefficient for inputs that require different types of reasoning and limits specialization and interpretability. We propose Hecto, a lightweight MoE architecture that leverages architectural heterogeneity by combining a GRU expert for temporal reasoning and an FFNN expert for static abstraction under a sparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AG News, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closely trails homogeneous baselines in performance despite receiving isolated input representations, while achieving clear expert specialization, with each expert aligning to distinct reasoning types (temporal vs static). At larger batch sizes, Hecto exhibits improved performance, benefiting from relaxed computational constraints that allow its heterogeneous architecture to optimize more effectively. Ablation results isolate architectural diversity as the source of Hecto's stability and interpretability across diverse reasoning tasks. Overall, Hecto establishes itself as a new benchmark for conditional computation, offering a principled framework for specialized reasoning in low-resource regimes with its model strength derived from principled specialization.",
    "summary": "arXiv:2506.22919v1 Announce Type: new Abstract: Mixture-of-Experts (MoE) models enable conditional computation by routing inputs to specialized experts, but these experts rely on identical inductive biases, thus limiting representational diversity. This static computation pathway is inefficient for inputs that require different types of reasoning and limits specialization and interpretability. We propose Hecto, a lightweight MoE architecture that leverages architectural heterogeneity by combining a GRU expert for temporal reasoning and an FFNN expert for static abstraction under a sparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AG News, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closely trails homogeneous baselines in performance despite receiving isolated input representations, while achieving clear expert specialization, with each expert aligning to distinct reasoning types (temporal vs static). At larger batch sizes, Hecto exhibits improved performance, benefiting from relaxed computational constraints that allow its heterogeneous architecture to optimize more effectively. Ablation results isolate architectural diversity as the source of Hecto's stability and interpretability across diverse reasoning tasks. Overall, Hecto establishes itself as a new benchmark for conditional computation, offering a principled framework for specialized reasoning in low-resource regimes with its model strength derived from principled specialization.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22919",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning",
    "description": "arXiv:2506.22992v1 Announce Type: new Abstract: The ability to process information from multiple modalities and to reason through it step-by-step remains a critical challenge in advancing artificial intelligence. However, existing reasoning benchmarks focus on text-only reasoning, or employ multimodal questions that can be answered by directly retrieving information from a non-text modality. Thus, complex reasoning remains poorly understood in multimodal domains. Here, we present MARBLE, a challenging multimodal reasoning benchmark that is designed to scrutinize multimodal language models (MLLMs) in their ability to carefully reason step-by-step through complex multimodal problems and environments. MARBLE is composed of two highly challenging tasks, M-Portal and M-Cube, that require the crafting and understanding of multistep plans under spatial, visual, and physical constraints. We find that current MLLMs perform poorly on MARBLE -- all the 12 advanced models obtain near-random performance on M-Portal and 0% accuracy on M-Cube. Only in simplified subtasks some models outperform the random baseline, indicating that complex reasoning is still a challenge for existing MLLMs. Moreover, we show that perception remains a bottleneck, where MLLMs occasionally fail to extract information from the visual inputs. By shedding a light on the limitations of MLLMs, we hope that MARBLE will spur the development of the next generation of models with the ability to reason and plan across many, multimodal reasoning steps.",
    "summary": "arXiv:2506.22992v1 Announce Type: new Abstract: The ability to process information from multiple modalities and to reason through it step-by-step remains a critical challenge in advancing artificial intelligence. However, existing reasoning benchmarks focus on text-only reasoning, or employ multimodal questions that can be answered by directly retrieving information from a non-text modality. Thus, complex reasoning remains poorly understood in multimodal domains. Here, we present MARBLE, a challenging multimodal reasoning benchmark that is designed to scrutinize multimodal language models (MLLMs) in their ability to carefully reason step-by-step through complex multimodal problems and environments. MARBLE is composed of two highly challenging tasks, M-Portal and M-Cube, that require the crafting and understanding of multistep plans under spatial, visual, and physical constraints. We find that current MLLMs perform poorly on MARBLE -- all the 12 advanced models obtain near-random performance on M-Portal and 0% accuracy on M-Cube. Only in simplified subtasks some models outperform the random baseline, indicating that complex reasoning is still a challenge for existing MLLMs. Moreover, we show that perception remains a bottleneck, where MLLMs occasionally fail to extract information from the visual inputs. By shedding a light on the limitations of MLLMs, we hope that MARBLE will spur the development of the next generation of models with the ability to reason and plan across many, multimodal reasoning steps.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22992",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "P4OMP: Retrieval-Augmented Prompting for OpenMP Parallelism in Serial Code",
    "description": "arXiv:2506.22703v1 Announce Type: cross Abstract: We present P4OMP, a retrieval-augmented framework for transforming serial C/C++ code into OpenMP-annotated parallel code using large language models (LLMs). To our knowledge, this is the first system to apply retrieval-based prompting for OpenMP pragma correctness without model fine-tuning or compiler instrumentation. P4OMP leverages Retrieval-Augmented Generation (RAG) with structured instructional knowledge from OpenMP tutorials to improve the reliability of prompt-driven code generation. By grounding generation in the retrieved context, P4OMP improves syntactic correctness compared to baseline prompting with GPT-3.5-Turbo. We evaluate P4OMP against a baseline, GPT-3.5-Turbo without retrieval, on a comprehensive benchmark of 108 real-world C++ programs drawn from Stack Overflow, PolyBench, and NAS benchmark suites. P4OMP achieves 100% compilation success on all parallelizable cases, while the baseline fails to compile in 20 out of 108 cases. Six cases that rely on non-random-access iterators or thread-unsafe constructs are excluded due to fundamental OpenMP limitations. A detailed analysis demonstrates how P4OMP consistently avoids scoping errors, syntactic misuse, and invalid directive combinations that commonly affect baseline-generated code. We further demonstrate strong runtime scaling across seven compute-intensive benchmarks on an HPC cluster. P4OMP offers a robust, modular pipeline that significantly improves the reliability and applicability of LLM-generated OpenMP code.",
    "summary": "arXiv:2506.22703v1 Announce Type: cross Abstract: We present P4OMP, a retrieval-augmented framework for transforming serial C/C++ code into OpenMP-annotated parallel code using large language models (LLMs). To our knowledge, this is the first system to apply retrieval-based prompting for OpenMP pragma correctness without model fine-tuning or compiler instrumentation. P4OMP leverages Retrieval-Augmented Generation (RAG) with structured instructional knowledge from OpenMP tutorials to improve the reliability of prompt-driven code generation. By grounding generation in the retrieved context, P4OMP improves syntactic correctness compared to baseline prompting with GPT-3.5-Turbo. We evaluate P4OMP against a baseline, GPT-3.5-Turbo without retrieval, on a comprehensive benchmark of 108 real-world C++ programs drawn from Stack Overflow, PolyBench, and NAS benchmark suites. P4OMP achieves 100% compilation success on all parallelizable cases, while the baseline fails to compile in 20 out of 108 cases. Six cases that rely on non-random-access iterators or thread-unsafe constructs are excluded due to fundamental OpenMP limitations. A detailed analysis demonstrates how P4OMP consistently avoids scoping errors, syntactic misuse, and invalid directive combinations that commonly affect baseline-generated code. We further demonstrate strong runtime scaling across seven compute-intensive benchmarks on an HPC cluster. P4OMP offers a robust, modular pipeline that significantly improves the reliability and applicability of LLM-generated OpenMP code.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22703",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AirSketch: Generative Motion to Sketch",
    "description": "arXiv:2407.08906v3 Announce Type: replace-cross Abstract: Illustration is a fundamental mode of human expression and communication. Certain types of motion that accompany speech can provide this illustrative mode of communication. While Augmented and Virtual Reality technologies (AR/VR) have introduced tools for producing drawings with hand motions (air drawing), they typically require costly hardware and additional digital markers, thereby limiting their accessibility and portability. Furthermore, air drawing demands considerable skill to achieve aesthetic results. To address these challenges, we introduce the concept of AirSketch, aimed at generating faithful and visually coherent sketches directly from hand motions, eliminating the need for complicated headsets or markers. We devise a simple augmentation-based self-supervised training procedure, enabling a controllable image diffusion model to learn to translate from highly noisy hand tracking images to clean, aesthetically pleasing sketches, while preserving the essential visual cues from the original tracking data. We present two air drawing datasets to study this problem. Our findings demonstrate that beyond producing photo-realistic images from precise spatial inputs, controllable image diffusion can effectively produce a refined, clear sketch from a noisy input. Our work serves as an initial step towards marker-less air drawing and reveals distinct applications of controllable diffusion models to AirSketch and AR/VR in general.",
    "summary": "arXiv:2407.08906v3 Announce Type: replace-cross Abstract: Illustration is a fundamental mode of human expression and communication. Certain types of motion that accompany speech can provide this illustrative mode of communication. While Augmented and Virtual Reality technologies (AR/VR) have introduced tools for producing drawings with hand motions (air drawing), they typically require costly hardware and additional digital markers, thereby limiting their accessibility and portability. Furthermore, air drawing demands considerable skill to achieve aesthetic results. To address these challenges, we introduce the concept of AirSketch, aimed at generating faithful and visually coherent sketches directly from hand motions, eliminating the need for complicated headsets or markers. We devise a simple augmentation-based self-supervised training procedure, enabling a controllable image diffusion model to learn to translate from highly noisy hand tracking images to clean, aesthetically pleasing sketches, while preserving the essential visual cues from the original tracking data. We present two air drawing datasets to study this problem. Our findings demonstrate that beyond producing photo-realistic images from precise spatial inputs, controllable image diffusion can effectively produce a refined, clear sketch from a noisy input. Our work serves as an initial step towards marker-less air drawing and reveals distinct applications of controllable diffusion models to AirSketch and AR/VR in general.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.08906",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From OpenAI to Open LLMs with Messages API",
    "description": "",
    "summary": "From OpenAI to Open LLMs with Messages API on Hugging Face We are excited to introduce the Messages ...",
    "pubDate": "Thu, 08 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-messages-api",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-messages-api/thumbnail.jpg"
  },
  {
    "title": "Learning with opponent-learning awareness",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-with-opponent-learning-awareness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing ChatGPT and Whisper APIs",
    "description": "Developers can now integrate ChatGPT and Whisper models into their apps and products through our API.",
    "summary": "Developers can now integrate ChatGPT and Whisper models into their apps and products through our API.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-and-whisper-apis",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemini 2.5: Our most intelligent AI model",
    "description": "Gemini 2.5 is our most intelligent AI model, now with thinking built in.",
    "summary": "Gemini 2.5 is our most intelligent AI model, now with thinking built in.",
    "pubDate": "Tue, 25 Mar 2025 17:00:36 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-2-5-our-most-intelligent-ai-model/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_keyword_social_share_text.width-1300.png"
  },
  {
    "title": "Introducing HealthBench",
    "description": "HealthBench is a new evaluation benchmark for AI in healthcare which evaluates models in realistic scenarios. Built with input from 250+ physicians, it aims to provide a shared standard for model performance and safety in health.",
    "summary": "HealthBench is a new evaluation benchmark for AI in healthcare which evaluates models in realistic scenarios. Built with input from 250+ physicians, it aims to provide a shared standard for model performance and safety in health.",
    "pubDate": "Mon, 12 May 2025 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/healthbench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Awareness",
    "description": "arXiv:2504.20084v2 Announce Type: replace Abstract: Recent breakthroughs in artificial intelligence (AI) have brought about increasingly capable systems that demonstrate remarkable abilities in reasoning, language understanding, and problem-solving. These advancements have prompted a renewed examination of AI awareness not as a philosophical question of consciousness, but as a measurable, functional capacity. AI awareness is a double-edged sword: it improves general capabilities, i.e., reasoning, safety, while also raising concerns around misalignment and societal risks, demanding careful oversight as AI capabilities grow. In this review, we explore the emerging landscape of AI awareness, which includes metacognition (the ability to represent and reason about its own cognitive state), self-awareness (recognizing its own identity, knowledge, limitations, inter alia), social awareness (modeling the knowledge, intentions, and behaviors of other agents and social norms), and situational awareness (assessing and responding to the context in which it operates). First, we draw on insights from cognitive science, psychology, and computational theory to trace the theoretical foundations of awareness and examine how the four distinct forms of AI awareness manifest in state-of-the-art AI. Next, we systematically analyze current evaluation methods and empirical findings to better understand these manifestations. Building on this, we explore how AI awareness is closely linked to AI capabilities, demonstrating that more aware AI agents tend to exhibit higher levels of intelligent behaviors. Finally, we discuss the risks associated with AI awareness, including key topics in AI safety, alignment, and broader ethical concerns.",
    "summary": "arXiv:2504.20084v2 Announce Type: replace Abstract: Recent breakthroughs in artificial intelligence (AI) have brought about increasingly capable systems that demonstrate remarkable abilities in reasoning, language understanding, and problem-solving. These advancements have prompted a renewed examination of AI awareness not as a philosophical question of consciousness, but as a measurable, functional capacity. AI awareness is a double-edged sword: it improves general capabilities, i.e., reasoning, safety, while also raising concerns around misalignment and societal risks, demanding careful oversight as AI capabilities grow. In this review, we explore the emerging landscape of AI awareness, which includes metacognition (the ability to represent and reason about its own cognitive state), self-awareness (recognizing its own identity, knowledge, limitations, inter alia), social awareness (modeling the knowledge, intentions, and behaviors of other agents and social norms), and situational awareness (assessing and responding to the context in which it operates). First, we draw on insights from cognitive science, psychology, and computational theory to trace the theoretical foundations of awareness and examine how the four distinct forms of AI awareness manifest in state-of-the-art AI. Next, we systematically analyze current evaluation methods and empirical findings to better understand these manifestations. Building on this, we explore how AI awareness is closely linked to AI capabilities, demonstrating that more aware AI agents tend to exhibit higher levels of intelligent behaviors. Finally, we discuss the risks associated with AI awareness, including key topics in AI safety, alignment, and broader ethical concerns.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.20084",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NPHardEval Leaderboard: Unveiling the Reasoning Abilities of Large Language Models through Complexity Classes and Dynamic Updates",
    "description": "",
    "summary": "NPHardEval Leaderboard: Unveiling the Reasoning Abilities of Large Language Models through Complexit...",
    "pubDate": "Fri, 02 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-nphardeval",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_nphardeval.png"
  },
  {
    "title": "Sam Altman returns as CEO, OpenAI has a new initial board",
    "description": "Mira Murati as CTO, Greg Brockman returns as President. Read messages from CEO Sam Altman and board chair Bret Taylor.",
    "summary": "Mira Murati as CTO, Greg Brockman returns as President. Read messages from CEO Sam Altman and board chair Bret Taylor.",
    "pubDate": "Wed, 29 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Lowe‚Äôs leverages AI to power home improvement retail",
    "description": "A conversation with Chandhu Nair, Senior Vice President of Data, AI, and Innovation.",
    "summary": "A conversation with Chandhu Nair, Senior Vice President of Data, AI, and Innovation.",
    "pubDate": "Mon, 05 May 2025 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lowes-chandhu-nair",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Measuring How LLMs Internalize Human Psychological Concepts: A preliminary analysis",
    "description": "arXiv:2506.23055v1 Announce Type: cross Abstract: Large Language Models (LLMs) such as ChatGPT have shown remarkable abilities in producing human-like text. However, it is unclear how accurately these models internalize concepts that shape human thought and behavior. Here, we developed a quantitative framework to assess concept alignment between LLMs and human psychological dimensions using 43 standardized psychological questionnaires, selected for their established validity in measuring distinct psychological constructs. Our method evaluates how accurately language models reconstruct and classify questionnaire items through pairwise similarity analysis. We compared resulting cluster structures with the original categorical labels using hierarchical clustering. A GPT-4 model achieved superior classification accuracy (66.2%), significantly outperforming GPT-3.5 (55.9%) and BERT (48.1%), all exceeding random baseline performance (31.9%). We also demonstrated that the estimated semantic similarity from GPT-4 is associated with Pearson's correlation coefficients of human responses in multiple psychological questionnaires. This framework provides a novel approach to evaluate the alignment of the human-LLM concept and identify potential representational biases. Our findings demonstrate that modern LLMs can approximate human psychological constructs with measurable accuracy, offering insights for developing more interpretable AI systems.",
    "summary": "arXiv:2506.23055v1 Announce Type: cross Abstract: Large Language Models (LLMs) such as ChatGPT have shown remarkable abilities in producing human-like text. However, it is unclear how accurately these models internalize concepts that shape human thought and behavior. Here, we developed a quantitative framework to assess concept alignment between LLMs and human psychological dimensions using 43 standardized psychological questionnaires, selected for their established validity in measuring distinct psychological constructs. Our method evaluates how accurately language models reconstruct and classify questionnaire items through pairwise similarity analysis. We compared resulting cluster structures with the original categorical labels using hierarchical clustering. A GPT-4 model achieved superior classification accuracy (66.2%), significantly outperforming GPT-3.5 (55.9%) and BERT (48.1%), all exceeding random baseline performance (31.9%). We also demonstrated that the estimated semantic similarity from GPT-4 is associated with Pearson's correlation coefficients of human responses in multiple psychological questionnaires. This framework provides a novel approach to evaluate the alignment of the human-LLM concept and identify potential representational biases. Our findings demonstrate that modern LLMs can approximate human psychological constructs with measurable accuracy, offering insights for developing more interpretable AI systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23055",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DistShap: Scalable GNN Explanations with Distributed Shapley Values",
    "description": "arXiv:2506.22668v1 Announce Type: cross Abstract: With the growing adoption of graph neural networks (GNNs), explaining their predictions has become increasingly important. However, attributing predictions to specific edges or features remains computationally expensive. For example, classifying a node with 100 neighbors using a 3-layer GNN may involve identifying important edges from millions of candidates contributing to the prediction. To address this challenge, we propose DistShap, a parallel algorithm that distributes Shapley value-based explanations across multiple GPUs. DistShap operates by sampling subgraphs in a distributed setting, executing GNN inference in parallel across GPUs, and solving a distributed least squares problem to compute edge importance scores. DistShap outperforms most existing GNN explanation methods in accuracy and is the first to scale to GNN models with millions of features by using up to 128 GPUs on the NERSC Perlmutter supercomputer.",
    "summary": "arXiv:2506.22668v1 Announce Type: cross Abstract: With the growing adoption of graph neural networks (GNNs), explaining their predictions has become increasingly important. However, attributing predictions to specific edges or features remains computationally expensive. For example, classifying a node with 100 neighbors using a 3-layer GNN may involve identifying important edges from millions of candidates contributing to the prediction. To address this challenge, we propose DistShap, a parallel algorithm that distributes Shapley value-based explanations across multiple GPUs. DistShap operates by sampling subgraphs in a distributed setting, executing GNN inference in parallel across GPUs, and solving a distributed least squares problem to compute edge importance scores. DistShap outperforms most existing GNN explanation methods in accuracy and is the first to scale to GNN models with millions of features by using up to 128 GPUs on the NERSC Perlmutter supercomputer.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22668",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Results of the Open Source AI Game Jam",
    "description": "",
    "summary": "Results of the Open Source AI Game Jam From July 7th to July 11th, we hosted our first Open Source A...",
    "pubDate": "Fri, 21 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/game-jam-first-edition-results",
    "thumbnail": "https://huggingface.co/blog/assets/game-jam-first-edition-results/thumbnail.jpg"
  },
  {
    "title": "Scaling robotics datasets with video encoding",
    "description": "",
    "summary": "Scaling robotics datasets with video encoding Over the past few years, text and image-based models h...",
    "pubDate": "Tue, 27 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/video-encoding",
    "thumbnail": "https://huggingface.co/blog/assets/video-encoding/thumbnail.png"
  },
  {
    "title": "Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks",
    "description": "arXiv:2506.22623v1 Announce Type: cross Abstract: In the present-day scenario, Large Language Models (LLMs) are establishing their presence as powerful instruments permeating various sectors of society. While their utility offers valuable support to individuals, there are multiple concerns over potential misuse. Consequently, some academic endeavors have sought to introduce watermarking techniques, characterized by the inclusion of markers within machine-generated text, to facilitate algorithmic identification. This research project is focused on the development of a novel methodology for the detection of synthetic text, with the overarching goal of ensuring the ethical application of LLMs in AI-driven text generation. The investigation commences with replicating findings from a previous baseline study, thereby underscoring its susceptibility to variations in the underlying generation model. Subsequently, we propose an innovative watermarking approach and subject it to rigorous evaluation, employing paraphrased generated text to asses its robustness. Experimental results highlight the robustness of our proposal compared to the~cite{aarson} watermarking method.",
    "summary": "arXiv:2506.22623v1 Announce Type: cross Abstract: In the present-day scenario, Large Language Models (LLMs) are establishing their presence as powerful instruments permeating various sectors of society. While their utility offers valuable support to individuals, there are multiple concerns over potential misuse. Consequently, some academic endeavors have sought to introduce watermarking techniques, characterized by the inclusion of markers within machine-generated text, to facilitate algorithmic identification. This research project is focused on the development of a novel methodology for the detection of synthetic text, with the overarching goal of ensuring the ethical application of LLMs in AI-driven text generation. The investigation commences with replicating findings from a previous baseline study, thereby underscoring its susceptibility to variations in the underlying generation model. Subsequently, we propose an innovative watermarking approach and subject it to rigorous evaluation, employing paraphrased generated text to asses its robustness. Experimental results highlight the robustness of our proposal compared to the~cite{aarson} watermarking method.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22623",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Case Study: Millisecond Latency using Hugging Face Infinity and modern CPUs",
    "description": "",
    "summary": "Case Study: Millisecond Latency using Hugging Face Infinity and modern CPUs Inference Endpoints to e...",
    "pubDate": "Thu, 13 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/infinity-cpu-performance",
    "thumbnail": "https://huggingface.co/blog/assets/46_infinity_cpu_performance/thumbnail.png"
  },
  {
    "title": "CLIP: Connecting text and images",
    "description": "We‚Äôre introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the ‚Äúzero-shot‚Äù capabilities of GPT-2 and¬†GPT-3.",
    "summary": "We‚Äôre introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the ‚Äúzero-shot‚Äù capabilities of GPT-2 and¬†GPT-3.",
    "pubDate": "Tue, 05 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/clip",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building an autonomous financial analyst with o1 and o3-mini",
    "description": "Endex builds the future of financial analysis, powered by OpenAI‚Äôs reasoning models.",
    "summary": "Endex builds the future of financial analysis, powered by OpenAI‚Äôs reasoning models.",
    "pubDate": "Thu, 27 Feb 2025 09:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/endex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TacticAI: an AI assistant for football tactics",
    "description": "As part of our multi-year collaboration with Liverpool FC, we develop a full AI system that can advise coaches on corner kicks",
    "summary": "As part of our multi-year collaboration with Liverpool FC, we develop a full AI system that can advise coaches on corner kicks",
    "pubDate": "Tue, 19 Mar 2024 16:03:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/tacticai-ai-assistant-for-football-tactics/",
    "thumbnail": "https://lh3.googleusercontent.com/pPa45NPPYrOc4QHbcLIsmueJXi9hKNFdB0rbnRMdiRH0Gf3fgIc_g26-UbFxHVzqUT85QA-N3IvPpQaDevlp3OeF3RIiLQjmuONVRVyX1et0WYEKTQ=w1200-h630-n-nu"
  },
  {
    "title": "Enhancing news in ChatGPT with The Atlantic",
    "description": "The Atlantic is announcing a strategic content and product partnership with OpenAI, which positions The Atlantic as a premium news source within OpenAI. The Atlantic‚Äôs articles will be discoverable within OpenAI‚Äôs products, including ChatGPT, and as a partner, The Atlantic will help to shape how news is surfaced and presented in future real-time discovery products.",
    "summary": "The Atlantic is announcing a strategic content and product partnership with OpenAI, which positions The Atlantic as a premium news source within OpenAI. The Atlantic‚Äôs articles will be discoverable within OpenAI‚Äôs products, including ChatGPT, and as a partner, The Atlantic will help to shape how news is surfaced and presented in future real-time discovery products.",
    "pubDate": "Wed, 29 May 2024 07:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/enhancing-news-in-chatgpt-with-the-atlantic",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MEMFOF: High-Resolution Training for Memory-Efficient Multi-Frame Optical Flow Estimation",
    "description": "arXiv:2506.23151v1 Announce Type: cross Abstract: Recent advances in optical flow estimation have prioritized accuracy at the cost of growing GPU memory consumption, particularly for high-resolution (FullHD) inputs. We introduce MEMFOF, a memory-efficient multi-frame optical flow method that identifies a favorable trade-off between multi-frame estimation and GPU memory usage. Notably, MEMFOF requires only 2.09 GB of GPU memory at runtime for 1080p inputs, and 28.5 GB during training, which uniquely positions our method to be trained at native 1080p without the need for cropping or downsampling. We systematically revisit design choices from RAFT-like architectures, integrating reduced correlation volumes and high-resolution training protocols alongside multi-frame estimation, to achieve state-of-the-art performance across multiple benchmarks while substantially reducing memory overhead. Our method outperforms more resource-intensive alternatives in both accuracy and runtime efficiency, validating its robustness for flow estimation at high resolutions. At the time of submission, our method ranks first on the Spring benchmark with a 1-pixel (1px) outlier rate of 3.289, leads Sintel (clean) with an endpoint error (EPE) of 0.963, and achieves the best Fl-all error on KITTI-2015 at 2.94%. The code is available at https://github.com/msu-video-group/memfof.",
    "summary": "arXiv:2506.23151v1 Announce Type: cross Abstract: Recent advances in optical flow estimation have prioritized accuracy at the cost of growing GPU memory consumption, particularly for high-resolution (FullHD) inputs. We introduce MEMFOF, a memory-efficient multi-frame optical flow method that identifies a favorable trade-off between multi-frame estimation and GPU memory usage. Notably, MEMFOF requires only 2.09 GB of GPU memory at runtime for 1080p inputs, and 28.5 GB during training, which uniquely positions our method to be trained at native 1080p without the need for cropping or downsampling. We systematically revisit design choices from RAFT-like architectures, integrating reduced correlation volumes and high-resolution training protocols alongside multi-frame estimation, to achieve state-of-the-art performance across multiple benchmarks while substantially reducing memory overhead. Our method outperforms more resource-intensive alternatives in both accuracy and runtime efficiency, validating its robustness for flow estimation at high resolutions. At the time of submission, our method ranks first on the Spring benchmark with a 1-pixel (1px) outlier rate of 3.289, leads Sintel (clean) with an endpoint error (EPE) of 0.963, and achieves the best Fl-all error on KITTI-2015 at 2.94%. The code is available at https://github.com/msu-video-group/memfof.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23151",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deploying ü§ó ViT on Vertex AI",
    "description": "",
    "summary": "Deploying ü§ó ViT on Vertex AI In the previous posts, we showed how to deploy a Vision Transformers (V...",
    "pubDate": "Fri, 19 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-vertex-ai",
    "thumbnail": "https://huggingface.co/blog/assets/97_vertex_ai/image1.png"
  },
  {
    "title": "Snorkel AI x Hugging Face: unlock foundation models for enterprises",
    "description": "",
    "summary": "Snorkel AI x Hugging Face: unlock foundation models for enterprises This article is a cross-post fro...",
    "pubDate": "Thu, 06 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/snorkel-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/snorkel.png"
  },
  {
    "title": "Roboschool",
    "description": "We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym.",
    "summary": "We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym.",
    "pubDate": "Mon, 15 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/roboschool",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Federated Timeline Synthesis: Scalable and Private Methodology For Model Training and Deployment",
    "description": "arXiv:2506.23358v1 Announce Type: cross Abstract: We present Federated Timeline Synthesis (FTS), a novel framework for training generative foundation models across distributed timeseries data applied to electronic health records (EHR). At its core, FTS represents patient history as tokenized Patient Health Timelines (PHTs), language-agnostic sequences encoding temporal, categorical, and continuous clinical information. Each institution trains an autoregressive transformer on its local PHTs and transmits only model weights to a central server. The server uses the generators to synthesize a large corpus of trajectories and train a Global Generator (GG), enabling zero-shot inference via Monte Carlo simulation of future PHTs. We evaluate FTS on five clinically meaningful prediction tasks using MIMIC-IV data, showing that models trained on synthetic data generated by GG perform comparably to those trained on real data. FTS offers strong privacy guarantees, scalability across institutions, and extensibility to diverse prediction and simulation tasks especially in healthcare, including counterfactual inference, early warning detection, and synthetic trial design.",
    "summary": "arXiv:2506.23358v1 Announce Type: cross Abstract: We present Federated Timeline Synthesis (FTS), a novel framework for training generative foundation models across distributed timeseries data applied to electronic health records (EHR). At its core, FTS represents patient history as tokenized Patient Health Timelines (PHTs), language-agnostic sequences encoding temporal, categorical, and continuous clinical information. Each institution trains an autoregressive transformer on its local PHTs and transmits only model weights to a central server. The server uses the generators to synthesize a large corpus of trajectories and train a Global Generator (GG), enabling zero-shot inference via Monte Carlo simulation of future PHTs. We evaluate FTS on five clinically meaningful prediction tasks using MIMIC-IV data, showing that models trained on synthetic data generated by GG perform comparably to those trained on real data. FTS offers strong privacy guarantees, scalability across institutions, and extensibility to diverse prediction and simulation tasks especially in healthcare, including counterfactual inference, early warning detection, and synthetic trial design.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23358",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Advancing Gemini's security safeguards",
    "description": "We‚Äôve made Gemini 2.5 our most secure model family to date.",
    "summary": "We‚Äôve made Gemini 2.5 our most secure model family to date.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
    "thumbnail": "https://lh3.googleusercontent.com/Uh_O6Nx1GWznAfODatYYz2sxiDekdb6HWnnSsy-cfmTxfjdUEEleh9w4cBdwUfBnyQBS-t1xW4UZXrMmC-rI6bz31hCrm5nHLt6Cp1FJAT7X9Upv5g=w1200-h630-n-nu"
  },
  {
    "title": "Spring Update",
    "description": "Introducing GPT-4o and making more capabilities available for free in ChatGPT.",
    "summary": "Introducing GPT-4o and making more capabilities available for free in ChatGPT.",
    "pubDate": "Mon, 13 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spring-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Partnering with Axios expands OpenAI‚Äôs work with the news industry",
    "description": "Publishers representing hundreds of newsrooms and content brands are using OpenAI partnerships and grant programs to adopt AI tools and strengthen the news ecosystem, while ChatGPT users gain access to information from leading, reliable publications.",
    "summary": "Publishers representing hundreds of newsrooms and content brands are using OpenAI partnerships and grant programs to adopt AI tools and strengthen the news ecosystem, while ChatGPT users gain access to information from leading, reliable publications.",
    "pubDate": "Wed, 15 Jan 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/partnering-with-axios-expands-openai-work-with-the-news-industry",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemini Robotics On-Device brings AI to local robotic devices",
    "description": "We‚Äôre introducing an efficient, on-device robotics model with general-purpose dexterity and fast task adaptation.",
    "summary": "We‚Äôre introducing an efficient, on-device robotics model with general-purpose dexterity and fast task adaptation.",
    "pubDate": "Tue, 24 Jun 2025 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-robotics-on-device-brings-ai-to-local-robotic-devices/",
    "thumbnail": "https://lh3.googleusercontent.com/Jt_Vw7PIJEZtXcMIKM1HbWbBCLxv7RUyjyf07eHp-YOfxMCUZA6mPI9kSCaz65UkMoGcZ8CwlD3dNBvy7bnnYchjSkWyN-SugglT3dmg1A9KdoDqdQM=w1200-h630-n-nu"
  },
  {
    "title": "Efficient training of language models to fill in the middle",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 28 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/efficient-training-of-language-models-to-fill-in-the-middle",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Catching halibut with ChatGPT",
    "description": "Using ChatGPT to catch halibut",
    "summary": "Using ChatGPT to catch halibut",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fishing-for-first-timers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New model predicts a chemical reaction‚Äôs point of no return",
    "description": "Chemists could use this quick computational method to design more efficient reactions that yield useful compounds, from fuels to pharmaceuticals.",
    "summary": "Chemists could use this quick computational method to design more efficient reactions that yield useful compounds, from fuels to pharmaceuticals.",
    "pubDate": "Wed, 23 Apr 2025 11:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-model-predicts-chemical-reactions-no-return-point-0423",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/BetterPredict-01-press.jpg"
  },
  {
    "title": "Large Language Models: A New Moore's Law?",
    "description": "",
    "summary": "Large Language Models: A New Moore's Law? A few days ago, Microsoft and NVIDIA introduced Megatron-T...",
    "pubDate": "Tue, 26 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/large-language-models",
    "thumbnail": "https://huggingface.co/blog/assets/33_large_language_models/01_model_size.jpg"
  },
  {
    "title": "Ethics and Society Newsletter #4: Bias in Text-to-Image Models",
    "description": "",
    "summary": "Ethics and Society Newsletter #4: Bias in Text-to-Image Models TL;DR: We need better ways of evaluat...",
    "pubDate": "Mon, 26 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-4",
    "thumbnail": "https://huggingface.co/blog/assets/152_ethics_soc_4/ethics_4_thumbnail.png"
  },
  {
    "title": "New ways to manage your data in ChatGPT",
    "description": "ChatGPT users can now turn off chat history, allowing you to choose which conversations can be used to train our models.",
    "summary": "ChatGPT users can now turn off chat history, allowing you to choose which conversations can be used to train our models.",
    "pubDate": "Tue, 25 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Guiding Text Generation with Constrained Beam Search in ü§ó Transformers",
    "description": "",
    "summary": "Guiding Text Generation with Constrained Beam Search in ü§ó Transformers Introduction This blog post a...",
    "pubDate": "Fri, 11 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/constrained-beam-search",
    "thumbnail": "https://huggingface.co/blog/assets/53_constrained_beam_search/thumbnail.png"
  },
  {
    "title": "Fine-Tune W2V2-Bert for low-resource ASR with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune W2V2-Bert for low-resource ASR with ü§ó Transformers New (01/2024): This blog post is strong...",
    "pubDate": "Fri, 19 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-w2v2-bert",
    "thumbnail": "https://huggingface.co/blog/assets/fine-tune-w2v2-bert/w2v_thumbnail.png"
  },
  {
    "title": "Novel AI model inspired by neural dynamics from the brain",
    "description": "New type of ‚Äústate-space model‚Äù leverages principles of harmonic oscillators.",
    "summary": "New type of ‚Äústate-space model‚Äù leverages principles of harmonic oscillators.",
    "pubDate": "Fri, 02 May 2025 15:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/novel-ai-model-inspired-neural-dynamics-from-brain-0502",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-LinOSS.jpg"
  },
  {
    "title": "Disrupting malicious uses of AI by state-affiliated threat actors",
    "description": "We terminated accounts associated with state-affiliated threat actors. Our findings show our models offer only limited, incremental capabilities for malicious cybersecurity tasks.",
    "summary": "We terminated accounts associated with state-affiliated threat actors. Our findings show our models offer only limited, incremental capabilities for malicious cybersecurity tasks.",
    "pubDate": "Wed, 14 Feb 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-malicious-uses-of-ai-by-state-affiliated-threat-actors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Universal Image Segmentation with Mask2Former and OneFormer",
    "description": "",
    "summary": "Universal Image Segmentation with Mask2Former and OneFormer This guide introduces Mask2Former and On...",
    "pubDate": "Thu, 19 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mask2former",
    "thumbnail": "https://huggingface.co/blog/assets/127_mask2former/thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT search",
    "description": "Get fast, timely answers with links to relevant web sources",
    "summary": "Get fast, timely answers with links to relevant web sources",
    "pubDate": "Thu, 31 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-search",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An Investigation into Seasonal Variations in Energy Forecasting for Student Residences",
    "description": "arXiv:2501.07423v2 Announce Type: replace-cross Abstract: This research provides an in-depth evaluation of various machine learning models for energy forecasting, focusing on the unique challenges of seasonal variations in student residential settings. The study assesses the performance of baseline models, such as LSTM and GRU, alongside state-of-the-art forecasting methods, including Autoregressive Feedforward Neural Networks, Transformers, and hybrid approaches. Special attention is given to predicting energy consumption amidst challenges like seasonal patterns, vacations, meteorological changes, and irregular human activities that cause sudden fluctuations in usage. The findings reveal that no single model consistently outperforms others across all seasons, emphasizing the need for season-specific model selection or tailored designs. Notably, the proposed Hyper Network based LSTM and MiniAutoEncXGBoost models exhibit strong adaptability to seasonal variations, effectively capturing abrupt changes in energy consumption during summer months. This study advances the energy forecasting field by emphasizing the critical role of seasonal dynamics and model-specific behavior in achieving accurate predictions.",
    "summary": "arXiv:2501.07423v2 Announce Type: replace-cross Abstract: This research provides an in-depth evaluation of various machine learning models for energy forecasting, focusing on the unique challenges of seasonal variations in student residential settings. The study assesses the performance of baseline models, such as LSTM and GRU, alongside state-of-the-art forecasting methods, including Autoregressive Feedforward Neural Networks, Transformers, and hybrid approaches. Special attention is given to predicting energy consumption amidst challenges like seasonal patterns, vacations, meteorological changes, and irregular human activities that cause sudden fluctuations in usage. The findings reveal that no single model consistently outperforms others across all seasons, emphasizing the need for season-specific model selection or tailored designs. Notably, the proposed Hyper Network based LSTM and MiniAutoEncXGBoost models exhibit strong adaptability to seasonal variations, effectively capturing abrupt changes in energy consumption during summer months. This study advances the energy forecasting field by emphasizing the critical role of seasonal dynamics and model-specific behavior in achieving accurate predictions.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.07423",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SafeCoder vs. Closed-source Code Assistants",
    "description": "",
    "summary": "SafeCoder vs. Closed-source Code Assistants For decades, software developers have designed methodolo...",
    "pubDate": "Mon, 11 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safecoder-vs-closed-source-code-assistants",
    "thumbnail": "https://huggingface.co/blog/assets/safecoder-vs-closed-source-code-assistants/image.png"
  },
  {
    "title": "SmolVLM2: Bringing Video Understanding to Every Device",
    "description": "",
    "summary": "SmolVLM2: Bringing Video Understanding to Every Device TL;DR: SmolVLM can now watch üì∫ with even bett...",
    "pubDate": "Thu, 20 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvlm2",
    "thumbnail": "https://huggingface.co/blog/assets/smolvlm2/banner.png"
  },
  {
    "title": "A Deepdive into Aya Expanse: Advancing the Frontier of Multilinguality",
    "description": "",
    "summary": "A Deepdive into Aya Expanse: Advancing the Frontier of Multilinguality This is a guest blog post by ...",
    "pubDate": "Thu, 24 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aya-expanse",
    "thumbnail": "https://huggingface.co/blog/assets/aya-expanse/thumbnail.jpg"
  },
  {
    "title": "Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon",
    "description": "",
    "summary": "Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon Large language models (LLM...",
    "pubDate": "Tue, 16 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/generative-ai-models-on-intel-cpu",
    "thumbnail": "https://huggingface.co/blog/assets/143_q8chat/thumbnail.png"
  },
  {
    "title": "ScreenSuite - The most comprehensive evaluation suite for GUI Agents!",
    "description": "",
    "summary": "ScreenSuite - The most comprehensive evaluation suite for GUI Agents! Releasing ScreenSuite, the mos...",
    "pubDate": "Fri, 06 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/screensuite",
    "thumbnail": "https://huggingface.co/blog/assets/screensuite/thumbnail.png"
  },
  {
    "title": "Fine-Tuning Next-Scale Visual Autoregressive Models with Group Relative Policy Optimization",
    "description": "arXiv:2505.23331v2 Announce Type: replace-cross Abstract: Fine-tuning pre-trained generative models with Reinforcement Learning (RL) has emerged as an effective approach for aligning outputs more closely with nuanced human preferences. In this paper, we investigate the application of Group Relative Policy Optimization (GRPO) to fine-tune next-scale visual autoregressive (VAR) models. Our empirical results demonstrate that this approach enables alignment to intricate reward signals derived from aesthetic predictors and CLIP embeddings, significantly enhancing image quality and enabling precise control over the generation style. Interestingly, by leveraging CLIP, our method can help VAR models generalize beyond their initial ImageNet distribution: through RL-driven exploration, these models can generate images aligned with prompts referencing image styles that were absent during pre-training. In summary, we show that RL-based fine-tuning is both efficient and effective for VAR models, benefiting particularly from their fast inference speeds, which are advantageous for online sampling, an aspect that poses significant challenges for diffusion-based alternatives.",
    "summary": "arXiv:2505.23331v2 Announce Type: replace-cross Abstract: Fine-tuning pre-trained generative models with Reinforcement Learning (RL) has emerged as an effective approach for aligning outputs more closely with nuanced human preferences. In this paper, we investigate the application of Group Relative Policy Optimization (GRPO) to fine-tune next-scale visual autoregressive (VAR) models. Our empirical results demonstrate that this approach enables alignment to intricate reward signals derived from aesthetic predictors and CLIP embeddings, significantly enhancing image quality and enabling precise control over the generation style. Interestingly, by leveraging CLIP, our method can help VAR models generalize beyond their initial ImageNet distribution: through RL-driven exploration, these models can generate images aligned with prompts referencing image styles that were absent during pre-training. In summary, we show that RL-based fine-tuning is both efficient and effective for VAR models, benefiting particularly from their fast inference speeds, which are advantageous for online sampling, an aspect that poses significant challenges for diffusion-based alternatives.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.23331",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„É™„Ç≥„Éº„ÄÅGENIAC„Åß„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„ÄÇ7Êúà„Å´ÁÑ°ÂÑüÂÖ¨Èñã",
    "description": "<p>„É™„Ç≥„Éº„ÅØ„ÄÅÁµåÊ∏àÁî£Ê•≠ÁúÅ„Åä„Çà„Å≥NEDO„ÅåÊé®ÈÄ≤„Åô„ÇãGENIAC„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Å´„Åä„ÅÑ„Å¶„ÄÅÊó•Êú¨‰ºÅÊ•≠Âêë„ÅëÂõ≥Ë°®„ÇíÂê´„ÇÄ„Éâ„Ç≠„É•„É°„É≥„ÉàË™≠„ÅøÂèñ„Çä„Å´ÁâπÂåñ„Åó„Åü„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„Åó„Åæ„Åó„Åü„ÄÇ7Êúà29Êó•ÈñãÂÇ¨„ÅÆMIRU2025„ÅßË´ñÊñáÁô∫Ë°® [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/'>„É™„Ç≥„Éº„ÄÅGENIAC„Åß„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„ÄÇ7Êúà„Å´ÁÑ°ÂÑüÂÖ¨Èñã</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>„É™„Ç≥„Éº„ÅØ„ÄÅÁµåÊ∏àÁî£Ê•≠ÁúÅ„Åä„Çà„Å≥NEDO„ÅåÊé®ÈÄ≤„Åô„ÇãGENIAC„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Å´„Åä„ÅÑ„Å¶„ÄÅÊó•Êú¨‰ºÅÊ•≠Âêë„ÅëÂõ≥Ë°®„ÇíÂê´„ÇÄ„Éâ„Ç≠„É•„É°„É≥„ÉàË™≠„ÅøÂèñ„Çä„Å´ÁâπÂåñ„Åó„Åü„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„Åó„Åæ„Åó„Åü„ÄÇ7Êúà29Êó•ÈñãÂÇ¨„ÅÆMIRU2025„ÅßË´ñÊñáÁô∫Ë°® [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/'>„É™„Ç≥„Éº„ÄÅGENIAC„Åß„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„ÄÇ7Êúà„Å´ÁÑ°ÂÑüÂÖ¨Èñã</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Tue, 24 Jun 2025 07:52:10 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/ricoh-genia-multimodal-llm.png"
  },
  {
    "title": "Latent Factorization of Tensors with Threshold Distance Weighted Loss for Traffic Data Estimation",
    "description": "arXiv:2506.22441v1 Announce Type: cross Abstract: Intelligent transportation systems (ITS) rely heavily on complete and high-quality spatiotemporal traffic data to achieve optimal performance. Nevertheless, in real-word traffic data collection processes, issues such as communication failures and sensor malfunctions often lead to incomplete or corrupted datasets, thereby posing significant challenges to the advancement of ITS. Among various methods for imputing missing spatiotemporal traffic data, the latent factorization of tensors (LFT) model has emerged as a widely adopted and effective solution. However, conventional LFT models typically employ the standard L2-norm in their learning objective, which makes them vulnerable to the influence of outliers. To overcome this limitation, this paper proposes a threshold distance weighted (TDW) loss-incorporated Latent Factorization of Tensors (TDWLFT) model. The proposed loss function effectively reduces the model's sensitivity to outliers by assigning differentiated weights to individual samples. Extensive experiments conducted on two traffic speed datasets sourced from diverse urban environments confirm that the proposed TDWLFT model consistently outperforms state-of-the-art approaches in terms of both in both prediction accuracy and computational efficiency.",
    "summary": "arXiv:2506.22441v1 Announce Type: cross Abstract: Intelligent transportation systems (ITS) rely heavily on complete and high-quality spatiotemporal traffic data to achieve optimal performance. Nevertheless, in real-word traffic data collection processes, issues such as communication failures and sensor malfunctions often lead to incomplete or corrupted datasets, thereby posing significant challenges to the advancement of ITS. Among various methods for imputing missing spatiotemporal traffic data, the latent factorization of tensors (LFT) model has emerged as a widely adopted and effective solution. However, conventional LFT models typically employ the standard L2-norm in their learning objective, which makes them vulnerable to the influence of outliers. To overcome this limitation, this paper proposes a threshold distance weighted (TDW) loss-incorporated Latent Factorization of Tensors (TDWLFT) model. The proposed loss function effectively reduces the model's sensitivity to outliers by assigning differentiated weights to individual samples. Extensive experiments conducted on two traffic speed datasets sourced from diverse urban environments confirm that the proposed TDWLFT model consistently outperforms state-of-the-art approaches in terms of both in both prediction accuracy and computational efficiency.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22441",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Machine Learning Experts - Sasha Luccioni Interview",
    "description": "",
    "summary": "Machine Learning Experts - Sasha Luccioni ü§ó Welcome to Machine Learning Experts - Sasha Luccioni üöÄ I...",
    "pubDate": "Tue, 17 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sasha-luccioni-interview",
    "thumbnail": "https://huggingface.co/blog/assets/69_sasha_luccioni_interview/thumbnail.png"
  },
  {
    "title": "Scenario-Based Hierarchical Reinforcement Learning for Automated Driving Decision Making",
    "description": "arXiv:2506.23023v1 Announce Type: cross Abstract: Developing decision-making algorithms for highly automated driving systems remains challenging, since these systems have to operate safely in an open and complex environments. Reinforcement Learning (RL) approaches can learn comprehensive decision policies directly from experience and already show promising results in simple driving tasks. However, current approaches fail to achieve generalizability for more complex driving tasks and lack learning efficiency. Therefore, we present Scenario-based Automated Driving Reinforcement Learning (SAD-RL), the first framework that integrates Reinforcement Learning (RL) of hierarchical policy in a scenario-based environment. A high-level policy selects maneuver templates that are evaluated and executed by a low-level control logic. The scenario-based environment allows to control the training experience for the agent and to explicitly introduce challenging, but rate situations into the training process. Our experiments show that an agent trained using the SAD-RL framework can achieve safe behaviour in easy as well as challenging situations efficiently. Our ablation studies confirmed that both HRL and scenario diversity are essential for achieving these results.",
    "summary": "arXiv:2506.23023v1 Announce Type: cross Abstract: Developing decision-making algorithms for highly automated driving systems remains challenging, since these systems have to operate safely in an open and complex environments. Reinforcement Learning (RL) approaches can learn comprehensive decision policies directly from experience and already show promising results in simple driving tasks. However, current approaches fail to achieve generalizability for more complex driving tasks and lack learning efficiency. Therefore, we present Scenario-based Automated Driving Reinforcement Learning (SAD-RL), the first framework that integrates Reinforcement Learning (RL) of hierarchical policy in a scenario-based environment. A high-level policy selects maneuver templates that are evaluated and executed by a low-level control logic. The scenario-based environment allows to control the training experience for the agent and to explicitly introduce challenging, but rate situations into the training process. Our experiments show that an agent trained using the SAD-RL framework can achieve safe behaviour in easy as well as challenging situations efficiently. Our ablation studies confirmed that both HRL and scenario diversity are essential for achieving these results.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23023",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome, Gradio 5",
    "description": "",
    "summary": "Welcome, Gradio 5 We‚Äôve been hard at work over the past few months, and we are excited to now announ...",
    "pubDate": "Wed, 09 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-5",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-5/thumbnail.png"
  },
  {
    "title": "Hear a podcast discussion about Gemini‚Äôs coding capabilities.",
    "description": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-600x600.format-webp.webp' />The latest episode of the Google AI: Release Notes podcast focuses on how the Gemini team built one of the world‚Äôs leading AI coding models.Host Logan Kilpatrick chats w‚Ä¶",
    "summary": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-600x600.format-webp.webp' />The latest episode of the Google AI: Release Notes podcast focuses on how the Gemini team built one of the world‚Äôs leading AI coding models.Host Logan Kilpatrick chats w‚Ä¶",
    "pubDate": "Wed, 18 Jun 2025 10:28:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/gemini/gemini-coding-podcast/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-1440x810.png"
  },
  {
    "title": "Using GPT-4 to improve teaching and learning in Brazil",
    "description": "Improving teaching and learning in Brazil",
    "summary": "Improving teaching and learning in Brazil",
    "pubDate": "Tue, 17 Sep 2024 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/arco-education",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "2023, year of open LLMs",
    "description": "",
    "summary": "2023, year of open LLMs 2023 has seen a surge of public interest in Large Language Models (LLMs), an...",
    "pubDate": "Mon, 18 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/2023-in-llms",
    "thumbnail": "https://huggingface.co/blog/assets/cv_state/thumbnail.png"
  },
  {
    "title": "How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?",
    "description": "arXiv:2506.20199v2 Announce Type: replace-cross Abstract: Large language models (LLMs) have enabled a wide variety of real-world applications in various domains. However, creating a high-performing application with high accuracy remains challenging, particularly for subjective tasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this study investigates approaches to improving conversational emotion recognition (CER) by LLMs. Specifically, we explore how to retrieve high-quality examples in in-context learning (ICL) to enhance CER. We propose various strategies based on random and augmented example retrieval and also analyze the impact of conversational context on CER accuracy. Experiments were conducted on the three datasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented example retrieval consistently outperforms other techniques under investigation across all datasets, highlighting the importance of retrieving coherent targeted examples and enhancing them through paraphrasing.",
    "summary": "arXiv:2506.20199v2 Announce Type: replace-cross Abstract: Large language models (LLMs) have enabled a wide variety of real-world applications in various domains. However, creating a high-performing application with high accuracy remains challenging, particularly for subjective tasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this study investigates approaches to improving conversational emotion recognition (CER) by LLMs. Specifically, we explore how to retrieve high-quality examples in in-context learning (ICL) to enhance CER. We propose various strategies based on random and augmented example retrieval and also analyze the impact of conversational context on CER accuracy. Experiments were conducted on the three datasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented example retrieval consistently outperforms other techniques under investigation across all datasets, highlighting the importance of retrieving coherent targeted examples and enhancing them through paraphrasing.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.20199",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Value-Free Policy Optimization via Reward Partitioning",
    "description": "arXiv:2506.13702v2 Announce Type: replace-cross Abstract: Single-trajectory reinforcement learning (RL) methods aim to optimize policies from datasets consisting of (prompt, response, reward) triplets, where scalar rewards are directly available. This supervision format is highly practical, as it mirrors real-world human feedback, such as thumbs-up/down signals, and avoids the need for structured preference annotations. In contrast, pairwise preference-based methods like Direct Preference Optimization (DPO) rely on datasets with both preferred and dispreferred responses, which are harder to construct and less natural to collect. Among single-trajectory approaches, Direct Reward Optimization (DRO) has shown strong empirical performance due to its simplicity and stability. However, DRO requires approximating a value function, which introduces several limitations: high off-policy variance, coupling between policy and value learning, and a lack of absolute supervision on the policy itself. We introduce Reward Partitioning Optimization (RPO), a new method that resolves these limitations by removing the need to model the value function. Instead, RPO normalizes observed rewards using a partitioning approach estimated directly from data. This leads to a straightforward supervised learning objective on the policy, with no auxiliary models and no joint optimization. RPO provides direct and stable supervision on the policy, making it robust and easy to implement in practice. We validate RPO on scalar-feedback language modeling tasks using Flan-T5 encoder-decoder models. Our results demonstrate that RPO outperforms existing single-trajectory baselines such as DRO and Kahneman-Tversky Optimization (KTO). These findings confirm that RPO is a simple, effective, and theoretically grounded method for single-trajectory policy optimization.",
    "summary": "arXiv:2506.13702v2 Announce Type: replace-cross Abstract: Single-trajectory reinforcement learning (RL) methods aim to optimize policies from datasets consisting of (prompt, response, reward) triplets, where scalar rewards are directly available. This supervision format is highly practical, as it mirrors real-world human feedback, such as thumbs-up/down signals, and avoids the need for structured preference annotations. In contrast, pairwise preference-based methods like Direct Preference Optimization (DPO) rely on datasets with both preferred and dispreferred responses, which are harder to construct and less natural to collect. Among single-trajectory approaches, Direct Reward Optimization (DRO) has shown strong empirical performance due to its simplicity and stability. However, DRO requires approximating a value function, which introduces several limitations: high off-policy variance, coupling between policy and value learning, and a lack of absolute supervision on the policy itself. We introduce Reward Partitioning Optimization (RPO), a new method that resolves these limitations by removing the need to model the value function. Instead, RPO normalizes observed rewards using a partitioning approach estimated directly from data. This leads to a straightforward supervised learning objective on the policy, with no auxiliary models and no joint optimization. RPO provides direct and stable supervision on the policy, making it robust and easy to implement in practice. We validate RPO on scalar-feedback language modeling tasks using Flan-T5 encoder-decoder models. Our results demonstrate that RPO outperforms existing single-trajectory baselines such as DRO and Kahneman-Tversky Optimization (KTO). These findings confirm that RPO is a simple, effective, and theoretically grounded method for single-trajectory policy optimization.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.13702",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Creating an AI-powered Magic Studio",
    "description": "Canva is a visual communication platform, enjoyed by more than 175 million people monthly to make presentations, videos, documents, websites, social media graphics and more. A majority of the world‚Äôs knowledge workers lack design training, but Canva‚Äôs combination of an easy-to-use interface, vast libraries, and time-saving tools allows anyone to create visually compelling content.",
    "summary": "Canva is a visual communication platform, enjoyed by more than 175 million people monthly to make presentations, videos, documents, websites, social media graphics and more. A majority of the world‚Äôs knowledge workers lack design training, but Canva‚Äôs combination of an easy-to-use interface, vast libraries, and time-saving tools allows anyone to create visually compelling content.",
    "pubDate": "Thu, 16 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/canva",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Google for Nonprofits will expand to 100+ new countries and launch 10+ new no-cost AI features",
    "description": "Collage on a white background showing people in multiple different situations including two people in suits sitting on the back of an ambulance, and an adult and child using a laptop together",
    "summary": "Collage on a white background showing people in multiple different situations including two people in suits sitting on the back of an ambulance, and an adult and child using a laptop together",
    "pubDate": "Wed, 11 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/google-org/google-nonprofits-updates-june-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GoogleforNonProfit_SS.width-1300.png"
  },
  {
    "title": "OpenAI‚Äôs technology explained",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-technology-explained",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Featherless AI on Hugging Face Inference Providers üî•",
    "description": "",
    "summary": "Featherless AI on Hugging Face Inference Providers üî• We're thrilled to share that Featherless AI is ...",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-featherless",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-featherless.jpg"
  },
  {
    "title": "quanto: a pytorch quantization toolkit",
    "description": "",
    "summary": "Quanto: a PyTorch quantization backend for Optimum Quantization is a technique to reduce the computa...",
    "pubDate": "Mon, 18 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/quanto-introduction",
    "thumbnail": "https://huggingface.co/blog/assets/169_quanto_intro/thumbnail.png"
  },
  {
    "title": "Making education data accessible",
    "description": "Zelma uses GPT-4 to make education data accessible.",
    "summary": "Zelma uses GPT-4 to make education data accessible.",
    "pubDate": "Thu, 28 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zelma",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI and compute",
    "description": "We‚Äôre releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore‚Äôs Law had a 2-year doubling period)[^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it‚Äôs worth preparing for the implications of systems far outside today‚Äôs capabilities.",
    "summary": "We‚Äôre releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore‚Äôs Law had a 2-year doubling period)[^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it‚Äôs worth preparing for the implications of systems far outside today‚Äôs capabilities.",
    "pubDate": "Wed, 16 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-and-compute",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Storage Regions on the HF Hub",
    "description": "",
    "summary": "Introducing Storage Regions on the Hub As part of our Enterprise Hub plan, we recently released supp...",
    "pubDate": "Fri, 03 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/regions",
    "thumbnail": "https://huggingface.co/blog/assets/172_regions/thumbnail.png"
  },
  {
    "title": "Better exploration with parameter noise",
    "description": "We‚Äôve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts performance. This exploration method is simple to implement and very rarely decreases performance, so it‚Äôs worth trying on any problem.",
    "summary": "We‚Äôve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts performance. This exploration method is simple to implement and very rarely decreases performance, so it‚Äôs worth trying on any problem.",
    "pubDate": "Thu, 27 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/better-exploration-with-parameter-noise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome Gemma - Google's new open LLM",
    "description": "",
    "summary": "Welcome Gemma - Google‚Äôs new open LLM An update to the Gemma models was released two months after th...",
    "pubDate": "Wed, 21 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma",
    "thumbnail": "https://huggingface.co/blog/assets/gemma/thumbnail.jpg"
  },
  {
    "title": "Introducing ChatGPT Plus",
    "description": "We‚Äôre launching a pilot subscription plan for ChatGPT, a conversational AI that can chat with you, answer follow-up questions, and challenge incorrect¬†assumptions.",
    "summary": "We‚Äôre launching a pilot subscription plan for ChatGPT, a conversational AI that can chat with you, answer follow-up questions, and challenge incorrect¬†assumptions.",
    "pubDate": "Wed, 01 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Aggregating Local Saliency Maps for Semi-Global Explainable Image Classification",
    "description": "arXiv:2506.23247v1 Announce Type: cross Abstract: Deep learning dominates image classification tasks, yet understanding how models arrive at predictions remains a challenge. Much research focuses on local explanations of individual predictions, such as saliency maps, which visualise the influence of specific pixels on a model's prediction. However, reviewing many of these explanations to identify recurring patterns is infeasible, while global methods often oversimplify and miss important local behaviours. To address this, we propose Segment Attribution Tables (SATs), a method for summarising local saliency explanations into (semi-)global insights. SATs take image segments (such as 'eyes' in Chihuahuas) and leverage saliency maps to quantify their influence. These segments highlight concepts the model relies on across instances and reveal spurious correlations, such as reliance on backgrounds or watermarks, even when out-of-distribution test performance sees little change. SATs can explain any classifier for which a form of saliency map can be produced, using segmentation maps that provide named segments. SATs bridge the gap between oversimplified global summaries and overly detailed local explanations, offering a practical tool for analysing and debugging image classifiers.",
    "summary": "arXiv:2506.23247v1 Announce Type: cross Abstract: Deep learning dominates image classification tasks, yet understanding how models arrive at predictions remains a challenge. Much research focuses on local explanations of individual predictions, such as saliency maps, which visualise the influence of specific pixels on a model's prediction. However, reviewing many of these explanations to identify recurring patterns is infeasible, while global methods often oversimplify and miss important local behaviours. To address this, we propose Segment Attribution Tables (SATs), a method for summarising local saliency explanations into (semi-)global insights. SATs take image segments (such as 'eyes' in Chihuahuas) and leverage saliency maps to quantify their influence. These segments highlight concepts the model relies on across instances and reveal spurious correlations, such as reliance on backgrounds or watermarks, even when out-of-distribution test performance sees little change. SATs can explain any classifier for which a form of saliency map can be produced, using segmentation maps that provide named segments. SATs bridge the gap between oversimplified global summaries and overly detailed local explanations, offering a practical tool for analysing and debugging image classifiers.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23247",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Inference for PROs",
    "description": "",
    "summary": "Inference for PROs Today, we're introducing Inference for PRO users - a community offering that give...",
    "pubDate": "Fri, 22 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-pro",
    "thumbnail": "https://huggingface.co/blog/assets/inference_pro/thumbnail.png"
  },
  {
    "title": "Photonic processor could streamline 6G wireless signal processing",
    "description": "By performing deep learning at the speed of light, this chip could give edge devices new capabilities for real-time data analysis.",
    "summary": "By performing deep learning at the speed of light, this chip could give edge devices new capabilities for real-time data analysis.",
    "pubDate": "Wed, 11 Jun 2025 14:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/photonic-processor-could-streamline-6g-wireless-signal-processing-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Photonic-Process-01-press.jpg"
  },
  {
    "title": "Introducing OpenAI Dublin",
    "description": "We‚Äôre growing our presence in Europe with an office in Dublin, Ireland.",
    "summary": "We‚Äôre growing our presence in Europe with an office in Dublin, Ireland.",
    "pubDate": "Wed, 13 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-dublin",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Prover-Verifier Games improve legibility of language model outputs",
    "description": "desc",
    "summary": "desc",
    "pubDate": "Wed, 17 Jul 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/prover-verifier-games-improve-legibility",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Policy Gradient with PyTorch",
    "description": "",
    "summary": "Policy Gradient with PyTorch Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 5, of the‚ö†Ô∏è ...",
    "pubDate": "Thu, 30 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-pg",
    "thumbnail": "https://huggingface.co/blog/assets/85_policy_gradient/thumbnail.gif"
  },
  {
    "title": "Introducing the Open FinLLM Leaderboard",
    "description": "",
    "summary": "Introducing the Open FinLLM Leaderboard Finding the best LLM models for finance use cases The growin...",
    "pubDate": "Fri, 04 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-finbench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_finbench.png"
  },
  {
    "title": "HalCECE: A Framework for Explainable Hallucination Detection through Conceptual Counterfactuals in Image Captioning",
    "description": "arXiv:2503.00436v2 Announce Type: replace-cross Abstract: In the dynamic landscape of artificial intelligence, the exploration of hallucinations within vision-language (VL) models emerges as a critical frontier. This work delves into the intricacies of hallucinatory phenomena exhibited by widely used image captioners, unraveling interesting patterns. Specifically, we step upon previously introduced techniques of conceptual counterfactual explanations to address VL hallucinations. The deterministic and efficient nature of the employed conceptual counterfactuals backbone is able to suggest semantically minimal edits driven by hierarchical knowledge, so that the transition from a hallucinated caption to a non-hallucinated one is performed in a black-box manner. HalCECE, our proposed hallucination detection framework is highly interpretable, by providing semantically meaningful edits apart from standalone numbers, while the hierarchical decomposition of hallucinated concepts leads to a thorough hallucination analysis. Another novelty tied to the current work is the investigation of role hallucinations, being one of the first works to involve interconnections between visual concepts in hallucination detection. Overall, HalCECE recommends an explainable direction to the crucial field of VL hallucination detection, thus fostering trustworthy evaluation of current and future VL systems.",
    "summary": "arXiv:2503.00436v2 Announce Type: replace-cross Abstract: In the dynamic landscape of artificial intelligence, the exploration of hallucinations within vision-language (VL) models emerges as a critical frontier. This work delves into the intricacies of hallucinatory phenomena exhibited by widely used image captioners, unraveling interesting patterns. Specifically, we step upon previously introduced techniques of conceptual counterfactual explanations to address VL hallucinations. The deterministic and efficient nature of the employed conceptual counterfactuals backbone is able to suggest semantically minimal edits driven by hierarchical knowledge, so that the transition from a hallucinated caption to a non-hallucinated one is performed in a black-box manner. HalCECE, our proposed hallucination detection framework is highly interpretable, by providing semantically meaningful edits apart from standalone numbers, while the hierarchical decomposition of hallucinated concepts leads to a thorough hallucination analysis. Another novelty tied to the current work is the investigation of role hallucinations, being one of the first works to involve interconnections between visual concepts in hallucination detection. Overall, HalCECE recommends an explainable direction to the crucial field of VL hallucination detection, thus fostering trustworthy evaluation of current and future VL systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.00436",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Open Medical-LLM Leaderboard: Benchmarking Large Language Models in Healthcare",
    "description": "",
    "summary": "The Open Medical-LLM Leaderboard: Benchmarking Large Language Models in Healthcare Over the years, L...",
    "pubDate": "Fri, 19 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-medicalllm",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_medicalllm.png"
  },
  {
    "title": "How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?",
    "description": "arXiv:2506.22501v1 Announce Type: cross Abstract: Remote sensing datasets offer significant promise for tackling key classification tasks such as land-use categorization, object presence detection, and rural/urban classification. However, many existing studies tend to focus on narrow tasks or datasets, which limits their ability to generalize across various remote sensing classification challenges. To overcome this, we propose a novel model, SpatialNet-ViT, leveraging the power of Vision Transformers (ViTs) and Multi-Task Learning (MTL). This integrated approach combines spatial awareness with contextual understanding, improving both classification accuracy and scalability. Additionally, techniques like data augmentation, transfer learning, and multi-task learning are employed to enhance model robustness and its ability to generalize across diverse datasets",
    "summary": "arXiv:2506.22501v1 Announce Type: cross Abstract: Remote sensing datasets offer significant promise for tackling key classification tasks such as land-use categorization, object presence detection, and rural/urban classification. However, many existing studies tend to focus on narrow tasks or datasets, which limits their ability to generalize across various remote sensing classification challenges. To overcome this, we propose a novel model, SpatialNet-ViT, leveraging the power of Vision Transformers (ViTs) and Multi-Task Learning (MTL). This integrated approach combines spatial awareness with contextual understanding, improving both classification accuracy and scalability. Additionally, techniques like data augmentation, transfer learning, and multi-task learning are employed to enhance model robustness and its ability to generalize across diverse datasets",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22501",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using Machine Learning to Aid Survivors and Race through Time",
    "description": "",
    "summary": "Using Machine Learning to Aid Survivors and Race through Time On February 6, 2023, earthquakes measu...",
    "pubDate": "Fri, 03 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/using-ml-for-disasters",
    "thumbnail": "https://huggingface.co/blog/assets/using-ml-for-disasters/thumbnail.png"
  },
  {
    "title": "Correlated Mutations for Integer Programming",
    "description": "arXiv:2506.22526v1 Announce Type: cross Abstract: Even with the recent theoretical advancements that dramatically reduced the complexity of Integer Programming (IP), heuristics remain the dominant problem-solvers for this difficult category. This study seeks to establish the groundwork for Integer Evolution Strategies (IESs), a class of randomized search heuristics inherently designed for continuous spaces. IESs already excel in treating IP in practice, but accomplish it via discretization and by applying sophisticated patches to their continuous operators, while persistently using the $ell_2$-norm as their operation pillar. We lay foundations for discrete search, by adopting the $ell_1$-norm, accounting for the suitable step-size, and questioning alternative measures to quantify correlations over the integer lattice. We focus on mutation distributions for unbounded integer decision variables. We briefly discuss a couple of candidate discrete probabilities induced by the uniform and binomial distributions, which we show to possess less appealing theoretical properties, and then narrow down to the Truncated Normal (TN) and Double Geometric (DG) distributions. We explore their theoretical properties, including entropy functions, and propose a procedure to generate scalable correlated mutation distributions. Our investigations are accompanied by extensive numerical simulations, which consistently support the claim that the DG distribution is better suited for unbounded integer search. We link our theoretical perspective to empirical evidence indicating that an IES with correlated DG mutations outperformed other strategies over non-separable quadratic IP. We conclude that while the replacement of the default TN distribution by the DG is theoretically justified and practically beneficial, the truly crucial change lies in adopting the $ell_1$-norm over the $ell_2$-norm.",
    "summary": "arXiv:2506.22526v1 Announce Type: cross Abstract: Even with the recent theoretical advancements that dramatically reduced the complexity of Integer Programming (IP), heuristics remain the dominant problem-solvers for this difficult category. This study seeks to establish the groundwork for Integer Evolution Strategies (IESs), a class of randomized search heuristics inherently designed for continuous spaces. IESs already excel in treating IP in practice, but accomplish it via discretization and by applying sophisticated patches to their continuous operators, while persistently using the $ell_2$-norm as their operation pillar. We lay foundations for discrete search, by adopting the $ell_1$-norm, accounting for the suitable step-size, and questioning alternative measures to quantify correlations over the integer lattice. We focus on mutation distributions for unbounded integer decision variables. We briefly discuss a couple of candidate discrete probabilities induced by the uniform and binomial distributions, which we show to possess less appealing theoretical properties, and then narrow down to the Truncated Normal (TN) and Double Geometric (DG) distributions. We explore their theoretical properties, including entropy functions, and propose a procedure to generate scalable correlated mutation distributions. Our investigations are accompanied by extensive numerical simulations, which consistently support the claim that the DG distribution is better suited for unbounded integer search. We link our theoretical perspective to empirical evidence indicating that an IES with correlated DG mutations outperformed other strategies over non-separable quadratic IP. We conclude that while the replacement of the default TN distribution by the DG is theoretically justified and practically beneficial, the truly crucial change lies in adopting the $ell_1$-norm over the $ell_2$-norm.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22526",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM",
    "description": "arXiv:2506.23504v1 Announce Type: new Abstract: The recent development of advanced machine learning methods for hybrid models has greatly addressed the need for the correct prediction of electrical prices. This method combines AlexNet and LSTM algorithms, which are used to introduce a new model with higher accuracy in price forecasting. Despite RNN and ANN being effective, they often fail to deal with forex time sequence data. The traditional methods do not accurately forecast the prices. These traditional methods only focus on demand and price which leads to insufficient analysis of data. To address this issue, using the hybrid approach, which focuses on external variables that also effect the predicted prices. Nevertheless, due to AlexNet's excellent feature extraction and LSTM's learning sequential patterns, the prediction accuracy is vastly increased. The model is built on the past data, which has been supplied with the most significant elements like demand, temperature, sunlight, and rain. For example, the model applies methods, such as minimum-maximum scaling and a time window, to predict the electricity prices of the future. The results show that this hybrid model is good than the standalone ones in terms of accuracy. Although we got our accuracy rating of 97.08, it shows higher accompaniments than remaining models RNN and ANN with accuracies of 96.64 and 96.63 respectively.",
    "summary": "arXiv:2506.23504v1 Announce Type: new Abstract: The recent development of advanced machine learning methods for hybrid models has greatly addressed the need for the correct prediction of electrical prices. This method combines AlexNet and LSTM algorithms, which are used to introduce a new model with higher accuracy in price forecasting. Despite RNN and ANN being effective, they often fail to deal with forex time sequence data. The traditional methods do not accurately forecast the prices. These traditional methods only focus on demand and price which leads to insufficient analysis of data. To address this issue, using the hybrid approach, which focuses on external variables that also effect the predicted prices. Nevertheless, due to AlexNet's excellent feature extraction and LSTM's learning sequential patterns, the prediction accuracy is vastly increased. The model is built on the past data, which has been supplied with the most significant elements like demand, temperature, sunlight, and rain. For example, the model applies methods, such as minimum-maximum scaling and a time window, to predict the electricity prices of the future. The results show that this hybrid model is good than the standalone ones in terms of accuracy. Although we got our accuracy rating of 97.08, it shows higher accompaniments than remaining models RNN and ANN with accuracies of 96.64 and 96.63 respectively.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23504",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DALL¬∑E: Introducing outpainting",
    "description": "Extend creativity and tell a bigger story with DALL¬∑E images of any¬†size.",
    "summary": "Extend creativity and tell a bigger story with DALL¬∑E images of any¬†size.",
    "pubDate": "Wed, 31 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-introducing-outpainting",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Federated Learning using Hugging Face and Flower",
    "description": "",
    "summary": "Federated Learning using Hugging Face and Flower This tutorial will show how to leverage Hugging Fac...",
    "pubDate": "Mon, 27 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fl-with-flower",
    "thumbnail": "https://huggingface.co/blog/assets/fl-with-flower/thumbnail.png"
  },
  {
    "title": "Teacher‚Äìstudent curriculum learning",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 01 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teacher-student-curriculum-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pok'eAI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red",
    "description": "arXiv:2506.23689v1 Announce Type: new Abstract: We introduce Pok'eAI, the first text-based, multi-agent large language model (LLM) framework designed to autonomously play and progress through Pok'emon Red. Our system consists of three specialized agents-Planning, Execution, and Critique-each with its own memory bank, role, and skill set. The Planning Agent functions as the central brain, generating tasks to progress through the game. These tasks are then delegated to the Execution Agent, which carries them out within the game environment. Upon task completion, the Critique Agent evaluates the outcome to determine whether the objective was successfully achieved. Once verification is complete, control returns to the Planning Agent, forming a closed-loop decision-making system. As a preliminary step, we developed a battle module within the Execution Agent. Our results show that the battle AI achieves an average win rate of 80.8% across 50 wild encounters, only 6% lower than the performance of an experienced human player. Furthermore, we find that a model's battle performance correlates strongly with its LLM Arena score on language-related tasks, indicating a meaningful link between linguistic ability and strategic reasoning. Finally, our analysis of gameplay logs reveals that each LLM exhibits a unique playstyle, suggesting that individual models develop distinct strategic behaviors.",
    "summary": "arXiv:2506.23689v1 Announce Type: new Abstract: We introduce Pok'eAI, the first text-based, multi-agent large language model (LLM) framework designed to autonomously play and progress through Pok'emon Red. Our system consists of three specialized agents-Planning, Execution, and Critique-each with its own memory bank, role, and skill set. The Planning Agent functions as the central brain, generating tasks to progress through the game. These tasks are then delegated to the Execution Agent, which carries them out within the game environment. Upon task completion, the Critique Agent evaluates the outcome to determine whether the objective was successfully achieved. Once verification is complete, control returns to the Planning Agent, forming a closed-loop decision-making system. As a preliminary step, we developed a battle module within the Execution Agent. Our results show that the battle AI achieves an average win rate of 80.8% across 50 wild encounters, only 6% lower than the performance of an experienced human player. Furthermore, we find that a model's battle performance correlates strongly with its LLM Arena score on language-related tasks, indicating a meaningful link between linguistic ability and strategic reasoning. Finally, our analysis of gameplay logs reveals that each LLM exhibits a unique playstyle, suggesting that individual models develop distinct strategic behaviors.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23689",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Enough Coin Flips Can Make LLMs Act Bayesian",
    "description": "arXiv:2503.04722v2 Announce Type: replace-cross Abstract: Large language models (LLMs) exhibit the ability to generalize given few-shot examples in their input prompt, an emergent capability known as in-context learning (ICL). We investigate whether LLMs use ICL to perform structured reasoning in ways that are consistent with a Bayesian framework or rely on pattern matching. Using a controlled setting of biased coin flips, we find that: (1) LLMs often possess biased priors, causing initial divergence in zero-shot settings, (2) in-context evidence outweighs explicit bias instructions, (3) LLMs broadly follow Bayesian posterior updates, with deviations primarily due to miscalibrated priors rather than flawed updates, and (4) attention magnitude has negligible effect on Bayesian inference. With sufficient demonstrations of biased coin flips via ICL, LLMs update their priors in a Bayesian manner.",
    "summary": "arXiv:2503.04722v2 Announce Type: replace-cross Abstract: Large language models (LLMs) exhibit the ability to generalize given few-shot examples in their input prompt, an emergent capability known as in-context learning (ICL). We investigate whether LLMs use ICL to perform structured reasoning in ways that are consistent with a Bayesian framework or rely on pattern matching. Using a controlled setting of biased coin flips, we find that: (1) LLMs often possess biased priors, causing initial divergence in zero-shot settings, (2) in-context evidence outweighs explicit bias instructions, (3) LLMs broadly follow Bayesian posterior updates, with deviations primarily due to miscalibrated priors rather than flawed updates, and (4) attention magnitude has negligible effect on Bayesian inference. With sufficient demonstrations of biased coin flips via ICL, LLMs update their priors in a Bayesian manner.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.04722",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Visualize proteins on Hugging Face Spaces",
    "description": "",
    "summary": "Visualize proteins on Hugging Face Spaces In this post we will look at how we can visualize proteins...",
    "pubDate": "Wed, 24 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spaces_3dmoljs",
    "thumbnail": "https://huggingface.co/blog/assets/98_spaces_3dmoljs/thumbnail.png"
  },
  {
    "title": "Director of Machine Learning Insights [Part 2: SaaS Edition]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 2: SaaS Edition] If you or your team are interested in b...",
    "pubDate": "Fri, 13 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-2",
    "thumbnail": "https://huggingface.co/blog/assets/67_ml_director_insights/thumbnail.png"
  },
  {
    "title": "HuggingFace, IISc partner to supercharge model building on India's diverse languages",
    "description": "",
    "summary": "HuggingFace, IISc partner to supercharge model building on India's diverse languages The Indian Inst...",
    "pubDate": "Thu, 27 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/iisc-huggingface-collab",
    "thumbnail": "https://huggingface.co/blog/assets/iisc-huggingface-collab/thumbnail.png"
  },
  {
    "title": "Language models can explain neurons in language models",
    "description": "We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to score those explanations. We release a dataset of these (imperfect) explanations and scores for every neuron in GPT-2.",
    "summary": "We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to score those explanations. We release a dataset of these (imperfect) explanations and scores for every neuron in GPT-2.",
    "pubDate": "Tue, 09 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-models-can-explain-neurons-in-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making AI models more trustworthy for high-stakes settings",
    "description": "A new method helps convey uncertainty more precisely, which could give researchers and medical clinicians better information to make decisions.",
    "summary": "A new method helps convey uncertainty more precisely, which could give researchers and medical clinicians better information to make decisions.",
    "pubDate": "Thu, 01 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/making-ai-models-more-trustworthy-high-stakes-settings-0501",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Conformal-Prediction-01.jpg"
  },
  {
    "title": "OpenAI Deutschland",
    "description": "OpenAI announces the opening of its first office in Germany, based in Munich.",
    "summary": "OpenAI announces the opening of its first office in Germany, based in Munich.",
    "pubDate": "Thu, 22 May 2025 23:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-deutschland",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling Self-Supervised Representation Learning for Symbolic Piano Performance",
    "description": "arXiv:2506.23869v1 Announce Type: cross Abstract: We study the capabilities of generative autoregressive transformer models trained on large amounts of symbolic solo-piano transcriptions. After first pretraining on approximately 60,000 hours of music, we use a comparatively smaller, high-quality subset, to finetune models to produce musical continuations, perform symbolic classification tasks, and produce general-purpose contrastive MIDI embeddings by adapting the SimCLR framework to symbolic music. When evaluating piano continuation coherence, our generative model outperforms leading symbolic generation techniques and remains competitive with proprietary audio generation models. On MIR classification benchmarks, frozen representations from our contrastive model achieve state-of-the-art results in linear probe experiments, while direct finetuning demonstrates the generalizability of pretrained representations, often requiring only a few hundred labeled examples to specialize to downstream tasks.",
    "summary": "arXiv:2506.23869v1 Announce Type: cross Abstract: We study the capabilities of generative autoregressive transformer models trained on large amounts of symbolic solo-piano transcriptions. After first pretraining on approximately 60,000 hours of music, we use a comparatively smaller, high-quality subset, to finetune models to produce musical continuations, perform symbolic classification tasks, and produce general-purpose contrastive MIDI embeddings by adapting the SimCLR framework to symbolic music. When evaluating piano continuation coherence, our generative model outperforms leading symbolic generation techniques and remains competitive with proprietary audio generation models. On MIR classification benchmarks, frozen representations from our contrastive model achieve state-of-the-art results in linear probe experiments, while direct finetuning demonstrates the generalizability of pretrained representations, often requiring only a few hundred labeled examples to specialize to downstream tasks.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23869",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Knowledge-Guided Multi-Agent Framework for Automated Requirements Development: A Vision",
    "description": "arXiv:2506.22656v1 Announce Type: cross Abstract: This paper envisions a knowledge-guided multi-agent framework named KGMAF for automated requirements development. KGMAF aims to address gaps in current automation systems for SE, which prioritize code development and overlook the complexities of requirements tasks. KGMAF is composed of six specialized agents and an artifact pool to improve efficiency and accuracy. Specifically, KGMAF outlines the functionality, actions, and knowledge of each agent and provides the conceptual design of the artifact pool. Our case study highlights the potential of KGMAF in real-world scenarios. Finally, we outline several research opportunities for implementing and enhancing automated requirements development using multi-agent systems. We believe that KGMAF will play a pivotal role in shaping the future of automated requirements development in the era of LLMs.",
    "summary": "arXiv:2506.22656v1 Announce Type: cross Abstract: This paper envisions a knowledge-guided multi-agent framework named KGMAF for automated requirements development. KGMAF aims to address gaps in current automation systems for SE, which prioritize code development and overlook the complexities of requirements tasks. KGMAF is composed of six specialized agents and an artifact pool to improve efficiency and accuracy. Specifically, KGMAF outlines the functionality, actions, and knowledge of each agent and provides the conceptual design of the artifact pool. Our case study highlights the potential of KGMAF in real-world scenarios. Finally, we outline several research opportunities for implementing and enhancing automated requirements development using multi-agent systems. We believe that KGMAF will play a pivotal role in shaping the future of automated requirements development in the era of LLMs.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22656",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "We now support VLMs in smolagents!",
    "description": "",
    "summary": "We just gave sight to smolagents You hypocrite, first take the log out of your own eye, and then you...",
    "pubDate": "Fri, 24 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents-can-see",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents-can-see/thumbnail.png"
  },
  {
    "title": "SQUASH: A SWAP-Based Quantum Attack to Sabotage Hybrid Quantum Neural Networks",
    "description": "arXiv:2506.24081v1 Announce Type: cross Abstract: We propose a circuit-level attack, SQUASH, a SWAP-Based Quantum Attack to sabotage Hybrid Quantum Neural Networks (HQNNs) for classification tasks. SQUASH is executed by inserting SWAP gate(s) into the variational quantum circuit of the victim HQNN. Unlike conventional noise-based or adversarial input attacks, SQUASH directly manipulates the circuit structure, leading to qubit misalignment and disrupting quantum state evolution. This attack is highly stealthy, as it does not require access to training data or introduce detectable perturbations in input states. Our results demonstrate that SQUASH significantly degrades classification performance, with untargeted SWAP attacks reducing accuracy by up to 74.08% and targeted SWAP attacks reducing target class accuracy by up to 79.78%. These findings reveal a critical vulnerability in HQNN implementations, underscoring the need for more resilient architectures against circuit-level adversarial interventions.",
    "summary": "arXiv:2506.24081v1 Announce Type: cross Abstract: We propose a circuit-level attack, SQUASH, a SWAP-Based Quantum Attack to sabotage Hybrid Quantum Neural Networks (HQNNs) for classification tasks. SQUASH is executed by inserting SWAP gate(s) into the variational quantum circuit of the victim HQNN. Unlike conventional noise-based or adversarial input attacks, SQUASH directly manipulates the circuit structure, leading to qubit misalignment and disrupting quantum state evolution. This attack is highly stealthy, as it does not require access to training data or introduce detectable perturbations in input states. Our results demonstrate that SQUASH significantly degrades classification performance, with untargeted SWAP attacks reducing accuracy by up to 74.08% and targeted SWAP attacks reducing target class accuracy by up to 79.78%. These findings reveal a critical vulnerability in HQNN implementations, underscoring the need for more resilient architectures against circuit-level adversarial interventions.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.24081",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evolution through large models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolution-through-large-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TruthfulQA: Measuring how models mimic human falsehoods",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/truthfulqa",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-tuning LLMs to 1.58bit: extreme quantization made easy",
    "description": "",
    "summary": "Fine-tuning LLMs to 1.58bit: extreme quantization made easy As Large Language Models (LLMs) grow in ...",
    "pubDate": "Wed, 18 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/1_58_llm_extreme_quantization",
    "thumbnail": "https://huggingface.co/blog/assets/1_58_llm_extreme_quantization/thumbnail.png"
  },
  {
    "title": "Transforming visual accessibility",
    "description": "Be My Eyes uses GPT-4 to transform visual accessibility.",
    "summary": "Be My Eyes uses GPT-4 to transform visual accessibility.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/be-my-eyes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Lowe‚Äôs puts project expertise into every hand",
    "description": "Lowe‚Äôs partnered with OpenAI to build Mylow and Mylow Companion, AI-powered tools that bring expert help to both customers and store associates‚Äîmaking complex home improvement projects easier to plan, navigate, and complete.",
    "summary": "Lowe‚Äôs partnered with OpenAI to build Mylow and Mylow Companion, AI-powered tools that bring expert help to both customers and store associates‚Äîmaking complex home improvement projects easier to plan, navigate, and complete.",
    "pubDate": "Wed, 07 May 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lowes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "StarCoder: A State-of-the-Art LLM for Code",
    "description": "",
    "summary": "StarCoder: A State-of-the-Art LLM for Code Introducing StarCoder StarCoder and StarCoderBase are Lar...",
    "pubDate": "Thu, 04 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starcoder",
    "thumbnail": "https://huggingface.co/blog/assets/141_starcoder/starcoder_thumbnail.png"
  },
  {
    "title": "The ethics of advanced AI assistants",
    "description": "Exploring the promise and risks of a future with more capable AI",
    "summary": "Exploring the promise and risks of a future with more capable AI",
    "pubDate": "Fri, 19 Apr 2024 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/the-ethics-of-advanced-ai-assistants/",
    "thumbnail": "https://lh3.googleusercontent.com/28MrwSZMny-Gf_FVYJS0z3JbnfLXzRLNAF2BA0YQ7rbcrZWdNNwddfFsWVh_n7C31N8oXBmWexFbyce4jzaX3FSNt3EXG6mSLSlXaSx70Mc7Q0s7FF4=w1200-h630-n-nu"
  },
  {
    "title": "1,000 Scientist AI Jam Session",
    "description": "OpenAI and nine national labs bring together leading scientists for first-of-its kind event.",
    "summary": "OpenAI and nine national labs bring together leading scientists for first-of-its kind event.",
    "pubDate": "Fri, 28 Feb 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/1000-scientist-ai-jam-session",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How ü§ó Accelerate runs very large models thanks to PyTorch",
    "description": "",
    "summary": "How ü§ó Accelerate runs very large models thanks to PyTorch Load and run large models Meta AI and BigS...",
    "pubDate": "Tue, 27 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-large-models",
    "thumbnail": "https://huggingface.co/blog/assets/104_accelerate-large-models/thumbnail.png"
  },
  {
    "title": "Accelerating Protein Language Model ProtST on Intel Gaudi 2",
    "description": "",
    "summary": "Accelerating Protein Language Model ProtST on Intel Gaudi 2 Introduction Protein Language Models (PL...",
    "pubDate": "Wed, 03 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-protein-language-model-protst",
    "thumbnail": "https://huggingface.co/blog/assets/intel-protein-language-model-protst/01.jpeg"
  },
  {
    "title": "„Äå„É¢„Éº„É†„É™„ÄçÈÅãÂñ∂„ÄÅ‚ÄúÈÉ®‰∏ã„Å´Ëæû„ÇÅ„Çâ„Çå„Å™„ÅÑ‰ºù„ÅàÊñπ‚ÄùÊîØÊè¥„ÄÄ3‰∏á‰∫∫Ë∂Ö„ÅÆ„ÄåÈÄÄËÅ∑Áõ∏Ë´á„ÄçÂ≠¶Áøí„Åó„ÅüAI„ÉÑ„Éº„É´Êèê‰æõ",
    "description": "ÈÄÄËÅ∑‰ª£Ë°å„Çµ„Éº„Éì„Çπ„Äå„É¢„Éº„É†„É™„Äç„Å™„Å©„ÇíÊâãÊéõ„Åë„Çã„Ç¢„É´„Éê„Éà„É≠„Çπ„ÅØ„ÄÅÁÆ°ÁêÜËÅ∑Âêë„Åë„ÅÆAI„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥ÊîØÊè¥„ÉÑ„Éº„É´„Äå„Ç≥„Éü„É•„Éà„É¨Z„Äç„ÅÆÊèê‰æõ„ÇíÂßã„ÇÅ„Åü„ÄÇÁÆ°ÁêÜËÅ∑„Å®Z‰∏ñ‰ª£„ÅÆÈÉ®‰∏ã„Å®„ÅÆ„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥„ÇÆ„É£„ÉÉ„Éó„ÇíËß£Ê±∫„Åó„ÄÅÊó©ÊúüÈõ¢ËÅ∑„ÅÆÈò≤Ê≠¢„ÇíÂõ≥„Çã„ÄÇ",
    "summary": "ÈÄÄËÅ∑‰ª£Ë°å„Çµ„Éº„Éì„Çπ„Äå„É¢„Éº„É†„É™„Äç„Å™„Å©„ÇíÊâãÊéõ„Åë„Çã„Ç¢„É´„Éê„Éà„É≠„Çπ„ÅØ„ÄÅÁÆ°ÁêÜËÅ∑Âêë„Åë„ÅÆAI„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥ÊîØÊè¥„ÉÑ„Éº„É´„Äå„Ç≥„Éü„É•„Éà„É¨Z„Äç„ÅÆÊèê‰æõ„ÇíÂßã„ÇÅ„Åü„ÄÇÁÆ°ÁêÜËÅ∑„Å®Z‰∏ñ‰ª£„ÅÆÈÉ®‰∏ã„Å®„ÅÆ„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥„ÇÆ„É£„ÉÉ„Éó„ÇíËß£Ê±∫„Åó„ÄÅÊó©ÊúüÈõ¢ËÅ∑„ÅÆÈò≤Ê≠¢„ÇíÂõ≥„Çã„ÄÇ",
    "pubDate": "Tue, 01 Jul 2025 14:51:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/01/news083.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/01/cover_news083.jpg"
  },
  {
    "title": "Introducing the Open Chain of Thought Leaderboard",
    "description": "",
    "summary": "Introducing the Open Chain of Thought Leaderboard Chain-of-thought prompting is emerging as a powerf...",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-cot",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_cot.png"
  },
  {
    "title": "Enhance Your Models in 5 Minutes with the Hugging Face Kernel Hub",
    "description": "",
    "summary": "üèéÔ∏è Enhance Your Models in 5 Minutes with the Hugging Face Kernel Hub Boost your model performance wi...",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hello-hf-kernels",
    "thumbnail": "https://huggingface.co/blog/assets/hello-hf-kernels/kernel-hub-five-mins-short.png"
  },
  {
    "title": "OpenAI at the Paris AI Action Summit",
    "description": "OpenAI looks forward to engaging with global leaders on AI‚Äôs role in shaping innovation and economic prosperity.",
    "summary": "OpenAI looks forward to engaging with global leaders on AI‚Äôs role in shaping innovation and economic prosperity.",
    "pubDate": "Fri, 07 Feb 2025 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-at-the-paris-ai-action-summit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations",
    "description": "arXiv:2506.24016v1 Announce Type: cross Abstract: Recent advances in large language models and vision-language models have led to growing interest in explainable evaluation metrics for image captioning. However, these metrics generate explanations without standardized criteria, and the overall quality of the generated explanations remains unverified. In this paper, we propose EXPERT, a reference-free evaluation metric that provides structured explanations based on three fundamental criteria: fluency, relevance, and descriptiveness. By constructing large-scale datasets of high-quality structured explanations, we develop a two-stage evaluation template to effectively supervise a vision-language model for both scoring and explanation generation. EXPERT achieves state-of-the-art results on benchmark datasets while providing significantly higher-quality explanations than existing metrics, as validated through comprehensive human evaluation. Our code and datasets are available at https://github.com/hjkim811/EXPERT.",
    "summary": "arXiv:2506.24016v1 Announce Type: cross Abstract: Recent advances in large language models and vision-language models have led to growing interest in explainable evaluation metrics for image captioning. However, these metrics generate explanations without standardized criteria, and the overall quality of the generated explanations remains unverified. In this paper, we propose EXPERT, a reference-free evaluation metric that provides structured explanations based on three fundamental criteria: fluency, relevance, and descriptiveness. By constructing large-scale datasets of high-quality structured explanations, we develop a two-stage evaluation template to effectively supervise a vision-language model for both scoring and explanation generation. EXPERT achieves state-of-the-art results on benchmark datasets while providing significantly higher-quality explanations than existing metrics, as validated through comprehensive human evaluation. Our code and datasets are available at https://github.com/hjkim811/EXPERT.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.24016",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Thinking with images",
    "description": "OpenAI o3 and o4-mini represent a significant breakthrough in visual perception by reasoning with images in their chain of thought.",
    "summary": "OpenAI o3 and o4-mini represent a significant breakthrough in visual perception by reasoning with images in their chain of thought.",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/thinking-with-images",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system",
    "description": "arXiv:2506.23926v1 Announce Type: new Abstract: Resilience non-equilibrium measurement, the ability to maintain fundamental functionality amidst failures and errors, is crucial for scientific management and engineering applications of industrial chain. The problem is particularly challenging when the number or types of multiple co-evolution of resilience (for example, randomly placed) are extremely chaos. Existing end-to-end deep learning ordinarily do not generalize well to unseen full-feld reconstruction of spatiotemporal co-evolution structure, and predict resilience of network topology, especially in multiple chaos data regimes typically seen in real-world applications. To address this challenge, here we propose industrial brain, a human-like autonomous cognitive decision-making and planning framework integrating higher-order activity-driven neuro network and CT-OODA symbolic reasoning to autonomous plan resilience directly from observational data of global variable. The industrial brain not only understands and model structure of node activity dynamics and network co-evolution topology without simplifying assumptions, and reveal the underlying laws hidden behind complex networks, but also enabling accurate resilience prediction, inference, and planning. Experimental results show that industrial brain significantly outperforms resilience prediction and planning methods, with an accurate improvement of up to 10.8% over GoT and OlaGPT framework and 11.03% over spectral dimension reduction. It also generalizes to unseen topologies and dynamics and maintains robust performance despite observational disturbances. Our findings suggest that industrial brain addresses an important gap in resilience prediction and planning for industrial chain.",
    "summary": "arXiv:2506.23926v1 Announce Type: new Abstract: Resilience non-equilibrium measurement, the ability to maintain fundamental functionality amidst failures and errors, is crucial for scientific management and engineering applications of industrial chain. The problem is particularly challenging when the number or types of multiple co-evolution of resilience (for example, randomly placed) are extremely chaos. Existing end-to-end deep learning ordinarily do not generalize well to unseen full-feld reconstruction of spatiotemporal co-evolution structure, and predict resilience of network topology, especially in multiple chaos data regimes typically seen in real-world applications. To address this challenge, here we propose industrial brain, a human-like autonomous cognitive decision-making and planning framework integrating higher-order activity-driven neuro network and CT-OODA symbolic reasoning to autonomous plan resilience directly from observational data of global variable. The industrial brain not only understands and model structure of node activity dynamics and network co-evolution topology without simplifying assumptions, and reveal the underlying laws hidden behind complex networks, but also enabling accurate resilience prediction, inference, and planning. Experimental results show that industrial brain significantly outperforms resilience prediction and planning methods, with an accurate improvement of up to 10.8% over GoT and OlaGPT framework and 11.03% over spectral dimension reduction. It also generalizes to unseen topologies and dynamics and maintains robust performance despite observational disturbances. Our findings suggest that industrial brain addresses an important gap in resilience prediction and planning for industrial chain.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23926",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Unlocking Longer Generation with Key-Value Cache Quantization",
    "description": "",
    "summary": "Unlocking Longer Generation with Key-Value Cache Quantization At Hugging Face, we are excited to sha...",
    "pubDate": "Thu, 16 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kv-cache-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/kv_cache_quantization/thumbnail.png"
  },
  {
    "title": "Decoupled Seg Tokens Make Stronger Reasoning Video Segmenter and Grounder",
    "description": "arXiv:2506.22880v1 Announce Type: cross Abstract: Existing video segmenter and grounder approaches, exemplified by Sa2VA, directly fuse features within segmentation models. This often results in an undesirable entanglement of dynamic visual information and static semantics, thereby degrading segmentation accuracy. To systematically mitigate this issue, we propose DeSa2VA, a decoupling-enhanced prompting scheme integrating text pre-training and a linear decoupling module to address the information processing limitations inherent in SAM-2. Specifically, first, we devise a pre-training paradigm that converts textual ground-truth labels into point-level prompts while generating corresponding text masks. These masks are refined through a hybrid loss function to strengthen the model's semantic grounding capabilities. Next, we employ linear projection to disentangle hidden states that generated by a large language model into distinct textual and visual feature subspaces. Finally, a dynamic mask fusion strategy synergistically combines these decoupled features through triple supervision from predicted text/visual masks and ground-truth annotations. Extensive experiments demonstrate state-of-the-art performance across diverse tasks, including image segmentation, image question answering, video segmentation, and video question answering. Our codes are available at https://github.com/longmalongma/DeSa2VA.",
    "summary": "arXiv:2506.22880v1 Announce Type: cross Abstract: Existing video segmenter and grounder approaches, exemplified by Sa2VA, directly fuse features within segmentation models. This often results in an undesirable entanglement of dynamic visual information and static semantics, thereby degrading segmentation accuracy. To systematically mitigate this issue, we propose DeSa2VA, a decoupling-enhanced prompting scheme integrating text pre-training and a linear decoupling module to address the information processing limitations inherent in SAM-2. Specifically, first, we devise a pre-training paradigm that converts textual ground-truth labels into point-level prompts while generating corresponding text masks. These masks are refined through a hybrid loss function to strengthen the model's semantic grounding capabilities. Next, we employ linear projection to disentangle hidden states that generated by a large language model into distinct textual and visual feature subspaces. Finally, a dynamic mask fusion strategy synergistically combines these decoupled features through triple supervision from predicted text/visual masks and ground-truth annotations. Extensive experiments demonstrate state-of-the-art performance across diverse tasks, including image segmentation, image question answering, video segmentation, and video question answering. Our codes are available at https://github.com/longmalongma/DeSa2VA.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22880",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From Large-scale Audio Tagging to Real-Time Explainable Emergency Vehicle Sirens Detection",
    "description": "arXiv:2506.23437v1 Announce Type: cross Abstract: Accurate recognition of Emergency Vehicle (EV) sirens is critical for the integration of intelligent transportation systems, smart city monitoring systems, and autonomous driving technologies. Modern automatic solutions are limited by the lack of large scale, curated datasets and by the computational demands of state of the art sound event detection models. This work introduces E2PANNs (Efficient Emergency Pre trained Audio Neural Networks), a lightweight Convolutional Neural Network architecture derived from the PANNs framework, specifically optimized for binary EV siren detection. Leveraging our dedicated subset of AudioSet (AudioSet EV) we fine-tune and evaluate E2PANNs across multiple reference datasets and test its viability on embedded hardware. The experimental campaign includes ablation studies, cross-domain benchmarking, and real-time inference deployment on edge device. Interpretability analyses exploiting Guided Backpropagation and ScoreCAM algorithms provide insights into the model internal representations and validate its ability to capture distinct spectrotemporal patterns associated with different types of EV sirens. Real time performance is assessed through frame wise and event based detection metrics, as well as a detailed analysis of false positive activations. Results demonstrate that E2PANNs establish a new state of the art in this research domain, with high computational efficiency, and suitability for edge-based audio monitoring and safety-critical applications.",
    "summary": "arXiv:2506.23437v1 Announce Type: cross Abstract: Accurate recognition of Emergency Vehicle (EV) sirens is critical for the integration of intelligent transportation systems, smart city monitoring systems, and autonomous driving technologies. Modern automatic solutions are limited by the lack of large scale, curated datasets and by the computational demands of state of the art sound event detection models. This work introduces E2PANNs (Efficient Emergency Pre trained Audio Neural Networks), a lightweight Convolutional Neural Network architecture derived from the PANNs framework, specifically optimized for binary EV siren detection. Leveraging our dedicated subset of AudioSet (AudioSet EV) we fine-tune and evaluate E2PANNs across multiple reference datasets and test its viability on embedded hardware. The experimental campaign includes ablation studies, cross-domain benchmarking, and real-time inference deployment on edge device. Interpretability analyses exploiting Guided Backpropagation and ScoreCAM algorithms provide insights into the model internal representations and validate its ability to capture distinct spectrotemporal patterns associated with different types of EV sirens. Real time performance is assessed through frame wise and event based detection metrics, as well as a detailed analysis of false positive activations. Results demonstrate that E2PANNs establish a new state of the art in this research domain, with high computational efficiency, and suitability for edge-based audio monitoring and safety-critical applications.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23437",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome, Pieter and Shivon!",
    "description": "We have two more team¬†updates.",
    "summary": "We have two more team¬†updates.",
    "pubDate": "Tue, 26 Apr 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/welcome-pieter-and-shivon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ControlNet in Diffusers üß®",
    "description": "",
    "summary": "Ultra fast ControlNet with üß® Diffusers Ever since Stable Diffusion took the world by storm, people h...",
    "pubDate": "Fri, 03 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/controlnet",
    "thumbnail": "https://huggingface.co/blog/assets/controlnet/thumbnail.png"
  },
  {
    "title": "The Technology Behind BLOOM Training",
    "description": "",
    "summary": "The Technology Behind BLOOM Training In recent years, training ever larger language models has becom...",
    "pubDate": "Thu, 14 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-megatron-deepspeed",
    "thumbnail": "https://huggingface.co/blog/assets/86_bloom_megatron_deepspeed/thumbnail.png"
  },
  {
    "title": "OpenAI leadership team update",
    "description": "We‚Äôre happy to announce several executive role changes that reflect our recent progress and will ensure continued momentum toward our next major¬†milestones.",
    "summary": "We‚Äôre happy to announce several executive role changes that reflect our recent progress and will ensure continued momentum toward our next major¬†milestones.",
    "pubDate": "Thu, 05 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-team-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix",
    "description": "arXiv:2505.08228v2 Announce Type: replace-cross Abstract: Enhancing the robustness of object detection systems under adverse weather conditions is crucial for the advancement of autonomous driving technology. This study presents a novel approach leveraging the diffusion model Instruct Pix2Pix to develop prompting methodologies that generate realistic datasets with weather-based augmentations aiming to mitigate the impact of adverse weather on the perception capabilities of state-of-the-art object detection models, including Faster R-CNN and YOLOv10. Experiments were conducted in two environments, in the CARLA simulator where an initial evaluation of the proposed data augmentation was provided, and then on the real-world image data sets BDD100K and ACDC demonstrating the effectiveness of the approach in real environments. The key contributions of this work are twofold: (1) identifying and quantifying the performance gap in object detection models under challenging weather conditions, and (2) demonstrating how tailored data augmentation strategies can significantly enhance the robustness of these models. This research establishes a solid foundation for improving the reliability of perception systems in demanding environmental scenarios, and provides a pathway for future advancements in autonomous driving.",
    "summary": "arXiv:2505.08228v2 Announce Type: replace-cross Abstract: Enhancing the robustness of object detection systems under adverse weather conditions is crucial for the advancement of autonomous driving technology. This study presents a novel approach leveraging the diffusion model Instruct Pix2Pix to develop prompting methodologies that generate realistic datasets with weather-based augmentations aiming to mitigate the impact of adverse weather on the perception capabilities of state-of-the-art object detection models, including Faster R-CNN and YOLOv10. Experiments were conducted in two environments, in the CARLA simulator where an initial evaluation of the proposed data augmentation was provided, and then on the real-world image data sets BDD100K and ACDC demonstrating the effectiveness of the approach in real environments. The key contributions of this work are twofold: (1) identifying and quantifying the performance gap in object detection models under challenging weather conditions, and (2) demonstrating how tailored data augmentation strategies can significantly enhance the robustness of these models. This research establishes a solid foundation for improving the reliability of perception systems in demanding environmental scenarios, and provides a pathway for future advancements in autonomous driving.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.08228",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The 4 Things Qwen-3's Chat Template Teaches Us",
    "description": "",
    "summary": "The 4 Things Qwen-3‚Äôs Chat Template Teaches Us What a boring Jinja snippet tells us about the new Qw...",
    "pubDate": "Wed, 30 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/qwen-3-chat-template-deep-dive",
    "thumbnail": "https://huggingface.co/blog/assets/qwen-3-chat-template-deep-dive/thumbnail.png"
  },
  {
    "title": "Our approach to AI safety",
    "description": "Ensuring that AI systems are built, deployed, and used safely is critical to our mission.",
    "summary": "Ensuring that AI systems are built, deployed, and used safely is critical to our mission.",
    "pubDate": "Wed, 05 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/our-approach-to-ai-safety",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI announces leadership transition",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-announces-leadership-transition",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Red-Teaming Large Language Models",
    "description": "",
    "summary": "Red-Teaming Large Language Models Warning: This article is about red-teaming and as such contains ex...",
    "pubDate": "Fri, 24 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/red-teaming",
    "thumbnail": "https://huggingface.co/blog/assets/red-teaming/thumbnail.png"
  },
  {
    "title": "Faster Text Generation with Self-Speculative Decoding",
    "description": "",
    "summary": "Faster Text Generation with Self-Speculative Decoding Self-speculative decoding, proposed in LayerSk...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/layerskip",
    "thumbnail": "https://huggingface.co/blog/assets/layerskip/thumbnail.png"
  },
  {
    "title": "Speak is personalizing language learning with AI",
    "description": "A conversation with Connor Zwick, CEO & Co-founder of Speak.",
    "summary": "A conversation with Connor Zwick, CEO & Co-founder of Speak.",
    "pubDate": "Tue, 22 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/speak-connor-zwick",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SEUF: Is Unlearning One Expert Enough for Mixture-of-Experts LLMs?",
    "description": "arXiv:2411.18797v2 Announce Type: replace-cross Abstract: Recent advancements in LLMs unlearning have shown remarkable success in removing unwanted data-model influences while preserving the model's utility for legitimate knowledge. Despite these strides, sparse Mixture-of-Experts (MoE) LLMs--a key subset of the LLM family--have remained unexplored in the context of unlearning. As MoE LLMs are celebrated for their exceptional performance, we ask:How can unlearning be performed effectively and efficiently on MoE LLMs? Our pilot study shows that the dynamic routing nature of MoE LLMs introduces unique challenges, leading to excessive forgetting, uncontrolled knowledge erasure and substantial utility drops when existing unlearning methods are applied. To address this, we propose a novel Selected-Expert Unlearning Framework (SEUF). Through expert attribution, unlearning is concentrated on the most actively engaged experts for the specified knowledge. Concurrently, an anchor loss is applied to the router to stabilize the active state of this targeted expert, ensuring focused and controlled unlearning. SEUF is compatible with various standard unlearning algorithms. Extensive experiments demonstrate that SEUF enhances both forget quality up to 5% and model utility by 35% on MoE LLMs across various benchmarks and LLM architectures (compared to standard unlearning algorithms), while only unlearning 0.06% of the model parameters.",
    "summary": "arXiv:2411.18797v2 Announce Type: replace-cross Abstract: Recent advancements in LLMs unlearning have shown remarkable success in removing unwanted data-model influences while preserving the model's utility for legitimate knowledge. Despite these strides, sparse Mixture-of-Experts (MoE) LLMs--a key subset of the LLM family--have remained unexplored in the context of unlearning. As MoE LLMs are celebrated for their exceptional performance, we ask:How can unlearning be performed effectively and efficiently on MoE LLMs? Our pilot study shows that the dynamic routing nature of MoE LLMs introduces unique challenges, leading to excessive forgetting, uncontrolled knowledge erasure and substantial utility drops when existing unlearning methods are applied. To address this, we propose a novel Selected-Expert Unlearning Framework (SEUF). Through expert attribution, unlearning is concentrated on the most actively engaged experts for the specified knowledge. Concurrently, an anchor loss is applied to the router to stabilize the active state of this targeted expert, ensuring focused and controlled unlearning. SEUF is compatible with various standard unlearning algorithms. Extensive experiments demonstrate that SEUF enhances both forget quality up to 5% and model utility by 35% on MoE LLMs across various benchmarks and LLM architectures (compared to standard unlearning algorithms), while only unlearning 0.06% of the model parameters.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.18797",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GaussMaster: An LLM-based Database Copilot System",
    "description": "arXiv:2506.23322v1 Announce Type: cross Abstract: In the financial industry, data is the lifeblood of operations, and DBAs shoulder significant responsibilities for SQL tuning, database deployment, diagnosis, and service repair. In recent years, both database vendors and customers have increasingly turned to autonomous database platforms in an effort to alleviate the heavy workload of DBAs. However, existing autonomous database platforms are limited in their capabilities, primarily addressing single-point issues such as NL2SQL, anomaly detection, and SQL tuning. Manual intervention remains a necessity for comprehensive database maintenance. GaussMaster aims to revolutionize this landscape by introducing an LLM-based database copilot system. This innovative solution is designed not only to assist developers in writing efficient SQL queries but also to provide comprehensive care for database services. When database instances exhibit abnormal behavior, GaussMaster is capable of orchestrating the entire maintenance process automatically. It achieves this by analyzing hundreds of metrics and logs, employing a Tree-of-thought approach to identify root causes, and invoking appropriate tools to resolve issues. We have successfully implemented GaussMaster in real-world scenarios, such as the banking industry, where it has achieved zero human intervention for over 34 database maintenance scenarios. In this paper, we present significant improvements in these tasks with code at https://gitcode.com/opengauss/openGauss-GaussMaster.",
    "summary": "arXiv:2506.23322v1 Announce Type: cross Abstract: In the financial industry, data is the lifeblood of operations, and DBAs shoulder significant responsibilities for SQL tuning, database deployment, diagnosis, and service repair. In recent years, both database vendors and customers have increasingly turned to autonomous database platforms in an effort to alleviate the heavy workload of DBAs. However, existing autonomous database platforms are limited in their capabilities, primarily addressing single-point issues such as NL2SQL, anomaly detection, and SQL tuning. Manual intervention remains a necessity for comprehensive database maintenance. GaussMaster aims to revolutionize this landscape by introducing an LLM-based database copilot system. This innovative solution is designed not only to assist developers in writing efficient SQL queries but also to provide comprehensive care for database services. When database instances exhibit abnormal behavior, GaussMaster is capable of orchestrating the entire maintenance process automatically. It achieves this by analyzing hundreds of metrics and logs, employing a Tree-of-thought approach to identify root causes, and invoking appropriate tools to resolve issues. We have successfully implemented GaussMaster in real-world scenarios, such as the banking industry, where it has achieved zero human intervention for over 34 database maintenance scenarios. In this paper, we present significant improvements in these tasks with code at https://gitcode.com/opengauss/openGauss-GaussMaster.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23322",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Object Detection Leaderboard",
    "description": "",
    "summary": "Object Detection Leaderboard: Decoding Metrics and Their Potential Pitfalls Welcome to our latest di...",
    "pubDate": "Mon, 18 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/object-detection-leaderboard",
    "thumbnail": "https://huggingface.co/blog/assets/object-detection-leaderboard/thumbnail.png"
  },
  {
    "title": "Video generation models as world simulators",
    "description": "We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.",
    "summary": "We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.",
    "pubDate": "Thu, 15 Feb 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/video-generation-models-as-world-simulators",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Get an audio overview of Search results in Labs, then click through to learn more.",
    "description": "A phone screen showing Google search results with a section titled 'Search Labs | Audio Overviews' and an audio player.",
    "summary": "A phone screen showing Google search results with a section titled 'Search Labs | Audio Overviews' and an audio player.",
    "pubDate": "Fri, 13 Jun 2025 15:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/audio-overviews-search-labs/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AudioOverview_SS.max-1440x810.png"
  },
  {
    "title": "OpenAI Five Finals",
    "description": "We‚Äôll be holding our final live event for OpenAI Five at 11:30am PT on April 13.",
    "summary": "We‚Äôll be holding our final live event for OpenAI Five at 11:30am PT on April 13.",
    "pubDate": "Tue, 26 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-finals",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How we leveraged distilabel to create an Argilla 2.0 Chatbot",
    "description": "",
    "summary": "How we leveraged distilabel to create an Argilla 2.0 Chatbot TL;DR Discover how to build a Chatbot f...",
    "pubDate": "Tue, 16 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/argilla-chatbot",
    "thumbnail": "https://huggingface.co/blog/assets/argilla-chatbot/thumbnail.png"
  },
  {
    "title": "Attention acts to suppress goal-based conflict under high competition",
    "description": "arXiv:1610.09431v1 Announce Type: cross Abstract: It is known that when multiple stimuli are present, top-down attention selectively enhances the neural signal in the visual cortex for task-relevant stimuli, but this has been tested only under conditions of minimal competition of visual attention. Here we show during high competition, that is, two stimuli in a shared receptive field possessing opposing modulatory goals, top-down attention suppresses both task-relevant and irrelevant neural signals within 100 ms of stimuli onset. This non-selective engagement of top-down attentional resources serves to reduce the feedforward signal representing irrelevant stimuli.",
    "summary": "arXiv:1610.09431v1 Announce Type: cross Abstract: It is known that when multiple stimuli are present, top-down attention selectively enhances the neural signal in the visual cortex for task-relevant stimuli, but this has been tested only under conditions of minimal competition of visual attention. Here we show during high competition, that is, two stimuli in a shared receptive field possessing opposing modulatory goals, top-down attention suppresses both task-relevant and irrelevant neural signals within 100 ms of stimuli onset. This non-selective engagement of top-down attentional resources serves to reduce the feedforward signal representing irrelevant stimuli.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/1610.09431",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Perspective Dial: Measuring Perspective of Text and Guiding LLM Outputs",
    "description": "arXiv:2506.23377v1 Announce Type: cross Abstract: Large language models (LLMs) are used in a variety of mission-critical roles. Due to the rapidly developing nature of LLMs, there is a lack of quantifiable understanding of the bias and perspective associated with LLM output. Inspired by this need, this paper considers the broader issue of perspective or viewpoint of general text and perspective control of large-language model (LLM) output. Perspective-Dial consists of two main components: a (1) metric space, dubbed Perspective Space, that enables quantitative measurements of different perspectives regarding a topic, and the use of (2) Systematic Prompt Engineering that utilizes greedy-coordinate descent to control LLM output perspective based on measurement feedback from the Perspective Space. The empirical nature of the approach allows progress to side step a principled understanding of perspective or bias -- effectively quantifying and adjusting outputs for a variety of topics. Potential applications include detection, tracking and mitigation of LLM bias, narrative detection, sense making and tracking in public discourse, and debate bot advocating given perspective.",
    "summary": "arXiv:2506.23377v1 Announce Type: cross Abstract: Large language models (LLMs) are used in a variety of mission-critical roles. Due to the rapidly developing nature of LLMs, there is a lack of quantifiable understanding of the bias and perspective associated with LLM output. Inspired by this need, this paper considers the broader issue of perspective or viewpoint of general text and perspective control of large-language model (LLM) output. Perspective-Dial consists of two main components: a (1) metric space, dubbed Perspective Space, that enables quantitative measurements of different perspectives regarding a topic, and the use of (2) Systematic Prompt Engineering that utilizes greedy-coordinate descent to control LLM output perspective based on measurement feedback from the Perspective Space. The empirical nature of the approach allows progress to side step a principled understanding of perspective or bias -- effectively quantifying and adjusting outputs for a variety of topics. Potential applications include detection, tracking and mitigation of LLM bias, narrative detection, sense making and tracking in public discourse, and debate bot advocating given perspective.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23377",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Efficient Controllable Generation for SDXL with T2I-Adapters",
    "description": "",
    "summary": "Efficient Controllable Generation for SDXL with T2I-Adapters T2I-Adapter is an efficient plug-and-pl...",
    "pubDate": "Fri, 08 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/t2i-sdxl-adapters",
    "thumbnail": "https://huggingface.co/blog/assets/t2i-sdxl-adapters/thumbnail.png"
  },
  {
    "title": "ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data",
    "description": "arXiv:2506.23520v1 Announce Type: new Abstract: With the increasing interest in robotic synthesis in the context of organic chemistry, the automated extraction of chemical procedures from literature is critical. However, this task remains challenging due to the inherent ambiguity of chemical language and the high cost of human annotation required for developing reliable computer-aided extraction protocols. Here, we present ChemActor, a fully fine-tuned large language model (LLM), as a chemical executor to convert between unstructured experimental procedures and structured action sequences. We propose a sequential LLM-generated data framework to address the challenges of insufficient and low-quality annotated data. This framework integrates a data selection module that selects data based on distribution divergence, with a general-purpose LLM, to generate machine-executable actions from a single molecule input. Additionally, we introduce a novel multi-round LLMs circle review metric, which reflects the model's advanced understanding of chemical experimental procedures. Extensive experiments on reaction-to-description (R2D) and description-to-action (D2A) tasks demonstrate that ChemActor, augmented by LLM-generated data, achieves state-of-the-art performance, outperforming the baseline model by 10%. The code is available at: https://github.com/Zhanghahah/ChemActor.",
    "summary": "arXiv:2506.23520v1 Announce Type: new Abstract: With the increasing interest in robotic synthesis in the context of organic chemistry, the automated extraction of chemical procedures from literature is critical. However, this task remains challenging due to the inherent ambiguity of chemical language and the high cost of human annotation required for developing reliable computer-aided extraction protocols. Here, we present ChemActor, a fully fine-tuned large language model (LLM), as a chemical executor to convert between unstructured experimental procedures and structured action sequences. We propose a sequential LLM-generated data framework to address the challenges of insufficient and low-quality annotated data. This framework integrates a data selection module that selects data based on distribution divergence, with a general-purpose LLM, to generate machine-executable actions from a single molecule input. Additionally, we introduce a novel multi-round LLMs circle review metric, which reflects the model's advanced understanding of chemical experimental procedures. Extensive experiments on reaction-to-description (R2D) and description-to-action (D2A) tasks demonstrate that ChemActor, augmented by LLM-generated data, achieves state-of-the-art performance, outperforming the baseline model by 10%. The code is available at: https://github.com/Zhanghahah/ChemActor.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23520",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Going multimodal: How Prezi is leveraging the Hub and the Expert Support Program to accelerate their ML roadmap",
    "description": "",
    "summary": "Going multimodal: How Prezi is leveraging the Hub and the Expert Support Program to accelerate their...",
    "pubDate": "Wed, 19 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/prezi-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/70_sempre_health/thumbnailprezi.jpg"
  },
  {
    "title": "We are hiring interns!",
    "description": "",
    "summary": "We are hiring interns! Want to help build the future at -- if we may say so ourselves -- one of the ...",
    "pubDate": "Tue, 29 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/interns-2023",
    "thumbnail": "https://huggingface.co/blog/assets/interns-2023/thumbnail.png"
  },
  {
    "title": "Dimensionality Reduction on IoT Monitoring Data of Smart Building for Energy Consumption Forecasting",
    "description": "arXiv:2506.22468v1 Announce Type: cross Abstract: The Internet of Things (IoT) plays a major role today in smart building infrastructures, from simple smart-home applications, to more sophisticated industrial type installations. The vast amounts of data generated from relevant systems can be processed in different ways revealing important information. This is especially true in the era of edge computing, when advanced data analysis and decision-making is gradually moving to the edge of the network where devices are generally characterised by low computing resources. In this context, one of the emerging main challenges is related to maintaining data analysis accuracy even with less data that can be efficiently handled by low resource devices. The present work focuses on correlation analysis of data retrieved from a pilot IoT network installation monitoring a small smart office by means of environmental and energy consumption sensors. The research motivation was to find statistical correlation between the monitoring variables that will allow the use of machine learning (ML) prediction algorithms for energy consumption reducing input parameters. For this to happen, a series of hypothesis tests for the correlation of three different environmental variables with the energy consumption were carried out. A total of ninety tests were performed, thirty for each pair of variables. In these tests, p-values showed the existence of strong or semi-strong correlation with two environmental variables, and of a weak correlation with a third one. Using the proposed methodology, we manage without examining the entire data set to exclude weak correlated variables while keeping the same score of accuracy.",
    "summary": "arXiv:2506.22468v1 Announce Type: cross Abstract: The Internet of Things (IoT) plays a major role today in smart building infrastructures, from simple smart-home applications, to more sophisticated industrial type installations. The vast amounts of data generated from relevant systems can be processed in different ways revealing important information. This is especially true in the era of edge computing, when advanced data analysis and decision-making is gradually moving to the edge of the network where devices are generally characterised by low computing resources. In this context, one of the emerging main challenges is related to maintaining data analysis accuracy even with less data that can be efficiently handled by low resource devices. The present work focuses on correlation analysis of data retrieved from a pilot IoT network installation monitoring a small smart office by means of environmental and energy consumption sensors. The research motivation was to find statistical correlation between the monitoring variables that will allow the use of machine learning (ML) prediction algorithms for energy consumption reducing input parameters. For this to happen, a series of hypothesis tests for the correlation of three different environmental variables with the energy consumption were carried out. A total of ninety tests were performed, thirty for each pair of variables. In these tests, p-values showed the existence of strong or semi-strong correlation with two environmental variables, and of a weak correlation with a third one. Using the proposed methodology, we manage without examining the entire data set to exclude weak correlated variables while keeping the same score of accuracy.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22468",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using AI to fight climate change",
    "description": "AI is a powerful technology that will transform our future, so how can we best apply it to help combat climate change and find sustainable solutions?",
    "summary": "AI is a powerful technology that will transform our future, so how can we best apply it to help combat climate change and find sustainable solutions?",
    "pubDate": "Fri, 21 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/using-ai-to-fight-climate-change/",
    "thumbnail": "https://lh3.googleusercontent.com/_7lNDyMo0JuzMRu0wVUtaJuXaEPDy8ay20vcsv08JvF3fMkEbk20mGBWdI09Wg0USIinNH5urB5nudEGZWRvTeUNOz_WOAwcduNdQQQNGx-JgtQE1aE=w1200-h630-n-nu"
  },
  {
    "title": "Welcome PaliGemma 2 ‚Äì New vision language models by Google",
    "description": "",
    "summary": "Welcome PaliGemma 2 ‚Äì New vision language models by Google We are excited to welcome Google's all-ne...",
    "pubDate": "Thu, 05 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma2",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma/Paligemma2.png"
  },
  {
    "title": "Red Teaming for Generative AI, Report on a Copyright-Focused Exercise Completed in an Academic Medical Center",
    "description": "arXiv:2506.22523v1 Announce Type: cross Abstract: Generative AI is present in multiple industries. Dana-Farber Cancer Institute, in partnership with Microsoft, has created an internal AI tool, GPT4DFCI. Together we hosted a red teaming event to assess whether the underlying GPT models that support the tool would output copyrighted data. Our teams focused on reproducing content from books, news articles, scientific articles, and electronic health records. We found isolated instances where GPT4DFCI was able to identify copyrighted material and reproduce exact quotes from famous books which indicates that copyrighted material was in the training data. The model was not able to reproduce content from our target news article, scientific article, or electronic health records. However, there were instances of fabrication. As a result of this event, a mitigation strategy is in production in GPT4DFCI v2.8.2, deployed on January 21, 2025. We hope this report leads to similar events in which AI software tools are stress-tested to assess the perimeter of their legal and ethical usage.",
    "summary": "arXiv:2506.22523v1 Announce Type: cross Abstract: Generative AI is present in multiple industries. Dana-Farber Cancer Institute, in partnership with Microsoft, has created an internal AI tool, GPT4DFCI. Together we hosted a red teaming event to assess whether the underlying GPT models that support the tool would output copyrighted data. Our teams focused on reproducing content from books, news articles, scientific articles, and electronic health records. We found isolated instances where GPT4DFCI was able to identify copyrighted material and reproduce exact quotes from famous books which indicates that copyrighted material was in the training data. The model was not able to reproduce content from our target news article, scientific article, or electronic health records. However, there were instances of fabrication. As a result of this event, a mitigation strategy is in production in GPT4DFCI v2.8.2, deployed on January 21, 2025. We hope this report leads to similar events in which AI software tools are stress-tested to assess the perimeter of their legal and ethical usage.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22523",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BenchmarkQED: Automated benchmarking of RAG systems",
    "description": "<p>BenchmarkQED is an open-source toolkit for benchmarking RAG systems using automated query generation, evaluation, and dataset prep. It shows that LazyGraphRAG outperforms standard methods, especially on complex, global queries.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/'>BenchmarkQED: Automated benchmarking of RAG systems</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>BenchmarkQED is an open-source toolkit for benchmarking RAG systems using automated query generation, evaluation, and dataset prep. It shows that LazyGraphRAG outperforms standard methods, especially on complex, global queries.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/'>BenchmarkQED: Automated benchmarking of RAG systems</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 05 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "No, of course I can! Refusal Mechanisms Can Be Exploited Using Harmless Fine-Tuning Data",
    "description": "arXiv:2502.19537v4 Announce Type: replace-cross Abstract: Leading language model (LM) providers like OpenAI and Anthropic allow customers to fine-tune frontier LMs for specific use cases. To prevent abuse, these providers apply filters to block fine-tuning on overtly harmful data. In this setting, we make three contributions: First, while past work has shown that safety alignment is 'shallow', we correspondingly demonstrate that existing fine-tuning attacks are shallow -- attacks target only the first several tokens of the model response, and consequently can be blocked by generating the first several response tokens with an aligned model. Second, we conceptually illustrate how to make attacks deeper by introducing a new fine-tuning attack that trains models to first refuse harmful requests before answering them; this 'refuse-then-comply' strategy bypasses shallow defenses and produces harmful responses that evade output filters. Third, we demonstrate the potency of our new fine-tuning attack by jailbreaking both open-source models equipped with defenses and production models, achieving attack success rates of 57% and 72% against GPT-4o and Claude Haiku, respectively. Our attack received a $2000 bug bounty from OpenAI and was acknowledged as a vulnerability by Anthropic. Our work undermines the notion that models are safe because they initially refuse harmful requests and broadens awareness of the scope of attacks that face production fine-tuning APIs.",
    "summary": "arXiv:2502.19537v4 Announce Type: replace-cross Abstract: Leading language model (LM) providers like OpenAI and Anthropic allow customers to fine-tune frontier LMs for specific use cases. To prevent abuse, these providers apply filters to block fine-tuning on overtly harmful data. In this setting, we make three contributions: First, while past work has shown that safety alignment is 'shallow', we correspondingly demonstrate that existing fine-tuning attacks are shallow -- attacks target only the first several tokens of the model response, and consequently can be blocked by generating the first several response tokens with an aligned model. Second, we conceptually illustrate how to make attacks deeper by introducing a new fine-tuning attack that trains models to first refuse harmful requests before answering them; this 'refuse-then-comply' strategy bypasses shallow defenses and produces harmful responses that evade output filters. Third, we demonstrate the potency of our new fine-tuning attack by jailbreaking both open-source models equipped with defenses and production models, achieving attack success rates of 57% and 72% against GPT-4o and Claude Haiku, respectively. Our attack received a $2000 bug bounty from OpenAI and was acknowledged as a vulnerability by Anthropic. Our work undermines the notion that models are safe because they initially refuse harmful requests and broadens awareness of the scope of attacks that face production fine-tuning APIs.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.19537",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The NLP Course is becoming the LLM Course!",
    "description": "",
    "summary": "The NLP Course is becoming the LLM Course! Education has always been at the heart of Hugging Face‚Äôs ...",
    "pubDate": "Thu, 03 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llm-course",
    "thumbnail": "https://huggingface.co/blog/assets/llm-course/llm-course-rename-thumbnail.png"
  },
  {
    "title": "VQ Diffusion with üß® Diffusers",
    "description": "",
    "summary": "VQ-Diffusion Vector Quantized Diffusion (VQ-Diffusion) is a conditional latent diffusion model devel...",
    "pubDate": "Wed, 30 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vq-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/117_vq_diffusion/thumbnail.png"
  },
  {
    "title": "Share your open ML datasets on Hugging Face Hub!",
    "description": "",
    "summary": "Share your open ML datasets on Hugging Face Hub! If you're working on data-intensive research or mac...",
    "pubDate": "Tue, 12 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/researcher-dataset-sharing",
    "thumbnail": "https://huggingface.co/blog/assets/researcher-dataset-sharing/thumbnail.png"
  },
  {
    "title": "Heart rate and respiratory rate prediction from noisy real-world smartphone based on Deep Learning methods",
    "description": "arXiv:2506.22460v1 Announce Type: cross Abstract: Using mobile phone video of the fingertip as a data source for estimating vital signs such as heart rate (HR) and respiratory rate (RR) during daily life has long been suggested. While existing literature indicates that these estimates are accurate to within several beats or breaths per minute, the data used to draw these conclusions are typically collected in laboratory environments under careful experimental control, and yet the results are assumed to generalize to daily life. In an effort to test it, a team of researchers collected a large dataset of mobile phone video recordings made during daily life and annotated with ground truth HR and RR labels from N=111 participants. They found that traditional algorithm performance on the fingerprint videos is worse than previously reported (7 times and 13 times worse for RR and HR, respectively). Fortunately, recent advancements in deep learning, especially in convolutional neural networks (CNNs), offer a promising solution to improve this performance. This study proposes a new method for estimating HR and RR using a novel 3D deep CNN, demonstrating a reduced error in estimated HR by 68% and RR by 75%. These promising results suggest that regressor-based deep learning approaches should be used in estimating HR and RR.",
    "summary": "arXiv:2506.22460v1 Announce Type: cross Abstract: Using mobile phone video of the fingertip as a data source for estimating vital signs such as heart rate (HR) and respiratory rate (RR) during daily life has long been suggested. While existing literature indicates that these estimates are accurate to within several beats or breaths per minute, the data used to draw these conclusions are typically collected in laboratory environments under careful experimental control, and yet the results are assumed to generalize to daily life. In an effort to test it, a team of researchers collected a large dataset of mobile phone video recordings made during daily life and annotated with ground truth HR and RR labels from N=111 participants. They found that traditional algorithm performance on the fingerprint videos is worse than previously reported (7 times and 13 times worse for RR and HR, respectively). Fortunately, recent advancements in deep learning, especially in convolutional neural networks (CNNs), offer a promising solution to improve this performance. This study proposes a new method for estimating HR and RR using a novel 3D deep CNN, demonstrating a reduced error in estimated HR by 68% and RR by 75%. These promising results suggest that regressor-based deep learning approaches should be used in estimating HR and RR.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22460",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SearchGPT is a prototype of new AI search features",
    "description": "We‚Äôre testing SearchGPT, a temporary prototype of new search features that give you fast and timely answers with clear and relevant sources.",
    "summary": "We‚Äôre testing SearchGPT, a temporary prototype of new search features that give you fast and timely answers with clear and relevant sources.",
    "pubDate": "Thu, 25 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/searchgpt-prototype",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing NextGenAI",
    "description": "OpenAI commits $50M in funding and tools to leading institutions.",
    "summary": "OpenAI commits $50M in funding and tools to leading institutions.",
    "pubDate": "Tue, 04 Mar 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-nextgenai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Implicit generation and generalization methods for energy-based models",
    "description": "We‚Äôve made progress towards stable and scalable training of¬†energy-based models¬†(EBMs) resulting in better sample quality and generalization ability than existing models. Generation in EBMs spends more compute to continually refine its answers and doing so can generate samples competitive with¬†GANs¬†at low temperatures,¬†while also having mode coverage guarantees of¬†likelihood-based models. We hope these findings stimulate further research into this promising class of¬†models.",
    "summary": "We‚Äôve made progress towards stable and scalable training of¬†energy-based models¬†(EBMs) resulting in better sample quality and generalization ability than existing models. Generation in EBMs spends more compute to continually refine its answers and doing so can generate samples competitive with¬†GANs¬†at low temperatures,¬†while also having mode coverage guarantees of¬†likelihood-based models. We hope these findings stimulate further research into this promising class of¬†models.",
    "pubDate": "Thu, 21 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/energy-based-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Subscribe to Enterprise Hub with your AWS Account",
    "description": "",
    "summary": "Subscribe to Enterprise Hub with your AWS Account You can now upgrade your Hugging Face Organization...",
    "pubDate": "Thu, 09 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/enterprise-hub-aws-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/158_aws_marketplace/thumbnail.jpg"
  },
  {
    "title": "Preparing for future AI risks in biology",
    "description": "Advanced AI can transform biology and medicine‚Äîbut also raises biosecurity risks. We‚Äôre proactively assessing capabilities and implementing safeguards to prevent misuse.",
    "summary": "Advanced AI can transform biology and medicine‚Äîbut also raises biosecurity risks. We‚Äôre proactively assessing capabilities and implementing safeguards to prevent misuse.",
    "pubDate": "Wed, 18 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/preparing-for-future-ai-capabilities-in-biology",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ÁîüÊàêAI„ÅåÂ§â„Åà„ÇãÊ∂àË≤ªËÄÖ„Å®„ÅÆ„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥„ÄÄÂçöÂ†±Â†Ç„Ç∞„É´„Éº„Éó„ÅÆÊ¥ªÁî®‰æã„ÄÄ‰ºÅÊ•≠„ÅåÈÖçÊÖÆ„Åô„Åπ„Åç3„Å§„ÅÆ„Éù„Ç§„É≥„Éà",
    "description": "ÂçöÂ†±Â†Ç„Ç∞„É´„Éº„Éó„ÅÆÁ∑èÂêàÂà∂‰Ωú‰∫ãÊ•≠‰ºöÁ§æ„Åß„ÅÇ„ÇãÂçöÂ†±Â†Ç„Éó„É≠„ÉÄ„ÇØ„ÉÑ„ÅØ„ÄÅÁîüÊàêAIÊäÄË°ì„ÇíÂäπÁéáÂåñÊâãÊÆµ„Å®„Åô„Çã„ÅÆ„Åß„ÅØ„Å™„Åè„ÄÅÁîüÊ¥ªËÄÖ„Å®Êñ∞„Åü„Å™Êé•ÁÇπ„ÇíÁîü„ÅøÂá∫„Åô„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„ÉÑ„Éº„É´„Å®„Åó„Å¶Ê¥ªÁî®„Åó„Å¶„ÅÑ„Çã„ÄÇÂÆüÈöõ„ÅÆ„Éû„Éº„Ç±„ÉÜ„Ç£„É≥„Ç∞ÁèæÂ†¥„Å´„Åä„Åë„ÇãÁîüÊàêAIÊ¥ªÁî®„ÅÆ‰æã„ÇíÁ¥π‰ªã„Åô„Çã„ÄÇ",
    "summary": "ÂçöÂ†±Â†Ç„Ç∞„É´„Éº„Éó„ÅÆÁ∑èÂêàÂà∂‰Ωú‰∫ãÊ•≠‰ºöÁ§æ„Åß„ÅÇ„ÇãÂçöÂ†±Â†Ç„Éó„É≠„ÉÄ„ÇØ„ÉÑ„ÅØ„ÄÅÁîüÊàêAIÊäÄË°ì„ÇíÂäπÁéáÂåñÊâãÊÆµ„Å®„Åô„Çã„ÅÆ„Åß„ÅØ„Å™„Åè„ÄÅÁîüÊ¥ªËÄÖ„Å®Êñ∞„Åü„Å™Êé•ÁÇπ„ÇíÁîü„ÅøÂá∫„Åô„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„ÉÑ„Éº„É´„Å®„Åó„Å¶Ê¥ªÁî®„Åó„Å¶„ÅÑ„Çã„ÄÇÂÆüÈöõ„ÅÆ„Éû„Éº„Ç±„ÉÜ„Ç£„É≥„Ç∞ÁèæÂ†¥„Å´„Åä„Åë„ÇãÁîüÊàêAIÊ¥ªÁî®„ÅÆ‰æã„ÇíÁ¥π‰ªã„Åô„Çã„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 12:28:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/30/news023.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/30/cover_news023.jpg"
  },
  {
    "title": "Online Human Action Detection during Escorting",
    "description": "arXiv:2506.23573v1 Announce Type: cross Abstract: The deployment of robot assistants in large indoor spaces has seen significant growth, with escorting tasks becoming a key application. However, most current escorting robots primarily rely on navigation-focused strategies, assuming that the person being escorted will follow without issue. In crowded environments, this assumption often falls short, as individuals may struggle to keep pace, become obstructed, get distracted, or need to stop unexpectedly. As a result, conventional robotic systems are often unable to provide effective escorting services due to their limited understanding of human movement dynamics. To address these challenges, an effective escorting robot must continuously detect and interpret human actions during the escorting process and adjust its movement accordingly. However, there is currently no existing dataset designed specifically for human action detection in the context of escorting. Given that escorting often occurs in crowded environments, where other individuals may enter the robot's camera view, the robot also needs to identify the specific human it is escorting (the subject) before predicting their actions. Since no existing model performs both person re-identification and action prediction in real-time, we propose a novel neural network architecture that can accomplish both tasks. This enables the robot to adjust its speed dynamically based on the escortee's movements and seamlessly resume escorting after any disruption. In comparative evaluations against strong baselines, our system demonstrates superior efficiency and effectiveness, showcasing its potential to significantly improve robotic escorting services in complex, real-world scenarios.",
    "summary": "arXiv:2506.23573v1 Announce Type: cross Abstract: The deployment of robot assistants in large indoor spaces has seen significant growth, with escorting tasks becoming a key application. However, most current escorting robots primarily rely on navigation-focused strategies, assuming that the person being escorted will follow without issue. In crowded environments, this assumption often falls short, as individuals may struggle to keep pace, become obstructed, get distracted, or need to stop unexpectedly. As a result, conventional robotic systems are often unable to provide effective escorting services due to their limited understanding of human movement dynamics. To address these challenges, an effective escorting robot must continuously detect and interpret human actions during the escorting process and adjust its movement accordingly. However, there is currently no existing dataset designed specifically for human action detection in the context of escorting. Given that escorting often occurs in crowded environments, where other individuals may enter the robot's camera view, the robot also needs to identify the specific human it is escorting (the subject) before predicting their actions. Since no existing model performs both person re-identification and action prediction in real-time, we propose a novel neural network architecture that can accomplish both tasks. This enables the robot to adjust its speed dynamically based on the escortee's movements and seamlessly resume escorting after any disruption. In comparative evaluations against strong baselines, our system demonstrates superior efficiency and effectiveness, showcasing its potential to significantly improve robotic escorting services in complex, real-world scenarios.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23573",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Cluster and Predict Latent Patches for Improved Masked Image Modeling",
    "description": "arXiv:2502.08769v3 Announce Type: replace-cross Abstract: Masked Image Modeling (MIM) offers a promising approach to self-supervised representation learning, however existing MIM models still lag behind the state-of-the-art. In this paper, we systematically analyze target representations, loss functions, and architectures, to introduce CAPI - a novel pure-MIM framework that relies on the prediction of latent clusterings. Our approach leverages a clustering-based loss, which is stable to train, and exhibits promising scaling properties. Our ViT-L backbone, CAPI, achieves 83.8% accuracy on ImageNet and 32.1% mIoU on ADE20K with simple linear probes, substantially outperforming previous MIM methods and approaching the performance of the current state-of-the-art, DINOv2. We release all our code and models.",
    "summary": "arXiv:2502.08769v3 Announce Type: replace-cross Abstract: Masked Image Modeling (MIM) offers a promising approach to self-supervised representation learning, however existing MIM models still lag behind the state-of-the-art. In this paper, we systematically analyze target representations, loss functions, and architectures, to introduce CAPI - a novel pure-MIM framework that relies on the prediction of latent clusterings. Our approach leverages a clustering-based loss, which is stable to train, and exhibits promising scaling properties. Our ViT-L backbone, CAPI, achieves 83.8% accuracy on ImageNet and 32.1% mIoU on ADE20K with simple linear probes, substantially outperforming previous MIM methods and approaching the performance of the current state-of-the-art, DINOv2. We release all our code and models.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.08769",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hybrid AI model crafts smooth, high-quality videos in seconds",
    "description": "The CausVid generative AI tool uses a diffusion model to teach an autoregressive (frame-by-frame) system to rapidly produce stable, high-resolution videos.",
    "summary": "The CausVid generative AI tool uses a diffusion model to teach an autoregressive (frame-by-frame) system to rapidly produce stable, high-resolution videos.",
    "pubDate": "Tue, 06 May 2025 12:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/causevid-hybrid-ai-model-crafts-smooth-high-quality-videos-in-seconds-0506",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-CausVid.jpg"
  },
  {
    "title": "DuckDB: run SQL queries on 50,000+ datasets on the Hugging Face Hub",
    "description": "",
    "summary": "DuckDB: run SQL queries on 50,000+ datasets on the Hugging Face Hub The Hugging Face Hub is dedicate...",
    "pubDate": "Wed, 07 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hub-duckdb",
    "thumbnail": "https://huggingface.co/blog/assets/hub_duckdb/hub_duckdb.png"
  },
  {
    "title": "OpenAI o1 Contributions",
    "description": "OpenAI o1 Contributions",
    "summary": "OpenAI o1 Contributions",
    "pubDate": "Thu, 12 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/openai-o1-contributions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An anomaly detection framework anyone can use",
    "description": "PhD student Sarah Alnegheimish wants to make machine learning systems accessible.",
    "summary": "PhD student Sarah Alnegheimish wants to make machine learning systems accessible.",
    "pubDate": "Wed, 28 May 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/anomaly-detection-framework-anyone-can-use-sarah-alnegheimish-0528",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Sarah-Abdulaziz-Alnegheimish.JPG"
  },
  {
    "title": "Testimony before the U.S. Senate",
    "description": "The following is the written testimony of Sam Altman, Chief Executive Officer of OpenAI, before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "summary": "The following is the written testimony of Sam Altman, Chief Executive Officer of OpenAI, before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/testimony-of-sam-altman-before-the-us-senate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accurately analyzing large scale qualitative data",
    "description": "Viable uses GPT-4 to analyze qualitative data at a revolutionary scale with unparalleled accuracy.",
    "summary": "Viable uses GPT-4 to analyze qualitative data at a revolutionary scale with unparalleled accuracy.",
    "pubDate": "Fri, 07 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/viable",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding and Reducing the Class-Dependent Effects of Data Augmentation with A Two-Player Game Approach",
    "description": "arXiv:2407.03146v5 Announce Type: replace-cross Abstract: Data augmentation is widely applied and has shown its benefits in different machine learning tasks. However, as recently observed, it may have an unfair effect in multi-class classification. While data augmentation generally improves the overall performance (and therefore is beneficial for many classes), it can actually be detrimental for other classes, which can be problematic in some application domains. In this paper, to counteract this phenomenon, we propose CLAM, a CLAss-dependent Multiplicative-weights method. To derive it, we first formulate the training of a classifier as a non-linear optimization problem that aims at simultaneously maximizing the individual class performances and balancing them. By rewriting this optimization problem as an adversarial two-player game, we propose a novel multiplicative weight algorithm, for which we prove the convergence. Interestingly, our formulation also reveals that the class-dependent effects of data augmentation is not due to data augmentation only, but is in fact a general phenomenon. Our empirical results over six datasets demonstrate that the performance of learned classifiers is indeed more fairly distributed over classes, with only limited impact on the average accuracy.",
    "summary": "arXiv:2407.03146v5 Announce Type: replace-cross Abstract: Data augmentation is widely applied and has shown its benefits in different machine learning tasks. However, as recently observed, it may have an unfair effect in multi-class classification. While data augmentation generally improves the overall performance (and therefore is beneficial for many classes), it can actually be detrimental for other classes, which can be problematic in some application domains. In this paper, to counteract this phenomenon, we propose CLAM, a CLAss-dependent Multiplicative-weights method. To derive it, we first formulate the training of a classifier as a non-linear optimization problem that aims at simultaneously maximizing the individual class performances and balancing them. By rewriting this optimization problem as an adversarial two-player game, we propose a novel multiplicative weight algorithm, for which we prove the convergence. Interestingly, our formulation also reveals that the class-dependent effects of data augmentation is not due to data augmentation only, but is in fact a general phenomenon. Our empirical results over six datasets demonstrate that the performance of learned classifiers is indeed more fairly distributed over classes, with only limited impact on the average accuracy.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.03146",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Test-Time Reasoning Through Visual Human Preferences with VLMs and Soft Rewards",
    "description": "arXiv:2503.19948v2 Announce Type: replace-cross Abstract: Can Visual Language Models (VLMs) effectively capture human visual preferences? This work addresses this question by training VLMs to think about preferences at test time, employing reinforcement learning methods inspired by DeepSeek R1 and OpenAI O1. Using datasets such as ImageReward and Human Preference Score v2 (HPSv2), our models achieve accuracies of 64.9% on the ImageReward test set (trained on ImageReward official split) and 65.4% on HPSv2 (trained on approximately 25% of its data). These results match traditional encoder-based models while providing transparent reasoning and enhanced generalization. This approach allows to use not only rich VLM world knowledge, but also its potential to think, yielding interpretable outcomes that help decision-making processes. By demonstrating that human visual preferences reasonable by current VLMs, we introduce efficient soft-reward strategies for image ranking, outperforming simplistic selection or scoring methods. This reasoning capability enables VLMs to rank arbitrary images-regardless of aspect ratio or complexity-thereby potentially amplifying the effectiveness of visual Preference Optimization. By reducing the need for extensive markup while improving reward generalization and explainability, our findings can be a strong mile-stone that will enhance text-to-vision models even further.",
    "summary": "arXiv:2503.19948v2 Announce Type: replace-cross Abstract: Can Visual Language Models (VLMs) effectively capture human visual preferences? This work addresses this question by training VLMs to think about preferences at test time, employing reinforcement learning methods inspired by DeepSeek R1 and OpenAI O1. Using datasets such as ImageReward and Human Preference Score v2 (HPSv2), our models achieve accuracies of 64.9% on the ImageReward test set (trained on ImageReward official split) and 65.4% on HPSv2 (trained on approximately 25% of its data). These results match traditional encoder-based models while providing transparent reasoning and enhanced generalization. This approach allows to use not only rich VLM world knowledge, but also its potential to think, yielding interpretable outcomes that help decision-making processes. By demonstrating that human visual preferences reasonable by current VLMs, we introduce efficient soft-reward strategies for image ranking, outperforming simplistic selection or scoring methods. This reasoning capability enables VLMs to rank arbitrary images-regardless of aspect ratio or complexity-thereby potentially amplifying the effectiveness of visual Preference Optimization. By reducing the need for extensive markup while improving reward generalization and explainability, our findings can be a strong mile-stone that will enhance text-to-vision models even further.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.19948",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Running Privacy-Preserving Inference on Hugging Face Endpoints",
    "description": "",
    "summary": "Running Privacy-Preserving Inferences on Hugging Face Endpoints This is a guest blog post by the Zam...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fhe-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/fhe-endpoints/thumbnail.png"
  },
  {
    "title": "Using & Mixing Hugging Face Models with Gradio 2.0",
    "description": "",
    "summary": "Using & Mixing Hugging Face Models with Gradio 2.0 Cross-posted from the Gradio blog. The Hugging Fa...",
    "pubDate": "Tue, 25 May 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio",
    "thumbnail": "https://huggingface.co/blog/assets/22_gradio/gradio.png"
  },
  {
    "title": "Overview of natively supported quantization schemes in ü§ó Transformers",
    "description": "",
    "summary": "Overview of natively supported quantization schemes in ü§ó Transformers We aim to give a clear overvie...",
    "pubDate": "Tue, 12 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/overview-quantization-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/163_overview_quantization_transformers/thumbnail.jpg"
  },
  {
    "title": "MIT Department of Economics to launch James M. and Cathleen D. Stone Center on Inequality and Shaping the Future of Work",
    "description": "With support from the Stone Foundation, the center will advance cutting-edge research and inform policy.",
    "summary": "With support from the Stone Foundation, the center will advance cutting-edge research and inform policy.",
    "pubDate": "Tue, 13 May 2025 16:35:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-economics-department-launches-james-cathleen-stone-center-inequality-shaping-future-work-0513",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-campus.jpg"
  },
  {
    "title": "OpenAI‚Äôs Approach to Frontier Risk",
    "description": "An Update for the UK AI Safety Summit",
    "summary": "An Update for the UK AI Safety Summit",
    "pubDate": "Thu, 26 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/our-approach-to-frontier-risk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "UK government harnesses Gemini to support faster planning decisions",
    "description": "A summary of how Extract works",
    "summary": "A summary of how Extract works",
    "pubDate": "Mon, 09 Jun 2025 11:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/around-the-globe/google-europe/united-kingdom/uk-government-harnesses-gemini-to-support-faster-planning-decisions/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/overview.width-1300.png"
  },
  {
    "title": "Response to NIST Executive Order on AI",
    "description": "The National Institute of Standards and Technology (NIST) request for information related to its assignments under sections 4.1, 4.5, and 11 of the Executive Order Concerning Artificial Intelligence",
    "summary": "The National Institute of Standards and Technology (NIST) request for information related to its assignments under sections 4.1, 4.5, and 11 of the Executive Order Concerning Artificial Intelligence",
    "pubDate": "Fri, 02 Feb 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-nist-executive-order-on-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MIT‚Äôs McGovern Institute is shaping brain science and improving human lives on a global scale",
    "description": "A quarter century after its founding, the McGovern Institute reflects on its discoveries in the areas of neuroscience, neurotechnology, artificial intelligence, brain-body connections, and therapeutics.",
    "summary": "A quarter century after its founding, the McGovern Institute reflects on its discoveries in the areas of neuroscience, neurotechnology, artificial intelligence, brain-body connections, and therapeutics.",
    "pubDate": "Fri, 18 Apr 2025 10:40:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-mcgovern-institute-shaping-brain-science-improving-human-lives-0418",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-mcgovern-madonna-fmri-600x900.jpg"
  },
  {
    "title": "Quantum Neural Networks for Wind Energy Forecasting: A Comparative Study of Performance and Scalability with Classical Models",
    "description": "arXiv:2506.22845v1 Announce Type: cross Abstract: Quantum Neural Networks (QNNs), a prominent approach in Quantum Machine Learning (QML), are emerging as a powerful alternative to classical machine learning methods. Recent studies have focused on the applicability of QNNs to various tasks, such as time-series forecasting, prediction, and classification, across a wide range of applications, including cybersecurity and medical imaging. With the increased use of smart grids driven by the integration of renewable energy systems, machine learning plays an important role in predicting power demand and detecting system disturbances. This study provides an in-depth investigation of QNNs for predicting the power output of a wind turbine. We assess the predictive performance and simulation time of six QNN configurations that are based on the Z Feature Map for data encoding and varying ansatz structures. Through detailed cross-validation experiments and tests on an unseen hold-out dataset, we experimentally demonstrate that QNNs can achieve predictive performance that is competitive with, and in some cases marginally better than, the benchmarked classical approaches. Our results also reveal the effects of dataset size and circuit complexity on predictive performance and simulation time. We believe our findings will offer valuable insights for researchers in the energy domain who wish to incorporate quantum machine learning into their work.",
    "summary": "arXiv:2506.22845v1 Announce Type: cross Abstract: Quantum Neural Networks (QNNs), a prominent approach in Quantum Machine Learning (QML), are emerging as a powerful alternative to classical machine learning methods. Recent studies have focused on the applicability of QNNs to various tasks, such as time-series forecasting, prediction, and classification, across a wide range of applications, including cybersecurity and medical imaging. With the increased use of smart grids driven by the integration of renewable energy systems, machine learning plays an important role in predicting power demand and detecting system disturbances. This study provides an in-depth investigation of QNNs for predicting the power output of a wind turbine. We assess the predictive performance and simulation time of six QNN configurations that are based on the Z Feature Map for data encoding and varying ansatz structures. Through detailed cross-validation experiments and tests on an unseen hold-out dataset, we experimentally demonstrate that QNNs can achieve predictive performance that is competitive with, and in some cases marginally better than, the benchmarked classical approaches. Our results also reveal the effects of dataset size and circuit complexity on predictive performance and simulation time. We believe our findings will offer valuable insights for researchers in the energy domain who wish to incorporate quantum machine learning into their work.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22845",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Securing Research Infrastructure for Advanced AI",
    "description": "We outline our architecture that supports the secure training of frontier models.",
    "summary": "We outline our architecture that supports the secure training of frontier models.",
    "pubDate": "Wed, 05 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/securing-research-infrastructure-for-advanced-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI API",
    "description": "We‚Äôre releasing an API for accessing new AI models developed by OpenAI.",
    "summary": "We‚Äôre releasing an API for accessing new AI models developed by OpenAI.",
    "pubDate": "Thu, 11 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From DeepSpeed to FSDP and Back Again with Hugging Face Accelerate",
    "description": "",
    "summary": "A Hugging Face Accelerate Story of Multiple Backends: FSDP and DeepSpeed There are two popular imple...",
    "pubDate": "Thu, 13 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deepspeed-to-fsdp-and-back",
    "thumbnail": "https://huggingface.co/blog/assets/deepspeed-to-fsdp-and-back/thumbnail.png"
  },
  {
    "title": "TTS Arena: Benchmarking Text-to-Speech Models in the Wild",
    "description": "",
    "summary": "TTS Arena: Benchmarking Text-to-Speech Models in the Wild Automated measurement of the quality of te...",
    "pubDate": "Tue, 27 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-tts",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail.png"
  },
  {
    "title": "AI for Game Development: Creating a Farming Game in 5 Days. Part 1",
    "description": "",
    "summary": "AI for Game Development: Creating a Farming Game in 5 Days. Part 1 Welcome to AI for Game Developmen...",
    "pubDate": "Mon, 02 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-1",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail.png"
  },
  {
    "title": "Gemini CLI: your open-source AI agent",
    "description": "Gemini CLI icon on a background with code snippets",
    "summary": "Gemini CLI icon on a background with code snippets",
    "pubDate": "Wed, 25 Jun 2025 13:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_CLI_Hero_Final.width-1300.png"
  },
  {
    "title": "Director of Machine Learning Insights [Part 3: Finance Edition]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 3: Finance Edition] If you're interested in building ML ...",
    "pubDate": "Tue, 14 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-3",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/thumbnail.png"
  },
  {
    "title": "Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models",
    "description": "arXiv:2506.23678v1 Announce Type: cross Abstract: The output quality of large language models (LLMs) can be improved via 'reasoning': generating segments of chain-of-thought (CoT) content to further condition the model prior to producing user-facing output. While these chains contain valuable information, they are verbose and lack explicit organization, making them tedious to review. Moreover, they lack opportunities for user feedback, such as to remove unwanted considerations, add desired ones, or clarify unclear assumptions. We introduce Interactive Reasoning, an interaction design that visualizes chain-of-thought outputs as a hierarchy of topics and enables user review and modification. We implement interactive reasoning in Hippo, a prototype for AI-assisted decision making in the face of uncertain trade-offs. In a user study with 16 participants, we find that interactive reasoning in Hippo allows users to quickly identify and interrupt erroneous generations, efficiently steer the model towards customized responses, and better understand both model reasoning and model outputs. Our work contributes to a new paradigm that incorporates user oversight into LLM reasoning processes.",
    "summary": "arXiv:2506.23678v1 Announce Type: cross Abstract: The output quality of large language models (LLMs) can be improved via 'reasoning': generating segments of chain-of-thought (CoT) content to further condition the model prior to producing user-facing output. While these chains contain valuable information, they are verbose and lack explicit organization, making them tedious to review. Moreover, they lack opportunities for user feedback, such as to remove unwanted considerations, add desired ones, or clarify unclear assumptions. We introduce Interactive Reasoning, an interaction design that visualizes chain-of-thought outputs as a hierarchy of topics and enables user review and modification. We implement interactive reasoning in Hippo, a prototype for AI-assisted decision making in the face of uncertain trade-offs. In a user study with 16 participants, we find that interactive reasoning in Hippo allows users to quickly identify and interrupt erroneous generations, efficiently steer the model towards customized responses, and better understand both model reasoning and model outputs. Our work contributes to a new paradigm that incorporates user oversight into LLM reasoning processes.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23678",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "KnowSafe: Combined Knowledge and Data Driven Hazard Mitigation in Artificial Pancreas Systems",
    "description": "arXiv:2311.07460v2 Announce Type: replace-cross Abstract: Significant progress has been made in anomaly detection and run-time monitoring to improve the safety and security of cyber-physical systems (CPS). However, less attention has been paid to hazard mitigation. This paper proposes a combined knowledge and data driven approach, KnowSafe, for the design of safety engines that can predict and mitigate safety hazards resulting from safety-critical malicious attacks or accidental faults targeting a CPS controller. We integrate domain-specific knowledge of safety constraints and context-specific mitigation actions with machine learning (ML) techniques to estimate system trajectories in the far and near future, infer potential hazards, and generate optimal corrective actions to keep the system safe. Experimental evaluation on two realistic closed-loop testbeds for artificial pancreas systems (APS) and a real-world clinical trial dataset for diabetes treatment demonstrates that KnowSafe outperforms the state-of-the-art by achieving higher accuracy in predicting system state trajectories and potential hazards, a low false positive rate, and no false negatives. It also maintains the safe operation of the simulated APS despite faults or attacks without introducing any new hazards, with a hazard mitigation success rate of 92.8%, which is at least 76% higher than solely rule-based (50.9%) and data-driven (52.7%) methods.",
    "summary": "arXiv:2311.07460v2 Announce Type: replace-cross Abstract: Significant progress has been made in anomaly detection and run-time monitoring to improve the safety and security of cyber-physical systems (CPS). However, less attention has been paid to hazard mitigation. This paper proposes a combined knowledge and data driven approach, KnowSafe, for the design of safety engines that can predict and mitigate safety hazards resulting from safety-critical malicious attacks or accidental faults targeting a CPS controller. We integrate domain-specific knowledge of safety constraints and context-specific mitigation actions with machine learning (ML) techniques to estimate system trajectories in the far and near future, infer potential hazards, and generate optimal corrective actions to keep the system safe. Experimental evaluation on two realistic closed-loop testbeds for artificial pancreas systems (APS) and a real-world clinical trial dataset for diabetes treatment demonstrates that KnowSafe outperforms the state-of-the-art by achieving higher accuracy in predicting system state trajectories and potential hazards, a low false positive rate, and no false negatives. It also maintains the safe operation of the simulated APS despite faults or attacks without introducing any new hazards, with a hazard mitigation success rate of 92.8%, which is at least 76% higher than solely rule-based (50.9%) and data-driven (52.7%) methods.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2311.07460",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Economic impacts research at OpenAI",
    "description": "Call for expressions of interest to study the economic impacts of large language¬†models.",
    "summary": "Call for expressions of interest to study the economic impacts of large language¬†models.",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/economic-impacts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "General Autonomous Cybersecurity Defense: Learning Robust Policies for Dynamic Topologies and Diverse Attackers",
    "description": "arXiv:2506.22706v1 Announce Type: cross Abstract: In the face of evolving cyber threats such as malware, ransomware and phishing, autonomous cybersecurity defense (ACD) systems have become essential for real-time threat detection and response with optional human intervention. However, existing ACD systems rely on limiting assumptions, particularly the stationarity of the underlying network dynamics. In real-world scenarios, network topologies can change due to actions taken by attackers or defenders, system failures, or time evolution of networks, leading to failures in the adaptive capabilities of current defense agents. Moreover, many agents are trained on static environments, resulting in overfitting to specific topologies, which hampers their ability to generalize to out-of-distribution network topologies. This work addresses these challenges by exploring methods for developing agents to learn generalizable policies across dynamic network environments -- general ACD (GACD).",
    "summary": "arXiv:2506.22706v1 Announce Type: cross Abstract: In the face of evolving cyber threats such as malware, ransomware and phishing, autonomous cybersecurity defense (ACD) systems have become essential for real-time threat detection and response with optional human intervention. However, existing ACD systems rely on limiting assumptions, particularly the stationarity of the underlying network dynamics. In real-world scenarios, network topologies can change due to actions taken by attackers or defenders, system failures, or time evolution of networks, leading to failures in the adaptive capabilities of current defense agents. Moreover, many agents are trained on static environments, resulting in overfitting to specific topologies, which hampers their ability to generalize to out-of-distribution network topologies. This work addresses these challenges by exploring methods for developing agents to learn generalizable policies across dynamic network environments -- general ACD (GACD).",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22706",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "‚ÄúPeriodic table of machine learning‚Äù could fuel AI discovery",
    "description": "Researchers have created a unifying framework that can help scientists combine existing ideas to improve AI models or create new ones.",
    "summary": "Researchers have created a unifying framework that can help scientists combine existing ideas to improve AI models or create new ones.",
    "pubDate": "Wed, 23 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/machine-learning-periodic-table-could-fuel-ai-discovery-0423",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Periodic-Algorithm-01-PRESS.jpg"
  },
  {
    "title": "EliseAI improves housing and healthcare efficiency with AI",
    "description": "A conversation with Minna Song, CEO & Co-founder of EliseAI.",
    "summary": "A conversation with Minna Song, CEO & Co-founder of EliseAI.",
    "pubDate": "Tue, 18 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/eliseai-minna-song",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New generative AI tools open the doors of music creation",
    "description": "Our latest AI music technologies are now available in MusicFX DJ, Music AI Sandbox and YouTube Shorts",
    "summary": "Our latest AI music technologies are now available in MusicFX DJ, Music AI Sandbox and YouTube Shorts",
    "pubDate": "Wed, 23 Oct 2024 16:53:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/new-generative-ai-tools-open-the-doors-of-music-creation/",
    "thumbnail": "https://lh3.googleusercontent.com/7CWJ9fVeC97FrWgcispxyms9gTL_1PIDMIwBYTQNnU8S56JaxGB2Z4ThqZ-1vBTO-u-UBZg_cYhG8PtZjYP0rPabUbg5x2cCUnNJuiZAZBsE8u7Kvig=w1200-h630-n-nu"
  },
  {
    "title": "FastRTC: The Real-Time Communication Library for Python",
    "description": "",
    "summary": "FastRTC: The Real-Time Communication Library for Python In the last few months, many new real-time s...",
    "pubDate": "Tue, 25 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastrtc",
    "thumbnail": "https://huggingface.co/blog/assets/fastrtc/fastrtc_logo.jpg"
  },
  {
    "title": "Bamba: Inference-Efficient Hybrid Mamba2 Model",
    "description": "",
    "summary": "Bamba: Inference-Efficient Hybrid Mamba2 Model üêç TL;DR We introduce Bamba-9B, an inference-efficient...",
    "pubDate": "Wed, 18 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bamba",
    "thumbnail": "https://huggingface.co/blog/assets/bamba/bamba_thumbnail.png"
  },
  {
    "title": "Accelerating engineering cycles 20% with OpenAI",
    "description": "Accelerating engineering cycles 20% with OpenAI.",
    "summary": "Accelerating engineering cycles 20% with OpenAI.",
    "pubDate": "Thu, 06 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/factory",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pairing data with APIs to unlock customer value",
    "description": "Rakuten Pairs Data with AI to Unlock Customer Insights and Value",
    "summary": "Rakuten Pairs Data with AI to Unlock Customer Insights and Value",
    "pubDate": "Wed, 07 Aug 2024 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rakuten",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI technical goals",
    "description": "OpenAI‚Äôs mission is to build safe AI, and ensure AI‚Äôs benefits are as widely and evenly distributed as possible.",
    "summary": "OpenAI‚Äôs mission is to build safe AI, and ensure AI‚Äôs benefits are as widely and evenly distributed as possible.",
    "pubDate": "Mon, 20 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-technical-goals",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Updating the Frontier Safety Framework",
    "description": "Our next iteration of the FSF sets out stronger security protocols on the path to AGI",
    "summary": "Our next iteration of the FSF sets out stronger security protocols on the path to AGI",
    "pubDate": "Tue, 04 Feb 2025 16:41:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/updating-the-frontier-safety-framework/",
    "thumbnail": "https://lh3.googleusercontent.com/0fu18H8X3miSAuwcVJ7Zulis_LZAL7F4bIFU7FYFA2dGx3Rm3HHlm5N202B0dtKBuS7iI5SD1QgpFPuU-O3TPzb7iG1Ns-loZzinRB3M3X3W-MAgIQ=w1200-h630-n-nu"
  },
  {
    "title": "New embedding models and API updates",
    "description": "We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management tools, and soon, lower pricing on GPT-3.5 Turbo.",
    "summary": "We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management tools, and soon, lower pricing on GPT-3.5 Turbo.",
    "pubDate": "Thu, 25 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-embedding-models-and-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An Introduction to AI Secure LLM Safety Leaderboard",
    "description": "",
    "summary": "An Introduction to AI Secure LLM Safety Leaderboard Given the widespread adoption of LLMs, it is cri...",
    "pubDate": "Fri, 26 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-decodingtrust",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_decodingtrust.png"
  },
  {
    "title": "NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics",
    "description": "arXiv:2411.07186v2 Announce Type: replace-cross Abstract: Large language models (LLMs) prompted with text and audio have achieved state-of-the-art performance across various auditory tasks, including speech, music, and general audio, showing emergent abilities on unseen tasks. However, their potential has yet to be fully demonstrated in bioacoustics tasks, such as detecting animal vocalizations in large recordings, classifying rare and endangered species, and labeling context and behavior -- tasks that are crucial for conservation, biodiversity monitoring, and animal behavior studies. In this work, we present NatureLM-audio, the first audio-language foundation model specifically designed for bioacoustics. Our training dataset consists of carefully curated text-audio pairs spanning bioacoustics, speech, and music, designed to address the field's limited availability of annotated data. We demonstrate successful transfer of learned representations from music and speech to bioacoustics, and our model shows promising generalization to unseen taxa and tasks. We evaluate NatureLM-audio on a novel benchmark (BEANS-Zero) and it sets a new state of the art on several bioacoustics tasks, including zero-shot classification of unseen species. To advance bioacoustics research, we release our model weights, benchmark data, and open-source the code for training and benchmark data generation and model training.",
    "summary": "arXiv:2411.07186v2 Announce Type: replace-cross Abstract: Large language models (LLMs) prompted with text and audio have achieved state-of-the-art performance across various auditory tasks, including speech, music, and general audio, showing emergent abilities on unseen tasks. However, their potential has yet to be fully demonstrated in bioacoustics tasks, such as detecting animal vocalizations in large recordings, classifying rare and endangered species, and labeling context and behavior -- tasks that are crucial for conservation, biodiversity monitoring, and animal behavior studies. In this work, we present NatureLM-audio, the first audio-language foundation model specifically designed for bioacoustics. Our training dataset consists of carefully curated text-audio pairs spanning bioacoustics, speech, and music, designed to address the field's limited availability of annotated data. We demonstrate successful transfer of learned representations from music and speech to bioacoustics, and our model shows promising generalization to unseen taxa and tasks. We evaluate NatureLM-audio on a novel benchmark (BEANS-Zero) and it sets a new state of the art on several bioacoustics tasks, including zero-shot classification of unseen species. To advance bioacoustics research, we release our model weights, benchmark data, and open-source the code for training and benchmark data generation and model training.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.07186",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face models in Amazon Bedrock",
    "description": "",
    "summary": "Use Hugging Face models with Amazon Bedrock We are excited to announce that popular open models from...",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bedrock-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/bedrock-marketplace/thumbnail.png"
  },
  {
    "title": "An Overview of Inference Solutions on Hugging Face",
    "description": "",
    "summary": "An Overview of Inference Solutions on Hugging Face Every day, developers and organizations are adopt...",
    "pubDate": "Mon, 21 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-update",
    "thumbnail": "https://huggingface.co/blog/assets/116_inference_update/widget.png"
  },
  {
    "title": "Images altered to trick machine vision can influence humans too",
    "description": "In a series of experiments published in Nature Communications, we found evidence that human judgments are indeed systematically influenced by adversarial perturbations.",
    "summary": "In a series of experiments published in Nature Communications, we found evidence that human judgments are indeed systematically influenced by adversarial perturbations.",
    "pubDate": "Tue, 02 Jan 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/images-altered-to-trick-machine-vision-can-influence-humans-too/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "Understanding the source of what we see and hear online",
    "description": "Today we‚Äôre introducing new technology to help researchers identify content created by our tools and joining the Coalition for Content Provenance and Authenticity Steering Committee to promote industry standards.",
    "summary": "Today we‚Äôre introducing new technology to help researchers identify content created by our tools and joining the Coalition for Content Provenance and Authenticity Steering Committee to promote industry standards.",
    "pubDate": "Tue, 07 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/understanding-the-source-of-what-we-see-and-hear-online",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Expanded access to Google Vids and no-cost AI tools in Classroom",
    "description": "Google Meet icon, Google Classroom icon, with various browser windows",
    "summary": "Google Meet icon, Google Classroom icon, with various browser windows",
    "pubDate": "Mon, 30 Jun 2025 13:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/education/expanded-access-to-google-vids-and-no-cost-ai-tools-in-classroom/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/027-ISTE-EDU-Keyword_blog-Google_Workspace_fo.width-1300.png"
  },
  {
    "title": "Hugging Face Collaborates with Microsoft to Launch Hugging Face Model Catalog on Azure",
    "description": "",
    "summary": "Hugging Face Collaborates with Microsoft to launch Hugging Face Model Catalog on Azure Today, we are...",
    "pubDate": "Wed, 24 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-endpoints-on-azure",
    "thumbnail": "https://huggingface.co/blog/assets/75_hugging_face_endpoints_on_azure/01.jpg"
  },
  {
    "title": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "description": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "summary": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "pubDate": "Tue, 22 Oct 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-chief-compliance-officer-announcement",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Vision Language Models (Better, Faster, Stronger)",
    "description": "",
    "summary": "Vision Language Models (Better, Faster, Stronger) Motivation Vision Language Models (VLMs) are the t...",
    "pubDate": "Mon, 12 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vlms-2025",
    "thumbnail": "https://huggingface.co/blog/assets/vlms2/vlms2.png"
  },
  {
    "title": "TOMI: Transforming and Organizing Music Ideas for Multi-Track Compositions with Full-Song Structure",
    "description": "arXiv:2506.23094v1 Announce Type: cross Abstract: Hierarchical planning is a powerful approach to model long sequences structurally. Aside from considering hierarchies in the temporal structure of music, this paper explores an even more important aspect: concept hierarchy, which involves generating music ideas, transforming them, and ultimately organizing them--across musical time and space--into a complete composition. To this end, we introduce TOMI (Transforming and Organizing Music Ideas) as a novel approach in deep music generation and develop a TOMI-based model via instruction-tuned foundation LLM. Formally, we represent a multi-track composition process via a sparse, four-dimensional space characterized by clips (short audio or MIDI segments), sections (temporal positions), tracks (instrument layers), and transformations (elaboration methods). Our model is capable of generating multi-track electronic music with full-song structure, and we further integrate the TOMI-based model with the REAPER digital audio workstation, enabling interactive human-AI co-creation. Experimental results demonstrate that our approach produces higher-quality electronic music with stronger structural coherence compared to baselines.",
    "summary": "arXiv:2506.23094v1 Announce Type: cross Abstract: Hierarchical planning is a powerful approach to model long sequences structurally. Aside from considering hierarchies in the temporal structure of music, this paper explores an even more important aspect: concept hierarchy, which involves generating music ideas, transforming them, and ultimately organizing them--across musical time and space--into a complete composition. To this end, we introduce TOMI (Transforming and Organizing Music Ideas) as a novel approach in deep music generation and develop a TOMI-based model via instruction-tuned foundation LLM. Formally, we represent a multi-track composition process via a sparse, four-dimensional space characterized by clips (short audio or MIDI segments), sections (temporal positions), tracks (instrument layers), and transformations (elaboration methods). Our model is capable of generating multi-track electronic music with full-song structure, and we further integrate the TOMI-based model with the REAPER digital audio workstation, enabling interactive human-AI co-creation. Experimental results demonstrate that our approach produces higher-quality electronic music with stronger structural coherence compared to baselines.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23094",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Opinion Classification with Kili and HuggingFace AutoTrain",
    "description": "",
    "summary": "Opinion Classification with Kili and HuggingFace AutoTrain Introduction Understanding your users‚Äô ne...",
    "pubDate": "Thu, 28 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/opinion-classification-with-kili",
    "thumbnail": "https://huggingface.co/blog/assets/59_opinion-classification-with-kili/thumbnail.png"
  },
  {
    "title": "Why we‚Äôre switching to Hugging Face Inference Endpoints, and maybe you should too",
    "description": "",
    "summary": "Why we‚Äôre switching to Hugging Face Inference Endpoints, and maybe you should too Hugging Face recen...",
    "pubDate": "Wed, 15 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mantis-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/mantis1.png"
  },
  {
    "title": "Rocket Money x Hugging Face: Scaling Volatile ML Models in Production",
    "description": "",
    "summary": "Rocket Money x Hugging Face: Scaling Volatile ML Models in Production 'We discovered that they were ...",
    "pubDate": "Tue, 19 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rocketmoney-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/rocketmoney.png"
  },
  {
    "title": "Liftoff! How to get started with your first ML project üöÄ",
    "description": "",
    "summary": "Liftoff! How to get started with your first ML project üöÄ People who are new to the Machine Learning ...",
    "pubDate": "Wed, 29 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/your-first-ml-project",
    "thumbnail": "https://huggingface.co/blog/assets/84_first_ml_project/thumbnail.png"
  },
  {
    "title": "Creating websites in minutes with AI Website Builder",
    "description": "Wix‚Äôs AI Website Builder, powered by OpenAI, lets anyone create a full website in minutes‚Äîjust by describing their idea in a conversation.",
    "summary": "Wix‚Äôs AI Website Builder, powered by OpenAI, lets anyone create a full website in minutes‚Äîjust by describing their idea in a conversation.",
    "pubDate": "Thu, 29 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/wix",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating Agents using Social Choice Theory",
    "description": "arXiv:2312.03121v4 Announce Type: replace Abstract: We argue that many general evaluation problems can be viewed through the lens of voting theory. Each task is interpreted as a separate voter, which requires only ordinal rankings or pairwise comparisons of agents to produce an overall evaluation. By viewing the aggregator as a social welfare function, we are able to leverage centuries of research in social choice theory to derive principled evaluation frameworks with axiomatic foundations. These evaluations are interpretable and flexible, while avoiding many of the problems currently facing cross-task evaluation. We apply this Voting-as-Evaluation (VasE) framework across multiple settings, including reinforcement learning, large language models, and humans. In practice, we observe that VasE can be more robust than popular evaluation frameworks (Elo and Nash averaging), discovers properties in the evaluation data not evident from scores alone, and can predict outcomes better than Elo in a complex seven-player game. We identify one particular approach, maximal lotteries, that satisfies important consistency properties relevant to evaluation, is computationally efficient (polynomial in the size of the evaluation data), and identifies game-theoretic cycles.",
    "summary": "arXiv:2312.03121v4 Announce Type: replace Abstract: We argue that many general evaluation problems can be viewed through the lens of voting theory. Each task is interpreted as a separate voter, which requires only ordinal rankings or pairwise comparisons of agents to produce an overall evaluation. By viewing the aggregator as a social welfare function, we are able to leverage centuries of research in social choice theory to derive principled evaluation frameworks with axiomatic foundations. These evaluations are interpretable and flexible, while avoiding many of the problems currently facing cross-task evaluation. We apply this Voting-as-Evaluation (VasE) framework across multiple settings, including reinforcement learning, large language models, and humans. In practice, we observe that VasE can be more robust than popular evaluation frameworks (Elo and Nash averaging), discovers properties in the evaluation data not evident from scores alone, and can predict outcomes better than Elo in a complex seven-player game. We identify one particular approach, maximal lotteries, that satisfies important consistency properties relevant to evaluation, is computationally efficient (polynomial in the size of the evaluation data), and identifies game-theoretic cycles.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2312.03121",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Efficiently Serving Large Multimodal Models Using EPD Disaggregation",
    "description": "arXiv:2501.05460v4 Announce Type: replace-cross Abstract: Large Multimodal Models (LMMs) extend Large Language Models (LLMs) by handling diverse inputs such as images, audio, and video, but at the cost of adding a multimodal encoding stage that increases both computational and memory overhead. This step negatively affects key Service Level Objectives (SLOs), such as time to first token (TTFT) and time per output token (TPOT). We introduce Encode-Prefill-Decode (EPD) Disaggregation, a novel framework that separates the encoding, prefill, and decode stages onto dedicated resources. Unlike current systems, which bundle encoding and prefill together, our approach decouples these steps, unlocking new opportunities and optimizations. These include a mechanism to cache multimedia tokens for efficient transfer, a novel way to parallelize the encoding load within a request, a module for optimal resource allocation for disaggregated serving, and a novel role-switching method to handle changing workload characteristics. Experimental evaluations with popular LMMs show substantial gains in memory efficiency (up to 15x lower peak memory utilization), batch sizes (up to 22x larger), 10x more images per request, and 2.2x larger KV caches. Furthermore, it leads to significant improvements in SLO attainment (up to 90-100% improvement) and TTFT (up to 71% reduction), compared to systems that do not disaggregate. The code is available at https://github.com/vbdi/epdserve.",
    "summary": "arXiv:2501.05460v4 Announce Type: replace-cross Abstract: Large Multimodal Models (LMMs) extend Large Language Models (LLMs) by handling diverse inputs such as images, audio, and video, but at the cost of adding a multimodal encoding stage that increases both computational and memory overhead. This step negatively affects key Service Level Objectives (SLOs), such as time to first token (TTFT) and time per output token (TPOT). We introduce Encode-Prefill-Decode (EPD) Disaggregation, a novel framework that separates the encoding, prefill, and decode stages onto dedicated resources. Unlike current systems, which bundle encoding and prefill together, our approach decouples these steps, unlocking new opportunities and optimizations. These include a mechanism to cache multimedia tokens for efficient transfer, a novel way to parallelize the encoding load within a request, a module for optimal resource allocation for disaggregated serving, and a novel role-switching method to handle changing workload characteristics. Experimental evaluations with popular LMMs show substantial gains in memory efficiency (up to 15x lower peak memory utilization), batch sizes (up to 22x larger), 10x more images per request, and 2.2x larger KV caches. Furthermore, it leads to significant improvements in SLO attainment (up to 90-100% improvement) and TTFT (up to 71% reduction), compared to systems that do not disaggregate. The code is available at https://github.com/vbdi/epdserve.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.05460",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Benchmarking Language Model Performance on 5th Gen Xeon at GCP",
    "description": "",
    "summary": "Benchmarking Language Model Performance on 5th Gen Xeon at GCP TL;DR: We benchmark 2 representative ...",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-gcp-c4",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Introduction to the Open Leaderboard for Japanese LLMs",
    "description": "",
    "summary": "Introduction to the Open Leaderboard for Japanese LLMs LLMs are now increasingly capable in English,...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-japanese",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_japanese.png"
  },
  {
    "title": "What can large language models do for sustainable food?",
    "description": "arXiv:2503.04734v2 Announce Type: replace-cross Abstract: Food systems are responsible for a third of human-caused greenhouse gas emissions. We investigate what Large Language Models (LLMs) can contribute to reducing the environmental impacts of food production. We define a typology of design and prediction tasks based on the sustainable food literature and collaboration with domain experts, and evaluate six LLMs on four tasks in our typology. For example, for a sustainable protein design task, food science experts estimated that collaboration with an LLM can reduce time spent by 45% on average, compared to 22% for collaboration with another expert human food scientist. However, for a sustainable menu design task, LLMs produce suboptimal solutions when instructed to consider both human satisfaction and climate impacts. We propose a general framework for integrating LLMs with combinatorial optimization to improve reasoning capabilities. Our approach decreases emissions of food choices by 79% in a hypothetical restaurant while maintaining participants' satisfaction with their set of choices. Our results demonstrate LLMs' potential, supported by optimization techniques, to accelerate sustainable food development and adoption.",
    "summary": "arXiv:2503.04734v2 Announce Type: replace-cross Abstract: Food systems are responsible for a third of human-caused greenhouse gas emissions. We investigate what Large Language Models (LLMs) can contribute to reducing the environmental impacts of food production. We define a typology of design and prediction tasks based on the sustainable food literature and collaboration with domain experts, and evaluate six LLMs on four tasks in our typology. For example, for a sustainable protein design task, food science experts estimated that collaboration with an LLM can reduce time spent by 45% on average, compared to 22% for collaboration with another expert human food scientist. However, for a sustainable menu design task, LLMs produce suboptimal solutions when instructed to consider both human satisfaction and climate impacts. We propose a general framework for integrating LLMs with combinatorial optimization to improve reasoning capabilities. Our approach decreases emissions of food choices by 79% in a hypothetical restaurant while maintaining participants' satisfaction with their set of choices. Our results demonstrate LLMs' potential, supported by optimization techniques, to accelerate sustainable food development and adoption.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.04734",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Course Launch Community Event",
    "description": "",
    "summary": "Course Launch Community Event We are excited to share that after a lot of work from the Hugging Face...",
    "pubDate": "Tue, 26 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/course-launch-event",
    "thumbnail": "https://huggingface.co/blog/assets/34_course_launch/speakers_day1_thumb.png"
  },
  {
    "title": "Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime",
    "description": "arXiv:2506.24120v1 Announce Type: cross Abstract: Data selection plays a crucial role in data-driven decision-making, including in large language models (LLMs), and is typically task-dependent. Properties such as data quality and diversity have been extensively studied and are known to enhance model performance. However, it remains unclear whether there exist other quantitative and general principles of data selection that can consistently improve performance, especially for complex tasks with limited prior knowledge. In this paper, we demonstrate that selecting more uniformly distributed data can improve training efficiency while enhancing performance. Specifically, we establish that more uniform (less biased) distribution leads to a larger minimum pairwise distance between data points, denoted by $h_{min}$, and prove that a smaller $h_{min}$ can slow down the training dynamics of gradient descent (GD). Moreover, we theoretically show that the approximation error of neural networks decreases as $h_{min}$ increases. Our analysis introduces a convergence framework for GD beyond the Neural Tangent Kernel (NTK) regime, applicable to a broad class of architectures, including transformers, without requiring Lipschitz smoothness. This framework further provides theoretical justification for the use of residual connections and function compositions in deep neural architectures. In the end, we conduct comprehensive experiments for supervised fine-tuning across various settings, including different optimization strategies, model sizes, and training datasets. The results consistently demonstrate that selecting data by maximizing pairwise distance significantly accelerates training and achieves comparable or better performance in LLMs across diverse datasets. Code and Datasets are available at the link: https://github.com/SafeRL-Lab/data-uniformity.",
    "summary": "arXiv:2506.24120v1 Announce Type: cross Abstract: Data selection plays a crucial role in data-driven decision-making, including in large language models (LLMs), and is typically task-dependent. Properties such as data quality and diversity have been extensively studied and are known to enhance model performance. However, it remains unclear whether there exist other quantitative and general principles of data selection that can consistently improve performance, especially for complex tasks with limited prior knowledge. In this paper, we demonstrate that selecting more uniformly distributed data can improve training efficiency while enhancing performance. Specifically, we establish that more uniform (less biased) distribution leads to a larger minimum pairwise distance between data points, denoted by $h_{min}$, and prove that a smaller $h_{min}$ can slow down the training dynamics of gradient descent (GD). Moreover, we theoretically show that the approximation error of neural networks decreases as $h_{min}$ increases. Our analysis introduces a convergence framework for GD beyond the Neural Tangent Kernel (NTK) regime, applicable to a broad class of architectures, including transformers, without requiring Lipschitz smoothness. This framework further provides theoretical justification for the use of residual connections and function compositions in deep neural architectures. In the end, we conduct comprehensive experiments for supervised fine-tuning across various settings, including different optimization strategies, model sizes, and training datasets. The results consistently demonstrate that selecting data by maximizing pairwise distance significantly accelerates training and achieves comparable or better performance in LLMs across diverse datasets. Code and Datasets are available at the link: https://github.com/SafeRL-Lab/data-uniformity.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.24120",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation",
    "description": "arXiv:2506.23724v1 Announce Type: cross Abstract: Test-time Adaptation (TTA) adapts a given model to testing domain data with potential domain shifts through online unsupervised learning, yielding impressive performance. However, to date, existing TTA methods primarily focus on single-model adaptation. In this work, we investigate an intriguing question: how does cross-model knowledge influence the TTA process? Our findings reveal that, in TTA's unsupervised online setting, each model can provide complementary, confident knowledge to the others, even when there are substantial differences in model size. For instance, a smaller model like MobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base (86.6M parameters). In light of this, we propose COCA, a Cross-Model Co-Learning framework for TTA, which mainly consists of two main strategies. 1) Co-adaptation adaptively integrates complementary knowledge from other models throughout the TTA process, reducing individual model biases. 2) Self-adaptation enhances each model's unique strengths via unsupervised learning, enabling diverse adaptation to the target domain. Extensive experiments show that COCA, which can also serve as a plug-and-play module, significantly boosts existing SOTAs, on models with various sizes--including ResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example, with Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracy on ImageNet-C from 51.7% to 64.5%. The code is publicly available at https://github.com/ycarobot/COCA.",
    "summary": "arXiv:2506.23724v1 Announce Type: cross Abstract: Test-time Adaptation (TTA) adapts a given model to testing domain data with potential domain shifts through online unsupervised learning, yielding impressive performance. However, to date, existing TTA methods primarily focus on single-model adaptation. In this work, we investigate an intriguing question: how does cross-model knowledge influence the TTA process? Our findings reveal that, in TTA's unsupervised online setting, each model can provide complementary, confident knowledge to the others, even when there are substantial differences in model size. For instance, a smaller model like MobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base (86.6M parameters). In light of this, we propose COCA, a Cross-Model Co-Learning framework for TTA, which mainly consists of two main strategies. 1) Co-adaptation adaptively integrates complementary knowledge from other models throughout the TTA process, reducing individual model biases. 2) Self-adaptation enhances each model's unique strengths via unsupervised learning, enabling diverse adaptation to the target domain. Extensive experiments show that COCA, which can also serve as a plug-and-play module, significantly boosts existing SOTAs, on models with various sizes--including ResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example, with Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracy on ImageNet-C from 51.7% to 64.5%. The code is publicly available at https://github.com/ycarobot/COCA.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23724",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NEU-ESC: A Comprehensive Vietnamese dataset for Educational Sentiment analysis and topic Classification toward multitask learning",
    "description": "arXiv:2506.23524v1 Announce Type: cross Abstract: In the field of education, understanding students' opinions through their comments is crucial, especially in the Vietnamese language, where resources remain limited. Existing educational datasets often lack domain relevance and student slang. To address these gaps, we introduce NEU-ESC, a new Vietnamese dataset for Educational Sentiment Classification and Topic Classification, curated from university forums, which offers more samples, richer class diversity, longer texts, and broader vocabulary. In addition, we explore multitask learning using encoder-only language models (BERT), in which we showed that it achieves performance up to 83.7% and 79.8% accuracy for sentiment and topic classification tasks. We also benchmark our dataset and model with other datasets and models, including Large Language Models, and discuss these benchmarks. The dataset is publicly available at: https://huggingface.co/datasets/hung20gg/NEU-ESC.",
    "summary": "arXiv:2506.23524v1 Announce Type: cross Abstract: In the field of education, understanding students' opinions through their comments is crucial, especially in the Vietnamese language, where resources remain limited. Existing educational datasets often lack domain relevance and student slang. To address these gaps, we introduce NEU-ESC, a new Vietnamese dataset for Educational Sentiment Classification and Topic Classification, curated from university forums, which offers more samples, richer class diversity, longer texts, and broader vocabulary. In addition, we explore multitask learning using encoder-only language models (BERT), in which we showed that it achieves performance up to 83.7% and 79.8% accuracy for sentiment and topic classification tasks. We also benchmark our dataset and model with other datasets and models, including Large Language Models, and discuss these benchmarks. The dataset is publicly available at: https://huggingface.co/datasets/hung20gg/NEU-ESC.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23524",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Powering next generation applications with OpenAI Codex",
    "description": "Codex is now powering 70 different applications across a variety of use cases through the OpenAI¬†API.",
    "summary": "Codex is now powering 70 different applications across a variety of use cases through the OpenAI¬†API.",
    "pubDate": "Tue, 24 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/codex-apps",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scalable Structure Learning of Bayesian Networks by Learning Algorithm Ensembles",
    "description": "arXiv:2506.22848v1 Announce Type: cross Abstract: Learning the structure of Bayesian networks (BNs) from data is challenging, especially for datasets involving a large number of variables. The recently proposed divide-and-conquer (D&amp;D) strategies present a promising approach for learning large BNs. However, they still face a main issue of unstable learning accuracy across subproblems. In this work, we introduce the idea of employing structure learning ensemble (SLE), which combines multiple BN structure learning algorithms, to consistently achieve high learning accuracy. We further propose an automatic approach called Auto-SLE for learning near-optimal SLEs, addressing the challenge of manually designing high-quality SLEs. The learned SLE is then integrated into a D&amp;D method. Extensive experiments firmly show the superiority of our method over D&amp;D methods with single BN structure learning algorithm in learning large BNs, achieving accuracy improvement usually by 30%$sim$225% on datasets involving 10,000 variables. Furthermore, our method generalizes well to datasets with many more (e.g., 30000) variables and different network characteristics than those present in the training data for learning the SLE. These results indicate the significant potential of employing (automatic learning of) SLEs for scalable BN structure learning.",
    "summary": "arXiv:2506.22848v1 Announce Type: cross Abstract: Learning the structure of Bayesian networks (BNs) from data is challenging, especially for datasets involving a large number of variables. The recently proposed divide-and-conquer (D&amp;D) strategies present a promising approach for learning large BNs. However, they still face a main issue of unstable learning accuracy across subproblems. In this work, we introduce the idea of employing structure learning ensemble (SLE), which combines multiple BN structure learning algorithms, to consistently achieve high learning accuracy. We further propose an automatic approach called Auto-SLE for learning near-optimal SLEs, addressing the challenge of manually designing high-quality SLEs. The learned SLE is then integrated into a D&amp;D method. Extensive experiments firmly show the superiority of our method over D&amp;D methods with single BN structure learning algorithm in learning large BNs, achieving accuracy improvement usually by 30%$sim$225% on datasets involving 10,000 variables. Furthermore, our method generalizes well to datasets with many more (e.g., 30000) variables and different network characteristics than those present in the training data for learning the SLE. These results indicate the significant potential of employing (automatic learning of) SLEs for scalable BN structure learning.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22848",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reinforcement Learning for Synchronised Flow Control in a Dual-Gate Resin Infusion System",
    "description": "arXiv:2506.23923v1 Announce Type: cross Abstract: Resin infusion (RI) and resin transfer moulding (RTM) are critical processes for the manufacturing of high-performance fibre-reinforced polymer composites, particularly for large-scale applications such as wind turbine blades. Controlling the resin flow dynamics in these processes is critical to ensure the uniform impregnation of the fibre reinforcements, thereby preventing residual porosities and dry spots that impact the consequent structural integrity of the final component. This paper presents a reinforcement learning (RL) based strategy, established using process simulations, for synchronising the different resin flow fronts in an infusion scenario involving two resin inlets and a single outlet. Using Proximal Policy Optimisation (PPO), our approach addresses the challenge of managing the fluid dynamics in a partially observable environment. The results demonstrate the effectiveness of the RL approach in achieving an accurate flow convergence, highlighting its potential towards improving process control and product quality in composites manufacturing.",
    "summary": "arXiv:2506.23923v1 Announce Type: cross Abstract: Resin infusion (RI) and resin transfer moulding (RTM) are critical processes for the manufacturing of high-performance fibre-reinforced polymer composites, particularly for large-scale applications such as wind turbine blades. Controlling the resin flow dynamics in these processes is critical to ensure the uniform impregnation of the fibre reinforcements, thereby preventing residual porosities and dry spots that impact the consequent structural integrity of the final component. This paper presents a reinforcement learning (RL) based strategy, established using process simulations, for synchronising the different resin flow fronts in an infusion scenario involving two resin inlets and a single outlet. Using Proximal Policy Optimisation (PPO), our approach addresses the challenge of managing the fluid dynamics in a partially observable environment. The results demonstrate the effectiveness of the RL approach in achieving an accurate flow convergence, highlighting its potential towards improving process control and product quality in composites manufacturing.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23923",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Patch Time Series Transformer in Hugging Face",
    "description": "",
    "summary": "Patch Time Series Transformer in Hugging Face - Getting Started In this blog, we provide examples of...",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/patchtst",
    "thumbnail": "https://huggingface.co/blog/assets/patchtst/thumbnail.png"
  },
  {
    "title": "Learning to model other minds",
    "description": "We‚Äôre releasing an algorithm which accounts for the fact that other agents are learning too, and discovers self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner‚Äôs dilemma. This algorithm, Learning with Opponent-Learning Awareness (LOLA), is a small step towards agents that model other minds.",
    "summary": "We‚Äôre releasing an algorithm which accounts for the fact that other agents are learning too, and discovers self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner‚Äôs dilemma. This algorithm, Learning with Opponent-Learning Awareness (LOLA), is a small step towards agents that model other minds.",
    "pubDate": "Thu, 14 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-model-other-minds",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PhonemeFake: Redefining Deepfake Realism with Language-Driven Segmental Manipulation and Adaptive Bilevel Detection",
    "description": "arXiv:2506.22783v1 Announce Type: cross Abstract: Deepfake (DF) attacks pose a growing threat as generative models become increasingly advanced. However, our study reveals that existing DF datasets fail to deceive human perception, unlike real DF attacks that influence public discourse. It highlights the need for more realistic DF attack vectors. We introduce PhonemeFake (PF), a DF attack that manipulates critical speech segments using language reasoning, significantly reducing human perception by up to 42% and benchmark accuracies by up to 94%. We release an easy-to-use PF dataset on HuggingFace and open-source bilevel DF segment detection model that adaptively prioritizes compute on manipulated regions. Our extensive experiments across three known DF datasets reveal that our detection model reduces EER by 91% while achieving up to 90% speed-up, with minimal compute overhead and precise localization beyond existing models as a scalable solution.",
    "summary": "arXiv:2506.22783v1 Announce Type: cross Abstract: Deepfake (DF) attacks pose a growing threat as generative models become increasingly advanced. However, our study reveals that existing DF datasets fail to deceive human perception, unlike real DF attacks that influence public discourse. It highlights the need for more realistic DF attack vectors. We introduce PhonemeFake (PF), a DF attack that manipulates critical speech segments using language reasoning, significantly reducing human perception by up to 42% and benchmark accuracies by up to 94%. We release an easy-to-use PF dataset on HuggingFace and open-source bilevel DF segment detection model that adaptively prioritizes compute on manipulated regions. Our extensive experiments across three known DF datasets reveal that our detection model reduces EER by 91% while achieving up to 90% speed-up, with minimal compute overhead and precise localization beyond existing models as a scalable solution.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22783",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deploy models on AWS Inferentia2 from Hugging Face",
    "description": "",
    "summary": "Deploy models on AWS Inferentia2 from Hugging Face AWS Inferentia2 is the latest AWS machine learnin...",
    "pubDate": "Wed, 22 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inferentia-inference-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/inferentia-inference-endpoints/thumbnail.jpg"
  },
  {
    "title": "Optimizing Stable Diffusion for Intel CPUs with NNCF and ü§ó Optimum",
    "description": "",
    "summary": "Optimizing Stable Diffusion for Intel CPUs with NNCF and ü§ó Optimum Latent Diffusion models are game ...",
    "pubDate": "Thu, 25 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-optimize-sd-intel",
    "thumbnail": "https://huggingface.co/blog/assets/train_optimize_sd_intel/thumbnail.png"
  },
  {
    "title": "Learning dexterity",
    "description": "We‚Äôve trained a human-like robot hand to manipulate physical objects with unprecedented¬†dexterity.",
    "summary": "We‚Äôve trained a human-like robot hand to manipulate physical objects with unprecedented¬†dexterity.",
    "pubDate": "Mon, 30 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-dexterity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Semi-supervised knowledge transfer for deep learning from private training data",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/semi-supervised-knowledge-transfer-for-deep-learning-from-private-training-data",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "We‚Äôre improving Ask Photos and bringing it to more Google Photos users.",
    "description": "Animation showing a search in Ask Photos for 'Photos that'd make great phone backgrounds,' then a grid of initial results followed by the most relevant photos.",
    "summary": "Animation showing a search in Ask Photos for 'Photos that'd make great phone backgrounds,' then a grid of initial results followed by the most relevant photos.",
    "pubDate": "Thu, 26 Jun 2025 17:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/photos/updates-ask-photos-search/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/wagtailvideo-mbcag8qi_thumb.jpg"
  },
  {
    "title": "Disrupting malicious uses of AI: June 2025",
    "description": "In our June 2025 update, we outline how we‚Äôre disrupting malicious uses of AI‚Äîthrough safety tools that detect and counter abuse, support democratic values, and promote responsible AI deployment for the benefit of all.",
    "summary": "In our June 2025 update, we outline how we‚Äôre disrupting malicious uses of AI‚Äîthrough safety tools that detect and counter abuse, support democratic values, and promote responsible AI deployment for the benefit of all.",
    "pubDate": "Thu, 05 Jun 2025 02:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai-june-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deep Learning with Proteins",
    "description": "",
    "summary": "Deep Learning With Proteins I have two audiences in mind while writing this. One is biologists who a...",
    "pubDate": "Fri, 02 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-learning-with-proteins",
    "thumbnail": "https://huggingface.co/blog/assets/119_deep_learning_with_proteins/folding_example.png"
  },
  {
    "title": "Deep research System Card",
    "description": "This report outlines the safety work carried out prior to releasing deep research including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "summary": "This report outlines the safety work carried out prior to releasing deep research including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "pubDate": "Tue, 25 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-research-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Predicting thinking time in Reasoning models",
    "description": "arXiv:2506.23274v1 Announce Type: cross Abstract: Reasoning models that produce long, hidden chains of thought have emerged as powerful tools for complex, reasoning-intensive taskscitep{deepseekai2025deepseekr1incentivizingreasoningcapability, openai2024openaio1card}. However, this paradigm introduces a new user experience challenge: users have little insight into how much time the model will spend reasoning before returning an answer. This unpredictability, can lead to user frustration and is likely to compound as LLMs can produce increasingly long tasks asynchronously citep{kwa2025measuringaiabilitycomplete}. In this paper, we introduce and evaluate methods for both online and offline prediction of model 'thinking time,' aiming to develop a practical 'progress bar for reasoning.' We discuss the implications for user interaction and future research directions.",
    "summary": "arXiv:2506.23274v1 Announce Type: cross Abstract: Reasoning models that produce long, hidden chains of thought have emerged as powerful tools for complex, reasoning-intensive taskscitep{deepseekai2025deepseekr1incentivizingreasoningcapability, openai2024openaio1card}. However, this paradigm introduces a new user experience challenge: users have little insight into how much time the model will spend reasoning before returning an answer. This unpredictability, can lead to user frustration and is likely to compound as LLMs can produce increasingly long tasks asynchronously citep{kwa2025measuringaiabilitycomplete}. In this paper, we introduce and evaluate methods for both online and offline prediction of model 'thinking time,' aiming to develop a practical 'progress bar for reasoning.' We discuss the implications for user interaction and future research directions.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23274",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "VAP-Diffusion: Enriching Descriptions with MLLMs for Enhanced Medical Image Generation",
    "description": "arXiv:2506.23641v1 Announce Type: cross Abstract: As the appearance of medical images is influenced by multiple underlying factors, generative models require rich attribute information beyond labels to produce realistic and diverse images. For instance, generating an image of skin lesion with specific patterns demands descriptions that go beyond diagnosis, such as shape, size, texture, and color. However, such detailed descriptions are not always accessible. To address this, we explore a framework, termed Visual Attribute Prompts (VAP)-Diffusion, to leverage external knowledge from pre-trained Multi-modal Large Language Models (MLLMs) to improve the quality and diversity of medical image generation. First, to derive descriptions from MLLMs without hallucination, we design a series of prompts following Chain-of-Thoughts for common medical imaging tasks, including dermatologic, colorectal, and chest X-ray images. Generated descriptions are utilized during training and stored across different categories. During testing, descriptions are randomly retrieved from the corresponding category for inference. Moreover, to make the generator robust to unseen combination of descriptions at the test time, we propose a Prototype Condition Mechanism that restricts test embeddings to be similar to those from training. Experiments on three common types of medical imaging across four datasets verify the effectiveness of VAP-Diffusion.",
    "summary": "arXiv:2506.23641v1 Announce Type: cross Abstract: As the appearance of medical images is influenced by multiple underlying factors, generative models require rich attribute information beyond labels to produce realistic and diverse images. For instance, generating an image of skin lesion with specific patterns demands descriptions that go beyond diagnosis, such as shape, size, texture, and color. However, such detailed descriptions are not always accessible. To address this, we explore a framework, termed Visual Attribute Prompts (VAP)-Diffusion, to leverage external knowledge from pre-trained Multi-modal Large Language Models (MLLMs) to improve the quality and diversity of medical image generation. First, to derive descriptions from MLLMs without hallucination, we design a series of prompts following Chain-of-Thoughts for common medical imaging tasks, including dermatologic, colorectal, and chest X-ray images. Generated descriptions are utilized during training and stored across different categories. During testing, descriptions are randomly retrieved from the corresponding category for inference. Moreover, to make the generator robust to unseen combination of descriptions at the test time, we propose a Prototype Condition Mechanism that restricts test embeddings to be similar to those from training. Experiments on three common types of medical imaging across four datasets verify the effectiveness of VAP-Diffusion.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23641",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fetch Consolidates AI Tools and Saves 30% Development Time with Hugging Face on AWS",
    "description": "",
    "summary": "Fetch Consolidates AI Tools and Saves 30% Development Time with Hugging Face on AWS If you need supp...",
    "pubDate": "Thu, 23 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fetch-eap-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/fetch2.png"
  },
  {
    "title": "Token Activation Map to Visually Explain Multimodal LLMs",
    "description": "arXiv:2506.23270v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) are broadly empowering various fields. Despite their advancements, the explainability of MLLMs remains less explored, hindering deeper understanding, model credibility, and effective visualization. Unlike conventional vision models (e.g., CNNs, ViTs, CLIP) that produce a single output, MLLMs generate sequences of tokens progressively, where each generated token depends on the previous context. Therefore, earlier context tokens can introduce redundant activations that interfere with the explanation of later tokens beyond their original information. Existing studies often overlook this issue, but our observations reveal that these redundant correlations can significantly hurt the reliability of explanations. To address this, we propose an estimated causal inference method to mitigate the interference of context to achieve high-quality MLLM explanation, with a novel rank Gaussian filter to further reduce activation noises. We term this method Token Activation Map (TAM) to highlight the consideration of interactions between tokens. TAM also indicates that it excels at explaining multiple tokens of MLLM, which is different from the Class Activation Map (CAM) for a single prediction. Our TAM method significantly outperforms existing SoTA methods, showcasing high-quality visualization results that can be utilized for various scenarios, such as object localization, failure case analysis, video visualization, MLLMs visual comparison, and model understanding (e.g., color, shape, action, location, visual reasoning, multi-turn conversation, etc). The code is available atgithub.com/xmed-lab/TAM.",
    "summary": "arXiv:2506.23270v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) are broadly empowering various fields. Despite their advancements, the explainability of MLLMs remains less explored, hindering deeper understanding, model credibility, and effective visualization. Unlike conventional vision models (e.g., CNNs, ViTs, CLIP) that produce a single output, MLLMs generate sequences of tokens progressively, where each generated token depends on the previous context. Therefore, earlier context tokens can introduce redundant activations that interfere with the explanation of later tokens beyond their original information. Existing studies often overlook this issue, but our observations reveal that these redundant correlations can significantly hurt the reliability of explanations. To address this, we propose an estimated causal inference method to mitigate the interference of context to achieve high-quality MLLM explanation, with a novel rank Gaussian filter to further reduce activation noises. We term this method Token Activation Map (TAM) to highlight the consideration of interactions between tokens. TAM also indicates that it excels at explaining multiple tokens of MLLM, which is different from the Class Activation Map (CAM) for a single prediction. Our TAM method significantly outperforms existing SoTA methods, showcasing high-quality visualization results that can be utilized for various scenarios, such as object localization, failure case analysis, video visualization, MLLMs visual comparison, and model understanding (e.g., color, shape, action, location, visual reasoning, multi-turn conversation, etc). The code is available atgithub.com/xmed-lab/TAM.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23270",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Gemini 2.0: our new AI model for the agentic era",
    "description": "Today, we‚Äôre announcing Gemini 2.0, our most capable multimodal AI model yet.",
    "summary": "Today, we‚Äôre announcing Gemini 2.0, our most capable multimodal AI model yet.",
    "pubDate": "Wed, 11 Dec 2024 15:30:40 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-20-our-new-ai-model-for-the-agentic-era/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/blog_gemini_hero_thumbnail.width-1300.png"
  },
  {
    "title": "Identifying AI-generated images with SynthID",
    "description": "New tool helps watermark and identify synthetic images created by Imagen",
    "summary": "New tool helps watermark and identify synthetic images created by Imagen",
    "pubDate": "Tue, 29 Aug 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/identifying-ai-generated-images-with-synthid/",
    "thumbnail": "https://lh3.googleusercontent.com/wUgtK2GBt2yZJ3dJkXtvAK84G93j6idOOalyihOMfwBxY0lR650fZZYIi3bXdgkKbBcitbUZ0ILbaIPg_-vDTgAJLlP1DO3h_UnyoZ27wl3mYSzKtw=w1200-h630-n-nu"
  },
  {
    "title": "Why OpenAI‚Äôs structure must evolve to advance our mission",
    "description": "A stronger non-profit supported by the for-profit‚Äôs success.",
    "summary": "A stronger non-profit supported by the for-profit‚Äôs success.",
    "pubDate": "Fri, 27 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/why-our-structure-must-evolve-to-advance-our-mission",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning concepts with energy functions",
    "description": "We‚Äôve developed an¬†energy-based model¬†that can quickly learn to identify and generate instances of concepts, such as near, above, between, closest, and furthest, expressed as sets of 2d points. Our model learns these concepts after only five demonstrations. We also show cross-domain transfer: we use concepts learned in a 2d particle environment to solve tasks on a 3-dimensional physics-based¬†robot.",
    "summary": "We‚Äôve developed an¬†energy-based model¬†that can quickly learn to identify and generate instances of concepts, such as near, above, between, closest, and furthest, expressed as sets of 2d points. Our model learns these concepts after only five demonstrations. We also show cross-domain transfer: we use concepts learned in a 2d particle environment to solve tasks on a 3-dimensional physics-based¬†robot.",
    "pubDate": "Wed, 07 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-concepts-with-energy-functions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "5 tips for getting started with Flow",
    "description": "Flow-generated video showing two astronaut pugs driving a car in outer space, with text overlaid saying 'Find your Flow'",
    "summary": "Flow-generated video showing two astronaut pugs driving a car in outer space, with text overlaid saying 'Find your Flow'",
    "pubDate": "Wed, 25 Jun 2025 22:45:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/flow-video-tips/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GetStartedwithFlow_SS.width-1300.png"
  },
  {
    "title": "Accelerating Stable Diffusion Inference on Intel CPUs",
    "description": "",
    "summary": "Accelerating Stable Diffusion Inference on Intel CPUs Recently, we introduced the latest generation ...",
    "pubDate": "Tue, 28 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-inference-intel",
    "thumbnail": "https://huggingface.co/blog/assets/136_stable_diffusion_inference_intel/01.png"
  },
  {
    "title": "Stochastic Neural Networks for hierarchical reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 10 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/stochastic-neural-networks-for-hierarchical-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning Truthful Mechanisms without Discretization",
    "description": "arXiv:2506.22911v1 Announce Type: cross Abstract: This paper introduces TEDI (Truthful, Expressive, and Dimension-Insensitive approach), a discretization-free algorithm to learn truthful and utility-maximizing mechanisms. Existing learning-based approaches often rely on discretization of outcome spaces to ensure truthfulness, which leads to inefficiency with increasing problem size. To address this limitation, we formalize the concept of pricing rules, defined as functions that map outcomes to prices. Based on this concept, we propose a novel menu mechanism, which can be equivalent to a truthful direct mechanism under specific conditions. The core idea of TEDI lies in its parameterization of pricing rules using Partial GroupMax Network, a new network architecture designed to universally approximate partial convex functions. To learn optimal pricing rules, we develop novel training techniques, including covariance trick and continuous sampling, to derive unbiased gradient estimators compatible with first-order optimization. Theoretical analysis establishes that TEDI guarantees truthfulness, full expressiveness, and dimension-insensitivity. Experimental evaluation in the studied auction setting demonstrates that TEDI achieves strong performance, competitive with or exceeding state-of-the-art methods. This work presents the first approaches to learn truthful mechanisms without outcome discretization, thereby enhancing algorithmic efficiency. The proposed concepts, network architecture, and learning techniques might offer potential value and provide new insights for automated mechanism design and differentiable economics.",
    "summary": "arXiv:2506.22911v1 Announce Type: cross Abstract: This paper introduces TEDI (Truthful, Expressive, and Dimension-Insensitive approach), a discretization-free algorithm to learn truthful and utility-maximizing mechanisms. Existing learning-based approaches often rely on discretization of outcome spaces to ensure truthfulness, which leads to inefficiency with increasing problem size. To address this limitation, we formalize the concept of pricing rules, defined as functions that map outcomes to prices. Based on this concept, we propose a novel menu mechanism, which can be equivalent to a truthful direct mechanism under specific conditions. The core idea of TEDI lies in its parameterization of pricing rules using Partial GroupMax Network, a new network architecture designed to universally approximate partial convex functions. To learn optimal pricing rules, we develop novel training techniques, including covariance trick and continuous sampling, to derive unbiased gradient estimators compatible with first-order optimization. Theoretical analysis establishes that TEDI guarantees truthfulness, full expressiveness, and dimension-insensitivity. Experimental evaluation in the studied auction setting demonstrates that TEDI achieves strong performance, competitive with or exceeding state-of-the-art methods. This work presents the first approaches to learn truthful mechanisms without outcome discretization, thereby enhancing algorithmic efficiency. The proposed concepts, network architecture, and learning techniques might offer potential value and provide new insights for automated mechanism design and differentiable economics.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22911",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deep Learning-Based Semantic Segmentation for Real-Time Kidney Imaging and Measurements with Augmented Reality-Assisted Ultrasound",
    "description": "arXiv:2506.23721v1 Announce Type: cross Abstract: Ultrasound (US) is widely accessible and radiation-free but has a steep learning curve due to its dynamic nature and non-standard imaging planes. Additionally, the constant need to shift focus between the US screen and the patient poses a challenge. To address these issues, we integrate deep learning (DL)-based semantic segmentation for real-time (RT) automated kidney volumetric measurements, which are essential for clinical assessment but are traditionally time-consuming and prone to fatigue. This automation allows clinicians to concentrate on image interpretation rather than manual measurements. Complementing DL, augmented reality (AR) enhances the usability of US by projecting the display directly into the clinician's field of view, improving ergonomics and reducing the cognitive load associated with screen-to-patient transitions. Two AR-DL-assisted US pipelines on HoloLens-2 are proposed: one streams directly via the application programming interface for a wireless setup, while the other supports any US device with video output for broader accessibility. We evaluate RT feasibility and accuracy using the Open Kidney Dataset and open-source segmentation models (nnU-Net, Segmenter, YOLO with MedSAM and LiteMedSAM). Our open-source GitHub pipeline includes model implementations, measurement algorithms, and a Wi-Fi-based streaming solution, enhancing US training and diagnostics, especially in point-of-care settings.",
    "summary": "arXiv:2506.23721v1 Announce Type: cross Abstract: Ultrasound (US) is widely accessible and radiation-free but has a steep learning curve due to its dynamic nature and non-standard imaging planes. Additionally, the constant need to shift focus between the US screen and the patient poses a challenge. To address these issues, we integrate deep learning (DL)-based semantic segmentation for real-time (RT) automated kidney volumetric measurements, which are essential for clinical assessment but are traditionally time-consuming and prone to fatigue. This automation allows clinicians to concentrate on image interpretation rather than manual measurements. Complementing DL, augmented reality (AR) enhances the usability of US by projecting the display directly into the clinician's field of view, improving ergonomics and reducing the cognitive load associated with screen-to-patient transitions. Two AR-DL-assisted US pipelines on HoloLens-2 are proposed: one streams directly via the application programming interface for a wireless setup, while the other supports any US device with video output for broader accessibility. We evaluate RT feasibility and accuracy using the Open Kidney Dataset and open-source segmentation models (nnU-Net, Segmenter, YOLO with MedSAM and LiteMedSAM). Our open-source GitHub pipeline includes model implementations, measurement algorithms, and a Wi-Fi-based streaming solution, enhancing US training and diagnostics, especially in point-of-care settings.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23721",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Variance reduction for policy gradient with action-dependent factorized baselines",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 20 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variance-reduction-for-policy-gradient-with-action-dependent-factorized-baselines",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Complex UNet Approach for Non-Invasive Fetal ECG Extraction Using Single-Channel Dry Textile Electrodes",
    "description": "arXiv:2506.22457v1 Announce Type: cross Abstract: Continuous, non-invasive pregnancy monitoring is crucial for minimising potential complications. The fetal electrocardiogram (fECG) represents a promising tool for assessing fetal health beyond clinical environments. Home-based monitoring necessitates the use of a minimal number of comfortable and durable electrodes, such as dry textile electrodes. However, this setup presents many challenges, including increased noise and motion artefacts, which complicate the accurate extraction of fECG signals. To overcome these challenges, we introduce a pioneering method for extracting fECG from single-channel recordings obtained using dry textile electrodes using AI techniques. We created a new dataset by simulating abdominal recordings, including noise closely resembling real-world characteristics of in-vivo recordings through dry textile electrodes, alongside mECG and fECG. To ensure the reliability of the extracted fECG, we propose an innovative pipeline based on a complex-valued denoising network, Complex UNet. Unlike previous approaches that focused solely on signal magnitude, our method processes both real and imaginary components of the spectrogram, addressing phase information and preventing incongruous predictions. We evaluated our novel pipeline against traditional, well-established approaches, on both simulated and real data in terms of fECG extraction and R-peak detection. The results showcase that our suggested method achieves new state-of-the-art results, enabling an accurate extraction of fECG morphology across all evaluated settings. This method is the first to effectively extract fECG signals from single-channel recordings using dry textile electrodes, making a significant advancement towards a fully non-invasive and self-administered fECG extraction solution.",
    "summary": "arXiv:2506.22457v1 Announce Type: cross Abstract: Continuous, non-invasive pregnancy monitoring is crucial for minimising potential complications. The fetal electrocardiogram (fECG) represents a promising tool for assessing fetal health beyond clinical environments. Home-based monitoring necessitates the use of a minimal number of comfortable and durable electrodes, such as dry textile electrodes. However, this setup presents many challenges, including increased noise and motion artefacts, which complicate the accurate extraction of fECG signals. To overcome these challenges, we introduce a pioneering method for extracting fECG from single-channel recordings obtained using dry textile electrodes using AI techniques. We created a new dataset by simulating abdominal recordings, including noise closely resembling real-world characteristics of in-vivo recordings through dry textile electrodes, alongside mECG and fECG. To ensure the reliability of the extracted fECG, we propose an innovative pipeline based on a complex-valued denoising network, Complex UNet. Unlike previous approaches that focused solely on signal magnitude, our method processes both real and imaginary components of the spectrogram, addressing phase information and preventing incongruous predictions. We evaluated our novel pipeline against traditional, well-established approaches, on both simulated and real data in terms of fECG extraction and R-peak detection. The results showcase that our suggested method achieves new state-of-the-art results, enabling an accurate extraction of fECG morphology across all evaluated settings. This method is the first to effectively extract fECG signals from single-channel recordings using dry textile electrodes, making a significant advancement towards a fully non-invasive and self-administered fECG extraction solution.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22457",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "StarCoder2 and The Stack v2",
    "description": "",
    "summary": "StarCoder2 and The Stack v2 BigCode is releasing StarCoder2, the next generation of transparently tr...",
    "pubDate": "Wed, 28 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starcoder2",
    "thumbnail": "https://huggingface.co/blog/assets/177_starcoder2/sc2-banner.png"
  },
  {
    "title": "Neural MMO: A massively multiagent game environment",
    "description": "We‚Äôre releasing a Neural¬†MMO, a massively multiagent game environment for reinforcement learning agents. Our platform supports a large, variable number of agents within a persistent and open-ended task. The inclusion of many agents and species leads to better exploration, divergent niche formation, and greater overall¬†competence.",
    "summary": "We‚Äôre releasing a Neural¬†MMO, a massively multiagent game environment for reinforcement learning agents. Our platform supports a large, variable number of agents within a persistent and open-ended task. The inclusion of many agents and species leads to better exploration, divergent niche formation, and greater overall¬†competence.",
    "pubDate": "Mon, 04 Mar 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/neural-mmo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI hackathon",
    "description": "Come to OpenAI‚Äôs office in San Francisco‚Äôs Mission District for talks and a hackathon on Saturday, March 3rd.",
    "summary": "Come to OpenAI‚Äôs office in San Francisco‚Äôs Mission District for talks and a hackathon on Saturday, March 3rd.",
    "pubDate": "Thu, 22 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-hackathon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ethical guidelines for developing the Diffusers library",
    "description": "",
    "summary": "Ethical guidelines for developing the Diffusers library We are on a journey to make our libraries mo...",
    "pubDate": "Thu, 02 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/ethics-diffusers/thumbnail.png"
  },
  {
    "title": "Potemkin Understanding in Large Language Models",
    "description": "arXiv:2506.21521v2 Announce Type: replace-cross Abstract: Large language models (LLMs) are regularly evaluated using benchmark datasets. But what justifies making inferences about an LLM's capabilities based on its answers to a curated set of questions? This paper first introduces a formal framework to address this question. The key is to note that the benchmarks used to test LLMs -- such as AP exams -- are also those used to test people. However, this raises an implication: these benchmarks are only valid tests if LLMs misunderstand concepts in ways that mirror human misunderstandings. Otherwise, success on benchmarks only demonstrates potemkin understanding: the illusion of understanding driven by answers irreconcilable with how any human would interpret a concept. We present two procedures for quantifying the existence of potemkins: one using a specially designed benchmark in three domains, the other using a general procedure that provides a lower-bound on their prevalence. We find that potemkins are ubiquitous across models, tasks, and domains. We also find that these failures reflect not just incorrect understanding, but deeper internal incoherence in concept representations.",
    "summary": "arXiv:2506.21521v2 Announce Type: replace-cross Abstract: Large language models (LLMs) are regularly evaluated using benchmark datasets. But what justifies making inferences about an LLM's capabilities based on its answers to a curated set of questions? This paper first introduces a formal framework to address this question. The key is to note that the benchmarks used to test LLMs -- such as AP exams -- are also those used to test people. However, this raises an implication: these benchmarks are only valid tests if LLMs misunderstand concepts in ways that mirror human misunderstandings. Otherwise, success on benchmarks only demonstrates potemkin understanding: the illusion of understanding driven by answers irreconcilable with how any human would interpret a concept. We present two procedures for quantifying the existence of potemkins: one using a specially designed benchmark in three domains, the other using a general procedure that provides a lower-bound on their prevalence. We find that potemkins are ubiquitous across models, tasks, and domains. We also find that these failures reflect not just incorrect understanding, but deeper internal incoherence in concept representations.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21521",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using OpenAI o1 for financial analysis",
    "description": "Rogo scales AI-driven financial research with OpenAI o1",
    "summary": "Rogo scales AI-driven financial research with OpenAI o1",
    "pubDate": "Thu, 13 Feb 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rogo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Nystr√∂mformer, Approximating self-attention in linear time and memory via the Nystr√∂m method",
    "description": "",
    "summary": "Nystr√∂mformer: Approximating self-attention in linear time and memory via the Nystr√∂m method Introdu...",
    "pubDate": "Tue, 02 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nystromformer",
    "thumbnail": "https://huggingface.co/blog/assets/86_nystromformer/thumbnail.png"
  },
  {
    "title": "OpenAI and GEDI partner for Italian news content",
    "description": "OpenAI and GEDI announce strategic partnership to bring Italian-language news content to ChatGPT.",
    "summary": "OpenAI and GEDI announce strategic partnership to bring Italian-language news content to ChatGPT.",
    "pubDate": "Thu, 26 Sep 2024 04:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gedi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Helping machines understand visual content with AI",
    "description": "Coactive, founded by two MIT alumni, has built an AI-powered platform to unlock new insights from content of all types.",
    "summary": "Coactive, founded by two MIT alumni, has built an AI-powered platform to unlock new insights from content of all types.",
    "pubDate": "Mon, 09 Jun 2025 15:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/coactive-helps-machines-understand-visual-content-ai-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Coactive-AI-01-press.jpg"
  },
  {
    "title": "FADRM: Fast and Accurate Data Residual Matching for Dataset Distillation",
    "description": "arXiv:2506.24125v1 Announce Type: cross Abstract: Residual connection has been extensively studied and widely applied at the model architecture level. However, its potential in the more challenging data-centric approaches remains unexplored. In this work, we introduce the concept of Data Residual Matching for the first time, leveraging data-level skip connections to facilitate data generation and mitigate data information vanishing. This approach maintains a balance between newly acquired knowledge through pixel space optimization and existing core local information identification within raw data modalities, specifically for the dataset distillation task. Furthermore, by incorporating optimization-level refinements, our method significantly improves computational efficiency, achieving superior performance while reducing training time and peak GPU memory usage by 50%. Consequently, the proposed method Fast and Accurate Data Residual Matching for Dataset Distillation (FADRM) establishes a new state-of-the-art, demonstrating substantial improvements over existing methods across multiple dataset benchmarks in both efficiency and effectiveness. For instance, with ResNet-18 as the student model and a 0.8% compression ratio on ImageNet-1K, the method achieves 47.7% test accuracy in single-model dataset distillation and 50.0% in multi-model dataset distillation, surpassing RDED by +5.7% and outperforming state-of-the-art multi-model approaches, EDC and CV-DD, by +1.4% and +4.0%. Code is available at: https://github.com/Jiacheng8/FADRM.",
    "summary": "arXiv:2506.24125v1 Announce Type: cross Abstract: Residual connection has been extensively studied and widely applied at the model architecture level. However, its potential in the more challenging data-centric approaches remains unexplored. In this work, we introduce the concept of Data Residual Matching for the first time, leveraging data-level skip connections to facilitate data generation and mitigate data information vanishing. This approach maintains a balance between newly acquired knowledge through pixel space optimization and existing core local information identification within raw data modalities, specifically for the dataset distillation task. Furthermore, by incorporating optimization-level refinements, our method significantly improves computational efficiency, achieving superior performance while reducing training time and peak GPU memory usage by 50%. Consequently, the proposed method Fast and Accurate Data Residual Matching for Dataset Distillation (FADRM) establishes a new state-of-the-art, demonstrating substantial improvements over existing methods across multiple dataset benchmarks in both efficiency and effectiveness. For instance, with ResNet-18 as the student model and a 0.8% compression ratio on ImageNet-1K, the method achieves 47.7% test accuracy in single-model dataset distillation and 50.0% in multi-model dataset distillation, surpassing RDED by +5.7% and outperforming state-of-the-art multi-model approaches, EDC and CV-DD, by +1.4% and +4.0%. Code is available at: https://github.com/Jiacheng8/FADRM.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.24125",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The power of personalized AI",
    "description": "The power of personalized AI",
    "summary": "The power of personalized AI",
    "pubDate": "Fri, 17 Jan 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/the-power-of-personalized-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Jupyter X Hugging Face",
    "description": "",
    "summary": "Jupyter X Hugging Face We‚Äôre excited to announce improved support for Jupyter notebooks hosted on th...",
    "pubDate": "Thu, 23 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/notebooks-hub",
    "thumbnail": "https://huggingface.co/blog/assets/135_notebooks-hub/before_after_notebook_rendering.png"
  },
  {
    "title": "Embedding AI into developer software",
    "description": "JetBrains uses OpenAI‚Äôs API to build its fastest-growing product ever.",
    "summary": "JetBrains uses OpenAI‚Äôs API to build its fastest-growing product ever.",
    "pubDate": "Thu, 21 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jetbrains",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaQubit tackles one of quantum computing‚Äôs biggest challenges",
    "description": "Our new AI system accurately identifies errors inside quantum computers, helping to make this new technology more reliable.",
    "summary": "Our new AI system accurately identifies errors inside quantum computers, helping to make this new technology more reliable.",
    "pubDate": "Wed, 20 Nov 2024 18:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaqubit-tackles-one-of-quantum-computings-biggest-challenges/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Social_Share_Image_-_1920_x_1080.width-1300.png"
  },
  {
    "title": "Zico Kolter Joins OpenAI‚Äôs Board of Directors",
    "description": "Zico Kolter Joins OpenAI‚Äôs Board of Directors We‚Äôre strengthening our governance with expertise in AI safety and alignment. Zico will also join the Safety & Security Committee",
    "summary": "Zico Kolter Joins OpenAI‚Äôs Board of Directors We‚Äôre strengthening our governance with expertise in AI safety and alignment. Zico will also join the Safety & Security Committee",
    "pubDate": "Thu, 08 Aug 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zico-kolter-joins-openais-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Put AI to work for your product team",
    "description": "Put AI to work for your product team",
    "summary": "Put AI to work for your product team",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/put-ai-to-work-for-your-product-team",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Five",
    "description": "Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota¬†2.",
    "summary": "Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota¬†2.",
    "pubDate": "Mon, 25 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and AWS partner to make AI more accessible",
    "description": "",
    "summary": "Hugging Face and AWS partner to make AI more accessible It‚Äôs time to make AI open and accessible to ...",
    "pubDate": "Tue, 21 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aws-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/131_aws-partnership/aws-partnership-thumbnail.png"
  },
  {
    "title": "Answering quantum physics questions with OpenAI o1",
    "description": "Quantum physicist Mario Krenn uses OpenAI o1 to help answer life's biggest questions.",
    "summary": "Quantum physicist Mario Krenn uses OpenAI o1 to help answer life's biggest questions.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-quantum-physics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Governance of superintelligence",
    "description": "Now is a good time to start thinking about the governance of superintelligence‚Äîfuture AI systems dramatically more capable than even AGI.",
    "summary": "Now is a good time to start thinking about the governance of superintelligence‚Äîfuture AI systems dramatically more capable than even AGI.",
    "pubDate": "Mon, 22 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/governance-of-superintelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Automatic Depression Assessment using Machine Learning: A Comprehensive Survey",
    "description": "arXiv:2506.18915v2 Announce Type: replace-cross Abstract: Depression is a common mental illness across current human society. Traditional depression assessment relying on inventories and interviews with psychologists frequently suffer from subjective diagnosis results, slow and expensive diagnosis process as well as lack of human resources. Since there is a solid evidence that depression is reflected by various human internal brain activities and external expressive behaviours, early traditional machine learning (ML) and advanced deep learning (DL) models have been widely explored for human behaviour-based automatic depression assessment (ADA) since 2012. However, recent ADA surveys typically only focus on a limited number of human behaviour modalities. Despite being used as a theoretical basis for developing ADA approaches, existing ADA surveys lack a comprehensive review and summary of multi-modal depression-related human behaviours. To bridge this gap, this paper specifically summarises depression-related human behaviours across a range of modalities (e.g. the human brain, verbal language and non-verbal audio/facial/body behaviours). We focus on conducting an up-to-date and comprehensive survey of ML-based ADA approaches for learning depression cues from these behaviours as well as discussing and comparing their distinctive features and limitations. In addition, we also review existing ADA competitions and datasets, identify and discuss the main challenges and opportunities to provide further research directions for future ADA researchers.",
    "summary": "arXiv:2506.18915v2 Announce Type: replace-cross Abstract: Depression is a common mental illness across current human society. Traditional depression assessment relying on inventories and interviews with psychologists frequently suffer from subjective diagnosis results, slow and expensive diagnosis process as well as lack of human resources. Since there is a solid evidence that depression is reflected by various human internal brain activities and external expressive behaviours, early traditional machine learning (ML) and advanced deep learning (DL) models have been widely explored for human behaviour-based automatic depression assessment (ADA) since 2012. However, recent ADA surveys typically only focus on a limited number of human behaviour modalities. Despite being used as a theoretical basis for developing ADA approaches, existing ADA surveys lack a comprehensive review and summary of multi-modal depression-related human behaviours. To bridge this gap, this paper specifically summarises depression-related human behaviours across a range of modalities (e.g. the human brain, verbal language and non-verbal audio/facial/body behaviours). We focus on conducting an up-to-date and comprehensive survey of ML-based ADA approaches for learning depression cues from these behaviours as well as discussing and comparing their distinctive features and limitations. In addition, we also review existing ADA competitions and datasets, identify and discuss the main challenges and opportunities to provide further research directions for future ADA researchers.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18915",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Join us for OpenAI‚Äôs first developer conference on November 6 in San Francisco",
    "description": "Developer registration for in-person attendance will open in the coming weeks and developers everywhere will be able to livestream the keynote.",
    "summary": "Developer registration for in-person attendance will open in the coming weeks and developers everywhere will be able to livestream the keynote.",
    "pubDate": "Wed, 06 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/announcing-openai-devday",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster TensorFlow models in Hugging Face Transformers",
    "description": "",
    "summary": "Faster TensorFlow models in Hugging Face Transformers In the last few months, the Hugging Face team ...",
    "pubDate": "Tue, 26 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-serving",
    "thumbnail": "https://huggingface.co/blog/assets/10_tf-serving/thumbnail.png"
  },
  {
    "title": "An update on disrupting deceptive uses of AI",
    "description": "OpenAI‚Äôs mission is to ensure that artificial general intelligence benefits all of humanity. We are dedicated to identifying, preventing, and disrupting attempts to abuse our models for harmful ends.",
    "summary": "OpenAI‚Äôs mission is to ensure that artificial general intelligence benefits all of humanity. We are dedicated to identifying, preventing, and disrupting attempts to abuse our models for harmful ends.",
    "pubDate": "Wed, 09 Oct 2024 03:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/an-update-on-disrupting-deceptive-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Federated Breast Cancer Detection Enhanced by Synthetic Ultrasound Image Augmentation",
    "description": "arXiv:2506.23334v1 Announce Type: cross Abstract: Federated learning (FL) has emerged as a promising paradigm for collaboratively training deep learning models across institutions without exchanging sensitive medical data. However, its effectiveness is often hindered by limited data availability and non-independent, identically distributed data across participating clients, which can degrade model performance and generalization. To address these challenges, we propose a generative AI based data augmentation framework that integrates synthetic image sharing into the federated training process for breast cancer diagnosis via ultrasound images. Specifically, we train two simple class-specific Deep Convolutional Generative Adversarial Networks: one for benign and one for malignant lesions. We then simulate a realistic FL setting using three publicly available breast ultrasound image datasets: BUSI, BUS-BRA, and UDIAT. FedAvg and FedProx are adopted as baseline FL algorithms. Experimental results show that incorporating a suitable number of synthetic images improved the average AUC from 0.9206 to 0.9237 for FedAvg and from 0.9429 to 0.9538 for FedProx. We also note that excessive use of synthetic data reduced performance, underscoring the importance of maintaining a balanced ratio of real and synthetic samples. Our findings highlight the potential of generative AI based data augmentation to enhance FL results in the breast ultrasound image classification task.",
    "summary": "arXiv:2506.23334v1 Announce Type: cross Abstract: Federated learning (FL) has emerged as a promising paradigm for collaboratively training deep learning models across institutions without exchanging sensitive medical data. However, its effectiveness is often hindered by limited data availability and non-independent, identically distributed data across participating clients, which can degrade model performance and generalization. To address these challenges, we propose a generative AI based data augmentation framework that integrates synthetic image sharing into the federated training process for breast cancer diagnosis via ultrasound images. Specifically, we train two simple class-specific Deep Convolutional Generative Adversarial Networks: one for benign and one for malignant lesions. We then simulate a realistic FL setting using three publicly available breast ultrasound image datasets: BUSI, BUS-BRA, and UDIAT. FedAvg and FedProx are adopted as baseline FL algorithms. Experimental results show that incorporating a suitable number of synthetic images improved the average AUC from 0.9206 to 0.9237 for FedAvg and from 0.9429 to 0.9538 for FedProx. We also note that excessive use of synthetic data reduced performance, underscoring the importance of maintaining a balanced ratio of real and synthetic samples. Our findings highlight the potential of generative AI based data augmentation to enhance FL results in the breast ultrasound image classification task.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23334",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PixelBoost: Leveraging Brownian Motion for Realistic-Image Super-Resolution",
    "description": "arXiv:2506.23254v1 Announce Type: cross Abstract: Diffusion-model-based image super-resolution techniques often face a trade-off between realistic image generation and computational efficiency. This issue is exacerbated when inference times by decreasing sampling steps, resulting in less realistic and hazy images. To overcome this challenge, we introduce a novel diffusion model named PixelBoost that underscores the significance of embracing the stochastic nature of Brownian motion in advancing image super-resolution, resulting in a high degree of realism, particularly focusing on texture and edge definitions. By integrating controlled stochasticity into the training regimen, our proposed model avoids convergence to local optima, effectively capturing and reproducing the inherent uncertainty of image textures and patterns. Our proposed model demonstrates superior objective results in terms of learned perceptual image patch similarity (LPIPS), lightness order error (LOE), peak signal-to-noise ratio(PSNR), structural similarity index measure (SSIM), as well as visual quality. To determine the edge enhancement, we evaluated the gradient magnitude and pixel value, and our proposed model exhibited a better edge reconstruction capability. Additionally, our model demonstrates adaptive learning capabilities by effectively adjusting to Brownian noise patterns and introduces a sigmoidal noise sequencing method that simplifies training, resulting in faster inference speeds.",
    "summary": "arXiv:2506.23254v1 Announce Type: cross Abstract: Diffusion-model-based image super-resolution techniques often face a trade-off between realistic image generation and computational efficiency. This issue is exacerbated when inference times by decreasing sampling steps, resulting in less realistic and hazy images. To overcome this challenge, we introduce a novel diffusion model named PixelBoost that underscores the significance of embracing the stochastic nature of Brownian motion in advancing image super-resolution, resulting in a high degree of realism, particularly focusing on texture and edge definitions. By integrating controlled stochasticity into the training regimen, our proposed model avoids convergence to local optima, effectively capturing and reproducing the inherent uncertainty of image textures and patterns. Our proposed model demonstrates superior objective results in terms of learned perceptual image patch similarity (LPIPS), lightness order error (LOE), peak signal-to-noise ratio(PSNR), structural similarity index measure (SSIM), as well as visual quality. To determine the edge enhancement, we evaluated the gradient magnitude and pixel value, and our proposed model exhibited a better edge reconstruction capability. Additionally, our model demonstrates adaptive learning capabilities by effectively adjusting to Brownian noise patterns and introduces a sigmoidal noise sequencing method that simplifies training, resulting in faster inference speeds.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23254",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models",
    "description": "",
    "summary": "Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models Florence-2, released by Mic...",
    "pubDate": "Mon, 24 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/finetune-florence2",
    "thumbnail": "https://huggingface.co/blog/assets/182_finetune-florence/thumbnail.png"
  },
  {
    "title": "Competitive programming with AlphaCode",
    "description": "Solving novel problems and setting a new milestone in competitive programming.",
    "summary": "Solving novel problems and setting a new milestone in competitive programming.",
    "pubDate": "Thu, 08 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/competitive-programming-with-alphacode/",
    "thumbnail": "https://lh3.googleusercontent.com/vQ0Ow6LwCpigfPyTGUhXEfdMBWPyHmaCo7eoQW7bv3QoZXW6EIj18FPiCLI1vlMYlUAOvEXta1KSkl8P2KScquYJb-Dm_QygP9kdlLYkpF4nVyEH=w1200-h630-n-nu"
  },
  {
    "title": "Evaluating social and ethical risks from generative AI",
    "description": "Introducing a context-based framework for comprehensively evaluating the social and ethical risks of AI systems",
    "summary": "Introducing a context-based framework for comprehensively evaluating the social and ethical risks of AI systems",
    "pubDate": "Thu, 19 Oct 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/evaluating-social-and-ethical-risks-from-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/LAqM0ZkFzkDefB5oVEEPoq6p--7XcfBWEDPjl6OdcfvwN9q3leY2qWCf30_MquTn5RfpcPswiAoRns2jOKjB5_8u-vl6TqueSwamEM6U-qyJHOiujkI=w1200-h630-n-nu"
  },
  {
    "title": "Fine-Tuning Gemma Models in Hugging Face",
    "description": "",
    "summary": "Fine-Tuning Gemma Models in Hugging Face We recently announced that Gemma, the open weights language...",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma-peft",
    "thumbnail": "https://huggingface.co/blog/assets/gemma-peft/thumbnail.png"
  },
  {
    "title": "Introducing Hugging Face for Education",
    "description": "",
    "summary": "Introducing Hugging Face for Education ü§ó Given that machine learning will make up the overwhelming m...",
    "pubDate": "Mon, 25 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/education",
    "thumbnail": "https://huggingface.co/blog/assets/61_education/thumbnail.png"
  },
  {
    "title": "OpenAI and Future partner on specialist content",
    "description": "OpenAI and Future, the global platform for specialist media, have today announced a strategic partnership to bring content from Future‚Äôs 200 plus media brands to OpenAI‚Äôs users.",
    "summary": "OpenAI and Future, the global platform for specialist media, have today announced a strategic partnership to bring content from Future‚Äôs 200 plus media brands to OpenAI‚Äôs users.",
    "pubDate": "Wed, 04 Dec 2024 23:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-future-partner-on-specialist-content",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PixelCNN++: Improving the PixelCNN with discretized logistic mixture likelihood and other modifications",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 19 Jan 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/pixelcnn-plus-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Transforming the future of music creation",
    "description": "Announcing our most advanced music generation model and two new AI experiments, designed to open a new playground for creativity",
    "summary": "Announcing our most advanced music generation model and two new AI experiments, designed to open a new playground for creativity",
    "pubDate": "Thu, 16 Nov 2023 07:20:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/",
    "thumbnail": "https://lh3.googleusercontent.com/msr-Fc99rrkeoQkZ6rLTKnof3RTqo5oo9D2_xPyqtpp0mAMqqkn-x3mPy2dD0My1g7w-cysBQzHU_iWF4mlblU4EgQRcMNKoBUgPdmdmEoyekFJEnA=w1200-h630-n-nu"
  },
  {
    "title": "Sample then Identify: A General Framework for Risk Control and Assessment in Multimodal Large Language Models",
    "description": "arXiv:2410.08174v3 Announce Type: replace-cross Abstract: Multimodal Large Language Models (MLLMs) exhibit promising advancements across various tasks, yet they still encounter significant trustworthiness issues. Prior studies apply Split Conformal Prediction (SCP) in language modeling to construct prediction sets with statistical guarantees. However, these methods typically rely on internal model logits or are restricted to multiple-choice settings, which hampers their generalizability and adaptability in dynamic, open-ended environments. In this paper, we introduce TRON, a two-step framework for risk control and assessment, applicable to any MLLM that supports sampling in both open-ended and closed-ended scenarios. TRON comprises two main components: (1) a novel conformal score to sample response sets of minimum size, and (2) a nonconformity score to identify high-quality responses based on self-consistency theory, controlling the error rates by two specific risk levels. Furthermore, we investigate semantic redundancy in prediction sets within open-ended contexts for the first time, leading to a promising evaluation metric for MLLMs based on average set size. Our comprehensive experiments across four Video Question-Answering (VideoQA) datasets utilizing eight MLLMs show that TRON achieves desired error rates bounded by two user-specified risk levels. Additionally, deduplicated prediction sets maintain adaptiveness while being more efficient and stable for risk assessment under different risk levels.",
    "summary": "arXiv:2410.08174v3 Announce Type: replace-cross Abstract: Multimodal Large Language Models (MLLMs) exhibit promising advancements across various tasks, yet they still encounter significant trustworthiness issues. Prior studies apply Split Conformal Prediction (SCP) in language modeling to construct prediction sets with statistical guarantees. However, these methods typically rely on internal model logits or are restricted to multiple-choice settings, which hampers their generalizability and adaptability in dynamic, open-ended environments. In this paper, we introduce TRON, a two-step framework for risk control and assessment, applicable to any MLLM that supports sampling in both open-ended and closed-ended scenarios. TRON comprises two main components: (1) a novel conformal score to sample response sets of minimum size, and (2) a nonconformity score to identify high-quality responses based on self-consistency theory, controlling the error rates by two specific risk levels. Furthermore, we investigate semantic redundancy in prediction sets within open-ended contexts for the first time, leading to a promising evaluation metric for MLLMs based on average set size. Our comprehensive experiments across four Video Question-Answering (VideoQA) datasets utilizing eight MLLMs show that TRON achieves desired error rates bounded by two user-specified risk levels. Additionally, deduplicated prediction sets maintain adaptiveness while being more efficient and stable for risk assessment under different risk levels.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.08174",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Habana Labs and Hugging Face Partner to Accelerate Transformer Model Training",
    "description": "",
    "summary": "Habana Labs and Hugging Face Partner to Accelerate Transformer Model Training Santa Clara and San Fr...",
    "pubDate": "Tue, 12 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana",
    "thumbnail": "https://huggingface.co/blog/assets/60_habana/habana.png"
  },
  {
    "title": "Introducing OpenAI o3 and o4-mini",
    "description": "Our smartest and most capable models to date with full tool access",
    "summary": "Our smartest and most capable models to date with full tool access",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-o3-and-o4-mini",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Artificial intelligence enhances air mobility planning",
    "description": "Lincoln Laboratory is transitioning tools to the 618th Air Operations Center to streamline global transport logistics.",
    "summary": "Lincoln Laboratory is transitioning tools to the 618th Air Operations Center to streamline global transport logistics.",
    "pubDate": "Fri, 25 Apr 2025 12:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/artificial-intelligence-enhances-air-mobility-planning-0425",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-lincoln-lab-us-air-mobility-00.jpg"
  },
  {
    "title": "Adversarial training methods for semi-supervised text classification",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 25 May 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adversarial-training-methods-for-semi-supervised-text-classification",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning",
    "description": "arXiv:2310.11594v3 Announce Type: replace-cross Abstract: The delicate equilibrium between user privacy and the ability to unleash the potential of distributed data is an important concern. Federated learning, which enables the training of collaborative models without sharing of data, has emerged as a privacy-centric solution. This approach brings forth security challenges, notably poisoning and backdoor attacks where malicious entities inject corrupted data into the training process, as well as evasion attacks that aim to induce misclassifications at test time. Our research investigates the intersection of adversarial training, a common defense method against evasion attacks, and backdoor attacks within federated learning. We introduce Adversarial Robustness Unhardening (ARU), which is employed by a subset of adversarial clients to intentionally undermine model robustness during federated training, rendering models susceptible to a broader range of evasion attacks. We present extensive experiments evaluating ARU's impact on adversarial training and existing robust aggregation defenses against poisoning and backdoor attacks. Our results show that ARU can substantially undermine adversarial training's ability to harden models against test-time evasion attacks, and that adversaries employing ARU can even evade robust aggregation defenses that often neutralize poisoning or backdoor attacks.",
    "summary": "arXiv:2310.11594v3 Announce Type: replace-cross Abstract: The delicate equilibrium between user privacy and the ability to unleash the potential of distributed data is an important concern. Federated learning, which enables the training of collaborative models without sharing of data, has emerged as a privacy-centric solution. This approach brings forth security challenges, notably poisoning and backdoor attacks where malicious entities inject corrupted data into the training process, as well as evasion attacks that aim to induce misclassifications at test time. Our research investigates the intersection of adversarial training, a common defense method against evasion attacks, and backdoor attacks within federated learning. We introduce Adversarial Robustness Unhardening (ARU), which is employed by a subset of adversarial clients to intentionally undermine model robustness during federated training, rendering models susceptible to a broader range of evasion attacks. We present extensive experiments evaluating ARU's impact on adversarial training and existing robust aggregation defenses against poisoning and backdoor attacks. Our results show that ARU can substantially undermine adversarial training's ability to harden models against test-time evasion attacks, and that adversaries employing ARU can even evade robust aggregation defenses that often neutralize poisoning or backdoor attacks.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2310.11594",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-enabled control system helps autonomous drones stay on target in uncertain environments",
    "description": "The system automatically learns to adapt to unknown disturbances such as gusting winds.",
    "summary": "The system automatically learns to adapt to unknown disturbances such as gusting winds.",
    "pubDate": "Mon, 09 Jun 2025 16:40:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-enabled-control-system-helps-autonomous-drones-uncertain-environments-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_MetaLearning-01.jpg"
  },
  {
    "title": "Delivering high-performance customer support",
    "description": "Decagon and OpenAI deliver high-performance, fully automated customer support at scale",
    "summary": "Decagon and OpenAI deliver high-performance, fully automated customer support at scale",
    "pubDate": "Tue, 29 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/decagon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Multimodal neurons in artificial neural networks",
    "description": "We‚Äôve discovered neurons in CLIP that respond to the same concept whether presented literally, symbolically, or conceptually. This may explain CLIP‚Äôs accuracy in classifying surprising visual renditions of concepts, and is also an important step toward understanding the associations and biases that CLIP and similar models learn.",
    "summary": "We‚Äôve discovered neurons in CLIP that respond to the same concept whether presented literally, symbolically, or conceptually. This may explain CLIP‚Äôs accuracy in classifying surprising visual renditions of concepts, and is also an important step toward understanding the associations and biases that CLIP and similar models learn.",
    "pubDate": "Thu, 04 Mar 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/multimodal-neurons",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PromptAug: Fine-grained Conflict Classification Using Data Augmentation",
    "description": "arXiv:2506.22491v1 Announce Type: cross Abstract: Given the rise of conflicts on social media, effective classification models to detect harmful behaviours are essential. Following the garbage-in-garbage-out maxim, machine learning performance depends heavily on training data quality. However, high-quality labelled data, especially for nuanced tasks like identifying conflict behaviours, is limited, expensive, and difficult to obtain. Additionally, as social media platforms increasingly restrict access to research data, text data augmentation is gaining attention as an alternative to generate training data. Augmenting conflict-related data poses unique challenges due to Large Language Model (LLM) guardrails that prevent generation of offensive content. This paper introduces PromptAug, an innovative LLM-based data augmentation method. PromptAug achieves statistically significant improvements of 2% in both accuracy and F1-score on conflict and emotion datasets. To thoroughly evaluate PromptAug against other data augmentation methods we conduct a robust evaluation using extreme data scarcity scenarios, quantitative diversity analysis and a qualitative thematic analysis. The thematic analysis identifies four problematic patterns in augmented text: Linguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and Augmented Content Misinterpretation. Overall, this work presents PromptAug as an effective method for augmenting data in sensitive tasks like conflict detection, offering a unique, interdisciplinary evaluation grounded in both natural language processing and social science methodology.",
    "summary": "arXiv:2506.22491v1 Announce Type: cross Abstract: Given the rise of conflicts on social media, effective classification models to detect harmful behaviours are essential. Following the garbage-in-garbage-out maxim, machine learning performance depends heavily on training data quality. However, high-quality labelled data, especially for nuanced tasks like identifying conflict behaviours, is limited, expensive, and difficult to obtain. Additionally, as social media platforms increasingly restrict access to research data, text data augmentation is gaining attention as an alternative to generate training data. Augmenting conflict-related data poses unique challenges due to Large Language Model (LLM) guardrails that prevent generation of offensive content. This paper introduces PromptAug, an innovative LLM-based data augmentation method. PromptAug achieves statistically significant improvements of 2% in both accuracy and F1-score on conflict and emotion datasets. To thoroughly evaluate PromptAug against other data augmentation methods we conduct a robust evaluation using extreme data scarcity scenarios, quantitative diversity analysis and a qualitative thematic analysis. The thematic analysis identifies four problematic patterns in augmented text: Linguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and Augmented Content Misinterpretation. Overall, this work presents PromptAug as an effective method for augmenting data in sensitive tasks like conflict detection, offering a unique, interdisciplinary evaluation grounded in both natural language processing and social science methodology.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22491",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Complete Guide to Audio Datasets",
    "description": "",
    "summary": "A Complete Guide to Audio Datasets Introduction ü§ó Datasets is an open-source library for downloading...",
    "pubDate": "Thu, 15 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/audio-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/116_audio_datasets/thumbnail.jpg"
  },
  {
    "title": "More on Dota 2",
    "description": "Our Dota 2 result shows that self-play can catapult the performance of machine learning systems from far below human level to superhuman, given sufficient compute. In the span of a month, our system went from barely matching a high-ranked player to beating the top pros and has continued to improve since then. Supervised deep learning systems can only be as good as their training datasets, but in self-play systems, the available data improves automatically as the agent gets better.",
    "summary": "Our Dota 2 result shows that self-play can catapult the performance of machine learning systems from far below human level to superhuman, given sufficient compute. In the span of a month, our system went from barely matching a high-ranked player to beating the top pros and has continued to improve since then. Supervised deep learning systems can only be as good as their training datasets, but in self-play systems, the available data improves automatically as the agent gets better.",
    "pubDate": "Wed, 16 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/more-on-dota-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Region-Aware CAM: High-Resolution Weakly-Supervised Defect Segmentation via Salient Region Perception",
    "description": "arXiv:2506.22866v1 Announce Type: cross Abstract: Surface defect detection plays a critical role in industrial quality inspection. Recent advances in artificial intelligence have significantly enhanced the automation level of detection processes. However, conventional semantic segmentation and object detection models heavily rely on large-scale annotated datasets, which conflicts with the practical requirements of defect detection tasks. This paper proposes a novel weakly supervised semantic segmentation framework comprising two key components: a region-aware class activation map (CAM) and pseudo-label training. To address the limitations of existing CAM methods, especially low-resolution thermal maps, and insufficient detail preservation, we introduce filtering-guided backpropagation (FGBP), which refines target regions by filtering gradient magnitudes to identify areas with higher relevance to defects. Building upon this, we further develop a region-aware weighted module to enhance spatial precision. Finally, pseudo-label segmentation is implemented to refine the model's performance iteratively. Comprehensive experiments on industrial defect datasets demonstrate the superiority of our method. The proposed framework effectively bridges the gap between weakly supervised learning and high-precision defect segmentation, offering a practical solution for resource-constrained industrial scenarios.",
    "summary": "arXiv:2506.22866v1 Announce Type: cross Abstract: Surface defect detection plays a critical role in industrial quality inspection. Recent advances in artificial intelligence have significantly enhanced the automation level of detection processes. However, conventional semantic segmentation and object detection models heavily rely on large-scale annotated datasets, which conflicts with the practical requirements of defect detection tasks. This paper proposes a novel weakly supervised semantic segmentation framework comprising two key components: a region-aware class activation map (CAM) and pseudo-label training. To address the limitations of existing CAM methods, especially low-resolution thermal maps, and insufficient detail preservation, we introduce filtering-guided backpropagation (FGBP), which refines target regions by filtering gradient magnitudes to identify areas with higher relevance to defects. Building upon this, we further develop a region-aware weighted module to enhance spatial precision. Finally, pseudo-label segmentation is implemented to refine the model's performance iteratively. Comprehensive experiments on industrial defect datasets demonstrate the superiority of our method. The proposed framework effectively bridges the gap between weakly supervised learning and high-precision defect segmentation, offering a practical solution for resource-constrained industrial scenarios.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22866",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing AutoRound: Intel‚Äôs Advanced Quantization for LLMs and VLMs",
    "description": "",
    "summary": "What is AutoRound? As large language models (LLMs) and vision-language models (VLMs) continue to gro...",
    "pubDate": "Tue, 29 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autoround",
    "thumbnail": "https://huggingface.co/blog/assets/autoround/thumbnail.png"
  },
  {
    "title": "ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction",
    "description": "arXiv:2506.22498v1 Announce Type: cross Abstract: Bed-related falls remain a leading source of injury in hospitals and long-term-care facilities, yet many commercial alarms trigger only after a patient has already left the bed. We show that early bed-exit intent can be predicted using only four low-cost load cells mounted under the bed legs. The resulting load signals are first converted into a compact set of complementary images: an RGB line plot that preserves raw waveforms and three texture maps - recurrence plot, Markov transition field, and Gramian angular field - that expose higher-order dynamics. We introduce ViFusionTST, a dual-stream Swin Transformer that processes the line plot and texture maps in parallel and fuses them through cross-attention to learn data-driven modality weights. To provide a realistic benchmark, we collected six months of continuous data from 95 beds in a long-term-care facility. On this real-world dataset ViFusionTST reaches an accuracy of 0.885 and an F1 score of 0.794, surpassing recent 1D and 2D time-series baselines across F1, recall, accuracy, and AUPRC. The results demonstrate that image-based fusion of load-sensor signals for time series classification is a practical and effective solution for real-time, privacy-preserving fall prevention.",
    "summary": "arXiv:2506.22498v1 Announce Type: cross Abstract: Bed-related falls remain a leading source of injury in hospitals and long-term-care facilities, yet many commercial alarms trigger only after a patient has already left the bed. We show that early bed-exit intent can be predicted using only four low-cost load cells mounted under the bed legs. The resulting load signals are first converted into a compact set of complementary images: an RGB line plot that preserves raw waveforms and three texture maps - recurrence plot, Markov transition field, and Gramian angular field - that expose higher-order dynamics. We introduce ViFusionTST, a dual-stream Swin Transformer that processes the line plot and texture maps in parallel and fuses them through cross-attention to learn data-driven modality weights. To provide a realistic benchmark, we collected six months of continuous data from 95 beds in a long-term-care facility. On this real-world dataset ViFusionTST reaches an accuracy of 0.885 and an F1 score of 0.794, surpassing recent 1D and 2D time-series baselines across F1, recall, accuracy, and AUPRC. The results demonstrate that image-based fusion of load-sensor signals for time series classification is a practical and effective solution for real-time, privacy-preserving fall prevention.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22498",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google DeepMind at NeurIPS 2024",
    "description": "Advancing adaptive AI agents, empowering 3D scene creation, and innovating LLM training for a smarter, safer future",
    "summary": "Advancing adaptive AI agents, empowering 3D scene creation, and innovating LLM training for a smarter, safer future",
    "pubDate": "Thu, 05 Dec 2024 17:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-neurips-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/cKpWE16vpsZ21VcH-_SdGF8tQEeEMp2phWFajdBq_A7aMVS2axiXQzd7V8mlHdJm-CXVKh1IaY3yeM_lAwu_zxc6SIBdWahdN6nYoaQqUbC8uU0qoY8=w1200-h630-n-nu"
  },
  {
    "title": "Non-engineers guide: Train a LLaMA 2 chatbot",
    "description": "",
    "summary": "Non-engineers guide: Train a LLaMA 2 chatbot Introduction In this tutorial we will show you how anyo...",
    "pubDate": "Thu, 28 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/Llama2-for-non-engineers",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/tuto.png"
  },
  {
    "title": "Introducing SafeCoder",
    "description": "",
    "summary": "Introducing SafeCoder Today we are excited to announce SafeCoder - a code assistant solution built f...",
    "pubDate": "Tue, 22 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safecoder",
    "thumbnail": "https://huggingface.co/blog/assets/159_safecoder/thumbnail.jpg"
  },
  {
    "title": "Introducing TextImage Augmentation for Document Images",
    "description": "",
    "summary": "Introducing Multimodal TextImage Augmentation for Document Images In this blog post, we provide a tu...",
    "pubDate": "Tue, 06 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/doc_aug_hf_alb",
    "thumbnail": "https://huggingface.co/blog/assets/185_albumentations/thumbnail.png"
  },
  {
    "title": "Use Sparse Autoencoders to Discover Unknown Concepts, Not to Act on Known Concepts",
    "description": "arXiv:2506.23845v1 Announce Type: cross Abstract: While sparse autoencoders (SAEs) have generated significant excitement, a series of negative results have added to skepticism about their usefulness. Here, we establish a conceptual distinction that reconciles competing narratives surrounding SAEs. We argue that while SAEs may be less effective for acting on known concepts, SAEs are powerful tools for discovering unknown concepts. This distinction cleanly separates existing negative and positive results, and suggests several classes of SAE applications. Specifically, we outline use cases for SAEs in (i) ML interpretability, explainability, fairness, auditing, and safety, and (ii) social and health sciences.",
    "summary": "arXiv:2506.23845v1 Announce Type: cross Abstract: While sparse autoencoders (SAEs) have generated significant excitement, a series of negative results have added to skepticism about their usefulness. Here, we establish a conceptual distinction that reconciles competing narratives surrounding SAEs. We argue that while SAEs may be less effective for acting on known concepts, SAEs are powerful tools for discovering unknown concepts. This distinction cleanly separates existing negative and positive results, and suggests several classes of SAE applications. Specifically, we outline use cases for SAEs in (i) ML interpretability, explainability, fairness, auditing, and safety, and (ii) social and health sciences.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23845",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemini 2.5: Our most intelligent models are getting even better",
    "description": "Gemini 2.5 Pro continues to be loved by developers as the best model for coding, and 2.5 Flash is getting even better with a new update. We‚Äôre bringing new capabilities to our models, including Deep Think, an experimental enhanced reasoning mode for 2.5 Pro.",
    "summary": "Gemini 2.5 Pro continues to be loved by developers as the best model for coding, and 2.5 Flash is getting even better with a new update. We‚Äôre bringing new capabilities to our models, including Deep Think, an experimental enhanced reasoning mode for 2.5 Pro.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-our-world-leading-model-is-getting-even-better/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/deep-think__key-art_16-9.width-1300.jpg"
  },
  {
    "title": "Text-Generation Pipeline on Intel¬Æ Gaudi¬Æ 2 AI Accelerator",
    "description": "",
    "summary": "Text-Generation Pipeline on Intel¬Æ Gaudi¬Æ 2 AI Accelerator With the Generative AI (GenAI) revolution...",
    "pubDate": "Thu, 29 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/textgen-pipe-gaudi",
    "thumbnail": "https://huggingface.co/blog/assets/textgen-pipe-gaudi/thumbnail.png"
  },
  {
    "title": "Explanations are a means to an end",
    "description": "arXiv:2506.22740v1 Announce Type: new Abstract: Modern methods for explainable machine learning are designed to describe how models map inputs to outputs--without deep consideration of how these explanations will be used in practice. This paper argues that explanations should be designed and evaluated with a specific end in mind. We describe how to formalize this end in a framework based in statistical decision theory. We show how this functionally-grounded approach can be applied across diverse use cases, such as clinical decision support, providing recourse, or debugging. We demonstrate its use to characterize the maximum 'boost' in performance on a particular task that an explanation could provide an idealized decision-maker, preventing misuse due to ambiguity by forcing researchers to specify concrete use cases that can be analyzed in light of models of expected explanation use. We argue that evaluation should meld theoretical and empirical perspectives on the value of explanation, and contribute definitions that span these perspectives.",
    "summary": "arXiv:2506.22740v1 Announce Type: new Abstract: Modern methods for explainable machine learning are designed to describe how models map inputs to outputs--without deep consideration of how these explanations will be used in practice. This paper argues that explanations should be designed and evaluated with a specific end in mind. We describe how to formalize this end in a framework based in statistical decision theory. We show how this functionally-grounded approach can be applied across diverse use cases, such as clinical decision support, providing recourse, or debugging. We demonstrate its use to characterize the maximum 'boost' in performance on a particular task that an explanation could provide an idealized decision-maker, preventing misuse due to ambiguity by forcing researchers to specify concrete use cases that can be analyzed in light of models of expected explanation use. We argue that evaluation should meld theoretical and empirical perspectives on the value of explanation, and contribute definitions that span these perspectives.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22740",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Rethinking LLM Evaluation with 3C3H: AraGen Benchmark and Leaderboard",
    "description": "",
    "summary": "Rethinking LLM Evaluation with 3C3H: AraGen Benchmark and Leaderboard In the rapidly evolving landsc...",
    "pubDate": "Wed, 04 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-3c3h-aragen",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_3c3h_aragen.png"
  },
  {
    "title": "BigCodeBench: Benchmarking Large Language Models on Solving Practical and Challenging Programming Tasks",
    "description": "",
    "summary": "BigCodeBench: The Next Generation of HumanEval HumanEval is a reference benchmark for evaluating lar...",
    "pubDate": "Tue, 18 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-bigcodebench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_bigcode.png"
  },
  {
    "title": "Very Large Language Models and How to Evaluate Them",
    "description": "",
    "summary": "Very Large Language Models and How to Evaluate Them Large language models can now be evaluated on ze...",
    "pubDate": "Mon, 03 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-shot-eval-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/106_zero_shot_eval_on_the_hub/thumbnail.png"
  },
  {
    "title": "OpenAI‚Äôs EU Economic Blueprint",
    "description": "Today, OpenAI is sharing the EU Economic Blueprint‚Äîa set of proposals to help Europe seize the promise of artificial intelligence, drive sustainable economic growth across the region, and ensure that AI is developed and deployed by Europe, in Europe, for Europe.",
    "summary": "Today, OpenAI is sharing the EU Economic Blueprint‚Äîa set of proposals to help Europe seize the promise of artificial intelligence, drive sustainable economic growth across the region, and ensure that AI is developed and deployed by Europe, in Europe, for Europe.",
    "pubDate": "Mon, 07 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-eu-economic-blueprint",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Google DeepMind at NeurIPS 2023",
    "description": "The Neural Information Processing Systems (NeurIPS) is the largest artificial intelligence (AI) conference in the world. NeurIPS 2023 will be taking place December 10-16 in New Orleans, USA.Teams from across Google DeepMind are presenting more than 150 papers at the main conference and workshops.",
    "summary": "The Neural Information Processing Systems (NeurIPS) is the largest artificial intelligence (AI) conference in the world. NeurIPS 2023 will be taking place December 10-16 in New Orleans, USA.Teams from across Google DeepMind are presenting more than 150 papers at the main conference and workshops.",
    "pubDate": "Fri, 08 Dec 2023 15:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-neurips-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/MDme_Q62zVqvTUs5uwaI3Ggy2rWIujPt2elkusnUuCA4wEo79V9mabIg66j9cr9zMso-LObOVcj6_ZnrgSMUKn6fl52kxOUEjcigXtDZ2UMuosX3-2s=w1200-h630-n-nu"
  },
  {
    "title": "Build awesome datasets for video generation",
    "description": "",
    "summary": "Build awesome datasets for video generation Tooling for image generation datasets is well establishe...",
    "pubDate": "Wed, 12 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vid_ds_scripts",
    "thumbnail": "https://huggingface.co/blog/assets/vid_ds_scripts/thumbnail.png"
  },
  {
    "title": "How good are LLMs at fixing their mistakes? A chatbot arena experiment with Keras and TPUs",
    "description": "",
    "summary": "How good are LLMs at fixing their mistakes? A chatbot arena experiment with Keras and TPUs while you...",
    "pubDate": "Thu, 05 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-chatbot-arena",
    "thumbnail": "https://huggingface.co/blog/assets/keras-chatbot-arena/thumbnail.png"
  },
  {
    "title": "Shaping the future of advanced robotics",
    "description": "Introducing AutoRT, SARA-RT, and RT-Trajectory",
    "summary": "Introducing AutoRT, SARA-RT, and RT-Trajectory",
    "pubDate": "Thu, 04 Jan 2024 11:39:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotics/",
    "thumbnail": "https://lh3.googleusercontent.com/qeWlfSbr0jW0OsZ0dvaQK2V7tYM0HtTtwivx-fUJzK4GivdM6kffvNXlSgqOJyjAQWXBCycqF77zT7XDGxIqGvPiCnTqLX_C3VRmXGJIGGW5GAv7YQ=w1200-h630-n-nu"
  },
  {
    "title": "Supporting sellers with enhanced product listings",
    "description": "Mercari leverages GPT-4o mini and GPT-4 to streamline selling, enhance product listings, and boost sales, transforming the online marketplace with features like AI Listing Support and Mercari AI Assistant.",
    "summary": "Mercari leverages GPT-4o mini and GPT-4 to streamline selling, enhance product listings, and boost sales, transforming the online marketplace with features like AI Listing Support and Mercari AI Assistant.",
    "pubDate": "Thu, 27 Feb 2025 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mercari",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Open-Source Text Generation & LLM Ecosystem at Hugging Face",
    "description": "",
    "summary": "Open-Source Text Generation & LLM Ecosystem at Hugging Face [Updated on July 24, 2023: Added Llama 2...",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/os-llms",
    "thumbnail": "https://huggingface.co/blog/assets/os_llms/thumbnail.png"
  },
  {
    "title": "How OpenAI is approaching 2024 worldwide elections",
    "description": "We‚Äôre working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate voting information.",
    "summary": "We‚Äôre working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate voting information.",
    "pubDate": "Mon, 15 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-openai-is-approaching-2024-worldwide-elections",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving India‚Äôs critical care infrastructure",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 06 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/10bedicu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Safetensors audited as really safe and becoming the default",
    "description": "",
    "summary": "Audit shows that safetensors is safe and ready to become the default Hugging Face, in close collabor...",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safetensors-security-audit",
    "thumbnail": "https://huggingface.co/blog/assets/142_safetensors_official/thumbnail.png"
  },
  {
    "title": "Fit More and Train Faster With ZeRO via DeepSpeed and FairScale",
    "description": "",
    "summary": "Fit More and Train Faster With ZeRO via DeepSpeed and FairScale A guest blog post by Hugging Face fe...",
    "pubDate": "Tue, 19 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-deepspeed-fairscale",
    "thumbnail": "https://huggingface.co/blog/assets/11_zero_deepspeed_fairscale/zero-partitioning.png"
  },
  {
    "title": "INSIGHT: Bridging the Student-Teacher Gap in Times of Large Language Models",
    "description": "arXiv:2504.17677v2 Announce Type: replace-cross Abstract: The rise of AI, especially Large Language Models, presents challenges and opportunities to integrate such technology into the classroom. AI has the potential to revolutionize education by helping teaching staff with various tasks, such as personalizing their teaching methods, but it also raises concerns, for example, about the degradation of student-teacher interactions and user privacy. Based on interviews with teaching staff, this paper introduces INSIGHT, a proof of concept to combine various AI tools to assist teaching staff and students in the process of solving exercises. INSIGHT has a modular design that allows it to be integrated into various higher education courses. We analyze students' questions to an LLM by extracting keywords, which we use to dynamically build an FAQ from students' questions and provide new insights for the teaching staff to use for more personalized face-to-face support. Future work could build upon INSIGHT by using the collected data to provide adaptive learning and adjust content based on student progress and learning styles to offer a more interactive and inclusive learning experience.",
    "summary": "arXiv:2504.17677v2 Announce Type: replace-cross Abstract: The rise of AI, especially Large Language Models, presents challenges and opportunities to integrate such technology into the classroom. AI has the potential to revolutionize education by helping teaching staff with various tasks, such as personalizing their teaching methods, but it also raises concerns, for example, about the degradation of student-teacher interactions and user privacy. Based on interviews with teaching staff, this paper introduces INSIGHT, a proof of concept to combine various AI tools to assist teaching staff and students in the process of solving exercises. INSIGHT has a modular design that allows it to be integrated into various higher education courses. We analyze students' questions to an LLM by extracting keywords, which we use to dynamically build an FAQ from students' questions and provide new insights for the teaching staff to use for more personalized face-to-face support. Future work could build upon INSIGHT by using the collected data to provide adaptive learning and adjust content based on student progress and learning styles to offer a more interactive and inclusive learning experience.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.17677",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GamePad: A learning environment for theorem proving",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 02 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gamepad",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemma Scope: helping the safety community shed light on the inner workings of language models",
    "description": "Announcing a comprehensive, open suite of sparse autoencoders for language model interpretability.",
    "summary": "Announcing a comprehensive, open suite of sparse autoencoders for language model interpretability.",
    "pubDate": "Wed, 31 Jul 2024 15:59:19 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemma-scope-helping-the-safety-community-shed-light-on-the-inner-workings-of-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/4amJbS1Q5bh_CoBHPAc4NEn0Q13izqrskMETkJl3h2Jdku08GryCCjW6BM59OKj1-Q7-8ZFCWlgu7tIMzjRBIXImy8wlgTOxYgJ88fQvYJTye07C=w1200-h630-n-nu"
  },
  {
    "title": "ChatGPT plugins",
    "description": "We‚Äôve implemented initial support for plugins in ChatGPT. Plugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run computations, or use third-party services.",
    "summary": "We‚Äôve implemented initial support for plugins in ChatGPT. Plugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run computations, or use third-party services.",
    "pubDate": "Thu, 23 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-plugins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative Decoding",
    "description": "arXiv:2503.10135v2 Announce Type: replace-cross Abstract: Speculative decoding (SPD) aims to accelerate the auto-regressive token generation process of a target Large Language Model (LLM). Some approaches employ a draft model with multiple heads to predict a sequence of future tokens, where each head handles a token in the sequence. The target LLM verifies the predicted sequence and accepts aligned tokens, enabling efficient multi-token generation. However, existing methods assume that all tokens within a sequence are equally important, employing identical head structures and relying on a single-generation paradigm, either serial or parallel. To this end, we theoretically demonstrate that initial tokens in the draft sequence are more important than later ones. Building on this insight, we propose Gumiho, a hybrid model combining serial and parallel heads. Specifically, given the critical importance of early tokens, we employ a sophisticated Transformer architecture for the early draft heads in a serial configuration to improve accuracy. For later tokens, we utilize multiple lightweight MLP heads operating in parallel to enhance efficiency. By allocating more advanced model structures and longer running times to the early heads, Gumiho achieves improved overall performance. The experimental results demonstrate that our method outperforms existing approaches, fully validating its effectiveness.",
    "summary": "arXiv:2503.10135v2 Announce Type: replace-cross Abstract: Speculative decoding (SPD) aims to accelerate the auto-regressive token generation process of a target Large Language Model (LLM). Some approaches employ a draft model with multiple heads to predict a sequence of future tokens, where each head handles a token in the sequence. The target LLM verifies the predicted sequence and accepts aligned tokens, enabling efficient multi-token generation. However, existing methods assume that all tokens within a sequence are equally important, employing identical head structures and relying on a single-generation paradigm, either serial or parallel. To this end, we theoretically demonstrate that initial tokens in the draft sequence are more important than later ones. Building on this insight, we propose Gumiho, a hybrid model combining serial and parallel heads. Specifically, given the critical importance of early tokens, we employ a sophisticated Transformer architecture for the early draft heads in a serial configuration to improve accuracy. For later tokens, we utilize multiple lightweight MLP heads operating in parallel to enhance efficiency. By allocating more advanced model structures and longer running times to the early heads, Gumiho achieves improved overall performance. The experimental results demonstrate that our method outperforms existing approaches, fully validating its effectiveness.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.10135",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Position: Machine Learning Conferences Should Establish a 'Refutations and Critiques' Track",
    "description": "arXiv:2506.19882v2 Announce Type: replace-cross Abstract: Science progresses by iteratively advancing and correcting humanity's understanding of the world. In machine learning (ML) research, rapid advancements have led to an explosion of publications, but have also led to misleading, incorrect, flawed or perhaps even fraudulent studies being accepted and sometimes highlighted at ML conferences due to the fallibility of peer review. While such mistakes are understandable, ML conferences do not offer robust processes to help the field systematically correct when such errors are made. This position paper argues that ML conferences should establish a dedicated 'Refutations and Critiques' (R&amp;C) Track. This R&amp;C Track would provide a high-profile, reputable platform to support vital research that critically challenges prior research, thereby fostering a dynamic self-correcting research ecosystem. We discuss key considerations including track design, review principles, potential pitfalls, and provide an illustrative example submission concerning a recent ICLR 2025 Oral. We conclude that ML conferences should create official, reputable mechanisms to help ML research self-correct.",
    "summary": "arXiv:2506.19882v2 Announce Type: replace-cross Abstract: Science progresses by iteratively advancing and correcting humanity's understanding of the world. In machine learning (ML) research, rapid advancements have led to an explosion of publications, but have also led to misleading, incorrect, flawed or perhaps even fraudulent studies being accepted and sometimes highlighted at ML conferences due to the fallibility of peer review. While such mistakes are understandable, ML conferences do not offer robust processes to help the field systematically correct when such errors are made. This position paper argues that ML conferences should establish a dedicated 'Refutations and Critiques' (R&amp;C) Track. This R&amp;C Track would provide a high-profile, reputable platform to support vital research that critically challenges prior research, thereby fostering a dynamic self-correcting research ecosystem. We discuss key considerations including track design, review principles, potential pitfalls, and provide an illustrative example submission concerning a recent ICLR 2025 Oral. We conclude that ML conferences should create official, reputable mechanisms to help ML research self-correct.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19882",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model",
    "description": "arXiv:2506.23210v1 Announce Type: cross Abstract: Federated learning(FL) is used for distributed scenarios to train artificial intelligence(AI) models while ensuring users' privacy. In federated learning scenario, the server generally never knows about users' data. This type of concept makes the AI training process efficient in terms of data privacy. However, regarding model performance, federated AI models may not sufficiently satisfy AI users' expectations. Furthermore, AI users have a wide range of different needs. It is not easy to satisfy the whole users needs. These types of issues can be addressed through AI model optimization, fine-tuning, or personalization to achieve optimal model performance. To address model optimization challenges, we propose reference model-based federated learning for optimal fine-tuning, which overcomes catastrophic forgetting in each round. This method is derived from Bayesian parameter-efficient transfer learning, which includes an optimal proximal term and enables overcoming the catastrophic forgetting issue in each round by utilizing a reference model that incorporates previous model parameters. As a result, this method achieves both high model performance and low computing cost.",
    "summary": "arXiv:2506.23210v1 Announce Type: cross Abstract: Federated learning(FL) is used for distributed scenarios to train artificial intelligence(AI) models while ensuring users' privacy. In federated learning scenario, the server generally never knows about users' data. This type of concept makes the AI training process efficient in terms of data privacy. However, regarding model performance, federated AI models may not sufficiently satisfy AI users' expectations. Furthermore, AI users have a wide range of different needs. It is not easy to satisfy the whole users needs. These types of issues can be addressed through AI model optimization, fine-tuning, or personalization to achieve optimal model performance. To address model optimization challenges, we propose reference model-based federated learning for optimal fine-tuning, which overcomes catastrophic forgetting in each round. This method is derived from Bayesian parameter-efficient transfer learning, which includes an optimal proximal term and enables overcoming the catastrophic forgetting issue in each round by utilizing a reference model that incorporates previous model parameters. As a result, this method achieves both high model performance and low computing cost.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23210",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "VisionScores -- A system-segmented image score dataset for deep learning tasks",
    "description": "arXiv:2506.23030v1 Announce Type: cross Abstract: VisionScores presents a novel proposal being the first system-segmented image score dataset, aiming to offer structure-rich, high information-density images for machine and deep learning tasks. Delimited to two-handed piano pieces, it was built to consider not only certain graphic similarity but also composition patterns, as this creative process is highly instrument-dependent. It provides two scenarios in relation to composer and composition type. The first, formed by 14k samples, considers works from different authors but the same composition type, specifically, Sonatinas. The latter, consisting of 10.8K samples, presents the opposite case, various composition types from the same author, being the one selected Franz Liszt. All of the 24.8k samples are formatted as grayscale jpg images of $128 times 512$ pixels. VisionScores supplies the users not only the formatted samples but the systems' order and pieces' metadata. Moreover, unsegmented full-page scores and the pre-formatted images are included for further analysis.",
    "summary": "arXiv:2506.23030v1 Announce Type: cross Abstract: VisionScores presents a novel proposal being the first system-segmented image score dataset, aiming to offer structure-rich, high information-density images for machine and deep learning tasks. Delimited to two-handed piano pieces, it was built to consider not only certain graphic similarity but also composition patterns, as this creative process is highly instrument-dependent. It provides two scenarios in relation to composer and composition type. The first, formed by 14k samples, considers works from different authors but the same composition type, specifically, Sonatinas. The latter, consisting of 10.8K samples, presents the opposite case, various composition types from the same author, being the one selected Franz Liszt. All of the 24.8k samples are formatted as grayscale jpg images of $128 times 512$ pixels. VisionScores supplies the users not only the formatted samples but the systems' order and pieces' metadata. Moreover, unsegmented full-page scores and the pre-formatted images are included for further analysis.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23030",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How we‚Äôre responding to The New York Times‚Äô data demands in order to protect user privacy",
    "description": "OpenAI is fighting a court order at the demands of The New York Times and plaintiffs, which involves retention of consumer ChatGPT and API user data indefinitely. Learn how we‚Äôre working to uphold user privacy, address legal requirements, and stay true to our data protection commitments.",
    "summary": "OpenAI is fighting a court order at the demands of The New York Times and plaintiffs, which involves retention of consumer ChatGPT and API user data indefinitely. Learn how we‚Äôre working to uphold user privacy, address legal requirements, and stay true to our data protection commitments.",
    "pubDate": "Thu, 05 Jun 2025 16:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/response-to-nyt-data-demands",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Remote VAEs for decoding with HF endpoints ü§ó",
    "description": "",
    "summary": "Remote VAEs for decoding with Inference Endpoints ü§ó When operating with latent-space diffusion model...",
    "pubDate": "Mon, 24 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/remote_vae",
    "thumbnail": "https://huggingface.co/blog/assets/remote_vae/thumbnail.png"
  },
  {
    "title": "Retro Contest",
    "description": "We‚Äôre launching a transfer learning contest that measures a reinforcement learning algorithm‚Äôs ability to generalize from previous experience.",
    "summary": "We‚Äôre launching a transfer learning contest that measures a reinforcement learning algorithm‚Äôs ability to generalize from previous experience.",
    "pubDate": "Thu, 05 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retro-contest",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CO‚ÇÇ Emissions and Models Performance: Insights from the Open LLM Leaderboard",
    "description": "",
    "summary": "CO‚ÇÇ Emissions and Models Performance: Insights from the Open LLM Leaderboard Since June 2024, we hav...",
    "pubDate": "Thu, 09 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-emissions-analysis",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "The Transformers Library: standardizing model definitions",
    "description": "",
    "summary": "The Transformers Library: standardizing model definitions TLDR: Going forward, we're aiming for Tran...",
    "pubDate": "Thu, 15 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-model-definition",
    "thumbnail": "https://huggingface.co/blog/assets/transformers-model-definition/transformers-thumbnail.png"
  },
  {
    "title": "„Ç§„Éº„É≠„É≥„Éª„Éû„Çπ„ÇØÊ∞è„ÅÆxAI„Åå1.4ÂÖÜÂÜÜË™øÈÅî„ÄÄGrok„ÇÑ„Éá„Éº„Çø„Çª„É≥„Çø„Éº„ÅÆÈñãÁô∫Âä†ÈÄü",
    "description": "„Ç§„Éº„É≠„É≥„Éª„Éû„Çπ„ÇØÊ∞è„ÅÆAI‰ºÅÊ•≠xAI„Åå„ÄÅ100ÂÑÑ„Éâ„É´„ÇíË™øÈÅî„Åó„Åü„ÄÇÂçäÂàÜ„ÅØÁ§æÂÇµ„ÅÆÁô∫Ë°å„ÇÑÂÄü„ÇäÂÖ•„Çå„ÄÅ„ÇÇ„ÅÜÂçäÂàÜ„ÅØÊ†™ÂºèÁô∫Ë°å„Å´„Çà„Çã„ÇÇ„ÅÆ„ÄÇË™øÈÅî„Çí‰∏ªÂ∞é„Åó„ÅüÁ±≥Morgan Stanley„ÅåX„ÅßÊòé„Çâ„Åã„Å´„Åó„Åü„ÄÇ",
    "summary": "„Ç§„Éº„É≠„É≥„Éª„Éû„Çπ„ÇØÊ∞è„ÅÆAI‰ºÅÊ•≠xAI„Åå„ÄÅ100ÂÑÑ„Éâ„É´„ÇíË™øÈÅî„Åó„Åü„ÄÇÂçäÂàÜ„ÅØÁ§æÂÇµ„ÅÆÁô∫Ë°å„ÇÑÂÄü„ÇäÂÖ•„Çå„ÄÅ„ÇÇ„ÅÜÂçäÂàÜ„ÅØÊ†™ÂºèÁô∫Ë°å„Å´„Çà„Çã„ÇÇ„ÅÆ„ÄÇË™øÈÅî„Çí‰∏ªÂ∞é„Åó„ÅüÁ±≥Morgan Stanley„ÅåX„ÅßÊòé„Çâ„Åã„Å´„Åó„Åü„ÄÇ",
    "pubDate": "Tue, 01 Jul 2025 18:13:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2507/01/news104.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2507/01/cover_news104.jpg"
  },
  {
    "title": "Google DeepMind‚Äôs latest research at ICML 2023",
    "description": "Exploring AI safety, adaptability, and efficiency for the real world",
    "summary": "Exploring AI safety, adaptability, and efficiency for the real world",
    "pubDate": "Thu, 20 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-research-at-icml-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/5UyUwX8KGovLbTZ0Q8Ynf5Nepy-1zyFaVIIwB7ty0Cp1F5wrKrv24aOT91PDo1vpH3T4P0cwtUn1WxxvtU5vqd4J7cBwEK6UsvnTMNL_qramtFbsX28=w1200-h630-n-nu"
  },
  {
    "title": "AI-Generated Song Detection via Lyrics Transcripts",
    "description": "arXiv:2506.18488v2 Announce Type: replace-cross Abstract: The recent rise in capabilities of AI-based music generation tools has created an upheaval in the music industry, necessitating the creation of accurate methods to detect such AI-generated content. This can be done using audio-based detectors; however, it has been shown that they struggle to generalize to unseen generators or when the audio is perturbed. Furthermore, recent work used accurate and cleanly formatted lyrics sourced from a lyrics provider database to detect AI-generated music. However, in practice, such perfect lyrics are not available (only the audio is); this leaves a substantial gap in applicability in real-life use cases. In this work, we instead propose solving this gap by transcribing songs using general automatic speech recognition (ASR) models. We do this using several detectors. The results on diverse, multi-genre, and multi-lingual lyrics show generally strong detection performance across languages and genres, particularly for our best-performing model using Whisper large-v2 and LLM2Vec embeddings. In addition, we show that our method is more robust than state-of-the-art audio-based ones when the audio is perturbed in different ways and when evaluated on different music generators. Our code is available at https://github.com/deezer/robust-AI-lyrics-detection.",
    "summary": "arXiv:2506.18488v2 Announce Type: replace-cross Abstract: The recent rise in capabilities of AI-based music generation tools has created an upheaval in the music industry, necessitating the creation of accurate methods to detect such AI-generated content. This can be done using audio-based detectors; however, it has been shown that they struggle to generalize to unseen generators or when the audio is perturbed. Furthermore, recent work used accurate and cleanly formatted lyrics sourced from a lyrics provider database to detect AI-generated music. However, in practice, such perfect lyrics are not available (only the audio is); this leaves a substantial gap in applicability in real-life use cases. In this work, we instead propose solving this gap by transcribing songs using general automatic speech recognition (ASR) models. We do this using several detectors. The results on diverse, multi-genre, and multi-lingual lyrics show generally strong detection performance across languages and genres, particularly for our best-performing model using Whisper large-v2 and LLM2Vec embeddings. In addition, we show that our method is more robust than state-of-the-art audio-based ones when the audio is perturbed in different ways and when evaluated on different music generators. Our code is available at https://github.com/deezer/robust-AI-lyrics-detection.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18488",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RT-2: New model translates vision and language into action",
    "description": "Robotic Transformer 2 (RT-2) is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for robotic control.",
    "summary": "Robotic Transformer 2 (RT-2) is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for robotic control.",
    "pubDate": "Fri, 28 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/",
    "thumbnail": "https://lh3.googleusercontent.com/ZduBtQRn2mrvSfNqkixe2XktBREieIhekS7NcboCn0E76gFVckUwNLZw74EJ5jIndzxbRoCqCY47iW1-eGi5c_JJV1DFyTmkS91vMnRalgT0rih125s=w1200-h630-n-nu"
  },
  {
    "title": "„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï„ÄÄ7/9ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„ÄÅÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨",
    "description": "<p>AIsmiley„ÅØ„ÄÅ2025Âπ¥7Êúà9Êó•ÔºàÊ∞¥ÔºâÔΩû7Êúà11Êó•ÔºàÈáëÔºâ„Å´ÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨„ÅÆ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„Çπ„ÇíÂá∫Â±ï„Åó„Åæ„Åô„ÄÇ ‰ºöÂ†¥„Åß„ÅØ„ÄÅÊúÄÊñ∞„ÅÆAI„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥„ÇÑ„Éã„É•„Éº„ÇπÁ≠â„ÇíÂèñ„Çä‰∏ä„Åí„ÇãAI„Éù„Éº„Çø [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/'>„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï„ÄÄ7/9ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„ÄÅÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AIsmiley„ÅØ„ÄÅ2025Âπ¥7Êúà9Êó•ÔºàÊ∞¥ÔºâÔΩû7Êúà11Êó•ÔºàÈáëÔºâ„Å´ÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨„ÅÆ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„Çπ„ÇíÂá∫Â±ï„Åó„Åæ„Åô„ÄÇ ‰ºöÂ†¥„Åß„ÅØ„ÄÅÊúÄÊñ∞„ÅÆAI„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥„ÇÑ„Éã„É•„Éº„ÇπÁ≠â„ÇíÂèñ„Çä‰∏ä„Åí„ÇãAI„Éù„Éº„Çø [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/'>„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï„ÄÄ7/9ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„ÄÅÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 04:00:20 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/05/monodukuri-world-tokyo-no37.png"
  },
  {
    "title": "Stable Diffusion with üß® Diffusers",
    "description": "",
    "summary": "Stable Diffusion with üß® Diffusers Stable Diffusion üé® ...using üß® Diffusers Stable Diffusion is a text...",
    "pubDate": "Mon, 22 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable_diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/98_stable_diffusion/thumbnail.png"
  },
  {
    "title": "Sora System Card",
    "description": "Sora is OpenAI‚Äôs video generation model, designed to take text, image, and video inputs and generate a new video as an output. Sora builds on learnings from DALL-E and GPT models, and is designed to give people expanded tools for storytelling and creative expression.",
    "summary": "Sora is OpenAI‚Äôs video generation model, designed to take text, image, and video inputs and generate a new video as an output. Sora builds on learnings from DALL-E and GPT models, and is designed to give people expanded tools for storytelling and creative expression.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Aligning language models to follow instructions",
    "description": "We‚Äôve trained language models that are much better at following user intentions than GPT-3 while also making them more truthful and less toxic, using techniques developed through our alignment research. These¬†InstructGPT¬†models, which are trained with humans in the loop, are now deployed as the default language models on our¬†API.",
    "summary": "We‚Äôve trained language models that are much better at following user intentions than GPT-3 while also making them more truthful and less toxic, using techniques developed through our alignment research. These¬†InstructGPT¬†models, which are trained with humans in the loop, are now deployed as the default language models on our¬†API.",
    "pubDate": "Thu, 27 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/instruction-following",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI safety via debate",
    "description": "We‚Äôre proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.",
    "summary": "We‚Äôre proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.",
    "pubDate": "Thu, 03 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/debate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pollen-Vision: Unified interface for Zero-Shot vision models in robotics",
    "description": "",
    "summary": "Pollen-Vision: Unified interface for Zero-Shot vision models in robotics This is a guest blog post b...",
    "pubDate": "Mon, 25 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pollen-vision",
    "thumbnail": "https://huggingface.co/blog/assets/pollen-vision/thumbnail.jpg"
  },
  {
    "title": "How AI training scales",
    "description": "We‚Äôve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks. Since complex tasks tend to have noisier gradients, increasingly large batch sizes are likely to become useful in the future, removing one potential limit to further growth of AI systems. More broadly, these results show that neural network training need not be considered a mysterious art, but can be rigorized and¬†systematized.",
    "summary": "We‚Äôve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks. Since complex tasks tend to have noisier gradients, increasingly large batch sizes are likely to become useful in the future, removing one potential limit to further growth of AI systems. More broadly, these results show that neural network training need not be considered a mysterious art, but can be rigorized and¬†systematized.",
    "pubDate": "Fri, 14 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-ai-training-scales",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Don't repeat yourself - ü§ó Transformers Design Philosophy",
    "description": "",
    "summary": "Don't Repeat Yourself* Designing open-source libraries for modern machine learning ü§ó Transformers De...",
    "pubDate": "Tue, 05 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-design-philosophy",
    "thumbnail": "https://huggingface.co/blog/assets/59_transformers_philosophy/transformers.png"
  },
  {
    "title": "OpenAI and journalism",
    "description": "We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.",
    "summary": "We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.",
    "pubDate": "Mon, 08 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-journalism",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaGenome: AI for better understanding the genome",
    "description": "Introducing a new, unifying DNA sequence model that advances regulatory variant-effect prediction and promises to shed new light on genome function ‚Äî now available via API.",
    "summary": "Introducing a new, unifying DNA sequence model that advances regulatory variant-effect prediction and promises to shed new light on genome function ‚Äî now available via API.",
    "pubDate": "Wed, 25 Jun 2025 13:59:51 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/",
    "thumbnail": "https://lh3.googleusercontent.com/SZkcKUQyLUhSQ06Rq-PJbxAqn1OpMeEa3khkrBVB1MGyHfxyftoqWwEb2aLP9JxX7CjhpLFODcc5zIoMoNdu0bl6ELsZV2nP9fDwZC6SYS36lzAKDw=w1200-h630-n-nu"
  },
  {
    "title": "Introducing the Open Arabic LLM Leaderboard",
    "description": "",
    "summary": "Introducing the Open Arabic LLM Leaderboard The Open Arabic LLM Leaderboard (OALL) is designed to ad...",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-arabic",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_arabic.png"
  },
  {
    "title": "Differentially Private Synthetic Data Release for Topics API Outputs",
    "description": "arXiv:2506.23855v1 Announce Type: cross Abstract: The analysis of the privacy properties of Privacy-Preserving Ads APIs is an area of research that has received strong interest from academics, industry, and regulators. Despite this interest, the empirical study of these methods is hindered by the lack of publicly available data. Reliable empirical analysis of the privacy properties of an API, in fact, requires access to a dataset consisting of realistic API outputs; however, privacy concerns prevent the general release of such data to the public. In this work, we develop a novel methodology to construct synthetic API outputs that are simultaneously realistic enough to enable accurate study and provide strong privacy protections. We focus on one Privacy-Preserving Ads APIs: the Topics API, part of Google Chrome's Privacy Sandbox. We developed a methodology to generate a differentially-private dataset that closely matches the re-identification risk properties of the real Topics API data. The use of differential privacy provides strong theoretical bounds on the leakage of private user information from this release. Our methodology is based on first computing a large number of differentially-private statistics describing how output API traces evolve over time. Then, we design a parameterized distribution over sequences of API traces and optimize its parameters so that they closely match the statistics obtained. Finally, we create the synthetic data by drawing from this distribution. Our work is complemented by an open-source release of the anonymized dataset obtained by this methodology. We hope this will enable external researchers to analyze the API in-depth and replicate prior and future work on a realistic large-scale dataset. We believe that this work will contribute to fostering transparency regarding the privacy properties of Privacy-Preserving Ads APIs.",
    "summary": "arXiv:2506.23855v1 Announce Type: cross Abstract: The analysis of the privacy properties of Privacy-Preserving Ads APIs is an area of research that has received strong interest from academics, industry, and regulators. Despite this interest, the empirical study of these methods is hindered by the lack of publicly available data. Reliable empirical analysis of the privacy properties of an API, in fact, requires access to a dataset consisting of realistic API outputs; however, privacy concerns prevent the general release of such data to the public. In this work, we develop a novel methodology to construct synthetic API outputs that are simultaneously realistic enough to enable accurate study and provide strong privacy protections. We focus on one Privacy-Preserving Ads APIs: the Topics API, part of Google Chrome's Privacy Sandbox. We developed a methodology to generate a differentially-private dataset that closely matches the re-identification risk properties of the real Topics API data. The use of differential privacy provides strong theoretical bounds on the leakage of private user information from this release. Our methodology is based on first computing a large number of differentially-private statistics describing how output API traces evolve over time. Then, we design a parameterized distribution over sequences of API traces and optimize its parameters so that they closely match the statistics obtained. Finally, we create the synthetic data by drawing from this distribution. Our work is complemented by an open-source release of the anonymized dataset obtained by this methodology. We hope this will enable external researchers to analyze the API in-depth and replicate prior and future work on a realistic large-scale dataset. We believe that this work will contribute to fostering transparency regarding the privacy properties of Privacy-Preserving Ads APIs.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23855",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Speech Synthesis, Recognition, and More With SpeechT5",
    "description": "",
    "summary": "Speech Synthesis, Recognition, and More With SpeechT5 We‚Äôre happy to announce that SpeechT5 is now a...",
    "pubDate": "Wed, 08 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/speecht5",
    "thumbnail": "https://huggingface.co/blog/assets/speecht5/thumbnail.png"
  },
  {
    "title": "EAGLE: Efficient Alignment of Generalized Latent Embeddings for Multimodal Survival Prediction with Interpretable Attribution Analysis",
    "description": "arXiv:2506.22446v1 Announce Type: cross Abstract: Accurate cancer survival prediction requires integration of diverse data modalities that reflect the complex interplay between imaging, clinical parameters, and textual reports. However, existing multimodal approaches suffer from simplistic fusion strategies, massive computational requirements, and lack of interpretability-critical barriers to clinical adoption. We present EAGLE (Efficient Alignment of Generalized Latent Embeddings), a novel deep learning framework that addresses these limitations through attention-based multimodal fusion with comprehensive attribution analysis. EAGLE introduces four key innovations: (1) dynamic cross-modal attention mechanisms that learn hierarchical relationships between modalities, (2) massive dimensionality reduction (99.96%) while maintaining predictive performance, (3) three complementary attribution methods providing patient-level interpretability, and (4) a unified pipeline enabling seamless adaptation across cancer types. We evaluated EAGLE on 911 patients across three distinct malignancies: glioblastoma (GBM, n=160), intraductal papillary mucinous neoplasms (IPMN, n=171), and non-small cell lung cancer (NSCLC, n=580). Patient-level analysis showed high-risk individuals relied more heavily on adverse imaging features, while low-risk patients demonstrated balanced modality contributions. Risk stratification identified clinically meaningful groups with 4-fold (GBM) to 5-fold (NSCLC) differences in median survival, directly informing treatment intensity decisions. By combining state-of-the-art performance with clinical interpretability, EAGLE bridges the gap between advanced AI capabilities and practical healthcare deployment, offering a scalable solution for multimodal survival prediction that enhances both prognostic accuracy and physician trust in automated predictions.",
    "summary": "arXiv:2506.22446v1 Announce Type: cross Abstract: Accurate cancer survival prediction requires integration of diverse data modalities that reflect the complex interplay between imaging, clinical parameters, and textual reports. However, existing multimodal approaches suffer from simplistic fusion strategies, massive computational requirements, and lack of interpretability-critical barriers to clinical adoption. We present EAGLE (Efficient Alignment of Generalized Latent Embeddings), a novel deep learning framework that addresses these limitations through attention-based multimodal fusion with comprehensive attribution analysis. EAGLE introduces four key innovations: (1) dynamic cross-modal attention mechanisms that learn hierarchical relationships between modalities, (2) massive dimensionality reduction (99.96%) while maintaining predictive performance, (3) three complementary attribution methods providing patient-level interpretability, and (4) a unified pipeline enabling seamless adaptation across cancer types. We evaluated EAGLE on 911 patients across three distinct malignancies: glioblastoma (GBM, n=160), intraductal papillary mucinous neoplasms (IPMN, n=171), and non-small cell lung cancer (NSCLC, n=580). Patient-level analysis showed high-risk individuals relied more heavily on adverse imaging features, while low-risk patients demonstrated balanced modality contributions. Risk stratification identified clinically meaningful groups with 4-fold (GBM) to 5-fold (NSCLC) differences in median survival, directly informing treatment intensity decisions. By combining state-of-the-art performance with clinical interpretability, EAGLE bridges the gap between advanced AI capabilities and practical healthcare deployment, offering a scalable solution for multimodal survival prediction that enhances both prognostic accuracy and physician trust in automated predictions.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22446",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models",
    "description": "arXiv:2506.23576v1 Announce Type: new Abstract: Recent advances in large language models (LLMs) have raised concerns about jailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper investigates the use of multi-agent LLM systems as a defence against such attacks. We evaluate three jailbreaking strategies, including the original AutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the AutoDefense framework, we compare single-agent setups with two- and three-agent configurations. Our results show that multi-agent systems enhance resistance to jailbreaks, especially by reducing false negatives. However, its effectiveness varies by attack type, and it introduces trade-offs such as increased false positives and computational overhead. These findings point to the limitations of current automated defences and suggest directions for improving alignment robustness in future LLM systems.",
    "summary": "arXiv:2506.23576v1 Announce Type: new Abstract: Recent advances in large language models (LLMs) have raised concerns about jailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper investigates the use of multi-agent LLM systems as a defence against such attacks. We evaluate three jailbreaking strategies, including the original AutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the AutoDefense framework, we compare single-agent setups with two- and three-agent configurations. Our results show that multi-agent systems enhance resistance to jailbreaks, especially by reducing false negatives. However, its effectiveness varies by attack type, and it introduces trade-offs such as increased false positives and computational overhead. These findings point to the limitations of current automated defences and suggest directions for improving alignment robustness in future LLM systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23576",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation",
    "description": "arXiv:2506.22567v1 Announce Type: cross Abstract: CLIP models pretrained on natural images with billion-scale image-text pairs have demonstrated impressive capabilities in zero-shot classification, cross-modal retrieval, and open-ended visual answering. However, transferring this success to biomedicine is hindered by the scarcity of large-scale biomedical image-text corpora, the heterogeneity of image modalities, and fragmented data standards across institutions. These limitations hinder the development of a unified and generalizable biomedical foundation model trained from scratch. To overcome this, we introduce MMKD-CLIP, a generalist biomedical foundation model developed via Multiple Medical CLIP Knowledge Distillation. Rather than relying on billion-scale raw data, MMKD-CLIP distills knowledge from nine state-of-the-art domain-specific or generalist biomedical CLIP models, each pretrained on millions of biomedical image-text pairs. Our two-stage training pipeline first performs CLIP-style pretraining on over 2.9 million biomedical image-text pairs from 26 image modalities, followed by feature-level distillation using over 19.2 million feature pairs extracted from teacher models. We evaluate MMKD-CLIP on 58 diverse biomedical datasets, encompassing over 10.8 million biomedical images across nine image modalities. The evaluation spans six core task types: zero-shot classification, linear probing, cross-modal retrieval, visual question answering, survival prediction, and cancer diagnosis. MMKD-CLIP consistently outperforms all teacher models while demonstrating remarkable robustness and generalization across image domains and task settings. These results underscore that multi-teacher knowledge distillation is a scalable and effective paradigm for building high-performing biomedical foundation models under the practical constraints of real-world data availability.",
    "summary": "arXiv:2506.22567v1 Announce Type: cross Abstract: CLIP models pretrained on natural images with billion-scale image-text pairs have demonstrated impressive capabilities in zero-shot classification, cross-modal retrieval, and open-ended visual answering. However, transferring this success to biomedicine is hindered by the scarcity of large-scale biomedical image-text corpora, the heterogeneity of image modalities, and fragmented data standards across institutions. These limitations hinder the development of a unified and generalizable biomedical foundation model trained from scratch. To overcome this, we introduce MMKD-CLIP, a generalist biomedical foundation model developed via Multiple Medical CLIP Knowledge Distillation. Rather than relying on billion-scale raw data, MMKD-CLIP distills knowledge from nine state-of-the-art domain-specific or generalist biomedical CLIP models, each pretrained on millions of biomedical image-text pairs. Our two-stage training pipeline first performs CLIP-style pretraining on over 2.9 million biomedical image-text pairs from 26 image modalities, followed by feature-level distillation using over 19.2 million feature pairs extracted from teacher models. We evaluate MMKD-CLIP on 58 diverse biomedical datasets, encompassing over 10.8 million biomedical images across nine image modalities. The evaluation spans six core task types: zero-shot classification, linear probing, cross-modal retrieval, visual question answering, survival prediction, and cancer diagnosis. MMKD-CLIP consistently outperforms all teacher models while demonstrating remarkable robustness and generalization across image domains and task settings. These results underscore that multi-teacher knowledge distillation is a scalable and effective paradigm for building high-performing biomedical foundation models under the practical constraints of real-world data availability.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22567",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hierarchical text-conditional image generation with CLIP latents",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Apr 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hierarchical-text-conditional-image-generation-with-clip-latents",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating Audio Reasoning with Big Bench Audio",
    "description": "",
    "summary": "Evaluating Audio Reasoning with Big Bench Audio The emergence of native Speech to Speech models offe...",
    "pubDate": "Fri, 20 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/big-bench-audio-release",
    "thumbnail": "https://huggingface.co/blog/assets/big_bench_audio_release/big-bench-audio-thumbnail.png"
  },
  {
    "title": "DisCoPatch: Taming Adversarially-driven Batch Statistics for Improved Out-of-Distribution Detection",
    "description": "arXiv:2501.08005v4 Announce Type: replace-cross Abstract: Out-of-distribution (OOD) detection holds significant importance across many applications. While semantic and domain-shift OOD problems are well-studied, this work focuses on covariate shifts - subtle variations in the data distribution that can degrade machine learning performance. We hypothesize that detecting these subtle shifts can improve our understanding of in-distribution boundaries, ultimately improving OOD detection. In adversarial discriminators trained with Batch Normalization (BN), real and adversarial samples form distinct domains with unique batch statistics - a property we exploit for OOD detection. We introduce DisCoPatch, an unsupervised Adversarial Variational Autoencoder (VAE) framework that harnesses this mechanism. During inference, batches consist of patches from the same image, ensuring a consistent data distribution that allows the model to rely on batch statistics. DisCoPatch uses the VAE's suboptimal outputs (generated and reconstructed) as negative samples to train the discriminator, thereby improving its ability to delineate the boundary between in-distribution samples and covariate shifts. By tightening this boundary, DisCoPatch achieves state-of-the-art results in public OOD detection benchmarks. The proposed model not only excels in detecting covariate shifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior methods on public Near-OOD (95.0%) benchmarks. With a compact model size of 25MB, it achieves high OOD detection performance at notably lower latency than existing methods, making it an efficient and practical solution for real-world OOD detection applications. The code is publicly available.",
    "summary": "arXiv:2501.08005v4 Announce Type: replace-cross Abstract: Out-of-distribution (OOD) detection holds significant importance across many applications. While semantic and domain-shift OOD problems are well-studied, this work focuses on covariate shifts - subtle variations in the data distribution that can degrade machine learning performance. We hypothesize that detecting these subtle shifts can improve our understanding of in-distribution boundaries, ultimately improving OOD detection. In adversarial discriminators trained with Batch Normalization (BN), real and adversarial samples form distinct domains with unique batch statistics - a property we exploit for OOD detection. We introduce DisCoPatch, an unsupervised Adversarial Variational Autoencoder (VAE) framework that harnesses this mechanism. During inference, batches consist of patches from the same image, ensuring a consistent data distribution that allows the model to rely on batch statistics. DisCoPatch uses the VAE's suboptimal outputs (generated and reconstructed) as negative samples to train the discriminator, thereby improving its ability to delineate the boundary between in-distribution samples and covariate shifts. By tightening this boundary, DisCoPatch achieves state-of-the-art results in public OOD detection benchmarks. The proposed model not only excels in detecting covariate shifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior methods on public Near-OOD (95.0%) benchmarks. With a compact model size of 25MB, it achieves high OOD detection performance at notably lower latency than existing methods, making it an efficient and practical solution for real-world OOD detection applications. The code is publicly available.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.08005",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sentiment Classification with Fully Homomorphic Encryption using Concrete ML",
    "description": "",
    "summary": "Sentiment Analysis on Encrypted Data with Homomorphic Encryption It is well-known that a sentiment a...",
    "pubDate": "Thu, 17 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-fhe",
    "thumbnail": "https://huggingface.co/blog/assets/sentiment-analysis-fhe/thumbnail.png"
  },
  {
    "title": "Democratic inputs to AI grant program: lessons learned and implementation plans",
    "description": "We funded 10 teams from around the world to design ideas and tools to collectively govern AI. We summarize the innovations, outline our learnings, and call for researchers and engineers to join us as we continue this work.",
    "summary": "We funded 10 teams from around the world to design ideas and tools to collectively govern AI. We summarize the innovations, outline our learnings, and call for researchers and engineers to join us as we continue this work.",
    "pubDate": "Tue, 16 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/democratic-inputs-to-ai-grant-program-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Expert Support case study: Bolstering a RAG app with LLM-as-a-Judge",
    "description": "",
    "summary": "Expert Support case study: Bolstering a RAG app with LLM-as-a-Judge This is a guest blog post author...",
    "pubDate": "Mon, 28 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/digital-green-llm-judge",
    "thumbnail": "https://huggingface.co/blog/assets/digital-gren-llm-judge/thumbnail.png"
  },
  {
    "title": "Measuring Goodhart‚Äôs law",
    "description": "Goodhart‚Äôs law¬†famously says: ‚ÄúWhen a measure becomes a target, it ceases to be a good measure.‚Äù Although originally from economics, it‚Äôs something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
    "summary": "Goodhart‚Äôs law¬†famously says: ‚ÄúWhen a measure becomes a target, it ceases to be a good measure.‚Äù Although originally from economics, it‚Äôs something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
    "pubDate": "Wed, 13 Apr 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/measuring-goodharts-law",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Unsupervised sentiment neuron",
    "description": "We‚Äôve developed an unsupervised system which learns an excellent representation of sentiment, despite being trained only to predict the next character in the text of Amazon reviews.",
    "summary": "We‚Äôve developed an unsupervised system which learns an excellent representation of sentiment, despite being trained only to predict the next character in the text of Amazon reviews.",
    "pubDate": "Thu, 06 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/unsupervised-sentiment-neuron",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Automating Adjudication of Cardiovascular Events Using Large Language Models",
    "description": "arXiv:2503.17222v2 Announce Type: replace-cross Abstract: Cardiovascular events, such as heart attacks and strokes, remain a leading cause of mortality globally, necessitating meticulous monitoring and adjudication in clinical trials. This process, traditionally performed manually by clinical experts, is time-consuming, resource-intensive, and prone to inter-reviewer variability, potentially introducing bias and hindering trial progress. This study addresses these critical limitations by presenting a novel framework for automating the adjudication of cardiovascular events in clinical trials using Large Language Models (LLMs). We developed a two-stage approach: first, employing an LLM-based pipeline for event information extraction from unstructured clinical data and second, using an LLM-based adjudication process guided by a Tree of Thoughts approach and clinical endpoint committee (CEC) guidelines. Using cardiovascular event-specific clinical trial data, the framework achieved an F1-score of 0.82 for event extraction and an accuracy of 0.68 for adjudication. Furthermore, we introduce the CLEART score, a novel, automated metric specifically designed for evaluating the quality of AI-generated clinical reasoning in adjudicating cardiovascular events. This approach demonstrates significant potential for substantially reducing adjudication time and costs while maintaining high-quality, consistent, and auditable outcomes in clinical trials. The reduced variability and enhanced standardization also allow for faster identification and mitigation of risks associated with cardiovascular therapies.",
    "summary": "arXiv:2503.17222v2 Announce Type: replace-cross Abstract: Cardiovascular events, such as heart attacks and strokes, remain a leading cause of mortality globally, necessitating meticulous monitoring and adjudication in clinical trials. This process, traditionally performed manually by clinical experts, is time-consuming, resource-intensive, and prone to inter-reviewer variability, potentially introducing bias and hindering trial progress. This study addresses these critical limitations by presenting a novel framework for automating the adjudication of cardiovascular events in clinical trials using Large Language Models (LLMs). We developed a two-stage approach: first, employing an LLM-based pipeline for event information extraction from unstructured clinical data and second, using an LLM-based adjudication process guided by a Tree of Thoughts approach and clinical endpoint committee (CEC) guidelines. Using cardiovascular event-specific clinical trial data, the framework achieved an F1-score of 0.82 for event extraction and an accuracy of 0.68 for adjudication. Furthermore, we introduce the CLEART score, a novel, automated metric specifically designed for evaluating the quality of AI-generated clinical reasoning in adjudicating cardiovascular events. This approach demonstrates significant potential for substantially reducing adjudication time and costs while maintaining high-quality, consistent, and auditable outcomes in clinical trials. The reduced variability and enhanced standardization also allow for faster identification and mitigation of risks associated with cardiovascular therapies.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.17222",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing ‚öîÔ∏è AI vs. AI ‚öîÔ∏è a deep reinforcement learning multi-agents competition system",
    "description": "",
    "summary": "Introducing ‚öîÔ∏è AI vs. AI ‚öîÔ∏è a deep reinforcement learning multi-agents competition system We‚Äôre exci...",
    "pubDate": "Tue, 07 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aivsai",
    "thumbnail": "https://huggingface.co/blog/assets/128_aivsai/thumbnail.png"
  },
  {
    "title": "Proximal Policy Optimization (PPO)",
    "description": "",
    "summary": "Proximal Policy Optimization (PPO) Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 8, of ...",
    "pubDate": "Fri, 05 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-ppo",
    "thumbnail": "https://huggingface.co/blog/assets/93_deep_rl_ppo/thumbnail.png"
  },
  {
    "title": "RL¬≤: Fast reinforcement learning via slow reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 09 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rl2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Large-scale study of curiosity-driven learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 13 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/large-scale-study-of-curiosity-driven-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI„Åå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Å´„ÄÅAIÂà©Áî®ËÄÖ„ÅÆÂçäÊï∞‰ª•‰∏ä„ÅåÂà©Áî®",
    "description": "<p>NEXER„Å®„Éù„Éº„É´„Éà„Ç•„Ç¶„Ç£„É≥„Åå„ÄÅÊôÆÊÆµAI„ÇíÂà©Áî®„Åô„ÇãÂÖ®ÂõΩ238Âêç„ÇíÂØæË±°„Å´ÂÆüÊñΩ„Åó„ÅüË™øÊüª„Åß„ÄÅÂçäÊï∞‰ª•‰∏ä„Åå„Äå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Äç„Å®„Åó„Å¶AI„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Çã„Å®Áô∫Ë°®„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà AIÂà©Áî®ËÄÖ„ÅÆ 51.3%„Åå„Äå„Éó„É© [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/use-ai-private-consultant/'>AI„Åå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Å´„ÄÅAIÂà©Áî®ËÄÖ„ÅÆÂçäÊï∞‰ª•‰∏ä„ÅåÂà©Áî®</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>NEXER„Å®„Éù„Éº„É´„Éà„Ç•„Ç¶„Ç£„É≥„Åå„ÄÅÊôÆÊÆµAI„ÇíÂà©Áî®„Åô„ÇãÂÖ®ÂõΩ238Âêç„ÇíÂØæË±°„Å´ÂÆüÊñΩ„Åó„ÅüË™øÊüª„Åß„ÄÅÂçäÊï∞‰ª•‰∏ä„Åå„Äå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Äç„Å®„Åó„Å¶AI„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Çã„Å®Áô∫Ë°®„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà AIÂà©Áî®ËÄÖ„ÅÆ 51.3%„Åå„Äå„Éó„É© [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/use-ai-private-consultant/'>AI„Åå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Å´„ÄÅAIÂà©Áî®ËÄÖ„ÅÆÂçäÊï∞‰ª•‰∏ä„ÅåÂà©Áî®</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Fri, 27 Jun 2025 05:08:11 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/use-ai-private-consultant/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/use-ai-private-consultant1.png"
  },
  {
    "title": "AI Testing and Evaluation: Learnings from genome editing",
    "description": "<p>Bioethics and law expert R. Alta Charo explores the value of regulating technologies at the application level and the role of coordinated oversight in genome editing, while Microsoft GM Daniel Kluttz reflects on Charo‚Äôs points, drawing parallels to AI governance.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/'>AI Testing and Evaluation: Learnings from genome editing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Bioethics and law expert R. Alta Charo explores the value of regulating technologies at the application level and the role of coordinated oversight in genome editing, while Microsoft GM Daniel Kluttz reflects on Charo‚Äôs points, drawing parallels to AI governance.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/'>AI Testing and Evaluation: Learnings from genome editing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Mon, 30 Jun 2025 16:00:17 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Team++",
    "description": "We've had some fantastic people join over the past few months (and we're still hiring). Welcome, everyone!",
    "summary": "We've had some fantastic people join over the past few months (and we're still hiring). Welcome, everyone!",
    "pubDate": "Thu, 31 Mar 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-plus-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Build rich, interactive web apps with an updated Gemini 2.5 Pro",
    "description": "Our updated version of Gemini 2.5 Pro Preview has improved capabilities for coding.",
    "summary": "Our updated version of Gemini 2.5 Pro Preview has improved capabilities for coding.",
    "pubDate": "Tue, 06 May 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/build-rich-interactive-web-apps-with-an-updated-gemini-25-pro/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini25prohero.width-1300.png"
  },
  {
    "title": "OpenAI Robotics Symposium 2019",
    "description": "We hosted the first OpenAI Robotics Symposium on April 27, 2019.",
    "summary": "We hosted the first OpenAI Robotics Symposium on April 27, 2019.",
    "pubDate": "Wed, 05 Jun 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/symposium-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "‰ΩèÂèãÁîüÂëΩ„ÄÅPFN„Å´Âá∫Ë≥á„ÄÄ„ÄåÂçîÊ•≠„ÇÇÊ§úË®é„Äç",
    "description": "‰ΩèÂèãÁîüÂëΩ„ÅØAI„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó„ÅÆPreferred NetworksÔºàPFNÔºâ„Å´Âá∫Ë≥á„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇPFN„Å®„ÅÆÂçîÊ•≠„ÇÇÊ§úË®é„Åô„Çã„ÄÇ",
    "summary": "‰ΩèÂèãÁîüÂëΩ„ÅØAI„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó„ÅÆPreferred NetworksÔºàPFNÔºâ„Å´Âá∫Ë≥á„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇPFN„Å®„ÅÆÂçîÊ•≠„ÇÇÊ§úË®é„Åô„Çã„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 15:35:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/30/news104.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/30/cover_news104.png"
  },
  {
    "title": "Introducing OpenAI for Countries",
    "description": "A new initiative to support countries around the world that want to build on democratic AI rails.",
    "summary": "A new initiative to support countries around the world that want to build on democratic AI rails.",
    "pubDate": "Wed, 07 May 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-for-countries",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generating audio for video",
    "description": "Video-to-audio research uses video pixels and text prompts to generate rich soundtracks",
    "summary": "Video-to-audio research uses video pixels and text prompts to generate rich soundtracks",
    "pubDate": "Mon, 17 Jun 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/generating-audio-for-video/",
    "thumbnail": "https://lh3.googleusercontent.com/Lzihw4F171DQeSgZ9q0MUONzbt1BkbK1sOgnqvLAV3AUIQQ1UJ4niEXOTgWiiyKZrJaCpE4Q6APwV8RRQj7a86_2yDlbIV6WUzD6S_Gu2mjuZDyVWqo=w1200-h630-n-nu"
  },
  {
    "title": "Sora first impressions",
    "description": "Since we introduced Sora to the world last month, we‚Äôve been working with artists to learn how Sora might aid in their creative process.",
    "summary": "Since we introduced Sora to the world last month, we‚Äôve been working with artists to learn how Sora might aid in their creative process.",
    "pubDate": "Mon, 25 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-first-impressions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Illustrating Reinforcement Learning from Human Feedback (RLHF)",
    "description": "",
    "summary": "Illustrating Reinforcement Learning from Human Feedback (RLHF) This article has been translated to C...",
    "pubDate": "Fri, 09 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rlhf",
    "thumbnail": "https://huggingface.co/blog/assets/120_rlhf/thumbnail.png"
  },
  {
    "title": "Machine Learning Experts - Meg Mitchell Interview",
    "description": "",
    "summary": "Machine Learning Experts - Margaret Mitchell Hey friends! Welcome to Machine Learning Experts. I'm y...",
    "pubDate": "Wed, 23 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/meg-mitchell-interview",
    "thumbnail": "https://huggingface.co/blog/assets/57_meg_mitchell_interview/thumbnail.png"
  },
  {
    "title": "Combining technology, education, and human connection to improve online learning",
    "description": "Caitlin Morris, a PhD student and 2024 MAD Fellow affiliated with the MIT Media Lab, designs digital learning platforms that make room for the ‚Äúsocial magic‚Äù that influences curiosity and motivation.",
    "summary": "Caitlin Morris, a PhD student and 2024 MAD Fellow affiliated with the MIT Media Lab, designs digital learning platforms that make room for the ‚Äúsocial magic‚Äù that influences curiosity and motivation.",
    "pubDate": "Tue, 17 Jun 2025 16:25:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/caitlin-morris-combines-tech-education-human-connection-improve-online-learning-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-Caitlin-Morris.jpg"
  },
  {
    "title": "Beyond Code: The Multidimensional Impacts of Large Language Models in Software Development",
    "description": "arXiv:2506.22704v1 Announce Type: cross Abstract: Large language models (LLMs) are poised to significantly impact software development, especially in the Open-Source Software (OSS) sector. To understand this impact, we first outline the mechanisms through which LLMs may influence OSS through code development, collaborative knowledge transfer, and skill development. We then empirically examine how LLMs affect OSS developers' work in these three key areas. Leveraging a natural experiment from a temporary ChatGPT ban in Italy, we employ a Difference-in-Differences framework with two-way fixed effects to analyze data from all OSS developers on GitHub in three similar countries, Italy, France, and Portugal, totaling 88,022 users. We find that access to ChatGPT increases developer productivity by 6.4%, knowledge sharing by 9.6%, and skill acquisition by 8.4%. These benefits vary significantly by user experience level: novice developers primarily experience productivity gains, whereas more experienced developers benefit more from improved knowledge sharing and accelerated skill acquisition. In addition, we find that LLM-assisted learning is highly context-dependent, with the greatest benefits observed in technically complex, fragmented, or rapidly evolving contexts. We show that the productivity effects of LLMs extend beyond direct code generation to include enhanced collaborative learning and knowledge exchange among developers; dynamics that are essential for gaining a holistic understanding of LLMs' impact in OSS. Our findings offer critical managerial implications: strategically deploying LLMs can accelerate novice developers' onboarding and productivity, empower intermediate developers to foster knowledge sharing and collaboration, and support rapid skill acquisition, together enhancing long-term organizational productivity and agility.",
    "summary": "arXiv:2506.22704v1 Announce Type: cross Abstract: Large language models (LLMs) are poised to significantly impact software development, especially in the Open-Source Software (OSS) sector. To understand this impact, we first outline the mechanisms through which LLMs may influence OSS through code development, collaborative knowledge transfer, and skill development. We then empirically examine how LLMs affect OSS developers' work in these three key areas. Leveraging a natural experiment from a temporary ChatGPT ban in Italy, we employ a Difference-in-Differences framework with two-way fixed effects to analyze data from all OSS developers on GitHub in three similar countries, Italy, France, and Portugal, totaling 88,022 users. We find that access to ChatGPT increases developer productivity by 6.4%, knowledge sharing by 9.6%, and skill acquisition by 8.4%. These benefits vary significantly by user experience level: novice developers primarily experience productivity gains, whereas more experienced developers benefit more from improved knowledge sharing and accelerated skill acquisition. In addition, we find that LLM-assisted learning is highly context-dependent, with the greatest benefits observed in technically complex, fragmented, or rapidly evolving contexts. We show that the productivity effects of LLMs extend beyond direct code generation to include enhanced collaborative learning and knowledge exchange among developers; dynamics that are essential for gaining a holistic understanding of LLMs' impact in OSS. Our findings offer critical managerial implications: strategically deploying LLMs can accelerate novice developers' onboarding and productivity, empower intermediate developers to foster knowledge sharing and collaboration, and support rapid skill acquisition, together enhancing long-term organizational productivity and agility.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22704",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Training a language model with ü§ó Transformers using TensorFlow and TPUs",
    "description": "",
    "summary": "Training a language model with ü§ó Transformers using TensorFlow and TPUs Introduction TPU training is...",
    "pubDate": "Thu, 27 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf_tpu",
    "thumbnail": "https://huggingface.co/blog/assets/tf_tpu_training/thumbnail.png"
  },
  {
    "title": "Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models",
    "description": "arXiv:2501.14406v3 Announce Type: replace-cross Abstract: Pre-trained Language Models (PLMs) have demonstrated their superiority and versatility in modern Natural Language Processing (NLP), effectively adapting to various downstream tasks through further fine-tuning. Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution to address privacy and efficiency challenges in distributed training for PLMs on resource-constrained local devices. However, our measurements reveal two key limitations of FedPEFT: heterogeneous data across devices exacerbates performance degradation of low-rank adaptation, and a fixed parameter configuration results in communication inefficiency. To overcome these limitations, we propose FedARA, a novel Adaptive Rank Allocation framework for federated parameter-efficient fine-tuning of language models. Specifically, FedARA employs truncated Singular Value Decomposition (SVD) adaptation to enhance similar feature representation across clients, significantly mitigating the adverse effects of data heterogeneity. Subsequently, it utilizes dynamic rank allocation to progressively identify critical ranks, effectively improving communication efficiency. Lastly, it leverages rank-based module pruning to automatically remove inactive modules, steadily reducing local computational cost and memory usage in each federated learning round. Extensive experiments show that FedARA consistently outperforms baselines by an average of 6.95% to 8.49% across various datasets and models under heterogeneous data while significantly improving communication efficiency by 2.40$ times$. Moreover, experiments on various edge devices demonstrate substantial decreases in total training time and energy consumption by up to 48.90% and 46.95%, respectively.",
    "summary": "arXiv:2501.14406v3 Announce Type: replace-cross Abstract: Pre-trained Language Models (PLMs) have demonstrated their superiority and versatility in modern Natural Language Processing (NLP), effectively adapting to various downstream tasks through further fine-tuning. Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as a promising solution to address privacy and efficiency challenges in distributed training for PLMs on resource-constrained local devices. However, our measurements reveal two key limitations of FedPEFT: heterogeneous data across devices exacerbates performance degradation of low-rank adaptation, and a fixed parameter configuration results in communication inefficiency. To overcome these limitations, we propose FedARA, a novel Adaptive Rank Allocation framework for federated parameter-efficient fine-tuning of language models. Specifically, FedARA employs truncated Singular Value Decomposition (SVD) adaptation to enhance similar feature representation across clients, significantly mitigating the adverse effects of data heterogeneity. Subsequently, it utilizes dynamic rank allocation to progressively identify critical ranks, effectively improving communication efficiency. Lastly, it leverages rank-based module pruning to automatically remove inactive modules, steadily reducing local computational cost and memory usage in each federated learning round. Extensive experiments show that FedARA consistently outperforms baselines by an average of 6.95% to 8.49% across various datasets and models under heterogeneous data while significantly improving communication efficiency by 2.40$ times$. Moreover, experiments on various edge devices demonstrate substantial decreases in total training time and energy consumption by up to 48.90% and 46.95%, respectively.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.14406",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ÂåóÊúùÈÆÆIT„ÉØ„Éº„Ç´„Éº„ÅÆ‰∏çÊ≠£ÂèéÁõä„ÄÅAI„ÅßÂ∑ßÂ¶ôÂåñ„ÄÄÁ±≥Âè∏Ê≥ïÁúÅ„ÅåÂ§ßË¶èÊ®°ÊëòÁô∫",
    "description": "Á±≥Âè∏Ê≥ïÁúÅ„ÅØ„ÄÅÂåóÊúùÈÆÆIT„ÉØ„Éº„Ç´„Éº„Å´„Çà„Çã‰∏çÊ≠£ÂèéÁõä„Çπ„Ç≠„Éº„É†„ÅÆÂ§ßË¶èÊ®°„Å™ÊëòÁô∫„ÇíÁô∫Ë°®„Åó„Åü„ÄÇMicrosoft„Å´„Çà„Çã„Å®„ÄÅ„ÉØ„Éº„Ç´„Éº„ÅØAI„ÇíÊÇ™Áî®„Åó„Å¶Ë∫´ÂÖÉ„ÇíÂÅΩË£Ö„Åó„ÄÅÊ¥ªÂãï„ÇíÂ∑ßÂ¶ôÂåñ„Åï„Åõ„Å¶„ÅÑ„Çã„Å®„ÅÑ„ÅÜ„ÄÇÂè∏Ê≥ïÁúÅ„ÅØ„É©„ÉÉ„Éó„Éà„ÉÉ„Éó„Éï„Ç°„Éº„É†„ÅÆÊçúÁ¥¢„ÇÑÂè£Â∫ßÊäºÂèé„Å™„Å©„ÅÆÂØæÁ≠ñ„ÇíË¨õ„Åò„Åü„ÄÇ",
    "summary": "Á±≥Âè∏Ê≥ïÁúÅ„ÅØ„ÄÅÂåóÊúùÈÆÆIT„ÉØ„Éº„Ç´„Éº„Å´„Çà„Çã‰∏çÊ≠£ÂèéÁõä„Çπ„Ç≠„Éº„É†„ÅÆÂ§ßË¶èÊ®°„Å™ÊëòÁô∫„ÇíÁô∫Ë°®„Åó„Åü„ÄÇMicrosoft„Å´„Çà„Çã„Å®„ÄÅ„ÉØ„Éº„Ç´„Éº„ÅØAI„ÇíÊÇ™Áî®„Åó„Å¶Ë∫´ÂÖÉ„ÇíÂÅΩË£Ö„Åó„ÄÅÊ¥ªÂãï„ÇíÂ∑ßÂ¶ôÂåñ„Åï„Åõ„Å¶„ÅÑ„Çã„Å®„ÅÑ„ÅÜ„ÄÇÂè∏Ê≥ïÁúÅ„ÅØ„É©„ÉÉ„Éó„Éà„ÉÉ„Éó„Éï„Ç°„Éº„É†„ÅÆÊçúÁ¥¢„ÇÑÂè£Â∫ßÊäºÂèé„Å™„Å©„ÅÆÂØæÁ≠ñ„ÇíË¨õ„Åò„Åü„ÄÇ",
    "pubDate": "Tue, 01 Jul 2025 10:15:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2507/01/news062.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2507/01/cover_news062.jpg"
  },
  {
    "title": "Our approach to data and AI",
    "description": "Just over a year after launching ChatGPT, AI is changing how we live, work and learn. It‚Äôs also raised important conversations about data in the age of AI. More on our approach, a new Media Manager for creators and content owners, and where we‚Äôre headed.",
    "summary": "Just over a year after launching ChatGPT, AI is changing how we live, work and learn. It‚Äôs also raised important conversations about data in the age of AI. More on our approach, a new Media Manager for creators and content owners, and where we‚Äôre headed.",
    "pubDate": "Tue, 07 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/approach-to-data-and-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sycophancy in GPT-4o: what happened and what we‚Äôre doing about it",
    "description": "We have rolled back last week‚Äôs GPT‚Äë4o update in ChatGPT so people are now using an earlier version with more balanced behavior. The update we removed was overly flattering or agreeable‚Äîoften described as sycophantic.",
    "summary": "We have rolled back last week‚Äôs GPT‚Äë4o update in ChatGPT so people are now using an earlier version with more balanced behavior. The update we removed was overly flattering or agreeable‚Äîoften described as sycophantic.",
    "pubDate": "Tue, 29 Apr 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sycophancy-in-gpt-4o",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Image Classification with AutoTrain",
    "description": "",
    "summary": "Image Classification with AutoTrain So you‚Äôve heard all about the cool things that are happening in ...",
    "pubDate": "Wed, 28 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autotrain-image-classification",
    "thumbnail": "https://huggingface.co/blog/assets/105_autotrain-image-classification/thumbnail.png"
  },
  {
    "title": "OpenAI and Hearst Content Partnership",
    "description": "Hearst‚Äôs iconic brands bring curated lifestyle and local news content to OpenAI‚Äôs products.",
    "summary": "Hearst‚Äôs iconic brands bring curated lifestyle and local news content to OpenAI‚Äôs products.",
    "pubDate": "Tue, 08 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hearst",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Tool Use, Unified",
    "description": "",
    "summary": "Tool Use, Unified There is now a unified tool use API across several popular families of models. Thi...",
    "pubDate": "Mon, 12 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unified-tool-use",
    "thumbnail": "https://huggingface.co/blog/assets/unified-tool-use/thumbnail.png"
  },
  {
    "title": "ResQuNNs:Towards Enabling Deep Learning in Quantum Convolution Neural Networks",
    "description": "arXiv:2402.09146v5 Announce Type: cross Abstract: In this paper, we present a novel framework for enhancing the performance of Quanvolutional Neural Networks (QuNNs) by introducing trainable quanvolutional layers and addressing the critical challenges associated with them. Traditional quanvolutional layers, although beneficial for feature extraction, have largely been static, offering limited adaptability. Unlike state-of-the-art, our research overcomes this limitation by enabling training within these layers, significantly increasing the flexibility and potential of QuNNs. However, the introduction of multiple trainable quanvolutional layers induces complexities in gradient-based optimization, primarily due to the difficulty in accessing gradients across these layers. To resolve this, we propose a novel architecture, Residual Quanvolutional Neural Networks (ResQuNNs), leveraging the concept of residual learning, which facilitates the flow of gradients by adding skip connections between layers. By inserting residual blocks between quanvolutional layers, we ensure enhanced gradient access throughout the network, leading to improved training performance. Moreover, we provide empirical evidence on the strategic placement of these residual blocks within QuNNs. Through extensive experimentation, we identify an efficient configuration of residual blocks, which enables gradients across all the layers in the network that eventually results in efficient training. Our findings suggest that the precise location of residual blocks plays a crucial role in maximizing the performance gains in QuNNs. Our results mark a substantial step forward in the evolution of quantum deep learning, offering new avenues for both theoretical development and practical quantum computing applications.",
    "summary": "arXiv:2402.09146v5 Announce Type: cross Abstract: In this paper, we present a novel framework for enhancing the performance of Quanvolutional Neural Networks (QuNNs) by introducing trainable quanvolutional layers and addressing the critical challenges associated with them. Traditional quanvolutional layers, although beneficial for feature extraction, have largely been static, offering limited adaptability. Unlike state-of-the-art, our research overcomes this limitation by enabling training within these layers, significantly increasing the flexibility and potential of QuNNs. However, the introduction of multiple trainable quanvolutional layers induces complexities in gradient-based optimization, primarily due to the difficulty in accessing gradients across these layers. To resolve this, we propose a novel architecture, Residual Quanvolutional Neural Networks (ResQuNNs), leveraging the concept of residual learning, which facilitates the flow of gradients by adding skip connections between layers. By inserting residual blocks between quanvolutional layers, we ensure enhanced gradient access throughout the network, leading to improved training performance. Moreover, we provide empirical evidence on the strategic placement of these residual blocks within QuNNs. Through extensive experimentation, we identify an efficient configuration of residual blocks, which enables gradients across all the layers in the network that eventually results in efficient training. Our findings suggest that the precise location of residual blocks plays a crucial role in maximizing the performance gains in QuNNs. Our results mark a substantial step forward in the evolution of quantum deep learning, offering new avenues for both theoretical development and practical quantum computing applications.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2402.09146",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Benchmarking safe exploration in deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 21 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/benchmarking-safe-exploration-in-deep-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI partners with Cond√© Nast",
    "description": "Cond√© Nast",
    "summary": "Cond√© Nast",
    "pubDate": "Tue, 20 Aug 2024 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/conde-nast",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing OpenAI‚Äôs Bug Bounty Program",
    "description": "This initiative is essential to our commitment to develop safe and advanced AI. As we create technology and services that are secure, reliable, and trustworthy, we need your help.",
    "summary": "This initiative is essential to our commitment to develop safe and advanced AI. As we create technology and services that are secure, reliable, and trustworthy, we need your help.",
    "pubDate": "Tue, 11 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bug-bounty-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Distill",
    "description": "We‚Äôre excited to support today‚Äôs launch of Distill, a new kind of journal aimed at excellent communication of machine learning results (novel or existing).",
    "summary": "We‚Äôre excited to support today‚Äôs launch of Distill, a new kind of journal aimed at excellent communication of machine learning results (novel or existing).",
    "pubDate": "Mon, 20 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/distill",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "HalluSegBench: Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation",
    "description": "arXiv:2506.21546v2 Announce Type: replace-cross Abstract: Recent progress in vision-language segmentation has significantly advanced grounded visual understanding. However, these models often exhibit hallucinations by producing segmentation masks for objects not grounded in the image content or by incorrectly labeling irrelevant regions. Existing evaluation protocols for segmentation hallucination primarily focus on label or textual hallucinations without manipulating the visual context, limiting their capacity to diagnose critical failures. In response, we introduce HalluSegBench, the first benchmark specifically designed to evaluate hallucinations in visual grounding through the lens of counterfactual visual reasoning. Our benchmark consists of a novel dataset of 1340 counterfactual instance pairs spanning 281 unique object classes, and a set of newly introduced metrics that quantify hallucination sensitivity under visually coherent scene edits. Experiments on HalluSegBench with state-of-the-art vision-language segmentation models reveal that vision-driven hallucinations are significantly more prevalent than label-driven ones, with models often persisting in false segmentation, highlighting the need for counterfactual reasoning to diagnose grounding fidelity.",
    "summary": "arXiv:2506.21546v2 Announce Type: replace-cross Abstract: Recent progress in vision-language segmentation has significantly advanced grounded visual understanding. However, these models often exhibit hallucinations by producing segmentation masks for objects not grounded in the image content or by incorrectly labeling irrelevant regions. Existing evaluation protocols for segmentation hallucination primarily focus on label or textual hallucinations without manipulating the visual context, limiting their capacity to diagnose critical failures. In response, we introduce HalluSegBench, the first benchmark specifically designed to evaluate hallucinations in visual grounding through the lens of counterfactual visual reasoning. Our benchmark consists of a novel dataset of 1340 counterfactual instance pairs spanning 281 unique object classes, and a set of newly introduced metrics that quantify hallucination sensitivity under visually coherent scene edits. Experiments on HalluSegBench with state-of-the-art vision-language segmentation models reveal that vision-driven hallucinations are significantly more prevalent than label-driven ones, with models often persisting in false segmentation, highlighting the need for counterfactual reasoning to diagnose grounding fidelity.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21546",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hosting your Models and Datasets on Hugging Face Spaces using Streamlit",
    "description": "",
    "summary": "Hosting your Models and Datasets on Hugging Face Spaces using Streamlit Showcase your Datasets and M...",
    "pubDate": "Tue, 05 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/streamlit-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/29_streamlit-spaces/thumbnail.png"
  },
  {
    "title": "OpenAI safety practices",
    "description": "Artificial general intelligence has the potential to benefit nearly every aspect of our lives‚Äîso it must be developed and deployed responsibly.",
    "summary": "Artificial general intelligence has the potential to benefit nearly every aspect of our lives‚Äîso it must be developed and deployed responsibly.",
    "pubDate": "Tue, 21 May 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-safety-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Flow-Modulated Scoring for Semantic-Aware Knowledge Graph Completion",
    "description": "arXiv:2506.23137v1 Announce Type: cross Abstract: Effective modeling of multifaceted relations is pivotal for Knowledge Graph Completion (KGC). However, a majority of existing approaches are predicated on static, embedding-based scoring, exhibiting inherent limitations in capturing contextual dependencies and relational dynamics. Addressing this gap, we propose the Flow-Modulated Scoring (FMS) framework. FMS comprises two principal components: (1) a semantic context learning module that encodes context-sensitive entity representations, and (2) a conditional flow-matching module designed to learn the dynamic transformation from a head to a tail embedding, governed by the aforementioned context. The resultant predictive vector field, representing the context-informed relational path, serves to dynamically refine the initial static score of an entity pair. Through this synergy of context-aware static representations and conditioned dynamic information, FMS facilitates a more profound modeling of relational semantics. Comprehensive evaluations on several standard benchmarks demonstrate that our proposed method surpasses prior state-of-the-art results.",
    "summary": "arXiv:2506.23137v1 Announce Type: cross Abstract: Effective modeling of multifaceted relations is pivotal for Knowledge Graph Completion (KGC). However, a majority of existing approaches are predicated on static, embedding-based scoring, exhibiting inherent limitations in capturing contextual dependencies and relational dynamics. Addressing this gap, we propose the Flow-Modulated Scoring (FMS) framework. FMS comprises two principal components: (1) a semantic context learning module that encodes context-sensitive entity representations, and (2) a conditional flow-matching module designed to learn the dynamic transformation from a head to a tail embedding, governed by the aforementioned context. The resultant predictive vector field, representing the context-informed relational path, serves to dynamically refine the initial static score of an entity pair. Through this synergy of context-aware static representations and conditioned dynamic information, FMS facilitates a more profound modeling of relational semantics. Comprehensive evaluations on several standard benchmarks demonstrate that our proposed method surpasses prior state-of-the-art results.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23137",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Strategic Content Partnership with TIME",
    "description": "We‚Äôre partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories on Time.com",
    "summary": "We‚Äôre partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories on Time.com",
    "pubDate": "Thu, 27 Jun 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/strategic-content-partnership-with-time",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Positioning AI Tools to Support Online Harm Reduction Practice: Applications and Design Directions",
    "description": "arXiv:2506.22941v1 Announce Type: cross Abstract: Access to accurate and actionable harm reduction information can directly impact the health outcomes of People Who Use Drugs (PWUD), yet existing online channels often fail to meet their diverse and dynamic needs due to limitations in adaptability, accessibility, and the pervasive impact of stigma. Large Language Models (LLMs) present a novel opportunity to enhance information provision, but their application in such a high-stakes domain is under-explored and presents socio-technical challenges. This paper investigates how LLMs can be responsibly designed to support the information needs of PWUD. Through a qualitative workshop involving diverse stakeholder groups (academics, harm reduction practitioners, and an online community moderator), we explored LLM capabilities, identified potential use cases, and delineated core design considerations. Our findings reveal that while LLMs can address some existing information barriers (e.g., by offering responsive, multilingual, and potentially less stigmatising interactions), their effectiveness is contingent upon overcoming challenges related to ethical alignment with harm reduction principles, nuanced contextual understanding, effective communication, and clearly defined operational boundaries. We articulate design pathways emphasising collaborative co-design with experts and PWUD to develop LLM systems that are helpful, safe, and responsibly governed. This work contributes empirically grounded insights and actionable design considerations for the responsible development of LLMs as supportive tools within the harm reduction ecosystem.",
    "summary": "arXiv:2506.22941v1 Announce Type: cross Abstract: Access to accurate and actionable harm reduction information can directly impact the health outcomes of People Who Use Drugs (PWUD), yet existing online channels often fail to meet their diverse and dynamic needs due to limitations in adaptability, accessibility, and the pervasive impact of stigma. Large Language Models (LLMs) present a novel opportunity to enhance information provision, but their application in such a high-stakes domain is under-explored and presents socio-technical challenges. This paper investigates how LLMs can be responsibly designed to support the information needs of PWUD. Through a qualitative workshop involving diverse stakeholder groups (academics, harm reduction practitioners, and an online community moderator), we explored LLM capabilities, identified potential use cases, and delineated core design considerations. Our findings reveal that while LLMs can address some existing information barriers (e.g., by offering responsive, multilingual, and potentially less stigmatising interactions), their effectiveness is contingent upon overcoming challenges related to ethical alignment with harm reduction principles, nuanced contextual understanding, effective communication, and clearly defined operational boundaries. We articulate design pathways emphasising collaborative co-design with experts and PWUD to develop LLM systems that are helpful, safe, and responsibly governed. This work contributes empirically grounded insights and actionable design considerations for the responsible development of LLMs as supportive tools within the harm reduction ecosystem.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22941",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Frontier Model Forum updates",
    "description": "Together with Anthropic, Google, and Microsoft, we‚Äôre announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",
    "summary": "Together with Anthropic, Google, and Microsoft, we‚Äôre announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",
    "pubDate": "Wed, 25 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-model-forum-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deep Q-Learning with Atari",
    "description": "",
    "summary": "Deep Q-Learning with Space Invaders Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 3, of...",
    "pubDate": "Tue, 07 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-dqn",
    "thumbnail": "https://huggingface.co/blog/assets/78_deep_rl_dqn/thumbnail.gif"
  },
  {
    "title": "From Diffusion to Transformers: A Unified Framework for Neural Message Passing",
    "description": "arXiv:2409.09111v3 Announce Type: replace-cross Abstract: Learning representations for structured data with certain geometries (e.g., observed or unobserved) is a fundamental challenge, wherein message passing neural networks (MPNNs) have become a de facto class of model solutions. In this paper, inspired by physical systems, we propose an energy-constrained diffusion model, which combines the inductive bias of diffusion on manifolds with layer-wise constraints of energy minimization. We identify that the diffusion operators have a one-to-one correspondence with the energy functions implicitly descended by the diffusion process, and the finite-difference iteration for solving the energy-constrained diffusion system induces the propagation layers of various types of MPNNs operating on observed or latent structures. This leads to a unified mathematical framework for common neural architectures whose computational flows can be cast as message passing (or its special case), including MLPs, GNNs, and Transformers. Building on these insights, we devise a new class of neural message passing models, dubbed diffusion-inspired Transformers, whose global attention layers are derived from the principled energy-constrained diffusion framework. Across diverse datasets ranging from real-world networks to images, texts, and physical particles, we demonstrate that the new model achieves promising performance in scenarios where the data structures are observed (as a graph), partially observed, or entirely unobserved.",
    "summary": "arXiv:2409.09111v3 Announce Type: replace-cross Abstract: Learning representations for structured data with certain geometries (e.g., observed or unobserved) is a fundamental challenge, wherein message passing neural networks (MPNNs) have become a de facto class of model solutions. In this paper, inspired by physical systems, we propose an energy-constrained diffusion model, which combines the inductive bias of diffusion on manifolds with layer-wise constraints of energy minimization. We identify that the diffusion operators have a one-to-one correspondence with the energy functions implicitly descended by the diffusion process, and the finite-difference iteration for solving the energy-constrained diffusion system induces the propagation layers of various types of MPNNs operating on observed or latent structures. This leads to a unified mathematical framework for common neural architectures whose computational flows can be cast as message passing (or its special case), including MLPs, GNNs, and Transformers. Building on these insights, we devise a new class of neural message passing models, dubbed diffusion-inspired Transformers, whose global attention layers are derived from the principled energy-constrained diffusion framework. Across diverse datasets ranging from real-world networks to images, texts, and physical particles, we demonstrate that the new model achieves promising performance in scenarios where the data structures are observed (as a graph), partially observed, or entirely unobserved.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.09111",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Foundation Models for Wearable Movement Data in Mental Health Research",
    "description": "arXiv:2411.15240v4 Announce Type: replace-cross Abstract: Pretrained foundation models and transformer architectures have driven the success of large language models (LLMs) and other modern AI breakthroughs. However, similar advancements in health data modeling remain limited due to the need for innovative adaptations. Wearable movement data offers a valuable avenue for exploration, as it's a core feature in nearly all commercial smartwatches, well established in clinical and mental health research, and the sequential nature of the data shares similarities to language. We introduce the Pretrained Actigraphy Transformer (PAT), the first open source foundation model designed for time-series wearable movement data. Leveraging transformer-based architectures and novel techniques, such as patch embeddings, and pretraining on data from 29,307 participants in a national U.S. sample, PAT achieves state-of-the-art performance in several mental health prediction tasks. PAT is also lightweight and easily interpretable, making it a robust tool for mental health research. GitHub: https://github.com/njacobsonlab/Pretrained-Actigraphy-Transformer/",
    "summary": "arXiv:2411.15240v4 Announce Type: replace-cross Abstract: Pretrained foundation models and transformer architectures have driven the success of large language models (LLMs) and other modern AI breakthroughs. However, similar advancements in health data modeling remain limited due to the need for innovative adaptations. Wearable movement data offers a valuable avenue for exploration, as it's a core feature in nearly all commercial smartwatches, well established in clinical and mental health research, and the sequential nature of the data shares similarities to language. We introduce the Pretrained Actigraphy Transformer (PAT), the first open source foundation model designed for time-series wearable movement data. Leveraging transformer-based architectures and novel techniques, such as patch embeddings, and pretraining on data from 29,307 participants in a national U.S. sample, PAT achieves state-of-the-art performance in several mental health prediction tasks. PAT is also lightweight and easily interpretable, making it a robust tool for mental health research. GitHub: https://github.com/njacobsonlab/Pretrained-Actigraphy-Transformer/",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.15240",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Faster physics in Python",
    "description": "We‚Äôre open-sourcing a high-performance Python library for robotic simulation using the MuJoCo engine, developed over our past year of robotics research.",
    "summary": "We‚Äôre open-sourcing a high-performance Python library for robotic simulation using the MuJoCo engine, developed over our past year of robotics research.",
    "pubDate": "Wed, 28 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/faster-physics-in-python",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sanitizing Manufacturing Dataset Labels Using Vision-Language Models",
    "description": "arXiv:2506.23465v1 Announce Type: cross Abstract: The success of machine learning models in industrial applications is heavily dependent on the quality of the datasets used to train the models. However, large-scale datasets, specially those constructed from crowd-sourcing and web-scraping, often suffer from label noise, inconsistencies, and errors. This problem is particularly pronounced in manufacturing domains, where obtaining high-quality labels is costly and time-consuming. This paper introduces Vision-Language Sanitization and Refinement (VLSR), which is a vision-language-based framework for label sanitization and refinement in multi-label manufacturing image datasets. This method embeds both images and their associated textual labels into a shared semantic space leveraging the CLIP vision-language model. Then two key tasks are addressed in this process by computing the cosine similarity between embeddings. First, label sanitization is performed to identify irrelevant, misspelled, or semantically weak labels, and surface the most semantically aligned label for each image by comparing image-label pairs using cosine similarity between image and label embeddings. Second, the method applies density-based clustering on text embeddings, followed by iterative cluster merging, to group semantically similar labels into unified label groups. The Factorynet dataset, which includes noisy labels from both human annotations and web-scraped sources, is employed to evaluate the effectiveness of the proposed framework. Experimental results demonstrate that the VLSR framework successfully identifies problematic labels and improves label consistency. This method enables a significant reduction in label vocabulary through clustering, which ultimately enhances the dataset's quality for training robust machine learning models in industrial applications with minimal human intervention.",
    "summary": "arXiv:2506.23465v1 Announce Type: cross Abstract: The success of machine learning models in industrial applications is heavily dependent on the quality of the datasets used to train the models. However, large-scale datasets, specially those constructed from crowd-sourcing and web-scraping, often suffer from label noise, inconsistencies, and errors. This problem is particularly pronounced in manufacturing domains, where obtaining high-quality labels is costly and time-consuming. This paper introduces Vision-Language Sanitization and Refinement (VLSR), which is a vision-language-based framework for label sanitization and refinement in multi-label manufacturing image datasets. This method embeds both images and their associated textual labels into a shared semantic space leveraging the CLIP vision-language model. Then two key tasks are addressed in this process by computing the cosine similarity between embeddings. First, label sanitization is performed to identify irrelevant, misspelled, or semantically weak labels, and surface the most semantically aligned label for each image by comparing image-label pairs using cosine similarity between image and label embeddings. Second, the method applies density-based clustering on text embeddings, followed by iterative cluster merging, to group semantically similar labels into unified label groups. The Factorynet dataset, which includes noisy labels from both human annotations and web-scraped sources, is employed to evaluate the effectiveness of the proposed framework. Experimental results demonstrate that the VLSR framework successfully identifies problematic labels and improves label consistency. This method enables a significant reduction in label vocabulary through clustering, which ultimately enhances the dataset's quality for training robust machine learning models in industrial applications with minimal human intervention.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23465",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The State of Computer Vision at Hugging Face ü§ó",
    "description": "",
    "summary": "The State of Computer Vision at Hugging Face ü§ó At Hugging Face, we pride ourselves on democratizing ...",
    "pubDate": "Mon, 30 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cv_state",
    "thumbnail": "https://huggingface.co/blog/assets/cv_state/thumbnail.png"
  },
  {
    "title": "Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning",
    "description": "arXiv:2506.23127v1 Announce Type: cross Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, yet they face significant challenges in embodied task planning scenarios that require continuous environmental understanding and action generation. Existing approaches generate open-loop action scripts based on static knowledge, making it difficult to learn causal relationships between actions and environmental feedback, particularly in partially observable environments. We introduce Embodied Planner-R1, a novel outcome-driven reinforcement learning framework that enables LLMs to develop interactive capabilities through autonomous exploration with minimal supervision. Our framework incorporates three key innovations: (1) Without human annotations, we employ pure reinforcement learning with group rollout, incorporating in-environment interaction through parallel exploration; (2) completion-driven sparse reward; and (3) Interactive Policy Optimization (IPO) for efficient learning from grouped trajectories. Across two challenging text-based Embodied planning benchmarks, Embodied Planner-R1 achieves impressive completion rates of 97.78% on ALFWorld and 79.92% on ScienceWorld, surpassing prior methods by a large margin, and suffers only a -3.66% drop in previously unseen environments, evidencing strong generalization.",
    "summary": "arXiv:2506.23127v1 Announce Type: cross Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, yet they face significant challenges in embodied task planning scenarios that require continuous environmental understanding and action generation. Existing approaches generate open-loop action scripts based on static knowledge, making it difficult to learn causal relationships between actions and environmental feedback, particularly in partially observable environments. We introduce Embodied Planner-R1, a novel outcome-driven reinforcement learning framework that enables LLMs to develop interactive capabilities through autonomous exploration with minimal supervision. Our framework incorporates three key innovations: (1) Without human annotations, we employ pure reinforcement learning with group rollout, incorporating in-environment interaction through parallel exploration; (2) completion-driven sparse reward; and (3) Interactive Policy Optimization (IPO) for efficient learning from grouped trajectories. Across two challenging text-based Embodied planning benchmarks, Embodied Planner-R1 achieves impressive completion rates of 97.78% on ALFWorld and 79.92% on ScienceWorld, surpassing prior methods by a large margin, and suffers only a -3.66% drop in previously unseen environments, evidencing strong generalization.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23127",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A sounding board for strengthening the student experience",
    "description": "Composed of ‚Äúcomputing bilinguals,‚Äù the Undergraduate Advisory Group provides vital input to help advance the mission of the MIT Schwarzman College of Computing.",
    "summary": "Composed of ‚Äúcomputing bilinguals,‚Äù the Undergraduate Advisory Group provides vital input to help advance the mission of the MIT Schwarzman College of Computing.",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/sounding-board-for-strengthening-student-experience-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-SCC-UAG.jpg"
  },
  {
    "title": "Towards Encrypted Large Language Models with FHE",
    "description": "",
    "summary": "Towards Encrypted Large Language Models with FHE Large Language Models (LLM) have recently been prov...",
    "pubDate": "Wed, 02 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/encrypted-llm",
    "thumbnail": "https://huggingface.co/blog/assets/encrypted-llm/thumbnail.png"
  },
  {
    "title": "An update on our safety & security practices",
    "description": "An update on our safety & security practices",
    "summary": "An update on our safety & security practices",
    "pubDate": "Mon, 16 Sep 2024 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/update-on-safety-and-security-practices",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Transformers.js v3: WebGPU support, new models & tasks, and more‚Ä¶",
    "description": "",
    "summary": "Transformers.js v3: WebGPU Support, New Models & Tasks, and More‚Ä¶ After more than a year of developm...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformersjs-v3",
    "thumbnail": "https://huggingface.co/blog/assets/transformersjs-v3/thumbnail.png"
  },
  {
    "title": "Recommender Systems for Good (RS4Good): Survey of Use Cases and a Call to Action for Research that Matters",
    "description": "arXiv:2411.16645v2 Announce Type: replace-cross Abstract: In the area of recommender systems, the vast majority of research efforts is spent on developing increasingly sophisticated recommendation models, also using increasingly more computational resources. Unfortunately, most of these research efforts target a very small set of application domains, mostly e-commerce and media recommendation. Furthermore, many of these models are never evaluated with users, let alone put into practice. The scientific, economic and societal value of much of these efforts by scholars therefore remains largely unclear. To achieve a stronger positive impact resulting from these efforts, we posit that we as a research community should more often address use cases where recommender systems contribute to societal good (RS4Good). In this opinion piece, we first discuss a number of examples where the use of recommender systems for problems of societal concern has been successfully explored in the literature. We then proceed by outlining a paradigmatic shift that is needed to conduct successful RS4Good research, where the key ingredients are interdisciplinary collaborations and longitudinal evaluation approaches with humans in the loop.",
    "summary": "arXiv:2411.16645v2 Announce Type: replace-cross Abstract: In the area of recommender systems, the vast majority of research efforts is spent on developing increasingly sophisticated recommendation models, also using increasingly more computational resources. Unfortunately, most of these research efforts target a very small set of application domains, mostly e-commerce and media recommendation. Furthermore, many of these models are never evaluated with users, let alone put into practice. The scientific, economic and societal value of much of these efforts by scholars therefore remains largely unclear. To achieve a stronger positive impact resulting from these efforts, we posit that we as a research community should more often address use cases where recommender systems contribute to societal good (RS4Good). In this opinion piece, we first discuss a number of examples where the use of recommender systems for problems of societal concern has been successfully explored in the literature. We then proceed by outlining a paradigmatic shift that is needed to conduct successful RS4Good research, where the key ingredients are interdisciplinary collaborations and longitudinal evaluation approaches with humans in the loop.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.16645",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing text and code embeddings",
    "description": "We are introducing embeddings, a new endpoint in the OpenAI API that makes it easy to perform natural language and code tasks like semantic search, clustering, topic modeling, and classification.",
    "summary": "We are introducing embeddings, a new endpoint in the OpenAI API that makes it easy to perform natural language and code tasks like semantic search, clustering, topic modeling, and classification.",
    "pubDate": "Tue, 25 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-text-and-code-embeddings",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models",
    "description": "",
    "summary": "Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models Transformer-based encod...",
    "pubDate": "Mon, 09 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/warm-starting-encoder-decoder",
    "thumbnail": "https://huggingface.co/blog/assets/08_warm_starting_encoder_decoder/thumbnail.png"
  },
  {
    "title": "Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer)",
    "description": "",
    "summary": "Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer) Introduction A few months...",
    "pubDate": "Fri, 16 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autoformer",
    "thumbnail": "https://huggingface.co/blog/assets/150_autoformer/thumbnail.png"
  },
  {
    "title": "Spectra 1.1: Scaling Laws and Efficient Inference for Ternary Language Models",
    "description": "arXiv:2506.23025v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used across research and industry applications, yet their inference efficiency remains a significant challenge. As the computational power of modern GPU architectures continuously improves, their memory bandwidth and capacity have not scaled proportionally, creating a critical bottleneck during inference. To address this, we investigate ternary language models (TriLMs) that employ quantization-aware training to significantly reduce memory requirements. We first analyze the scalability of TriLMs by conducting a scaling law analysis, revealing that TriLMs benefit more from increasing training data than from scaling model parameters. Based on this observation, we introduce Spectra-1.1, an open suite of TriLMs trained on up to 1.2 trillion tokens, demonstrating sustained performance gains at scale. Furthermore, to improve inference efficiency, we propose novel 2-bit and 1.6-bit packing schemes for ternary weights, which demonstrate accelerated inference across various CPU architectures. Also, building on the 2-bit packing, we develop a GPU kernel called TriRun that accelerates end-to-end model inference by up to 5 times compared to floating-point baselines. To encourage further exploration and development of TriLMs, we will release the Spectra-1.1 suite and TriRun inference kernels. Overall, our work lays the foundation for building and deploying efficient LLMs, providing a valuable resource for the research community.",
    "summary": "arXiv:2506.23025v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used across research and industry applications, yet their inference efficiency remains a significant challenge. As the computational power of modern GPU architectures continuously improves, their memory bandwidth and capacity have not scaled proportionally, creating a critical bottleneck during inference. To address this, we investigate ternary language models (TriLMs) that employ quantization-aware training to significantly reduce memory requirements. We first analyze the scalability of TriLMs by conducting a scaling law analysis, revealing that TriLMs benefit more from increasing training data than from scaling model parameters. Based on this observation, we introduce Spectra-1.1, an open suite of TriLMs trained on up to 1.2 trillion tokens, demonstrating sustained performance gains at scale. Furthermore, to improve inference efficiency, we propose novel 2-bit and 1.6-bit packing schemes for ternary weights, which demonstrate accelerated inference across various CPU architectures. Also, building on the 2-bit packing, we develop a GPU kernel called TriRun that accelerates end-to-end model inference by up to 5 times compared to floating-point baselines. To encourage further exploration and development of TriLMs, we will release the Spectra-1.1 suite and TriRun inference kernels. Overall, our work lays the foundation for building and deploying efficient LLMs, providing a valuable resource for the research community.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Bridging Physical and Digital Worlds: Embodied Large AI for Future Wireless Systems",
    "description": "arXiv:2506.24009v1 Announce Type: cross Abstract: Large artificial intelligence (AI) models offer revolutionary potential for future wireless systems, promising unprecedented capabilities in network optimization and performance. However, current paradigms largely overlook crucial physical interactions. This oversight means they primarily rely on offline datasets, leading to difficulties in handling real-time wireless dynamics and non-stationary environments. Furthermore, these models often lack the capability for active environmental probing. This paper proposes a fundamental paradigm shift towards wireless embodied large AI (WELAI), moving from passive observation to active embodiment. We first identify key challenges faced by existing models, then we explore the design principles and system structure of WELAI. Besides, we outline prospective applications in next-generation wireless. Finally, through an illustrative case study, we demonstrate the effectiveness of WELAI and point out promising research directions for realizing adaptive, robust, and autonomous wireless systems.",
    "summary": "arXiv:2506.24009v1 Announce Type: cross Abstract: Large artificial intelligence (AI) models offer revolutionary potential for future wireless systems, promising unprecedented capabilities in network optimization and performance. However, current paradigms largely overlook crucial physical interactions. This oversight means they primarily rely on offline datasets, leading to difficulties in handling real-time wireless dynamics and non-stationary environments. Furthermore, these models often lack the capability for active environmental probing. This paper proposes a fundamental paradigm shift towards wireless embodied large AI (WELAI), moving from passive observation to active embodiment. We first identify key challenges faced by existing models, then we explore the design principles and system structure of WELAI. Besides, we outline prospective applications in next-generation wireless. Finally, through an illustrative case study, we demonstrate the effectiveness of WELAI and point out promising research directions for realizing adaptive, robust, and autonomous wireless systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.24009",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SetFitABSA: Few-Shot Aspect Based Sentiment Analysis using SetFit",
    "description": "",
    "summary": "SetFitABSA: Few-Shot Aspect Based Sentiment Analysis using SetFit SetFitABSA is an efficient techniq...",
    "pubDate": "Wed, 06 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit-absa",
    "thumbnail": "https://huggingface.co/blog/assets/setfit-absa/intel_hf_logo_2.png"
  },
  {
    "title": "3D Asset Generation: AI for Game Development #3",
    "description": "",
    "summary": "3D Asset Generation: AI for Game Development #3 Welcome to AI for Game Development! In this series, ...",
    "pubDate": "Fri, 20 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-3",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail3.png"
  },
  {
    "title": "CHARTOM: A Visual Theory-of-Mind Benchmark for LLMs on Misleading Charts",
    "description": "arXiv:2408.14419v3 Announce Type: replace Abstract: We introduce CHARTOM, a visual theory-of-mind benchmark designed to evaluate multimodal large language models' capability to understand and reason about misleading data visualizations though charts. CHARTOM consists of carefully designed charts and associated questions that require a language model to not only correctly comprehend the factual content in the chart (the FACT question) but also judge whether the chart will be misleading to a human readers (the MIND question), a dual capability with significant societal benefits. We detail the construction of our benchmark including its calibration on human performance and estimation of MIND ground truth called the Human Misleadingness Index. We evaluated several leading LLMs -- including GPT, Claude, Gemini, Qwen, Llama, and Llava series models -- on the CHARTOM dataset and found that it was challenging to all models both on FACT and MIND questions. This highlights the limitations of current LLMs and presents significant opportunity for future LLMs to improve on understanding misleading charts.",
    "summary": "arXiv:2408.14419v3 Announce Type: replace Abstract: We introduce CHARTOM, a visual theory-of-mind benchmark designed to evaluate multimodal large language models' capability to understand and reason about misleading data visualizations though charts. CHARTOM consists of carefully designed charts and associated questions that require a language model to not only correctly comprehend the factual content in the chart (the FACT question) but also judge whether the chart will be misleading to a human readers (the MIND question), a dual capability with significant societal benefits. We detail the construction of our benchmark including its calibration on human performance and estimation of MIND ground truth called the Human Misleadingness Index. We evaluated several leading LLMs -- including GPT, Claude, Gemini, Qwen, Llama, and Llava series models -- on the CHARTOM dataset and found that it was challenging to all models both on FACT and MIND questions. This highlights the limitations of current LLMs and presents significant opportunity for future LLMs to improve on understanding misleading charts.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.14419",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Chat Templates: An End to the Silent Performance Killer",
    "description": "",
    "summary": "Chat Templates A spectre is haunting chat models - the spectre of incorrect formatting! tl;dr Chat m...",
    "pubDate": "Tue, 03 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chat-templates",
    "thumbnail": "https://huggingface.co/blog/assets/chat-templates/thumbnail.png"
  },
  {
    "title": "Solving (some) formal math olympiad problems",
    "description": "We built a neural theorem prover for¬†Lean¬†that learned to solve a variety of challenging high-school olympiad problems, including problems from the¬†AMC12¬†and¬†AIME¬†competitions, as well as two problems adapted from the¬†IMO.",
    "summary": "We built a neural theorem prover for¬†Lean¬†that learned to solve a variety of challenging high-school olympiad problems, including problems from the¬†AMC12¬†and¬†AIME¬†competitions, as well as two problems adapted from the¬†IMO.",
    "pubDate": "Wed, 02 Feb 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/formal-math",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI and Guardian Media Group launch content partnership",
    "description": "OpenAI and Guardian Media Group announce content partnership to bring Guardian news content to ChatGPT.",
    "summary": "OpenAI and Guardian Media Group announce content partnership to bring Guardian news content to ChatGPT.",
    "pubDate": "Fri, 14 Feb 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-guardian-media-group-launch-content-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning Montezuma‚Äôs Revenge from a single demonstration",
    "description": "We‚Äôve trained an agent to achieve a high score of 74,500 on¬†Montezuma‚Äôs Revenge¬†from a single human demonstration, better than any previously published result. Our algorithm is simple: the agent plays a sequence of games starting from carefully chosen states from the demonstration, and learns from them by optimizing the game score using¬†PPO, the same reinforcement learning algorithm that underpins¬†OpenAI¬†Five.",
    "summary": "We‚Äôve trained an agent to achieve a high score of 74,500 on¬†Montezuma‚Äôs Revenge¬†from a single human demonstration, better than any previously published result. Our algorithm is simple: the agent plays a sequence of games starting from carefully chosen states from the demonstration, and learns from them by optimizing the game score using¬†PPO, the same reinforcement learning algorithm that underpins¬†OpenAI¬†Five.",
    "pubDate": "Wed, 04 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-montezumas-revenge-from-a-single-demonstration",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-Tune a Semantic Segmentation Model with a Custom Dataset",
    "description": "",
    "summary": "Fine-Tune a Semantic Segmentation Model with a Custom Dataset This guide shows how you can fine-tune...",
    "pubDate": "Thu, 17 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-segformer",
    "thumbnail": "https://huggingface.co/blog/assets/56_fine_tune_segformer/thumb.png"
  },
  {
    "title": "Preference Optimization for Vision Language Models",
    "description": "",
    "summary": "Preference Optimization for Vision Language Models with TRL Training models to understand and predic...",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dpo_vlm",
    "thumbnail": "https://huggingface.co/blog/assets/dpo_vlm/thumbnail.png"
  },
  {
    "title": "Accelerating LLM Inference with TGI on Intel Gaudi",
    "description": "",
    "summary": "üöÄ Accelerating LLM Inference with TGI on Intel Gaudi We're excited to announce the native integratio...",
    "pubDate": "Fri, 28 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-gaudi-backend-for-tgi",
    "thumbnail": "https://huggingface.co/blog/assets/intel-gaudi-backend-for-tgi/tgi-gaudi-thumbnail.png"
  },
  {
    "title": "Improving GANs using optimal transport",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 15 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-gans-using-optimal-transport",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FACTS Grounding: A new benchmark for evaluating the factuality of large language models",
    "description": "Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations",
    "summary": "Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations",
    "pubDate": "Tue, 17 Dec 2024 15:29:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/PNlhxhf4LKLRCezIt7Ap358F91-vbK5dLp56Ak1FejpCZh3YTp6jGqIDJm9c0iAtx8Y73MCTu279c1k2GZkM2qXXaqx315NSOaSiU0y0ATMK2c2Hyw=w1200-h630-n-nu"
  },
  {
    "title": "Autonomy by Design: Preserving Human Autonomy in AI Decision-Support",
    "description": "arXiv:2506.23952v1 Announce Type: cross Abstract: AI systems increasingly support human decision-making across domains of professional, skill-based, and personal activity. While previous work has examined how AI might affect human autonomy globally, the effects of AI on domain-specific autonomy -- the capacity for self-governed action within defined realms of skill or expertise -- remain understudied. We analyze how AI decision-support systems affect two key components of domain-specific autonomy: skilled competence (the ability to make informed judgments within one's domain) and authentic value-formation (the capacity to form genuine domain-relevant values and preferences). By engaging with prior investigations and analyzing empirical cases across medical, financial, and educational domains, we demonstrate how the absence of reliable failure indicators and the potential for unconscious value shifts can erode domain-specific autonomy both immediately and over time. We then develop a constructive framework for autonomy-preserving AI support systems. We propose specific socio-technical design patterns -- including careful role specification, implementation of defeater mechanisms, and support for reflective practice -- that can help maintain domain-specific autonomy while leveraging AI capabilities. This framework provides concrete guidance for developing AI systems that enhance rather than diminish human agency within specialized domains of action.",
    "summary": "arXiv:2506.23952v1 Announce Type: cross Abstract: AI systems increasingly support human decision-making across domains of professional, skill-based, and personal activity. While previous work has examined how AI might affect human autonomy globally, the effects of AI on domain-specific autonomy -- the capacity for self-governed action within defined realms of skill or expertise -- remain understudied. We analyze how AI decision-support systems affect two key components of domain-specific autonomy: skilled competence (the ability to make informed judgments within one's domain) and authentic value-formation (the capacity to form genuine domain-relevant values and preferences). By engaging with prior investigations and analyzing empirical cases across medical, financial, and educational domains, we demonstrate how the absence of reliable failure indicators and the potential for unconscious value shifts can erode domain-specific autonomy both immediately and over time. We then develop a constructive framework for autonomy-preserving AI support systems. We propose specific socio-technical design patterns -- including careful role specification, implementation of defeater mechanisms, and support for reflective practice -- that can help maintain domain-specific autonomy while leveraging AI capabilities. This framework provides concrete guidance for developing AI systems that enhance rather than diminish human agency within specialized domains of action.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23952",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Time-R1: Post-Training Large Vision Language Model for Temporal Video Grounding",
    "description": "arXiv:2503.13377v3 Announce Type: replace-cross Abstract: Temporal Video Grounding (TVG), the task of locating specific video segments based on language queries, is a core challenge in long-form video understanding. While recent Large Vision-Language Models (LVLMs) have shown early promise in tackling TVG through supervised fine-tuning (SFT), their abilities to generalize remain limited. To address this, we propose a novel post-training framework that enhances the generalization capabilities of LVLMs via reinforcement learning (RL). Specifically, our contributions span three key directions: (1) Time-R1: we introduce a reasoning-guided post-training framework via RL with verifiable reward to enhance the capabilities of LVLMs on the TVG task. (2) TimeRFT: we explore data-efficient post-training strategies on our curated RL-friendly dataset, which trains the model to progressively comprehend difficult samples, leading to better generalization. (3) TVGBench: we carefully construct a small yet comprehensive benchmark for LVLM evaluation, assessing 11 types of queries and featuring balanced distributions across both videos and queries. Extensive experiments demonstrate that Time-R1 achieves state-of-the-art performance across multiple downstream datasets using only 2.5K training data, while improving its general video understanding capabilities.",
    "summary": "arXiv:2503.13377v3 Announce Type: replace-cross Abstract: Temporal Video Grounding (TVG), the task of locating specific video segments based on language queries, is a core challenge in long-form video understanding. While recent Large Vision-Language Models (LVLMs) have shown early promise in tackling TVG through supervised fine-tuning (SFT), their abilities to generalize remain limited. To address this, we propose a novel post-training framework that enhances the generalization capabilities of LVLMs via reinforcement learning (RL). Specifically, our contributions span three key directions: (1) Time-R1: we introduce a reasoning-guided post-training framework via RL with verifiable reward to enhance the capabilities of LVLMs on the TVG task. (2) TimeRFT: we explore data-efficient post-training strategies on our curated RL-friendly dataset, which trains the model to progressively comprehend difficult samples, leading to better generalization. (3) TVGBench: we carefully construct a small yet comprehensive benchmark for LVLM evaluation, assessing 11 types of queries and featuring balanced distributions across both videos and queries. Extensive experiments demonstrate that Time-R1 achieves state-of-the-art performance across multiple downstream datasets using only 2.5K training data, while improving its general video understanding capabilities.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.13377",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improving verifiability in AI development",
    "description": "We‚Äôve contributed to a multi-stakeholder report by¬†58 co-authors¬†at 30 organizations, including the¬†Centre for the Future of Intelligence,¬†Mila,¬†Schwartz Reisman Institute for Technology and Society,¬†Center for Advanced Study in the Behavioral Sciences, and¬†Center for Security and Emerging Technologies. This report describes 10 mechanisms to improve the verifiability of claims made about AI systems. Developers can use these tools to provide evidence that AI systems are safe, secure, fair, or privacy-preserving. Users, policymakers, and civil society can use these tools to evaluate AI development¬†processes.",
    "summary": "We‚Äôve contributed to a multi-stakeholder report by¬†58 co-authors¬†at 30 organizations, including the¬†Centre for the Future of Intelligence,¬†Mila,¬†Schwartz Reisman Institute for Technology and Society,¬†Center for Advanced Study in the Behavioral Sciences, and¬†Center for Security and Emerging Technologies. This report describes 10 mechanisms to improve the verifiability of claims made about AI systems. Developers can use these tools to provide evidence that AI systems are safe, secure, fair, or privacy-preserving. Users, policymakers, and civil society can use these tools to evaluate AI development¬†processes.",
    "pubDate": "Thu, 16 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-verifiability",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LoRA training scripts of the world, unite!",
    "description": "",
    "summary": "LoRA training scripts of the world, unite! A community derived guide to some of the SOTA practices f...",
    "pubDate": "Tue, 02 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_lora_advanced_script",
    "thumbnail": "https://huggingface.co/blog/assets/dreambooth_lora_sdxl/thumbnail.png"
  },
  {
    "title": "Teaching AI models what they don‚Äôt know",
    "description": "A team of MIT researchers founded Themis AI to quantify AI model uncertainty and address knowledge gaps.",
    "summary": "A team of MIT researchers founded Themis AI to quantify AI model uncertainty and address knowledge gaps.",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/themis-ai-teaches-ai-models-what-they-dont-know-0603",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-ThemisAI-01-Press.jpg"
  },
  {
    "title": "Privacy Ethics Alignment in AI: A Stakeholder-Centric Framework for Ethical AI",
    "description": "arXiv:2503.11950v3 Announce Type: replace-cross Abstract: The increasing integration of Artificial Intelligence (AI) in digital ecosystems has reshaped privacy dynamics, particularly for young digital citizens navigating data-driven environments. This study explores evolving privacy concerns across three key stakeholder groups, digital citizens (ages 16-19), parents/educators, and AI professionals, and assesses differences in data ownership, trust, transparency, parental mediation, education, and risk-benefit perceptions. Employing a grounded theory methodology, this research synthesizes insights from 482 participants through structured surveys, qualitative interviews, and focus groups. The findings reveal distinct privacy expectations: Young users emphasize autonomy and digital freedom, while parents and educators advocate for regulatory oversight and AI literacy programs. AI professionals, in contrast, prioritize the balance between ethical system design and technological efficiency. The data further highlights gaps in AI literacy and transparency, emphasizing the need for comprehensive, stakeholder-driven privacy frameworks that accommodate diverse user needs. Using comparative thematic analysis, this study identifies key tensions in privacy governance and develops the novel Privacy-Ethics Alignment in AI (PEA-AI) model, which structures privacy decision-making as a dynamic negotiation between stakeholders. By systematically analyzing themes such as transparency, user control, risk perception, and parental mediation, this research provides a scalable, adaptive foundation for AI governance, ensuring that privacy protections evolve alongside emerging AI technologies and youth-centric digital interactions.",
    "summary": "arXiv:2503.11950v3 Announce Type: replace-cross Abstract: The increasing integration of Artificial Intelligence (AI) in digital ecosystems has reshaped privacy dynamics, particularly for young digital citizens navigating data-driven environments. This study explores evolving privacy concerns across three key stakeholder groups, digital citizens (ages 16-19), parents/educators, and AI professionals, and assesses differences in data ownership, trust, transparency, parental mediation, education, and risk-benefit perceptions. Employing a grounded theory methodology, this research synthesizes insights from 482 participants through structured surveys, qualitative interviews, and focus groups. The findings reveal distinct privacy expectations: Young users emphasize autonomy and digital freedom, while parents and educators advocate for regulatory oversight and AI literacy programs. AI professionals, in contrast, prioritize the balance between ethical system design and technological efficiency. The data further highlights gaps in AI literacy and transparency, emphasizing the need for comprehensive, stakeholder-driven privacy frameworks that accommodate diverse user needs. Using comparative thematic analysis, this study identifies key tensions in privacy governance and develops the novel Privacy-Ethics Alignment in AI (PEA-AI) model, which structures privacy decision-making as a dynamic negotiation between stakeholders. By systematically analyzing themes such as transparency, user control, risk perception, and parental mediation, this research provides a scalable, adaptive foundation for AI governance, ensuring that privacy protections evolve alongside emerging AI technologies and youth-centric digital interactions.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.11950",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Calibrating Graph Neural Networks with Wavelet-Aware Temperature Scaling",
    "description": "arXiv:2506.23782v1 Announce Type: cross Abstract: Graph Neural Networks (GNNs) have demonstrated strong predictive performance on relational data; however, their confidence estimates often misalign with actual predictive correctness, posing significant limitations for deployment in safety-critical settings. While existing graph-aware calibration methods seek to mitigate this limitation, they primarily depend on coarse one-hop statistics, such as neighbor-predicted confidence, or latent node embeddings, thereby neglecting the fine-grained structural heterogeneity inherent in graph topology. In this work, we propose Wavelet-Aware Temperature Scaling (WATS), a post-hoc calibration framework that assigns node-specific temperatures based on tunable heat-kernel graph wavelet features. Specifically, WATS harnesses the scalability and topology sensitivity of graph wavelets to refine confidence estimates, all without necessitating model retraining or access to neighboring logits or predictions. Extensive evaluations across seven benchmark datasets with varying graph structures and two GNN backbones demonstrate that WATS achieves the lowest Expected Calibration Error (ECE) among all compared methods, outperforming both classical and graph-specific baselines by up to 42.3% in ECE and reducing calibration variance by 17.24% on average compared with graph-specific methods. Moreover, WATS remains computationally efficient, scaling well across graphs of diverse sizes and densities. Code will be released based on publication.",
    "summary": "arXiv:2506.23782v1 Announce Type: cross Abstract: Graph Neural Networks (GNNs) have demonstrated strong predictive performance on relational data; however, their confidence estimates often misalign with actual predictive correctness, posing significant limitations for deployment in safety-critical settings. While existing graph-aware calibration methods seek to mitigate this limitation, they primarily depend on coarse one-hop statistics, such as neighbor-predicted confidence, or latent node embeddings, thereby neglecting the fine-grained structural heterogeneity inherent in graph topology. In this work, we propose Wavelet-Aware Temperature Scaling (WATS), a post-hoc calibration framework that assigns node-specific temperatures based on tunable heat-kernel graph wavelet features. Specifically, WATS harnesses the scalability and topology sensitivity of graph wavelets to refine confidence estimates, all without necessitating model retraining or access to neighboring logits or predictions. Extensive evaluations across seven benchmark datasets with varying graph structures and two GNN backbones demonstrate that WATS achieves the lowest Expected Calibration Error (ECE) among all compared methods, outperforming both classical and graph-specific baselines by up to 42.3% in ECE and reducing calibration variance by 17.24% on average compared with graph-specific methods. Moreover, WATS remains computationally efficient, scaling well across graphs of diverse sizes and densities. Code will be released based on publication.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23782",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans",
    "description": "arXiv:2506.22439v1 Announce Type: cross Abstract: The evaluation of LLMs has so far focused primarily on how well they can perform different tasks such as reasoning, question-answering, paraphrasing, or translating. For most of these tasks, performance can be measured with objective metrics, such as the number of correct answers. However, other language features are not easily quantified. For example, arousal, concreteness, or gender associated with a given word, as well as the extent to which we experience words with senses and relate them to a specific sense. Those features have been studied for many years by psycholinguistics, conducting large-scale experiments with humans to produce ratings for thousands of words. This opens an opportunity to evaluate how well LLMs align with human ratings on these word features, taking advantage of existing studies that cover many different language features in a large number of words. In this paper, we evaluate the alignment of a representative group of LLMs with human ratings on two psycholinguistic datasets: the Glasgow and Lancaster norms. These datasets cover thirteen features over thousands of words. The results show that alignment is textcolor{black}{generally} better in the Glasgow norms evaluated (arousal, valence, dominance, concreteness, imageability, familiarity, and gender) than on the Lancaster norms evaluated (introceptive, gustatory, olfactory, haptic, auditory, and visual). This suggests a potential limitation of current LLMs in aligning with human sensory associations for words, which may be due to their lack of embodied cognition present in humans and illustrates the usefulness of evaluating LLMs with psycholinguistic datasets.",
    "summary": "arXiv:2506.22439v1 Announce Type: cross Abstract: The evaluation of LLMs has so far focused primarily on how well they can perform different tasks such as reasoning, question-answering, paraphrasing, or translating. For most of these tasks, performance can be measured with objective metrics, such as the number of correct answers. However, other language features are not easily quantified. For example, arousal, concreteness, or gender associated with a given word, as well as the extent to which we experience words with senses and relate them to a specific sense. Those features have been studied for many years by psycholinguistics, conducting large-scale experiments with humans to produce ratings for thousands of words. This opens an opportunity to evaluate how well LLMs align with human ratings on these word features, taking advantage of existing studies that cover many different language features in a large number of words. In this paper, we evaluate the alignment of a representative group of LLMs with human ratings on two psycholinguistic datasets: the Glasgow and Lancaster norms. These datasets cover thirteen features over thousands of words. The results show that alignment is textcolor{black}{generally} better in the Glasgow norms evaluated (arousal, valence, dominance, concreteness, imageability, familiarity, and gender) than on the Lancaster norms evaluated (introceptive, gustatory, olfactory, haptic, auditory, and visual). This suggests a potential limitation of current LLMs in aligning with human sensory associations for words, which may be due to their lack of embodied cognition present in humans and illustrates the usefulness of evaluating LLMs with psycholinguistic datasets.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22439",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Mapping the misuse of generative AI",
    "description": "New research analyzes the misuse of multimodal generative AI today, in order to help build safer and more responsible technologies.",
    "summary": "New research analyzes the misuse of multimodal generative AI today, in order to help build safer and more responsible technologies.",
    "pubDate": "Fri, 02 Aug 2024 10:50:58 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/mapping-the-misuse-of-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/IzYg4pdM7_tKoEbQHE4-Em9cvFxbx2Aq4_YOQdLr6VK754c8-bJRW9LWMf1_nUraA5BfNcBjAjpIjcfF1M_qQviR8b7qyRnAiUzapq3LKVbTpoJ8Cw=w1200-h630-n-nu"
  },
  {
    "title": "Pipelined Decoder for Efficient Context-Aware Text Generation",
    "description": "arXiv:2506.23431v1 Announce Type: cross Abstract: As the basis of generative AI, an autoregressive model requires the generation of a new token depending on all the previously generated tokens, which brings high quality but also restricts the model to generate tokens one by one, forming a bottleneck limiting the generation speed. In this paper, we propose a new decoder architecture that efficiently generates text in parallel for context-aware generation tasks. Our proposed pipelined decoder initiates the generation of multiple subsequences simultaneously, and, at each time-step, it generates a new token for each subsequence to realize parallelism. Experiments on multiple text generation tasks, including question answering, text summarization, and keyphrase generation, show that our pipelined decoder significantly improves the generation speed without a significant loss of generation quality or additional memory consumption.",
    "summary": "arXiv:2506.23431v1 Announce Type: cross Abstract: As the basis of generative AI, an autoregressive model requires the generation of a new token depending on all the previously generated tokens, which brings high quality but also restricts the model to generate tokens one by one, forming a bottleneck limiting the generation speed. In this paper, we propose a new decoder architecture that efficiently generates text in parallel for context-aware generation tasks. Our proposed pipelined decoder initiates the generation of multiple subsequences simultaneously, and, at each time-step, it generates a new token for each subsequence to realize parallelism. Experiments on multiple text generation tasks, including question answering, text summarization, and keyphrase generation, show that our pipelined decoder significantly improves the generation speed without a significant loss of generation quality or additional memory consumption.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23431",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Navigating with Annealing Guidance Scale in Diffusion Space",
    "description": "arXiv:2506.24108v1 Announce Type: cross Abstract: Denoising diffusion models excel at generating high-quality images conditioned on text prompts, yet their effectiveness heavily relies on careful guidance during the sampling process. Classifier-Free Guidance (CFG) provides a widely used mechanism for steering generation by setting the guidance scale, which balances image quality and prompt alignment. However, the choice of the guidance scale has a critical impact on the convergence toward a visually appealing and prompt-adherent image. In this work, we propose an annealing guidance scheduler which dynamically adjusts the guidance scale over time based on the conditional noisy signal. By learning a scheduling policy, our method addresses the temperamental behavior of CFG. Empirical results demonstrate that our guidance scheduler significantly enhances image quality and alignment with the text prompt, advancing the performance of text-to-image generation. Notably, our novel scheduler requires no additional activations or memory consumption, and can seamlessly replace the common classifier-free guidance, offering an improved trade-off between prompt alignment and quality.",
    "summary": "arXiv:2506.24108v1 Announce Type: cross Abstract: Denoising diffusion models excel at generating high-quality images conditioned on text prompts, yet their effectiveness heavily relies on careful guidance during the sampling process. Classifier-Free Guidance (CFG) provides a widely used mechanism for steering generation by setting the guidance scale, which balances image quality and prompt alignment. However, the choice of the guidance scale has a critical impact on the convergence toward a visually appealing and prompt-adherent image. In this work, we propose an annealing guidance scheduler which dynamically adjusts the guidance scale over time based on the conditional noisy signal. By learning a scheduling policy, our method addresses the temperamental behavior of CFG. Empirical results demonstrate that our guidance scheduler significantly enhances image quality and alignment with the text prompt, advancing the performance of text-to-image generation. Notably, our novel scheduler requires no additional activations or memory consumption, and can seamlessly replace the common classifier-free guidance, offering an improved trade-off between prompt alignment and quality.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.24108",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How can we build human values into AI?",
    "description": "Drawing from philosophy to identify fair principles for ethical AI...",
    "summary": "Drawing from philosophy to identify fair principles for ethical AI...",
    "pubDate": "Mon, 24 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/how-can-we-build-human-values-into-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/jXiO9PpMnNRhxz3kyDP97SVi5c68dQie9V4AHbH_I0Py0EJoOl0fyPhoVljUGETrNmj3BhbAEahqmsq4r-33IgLgGhsuUhN2p384-d8B_vc4asHWB6Q=w1200-h630-n-nu"
  },
  {
    "title": "Extensions and limitations of the neural GPU",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 02 Nov 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/extensions-and-limitations-of-the-neural-gpu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making thousands of open LLMs bloom in the Vertex AI Model Garden",
    "description": "",
    "summary": "Making thousands of open LLMs bloom in the Vertex AI Model Garden Today, we are thrilled to announce...",
    "pubDate": "Wed, 10 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/google-cloud-model-garden",
    "thumbnail": "https://huggingface.co/blog/assets/173_gcp-partnership/thumbnail.jpg"
  },
  {
    "title": "Gemma 3n fully available in the open-source ecosystem!",
    "description": "",
    "summary": "Gemma 3n fully available in the open-source ecosystem! Gemma 3n was announced as a preview during Go...",
    "pubDate": "Thu, 26 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma3n",
    "thumbnail": "https://huggingface.co/blog/assets/gemma3n/thumbnail.png"
  },
  {
    "title": "Emergence of grounded compositional language in multi-agent populations",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 15 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergence-of-grounded-compositional-language-in-multi-agent-populations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Wayfair is shaping the future of retail with AI",
    "description": "A conversation with Fiona Tan, Chief Technology Officer of Wayfair.",
    "summary": "A conversation with Fiona Tan, Chief Technology Officer of Wayfair.",
    "pubDate": "Thu, 13 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/wayfair-fiona-tan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Survey of Test-Time Compute: From Intuitive Inference to Deliberate Reasoning",
    "description": "arXiv:2501.02497v3 Announce Type: replace Abstract: The remarkable performance of the o1 model in complex reasoning demonstrates that test-time compute scaling can further unlock the model's potential, enabling powerful System-2 thinking. However, there is still a lack of comprehensive surveys for test-time compute scaling. We trace the concept of test-time compute back to System-1 models. In System-1 models, test-time compute addresses distribution shifts and improves robustness and generalization through parameter updating, input modification, representation editing, and output calibration. In System-2 models, it enhances the model's reasoning ability to solve complex problems through repeated sampling, self-correction, and tree search. We organize this survey according to the trend of System-1 to System-2 thinking, highlighting the key role of test-time compute in the transition from System-1 models to weak System-2 models, and then to strong System-2 models. We also point out advanced topics and future directions.",
    "summary": "arXiv:2501.02497v3 Announce Type: replace Abstract: The remarkable performance of the o1 model in complex reasoning demonstrates that test-time compute scaling can further unlock the model's potential, enabling powerful System-2 thinking. However, there is still a lack of comprehensive surveys for test-time compute scaling. We trace the concept of test-time compute back to System-1 models. In System-1 models, test-time compute addresses distribution shifts and improves robustness and generalization through parameter updating, input modification, representation editing, and output calibration. In System-2 models, it enhances the model's reasoning ability to solve complex problems through repeated sampling, self-correction, and tree search. We organize this survey according to the trend of System-1 to System-2 thinking, highlighting the key role of test-time compute in the transition from System-1 models to weak System-2 models, and then to strong System-2 models. We also point out advanced topics and future directions.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.02497",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Ë®ÄË™ûÂá¶ÁêÜÂ≠¶‰ºöÁ¨¨31ÂõûÂπ¥Ê¨°Â§ß‰ºö(NLP2025) Áô∫Ë°®Â†±Âëä",
    "description": "<p>1. „ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÇAI„ÉÅ„Éº„É†„ÅÆÊ†óÂéü„Åß„Åô„ÄÇ2025Âπ¥3Êúà10Êó•(Êúà)„Äú3Êúà14Êó•(Èáë)„Å´Âá∫Â≥∂„É°„ÉÉ„ÇªÈï∑Â¥é„Å´„Å¶Ë°å„Çè„Çå„ÅüË®ÄË™ûÂá¶ÁêÜÂ≠¶‰ºöÁ¨¨31ÂõûÂπ¥Ê¨°Â§ß‰ºö„Åß„ÄÅÂºäÁ§æ„Åã„Çâ„Éù„Çπ„Çø„ÉºÁô∫Ë°®„Åß3‰ª∂„ÄÅÂè£È†≠Áô∫Ë°®„Åß1‰ª∂„ÅÆÁô∫Ë°®„ÇíË°å„ÅÑ„Åæ„Åó„Åü„ÄÇ Êò® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5586' rel='nofollow'>Ë®ÄË™ûÂá¶ÁêÜÂ≠¶‰ºöÁ¨¨31ÂõûÂπ¥Ê¨°Â§ß‰ºö(NLP2025) Áô∫Ë°®Â†±Âëä</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>1. „ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÇAI„ÉÅ„Éº„É†„ÅÆÊ†óÂéü„Åß„Åô„ÄÇ2025Âπ¥3Êúà10Êó•(Êúà)„Äú3Êúà14Êó•(Èáë)„Å´Âá∫Â≥∂„É°„ÉÉ„ÇªÈï∑Â¥é„Å´„Å¶Ë°å„Çè„Çå„ÅüË®ÄË™ûÂá¶ÁêÜÂ≠¶‰ºöÁ¨¨31ÂõûÂπ¥Ê¨°Â§ß‰ºö„Åß„ÄÅÂºäÁ§æ„Åã„Çâ„Éù„Çπ„Çø„ÉºÁô∫Ë°®„Åß3‰ª∂„ÄÅÂè£È†≠Áô∫Ë°®„Åß1‰ª∂„ÅÆÁô∫Ë°®„ÇíË°å„ÅÑ„Åæ„Åó„Åü„ÄÇ Êò® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5586' rel='nofollow'>Ë®ÄË™ûÂá¶ÁêÜÂ≠¶‰ºöÁ¨¨31ÂõûÂπ¥Ê¨°Â§ß‰ºö(NLP2025) Áô∫Ë°®Â†±Âëä</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Fri, 14 Mar 2025 10:50:19 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5586",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/IMG_1253-1-scaled.jpg"
  },
  {
    "title": "Open LLM Leaderboard: DROP deep dive",
    "description": "",
    "summary": "Open LLM Leaderboard: DROP deep dive Recently, three new benchmarks were added to the Open LLM Leade...",
    "pubDate": "Fri, 01 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-drop",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "Fuel your creativity with new generative media models and tools",
    "description": "Introducing Veo 3 and Imagen 4, and a new tool for filmmaking called Flow.",
    "summary": "Introducing Veo 3 and Imagen 4, and a new tool for filmmaking called Flow.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/fuel-your-creativity-with-new-generative-media-models-and-tools/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5.20v2_SS_1920x1080.width-1300.png"
  },
  {
    "title": "Retro Contest: Results",
    "description": "The first run of our¬†Retro Contest‚Äîexploring the development of algorithms that can generalize from previous experience‚Äîis now¬†complete.",
    "summary": "The first run of our¬†Retro Contest‚Äîexploring the development of algorithms that can generalize from previous experience‚Äîis now¬†complete.",
    "pubDate": "Fri, 22 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retro-contest-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlignGuard: Scalable Safety Alignment for Text-to-Image Generation",
    "description": "arXiv:2412.10493v2 Announce Type: replace-cross Abstract: Text-to-image (T2I) models are widespread, but their limited safety guardrails expose end users to harmful content and potentially allow for model misuse. Current safety measures are typically limited to text-based filtering or concept removal strategies, able to remove just a few concepts from the model's generative capabilities. In this work, we introduce AlignGuard, a method for safety alignment of T2I models. We enable the application of Direct Preference Optimization (DPO) for safety purposes in T2I models by synthetically generating a dataset of harmful and safe image-text pairs, which we call CoProV2. Using a custom DPO strategy and this dataset, we train safety experts, in the form of low-rank adaptation (LoRA) matrices, able to guide the generation process away from specific safety-related concepts. Then, we merge the experts into a single LoRA using a novel merging strategy for optimal scaling performance. This expert-based approach enables scalability, allowing us to remove 7x more harmful concepts from T2I models compared to baselines. AlignGuard consistently outperforms the state-of-the-art on many benchmarks and establishes new practices for safety alignment in T2I networks. Code and data will be shared at https://safetydpo.github.io/.",
    "summary": "arXiv:2412.10493v2 Announce Type: replace-cross Abstract: Text-to-image (T2I) models are widespread, but their limited safety guardrails expose end users to harmful content and potentially allow for model misuse. Current safety measures are typically limited to text-based filtering or concept removal strategies, able to remove just a few concepts from the model's generative capabilities. In this work, we introduce AlignGuard, a method for safety alignment of T2I models. We enable the application of Direct Preference Optimization (DPO) for safety purposes in T2I models by synthetically generating a dataset of harmful and safe image-text pairs, which we call CoProV2. Using a custom DPO strategy and this dataset, we train safety experts, in the form of low-rank adaptation (LoRA) matrices, able to guide the generation process away from specific safety-related concepts. Then, we merge the experts into a single LoRA using a novel merging strategy for optimal scaling performance. This expert-based approach enables scalability, allowing us to remove 7x more harmful concepts from T2I models compared to baselines. AlignGuard consistently outperforms the state-of-the-art on many benchmarks and establishes new practices for safety alignment in T2I networks. Code and data will be shared at https://safetydpo.github.io/.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.10493",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Making a web app generator with open ML models",
    "description": "",
    "summary": "Making a web app generator with open ML models As more code generation models become publicly availa...",
    "pubDate": "Mon, 03 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-to-webapp",
    "thumbnail": "https://huggingface.co/blog/assets/153_text_to_webapp/thumbnail.jpg"
  },
  {
    "title": "Serverless Inference with Hugging Face and NVIDIA NIMs",
    "description": "",
    "summary": "Serverless Inference with Hugging Face and NVIDIA NIM Update: This service is deprecated and no long...",
    "pubDate": "Mon, 29 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-dgx-cloud",
    "thumbnail": "https://huggingface.co/blog/assets/train-dgx-cloud/thumbnail.jpg"
  },
  {
    "title": "Introducing new audio and vision documentation in ü§ó Datasets",
    "description": "",
    "summary": "Introducing new audio and vision documentation in ü§ó Datasets Open and reproducible datasets are esse...",
    "pubDate": "Thu, 28 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/datasets-docs-update",
    "thumbnail": "https://huggingface.co/blog/assets/87_datasets-docs-update/thumbnail.gif"
  },
  {
    "title": "Introducing ChatGPT Gov",
    "description": "ChatGPT Gov is designed to streamline government agencies‚Äô access to OpenAI‚Äôs frontier models.",
    "summary": "ChatGPT Gov is designed to streamline government agencies‚Äô access to OpenAI‚Äôs frontier models.",
    "pubDate": "Tue, 28 Jan 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-chatgpt-gov",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-3.5 Turbo fine-tuning and API updates",
    "description": "Developers can now bring their own data to customize GPT-3.5 Turbo for their use cases.",
    "summary": "Developers can now bring their own data to customize GPT-3.5 Turbo for their use cases.",
    "pubDate": "Tue, 22 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LLM„ÅÆÊé®Ë´ñ„Å´„Åä„Åë„Çã ‚Äúaha moment‚Äù „Å´„Å§„ÅÑ„Å¶Ë™ø„Åπ„Å¶„Åø„Åü",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ÂÖàÊó•„ÄÅLLM„ÅÆ 'aha moment' „Å´Èñ¢„Åó„Å¶ËààÂë≥„ÇíÊåÅ„Å°„ÄÅÈñ¢ÈÄ£Ë´ñÊñá„ÇÑWeb‰∏ä„ÅÆË®ò‰∫ã„ÇíË™≠„Çì„Åß„Åø„Åü„Å®„Åì„Çç„ÄÅË≥õÂê¶‰∏°Ë´ñ„ÅÆÊßò„ÄÖ„Å™Ë¶ãËß£„Åå„ÅÇ„ÇäËààÂë≥Ê∑±„Åã„Å£„Åü„ÅÆ„Åß„ÄÅ‰ªäÂõû„ÅØ„Åù„ÅÆÂÜÖÂÆπ„ÇíÂÖ±Êúâ„Åó„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5766' rel='nofollow'>LLM„ÅÆÊé®Ë´ñ„Å´„Åä„Åë„Çã &#8220;aha moment&#8221; „Å´„Å§„ÅÑ„Å¶Ë™ø„Åπ„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ÂÖàÊó•„ÄÅLLM„ÅÆ 'aha moment' „Å´Èñ¢„Åó„Å¶ËààÂë≥„ÇíÊåÅ„Å°„ÄÅÈñ¢ÈÄ£Ë´ñÊñá„ÇÑWeb‰∏ä„ÅÆË®ò‰∫ã„ÇíË™≠„Çì„Åß„Åø„Åü„Å®„Åì„Çç„ÄÅË≥õÂê¶‰∏°Ë´ñ„ÅÆÊßò„ÄÖ„Å™Ë¶ãËß£„Åå„ÅÇ„ÇäËààÂë≥Ê∑±„Åã„Å£„Åü„ÅÆ„Åß„ÄÅ‰ªäÂõû„ÅØ„Åù„ÅÆÂÜÖÂÆπ„ÇíÂÖ±Êúâ„Åó„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5766' rel='nofollow'>LLM„ÅÆÊé®Ë´ñ„Å´„Åä„Åë„Çã &#8220;aha moment&#8221; „Å´„Å§„ÅÑ„Å¶Ë™ø„Åπ„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Fri, 16 May 2025 04:41:37 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5766",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/d099d886ed65ef765625779e628d2c5f.png"
  },
  {
    "title": "A research agenda for assessing the economic impacts of code generation models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/economic-impacts-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building agricultural database for farmers",
    "description": "Digital Green uses OpenAI to increase farmer income.",
    "summary": "Digital Green uses OpenAI to increase farmer income.",
    "pubDate": "Fri, 12 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/digital-green",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning to communicate",
    "description": "In this post we‚Äôll outline new OpenAI research in which agents develop their own language.",
    "summary": "In this post we‚Äôll outline new OpenAI research in which agents develop their own language.",
    "pubDate": "Thu, 16 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-communicate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeRobot Community Datasets: The ‚ÄúImageNet‚Äù of Robotics ‚Äî When and How?",
    "description": "",
    "summary": "LeRobot Community Datasets: The ‚ÄúImageNet‚Äù of Robotics ‚Äî When and How? üß≠ TL;DR ‚Äî Why This Blogpost? ...",
    "pubDate": "Sun, 11 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lerobot-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/195_lerobot_datasets/1.png"
  },
  {
    "title": "OpenAI partners with Schibsted Media Group",
    "description": "OpenAI and Schibsted Media Group announce content partnership to bring Guardian news and archive content to  ChatGPT.",
    "summary": "OpenAI and Schibsted Media Group announce content partnership to bring Guardian news and archive content to  ChatGPT.",
    "pubDate": "Mon, 10 Feb 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-partners-with-schibsted-media-group",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing The World's Largest Open Multilingual Language Model: BLOOM",
    "description": "",
    "summary": "üå∏ Introducing The World's Largest Open Multilingual Language Model: BLOOM üå∏ Large language models (L...",
    "pubDate": "Tue, 12 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom",
    "thumbnail": "https://huggingface.co/blog/assets/86_bloom/thumbnail.png"
  },
  {
    "title": "Super-Resolution Generative Adversarial Networks based Video Enhancement",
    "description": "arXiv:2505.10589v4 Announce Type: replace-cross Abstract: This study introduces an enhanced approach to video super-resolution by extending ordinary Single-Image Super-Resolution (SISR) Super-Resolution Generative Adversarial Network (SRGAN) structure to handle spatio-temporal data. While SRGAN has proven effective for single-image enhancement, its design does not account for the temporal continuity required in video processing. To address this, a modified framework that incorporates 3D Non-Local Blocks is proposed, which is enabling the model to capture relationships across both spatial and temporal dimensions. An experimental training pipeline is developed, based on patch-wise learning and advanced data degradation techniques, to simulate real-world video conditions and learn from both local and global structures and details. This helps the model generalize better and maintain stability across varying video content while maintaining the general structure besides the pixel-wise correctness. Two model variants-one larger and one more lightweight-are presented to explore the trade-offs between performance and efficiency. The results demonstrate improved temporal coherence, sharper textures, and fewer visual artifacts compared to traditional single-image methods. This work contributes to the development of practical, learning-based solutions for video enhancement tasks, with potential applications in streaming, gaming, and digital restoration.",
    "summary": "arXiv:2505.10589v4 Announce Type: replace-cross Abstract: This study introduces an enhanced approach to video super-resolution by extending ordinary Single-Image Super-Resolution (SISR) Super-Resolution Generative Adversarial Network (SRGAN) structure to handle spatio-temporal data. While SRGAN has proven effective for single-image enhancement, its design does not account for the temporal continuity required in video processing. To address this, a modified framework that incorporates 3D Non-Local Blocks is proposed, which is enabling the model to capture relationships across both spatial and temporal dimensions. An experimental training pipeline is developed, based on patch-wise learning and advanced data degradation techniques, to simulate real-world video conditions and learn from both local and global structures and details. This helps the model generalize better and maintain stability across varying video content while maintaining the general structure besides the pixel-wise correctness. Two model variants-one larger and one more lightweight-are presented to explore the trade-offs between performance and efficiency. The results demonstrate improved temporal coherence, sharper textures, and fewer visual artifacts compared to traditional single-image methods. This work contributes to the development of practical, learning-based solutions for video enhancement tasks, with potential applications in streaming, gaming, and digital restoration.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.10589",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLM Inference on Edge: A Fun and Easy Guide to run LLMs via React Native on your Phone!",
    "description": "",
    "summary": "LLM Inference on Edge: A Fun and Easy Guide to run LLMs via React Native on your Phone! As LLMs cont...",
    "pubDate": "Fri, 07 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llm-inference-on-edge",
    "thumbnail": "https://huggingface.co/blog/assets/llm_inference_on_edge/thumbnail.png"
  },
  {
    "title": "Dota 2",
    "description": "We‚Äôve created a bot which beats the world‚Äôs top professionals at 1v1 matches of Dota 2 under standard tournament rules. The bot learned the game from scratch by self-play, and does not use imitation learning or tree search. This is a step towards building AI systems which accomplish well-defined goals in messy, complicated situations involving real humans.",
    "summary": "We‚Äôve created a bot which beats the world‚Äôs top professionals at 1v1 matches of Dota 2 under standard tournament rules. The bot learned the game from scratch by self-play, and does not use imitation learning or tree search. This is a step towards building AI systems which accomplish well-defined goals in messy, complicated situations involving real humans.",
    "pubDate": "Fri, 11 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dota-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows",
    "description": "arXiv:2506.23260v1 Announce Type: cross Abstract: Autonomous AI agents powered by large language models (LLMs) with structured function-calling interfaces have dramatically expanded capabilities for real-time data retrieval, complex computation, and multi-step orchestration. Yet, the explosive proliferation of plugins, connectors, and inter-agent protocols has outpaced discovery mechanisms and security practices, resulting in brittle integrations vulnerable to diverse threats. In this survey, we introduce the first unified, end-to-end threat model for LLM-agent ecosystems, spanning host-to-tool and agent-to-agent communications, formalize adversary capabilities and attacker objectives, and catalog over thirty attack techniques. Specifically, we organized the threat model into four domains: Input Manipulation (e.g., prompt injections, long-context hijacks, multimodal adversarial inputs), Model Compromise (e.g., prompt- and parameter-level backdoors, composite and encrypted multi-backdoors, poisoning strategies), System and Privacy Attacks (e.g., speculative side-channels, membership inference, retrieval poisoning, social-engineering simulations), and Protocol Vulnerabilities (e.g., exploits in Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent Network Protocol (ANP), and Agent-to-Agent (A2A) protocol). For each category, we review representative scenarios, assess real-world feasibility, and evaluate existing defenses. Building on our threat taxonomy, we identify key open challenges and future research directions, such as securing MCP deployments through dynamic trust management and cryptographic provenance tracking; designing and hardening Agentic Web Interfaces; and achieving resilience in multi-agent and federated environments. Our work provides a comprehensive reference to guide the design of robust defense mechanisms and establish best practices for resilient LLM-agent workflows.",
    "summary": "arXiv:2506.23260v1 Announce Type: cross Abstract: Autonomous AI agents powered by large language models (LLMs) with structured function-calling interfaces have dramatically expanded capabilities for real-time data retrieval, complex computation, and multi-step orchestration. Yet, the explosive proliferation of plugins, connectors, and inter-agent protocols has outpaced discovery mechanisms and security practices, resulting in brittle integrations vulnerable to diverse threats. In this survey, we introduce the first unified, end-to-end threat model for LLM-agent ecosystems, spanning host-to-tool and agent-to-agent communications, formalize adversary capabilities and attacker objectives, and catalog over thirty attack techniques. Specifically, we organized the threat model into four domains: Input Manipulation (e.g., prompt injections, long-context hijacks, multimodal adversarial inputs), Model Compromise (e.g., prompt- and parameter-level backdoors, composite and encrypted multi-backdoors, poisoning strategies), System and Privacy Attacks (e.g., speculative side-channels, membership inference, retrieval poisoning, social-engineering simulations), and Protocol Vulnerabilities (e.g., exploits in Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent Network Protocol (ANP), and Agent-to-Agent (A2A) protocol). For each category, we review representative scenarios, assess real-world feasibility, and evaluate existing defenses. Building on our threat taxonomy, we identify key open challenges and future research directions, such as securing MCP deployments through dynamic trust management and cryptographic provenance tracking; designing and hardening Agentic Web Interfaces; and achieving resilience in multi-agent and federated environments. Our work provides a comprehensive reference to guide the design of robust defense mechanisms and establish best practices for resilient LLM-agent workflows.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23260",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Snowball Fight ‚òÉÔ∏è, our First ML-Agents Environment",
    "description": "",
    "summary": "Introducing Snowball Fight ‚òÉÔ∏è, our First ML-Agents Environment We're excited to share our first cust...",
    "pubDate": "Thu, 02 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/snowball-fight",
    "thumbnail": "https://huggingface.co/blog/assets/39_introducing_snowball_fight/thumbnail.png"
  },
  {
    "title": "DALL¬∑E 3 system card",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 03 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-3-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Novel method detects microbial contamination in cell cultures",
    "description": "Ultraviolet light ‚Äúfingerprints‚Äù on cell cultures and machine learning can provide a definitive yes/no contamination assessment within 30 minutes.",
    "summary": "Ultraviolet light ‚Äúfingerprints‚Äù on cell cultures and machine learning can provide a definitive yes/no contamination assessment within 30 minutes.",
    "pubDate": "Fri, 25 Apr 2025 22:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/novel-method-detects-microbial-contamination-smart-0425",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/SMART-CAMP-Senior-Research-Engineer.jpg"
  },
  {
    "title": "Gradio joins Hugging Face!",
    "description": "",
    "summary": "Gradio is joining Hugging Face! Gradio is joining Hugging Face! By acquiring Gradio, a machine learn...",
    "pubDate": "Tue, 21 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-joins-hf",
    "thumbnail": "https://huggingface.co/blog/assets/42_gradio_joins_hf/thumbnail.png"
  },
  {
    "title": "Designing a new way to optimize complex coordinated systems",
    "description": "Using diagrams to represent interactions in multipart systems can provide a faster way to design software improvements.",
    "summary": "Using diagrams to represent interactions in multipart systems can provide a faster way to design software improvements.",
    "pubDate": "Thu, 24 Apr 2025 15:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/designing-new-way-optimize-complex-coordinated-systems-0424",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/deep-learning-diagram.jpg"
  },
  {
    "title": "Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models",
    "description": "arXiv:2502.03607v2 Announce Type: replace-cross Abstract: Recent advances in diffusion models hold significant potential in robotics, enabling the generation of diverse and smooth trajectories directly from raw representations of the environment. Despite this promise, applying diffusion models to motion planning remains challenging due to their difficulty in enforcing critical constraints, such as collision avoidance and kinematic feasibility. These limitations become even more pronounced in Multi-Robot Motion Planning (MRMP), where multiple robots must coordinate in shared spaces. To address these challenges, this work proposes Simultaneous MRMP Diffusion (SMD), a novel approach integrating constrained optimization into the diffusion sampling process to produce collision-free, kinematically feasible trajectories. Additionally, the paper introduces a comprehensive MRMP benchmark to evaluate trajectory planning algorithms across scenarios with varying robot densities, obstacle complexities, and motion constraints. Experimental results show SMD consistently outperforms classical and other learning-based motion planners, achieving higher success rates and efficiency in complex multi-robot environments.",
    "summary": "arXiv:2502.03607v2 Announce Type: replace-cross Abstract: Recent advances in diffusion models hold significant potential in robotics, enabling the generation of diverse and smooth trajectories directly from raw representations of the environment. Despite this promise, applying diffusion models to motion planning remains challenging due to their difficulty in enforcing critical constraints, such as collision avoidance and kinematic feasibility. These limitations become even more pronounced in Multi-Robot Motion Planning (MRMP), where multiple robots must coordinate in shared spaces. To address these challenges, this work proposes Simultaneous MRMP Diffusion (SMD), a novel approach integrating constrained optimization into the diffusion sampling process to produce collision-free, kinematically feasible trajectories. Additionally, the paper introduces a comprehensive MRMP benchmark to evaluate trajectory planning algorithms across scenarios with varying robot densities, obstacle complexities, and motion constraints. Experimental results show SMD consistently outperforms classical and other learning-based motion planners, achieving higher success rates and efficiency in complex multi-robot environments.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.03607",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Ludax: A GPU-Accelerated Domain Specific Language for Board Games",
    "description": "arXiv:2506.22609v1 Announce Type: new Abstract: Games have long been used as benchmarks and testing environments for research in artificial intelligence. A key step in supporting this research was the development of game description languages: frameworks that compile domain-specific code into playable and simulatable game environments, allowing researchers to generalize their algorithms and approaches across multiple games without having to manually implement each one. More recently, progress in reinforcement learning (RL) has been largely driven by advances in hardware acceleration. Libraries like JAX allow practitioners to take full advantage of cutting-edge computing hardware, often speeding up training and testing by orders of magnitude. Here, we present a synthesis of these strands of research: a domain-specific language for board games which automatically compiles into hardware-accelerated code. Our framework, Ludax, combines the generality of game description languages with the speed of modern parallel processing hardware and is designed to fit neatly into existing deep learning pipelines. We envision Ludax as a tool to help accelerate games research generally, from RL to cognitive science, by enabling rapid simulation and providing a flexible representation scheme. We present a detailed breakdown of Ludax's description language and technical notes on the compilation process, along with speed benchmarking and a demonstration of training RL agents. The Ludax framework, along with implementations of existing board games, is open-source and freely available.",
    "summary": "arXiv:2506.22609v1 Announce Type: new Abstract: Games have long been used as benchmarks and testing environments for research in artificial intelligence. A key step in supporting this research was the development of game description languages: frameworks that compile domain-specific code into playable and simulatable game environments, allowing researchers to generalize their algorithms and approaches across multiple games without having to manually implement each one. More recently, progress in reinforcement learning (RL) has been largely driven by advances in hardware acceleration. Libraries like JAX allow practitioners to take full advantage of cutting-edge computing hardware, often speeding up training and testing by orders of magnitude. Here, we present a synthesis of these strands of research: a domain-specific language for board games which automatically compiles into hardware-accelerated code. Our framework, Ludax, combines the generality of game description languages with the speed of modern parallel processing hardware and is designed to fit neatly into existing deep learning pipelines. We envision Ludax as a tool to help accelerate games research generally, from RL to cognitive science, by enabling rapid simulation and providing a flexible representation scheme. We present a detailed breakdown of Ludax's description language and technical notes on the compilation process, along with speed benchmarking and a demonstration of training RL agents. The Ludax framework, along with implementations of existing board games, is open-source and freely available.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22609",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Retrieval Augmented Generation with Huggingface Transformers and Ray",
    "description": "",
    "summary": "Retrieval Augmented Generation with Huggingface Transformers and Ray A guest blog post by Amog Kamse...",
    "pubDate": "Wed, 10 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ray-rag",
    "thumbnail": "https://huggingface.co/blog/assets/12_ray_rag/ray_arch_updated.png"
  },
  {
    "title": "Missing-Modality-Aware Graph Neural Network for Cancer Classification",
    "description": "arXiv:2506.22901v1 Announce Type: cross Abstract: A key challenge in learning from multimodal biological data is missing modalities, where all data from some modalities are missing for some patients. Current fusion methods address this by excluding patients with missing modalities, imputing missing modalities, or making predictions directly with partial modalities. However, they often struggle with diverse missing-modality patterns and the exponential growth of the number of such patterns as the number of modalities increases. To address these limitations, we propose MAGNET (Missing-modality-Aware Graph neural NETwork) for direct prediction with partial modalities, which introduces a patient-modality multi-head attention mechanism to fuse lower-dimensional modality embeddings based on their importance and missingness. MAGNET's complexity increases linearly with the number of modalities while adapting to missing-pattern variability. To generate predictions, MAGNET further constructs a patient graph with fused multimodal embeddings as node features and the connectivity determined by the modality missingness, followed by a conventional graph neural network. Experiments on three public multiomics datasets for cancer classification, with real-world instead of artificial missingness, show that MAGNET outperforms the state-of-the-art fusion methods. The data and code are available at https://github.com/SinaTabakhi/MAGNET.",
    "summary": "arXiv:2506.22901v1 Announce Type: cross Abstract: A key challenge in learning from multimodal biological data is missing modalities, where all data from some modalities are missing for some patients. Current fusion methods address this by excluding patients with missing modalities, imputing missing modalities, or making predictions directly with partial modalities. However, they often struggle with diverse missing-modality patterns and the exponential growth of the number of such patterns as the number of modalities increases. To address these limitations, we propose MAGNET (Missing-modality-Aware Graph neural NETwork) for direct prediction with partial modalities, which introduces a patient-modality multi-head attention mechanism to fuse lower-dimensional modality embeddings based on their importance and missingness. MAGNET's complexity increases linearly with the number of modalities while adapting to missing-pattern variability. To generate predictions, MAGNET further constructs a patient graph with fused multimodal embeddings as node features and the connectivity determined by the modality missingness, followed by a conventional graph neural network. Experiments on three public multiomics datasets for cancer classification, with real-world instead of artificial missingness, show that MAGNET outperforms the state-of-the-art fusion methods. The data and code are available at https://github.com/SinaTabakhi/MAGNET.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22901",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI appoints Retired U.S. Army General Paul M. Nakasone to Board of Directors",
    "description": "Nakasone brings cybersecurity experience to growing Board of Directors; will join the Board‚Äôs Safety and Security Committee",
    "summary": "Nakasone brings cybersecurity experience to growing Board of Directors; will join the Board‚Äôs Safety and Security Committee",
    "pubDate": "Thu, 13 Jun 2024 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-appoints-retired-us-army-general",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2020: Applications open",
    "description": "We are now accepting applications for our third class of OpenAI Scholars.",
    "summary": "We are now accepting applications for our third class of OpenAI Scholars.",
    "pubDate": "Fri, 11 Oct 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2020",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reinforcement Fine-Tuning Enables MLLMs Learning Novel Tasks Stably",
    "description": "arXiv:2506.23508v1 Announce Type: cross Abstract: Post-training algorithms such as Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT) are widely used to adapt multimodal large language models to downstream tasks. While effective at task adaptation, their impact on prior knowledge remains unclear. In this paper, we introduce jigsaw puzzles as a novel task absent from existing pretraining corpora and systematically study the behavior of SFT and RFT on an open-source multimodal model, Qwen2.5-VL. Our experiments reveal a sharp trade-off: SFT enables rapid task acquisition but leads to catastrophic forgetting, whereas RFT learns more slowly on novel tasks but maintains prior knowledge. We analyze this phenomenon through the lens of learning dynamics, showing that RFT reinforces correct samples that are naturally aligned with the base model's probability landscape, mitigating interference with prior knowledge. Moreover, supervised training on correct RFT-simulated rollouts allows SFT to preserve knowledge while rapidly learning new tasks. These findings suggest that data distribution, rather than algorithmic differences, plays a central role in forgetting, and highlight RFT's potential for stable continual learning in multimodal large language models.",
    "summary": "arXiv:2506.23508v1 Announce Type: cross Abstract: Post-training algorithms such as Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning (RFT) are widely used to adapt multimodal large language models to downstream tasks. While effective at task adaptation, their impact on prior knowledge remains unclear. In this paper, we introduce jigsaw puzzles as a novel task absent from existing pretraining corpora and systematically study the behavior of SFT and RFT on an open-source multimodal model, Qwen2.5-VL. Our experiments reveal a sharp trade-off: SFT enables rapid task acquisition but leads to catastrophic forgetting, whereas RFT learns more slowly on novel tasks but maintains prior knowledge. We analyze this phenomenon through the lens of learning dynamics, showing that RFT reinforces correct samples that are naturally aligned with the base model's probability landscape, mitigating interference with prior knowledge. Moreover, supervised training on correct RFT-simulated rollouts allows SFT to preserve knowledge while rapidly learning new tasks. These findings suggest that data distribution, rather than algorithmic differences, plays a central role in forgetting, and highlight RFT's potential for stable continual learning in multimodal large language models.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23508",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BenchMake: Turn any scientific data set into a reproducible benchmark",
    "description": "arXiv:2506.23419v1 Announce Type: cross Abstract: Benchmark data sets are a cornerstone of machine learning development and applications, ensuring new methods are robust, reliable and competitive. The relative rarity of benchmark sets in computational science, due to the uniqueness of the problems and the pace of change in the associated domains, makes evaluating new innovations difficult for computational scientists. In this paper a new tool is developed and tested to potentially turn any of the increasing numbers of scientific data sets made openly available into a benchmark accessible to the community. BenchMake uses non-negative matrix factorisation to deterministically identify and isolate challenging edge cases on the convex hull (the smallest convex set that contains all existing data instances) and partitions a required fraction of matched data instances into a testing set that maximises divergence and statistical significance, across tabular, graph, image, signal and textual modalities. BenchMake splits are compared to establish splits and random splits using ten publicly available benchmark sets from different areas of science, with different sizes, shapes, distributions.",
    "summary": "arXiv:2506.23419v1 Announce Type: cross Abstract: Benchmark data sets are a cornerstone of machine learning development and applications, ensuring new methods are robust, reliable and competitive. The relative rarity of benchmark sets in computational science, due to the uniqueness of the problems and the pace of change in the associated domains, makes evaluating new innovations difficult for computational scientists. In this paper a new tool is developed and tested to potentially turn any of the increasing numbers of scientific data sets made openly available into a benchmark accessible to the community. BenchMake uses non-negative matrix factorisation to deterministically identify and isolate challenging edge cases on the convex hull (the smallest convex set that contains all existing data instances) and partitions a required fraction of matched data instances into a testing set that maximises divergence and statistical significance, across tabular, graph, image, signal and textual modalities. BenchMake splits are compared to establish splits and random splits using ten publicly available benchmark sets from different areas of science, with different sizes, shapes, distributions.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23419",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Uncertainty-aware Diffusion and Reinforcement Learning for Joint Plane Localization and Anomaly Diagnosis in 3D Ultrasound",
    "description": "arXiv:2506.23538v1 Announce Type: cross Abstract: Congenital uterine anomalies (CUAs) can lead to infertility, miscarriage, preterm birth, and an increased risk of pregnancy complications. Compared to traditional 2D ultrasound (US), 3D US can reconstruct the coronal plane, providing a clear visualization of the uterine morphology for assessing CUAs accurately. In this paper, we propose an intelligent system for simultaneous automated plane localization and CUA diagnosis. Our highlights are: 1) we develop a denoising diffusion model with local (plane) and global (volume/text) guidance, using an adaptive weighting strategy to optimize attention allocation to different conditions; 2) we introduce a reinforcement learning-based framework with unsupervised rewards to extract the key slice summary from redundant sequences, fully integrating information across multiple planes to reduce learning difficulty; 3) we provide text-driven uncertainty modeling for coarse prediction, and leverage it to adjust the classification probability for overall performance improvement. Extensive experiments on a large 3D uterine US dataset show the efficacy of our method, in terms of plane localization and CUA diagnosis. Code is available at https://github.com/yuhoo0302/CUA-US.",
    "summary": "arXiv:2506.23538v1 Announce Type: cross Abstract: Congenital uterine anomalies (CUAs) can lead to infertility, miscarriage, preterm birth, and an increased risk of pregnancy complications. Compared to traditional 2D ultrasound (US), 3D US can reconstruct the coronal plane, providing a clear visualization of the uterine morphology for assessing CUAs accurately. In this paper, we propose an intelligent system for simultaneous automated plane localization and CUA diagnosis. Our highlights are: 1) we develop a denoising diffusion model with local (plane) and global (volume/text) guidance, using an adaptive weighting strategy to optimize attention allocation to different conditions; 2) we introduce a reinforcement learning-based framework with unsupervised rewards to extract the key slice summary from redundant sequences, fully integrating information across multiple planes to reduce learning difficulty; 3) we provide text-driven uncertainty modeling for coarse prediction, and leverage it to adjust the classification probability for overall performance improvement. Extensive experiments on a large 3D uterine US dataset show the efficacy of our method, in terms of plane localization and CUA diagnosis. Code is available at https://github.com/yuhoo0302/CUA-US.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23538",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Supercharged Customer Service with Machine Learning",
    "description": "",
    "summary": "Supercharged Customer Service with Machine Learning In this blog post, we will simulate a real-world...",
    "pubDate": "Mon, 25 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/supercharge-customer-service-with-machine-learning",
    "thumbnail": "https://huggingface.co/blog/assets/61_supercharged_customer_service_with_nlp/thumbnail.png"
  },
  {
    "title": "Team update",
    "description": "We‚Äôd like to welcome the latest set of team members to OpenAI (and we‚Äôre still hiring!)",
    "summary": "We‚Äôd like to welcome the latest set of team members to OpenAI (and we‚Äôre still hiring!)",
    "pubDate": "Wed, 25 May 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Safety Gym",
    "description": "We‚Äôre releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while¬†training.",
    "summary": "We‚Äôre releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while¬†training.",
    "pubDate": "Thu, 21 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/safety-gym",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "KV Cache from scratch in nanoVLM",
    "description": "",
    "summary": "KV Cache from scratch in nanoVLM TL;DR We have implemented KV Caching from scratch in our nanoVLM re...",
    "pubDate": "Wed, 04 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kv-cache",
    "thumbnail": "https://huggingface.co/blog/assets/kv-cache/thumbnail.png"
  },
  {
    "title": "MGPRL: Distributed Multi-Gaussian Processes for Wi-Fi-based Multi-Robot Relative Localization in Large Indoor Environments",
    "description": "arXiv:2506.23514v1 Announce Type: cross Abstract: Relative localization is a crucial capability for multi-robot systems operating in GPS-denied environments. Existing approaches for multi-robot relative localization often depend on costly or short-range sensors like cameras and LiDARs. Consequently, these approaches face challenges such as high computational overhead (e.g., map merging) and difficulties in disjoint environments. To address this limitation, this paper introduces MGPRL, a novel distributed framework for multi-robot relative localization using convex-hull of multiple Wi-Fi access points (AP). To accomplish this, we employ co-regionalized multi-output Gaussian Processes for efficient Radio Signal Strength Indicator (RSSI) field prediction and perform uncertainty-aware multi-AP localization, which is further coupled with weighted convex hull-based alignment for robust relative pose estimation. Each robot predicts the RSSI field of the environment by an online scan of APs in its environment, which are utilized for position estimation of multiple APs. To perform relative localization, each robot aligns the convex hull of its predicted AP locations with that of the neighbor robots. This approach is well-suited for devices with limited computational resources and operates solely on widely available Wi-Fi RSSI measurements without necessitating any dedicated pre-calibration or offline fingerprinting. We rigorously evaluate the performance of the proposed MGPRL in ROS simulations and demonstrate it with real-world experiments, comparing it against multiple state-of-the-art approaches. The results showcase that MGPRL outperforms existing methods in terms of localization accuracy and computational efficiency. Finally, we open source MGPRL as a ROS package https://github.com/herolab-uga/MGPRL.",
    "summary": "arXiv:2506.23514v1 Announce Type: cross Abstract: Relative localization is a crucial capability for multi-robot systems operating in GPS-denied environments. Existing approaches for multi-robot relative localization often depend on costly or short-range sensors like cameras and LiDARs. Consequently, these approaches face challenges such as high computational overhead (e.g., map merging) and difficulties in disjoint environments. To address this limitation, this paper introduces MGPRL, a novel distributed framework for multi-robot relative localization using convex-hull of multiple Wi-Fi access points (AP). To accomplish this, we employ co-regionalized multi-output Gaussian Processes for efficient Radio Signal Strength Indicator (RSSI) field prediction and perform uncertainty-aware multi-AP localization, which is further coupled with weighted convex hull-based alignment for robust relative pose estimation. Each robot predicts the RSSI field of the environment by an online scan of APs in its environment, which are utilized for position estimation of multiple APs. To perform relative localization, each robot aligns the convex hull of its predicted AP locations with that of the neighbor robots. This approach is well-suited for devices with limited computational resources and operates solely on widely available Wi-Fi RSSI measurements without necessitating any dedicated pre-calibration or offline fingerprinting. We rigorously evaluate the performance of the proposed MGPRL in ROS simulations and demonstrate it with real-world experiments, comparing it against multiple state-of-the-art approaches. The results showcase that MGPRL outperforms existing methods in terms of localization accuracy and computational efficiency. Finally, we open source MGPRL as a ROS package https://github.com/herolab-uga/MGPRL.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23514",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Graphcore and Hugging Face Launch New Lineup of IPU-Ready Transformers",
    "description": "",
    "summary": "Graphcore and Hugging Face Launch New Lineup of IPU-Ready Transformers Graphcore and Hugging Face ha...",
    "pubDate": "Thu, 26 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore-update",
    "thumbnail": "https://huggingface.co/blog/assets/77_graphcore-update/graphcore_update.png"
  },
  {
    "title": "Fast Inference on Large Language Models: BLOOMZ on Habana Gaudi2 Accelerator",
    "description": "",
    "summary": "Fast Inference on Large Language Models: BLOOMZ on Habana Gaudi2 Accelerator This article will show ...",
    "pubDate": "Tue, 28 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana-gaudi-2-bloom",
    "thumbnail": "https://huggingface.co/blog/assets/habana-gaudi-2-bloom/thumbnail.png"
  },
  {
    "title": "Multi Layered Autonomy and AI Ecologies in Robotic Art Installations",
    "description": "arXiv:2506.02606v3 Announce Type: replace-cross Abstract: This paper presents Symbiosis of Agents, is a large-scale installation by Baoyang Chen (baoyangchen.com), that embeds AI-driven robots in an immersive, mirror-lined arena, probing the tension between machine agency and artistic authorship. Drawing on early cybernetics, rule-based conceptual art, and seminal robotic works, it orchestrates fluid exchanges among robotic arms, quadruped machines, their environment, and the public. A three tier faith system pilots the ecology: micro-level adaptive tactics, meso-level narrative drives, and a macro-level prime directive. This hierarchy lets behaviors evolve organically in response to environmental cues and even a viewer's breath, turning spectators into co-authors of the unfolding drama. Framed by a speculative terraforming scenario that recalls the historical exploitation of marginalized labor, the piece asks who bears responsibility in AI-mediated futures. Choreographed motion, AI-generated scripts, reactive lighting, and drifting fog cast the robots as collaborators rather than tools, forging a living, emergent artwork. Exhibited internationally, Symbiosis of Agents shows how cybernetic feedback, robotic experimentation, and conceptual rule-making can converge to redefine agency, authorship, and ethics in contemporary art.",
    "summary": "arXiv:2506.02606v3 Announce Type: replace-cross Abstract: This paper presents Symbiosis of Agents, is a large-scale installation by Baoyang Chen (baoyangchen.com), that embeds AI-driven robots in an immersive, mirror-lined arena, probing the tension between machine agency and artistic authorship. Drawing on early cybernetics, rule-based conceptual art, and seminal robotic works, it orchestrates fluid exchanges among robotic arms, quadruped machines, their environment, and the public. A three tier faith system pilots the ecology: micro-level adaptive tactics, meso-level narrative drives, and a macro-level prime directive. This hierarchy lets behaviors evolve organically in response to environmental cues and even a viewer's breath, turning spectators into co-authors of the unfolding drama. Framed by a speculative terraforming scenario that recalls the historical exploitation of marginalized labor, the piece asks who bears responsibility in AI-mediated futures. Choreographed motion, AI-generated scripts, reactive lighting, and drifting fog cast the robots as collaborators rather than tools, forging a living, emergent artwork. Exhibited internationally, Symbiosis of Agents shows how cybernetic feedback, robotic experimentation, and conceptual rule-making can converge to redefine agency, authorship, and ethics in contemporary art.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.02606",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "My Journey to a serverless transformers pipeline on Google Cloud",
    "description": "",
    "summary": "My Journey to a serverless transformers pipeline on Google Cloud A guest blog post by community memb...",
    "pubDate": "Thu, 18 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-deploy-a-pipeline-to-google-clouds",
    "thumbnail": "https://huggingface.co/blog/assets/14_how_to_deploy_a_pipeline_to_google_clouds/thumbnail.png"
  },
  {
    "title": "Hugging Face's TensorFlow Philosophy",
    "description": "",
    "summary": "Hugging Face's TensorFlow Philosophy Introduction Despite increasing competition from PyTorch and JA...",
    "pubDate": "Fri, 12 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tensorflow-philosophy",
    "thumbnail": "https://huggingface.co/blog/assets/96_tensorflow_philosophy/thumbnail.png"
  },
  {
    "title": "xLSTMAD: A Powerful xLSTM-based Method for Anomaly Detection",
    "description": "arXiv:2506.22837v1 Announce Type: cross Abstract: The recently proposed xLSTM is a powerful model that leverages expressive multiplicative gating and residual connections, providing the temporal capacity needed for long-horizon forecasting and representation learning. This architecture has demonstrated success in time series forecasting, lossless compression, and even large-scale language modeling tasks, where its linear memory footprint and fast inference make it a viable alternative to Transformers. Despite its growing popularity, no prior work has explored xLSTM for anomaly detection. In this work, we fill this gap by proposing xLSTMAD, the first anomaly detection method that integrates a full encoder-decoder xLSTM architecture, purpose-built for multivariate time series data. Our encoder processes input sequences to capture historical context, while the decoder is devised in two separate variants of the method. In the forecasting approach, the decoder iteratively generates forecasted future values xLSTMAD-F, while the reconstruction approach reconstructs the input time series from its encoded counterpart xLSTMAD-R. We investigate the performance of two loss functions: Mean Squared Error (MSE), and Soft Dynamic Time Warping (SoftDTW) to consider local reconstruction fidelity and global sequence alignment, respectively. We evaluate our method on the comprehensive TSB-AD-M benchmark, which spans 17 real-world datasets, using state-of-the-art challenging metrics such as VUS-PR. In our results, xLSTM showcases state-of-the-art accuracy, outperforming 23 popular anomaly detection baselines. Our paper is the first work revealing the powerful modeling capabilities of xLSTM for anomaly detection, paving the way for exciting new developments on this subject. Our code is available at: https://github.com/Nyderx/xlstmad",
    "summary": "arXiv:2506.22837v1 Announce Type: cross Abstract: The recently proposed xLSTM is a powerful model that leverages expressive multiplicative gating and residual connections, providing the temporal capacity needed for long-horizon forecasting and representation learning. This architecture has demonstrated success in time series forecasting, lossless compression, and even large-scale language modeling tasks, where its linear memory footprint and fast inference make it a viable alternative to Transformers. Despite its growing popularity, no prior work has explored xLSTM for anomaly detection. In this work, we fill this gap by proposing xLSTMAD, the first anomaly detection method that integrates a full encoder-decoder xLSTM architecture, purpose-built for multivariate time series data. Our encoder processes input sequences to capture historical context, while the decoder is devised in two separate variants of the method. In the forecasting approach, the decoder iteratively generates forecasted future values xLSTMAD-F, while the reconstruction approach reconstructs the input time series from its encoded counterpart xLSTMAD-R. We investigate the performance of two loss functions: Mean Squared Error (MSE), and Soft Dynamic Time Warping (SoftDTW) to consider local reconstruction fidelity and global sequence alignment, respectively. We evaluate our method on the comprehensive TSB-AD-M benchmark, which spans 17 real-world datasets, using state-of-the-art challenging metrics such as VUS-PR. In our results, xLSTM showcases state-of-the-art accuracy, outperforming 23 popular anomaly detection baselines. Our paper is the first work revealing the powerful modeling capabilities of xLSTM for anomaly detection, paving the way for exciting new developments on this subject. Our code is available at: https://github.com/Nyderx/xlstmad",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22837",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Customizing GPT-3 for your application",
    "description": "Fine-tune with a single¬†command.",
    "summary": "Fine-tune with a single¬†command.",
    "pubDate": "Tue, 14 Dec 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/customizing-gpt-3",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Build AI on premise with Dell Enterprise Hub",
    "description": "",
    "summary": "Build AI on premise with Dell Enterprise Hub Today we announce the Dell Enterprise Hub, a new experi...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dell-enterprise-hub",
    "thumbnail": "https://huggingface.co/blog/assets/dell-enterprise-hub/thumbnail.jpg"
  },
  {
    "title": "Ad-Hoc Human-AI Coordination Challenge",
    "description": "arXiv:2506.21490v2 Announce Type: replace Abstract: Achieving seamless coordination between AI agents and humans is crucial for real-world applications, yet it remains a significant open challenge. Hanabi is a cooperative card game featuring imperfect information, constrained communication, theory of mind requirements, and coordinated action -- making it an ideal testbed for human-AI coordination. However, its use for human-AI interaction has been limited by the challenges of human evaluation. In this work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to overcome the constraints of costly and difficult-to-reproduce human evaluations. We develop textit{human proxy agents} on a large-scale human dataset that serve as robust, cheap, and reproducible human-like evaluation partners in AH2AC2. To encourage the development of data-efficient methods, we open-source a dataset of 3,079 games, deliberately limiting the amount of available human gameplay data. We present baseline results for both two- and three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy agents through a controlled evaluation system rather than releasing them publicly. The code is available at href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.",
    "summary": "arXiv:2506.21490v2 Announce Type: replace Abstract: Achieving seamless coordination between AI agents and humans is crucial for real-world applications, yet it remains a significant open challenge. Hanabi is a cooperative card game featuring imperfect information, constrained communication, theory of mind requirements, and coordinated action -- making it an ideal testbed for human-AI coordination. However, its use for human-AI interaction has been limited by the challenges of human evaluation. In this work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to overcome the constraints of costly and difficult-to-reproduce human evaluations. We develop textit{human proxy agents} on a large-scale human dataset that serve as robust, cheap, and reproducible human-like evaluation partners in AH2AC2. To encourage the development of data-efficient methods, we open-source a dataset of 3,079 games, deliberately limiting the amount of available human gameplay data. We present baseline results for both two- and three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy agents through a controlled evaluation system rather than releasing them publicly. The code is available at href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21490",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing ChatGPT Pro",
    "description": "Broadening usage of frontier AI",
    "summary": "Broadening usage of frontier AI",
    "pubDate": "Thu, 05 Dec 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-pro",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Listener-Rewarded Thinking in VLMs for Image Preferences",
    "description": "arXiv:2506.22832v1 Announce Type: cross Abstract: Training robust and generalizable reward models for human visual preferences is essential for aligning text-to-image and text-to-video generative models with human intent. However, current reward models often fail to generalize, and supervised fine-tuning leads to memorization, demanding complex annotation pipelines. While reinforcement learning (RL), specifically Group Relative Policy Optimization (GRPO), improves generalization, we uncover a key failure mode: a significant drop in reasoning accuracy occurs when a model's reasoning trace contradicts that of an independent, frozen vision-language model ('listener') evaluating the same output. To address this, we introduce a listener-augmented GRPO framework. Here, the listener re-evaluates the reasoner's chain-of-thought to provide a dense, calibrated confidence score, shaping the RL reward signal. This encourages the reasoner not only to answer correctly, but to produce explanations that are persuasive to an independent model. Our listener-shaped reward scheme achieves best accuracy on the ImageReward benchmark (67.4%), significantly improves out-of-distribution (OOD) performance on a large-scale human preference dataset (1.2M votes, up to +6% over naive reasoner), and reduces reasoning contradictions compared to strong GRPO and SFT baselines. These results demonstrate that listener-based rewards provide a scalable, data-efficient path to aligning vision-language models with nuanced human preferences. We will release our reasoning model here: https://huggingface.co/alexgambashidze/qwen2.5vl_image_preference_reasoner.",
    "summary": "arXiv:2506.22832v1 Announce Type: cross Abstract: Training robust and generalizable reward models for human visual preferences is essential for aligning text-to-image and text-to-video generative models with human intent. However, current reward models often fail to generalize, and supervised fine-tuning leads to memorization, demanding complex annotation pipelines. While reinforcement learning (RL), specifically Group Relative Policy Optimization (GRPO), improves generalization, we uncover a key failure mode: a significant drop in reasoning accuracy occurs when a model's reasoning trace contradicts that of an independent, frozen vision-language model ('listener') evaluating the same output. To address this, we introduce a listener-augmented GRPO framework. Here, the listener re-evaluates the reasoner's chain-of-thought to provide a dense, calibrated confidence score, shaping the RL reward signal. This encourages the reasoner not only to answer correctly, but to produce explanations that are persuasive to an independent model. Our listener-shaped reward scheme achieves best accuracy on the ImageReward benchmark (67.4%), significantly improves out-of-distribution (OOD) performance on a large-scale human preference dataset (1.2M votes, up to +6% over naive reasoner), and reduces reasoning contradictions compared to strong GRPO and SFT baselines. These results demonstrate that listener-based rewards provide a scalable, data-efficient path to aligning vision-language models with nuanced human preferences. We will release our reasoning model here: https://huggingface.co/alexgambashidze/qwen2.5vl_image_preference_reasoner.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22832",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games",
    "description": "arXiv:2506.23626v1 Announce Type: new Abstract: Reinforcement Learning (RL) in games has gained significant momentum in recent years, enabling the creation of different agent behaviors that can transform a player's gaming experience. However, deploying RL agents in production environments presents two key challenges: (1) designing an effective reward function typically requires an RL expert, and (2) when a game's content or mechanics are modified, previously tuned reward weights may no longer be optimal. Towards the latter challenge, we propose an automated approach for iteratively fine-tuning an RL agent's reward function weights, based on a user-defined language based behavioral goal. A Language Model (LM) proposes updated weights at each iteration based on this target behavior and a summary of performance statistics from prior training rounds. This closed-loop process allows the LM to self-correct and refine its output over time, producing increasingly aligned behavior without the need for manual reward engineering. We evaluate our approach in a racing task and show that it consistently improves agent performance across iterations. The LM-guided agents show a significant increase in performance from $9%$ to $74%$ success rate in just one iteration. We compare our LM-guided tuning against a human expert's manual weight design in the racing task: by the final iteration, the LM-tuned agent achieved an $80%$ success rate, and completed laps in an average of $855$ time steps, a competitive performance against the expert-tuned agent's peak $94%$ success, and $850$ time steps.",
    "summary": "arXiv:2506.23626v1 Announce Type: new Abstract: Reinforcement Learning (RL) in games has gained significant momentum in recent years, enabling the creation of different agent behaviors that can transform a player's gaming experience. However, deploying RL agents in production environments presents two key challenges: (1) designing an effective reward function typically requires an RL expert, and (2) when a game's content or mechanics are modified, previously tuned reward weights may no longer be optimal. Towards the latter challenge, we propose an automated approach for iteratively fine-tuning an RL agent's reward function weights, based on a user-defined language based behavioral goal. A Language Model (LM) proposes updated weights at each iteration based on this target behavior and a summary of performance statistics from prior training rounds. This closed-loop process allows the LM to self-correct and refine its output over time, producing increasingly aligned behavior without the need for manual reward engineering. We evaluate our approach in a racing task and show that it consistently improves agent performance across iterations. The LM-guided agents show a significant increase in performance from $9%$ to $74%$ success rate in just one iteration. We compare our LM-guided tuning against a human expert's manual weight design in the racing task: by the final iteration, the LM-tuned agent achieved an $80%$ success rate, and completed laps in an average of $855$ time steps, a competitive performance against the expert-tuned agent's peak $94%$ success, and $850$ time steps.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23626",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evolution strategies as a scalable alternative to reinforcement learning",
    "description": "We‚Äôve discovered that evolution strategies (ES), an optimization technique that‚Äôs been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks (e.g. Atari/MuJoCo), while overcoming many of RL‚Äôs inconveniences.",
    "summary": "We‚Äôve discovered that evolution strategies (ES), an optimization technique that‚Äôs been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks (e.g. Atari/MuJoCo), while overcoming many of RL‚Äôs inconveniences.",
    "pubDate": "Fri, 24 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolution-strategies",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and JFrog partner to make AI Security more transparent",
    "description": "",
    "summary": "Hugging Face and JFrog partner to make AI Security more transparent We are pleased to announce our p...",
    "pubDate": "Tue, 04 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/jfrog",
    "thumbnail": "https://huggingface.co/blog/assets/jfrog/thumbnail.png"
  },
  {
    "title": "Introducing DOI: the Digital Object Identifier to Datasets and Models",
    "description": "",
    "summary": "Introducing DOI: the Digital Object Identifier to Datasets and Models Our mission at Hugging Face is...",
    "pubDate": "Fri, 07 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-doi",
    "thumbnail": "https://huggingface.co/blog/assets/107_launching_doi/thumbnail.jpeg"
  },
  {
    "title": "E2EÈü≥Â£∞ÂØæË©±API„ÉªÊßãÁØâ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÊúÄÊñ∞ÂãïÂêë„ÅÆË™øÊüª„Å®Ëá™ÂæãÂûãÈü≥Â£∞ÂØæË©±„Ç∑„Çπ„ÉÜ„É†„ÅÆÂ±ïÊúõ",
    "description": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ ËøëÂπ¥„ÄÅÈü≥Â£∞ÂØæË©±„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆÈÄ≤Âåñ„ÅåÁõÆË¶ö„Åæ„Åó„Åè„ÄÅÈ°ßÂÆ¢ÂØæÂøú„ÅÆËá™ÂãïÂåñ„ÇÑÊ•≠ÂãôÂäπÁéáÂåñ„Å∏„ÅÆÊúüÂæÖ„ÅåÈ´ò„Åæ„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇÂºäÁ§æ„ÅÆAI Messenger Voicebot„ÇÇ‰æãÂ§ñ„Åß„ÅØ„Å™„Åè„ÄÅÊúÄÂÖàÁ´Ø [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5852' rel='nofollow'>E2EÈü≥Â£∞ÂØæË©±API„ÉªÊßãÁØâ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÊúÄÊñ∞ÂãïÂêë„ÅÆË™øÊüª„Å®Ëá™ÂæãÂûãÈü≥Â£∞ÂØæË©±„Ç∑„Çπ„ÉÜ„É†„ÅÆÂ±ïÊúõ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ ËøëÂπ¥„ÄÅÈü≥Â£∞ÂØæË©±„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆÈÄ≤Âåñ„ÅåÁõÆË¶ö„Åæ„Åó„Åè„ÄÅÈ°ßÂÆ¢ÂØæÂøú„ÅÆËá™ÂãïÂåñ„ÇÑÊ•≠ÂãôÂäπÁéáÂåñ„Å∏„ÅÆÊúüÂæÖ„ÅåÈ´ò„Åæ„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇÂºäÁ§æ„ÅÆAI Messenger Voicebot„ÇÇ‰æãÂ§ñ„Åß„ÅØ„Å™„Åè„ÄÅÊúÄÂÖàÁ´Ø [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5852' rel='nofollow'>E2EÈü≥Â£∞ÂØæË©±API„ÉªÊßãÁØâ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÊúÄÊñ∞ÂãïÂêë„ÅÆË™øÊüª„Å®Ëá™ÂæãÂûãÈü≥Â£∞ÂØæË©±„Ç∑„Çπ„ÉÜ„É†„ÅÆÂ±ïÊúõ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Fri, 30 May 2025 01:38:01 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5852",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/icon.png"
  },
  {
    "title": "WebGPT: Improving the factual accuracy of language models through web browsing",
    "description": "We‚Äôve fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.",
    "summary": "We‚Äôve fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.",
    "pubDate": "Thu, 16 Dec 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/webgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Leveraging Hugging Face for complex generative AI use cases",
    "description": "",
    "summary": "Leveraging Hugging Face for complex generative AI use casess Published July 1, 2023 Update on GitHub...",
    "pubDate": "Sat, 01 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/writer-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/writer.png"
  },
  {
    "title": "ÁÑ°Êñô„Åß‰Ωø„Åà„Çã„Ç™„Éº„Éó„É≥„ÇΩ„Éº„ÇπAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÄåGemini CLI„Äç„ÄÄGoogle„ÅåÁô∫Ë°®",
    "description": "Google„ÅØ„ÄÅÂêåÁ§æ„ÅÆLLM„ÄåGemini„Äç„Çí„Çø„Éº„Éü„Éä„É´„ÅßÂà©Áî®„Åß„Åç„Çã„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„ÅÆAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÄåGemini CLI„Äç„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ",
    "summary": "Google„ÅØ„ÄÅÂêåÁ§æ„ÅÆLLM„ÄåGemini„Äç„Çí„Çø„Éº„Éü„Éä„É´„ÅßÂà©Áî®„Åß„Åç„Çã„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„ÅÆAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÄåGemini CLI„Äç„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://atmarkit.itmedia.co.jp/ait/articles/2506/30/news038.html",
    "thumbnail": "https://image.itmedia.co.jp/ait/articles/2506/30/cover_news038.jpg"
  },
  {
    "title": "Introducing Stargate UAE",
    "description": "We‚Äôre launching Stargate UAE ‚Äì the first international deployment of Stargate, OpenAI‚Äôs AI infrastructure platform.",
    "summary": "We‚Äôre launching Stargate UAE ‚Äì the first international deployment of Stargate, OpenAI‚Äôs AI infrastructure platform.",
    "pubDate": "Thu, 22 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-stargate-uae",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DABStep: Data Agent Benchmark for Multi-step Reasoning",
    "description": "",
    "summary": "DABStep: Data Agent Benchmark for Multi-step Reasoning Language models are becoming increasingly cap...",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dabstep",
    "thumbnail": "https://huggingface.co/blog/assets/dabstep/thumbnail.png"
  },
  {
    "title": "Gradio-Lite: Serverless Gradio Running Entirely in Your Browser",
    "description": "",
    "summary": "Gradio-Lite: Serverless Gradio Running Entirely in Your Browser Gradio is a popular Python library f...",
    "pubDate": "Thu, 19 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-lite",
    "thumbnail": "https://huggingface.co/blog/assets/167_gradio_lite/thumbnail.png"
  },
  {
    "title": "Introducing Three New Serverless Inference Providers: Hyperbolic, Nebius AI Studio, and Novita üî•",
    "description": "",
    "summary": "Introducing Three New Serverless Inference Providers: Hyperbolic, Nebius AI Studio, and Novita üî• We‚Äô...",
    "pubDate": "Tue, 18 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-nebius-novita-hyperbolic",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/second-batch-thumbnail.webp"
  },
  {
    "title": "AI stirs up the recipe for concrete in MIT study",
    "description": "With demand for cement alternatives rising, an MIT team uses machine learning to hunt for new ingredients across the scientific literature.",
    "summary": "With demand for cement alternatives rising, an MIT team uses machine learning to hunt for new ingredients across the scientific literature.",
    "pubDate": "Mon, 02 Jun 2025 15:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-stirs-recipe-for-concrete-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Soroush-Mahjoubi.jpg"
  },
  {
    "title": "Introducing the Synthetic Data Generator - Build Datasets with Natural Language",
    "description": "",
    "summary": "Introducing the Synthetic Data Generator - Build Datasets with Natural Language Introducing the Synt...",
    "pubDate": "Mon, 16 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthetic-data-generator",
    "thumbnail": "https://huggingface.co/blog/assets/synthetic-data-generator/_thumbnail.png"
  },
  {
    "title": "Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning",
    "description": "arXiv:2506.23944v1 Announce Type: cross Abstract: Imitation learning models for robotic tasks typically rely on multi-modal inputs, such as RGB images, language, and proprioceptive states. While proprioception is intuitively important for decision-making and obstacle avoidance, simply incorporating all proprioceptive states leads to a surprising degradation in imitation learning performance. In this work, we identify the underlying issue as the proprioception shift problem, where the distributions of proprioceptive states diverge significantly between training and deployment. To address this challenge, we propose a domain adaptation framework that bridges the gap by utilizing rollout data collected during deployment. Using Wasserstein distance, we quantify the discrepancy between expert and rollout proprioceptive states and minimize this gap by adding noise to both sets of states, proportional to the Wasserstein distance. This strategy enhances robustness against proprioception shifts by aligning the training and deployment distributions. Experiments on robotic manipulation tasks demonstrate the efficacy of our method, enabling the imitation policy to leverage proprioception while mitigating its adverse effects. Our approach outperforms the naive solution which discards proprioception, and other baselines designed to address distributional shifts.",
    "summary": "arXiv:2506.23944v1 Announce Type: cross Abstract: Imitation learning models for robotic tasks typically rely on multi-modal inputs, such as RGB images, language, and proprioceptive states. While proprioception is intuitively important for decision-making and obstacle avoidance, simply incorporating all proprioceptive states leads to a surprising degradation in imitation learning performance. In this work, we identify the underlying issue as the proprioception shift problem, where the distributions of proprioceptive states diverge significantly between training and deployment. To address this challenge, we propose a domain adaptation framework that bridges the gap by utilizing rollout data collected during deployment. Using Wasserstein distance, we quantify the discrepancy between expert and rollout proprioceptive states and minimize this gap by adding noise to both sets of states, proportional to the Wasserstein distance. This strategy enhances robustness against proprioception shifts by aligning the training and deployment distributions. Experiments on robotic manipulation tasks demonstrate the efficacy of our method, enabling the imitation policy to leverage proprioception while mitigating its adverse effects. Our approach outperforms the naive solution which discards proprioception, and other baselines designed to address distributional shifts.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23944",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„ÄåAI SHIFT SUMMIT 2025„Äç„É¨„Éù„Éº„Éà‚îÄ‰ºÅÊ•≠„ÅÆÊúÄÂâçÁ∑ö„Å´Ë¶ã„ÇãAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÆüË£Ö„ÅÆ‰ªä",
    "description": "<p>2025Âπ¥„ÅØ„ÄåAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÖÉÂπ¥„Äç„Å®„ÇÇÂëº„Å∞„Çå„ÄÅËá™ÂæãÂûãAI„ÅÆÁ§æ‰ºöÂÆüË£Ö„Å´Ê≥®ÁõÆ„ÅåÈõÜ„Åæ„ÇãÂπ¥„Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„ÅÜ„Åó„ÅüÊΩÆÊµÅ„ÅÆ‰∏≠„ÄÅÊ†™Âºè‰ºöÁ§æAI Shift‰∏ªÂÇ¨„ÅßÈñãÂÇ¨„Åï„Çå„Åü„ÄåAI SHIFT SUMMIT 2025„Äç„Åß„ÅØ„ÄÅMicros [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ai-shift-summit-2025-ai-agent/'>„ÄåAI SHIFT SUMMIT 2025„Äç„É¨„Éù„Éº„Éà‚îÄ‰ºÅÊ•≠„ÅÆÊúÄÂâçÁ∑ö„Å´Ë¶ã„ÇãAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÆüË£Ö„ÅÆ‰ªä</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>2025Âπ¥„ÅØ„ÄåAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÖÉÂπ¥„Äç„Å®„ÇÇÂëº„Å∞„Çå„ÄÅËá™ÂæãÂûãAI„ÅÆÁ§æ‰ºöÂÆüË£Ö„Å´Ê≥®ÁõÆ„ÅåÈõÜ„Åæ„ÇãÂπ¥„Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„ÅÜ„Åó„ÅüÊΩÆÊµÅ„ÅÆ‰∏≠„ÄÅÊ†™Âºè‰ºöÁ§æAI Shift‰∏ªÂÇ¨„ÅßÈñãÂÇ¨„Åï„Çå„Åü„ÄåAI SHIFT SUMMIT 2025„Äç„Åß„ÅØ„ÄÅMicros [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ai-shift-summit-2025-ai-agent/'>„ÄåAI SHIFT SUMMIT 2025„Äç„É¨„Éù„Éº„Éà‚îÄ‰ºÅÊ•≠„ÅÆÊúÄÂâçÁ∑ö„Å´Ë¶ã„ÇãAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂÆüË£Ö„ÅÆ‰ªä</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Tue, 01 Jul 2025 01:24:49 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/ai-shift-summit-2025-ai-agent/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/main-1.png"
  },
  {
    "title": "Competitive self-play",
    "description": "We‚Äôve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind. Self-play ensures that the environment is always the right difficulty for an AI to improve. Taken alongside our Dota 2 self-play results, we have increasing confidence that self-play will be a core part of powerful AI systems in the future.",
    "summary": "We‚Äôve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind. Self-play ensures that the environment is always the right difficulty for an AI to improve. Taken alongside our Dota 2 self-play results, we have increasing confidence that self-play will be a core part of powerful AI systems in the future.",
    "pubDate": "Wed, 11 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/competitive-self-play",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion",
    "description": "arXiv:2506.15981v2 Announce Type: replace-cross Abstract: The rapid advancement of AI-based music generation tools is revolutionizing the music industry but also posing challenges to artists, copyright holders, and providers alike. This necessitates reliable methods for detecting such AI-generated content. However, existing detectors, relying on either audio or lyrics, face key practical limitations: audio-based detectors fail to generalize to new or unseen generators and are vulnerable to audio perturbations; lyrics-based methods require cleanly formatted and accurate lyrics, unavailable in practice. To overcome these limitations, we propose a novel, practically grounded approach: a multimodal, modular late-fusion pipeline that combines automatically transcribed sung lyrics and speech features capturing lyrics-related information within the audio. By relying on lyrical aspects directly from audio, our method enhances robustness, mitigates susceptibility to low-level artifacts, and enables practical applicability. Experiments show that our method, DE-detect, outperforms existing lyrics-based detectors while also being more robust to audio perturbations. Thus, it offers an effective, robust solution for detecting AI-generated music in real-world scenarios. Our code is available at https://github.com/deezer/robust-AI-lyrics-detection.",
    "summary": "arXiv:2506.15981v2 Announce Type: replace-cross Abstract: The rapid advancement of AI-based music generation tools is revolutionizing the music industry but also posing challenges to artists, copyright holders, and providers alike. This necessitates reliable methods for detecting such AI-generated content. However, existing detectors, relying on either audio or lyrics, face key practical limitations: audio-based detectors fail to generalize to new or unseen generators and are vulnerable to audio perturbations; lyrics-based methods require cleanly formatted and accurate lyrics, unavailable in practice. To overcome these limitations, we propose a novel, practically grounded approach: a multimodal, modular late-fusion pipeline that combines automatically transcribed sung lyrics and speech features capturing lyrics-related information within the audio. By relying on lyrical aspects directly from audio, our method enhances robustness, mitigates susceptibility to low-level artifacts, and enables practical applicability. Experiments show that our method, DE-detect, outperforms existing lyrics-based detectors while also being more robust to audio perturbations. Thus, it offers an effective, robust solution for detecting AI-generated music in real-world scenarios. Our code is available at https://github.com/deezer/robust-AI-lyrics-detection.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15981",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Creating a Coding Assistant with StarCoder",
    "description": "",
    "summary": "Creating a Coding Assistant with StarCoder If you‚Äôre a software developer, chances are that you‚Äôve u...",
    "pubDate": "Tue, 09 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starchat-alpha",
    "thumbnail": "https://huggingface.co/blog/assets/starchat_alpha/thumbnail.png"
  },
  {
    "title": "Millions of new materials discovered with deep learning",
    "description": "We share the discovery of 2.2 million new crystals  ‚Äì  equivalent to nearly 800 years‚Äô worth of knowledge. We introduce Graph Networks for Materials Exploration (GNoME), our new deep learning tool that dramatically increases the speed and efficiency of discovery by predicting the stability of new materials.",
    "summary": "We share the discovery of 2.2 million new crystals  ‚Äì  equivalent to nearly 800 years‚Äô worth of knowledge. We introduce Graph Networks for Materials Exploration (GNoME), our new deep learning tool that dramatically increases the speed and efficiency of discovery by predicting the stability of new materials.",
    "pubDate": "Wed, 29 Nov 2023 16:04:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/",
    "thumbnail": "https://lh3.googleusercontent.com/mq3mFiVHSVuszhJMt-Nz4jckN5qy3cAckEIdNYDPhy8UHjxk4VkGFriqo8sA76teioNQ2fC3qgMH7FJfPc0L5JJPppXiZzHP7Rl3UodlU4IC4TWw=w1200-h630-n-nu"
  },
  {
    "title": "Scaling AI-based Data Processing with Hugging Face + Dask",
    "description": "",
    "summary": "Scaling AI-Based Data Processing with Hugging Face + Dask The Hugging Face platform has many dataset...",
    "pubDate": "Wed, 09 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dask-scaling",
    "thumbnail": "https://huggingface.co/blog/assets/dask-scaling/thumbnail.png"
  },
  {
    "title": "Accelerate 1.0.0",
    "description": "",
    "summary": "Accelerate 1.0.0 What is Accelerate today? 3.5 years ago, Accelerate was a simple framework aimed at...",
    "pubDate": "Fri, 13 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-v1",
    "thumbnail": "https://huggingface.co/blog/assets/186_accelerate_v1/accelerate_v1_thumbnail.png"
  },
  {
    "title": "Aria-MIDI: A Dataset of Piano MIDI Files for Symbolic Music Modeling",
    "description": "arXiv:2504.15071v1 Announce Type: cross Abstract: We introduce an extensive new dataset of MIDI files, created by transcribing audio recordings of piano performances into their constituent notes. The data pipeline we use is multi-stage, employing a language model to autonomously crawl and score audio recordings from the internet based on their metadata, followed by a stage of pruning and segmentation using an audio classifier. The resulting dataset contains over one million distinct MIDI files, comprising roughly 100,000 hours of transcribed audio. We provide an in-depth analysis of our techniques, offering statistical insights, and investigate the content by extracting metadata tags, which we also provide. Dataset available at https://github.com/loubbrad/aria-midi.",
    "summary": "arXiv:2504.15071v1 Announce Type: cross Abstract: We introduce an extensive new dataset of MIDI files, created by transcribing audio recordings of piano performances into their constituent notes. The data pipeline we use is multi-stage, employing a language model to autonomously crawl and score audio recordings from the internet based on their metadata, followed by a stage of pruning and segmentation using an audio classifier. The resulting dataset contains over one million distinct MIDI files, comprising roughly 100,000 hours of transcribed audio. We provide an in-depth analysis of our techniques, offering statistical insights, and investigate the content by extracting metadata tags, which we also provide. Dataset available at https://github.com/loubbrad/aria-midi.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.15071",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Vision Transformers for Multi-Variable Climate Downscaling: Emulating Regional Climate Models with a Shared Encoder and Multi-Decoder Architecture",
    "description": "arXiv:2506.22447v1 Announce Type: cross Abstract: Global Climate Models (GCMs) are critical for simulating large-scale climate dynamics, but their coarse spatial resolution limits their applicability in regional studies. Regional Climate Models (RCMs) refine this through dynamic downscaling, albeit at considerable computational cost and with limited flexibility. While deep learning has emerged as an efficient data-driven alternative, most existing studies have focused on single-variable models that downscale one variable at a time. This approach can lead to limited contextual awareness, redundant computation, and lack of cross-variable interaction. Our study addresses these limitations by proposing a multi-task, multi-variable Vision Transformer (ViT) architecture with a shared encoder and variable-specific decoders (1EMD). The proposed architecture jointly predicts three key climate variables: surface temperature (tas), wind speed (sfcWind), and 500 hPa geopotential height (zg500), directly from GCM-resolution inputs, emulating RCM-scale downscaling over Europe. We show that our multi-variable approach achieves positive cross-variable knowledge transfer and consistently outperforms single-variable baselines trained under identical conditions, while also improving computational efficiency. These results demonstrate the effectiveness of multi-variable modeling for high-resolution climate downscaling.",
    "summary": "arXiv:2506.22447v1 Announce Type: cross Abstract: Global Climate Models (GCMs) are critical for simulating large-scale climate dynamics, but their coarse spatial resolution limits their applicability in regional studies. Regional Climate Models (RCMs) refine this through dynamic downscaling, albeit at considerable computational cost and with limited flexibility. While deep learning has emerged as an efficient data-driven alternative, most existing studies have focused on single-variable models that downscale one variable at a time. This approach can lead to limited contextual awareness, redundant computation, and lack of cross-variable interaction. Our study addresses these limitations by proposing a multi-task, multi-variable Vision Transformer (ViT) architecture with a shared encoder and variable-specific decoders (1EMD). The proposed architecture jointly predicts three key climate variables: surface temperature (tas), wind speed (sfcWind), and 500 hPa geopotential height (zg500), directly from GCM-resolution inputs, emulating RCM-scale downscaling over Europe. We show that our multi-variable approach achieves positive cross-variable knowledge transfer and consistently outperforms single-variable baselines trained under identical conditions, while also improving computational efficiency. These results demonstrate the effectiveness of multi-variable modeling for high-resolution climate downscaling.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22447",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Can 'consciousness' be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis",
    "description": "arXiv:2506.22516v1 Announce Type: cross Abstract: Integrated Information Theory (IIT) provides a quantitative framework for explaining consciousness phenomenon, positing that conscious systems comprise elements integrated through causal properties. We apply IIT 3.0 and 4.0 -- the latest iterations of this framework -- to sequences of Large Language Model (LLM) representations, analyzing data derived from existing Theory of Mind (ToM) test results. Our study systematically investigates whether the differences of ToM test performances, when presented in the LLM representations, can be revealed by IIT estimates, i.e., $Phi^{max}$ (IIT 3.0), $Phi$ (IIT 4.0), Conceptual Information (IIT 3.0), and $Phi$-structure (IIT 4.0). Furthermore, we compare these metrics with the Span Representations independent of any estimate for consciousness. This additional effort aims to differentiate between potential 'consciousness' phenomena and inherent separations within LLM representational space. We conduct comprehensive experiments examining variations across LLM transformer layers and linguistic spans from stimuli. Our results suggest that sequences of contemporary Transformer-based LLM representations lack statistically significant indicators of observed 'consciousness' phenomena but exhibit intriguing patterns under $textit{spatio}$-permutational analyses. The Appendix and code are available as Supplementary Materials at: https://doi.org/10.1016/j.nlp.2025.100163.",
    "summary": "arXiv:2506.22516v1 Announce Type: cross Abstract: Integrated Information Theory (IIT) provides a quantitative framework for explaining consciousness phenomenon, positing that conscious systems comprise elements integrated through causal properties. We apply IIT 3.0 and 4.0 -- the latest iterations of this framework -- to sequences of Large Language Model (LLM) representations, analyzing data derived from existing Theory of Mind (ToM) test results. Our study systematically investigates whether the differences of ToM test performances, when presented in the LLM representations, can be revealed by IIT estimates, i.e., $Phi^{max}$ (IIT 3.0), $Phi$ (IIT 4.0), Conceptual Information (IIT 3.0), and $Phi$-structure (IIT 4.0). Furthermore, we compare these metrics with the Span Representations independent of any estimate for consciousness. This additional effort aims to differentiate between potential 'consciousness' phenomena and inherent separations within LLM representational space. We conduct comprehensive experiments examining variations across LLM transformer layers and linguistic spans from stimuli. Our results suggest that sequences of contemporary Transformer-based LLM representations lack statistically significant indicators of observed 'consciousness' phenomena but exhibit intriguing patterns under $textit{spatio}$-permutational analyses. The Appendix and code are available as Supplementary Materials at: https://doi.org/10.1016/j.nlp.2025.100163.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22516",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BEST-Route: Adaptive LLM Routing with Test-Time Optimal Compute",
    "description": "arXiv:2506.22716v1 Announce Type: cross Abstract: Large language models (LLMs) are powerful tools but are often expensive to deploy at scale. LLM query routing mitigates this by dynamically assigning queries to models of varying cost and quality to obtain a desired trade-off. Prior query routing approaches generate only one response from the selected model and a single response from a small (inexpensive) model was often not good enough to beat a response from a large (expensive) model due to which they end up overusing the large model and missing out on potential cost savings. However, it is well known that for small models, generating multiple responses and selecting the best can enhance quality while remaining cheaper than a single large-model response. We leverage this idea to propose BEST-Route, a novel routing framework that chooses a model and the number of responses to sample from it based on query difficulty and the quality thresholds. Experiments on real-world datasets demonstrate that our method reduces costs by up to 60% with less than 1% performance drop.",
    "summary": "arXiv:2506.22716v1 Announce Type: cross Abstract: Large language models (LLMs) are powerful tools but are often expensive to deploy at scale. LLM query routing mitigates this by dynamically assigning queries to models of varying cost and quality to obtain a desired trade-off. Prior query routing approaches generate only one response from the selected model and a single response from a small (inexpensive) model was often not good enough to beat a response from a large (expensive) model due to which they end up overusing the large model and missing out on potential cost savings. However, it is well known that for small models, generating multiple responses and selecting the best can enhance quality while remaining cheaper than a single large-model response. We leverage this idea to propose BEST-Route, a novel routing framework that chooses a model and the number of responses to sample from it based on query difficulty and the quality thresholds. Experiments on real-world datasets demonstrate that our method reduces costs by up to 60% with less than 1% performance drop.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22716",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "WWDC 24: Running Mistral 7B with Core ML",
    "description": "",
    "summary": "WWDC 24: Running Mistral 7B with Core ML WWDC‚Äô 24 is the moment Apple officially unveiled Apple Inte...",
    "pubDate": "Mon, 22 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mistral-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/mistral-coreml/thumbnail.png"
  },
  {
    "title": "Director of Machine Learning Insights [Series]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 1] Few seats at the Machine Learning table span both tec...",
    "pubDate": "Wed, 27 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights",
    "thumbnail": "https://huggingface.co/blog/assets/61_ml_director_insights/thumbnail.png"
  },
  {
    "title": "Improving Prompt Consistency with Structured Generations",
    "description": "",
    "summary": "Improving Prompt Consistency with Structured Generations Recently, the Leaderboards and Evals resear...",
    "pubDate": "Tue, 30 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/evaluation-structured-outputs",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "AI Policy @ü§ó: Comments on U.S. National AI Research Resource Interim Report",
    "description": "",
    "summary": "AI Policy @ü§ó: Comments on U.S. National AI Research Resource Interim Report In late June 2022, Huggi...",
    "pubDate": "Mon, 01 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/us-national-ai-research-resource",
    "thumbnail": "https://huggingface.co/blog/assets/92_us_national_ai_research_resource/nairr_thumbnail.png"
  },
  {
    "title": "XY-Tokenizer: Mitigating the Semantic-Acoustic Conflict in Low-Bitrate Speech Codecs",
    "description": "arXiv:2506.23325v1 Announce Type: cross Abstract: Speech codecs serve as bridges between speech signals and large language models. An ideal codec for speech language models should not only preserve acoustic information but also capture rich semantic information. However, existing speech codecs struggle to balance high-quality audio reconstruction with ease of modeling by language models. In this study, we analyze the limitations of previous codecs in balancing semantic richness and acoustic fidelity. We propose XY-Tokenizer, a novel codec that mitigates the conflict between semantic and acoustic capabilities through multi-stage, multi-task learning. Experimental results demonstrate that XY-Tokenizer achieves performance in both semantic and acoustic tasks comparable to that of state-of-the-art codecs operating at similar bitrates, even though those existing codecs typically excel in only one aspect. Specifically, XY-Tokenizer achieves strong text alignment, surpassing distillation-based semantic modeling methods such as SpeechTokenizer and Mimi, while maintaining a speaker similarity score of 0.83 between reconstructed and original audio. The reconstruction performance of XY-Tokenizer is comparable to that of BigCodec, the current state-of-the-art among acoustic-only codecs, which achieves a speaker similarity score of 0.84 at a similar bitrate. Code and models are available at https://github.com/gyt1145028706/XY-Tokenizer.",
    "summary": "arXiv:2506.23325v1 Announce Type: cross Abstract: Speech codecs serve as bridges between speech signals and large language models. An ideal codec for speech language models should not only preserve acoustic information but also capture rich semantic information. However, existing speech codecs struggle to balance high-quality audio reconstruction with ease of modeling by language models. In this study, we analyze the limitations of previous codecs in balancing semantic richness and acoustic fidelity. We propose XY-Tokenizer, a novel codec that mitigates the conflict between semantic and acoustic capabilities through multi-stage, multi-task learning. Experimental results demonstrate that XY-Tokenizer achieves performance in both semantic and acoustic tasks comparable to that of state-of-the-art codecs operating at similar bitrates, even though those existing codecs typically excel in only one aspect. Specifically, XY-Tokenizer achieves strong text alignment, surpassing distillation-based semantic modeling methods such as SpeechTokenizer and Mimi, while maintaining a speaker similarity score of 0.83 between reconstructed and original audio. The reconstruction performance of XY-Tokenizer is comparable to that of BigCodec, the current state-of-the-art among acoustic-only codecs, which achieves a speaker similarity score of 0.84 at a similar bitrate. Code and models are available at https://github.com/gyt1145028706/XY-Tokenizer.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23325",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Offline Reinforcement Learning for Mobility Robustness Optimization",
    "description": "arXiv:2506.22793v1 Announce Type: cross Abstract: In this work we revisit the Mobility Robustness Optimisation (MRO) algorithm and study the possibility of learning the optimal Cell Individual Offset tuning using offline Reinforcement Learning. Such methods make use of collected offline datasets to learn the optimal policy, without further exploration. We adapt and apply a sequence-based method called Decision Transformers as well as a value-based method called Conservative Q-Learning to learn the optimal policy for the same target reward as the vanilla rule-based MRO. The same input features related to failures, ping-pongs, and other handover issues are used. Evaluation for realistic New Radio networks with 3500 MHz carrier frequency on a traffic mix including diverse user service types and a specific tunable cell-pair shows that offline-RL methods outperform rule-based MRO, offering up to 7% improvement. Furthermore, offline-RL can be trained for diverse objective functions using the same available dataset, thus offering operational flexibility compared to rule-based methods.",
    "summary": "arXiv:2506.22793v1 Announce Type: cross Abstract: In this work we revisit the Mobility Robustness Optimisation (MRO) algorithm and study the possibility of learning the optimal Cell Individual Offset tuning using offline Reinforcement Learning. Such methods make use of collected offline datasets to learn the optimal policy, without further exploration. We adapt and apply a sequence-based method called Decision Transformers as well as a value-based method called Conservative Q-Learning to learn the optimal policy for the same target reward as the vanilla rule-based MRO. The same input features related to failures, ping-pongs, and other handover issues are used. Evaluation for realistic New Radio networks with 3500 MHz carrier frequency on a traffic mix including diverse user service types and a specific tunable cell-pair shows that offline-RL methods outperform rule-based MRO, offering up to 7% improvement. Furthermore, offline-RL can be trained for diverse objective functions using the same available dataset, thus offering operational flexibility compared to rule-based methods.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22793",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Language models are few-shot learners",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 28 May 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-models-are-few-shot-learners",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing improvements to the fine-tuning API and expanding our custom models program",
    "description": "We‚Äôre adding new features to help developers have more control over fine-tuning and announcing new ways to build custom models with OpenAI.",
    "summary": "We‚Äôre adding new features to help developers have more control over fine-tuning and announcing new ways to build custom models with OpenAI.",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and IBM partner on watsonx.ai, the next-generation enterprise studio for AI builders",
    "description": "",
    "summary": "Hugging Face and IBM partner on watsonx.ai, the next-generation enterprise studio for AI builders Al...",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-ibm",
    "thumbnail": "https://huggingface.co/blog/assets/144_ibm/01.png"
  },
  {
    "title": "Open Preference Dataset for Text-to-Image Generation by the ü§ó Community",
    "description": "",
    "summary": "Open Preference Dataset for Text-to-Image Generation by the ü§ó Community The Data is Better Together ...",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-preferences",
    "thumbnail": "https://huggingface.co/blog/assets/image_preferences/thumbnail.png"
  },
  {
    "title": "Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments",
    "description": "arXiv:2506.23706v1 Announce Type: new Abstract: Benchmarks are important measures to evaluate safety and compliance of AI models at scale. However, they typically do not offer verifiable results and lack confidentiality for model IP and benchmark datasets. We propose Attestable Audits, which run inside Trusted Execution Environments and enable users to verify interaction with a compliant AI model. Our work protects sensitive data even when model provider and auditor do not trust each other. This addresses verification challenges raised in recent AI governance frameworks. We build a prototype demonstrating feasibility on typical audit benchmarks against Llama-3.1.",
    "summary": "arXiv:2506.23706v1 Announce Type: new Abstract: Benchmarks are important measures to evaluate safety and compliance of AI models at scale. However, they typically do not offer verifiable results and lack confidentiality for model IP and benchmark datasets. We propose Attestable Audits, which run inside Trusted Execution Environments and enable users to verify interaction with a compliant AI model. Our work protects sensitive data even when model provider and auditor do not trust each other. This addresses verification challenges raised in recent AI governance frameworks. We build a prototype demonstrating feasibility on typical audit benchmarks against Llama-3.1.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23706",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemini breaks new ground: a faster model, longer context and AI agents",
    "description": "We‚Äôre introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants.",
    "summary": "We‚Äôre introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants.",
    "pubDate": "Tue, 14 May 2024 17:58:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-breaks-new-ground-a-faster-model-longer-context-and-ai-agents/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_Blog_Social_Share.width-1300.png"
  },
  {
    "title": "Google Cloud: Driving digital transformation",
    "description": "Google Cloud empowers organizations to digitally transform themselves into smarter businesses. It offers cloud computing, data analytics, and the latest artificial intelligence (AI) and machine learning tools.",
    "summary": "Google Cloud empowers organizations to digitally transform themselves into smarter businesses. It offers cloud computing, data analytics, and the latest artificial intelligence (AI) and machine learning tools.",
    "pubDate": "Wed, 14 Jun 2023 14:51:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-cloud-driving-digital-transformation/",
    "thumbnail": "https://lh3.googleusercontent.com/xIps-6-tV3GGWQjVrHYTkLGnXAdZwmjG6jOAgECP5aynUXKeAfUhWv7fFfjPaV8Jmn3B3IabKBeDzBtB491hJAozuAhdQ-TUtZ5dzy9dmE1zWC-J=w1200-h630-n-nu"
  },
  {
    "title": "Weak-to-strong generalization",
    "description": "We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning to control strong models with weak supervisors?",
    "summary": "We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning to control strong models with weak supervisors?",
    "pubDate": "Thu, 14 Dec 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/weak-to-strong-generalization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "description": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "summary": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "pubDate": "Tue, 22 Oct 2024 06:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lenfest-institute",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reptile: A scalable meta-learning algorithm",
    "description": "We‚Äôve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task, performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters learned on that task. Reptile is the application of the Shortest Descent algorithm to the meta-learning setting, and is mathematically similar to first-order MAML (which is a version of the well-known MAML algorithm) that only needs black-box access to an optimizer such as SGD or Adam, with similar computational efficiency and performance.",
    "summary": "We‚Äôve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task, performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters learned on that task. Reptile is the application of the Shortest Descent algorithm to the meta-learning setting, and is mathematically similar to first-order MAML (which is a version of the well-known MAML algorithm) that only needs black-box access to an optimizer such as SGD or Adam, with similar computational efficiency and performance.",
    "pubDate": "Wed, 07 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reptile",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing New Hugging Face and KerasHub integration",
    "description": "",
    "summary": "Announcing New Hugging Face and KerasHub integration The Hugging Face Hub is a vast repository, curr...",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-hub-integration",
    "thumbnail": "https://huggingface.co/blog/assets/keras-hub-integration/thumbnail.png"
  },
  {
    "title": "Making ML-powered web games with Transformers.js",
    "description": "",
    "summary": "Making ML-powered web games with Transformers.js In this blog post, I'll show you how I made Doodle ...",
    "pubDate": "Wed, 05 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-web-games",
    "thumbnail": "https://huggingface.co/blog/assets/ml-web-games/thumbnail.png"
  },
  {
    "title": "Xet is on the Hub",
    "description": "",
    "summary": "Xet is on the Hub Click here to read about joining the Xet waitlist (or head over to join immediatel...",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xet-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/xet-on-the-hub/thumbnail.png"
  },
  {
    "title": "Introducing the Model Spec",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-model-spec",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building AI-powered apps for business",
    "description": "Retool uses GPT-4 to give businesses a fast, secure way to build AI-powered apps.",
    "summary": "Retool uses GPT-4 to give businesses a fast, secure way to build AI-powered apps.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retool",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Uncertain Boundaries: Multidisciplinary Approaches to Copyright Issues in Generative AI",
    "description": "arXiv:2404.08221v2 Announce Type: replace-cross Abstract: Generative AI is becoming increasingly prevalent in creative fields, sparking urgent debates over how current copyright laws can keep pace with technological innovation. Recent controversies of AI models generating near-replicas of copyrighted material highlight the need to adapt current legal frameworks and develop technical methods to mitigate copyright infringement risks. This task requires understanding the intersection between computational concepts such as large-scale data scraping and probabilistic content generation, legal definitions of originality and fair use, and economic impacts on IP rights holders. However, most existing research on copyright in AI takes a purely computer science or law-based approach, leaving a gap in coordinating these approaches that only multidisciplinary efforts can effectively address. To bridge this gap, our survey adopts a comprehensive approach synthesizing insights from law, policy, economics, and computer science. It begins by discussing the foundational goals and considerations that should be applied to copyright in generative AI, followed by methods for detecting and assessing potential violations in AI system outputs. Next, it explores various regulatory options influenced by legal, policy, and economic frameworks to manage and mitigate copyright concerns associated with generative AI and reconcile the interests of IP rights holders with that of generative AI producers. The discussion then introduces techniques to safeguard individual creative works from unauthorized replication, such as watermarking and cryptographic protections. Finally, it describes advanced training strategies designed to prevent AI models from reproducing protected content. In doing so, we highlight key opportunities for action and offer actionable strategies that creators, developers, and policymakers can use in navigating the evolving copyright landscape.",
    "summary": "arXiv:2404.08221v2 Announce Type: replace-cross Abstract: Generative AI is becoming increasingly prevalent in creative fields, sparking urgent debates over how current copyright laws can keep pace with technological innovation. Recent controversies of AI models generating near-replicas of copyrighted material highlight the need to adapt current legal frameworks and develop technical methods to mitigate copyright infringement risks. This task requires understanding the intersection between computational concepts such as large-scale data scraping and probabilistic content generation, legal definitions of originality and fair use, and economic impacts on IP rights holders. However, most existing research on copyright in AI takes a purely computer science or law-based approach, leaving a gap in coordinating these approaches that only multidisciplinary efforts can effectively address. To bridge this gap, our survey adopts a comprehensive approach synthesizing insights from law, policy, economics, and computer science. It begins by discussing the foundational goals and considerations that should be applied to copyright in generative AI, followed by methods for detecting and assessing potential violations in AI system outputs. Next, it explores various regulatory options influenced by legal, policy, and economic frameworks to manage and mitigate copyright concerns associated with generative AI and reconcile the interests of IP rights holders with that of generative AI producers. The discussion then introduces techniques to safeguard individual creative works from unauthorized replication, such as watermarking and cryptographic protections. Finally, it describes advanced training strategies designed to prevent AI models from reproducing protected content. In doing so, we highlight key opportunities for action and offer actionable strategies that creators, developers, and policymakers can use in navigating the evolving copyright landscape.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2404.08221",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent",
    "description": "",
    "summary": "Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent Introduction We're excited to ...",
    "pubDate": "Mon, 22 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/jat",
    "thumbnail": "https://huggingface.co/blog/assets/jat/thumbnail.png"
  },
  {
    "title": "Diffusion Models Live Event",
    "description": "",
    "summary": "Diffusion Models Live Event We are excited to share that the Diffusion Models Class with Hugging Fac...",
    "pubDate": "Fri, 25 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusion-models-event",
    "thumbnail": "https://huggingface.co/blog/assets/diffusion-models-event/thumbnail.png"
  },
  {
    "title": "Finetune Stable Diffusion Models with DDPO via TRL",
    "description": "",
    "summary": "Finetune Stable Diffusion Models with DDPO via TRL Introduction Diffusion models (e.g., DALL-E 2, St...",
    "pubDate": "Fri, 29 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trl-ddpo",
    "thumbnail": "https://huggingface.co/blog/assets/166_trl_ddpo/thumbnail.png"
  },
  {
    "title": "Building smarter maps with GPT-4o vision fine-tuning",
    "description": "Building smarter maps with GPT-4o vision fine-tuning",
    "summary": "Building smarter maps with GPT-4o vision fine-tuning",
    "pubDate": "Wed, 20 Nov 2024 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/grab",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Claude 4 „É¢„Éá„É´ÁôªÂ†¥ÔºÅÊñ∞Ê©üËÉΩ„ÇÑ‰ªñÁ§æ„Å®„ÅÆÊØîËºÉ„ÉªÊñôÈáë„Å™„Å©Ë©≥„Åó„ÅèËß£Ë™¨",
    "description": "<p>Anthropic Á§æ„ÅØ2025Âπ¥5Êúà22Êó•„ÄÅClaude „ÅÆÊúÄÊñ∞Áâà„ÄåClaude 4„Äç„ÅÆÊèê‰æõ„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„ÄÇ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„ÇÑÊé®Ë´ñ„Çí„ÅØ„Åò„ÇÅ„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÊßãÁØâ„Å®„ÅÑ„Å£„Åü„Ç∑„Éº„É≥„ÅßÊúÄÈ´òÊ∞¥Ê∫ñ„ÅÆËÉΩÂäõ„ÇíÂÆüÁèæ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅ„Ç≥„Éº„Éá [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/claude-4-model-new-features/'>Claude 4 „É¢„Éá„É´ÁôªÂ†¥ÔºÅÊñ∞Ê©üËÉΩ„ÇÑ‰ªñÁ§æ„Å®„ÅÆÊØîËºÉ„ÉªÊñôÈáë„Å™„Å©Ë©≥„Åó„ÅèËß£Ë™¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>Anthropic Á§æ„ÅØ2025Âπ¥5Êúà22Êó•„ÄÅClaude „ÅÆÊúÄÊñ∞Áâà„ÄåClaude 4„Äç„ÅÆÊèê‰æõ„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„ÄÇ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„ÇÑÊé®Ë´ñ„Çí„ÅØ„Åò„ÇÅ„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÊßãÁØâ„Å®„ÅÑ„Å£„Åü„Ç∑„Éº„É≥„ÅßÊúÄÈ´òÊ∞¥Ê∫ñ„ÅÆËÉΩÂäõ„ÇíÂÆüÁèæ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅ„Ç≥„Éº„Éá [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/claude-4-model-new-features/'>Claude 4 „É¢„Éá„É´ÁôªÂ†¥ÔºÅÊñ∞Ê©üËÉΩ„ÇÑ‰ªñÁ§æ„Å®„ÅÆÊØîËºÉ„ÉªÊñôÈáë„Å™„Å©Ë©≥„Åó„ÅèËß£Ë™¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 03:33:57 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/claude-4-model-new-features/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/claude4.png"
  },
  {
    "title": "How to deploy and fine-tune DeepSeek models on AWS",
    "description": "",
    "summary": "How to deploy and fine-tune DeepSeek models on AWS A running document to showcase how to deploy and ...",
    "pubDate": "Thu, 30 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deepseek-r1-aws",
    "thumbnail": "https://huggingface.co/blog/assets/deepseek-r1-aws/thumbnail.png"
  },
  {
    "title": "Accelerating scientific discovery with AI",
    "description": "FutureHouse, co-founded by Sam Rodriques PhD ‚Äô19, has developed AI agents to automate key steps on the path toward scientific progress.",
    "summary": "FutureHouse, co-founded by Sam Rodriques PhD ‚Äô19, has developed AI agents to automate key steps on the path toward scientific progress.",
    "pubDate": "Mon, 30 Jun 2025 10:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/futurehouse-accelerates-scientific-discovery-with-ai-0630",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Future-House-01-press.jpg"
  },
  {
    "title": "Testing robustness against unforeseen adversaries",
    "description": "We‚Äôve developed a method to assess whether a neural network classifier can reliably defend against adversarial attacks not seen during training. Our method yields a new metric, UAR (Unforeseen Attack Robustness), which evaluates the robustness of a single model against an unanticipated attack, and highlights the need to measure performance across a more diverse range of unforeseen¬†attacks.",
    "summary": "We‚Äôve developed a method to assess whether a neural network classifier can reliably defend against adversarial attacks not seen during training. Our method yields a new metric, UAR (Unforeseen Attack Robustness), which evaluates the robustness of a single model against an unanticipated attack, and highlights the need to measure performance across a more diverse range of unforeseen¬†attacks.",
    "pubDate": "Thu, 22 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/testing-robustness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Watermarking 101: Tools and Techniques",
    "description": "",
    "summary": "AI Watermarking 101: Tools and Techniques In recent months, we've seen multiple news stories involvi...",
    "pubDate": "Mon, 26 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/watermarking",
    "thumbnail": "https://huggingface.co/blog/assets/watermarking/thumbnail.png"
  },
  {
    "title": "From Files to Chunks: Improving Hugging Face Storage Efficiency",
    "description": "",
    "summary": "From Files to Chunks: Improving HF Storage Efficiency Hugging Face stores over 30 PB of models, data...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/from-files-to-chunks",
    "thumbnail": "https://huggingface.co/blog/assets/from-files-to-chunks/thumbnail.png"
  },
  {
    "title": "GATSim: Urban Mobility Simulation with Generative Agents",
    "description": "arXiv:2506.23306v1 Announce Type: new Abstract: Traditional agent-based urban mobility simulations rely on rigid rule-based systems that fail to capture the complexity, adaptability, and behavioral diversity characteristic of human travel decision-making. Recent advances in large language models and AI agent technology offer opportunities to create agents with reasoning capabilities, persistent memory, and adaptive learning mechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel framework that leverages these advances to create generative agents with rich behavioral characteristics for urban mobility simulation. Unlike conventional approaches, GATSim agents possess diverse socioeconomic attributes, individual lifestyles, and evolving preferences that shape their mobility decisions through psychologically-informed memory systems, tool usage capabilities, and lifelong learning mechanisms. The main contributions of this study include: (1) a comprehensive architecture combining an urban mobility foundation model with agent cognitive systems and transport simulation environment, (2) a fully functional prototype implementation, and (3) systematic validation demonstrating that generative agents produce believable travel behaviors. Through designed reflection processes, generative agents in this study can transform specific travel experiences into generalized insights, enabling realistic behavioral adaptation over time with specialized mechanisms for activity planning and real-time reactive behaviors tailored to urban mobility contexts. Experiments show that generative agents perform competitively with human annotators in mobility scenarios while naturally producing macroscopic traffic evolution patterns. The code for the prototype system is shared at https://github.com/qiliuchn/gatsim.",
    "summary": "arXiv:2506.23306v1 Announce Type: new Abstract: Traditional agent-based urban mobility simulations rely on rigid rule-based systems that fail to capture the complexity, adaptability, and behavioral diversity characteristic of human travel decision-making. Recent advances in large language models and AI agent technology offer opportunities to create agents with reasoning capabilities, persistent memory, and adaptive learning mechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel framework that leverages these advances to create generative agents with rich behavioral characteristics for urban mobility simulation. Unlike conventional approaches, GATSim agents possess diverse socioeconomic attributes, individual lifestyles, and evolving preferences that shape their mobility decisions through psychologically-informed memory systems, tool usage capabilities, and lifelong learning mechanisms. The main contributions of this study include: (1) a comprehensive architecture combining an urban mobility foundation model with agent cognitive systems and transport simulation environment, (2) a fully functional prototype implementation, and (3) systematic validation demonstrating that generative agents produce believable travel behaviors. Through designed reflection processes, generative agents in this study can transform specific travel experiences into generalized insights, enabling realistic behavioral adaptation over time with specialized mechanisms for activity planning and real-time reactive behaviors tailored to urban mobility contexts. Experiments show that generative agents perform competitively with human annotators in mobility scenarios while naturally producing macroscopic traffic evolution patterns. The code for the prototype system is shared at https://github.com/qiliuchn/gatsim.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23306",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Rearchitecting Hugging Face Uploads and Downloads",
    "description": "",
    "summary": "Rearchitecting Hugging Face Uploads and Downloads As part of Hugging Face's Xet team‚Äôs work to impro...",
    "pubDate": "Tue, 26 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rearchitecting-uploads-and-downloads",
    "thumbnail": "https://huggingface.co/blog/assets/rearchitecting-uploads-and-downloads/thumbnail.png"
  },
  {
    "title": "No GPU left behind: Unlocking Efficiency with Co-located vLLM in TRL",
    "description": "",
    "summary": "No GPU left behind: Unlocking Efficiency with Co-located vLLM in TRL üöÄ Introduction TRL supports tra...",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vllm-colocate",
    "thumbnail": "https://huggingface.co/blog/assets/liger-grpo/thumbnail.png"
  },
  {
    "title": "CyberSecEval 2 - A Comprehensive Evaluation Framework for Cybersecurity Risks and Capabilities of Large Language Models",
    "description": "",
    "summary": "CyberSecEval 2 - A Comprehensive Evaluation Framework for Cybersecurity Risks and Capabilities of La...",
    "pubDate": "Fri, 24 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-llamaguard",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_llamaguard.png"
  },
  {
    "title": "Speculative Decoding for 2x Faster Whisper Inference",
    "description": "",
    "summary": "Speculative Decoding for 2x Faster Whisper Inference Open AI's Whisper is a general purpose speech t...",
    "pubDate": "Wed, 20 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/whisper-speculative-decoding",
    "thumbnail": "https://huggingface.co/blog/assets/whisper-speculative-decoding/thumbnail.png"
  },
  {
    "title": "How we built one of the most ambitious datasets in brain activity research",
    "description": "Four small, translucent zebrafish swim against a dark background",
    "summary": "Four small, translucent zebrafish swim against a dark background",
    "pubDate": "Mon, 09 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/research/zapbench-zebrafish-brain-mapping/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SS_How-we-built-one-of-the-most-ambitious-dat.width-1300.png"
  },
  {
    "title": "OpenAI acquires Global Illumination",
    "description": "The entire team has joined OpenAI.",
    "summary": "The entire team has joined OpenAI.",
    "pubDate": "Wed, 16 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-acquires-global-illumination",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Expanding on what we missed with sycophancy",
    "description": "A deeper dive on our findings, what went wrong, and future changes we‚Äôre making.",
    "summary": "A deeper dive on our findings, what went wrong, and future changes we‚Äôre making.",
    "pubDate": "Fri, 02 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expanding-on-sycophancy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CO2 Emissions and the ü§ó Hub: Leading the Charge",
    "description": "",
    "summary": "CO2 Emissions and the ü§ó Hub: Leading the Charge What are CO2 Emissions and why are they important? C...",
    "pubDate": "Fri, 22 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/carbon-emissions-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/60_carbon_emissions_on_the_hub/thumbnail.jpg"
  },
  {
    "title": "Synthetic data: save money, time and carbon with open source",
    "description": "",
    "summary": "Synthetic data: save money, time and carbon with open source tl;dr Should you fine-tune your own mod...",
    "pubDate": "Fri, 16 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthetic-data-save-costs",
    "thumbnail": "https://huggingface.co/blog/assets/176_synthetic-data-save-costs/thumbnail.png"
  },
  {
    "title": "Upgrading the Moderation API with our new multimodal moderation model",
    "description": "We‚Äôre introducing a new model built on GPT-4o that is more accurate at detecting harmful text and images, enabling developers to build more robust moderation systems.",
    "summary": "We‚Äôre introducing a new model built on GPT-4o that is more accurate at detecting harmful text and images, enabling developers to build more robust moderation systems.",
    "pubDate": "Thu, 26 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/upgrading-the-moderation-api-with-our-new-multimodal-moderation-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Machine Learning Unconference",
    "description": "The latest information about the Unconference is now available at the Unconference wiki, which will be periodically updated with more information for attendees.",
    "summary": "The latest information about the Unconference is now available at the Unconference wiki, which will be periodically updated with more information for attendees.",
    "pubDate": "Thu, 18 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/machine-learning-unconference",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Towards Building Private LLMs: Exploring Multi-Node Expert Parallelism on Apple Silicon for Mixture-of-Experts Large Language Model",
    "description": "arXiv:2506.23635v1 Announce Type: cross Abstract: Large Language Models (LLMs) have revolutionized Artificial Intelligence (AI) with significant advancements such as OpenAI's ChatGPT, Meta's Llama, and Databricks' DBRX. This paper addresses the cost and scalability challenges encountered when constructing private LLM systems for personal or small group services, as aimed by Apple Intelligence. A Mac Studio cluster with Apple's M2 Ultra chips is established as a cost-efficient solution to host and accelerate the pretrained DBRX model with the Mixture-of-Experts (MoE) architecture. Our performance analysis reveal that parallel execution of the model's experts across two to four machine nodes significantly reduces inference time. We find that computation time for the experts is comparable to the communication time for exchanging their outputs, emphasizing the importance of network latency over bandwidth. We also observe significant management overhead due to Apple software stack's memory management logic. Based on these findings, we develop optimization schemes to eliminate the memory management overhead. As a result, the Mac Studio cluster is 1.15 times more cost-efficient than the state-of-the-art AI supercomputer with NVIDIA H100 GPUs. In addition, we construct a performance model to estimate system performance under varying configurations, and the model provides valuable insights for designing private LLM systems.",
    "summary": "arXiv:2506.23635v1 Announce Type: cross Abstract: Large Language Models (LLMs) have revolutionized Artificial Intelligence (AI) with significant advancements such as OpenAI's ChatGPT, Meta's Llama, and Databricks' DBRX. This paper addresses the cost and scalability challenges encountered when constructing private LLM systems for personal or small group services, as aimed by Apple Intelligence. A Mac Studio cluster with Apple's M2 Ultra chips is established as a cost-efficient solution to host and accelerate the pretrained DBRX model with the Mixture-of-Experts (MoE) architecture. Our performance analysis reveal that parallel execution of the model's experts across two to four machine nodes significantly reduces inference time. We find that computation time for the experts is comparable to the communication time for exchanging their outputs, emphasizing the importance of network latency over bandwidth. We also observe significant management overhead due to Apple software stack's memory management logic. Based on these findings, we develop optimization schemes to eliminate the memory management overhead. As a result, the Mac Studio cluster is 1.15 times more cost-efficient than the state-of-the-art AI supercomputer with NVIDIA H100 GPUs. In addition, we construct a performance model to estimate system performance under varying configurations, and the model provides valuable insights for designing private LLM systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23635",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Databricks ‚ù§Ô∏è Hugging Face: up to 40% faster training and tuning of Large Language Models",
    "description": "",
    "summary": "Databricks ‚ù§Ô∏è Hugging Face: up to 40% faster training and tuning of Large Language Models Generative...",
    "pubDate": "Wed, 26 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/databricks-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/databricks.png"
  },
  {
    "title": "VeriLoC: Line-of-Code Level Prediction of Hardware Design Quality from Verilog Code",
    "description": "arXiv:2506.07239v2 Announce Type: replace-cross Abstract: Modern chip design is complex, and there is a crucial need for early-stage prediction of key design-quality metrics like timing and routing congestion directly from Verilog code (a commonly used programming language for hardware design). It is especially important yet complex to predict individual lines of code that cause timing violations or downstream routing congestion. Prior works have tried approaches like converting Verilog into an intermediate graph representation and using LLM embeddings alongside other features to predict module-level quality, but did not consider line-level quality prediction. We propose VeriLoC, the first method that predicts design quality directly from Verilog at both the line- and module-level. To this end, VeriLoC leverages recent Verilog code-generation LLMs to extract local line-level and module-level embeddings, and train downstream classifiers/regressors on concatenations of these embeddings. VeriLoC achieves high F1-scores of 0.86-0.95 for line-level congestion and timing prediction, and reduces the mean average percentage error from 14% - 18% for SOTA methods down to only 4%. We believe that VeriLoC embeddings and insights from our work will also be of value for other predictive and optimization tasks for complex hardware design.",
    "summary": "arXiv:2506.07239v2 Announce Type: replace-cross Abstract: Modern chip design is complex, and there is a crucial need for early-stage prediction of key design-quality metrics like timing and routing congestion directly from Verilog code (a commonly used programming language for hardware design). It is especially important yet complex to predict individual lines of code that cause timing violations or downstream routing congestion. Prior works have tried approaches like converting Verilog into an intermediate graph representation and using LLM embeddings alongside other features to predict module-level quality, but did not consider line-level quality prediction. We propose VeriLoC, the first method that predicts design quality directly from Verilog at both the line- and module-level. To this end, VeriLoC leverages recent Verilog code-generation LLMs to extract local line-level and module-level embeddings, and train downstream classifiers/regressors on concatenations of these embeddings. VeriLoC achieves high F1-scores of 0.86-0.95 for line-level congestion and timing prediction, and reduces the mean average percentage error from 14% - 18% for SOTA methods down to only 4%. We believe that VeriLoC embeddings and insights from our work will also be of value for other predictive and optimization tasks for complex hardware design.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.07239",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome FalconMamba: The first strong attention-free 7B model",
    "description": "",
    "summary": "Welcome FalconMamba: The first strong attention-free 7B model Falcon Mamba is a new model by Technol...",
    "pubDate": "Mon, 12 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falconmamba",
    "thumbnail": "https://huggingface.co/blog/assets/falconmamba/thumbnail.png"
  },
  {
    "title": "GPT-4o mini: advancing cost-efficient intelligence",
    "description": "Introducing the most cost-efficient small model in the market",
    "summary": "Introducing the most cost-efficient small model in the market",
    "pubDate": "Thu, 18 Jul 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-mini-advancing-cost-efficient-intelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Testing and Evaluation: Learnings from Science and Industry",
    "description": "<p>In the introductory episode of this new series, host Kathleen Sullivan and Senior Director Amanda Craig Deckard explore Microsoft‚Äôs efforts to draw on the experience of other domains to help advance the role of AI testing and evaluation as a governance tool.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/'>AI Testing and Evaluation: Learnings from Science and Industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>In the introductory episode of this new series, host Kathleen Sullivan and Senior Director Amanda Craig Deckard explore Microsoft‚Äôs efforts to draw on the experience of other domains to help advance the role of AI testing and evaluation as a governance tool.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/'>AI Testing and Evaluation: Learnings from Science and Industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 16:38:09 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Deploy GPT-J 6B for inference using Hugging Face Transformers and Amazon SageMaker",
    "description": "",
    "summary": "Deploy GPT-J 6B for inference using Hugging Face Transformers and Amazon SageMaker Almost 6 months a...",
    "pubDate": "Tue, 11 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gptj-sagemaker",
    "thumbnail": "https://huggingface.co/blog/assets/45_gptj_sagemaker/thumbnail.png"
  },
  {
    "title": "Merging design and computer science in creative ways",
    "description": "MAD Fellow Alexander Htet Kyaw connects humans, machines, and the physical world using AI and augmented reality.",
    "summary": "MAD Fellow Alexander Htet Kyaw connects humans, machines, and the physical world using AI and augmented reality.",
    "pubDate": "Mon, 28 Apr 2025 16:55:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/alexander-htet-kyaw-merging-design-computer-science-in-creative-ways-0428",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-mad-Alexander-htet-kyaw_0.jpg"
  },
  {
    "title": "Easily Train Models with H100 GPUs on NVIDIA DGX Cloud",
    "description": "",
    "summary": "Easily Train Models with H100 GPUs on NVIDIA DGX Cloud Update: This service is deprecated and no lon...",
    "pubDate": "Mon, 18 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-dgx-cloud",
    "thumbnail": "https://huggingface.co/blog/assets/train-dgx-cloud/thumbnail.jpg"
  },
  {
    "title": "Making LLMs lighter with AutoGPTQ and transformers",
    "description": "",
    "summary": "Making LLMs lighter with AutoGPTQ and transformers Large language models have demonstrated remarkabl...",
    "pubDate": "Wed, 23 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gptq-integration",
    "thumbnail": "https://huggingface.co/blog/assets/159_autogptq_transformers/thumbnail.jpg"
  },
  {
    "title": "Llama 3.2 in Keras",
    "description": "",
    "summary": "Llama 3.2 in Keras This is going to be the shortest blog post ever. Question: Llama 3.2 landed two w...",
    "pubDate": "Mon, 21 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-llama-32",
    "thumbnail": "https://huggingface.co/blog/assets/keras_llama_32/thumbnail.jpg"
  },
  {
    "title": "Swift Diffusers: Fast Stable Diffusion for Mac",
    "description": "",
    "summary": "Swift üß®Diffusers: Fast Stable Diffusion for Mac Transform your text into stunning images with ease u...",
    "pubDate": "Fri, 24 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-mac-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/fast-mac-diffusers/thumbnail.png"
  },
  {
    "title": "TriADA: Massively Parallel Trilinear Matrix-by-Tensor Multiply-Add Algorithm and Device Architecture for the Acceleration of 3D Discrete Transformations",
    "description": "arXiv:2506.22818v1 Announce Type: cross Abstract: Multilinear transformations are key in high-performance computing (HPC) and artificial intelligence (AI) workloads, where data is represented as tensors. However, their high computational and memory demands, which grow with dimensionality, often slow down critical tasks. Moreover, scaling computation by enlarging the number of parallel processing units substantially increases energy consumption, limiting widespread adoption, especially for sparse data, which is common in HPC and AI applications. This paper introduces the Trilinear Algorithm and isomorphic to algorithm Device Architecture (TriADA) to address these challenges with the following innovations: (1) a massively parallel, low-rank algorithm for computing a family of trilinear (3D) discrete orthogonal transformations (3D-DXTs), which is a special case of the more general 3-mode matrix-by-tensor multiplication (3D-GEMT); (2) a new outer-product-based GEMM kernel with decoupled streaming active memory, specially designed to accelerate 3D-GEMT operation; (3) an isomorphic to the proposed algorithm, fully distributed 3D network of mesh interconnected processing elements or cells with a coordinate-free, data-driven local processing activity, which is independent of problem size; (4) an elastic sparse outer-product (ESOP) method that avoids unnecessary computing and communication operations with zero-valued operands, thereby enhancing energy efficiency, computational accuracy, and stability. TriADA is capable of performing a variety of trilinear transformations with hypercubic arithmetic complexity in a linear number of time-steps. The massively parallel, scalable, and energy-efficient architecture of TriADA is ideal for accelerating multilinear tensor operations, which are the most demanding parts of AI and HPC workloads.",
    "summary": "arXiv:2506.22818v1 Announce Type: cross Abstract: Multilinear transformations are key in high-performance computing (HPC) and artificial intelligence (AI) workloads, where data is represented as tensors. However, their high computational and memory demands, which grow with dimensionality, often slow down critical tasks. Moreover, scaling computation by enlarging the number of parallel processing units substantially increases energy consumption, limiting widespread adoption, especially for sparse data, which is common in HPC and AI applications. This paper introduces the Trilinear Algorithm and isomorphic to algorithm Device Architecture (TriADA) to address these challenges with the following innovations: (1) a massively parallel, low-rank algorithm for computing a family of trilinear (3D) discrete orthogonal transformations (3D-DXTs), which is a special case of the more general 3-mode matrix-by-tensor multiplication (3D-GEMT); (2) a new outer-product-based GEMM kernel with decoupled streaming active memory, specially designed to accelerate 3D-GEMT operation; (3) an isomorphic to the proposed algorithm, fully distributed 3D network of mesh interconnected processing elements or cells with a coordinate-free, data-driven local processing activity, which is independent of problem size; (4) an elastic sparse outer-product (ESOP) method that avoids unnecessary computing and communication operations with zero-valued operands, thereby enhancing energy efficiency, computational accuracy, and stability. TriADA is capable of performing a variety of trilinear transformations with hypercubic arithmetic complexity in a linear number of time-steps. The massively parallel, scalable, and energy-efficient architecture of TriADA is ideal for accelerating multilinear tensor operations, which are the most demanding parts of AI and HPC workloads.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22818",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Mechanistic Interpretability of Emotion Inference in Large Language Models",
    "description": "arXiv:2502.05489v2 Announce Type: replace-cross Abstract: Large language models (LLMs) show promising capabilities in predicting human emotions from text. However, the mechanisms through which these models process emotional stimuli remain largely unexplored. Our study addresses this gap by investigating how autoregressive LLMs infer emotions, showing that emotion representations are functionally localized to specific regions in the model. Our evaluation includes diverse model families and sizes and is supported by robustness checks. We then show that the identified representations are psychologically plausible by drawing on cognitive appraisal theory, a well-established psychological framework positing that emotions emerge from evaluations (appraisals) of environmental stimuli. By causally intervening on construed appraisal concepts, we steer the generation and show that the outputs align with theoretical and intuitive expectations. This work highlights a novel way to causally intervene and precisely shape emotional text generation, potentially benefiting safety and alignment in sensitive affective domains.",
    "summary": "arXiv:2502.05489v2 Announce Type: replace-cross Abstract: Large language models (LLMs) show promising capabilities in predicting human emotions from text. However, the mechanisms through which these models process emotional stimuli remain largely unexplored. Our study addresses this gap by investigating how autoregressive LLMs infer emotions, showing that emotion representations are functionally localized to specific regions in the model. Our evaluation includes diverse model families and sizes and is supported by robustness checks. We then show that the identified representations are psychologically plausible by drawing on cognitive appraisal theory, a well-established psychological framework positing that emotions emerge from evaluations (appraisals) of environmental stimuli. By causally intervening on construed appraisal concepts, we steer the generation and show that the outputs align with theoretical and intuitive expectations. This work highlights a novel way to causally intervene and precisely shape emotional text generation, potentially benefiting safety and alignment in sensitive affective domains.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.05489",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Trading inference-time compute for adversarial robustness",
    "description": "Trading Inference-Time Compute for Adversarial Robustness",
    "summary": "Trading Inference-Time Compute for Adversarial Robustness",
    "pubDate": "Wed, 22 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/trading-inference-time-compute-for-adversarial-robustness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2",
    "description": "",
    "summary": "Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2 Update (29/08/2023): A benchmark o...",
    "pubDate": "Thu, 29 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bridgetower",
    "thumbnail": "https://huggingface.co/blog/assets/bridgetower/thumbnail.png"
  },
  {
    "title": "Train 400x faster Static Embedding Models with Sentence Transformers",
    "description": "",
    "summary": "Train 400x faster Static Embedding Models with Sentence Transformers TL;DR This blog post introduces...",
    "pubDate": "Wed, 15 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/static-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "Our latest advances in robot dexterity",
    "description": "Two new AI systems, ALOHA Unleashed and DemoStart, help robots learn to perform complex tasks that require dexterous movement",
    "summary": "Two new AI systems, ALOHA Unleashed and DemoStart, help robots learn to perform complex tasks that require dexterous movement",
    "pubDate": "Thu, 12 Sep 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advances-in-robot-dexterity/",
    "thumbnail": "https://lh3.googleusercontent.com/63ROjLq4VNqk3RDA5vl1mYS1i5xvcgU8-augVWQY5OZCtVsm_e4YX8rR4_DLUlQiTmMHT6qx3p9shUtPGUHy_4SA64RDeMghvk0eDKT6Fqh6-P3d4A=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "description": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "summary": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "pubDate": "Mon, 10 Jun 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-welcomes-cfo-cpo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Could LLMs help design our next medicines and materials?",
    "description": "A new method lets users ask, in plain language, for a new molecule with certain properties, and receive a detailed description of how to synthesize it.",
    "summary": "A new method lets users ask, in plain language, for a new molecule with certain properties, and receive a detailed description of how to synthesize it.",
    "pubDate": "Wed, 09 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/could-llms-help-design-our-next-medicines-and-materials-0409",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-inverse-molecule-01-press.jpg"
  },
  {
    "title": "Introducing ConTextual: How well can your Multimodal model jointly reason over text and image in text-rich scenes?",
    "description": "",
    "summary": "Introducing ConTextual: How well can your Multimodal model jointly reason over text and image in tex...",
    "pubDate": "Tue, 05 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-contextual",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_contextual.png"
  },
  {
    "title": "Time to Rethink AI for Combinatorial Optimization: Classical Algorithms Remain Tough to Match",
    "description": "arXiv:2502.03669v2 Announce Type: replace-cross Abstract: This position paper argues that the machine learning community should fundamentally rethink how AI-inspired methods are developed and evaluated for combinatorial optimization (CO). We present comprehensive empirical benchmarks comparing various recent AI-inspired GPU-based methods with several classical CPU-based solvers on the Maximum Independent Set (MIS) problem. Strikingly, even on in-distribution random graphs, leading AI-inspired methods are consistently outperformed by the state-of-the-art classical solver KaMIS, and some AI-inspired methods frequently fail to surpass even the simplest degree-based greedy heuristic. To better understand the source of these failures, we introduce a novel analysis, serialization, which reveals that non-backtracking AI methods, such as LTFT (based on GFlowNets), end up reasoning similarly to the simplest degree-based greedy heuristic, and thus worse than KaMIS. Our findings reveal three core issues: (1) Limited benchmarks and evaluation - AI-inspired methods are often tested only on small instances with very limited inference time, which covers up issues with scalability and resource usage; (2) Intrinsic hardness and learning limits - even under ideal, in-distribution conditions, learning-based approaches lag behind classical heuristics, highlighting inherent barriers that receive little attention; and (3) Insufficient use and understanding of classical heuristics - current learning frameworks often neglect to incorporate effective classical techniques. Although we use MIS as a testbed, similar gaps and challenges have been reported in other combinatorial optimization problems, suggesting broader relevance for our recommendations. We propose that future research must address these issues by rigorous benchmarking, deepening understanding of learning limitations, and integrating classical heuristics into AI-inspired methods.",
    "summary": "arXiv:2502.03669v2 Announce Type: replace-cross Abstract: This position paper argues that the machine learning community should fundamentally rethink how AI-inspired methods are developed and evaluated for combinatorial optimization (CO). We present comprehensive empirical benchmarks comparing various recent AI-inspired GPU-based methods with several classical CPU-based solvers on the Maximum Independent Set (MIS) problem. Strikingly, even on in-distribution random graphs, leading AI-inspired methods are consistently outperformed by the state-of-the-art classical solver KaMIS, and some AI-inspired methods frequently fail to surpass even the simplest degree-based greedy heuristic. To better understand the source of these failures, we introduce a novel analysis, serialization, which reveals that non-backtracking AI methods, such as LTFT (based on GFlowNets), end up reasoning similarly to the simplest degree-based greedy heuristic, and thus worse than KaMIS. Our findings reveal three core issues: (1) Limited benchmarks and evaluation - AI-inspired methods are often tested only on small instances with very limited inference time, which covers up issues with scalability and resource usage; (2) Intrinsic hardness and learning limits - even under ideal, in-distribution conditions, learning-based approaches lag behind classical heuristics, highlighting inherent barriers that receive little attention; and (3) Insufficient use and understanding of classical heuristics - current learning frameworks often neglect to incorporate effective classical techniques. Although we use MIS as a testbed, similar gaps and challenges have been reported in other combinatorial optimization problems, suggesting broader relevance for our recommendations. We propose that future research must address these issues by rigorous benchmarking, deepening understanding of learning limitations, and integrating classical heuristics into AI-inspired methods.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.03669",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„Éê„Éº„ÉÅ„É£„É´„ÉÑ„Ç§„É≥„Åå„ÇÇ„Åü„Çâ„ÅôÂåªÁôÇ„ÅÆÊñ∞Â∏∏Ë≠ò„ÄÄÂøÉËáìÊ≤ªÁôÇ„ÇÇËÑ≥Ëñ¨Êäï‰∏é„ÇÇ„Åæ„Åö„ÅØ‰ªÆÊÉ≥Á©∫Èñì„Åß",
    "description": "„ÉÄ„ÉÉ„ÇΩ„Éº„Éª„Ç∑„Çπ„ÉÜ„É†„Ç∫„ÅØ„ÄåÂåªÁôÇÂàÜÈáé„Å´„Åä„Åë„Çã„Éê„Éº„ÉÅ„É£„É´„ÉÑ„Ç§„É≥„Äç„Å´Èñ¢„Åô„ÇãË®òËÄÖË™¨Êòé‰ºö„ÇíÈñãÂÇ¨„Åó„ÄÅ„Éê„Éº„ÉÅ„É£„É´„ÉÑ„Ç§„É≥„ÅÆÂÆöÁæ©„ÇÑ„É©„Ç§„Éï„Çµ„Ç§„Ç®„É≥„Çπ„Åä„Çà„Å≥„Éò„É´„Çπ„Ç±„Ç¢È†òÂüü„Åß„ÅÆÂΩπÂâ≤„ÄÅÂÖ∑‰ΩìÁöÑ„Å™Â∞éÂÖ•‰∫ã‰æã„ÄÅÂ∞ÜÊù•„ÅÆÂ±ïÊúõ„Å´„Å§„ÅÑ„Å¶Á¥π‰ªã„Åó„Åü„ÄÇ",
    "summary": "„ÉÄ„ÉÉ„ÇΩ„Éº„Éª„Ç∑„Çπ„ÉÜ„É†„Ç∫„ÅØ„ÄåÂåªÁôÇÂàÜÈáé„Å´„Åä„Åë„Çã„Éê„Éº„ÉÅ„É£„É´„ÉÑ„Ç§„É≥„Äç„Å´Èñ¢„Åô„ÇãË®òËÄÖË™¨Êòé‰ºö„ÇíÈñãÂÇ¨„Åó„ÄÅ„Éê„Éº„ÉÅ„É£„É´„ÉÑ„Ç§„É≥„ÅÆÂÆöÁæ©„ÇÑ„É©„Ç§„Éï„Çµ„Ç§„Ç®„É≥„Çπ„Åä„Çà„Å≥„Éò„É´„Çπ„Ç±„Ç¢È†òÂüü„Åß„ÅÆÂΩπÂâ≤„ÄÅÂÖ∑‰ΩìÁöÑ„Å™Â∞éÂÖ•‰∫ã‰æã„ÄÅÂ∞ÜÊù•„ÅÆÂ±ïÊúõ„Å´„Å§„ÅÑ„Å¶Á¥π‰ªã„Åó„Åü„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 06:15:00 +0900",
    "source": "ITmedia AI",
    "url": "https://monoist.itmedia.co.jp/mn/articles/2506/30/news053.html",
    "thumbnail": "https://image.itmedia.co.jp/mn/articles/2506/30/cover_news053.jpg"
  },
  {
    "title": "Training and Finetuning Embedding Models with Sentence Transformers v3",
    "description": "",
    "summary": "Training and Finetuning Embedding Models with Sentence Transformers v3 Sentence Transformers is a Py...",
    "pubDate": "Tue, 28 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-sentence-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "Introducing data residency in Europe",
    "description": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "summary": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "pubDate": "Wed, 05 Feb 2025 22:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-data-residency-in-europe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding",
    "description": "arXiv:2506.23219v1 Announce Type: cross Abstract: Urban research involves a wide range of scenarios and tasks that require the understanding of multi-modal data. Current methods often focus on specific data types and lack a unified framework in urban field for processing them comprehensively. The recent success of multi-modal large language models (MLLMs) presents a promising opportunity to overcome this limitation. In this paper, we introduce $textit{UrbanLLaVA}$, a multi-modal large language model designed to process these four types of data simultaneously and achieve strong performance across diverse urban tasks compared with general MLLMs. In $textit{UrbanLLaVA}$, we first curate a diverse urban instruction dataset encompassing both single-modal and cross-modal urban data, spanning from location view to global view of urban environment. Additionally, we propose a multi-stage training framework that decouples spatial reasoning enhancement from domain knowledge learning, thereby improving the compatibility and downstream performance of $textit{UrbanLLaVA}$ across diverse urban tasks. Finally, we also extend existing benchmark for urban research to assess the performance of MLLMs across a wide range of urban tasks. Experimental results from three cities demonstrate that $textit{UrbanLLaVA}$ outperforms open-source and proprietary MLLMs in both single-modal tasks and complex cross-modal tasks and shows robust generalization abilities across cities. Source codes and data are openly accessible to the research community via https://github.com/tsinghua-fib-lab/UrbanLLaVA.",
    "summary": "arXiv:2506.23219v1 Announce Type: cross Abstract: Urban research involves a wide range of scenarios and tasks that require the understanding of multi-modal data. Current methods often focus on specific data types and lack a unified framework in urban field for processing them comprehensively. The recent success of multi-modal large language models (MLLMs) presents a promising opportunity to overcome this limitation. In this paper, we introduce $textit{UrbanLLaVA}$, a multi-modal large language model designed to process these four types of data simultaneously and achieve strong performance across diverse urban tasks compared with general MLLMs. In $textit{UrbanLLaVA}$, we first curate a diverse urban instruction dataset encompassing both single-modal and cross-modal urban data, spanning from location view to global view of urban environment. Additionally, we propose a multi-stage training framework that decouples spatial reasoning enhancement from domain knowledge learning, thereby improving the compatibility and downstream performance of $textit{UrbanLLaVA}$ across diverse urban tasks. Finally, we also extend existing benchmark for urban research to assess the performance of MLLMs across a wide range of urban tasks. Experimental results from three cities demonstrate that $textit{UrbanLLaVA}$ outperforms open-source and proprietary MLLMs in both single-modal tasks and complex cross-modal tasks and shows robust generalization abilities across cities. Source codes and data are openly accessible to the research community via https://github.com/tsinghua-fib-lab/UrbanLLaVA.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23219",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI LP",
    "description": "We‚Äôve created OpenAI LP, a new ‚Äúcapped-profit‚Äù company that allows us to rapidly increase our investments in compute and talent while including checks and balances to actualize our mission.",
    "summary": "We‚Äôve created OpenAI LP, a new ‚Äúcapped-profit‚Äù company that allows us to rapidly increase our investments in compute and talent while including checks and balances to actualize our mission.",
    "pubDate": "Mon, 11 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-lp",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Genie 2: A large-scale foundation world model",
    "description": "Generating unlimited diverse training environments for future general agents",
    "summary": "Generating unlimited diverse training environments for future general agents",
    "pubDate": "Wed, 04 Dec 2024 14:23:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/",
    "thumbnail": "https://lh3.googleusercontent.com/wvcJdqh_wddVc-WiMGgcqe7nWp7Ybu0wd-PBDxC_VUQkfxI7HPfQz3fi_HyYTOoRM_XV3Bofp9l1wBZ1CJPZPG6yZMdZxqH8X7_Lb9nhVAquAul1=w1200-h630-n-nu"
  },
  {
    "title": "BERT 101 ü§ó State Of The Art NLP Model Explained",
    "description": "",
    "summary": "BERT 101 ü§ó State Of The Art NLP Model Explained What is BERT? BERT, short for Bidirectional Encoder ...",
    "pubDate": "Wed, 02 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-101",
    "thumbnail": "https://huggingface.co/blog/assets/52_bert_101/thumbnail.jpg"
  },
  {
    "title": "Generate videos in Gemini and Whisk with Veo 2",
    "description": "Transform text-based prompts into high-resolution eight-second videos in Gemini Advanced and use Whisk Animate to turn images into eight-second animated clips.",
    "summary": "Transform text-based prompts into high-resolution eight-second videos in Gemini Advanced and use Whisk Animate to turn images into eight-second animated clips.",
    "pubDate": "Tue, 15 Apr 2025 17:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/generate-videos-in-gemini-and-whisk-with-veo-2/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GenerateVideos_Static1_1920x1080.width-1300.png"
  },
  {
    "title": "What AI‚Äôs impact on individuals means for the health workforce and industry",
    "description": "<p>Ethan Mollick and Azeem Azhar, thought leaders at the forefront of AI‚Äôs influence on work, education, and society, discuss the impact of AI at the individual level and what that means for the healthcare workforce and the organizations and systems in medicine.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/'>What AI&#8217;s impact on individuals means for the health workforce and industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Ethan Mollick and Azeem Azhar, thought leaders at the forefront of AI‚Äôs influence on work, education, and society, discuss the impact of AI at the individual level and what that means for the healthcare workforce and the organizations and systems in medicine.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/'>What AI&#8217;s impact on individuals means for the health workforce and industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 29 May 2025 15:13:48 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Powering virtual education for the classroom",
    "description": "Khan Academy explores the potential for GPT-4 in a limited pilot program.",
    "summary": "Khan Academy explores the potential for GPT-4 in a limited pilot program.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/khan-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reimagining the email experience with AI",
    "description": "Superhuman introduces a new era of email with OpenAI.",
    "summary": "Superhuman introduces a new era of email with OpenAI.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/superhuman",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fixing Open LLM Leaderboard with Math-Verify",
    "description": "",
    "summary": "Fixing Open LLM Leaderboard with Math-Verify 3 weeks ago, we showed how hard it is to correctly eval...",
    "pubDate": "Fri, 14 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/math_verify_leaderboard",
    "thumbnail": "https://huggingface.co/blog/assets/math_verify_leaderboard/thumbnail.png"
  },
  {
    "title": "Training Stable Diffusion with Dreambooth using üß® Diffusers",
    "description": "",
    "summary": "Training Stable Diffusion with Dreambooth using üß® Diffusers Dreambooth is a technique to teach new c...",
    "pubDate": "Mon, 07 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dreambooth",
    "thumbnail": "https://huggingface.co/blog/assets/sd_dreambooth_training/thumbnail.jpg"
  },
  {
    "title": "FZOO: Fast Zeroth-Order Optimizer for Fine-Tuning Large Language Models towards Adam-Scale Speed",
    "description": "arXiv:2506.09034v2 Announce Type: replace-cross Abstract: Fine-tuning large language models (LLMs) often faces GPU memory bottlenecks: the backward pass of first-order optimizers like Adam increases memory usage to more than 10 times the inference level (e.g., 633 GB for OPT-30B). Zeroth-order (ZO) optimizers avoid this cost by estimating gradients only from forward passes, yet existing methods like MeZO usually require many more steps to converge. Can this trade-off between speed and memory in ZO be fundamentally improved? Normalized-SGD demonstrates strong empirical performance with greater memory efficiency than Adam. In light of this, we introduce FZOO, a Fast Zeroth-Order Optimizer toward Adam-Scale Speed. FZOO reduces the total forward passes needed for convergence by employing batched one-sided estimates that adapt step sizes based on the standard deviation of batch losses. It also accelerates per-batch computation through the use of Rademacher random vector perturbations coupled with CUDA's parallel processing. Extensive experiments on diverse models, including RoBERTa-large, OPT (350M-66B), Phi-2, and Llama3, across 11 tasks validate FZOO's effectiveness. On average, FZOO outperforms MeZO by 3 percent in accuracy while requiring 3 times fewer forward passes. For RoBERTa-large, FZOO achieves average improvements of 5.6 percent in accuracy and an 18 times reduction in forward passes compared to MeZO, achieving convergence speeds comparable to Adam. We also provide theoretical analysis proving FZOO's formal equivalence to a normalized-SGD update rule and its convergence guarantees. FZOO integrates smoothly into PEFT techniques, enabling even larger memory savings. Overall, our results make single-GPU, high-speed, full-parameter fine-tuning practical and point toward future work on memory-efficient pre-training.",
    "summary": "arXiv:2506.09034v2 Announce Type: replace-cross Abstract: Fine-tuning large language models (LLMs) often faces GPU memory bottlenecks: the backward pass of first-order optimizers like Adam increases memory usage to more than 10 times the inference level (e.g., 633 GB for OPT-30B). Zeroth-order (ZO) optimizers avoid this cost by estimating gradients only from forward passes, yet existing methods like MeZO usually require many more steps to converge. Can this trade-off between speed and memory in ZO be fundamentally improved? Normalized-SGD demonstrates strong empirical performance with greater memory efficiency than Adam. In light of this, we introduce FZOO, a Fast Zeroth-Order Optimizer toward Adam-Scale Speed. FZOO reduces the total forward passes needed for convergence by employing batched one-sided estimates that adapt step sizes based on the standard deviation of batch losses. It also accelerates per-batch computation through the use of Rademacher random vector perturbations coupled with CUDA's parallel processing. Extensive experiments on diverse models, including RoBERTa-large, OPT (350M-66B), Phi-2, and Llama3, across 11 tasks validate FZOO's effectiveness. On average, FZOO outperforms MeZO by 3 percent in accuracy while requiring 3 times fewer forward passes. For RoBERTa-large, FZOO achieves average improvements of 5.6 percent in accuracy and an 18 times reduction in forward passes compared to MeZO, achieving convergence speeds comparable to Adam. We also provide theoretical analysis proving FZOO's formal equivalence to a normalized-SGD update rule and its convergence guarantees. FZOO integrates smoothly into PEFT techniques, enabling even larger memory savings. Overall, our results make single-GPU, high-speed, full-parameter fine-tuning practical and point toward future work on memory-efficient pre-training.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.09034",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-written critiques help humans notice flaws",
    "description": "We trained ‚Äúcritique-writing‚Äù models to describe flaws in summaries. Human evaluators find flaws in summaries much more often when shown our model‚Äôs critiques. Larger models are better at self-critiquing, with scale improving critique-writing more than summary-writing. This shows promise for using AI systems to assist human supervision of AI systems on difficult¬†tasks.",
    "summary": "We trained ‚Äúcritique-writing‚Äù models to describe flaws in summaries. Human evaluators find flaws in summaries much more often when shown our model‚Äôs critiques. Larger models are better at self-critiquing, with scale improving critique-writing more than summary-writing. This shows promise for using AI systems to assist human supervision of AI systems on difficult¬†tasks.",
    "pubDate": "Mon, 13 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/critiques",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New method efficiently safeguards sensitive AI training data",
    "description": "The approach maintains an AI model‚Äôs accuracy while ensuring attackers can‚Äôt extract secret information.",
    "summary": "The approach maintains an AI model‚Äôs accuracy while ensuring attackers can‚Äôt extract secret information.",
    "pubDate": "Fri, 11 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-method-efficiently-safeguards-sensitive-ai-training-data-0411",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Private-Algorithm-01-press.jpg"
  },
  {
    "title": "Here‚Äôs the next cohort of the Google.org Accelerator: Generative AI",
    "description": "A collage of photos showing people using technology around the world, on a white background",
    "summary": "A collage of photos showing people using technology around the world, on a white background",
    "pubDate": "Mon, 09 Jun 2025 14:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/google-org/generative-ai-accelerator-cohort-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gen_AI_Accelerator_ss.width-1300.png"
  },
  {
    "title": "Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub",
    "description": "",
    "summary": "Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub Huggy Lingo...",
    "pubDate": "Wed, 02 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggy-lingo",
    "thumbnail": "https://huggingface.co/blog/huggy-lingo/blog/assets/156_huggylingo/Huggy_Lingo.png"
  },
  {
    "title": "Open Source Developers Guide to the EU AI Act",
    "description": "",
    "summary": "Open Source Developers Guide to the EU AI Act The EU AI Act, the world‚Äôs first comprehensive legisla...",
    "pubDate": "Mon, 02 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eu-ai-act-for-oss-developers",
    "thumbnail": "https://huggingface.co/blog/assets/189_eu-ai-act-for-oss-developers/thumbnail.png"
  },
  {
    "title": "From Alignment to Advancement: Bootstrapping Audio-Language Alignment with Synthetic Data",
    "description": "arXiv:2505.20166v2 Announce Type: replace-cross Abstract: Audio-aware large language models (ALLMs) have recently made great strides in understanding and processing audio inputs. These models are typically adapted from text-based large language models (LLMs) through additional training on audio-related tasks. However, this adaptation process presents two major limitations. First, ALLMs often suffer from catastrophic forgetting, where crucial textual capabilities like instruction-following are lost after training on audio data. In some cases, models may even hallucinate sounds that are not present in the input audio, raising concerns about reliability. Second, achieving cross-modal alignment between audio and language typically relies on large collections of task-specific question-answer pairs for instruction tuning, making it resource-intensive. To address these issues, previous works have leveraged the backbone LLMs to synthesize general-purpose, caption-style alignment data. In this paper, we propose a data generation framework that produces contrastive-like training data, designed to enhance ALLMs' ability to differentiate between present and absent sounds. We further extend our approach to multi-audio scenarios, enabling the model to either explain differences between audio inputs or produce unified captions that describe all inputs, thereby enhancing audio-language alignment. We refer to the entire ALLM training framework as bootstrapping audio-language alignment via synthetic data generation from backbone LLMs (BALSa). Experimental results indicate that our method effectively mitigates audio hallucinations while reliably maintaining strong performance on audio understanding and reasoning benchmarks, as well as instruction-following skills. Moreover, incorporating multi-audio training further enhances the model's comprehension and reasoning capabilities. Overall, BALSa offers an efficient and scalable approach to developing ALLMs.",
    "summary": "arXiv:2505.20166v2 Announce Type: replace-cross Abstract: Audio-aware large language models (ALLMs) have recently made great strides in understanding and processing audio inputs. These models are typically adapted from text-based large language models (LLMs) through additional training on audio-related tasks. However, this adaptation process presents two major limitations. First, ALLMs often suffer from catastrophic forgetting, where crucial textual capabilities like instruction-following are lost after training on audio data. In some cases, models may even hallucinate sounds that are not present in the input audio, raising concerns about reliability. Second, achieving cross-modal alignment between audio and language typically relies on large collections of task-specific question-answer pairs for instruction tuning, making it resource-intensive. To address these issues, previous works have leveraged the backbone LLMs to synthesize general-purpose, caption-style alignment data. In this paper, we propose a data generation framework that produces contrastive-like training data, designed to enhance ALLMs' ability to differentiate between present and absent sounds. We further extend our approach to multi-audio scenarios, enabling the model to either explain differences between audio inputs or produce unified captions that describe all inputs, thereby enhancing audio-language alignment. We refer to the entire ALLM training framework as bootstrapping audio-language alignment via synthetic data generation from backbone LLMs (BALSa). Experimental results indicate that our method effectively mitigates audio hallucinations while reliably maintaining strong performance on audio understanding and reasoning benchmarks, as well as instruction-following skills. Moreover, incorporating multi-audio training further enhances the model's comprehension and reasoning capabilities. Overall, BALSa offers an efficient and scalable approach to developing ALLMs.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.20166",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition ü§ñ",
    "description": "",
    "summary": "Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition ü§ñ Simon Alibert and R√©...",
    "pubDate": "Mon, 14 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-pollen-robotics-acquisition",
    "thumbnail": "https://huggingface.co/blog/assets/hugging-face-pollen-robotics-acquisition/hf-pollen.png"
  },
  {
    "title": "Introducing our new pricing",
    "description": "",
    "summary": "Introducing our new pricing As you might have noticed, our pricing page has changed a lot recently. ...",
    "pubDate": "Tue, 08 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pricing-update",
    "thumbnail": "https://huggingface.co/blog/assets/114_pricing-update/thumbnail.png"
  },
  {
    "title": "Bertelsmann powers creativity and productivity with OpenAI",
    "description": "Bertelsmann, the global media, services, and education company headquartered in Germany, will integrate OpenAI‚Äôs technology across multiple brands around the world.",
    "summary": "Bertelsmann, the global media, services, and education company headquartered in Germany, will integrate OpenAI‚Äôs technology across multiple brands around the world.",
    "pubDate": "Wed, 22 Jan 2025 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bertelsmann-powers-creativity-and-productivity-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "üß® Diffusers welcomes Stable Diffusion 3",
    "description": "",
    "summary": "üß® Diffusers welcomes Stable Diffusion 3 Stable Diffusion 3 (SD3), Stability AI‚Äôs latest iteration of...",
    "pubDate": "Wed, 12 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd3",
    "thumbnail": "https://huggingface.co/blog/assets/sd3/thumbnail.png"
  },
  {
    "title": "Block-sparse GPU kernels",
    "description": "We‚Äôre releasing highly-optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights. Depending on the chosen sparsity, these kernels can run orders of magnitude faster than cuBLAS or cuSPARSE. We‚Äôve used them to attain state-of-the-art results in text sentiment analysis and generative modeling of text and images.",
    "summary": "We‚Äôre releasing highly-optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights. Depending on the chosen sparsity, these kernels can run orders of magnitude faster than cuBLAS or cuSPARSE. We‚Äôve used them to attain state-of-the-art results in text sentiment analysis and generative modeling of text and images.",
    "pubDate": "Wed, 06 Dec 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/block-sparse-gpu-kernels",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An Introduction to Deep Reinforcement Learning",
    "description": "",
    "summary": "An Introduction to Deep Reinforcement Learning Deep Reinforcement Learning Class with Hugging Face ü§ó...",
    "pubDate": "Wed, 04 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-intro",
    "thumbnail": "https://huggingface.co/blog/assets/63_deep_rl_intro/thumbnail.png"
  },
  {
    "title": "Reducing bias and improving safety in DALL¬∑E 2",
    "description": "Today, we are implementing a new technique so that DALL¬∑E generates images of people that more accurately reflect the diversity of the world‚Äôs population.",
    "summary": "Today, we are implementing a new technique so that DALL¬∑E generates images of people that more accurately reflect the diversity of the world‚Äôs population.",
    "pubDate": "Mon, 18 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Delivering contextual job matching for millions with OpenAI",
    "description": "Indeed, whose mission is to help people get jobs, is the world‚Äôs #1 job site. Over 350 million unique visitors come to Indeed every month to connect with more than 3.5 million employers and over 32 million jobs. But what‚Äôs more is that every three seconds someone gets hired on Indeed.",
    "summary": "Indeed, whose mission is to help people get jobs, is the world‚Äôs #1 job site. Over 350 million unique visitors come to Indeed every month to connect with more than 3.5 million employers and over 32 million jobs. But what‚Äôs more is that every three seconds someone gets hired on Indeed.",
    "pubDate": "Thu, 15 Aug 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/indeed",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Kubernetes Network Driver Model: A Composable Architecture for High-Performance Networking",
    "description": "arXiv:2506.23628v1 Announce Type: cross Abstract: Traditional Kubernetes networking struggles to meet the escalating demands of AI/ML and evolving Telco infrastructure. This paper introduces Kubernetes Network Drivers (KNDs), a transformative, modular, and declarative architecture designed to overcome current imperative provisioning and API limitations. KNDs integrate network resource management into Kubernetes' core by utilizing Dynamic Resource Allocation (DRA), Node Resource Interface (NRI) improvements, and upcoming OCI Runtime Specification changes. Our DraNet implementation demonstrates declarative attachment of network interfaces, including Remote Direct Memory Access (RDMA) devices, significantly boosting high-performance AI/ML workloads. This capability enables sophisticated cloud-native applications and lays crucial groundwork for future Telco solutions, fostering a 'galaxy' of specialized KNDs for enhanced application delivery and reduced operational complexity.",
    "summary": "arXiv:2506.23628v1 Announce Type: cross Abstract: Traditional Kubernetes networking struggles to meet the escalating demands of AI/ML and evolving Telco infrastructure. This paper introduces Kubernetes Network Drivers (KNDs), a transformative, modular, and declarative architecture designed to overcome current imperative provisioning and API limitations. KNDs integrate network resource management into Kubernetes' core by utilizing Dynamic Resource Allocation (DRA), Node Resource Interface (NRI) improvements, and upcoming OCI Runtime Specification changes. Our DraNet implementation demonstrates declarative attachment of network interfaces, including Remote Direct Memory Access (RDMA) devices, significantly boosting high-performance AI/ML workloads. This capability enables sophisticated cloud-native applications and lays crucial groundwork for future Telco solutions, fostering a 'galaxy' of specialized KNDs for enhanced application delivery and reduced operational complexity.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23628",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Adversarial Cooperative Rationalization: The Risk of Spurious Correlations in Even Clean Datasets",
    "description": "arXiv:2505.02118v4 Announce Type: replace Abstract: This study investigates the self-rationalization framework constructed with a cooperative game, where a generator initially extracts the most informative segment from raw input, and a subsequent predictor utilizes the selected subset for its input. The generator and predictor are trained collaboratively to maximize prediction accuracy. In this paper, we first uncover a potential caveat: such a cooperative game could unintentionally introduce a sampling bias during rationale extraction. Specifically, the generator might inadvertently create an incorrect correlation between the selected rationale candidate and the label, even when they are semantically unrelated in the original dataset. Subsequently, we elucidate the origins of this bias using both detailed theoretical analysis and empirical evidence. Our findings suggest a direction for inspecting these correlations through attacks, based on which we further introduce an instruction to prevent the predictor from learning the correlations. Through experiments on six text classification datasets and two graph classification datasets using three network architectures (GRUs, BERT, and GCN), we show that our method not only significantly outperforms recent rationalization methods, but also achieves comparable or even better results than a representative LLM (llama3.1-8b-instruct).",
    "summary": "arXiv:2505.02118v4 Announce Type: replace Abstract: This study investigates the self-rationalization framework constructed with a cooperative game, where a generator initially extracts the most informative segment from raw input, and a subsequent predictor utilizes the selected subset for its input. The generator and predictor are trained collaboratively to maximize prediction accuracy. In this paper, we first uncover a potential caveat: such a cooperative game could unintentionally introduce a sampling bias during rationale extraction. Specifically, the generator might inadvertently create an incorrect correlation between the selected rationale candidate and the label, even when they are semantically unrelated in the original dataset. Subsequently, we elucidate the origins of this bias using both detailed theoretical analysis and empirical evidence. Our findings suggest a direction for inspecting these correlations through attacks, based on which we further introduce an instruction to prevent the predictor from learning the correlations. Through experiments on six text classification datasets and two graph classification datasets using three network architectures (GRUs, BERT, and GCN), we show that our method not only significantly outperforms recent rationalization methods, but also achieves comparable or even better results than a representative LLM (llama3.1-8b-instruct).",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.02118",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improving mathematical reasoning with process supervision",
    "description": "We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (‚Äúprocess supervision‚Äù) instead of simply rewarding the correct final answer (‚Äúoutcome supervision‚Äù). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.",
    "summary": "We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (‚Äúprocess supervision‚Äù) instead of simply rewarding the correct final answer (‚Äúoutcome supervision‚Äù). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.",
    "pubDate": "Wed, 31 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-mathematical-reasoning-with-process-supervision",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Run ComfyUI workflows for free on Spaces",
    "description": "",
    "summary": "Run ComfyUI workflows for free with Gradio on Hugging Face Spaces Index: - Intro - Exporting your Co...",
    "pubDate": "Sun, 14 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/run-comfyui-workflows-on-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/comfyui-to-gradio/cover.png"
  },
  {
    "title": "Learning how to predict rare kinds of failures",
    "description": "Researchers are developing algorithms to predict failures when automation meets the real world in areas like air traffic scheduling or autonomous vehicles.",
    "summary": "Researchers are developing algorithms to predict failures when automation meets the real world in areas like air traffic scheduling or autonomous vehicles.",
    "pubDate": "Wed, 21 May 2025 16:35:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/learning-how-predict-rare-kinds-failures-0521",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-rare-event-modeling.jpg"
  },
  {
    "title": "A General Framework on Conditions for Constraint-based Causal Learning",
    "description": "arXiv:2408.07575v2 Announce Type: replace Abstract: Most constraint-based causal learning algorithms provably return the correct causal graph under certain correctness conditions, such as faithfulness. By representing any constraint-based causal learning algorithm using the notion of a property, we provide a general framework to obtain and study correctness conditions for these algorithms. From the framework, we provide exact correctness conditions for the PC algorithm, which are then related to the correctness conditions of some other existing causal discovery algorithms. The framework also suggests a paradigm for designing causal learning algorithms which allows for the correctness conditions of algorithms to be controlled for before designing the actual algorithm, and has the following implications. We show that the sparsest Markov representation condition is the weakest correctness condition for algorithms that output ancestral graphs or directed acyclic graphs satisfying any existing notions of minimality. We also reason that Pearl-minimality is necessary for meaningful causal learning but not sufficient to relax the faithfulness condition and, as such, has to be strengthened, such as by including background knowledge, for causal learning beyond faithfulness.",
    "summary": "arXiv:2408.07575v2 Announce Type: replace Abstract: Most constraint-based causal learning algorithms provably return the correct causal graph under certain correctness conditions, such as faithfulness. By representing any constraint-based causal learning algorithm using the notion of a property, we provide a general framework to obtain and study correctness conditions for these algorithms. From the framework, we provide exact correctness conditions for the PC algorithm, which are then related to the correctness conditions of some other existing causal discovery algorithms. The framework also suggests a paradigm for designing causal learning algorithms which allows for the correctness conditions of algorithms to be controlled for before designing the actual algorithm, and has the following implications. We show that the sparsest Markov representation condition is the weakest correctness condition for algorithms that output ancestral graphs or directed acyclic graphs satisfying any existing notions of minimality. We also reason that Pearl-minimality is necessary for meaningful causal learning but not sufficient to relax the faithfulness condition and, as such, has to be strengthened, such as by including background knowledge, for causal learning beyond faithfulness.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.07575",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Announcing our new Content Guidelines and Policy",
    "description": "",
    "summary": "Announcing our new Community Policy As a community-driven platform that aims to advance Open, Collab...",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/content-guidelines-update",
    "thumbnail": "https://huggingface.co/blog/assets/content-guidelines-blogpost/thumbnail.png"
  },
  {
    "title": "Quantifying generalization in reinforcement learning",
    "description": "We‚Äôre releasing CoinRun, a training environment which provides a metric for an agent‚Äôs ability to transfer its experience to novel situations and has already helped clarify a¬†longstanding¬†puzzle¬†in reinforcement learning. CoinRun strikes a desirable balance in complexity: the environment is simpler than traditional platformer games like Sonic the Hedgehog but still poses a worthy generalization challenge for state of the art¬†algorithms.",
    "summary": "We‚Äôre releasing CoinRun, a training environment which provides a metric for an agent‚Äôs ability to transfer its experience to novel situations and has already helped clarify a¬†longstanding¬†puzzle¬†in reinforcement learning. CoinRun strikes a desirable balance in complexity: the environment is simpler than traditional platformer games like Sonic the Hedgehog but still poses a worthy generalization challenge for state of the art¬†algorithms.",
    "pubDate": "Thu, 06 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/quantifying-generalization-in-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "WavShape: Information-Theoretic Speech Representation Learning for Fair and Privacy-Aware Audio Processing",
    "description": "arXiv:2506.22789v1 Announce Type: cross Abstract: Speech embeddings often retain sensitive attributes such as speaker identity, accent, or demographic information, posing risks in biased model training and privacy leakage. We propose WavShape, an information-theoretic speech representation learning framework that optimizes embeddings for fairness and privacy while preserving task-relevant information. We leverage mutual information (MI) estimation using the Donsker-Varadhan formulation to guide an MI-based encoder that systematically filters sensitive attributes while maintaining speech content essential for downstream tasks. Experimental results on three known datasets show that WavShape reduces MI between embeddings and sensitive attributes by up to 81% while retaining 97% of task-relevant information. By integrating information theory with self-supervised speech models, this work advances the development of fair, privacy-aware, and resource-efficient speech systems.",
    "summary": "arXiv:2506.22789v1 Announce Type: cross Abstract: Speech embeddings often retain sensitive attributes such as speaker identity, accent, or demographic information, posing risks in biased model training and privacy leakage. We propose WavShape, an information-theoretic speech representation learning framework that optimizes embeddings for fairness and privacy while preserving task-relevant information. We leverage mutual information (MI) estimation using the Donsker-Varadhan formulation to guide an MI-based encoder that systematically filters sensitive attributes while maintaining speech content essential for downstream tasks. Experimental results on three known datasets show that WavShape reduces MI between embeddings and sensitive attributes by up to 81% while retaining 97% of task-relevant information. By integrating information theory with self-supervised speech models, this work advances the development of fair, privacy-aware, and resource-efficient speech systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22789",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "nanoVLM: The simplest repository to train your VLM in pure PyTorch",
    "description": "",
    "summary": "nanoVLM: The simplest repository to train your VLM in pure PyTorch nanoVLM is the simplest way to ge...",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nanovlm",
    "thumbnail": "https://huggingface.co/blog/assets/nanovlm/thumbnail.png"
  },
  {
    "title": "Scaling Kubernetes to 2,500 nodes",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 18 Jan 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-kubernetes-to-2500-nodes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FastRTC„Çí‰Ωø„Å£„Å¶ÁàÜÈÄü„ÅßVoicebot„ÇíÊßãÁØâ„Åô„Çã",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØPython„Åß„É™„Ç¢„É´„Çø„Ç§„É†„Å™AI„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Çí‰Ωú„ÇãÈöõ„Å´ÂΩπÁ´ã„Å§„É©„Ç§„Éñ„É©„É™„ÄÅFastRTC„Çí‰Ωø„Å£„Å¶Á∞°Âçò„Å™Voicebot„ÇíÊßãÁØâ„Åó„Å¶„Åø„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ FastRTC FastRT [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5680' rel='nofollow'>FastRTC„Çí‰Ωø„Å£„Å¶ÁàÜÈÄü„ÅßVoicebot„ÇíÊßãÁØâ„Åô„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØPython„Åß„É™„Ç¢„É´„Çø„Ç§„É†„Å™AI„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Çí‰Ωú„ÇãÈöõ„Å´ÂΩπÁ´ã„Å§„É©„Ç§„Éñ„É©„É™„ÄÅFastRTC„Çí‰Ωø„Å£„Å¶Á∞°Âçò„Å™Voicebot„ÇíÊßãÁØâ„Åó„Å¶„Åø„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ FastRTC FastRT [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5680' rel='nofollow'>FastRTC„Çí‰Ωø„Å£„Å¶ÁàÜÈÄü„ÅßVoicebot„ÇíÊßãÁØâ„Åô„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Wed, 16 Apr 2025 00:41:50 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5680",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/f81fd2e4c52864042852c112ce927ae2.png"
  },
  {
    "title": "Using GPT-4 for content moderation",
    "description": "We use GPT-4 for content policy development and content moderation decisions, enabling more consistent labeling, a faster feedback loop for policy refinement, and less involvement from human moderators.",
    "summary": "We use GPT-4 for content policy development and content moderation decisions, enabling more consistent labeling, a faster feedback loop for policy refinement, and less involvement from human moderators.",
    "pubDate": "Tue, 15 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/using-gpt-4-for-content-moderation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Enabling Precise Topic Alignment in Large Language Models Via Sparse Autoencoders",
    "description": "arXiv:2506.12576v2 Announce Type: replace-cross Abstract: Recent work shows that Sparse Autoencoders (SAE) applied to large language model (LLM) layers have neurons corresponding to interpretable concepts. These SAE neurons can be modified to align generated outputs, but only towards pre-identified topics and with some parameter tuning. Our approach leverages the observational and modification properties of SAEs to enable alignment for any topic. This method 1) scores each SAE neuron by its semantic similarity to an alignment text and uses them to 2) modify SAE-layer-level outputs by emphasizing topic-aligned neurons. We assess the alignment capabilities of this approach on diverse public topic datasets including Amazon reviews, Medicine, and Sycophancy, across the currently available open-source LLMs and SAE pairs (GPT2 and Gemma) with multiple SAEs configurations. Experiments aligning to medical prompts reveal several benefits over fine-tuning, including increased average language acceptability (0.25 vs. 0.5), reduced training time across multiple alignment topics (333.6s vs. 62s), and acceptable inference time for many applications (+0.00092s/token). Our open-source code is available at github.com/IBM/sae-steering.",
    "summary": "arXiv:2506.12576v2 Announce Type: replace-cross Abstract: Recent work shows that Sparse Autoencoders (SAE) applied to large language model (LLM) layers have neurons corresponding to interpretable concepts. These SAE neurons can be modified to align generated outputs, but only towards pre-identified topics and with some parameter tuning. Our approach leverages the observational and modification properties of SAEs to enable alignment for any topic. This method 1) scores each SAE neuron by its semantic similarity to an alignment text and uses them to 2) modify SAE-layer-level outputs by emphasizing topic-aligned neurons. We assess the alignment capabilities of this approach on diverse public topic datasets including Amazon reviews, Medicine, and Sycophancy, across the currently available open-source LLMs and SAE pairs (GPT2 and Gemma) with multiple SAEs configurations. Experiments aligning to medical prompts reveal several benefits over fine-tuning, including increased average language acceptability (0.25 vs. 0.5), reduced training time across multiple alignment topics (333.6s vs. 62s), and acceptable inference time for many applications (+0.00092s/token). Our open-source code is available at github.com/IBM/sae-steering.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12576",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DALL¬∑E 3 is now available in ChatGPT Plus and Enterprise",
    "description": "We developed a safety mitigation stack to ready DALL¬∑E 3 for wider release and are sharing updates on our provenance research.",
    "summary": "We developed a safety mitigation stack to ready DALL¬∑E 3 for wider release and are sharing updates on our provenance research.",
    "pubDate": "Thu, 19 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Leadership updates",
    "description": "OpenAI has grown a lot. We remain focused on the same core‚Äîpursuing frontier AI research that accelerates human progress‚Äìbut we now also deliver products used by hundreds of millions of people.",
    "summary": "OpenAI has grown a lot. We remain focused on the same core‚Äîpursuing frontier AI research that accelerates human progress‚Äìbut we now also deliver products used by hundreds of millions of people.",
    "pubDate": "Mon, 24 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-updates-march-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A generalist AI agent for 3D virtual environments",
    "description": "Introducing SIMA, a Scalable Instructable Multiworld Agent",
    "summary": "Introducing SIMA, a Scalable Instructable Multiworld Agent",
    "pubDate": "Wed, 13 Mar 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/",
    "thumbnail": "https://lh3.googleusercontent.com/2GNumOaJCB48RQIFbwJmmZro-AFdBebufxvY_ZkSdUs9RQ-0nSTgBMXuhUdIE5zpPknqevL4ZyP44PLOpJlg0U0ArlOCcJHfoOagzSnZZoXLnq7hdQ=w1200-h630-n-nu"
  },
  {
    "title": "Global news partnerships: Le Monde and Prisa Media",
    "description": "We have partnered with international news organizations Le Monde and Prisa Media to bring French and Spanish news content to ChatGPT.",
    "summary": "We have partnered with international news organizations Le Monde and Prisa Media to bring French and Spanish news content to ChatGPT.",
    "pubDate": "Wed, 13 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/global-news-partnerships-le-monde-and-prisa-media",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating SD Turbo and SDXL Turbo Inference with ONNX Runtime and Olive",
    "description": "",
    "summary": "Accelerating SD Turbo and SDXL Turbo Inference with ONNX Runtime and Olive Introduction SD Turbo and...",
    "pubDate": "Mon, 15 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_ort_inference",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_onnxruntime-training/thumbnail.png"
  },
  {
    "title": "Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation",
    "description": "arXiv:2502.00306v2 Announce Type: replace-cross Abstract: Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to generate grounded responses by leveraging external knowledge databases without altering model parameters. Although the absence of weight tuning prevents leakage via model parameters, it introduces the risk of inference adversaries exploiting retrieved documents in the model's context. Existing methods for membership inference and data extraction often rely on jailbreaking or carefully crafted unnatural queries, which can be easily detected or thwarted with query rewriting techniques common in RAG systems. In this work, we present Interrogation Attack (IA), a membership inference technique targeting documents in the RAG datastore. By crafting natural-text queries that are answerable only with the target document's presence, our approach demonstrates successful inference with just 30 queries while remaining stealthy; straightforward detectors identify adversarial prompts from existing methods up to ~76x more frequently than those generated by our attack. We observe a 2x improvement in TPR@1%FPR over prior inference attacks across diverse RAG configurations, all while costing less than $0.02 per document inference.",
    "summary": "arXiv:2502.00306v2 Announce Type: replace-cross Abstract: Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to generate grounded responses by leveraging external knowledge databases without altering model parameters. Although the absence of weight tuning prevents leakage via model parameters, it introduces the risk of inference adversaries exploiting retrieved documents in the model's context. Existing methods for membership inference and data extraction often rely on jailbreaking or carefully crafted unnatural queries, which can be easily detected or thwarted with query rewriting techniques common in RAG systems. In this work, we present Interrogation Attack (IA), a membership inference technique targeting documents in the RAG datastore. By crafting natural-text queries that are answerable only with the target document's presence, our approach demonstrates successful inference with just 30 queries while remaining stealthy; straightforward detectors identify adversarial prompts from existing methods up to ~76x more frequently than those generated by our attack. We observe a 2x improvement in TPR@1%FPR over prior inference attacks across diverse RAG configurations, all while costing less than $0.02 per document inference.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.00306",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Empowering defenders through our Cybersecurity Grant Program",
    "description": "Highlighting innovative research and AI integration in cybersecurity",
    "summary": "Highlighting innovative research and AI integration in cybersecurity",
    "pubDate": "Thu, 20 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/empowering-defenders-through-our-cybersecurity-grant-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PromptDSI: Prompt-based Rehearsal-free Continual Learning for Document Retrieval",
    "description": "arXiv:2406.12593v4 Announce Type: replace-cross Abstract: Differentiable Search Index (DSI) utilizes pre-trained language models to perform indexing and document retrieval via end-to-end learning without relying on external indexes. However, DSI requires full re-training to index new documents, causing significant computational inefficiencies. Continual learning (CL) offers a solution by enabling the model to incrementally update without full re-training. Existing CL solutions in document retrieval rely on memory buffers or generative models for rehearsal, which is infeasible when accessing previous training data is restricted due to privacy concerns. To this end, we introduce PromptDSI, a prompt-based, rehearsal-free continual learning approach for document retrieval. PromptDSI follows the Prompt-based Continual Learning (PCL) framework, using learnable prompts to efficiently index new documents without accessing previous documents or queries. To improve retrieval latency, we remove the initial forward pass of PCL, which otherwise greatly increases training and inference time, with a negligible trade-off in performance. Additionally, we introduce a novel topic-aware prompt pool that employs neural topic embeddings as fixed keys, eliminating the instability of prompt key optimization while maintaining competitive performance with existing PCL prompt pools. In a challenging rehearsal-free continual learning setup, we demonstrate that PromptDSI variants outperform rehearsal-based baselines, match the strong cache-based baseline in mitigating forgetting, and significantly improving retrieval performance on new corpora.",
    "summary": "arXiv:2406.12593v4 Announce Type: replace-cross Abstract: Differentiable Search Index (DSI) utilizes pre-trained language models to perform indexing and document retrieval via end-to-end learning without relying on external indexes. However, DSI requires full re-training to index new documents, causing significant computational inefficiencies. Continual learning (CL) offers a solution by enabling the model to incrementally update without full re-training. Existing CL solutions in document retrieval rely on memory buffers or generative models for rehearsal, which is infeasible when accessing previous training data is restricted due to privacy concerns. To this end, we introduce PromptDSI, a prompt-based, rehearsal-free continual learning approach for document retrieval. PromptDSI follows the Prompt-based Continual Learning (PCL) framework, using learnable prompts to efficiently index new documents without accessing previous documents or queries. To improve retrieval latency, we remove the initial forward pass of PCL, which otherwise greatly increases training and inference time, with a negligible trade-off in performance. Additionally, we introduce a novel topic-aware prompt pool that employs neural topic embeddings as fixed keys, eliminating the instability of prompt key optimization while maintaining competitive performance with existing PCL prompt pools. In a challenging rehearsal-free continual learning setup, we demonstrate that PromptDSI variants outperform rehearsal-based baselines, match the strong cache-based baseline in mitigating forgetting, and significantly improving retrieval performance on new corpora.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.12593",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How Hugging Face Scaled Secrets Management for AI Infrastructure",
    "description": "",
    "summary": "How Hugging Face Scaled Secrets Management for AI Infrastructure Hugging Face has become synonymous ...",
    "pubDate": "Mon, 31 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/scaling-secrets-management",
    "thumbnail": "https://huggingface.co/blog/assets/infisical/thumbnail.png"
  },
  {
    "title": "Powerful ASR + diarization + speculative decoding with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Powerful ASR + diarization + speculative decoding with Hugging Face Inference Endpoints Whisper is o...",
    "pubDate": "Wed, 01 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/asr-diarization",
    "thumbnail": "https://huggingface.co/blog/assets/asr-diarization/thumbnail.png"
  },
  {
    "title": "Introducing Whisper",
    "description": "We‚Äôve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech¬†recognition.",
    "summary": "We‚Äôve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech¬†recognition.",
    "pubDate": "Wed, 21 Sep 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/whisper",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning",
    "description": "arXiv:2503.11655v2 Announce Type: replace-cross Abstract: Large language models (LLMs) have transformed sentiment analysis, yet balancing accuracy, efficiency, and explainability remains a critical challenge. This study presents the first comprehensive evaluation of DeepSeek-R1--an open-source reasoning model--against OpenAI's GPT-4o and GPT-4o-mini. We test the full 671B model and its distilled variants, systematically documenting few-shot learning curves. Our experiments show DeepSeek-R1 achieves a 91.39% F1 score on 5-class sentiment and 99.31% accuracy on binary tasks with just 5 shots, an eightfold improvement in few-shot efficiency over GPT-4o. Architecture-specific distillation effects emerge, where a 32B Qwen2.5-based model outperforms the 70B Llama-based variant by 6.69 percentage points. While its reasoning process reduces throughput, DeepSeek-R1 offers superior explainability via transparent, step-by-step traces, establishing it as a powerful, interpretable open-source alternative.",
    "summary": "arXiv:2503.11655v2 Announce Type: replace-cross Abstract: Large language models (LLMs) have transformed sentiment analysis, yet balancing accuracy, efficiency, and explainability remains a critical challenge. This study presents the first comprehensive evaluation of DeepSeek-R1--an open-source reasoning model--against OpenAI's GPT-4o and GPT-4o-mini. We test the full 671B model and its distilled variants, systematically documenting few-shot learning curves. Our experiments show DeepSeek-R1 achieves a 91.39% F1 score on 5-class sentiment and 99.31% accuracy on binary tasks with just 5 shots, an eightfold improvement in few-shot efficiency over GPT-4o. Architecture-specific distillation effects emerge, where a 32B Qwen2.5-based model outperforms the 70B Llama-based variant by 6.69 percentage points. While its reasoning process reduces throughput, DeepSeek-R1 offers superior explainability via transparent, step-by-step traces, establishing it as a powerful, interpretable open-source alternative.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.11655",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI standardizes on PyTorch",
    "description": "We are standardizing OpenAI‚Äôs deep learning framework on¬†PyTorch.",
    "summary": "We are standardizing OpenAI‚Äôs deep learning framework on¬†PyTorch.",
    "pubDate": "Thu, 30 Jan 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-pytorch",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Inroads to personalized AI trip planning",
    "description": "A new framework from the MIT-IBM Watson AI Lab supercharges language models, so they can reason over, interactively develop, and verify valid, complex travel agendas.",
    "summary": "A new framework from the MIT-IBM Watson AI Lab supercharges language models, so they can reason over, interactively develop, and verify valid, complex travel agendas.",
    "pubDate": "Tue, 10 Jun 2025 15:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/inroads-personalized-ai-trip-planning-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-watson-travel-planning.jpg"
  },
  {
    "title": "The San Antonio Spurs use ChatGPT to scale impact on and off the court",
    "description": "Discover how the San Antonio Spurs are using custom GPTs to enhance fan engagement, streamline operations, and drive innovation across teams.",
    "summary": "Discover how the San Antonio Spurs are using custom GPTs to enhance fan engagement, streamline operations, and drive innovation across teams.",
    "pubDate": "Wed, 07 May 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/san-antonio-spurs",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Attacking machine learning with adversarial examples",
    "description": "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they‚Äôre like optical illusions for machines. In this post we‚Äôll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult.",
    "summary": "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they‚Äôre like optical illusions for machines. In this post we‚Äôll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult.",
    "pubDate": "Fri, 24 Feb 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/attacking-machine-learning-with-adversarial-examples",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions",
    "description": "arXiv:2506.23046v1 Announce Type: cross Abstract: Humans continuously infer the states, goals, and behaviors of others by perceiving their surroundings in dynamic, real-world social interactions. However, most Theory of Mind (ToM) benchmarks only evaluate static, text-based scenarios, which have a significant gap compared to real interactions. We propose the SoMi-ToM benchmark, designed to evaluate multi-perspective ToM in embodied multi-agent complex social interactions. This benchmark is based on rich multimodal interaction data generated by the interaction environment SoMi, covering diverse crafting goals and social relationships. Our framework supports multi-level evaluation: (1) first-person evaluation provides multimodal (visual, dialogue, action, etc.) input from a first-person perspective during a task for real-time state inference, (2) third-person evaluation provides complete third-person perspective video and text records after a task for goal and behavior inference. This evaluation method allows for a more comprehensive examination of a model's ToM capabilities from both the subjective immediate experience and the objective global observation. We constructed a challenging dataset containing 35 third-person perspective videos, 363 first-person perspective images, and 1225 expert-annotated multiple-choice questions (three options). On this dataset, we systematically evaluated the performance of human subjects and several state-of-the-art large vision-language models (LVLMs). The results show that LVLMs perform significantly worse than humans on SoMi-ToM: the average accuracy gap between humans and models is 40.1% in first-person evaluation and 26.4% in third-person evaluation. This indicates that future LVLMs need to further improve their ToM capabilities in embodied, complex social interactions.",
    "summary": "arXiv:2506.23046v1 Announce Type: cross Abstract: Humans continuously infer the states, goals, and behaviors of others by perceiving their surroundings in dynamic, real-world social interactions. However, most Theory of Mind (ToM) benchmarks only evaluate static, text-based scenarios, which have a significant gap compared to real interactions. We propose the SoMi-ToM benchmark, designed to evaluate multi-perspective ToM in embodied multi-agent complex social interactions. This benchmark is based on rich multimodal interaction data generated by the interaction environment SoMi, covering diverse crafting goals and social relationships. Our framework supports multi-level evaluation: (1) first-person evaluation provides multimodal (visual, dialogue, action, etc.) input from a first-person perspective during a task for real-time state inference, (2) third-person evaluation provides complete third-person perspective video and text records after a task for goal and behavior inference. This evaluation method allows for a more comprehensive examination of a model's ToM capabilities from both the subjective immediate experience and the objective global observation. We constructed a challenging dataset containing 35 third-person perspective videos, 363 first-person perspective images, and 1225 expert-annotated multiple-choice questions (three options). On this dataset, we systematically evaluated the performance of human subjects and several state-of-the-art large vision-language models (LVLMs). The results show that LVLMs perform significantly worse than humans on SoMi-ToM: the average accuracy gap between humans and models is 40.1% in first-person evaluation and 26.4% in third-person evaluation. This indicates that future LVLMs need to further improve their ToM capabilities in embodied, complex social interactions.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23046",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face Selected for the French Data Protection Agency Enhanced Support Program",
    "description": "",
    "summary": "Hugging Face Selected for the French Data Protection Agency Enhanced Support Program This blog post ...",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cnil",
    "thumbnail": "https://huggingface.co/blog/assets/146_cnil-accompaniment/logo.png"
  },
  {
    "title": "OpenAI o3-mini",
    "description": "Pushing the frontier of cost-effective reasoning.",
    "summary": "Pushing the frontier of cost-effective reasoning.",
    "pubDate": "Fri, 31 Jan 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o3-mini",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Looking ahead to the AI Seoul Summit",
    "description": "How summits in Seoul, France and beyond can galvanize international cooperation on frontier AI safety",
    "summary": "How summits in Seoul, France and beyond can galvanize international cooperation on frontier AI safety",
    "pubDate": "Mon, 20 May 2024 07:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/looking-ahead-to-the-ai-seoul-summit/",
    "thumbnail": "https://lh3.googleusercontent.com/LuT46lyRujmyyTlxwixL9_e8LKvzqZOGUyQUAFbTO6POaYlAqWYfEMag39UkZGsZhjs3SmW3V-s0dCjK4_81jpezAzL7c6kXuTY2MhXbv5yR4NDG8Q=w1200-h630-n-nu"
  },
  {
    "title": "How should AI systems behave, and who should decide?",
    "description": "We‚Äôre clarifying how ChatGPT‚Äôs behavior is shaped and our plans for improving that behavior, allowing more user customization, and getting more public input into our decision-making in these¬†areas.",
    "summary": "We‚Äôre clarifying how ChatGPT‚Äôs behavior is shaped and our plans for improving that behavior, allowing more user customization, and getting more public input into our decision-making in these¬†areas.",
    "pubDate": "Thu, 16 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-should-ai-systems-behave",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Google releases Gemma 2 2B, ShieldGemma and Gemma Scope",
    "description": "",
    "summary": "Google releases Gemma 2 2B, ShieldGemma and Gemma Scope One month after the release of Gemma 2, Goog...",
    "pubDate": "Wed, 31 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma-july-update",
    "thumbnail": "https://huggingface.co/blog/assets/gemma-july-update/thumbnail.jpg"
  },
  {
    "title": "Welcome PaddlePaddle to the Hugging Face Hub",
    "description": "",
    "summary": "Welcome PaddlePaddle to the Hugging Face Hub We are happy to share an open source collaboration betw...",
    "pubDate": "Tue, 17 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paddlepaddle",
    "thumbnail": "https://huggingface.co/blog/assets/126_paddlepaddle/thumbnail.jpg"
  },
  {
    "title": "Frontier risk and preparedness",
    "description": "To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge.",
    "summary": "To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge.",
    "pubDate": "Thu, 26 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-risk-and-preparedness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Exploring the Daily Papers Page on Hugging Face",
    "description": "",
    "summary": "Exploring the Daily Papers Page on Hugging Face In the fast-paced world of research, staying up-to-d...",
    "pubDate": "Mon, 23 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/daily-papers",
    "thumbnail": "https://huggingface.co/blog/assets/daily-papers/thumbnail.png"
  },
  {
    "title": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "description": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "summary": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "pubDate": "Tue, 14 May 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/collaborating-with-carlyle-to-chart-the-future-of-private-equity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenRAIL: Towards open and responsible AI licensing frameworks",
    "description": "",
    "summary": "OpenRAIL: Towards open and responsible AI licensing frameworks Open & Responsible AI licenses ('Open...",
    "pubDate": "Wed, 31 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open_rail",
    "thumbnail": "https://huggingface.co/blog/assets/100_open_rail/100_open-rail.png"
  },
  {
    "title": "Moving from intent-based bots to proactive AI agents",
    "description": "Moving from intent-based bots to proactive AI agents.",
    "summary": "Moving from intent-based bots to proactive AI agents.",
    "pubDate": "Thu, 27 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zendesk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster fine-tuning using TRL & Unsloth",
    "description": "",
    "summary": "Make LLM Fine-tuning 2x faster with Unsloth and ü§ó TRL Pulling your hair out because LLM fine-tuning ...",
    "pubDate": "Wed, 10 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unsloth-trl",
    "thumbnail": "https://huggingface.co/blog/assets/hf_unsloth/thumbnail.png"
  },
  {
    "title": "AI Policy @ü§ó: Response to the U.S. NTIA's Request for Comment on AI Accountability",
    "description": "",
    "summary": "AI Policy @ü§ó: Response to the U.S. National Telecommunications and Information Administration‚Äôs (NTI...",
    "pubDate": "Tue, 20 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/policy-ntia-rfc",
    "thumbnail": "https://huggingface.co/blog/assets/151_policy_ntia_rfc/us_policy_thumbnail.png"
  },
  {
    "title": "Deep Support Vectors",
    "description": "arXiv:2403.17329v3 Announce Type: replace-cross Abstract: Deep learning has achieved tremendous success. However, unlike SVMs, which provide direct decision criteria and can be trained with a small dataset, it still has significant weaknesses due to its requirement for massive datasets during training and the black-box characteristics on decision criteria. This paper addresses these issues by identifying support vectors in deep learning models. To this end, we propose the DeepKKT condition, an adaptation of the traditional Karush-Kuhn-Tucker (KKT) condition for deep learning models, and confirm that generated Deep Support Vectors (DSVs) using this condition exhibit properties similar to traditional support vectors. This allows us to apply our method to few-shot dataset distillation problems and alleviate the black-box characteristics of deep learning models. Additionally, we demonstrate that the DeepKKT condition can transform conventional classification models into generative models with high fidelity, particularly as latent generative models using class labels as latent variables. We validate the effectiveness of DSVs using common datasets (ImageNet, CIFAR10 and CIFAR100) on the general architectures (ResNet and ConvNet), proving their practical applicability.",
    "summary": "arXiv:2403.17329v3 Announce Type: replace-cross Abstract: Deep learning has achieved tremendous success. However, unlike SVMs, which provide direct decision criteria and can be trained with a small dataset, it still has significant weaknesses due to its requirement for massive datasets during training and the black-box characteristics on decision criteria. This paper addresses these issues by identifying support vectors in deep learning models. To this end, we propose the DeepKKT condition, an adaptation of the traditional Karush-Kuhn-Tucker (KKT) condition for deep learning models, and confirm that generated Deep Support Vectors (DSVs) using this condition exhibit properties similar to traditional support vectors. This allows us to apply our method to few-shot dataset distillation problems and alleviate the black-box characteristics of deep learning models. Additionally, we demonstrate that the DeepKKT condition can transform conventional classification models into generative models with high fidelity, particularly as latent generative models using class labels as latent variables. We validate the effectiveness of DSVs using common datasets (ImageNet, CIFAR10 and CIFAR100) on the general architectures (ResNet and ConvNet), proving their practical applicability.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2403.17329",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation",
    "description": "",
    "summary": "StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation Instruction...",
    "pubDate": "Mon, 29 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sc2-instruct",
    "thumbnail": "https://huggingface.co/blog/assets/sc2-instruct/sc2-instruct-banner.png"
  },
  {
    "title": "How to Build an MCP Server with Gradio",
    "description": "",
    "summary": "How to Build an MCP Server in 5 Lines of Python Gradio is a Python library used by more than 1 milli...",
    "pubDate": "Wed, 30 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-mcp",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-mcp/thumbnail.png"
  },
  {
    "title": "Delivering nuanced insights from customer feedback",
    "description": "Using GPT-3 to deliver fast, nuanced insights from customer feedback.",
    "summary": "Using GPT-3 to deliver fast, nuanced insights from customer feedback.",
    "pubDate": "Wed, 04 Jan 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/yabble",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Visualize and understand GPU memory in PyTorch",
    "description": "",
    "summary": "Visualize and understand GPU memory in PyTorch You must be familiar with this message ü§¨: RuntimeErro...",
    "pubDate": "Tue, 24 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train_memory",
    "thumbnail": "https://huggingface.co/blog/assets/train_memory/thumbnail.png"
  },
  {
    "title": "Watermarking AI-generated text and video with SynthID",
    "description": "Announcing our novel watermarking method for AI-generated text and video, and how we‚Äôre bringing SynthID to key Google products",
    "summary": "Announcing our novel watermarking method for AI-generated text and video, and how we‚Äôre bringing SynthID to key Google products",
    "pubDate": "Tue, 14 May 2024 17:56:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/watermarking-ai-generated-text-and-video-with-synthid/",
    "thumbnail": "https://lh3.googleusercontent.com/I6bH75hNf57977cub27rFEsgxhcmkLrcINfCmGUaBCr7Q1bFTIl552R_6kuqlSkUjRtsTh929u6NoQmtHcwIG-GnjvPqMeynVLY0Rc9RRvezPQS0=w1200-h630-n-nu"
  },
  {
    "title": "Introducing the Data Measurements Tool: an Interactive Tool for Looking at Datasets",
    "description": "",
    "summary": "Introducing the ü§ó Data Measurements Tool: an Interactive Tool for Looking at Datasets tl;dr: We made...",
    "pubDate": "Mon, 29 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/data-measurements-tool",
    "thumbnail": "https://huggingface.co/blog/assets/37_data-measurements-tool/datametrics.png"
  },
  {
    "title": "Creating next-gen characters",
    "description": "Using GPT-3 to create the next generation of AI-powered characters.",
    "summary": "Using GPT-3 to create the next generation of AI-powered characters.",
    "pubDate": "Sun, 01 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/inworld-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ü§ó PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware",
    "description": "",
    "summary": "ü§ó PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware Motivation ...",
    "pubDate": "Fri, 10 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/peft",
    "thumbnail": "https://huggingface.co/blog/assets/130_peft/thumbnail.png"
  },
  {
    "title": "DALL¬∑E now available in beta",
    "description": "We‚Äôll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL¬∑E using free credits that refill every month, and buy additional credits in 115-generation increments for¬†$15.",
    "summary": "We‚Äôll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL¬∑E using free credits that refill every month, and buy additional credits in 115-generation increments for¬†$15.",
    "pubDate": "Wed, 20 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-now-available-in-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Trace & Evaluate your Agent with Arize Phoenix",
    "description": "",
    "summary": "Trace & Evaluate your Agent with Arize Phoenix So, you‚Äôve built your agent. It takes in inputs and t...",
    "pubDate": "Fri, 28 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents-phoenix",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents-phoenix/thumbnail.jpg"
  },
  {
    "title": "RoboCat: A self-improving robotic agent",
    "description": "Robots are quickly becoming part of our everyday lives, but they‚Äôre often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data.¬†Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.",
    "summary": "Robots are quickly becoming part of our everyday lives, but they‚Äôre often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data.¬†Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.",
    "pubDate": "Tue, 20 Jun 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/robocat-a-self-improving-robotic-agent/",
    "thumbnail": "https://lh3.googleusercontent.com/Rz9Xv4TXuTe-eO2UDUD6kDElDB5wDE2b2hEU1liUAi0AyiTwQ81mLMigXg3kueWrHoqeNctRO5-EMprZDRnXcaL8snfqHwDqgQpw_qB3VEvoO_jCCzI=w1200-h630-n-nu"
  },
  {
    "title": "XLSCOUT Unveils ParaEmbed 2.0: a Powerful Embedding Model Tailored for Patents and IP with Expert Support from Hugging Face",
    "description": "",
    "summary": "XLSCOUT Unveils ParaEmbed 2.0: a Powerful Embedding Model Tailored for Patents and IP with Expert Su...",
    "pubDate": "Tue, 25 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xlscout-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/xlscout-case-study/thumbnail.png"
  },
  {
    "title": "GPT-4o System Card",
    "description": "This report outlines the safety work carried out prior to releasing GPT-4o including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "summary": "This report outlines the safety work carried out prior to releasing GPT-4o including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Age of Machine Learning As Code Has Arrived",
    "description": "",
    "summary": "The Age of Machine Learning As Code Has Arrived The 2021 edition of the State of AI Report came out ...",
    "pubDate": "Wed, 20 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the-age-of-ml-as-code",
    "thumbnail": "https://huggingface.co/blog/assets/31_age_of_ml_as_code/05_vision_transformer.png"
  },
  {
    "title": "An Introduction to Q-Learning Part 1",
    "description": "",
    "summary": "An Introduction to Q-Learning Part 1 Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 2, p...",
    "pubDate": "Wed, 18 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-q-part1",
    "thumbnail": "https://huggingface.co/blog/assets/70_deep_rl_q_part1/thumbnail.gif"
  },
  {
    "title": "AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models",
    "description": "arXiv:2506.23949v1 Announce Type: new Abstract: Increasingly multi-purpose AI models, such as cutting-edge large language models or other 'general-purpose AI' (GPAI) models, 'foundation models,' generative AI models, and 'frontier models' (typically all referred to hereafter with the umbrella term 'GPAI/foundation models' except where greater specificity is needed), can provide many beneficial capabilities but also risks of adverse events with profound consequences. This document provides risk-management practices or controls for identifying, analyzing, and mitigating risks of GPAI/foundation models. We intend this document primarily for developers of large-scale, state-of-the-art GPAI/foundation models; others that can benefit from this guidance include downstream developers of end-use applications that build on a GPAI/foundation model. This document facilitates conformity with or use of leading AI risk management-related standards, adapting and building on the generic voluntary guidance in the NIST AI Risk Management Framework and ISO/IEC 23894, with a focus on the unique issues faced by developers of GPAI/foundation models.",
    "summary": "arXiv:2506.23949v1 Announce Type: new Abstract: Increasingly multi-purpose AI models, such as cutting-edge large language models or other 'general-purpose AI' (GPAI) models, 'foundation models,' generative AI models, and 'frontier models' (typically all referred to hereafter with the umbrella term 'GPAI/foundation models' except where greater specificity is needed), can provide many beneficial capabilities but also risks of adverse events with profound consequences. This document provides risk-management practices or controls for identifying, analyzing, and mitigating risks of GPAI/foundation models. We intend this document primarily for developers of large-scale, state-of-the-art GPAI/foundation models; others that can benefit from this guidance include downstream developers of end-use applications that build on a GPAI/foundation model. This document facilitates conformity with or use of leading AI risk management-related standards, adapting and building on the generic voluntary guidance in the NIST AI Risk Management Framework and ISO/IEC 23894, with a focus on the unique issues faced by developers of GPAI/foundation models.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23949",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Mitigating Gambling-Like Risk-Taking Behaviors in Large Language Models: A Behavioral Economics Approach to AI Safety",
    "description": "arXiv:2506.22496v1 Announce Type: cross Abstract: Large Language Models (LLMs) exhibit systematic risk-taking behaviors analogous to those observed in gambling psychology, including overconfidence bias, loss-chasing tendencies, and probability misjudgment. Drawing from behavioral economics and prospect theory, we identify and formalize these 'gambling-like' patterns where models sacrifice accuracy for high-reward outputs, exhibit escalating risk-taking after errors, and systematically miscalibrate uncertainty. We propose the Risk-Aware Response Generation (RARG) framework, incorporating insights from gambling research to address these behavioral biases through risk-calibrated training, loss-aversion mechanisms, and uncertainty-aware decision making. Our approach introduces novel evaluation paradigms based on established gambling psychology experiments, including AI adaptations of the Iowa Gambling Task and probability learning assessments. Experimental results demonstrate measurable reductions in gambling-like behaviors: 18.7% decrease in overconfidence bias, 24.3% reduction in loss-chasing tendencies, and improved risk calibration across diverse scenarios. This work establishes the first systematic framework for understanding and mitigating gambling psychology patterns in AI systems.",
    "summary": "arXiv:2506.22496v1 Announce Type: cross Abstract: Large Language Models (LLMs) exhibit systematic risk-taking behaviors analogous to those observed in gambling psychology, including overconfidence bias, loss-chasing tendencies, and probability misjudgment. Drawing from behavioral economics and prospect theory, we identify and formalize these 'gambling-like' patterns where models sacrifice accuracy for high-reward outputs, exhibit escalating risk-taking after errors, and systematically miscalibrate uncertainty. We propose the Risk-Aware Response Generation (RARG) framework, incorporating insights from gambling research to address these behavioral biases through risk-calibrated training, loss-aversion mechanisms, and uncertainty-aware decision making. Our approach introduces novel evaluation paradigms based on established gambling psychology experiments, including AI adaptations of the Iowa Gambling Task and probability learning assessments. Experimental results demonstrate measurable reductions in gambling-like behaviors: 18.7% decrease in overconfidence bias, 24.3% reduction in loss-chasing tendencies, and improved risk calibration across diverse scenarios. This work establishes the first systematic framework for understanding and mitigating gambling psychology patterns in AI systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22496",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DABstep: Data Agent Benchmark for Multi-step Reasoning",
    "description": "arXiv:2506.23719v1 Announce Type: cross Abstract: We introduce DABstep, a novel benchmark for evaluating AI agents on realistic multi-step data analysis tasks. DABstep comprises over 450 real-world challenges derived from a financial analytics platform, requiring models to combine code-based data processing with contextual reasoning over heterogeneous documentation. Each task demands an iterative, multi-step problem-solving approach, testing capabilities in data manipulation, cross-referencing multiple sources, and precise result reporting. The benchmark provides a factoid-style answer format with automatic correctness checks for objective scoring at scale. We evaluate leading LLM-based agents, revealing a substantial performance gap: even the best agent achieves only 14.55% accuracy on the hardest tasks. We detail our benchmark's design, dataset composition, task formulation, evaluation protocol, report baseline results and analyze failure modes. DABstep is released with a public leaderboard and toolkit to accelerate research in autonomous data analysis.",
    "summary": "arXiv:2506.23719v1 Announce Type: cross Abstract: We introduce DABstep, a novel benchmark for evaluating AI agents on realistic multi-step data analysis tasks. DABstep comprises over 450 real-world challenges derived from a financial analytics platform, requiring models to combine code-based data processing with contextual reasoning over heterogeneous documentation. Each task demands an iterative, multi-step problem-solving approach, testing capabilities in data manipulation, cross-referencing multiple sources, and precise result reporting. The benchmark provides a factoid-style answer format with automatic correctness checks for objective scoring at scale. We evaluate leading LLM-based agents, revealing a substantial performance gap: even the best agent achieves only 14.55% accuracy on the hardest tasks. We detail our benchmark's design, dataset composition, task formulation, evaluation protocol, report baseline results and analyze failure modes. DABstep is released with a public leaderboard and toolkit to accelerate research in autonomous data analysis.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23719",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sharing the latest Model Spec",
    "description": "We‚Äôve made updates to the Model Spec based on external feedback and our continued research in shaping desired model behavior.",
    "summary": "We‚Äôve made updates to the Model Spec based on external feedback and our continued research in shaping desired model behavior.",
    "pubDate": "Wed, 12 Feb 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sharing-the-latest-model-spec",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Student-AI Interaction Through Pedagogical Prompting: An Example in Computer Science Education",
    "description": "arXiv:2506.19107v2 Announce Type: replace-cross Abstract: With the proliferation of large language model (LLM) applications since 2022, their use in education has sparked both excitement and concern. Recent studies consistently highlight students' (mis)use of LLMs can hinder learning outcomes. This work aims to teach students how to effectively prompt LLMs to improve their learning. We first proposed pedagogical prompting, a theoretically-grounded new concept to elicit learning-oriented responses from LLMs. To move from concept design to a proof-of-concept learning intervention in real educational settings, we selected early undergraduate CS education (CS1/CS2) as the example context. We began with a formative survey study with instructors (N=36) teaching early-stage undergraduate-level CS courses to inform the instructional design based on classroom needs. Based on their insights, we designed and developed a learning intervention through an interactive system with scenario-based instruction to train pedagogical prompting skills. Finally, we evaluated its instructional effectiveness through a user study with CS novice students (N=22) using pre/post-tests. Through mixed methods analyses, our results indicate significant improvements in learners' LLM-based pedagogical help-seeking skills, along with positive attitudes toward the system and increased willingness to use pedagogical prompts in the future. Our contributions include (1) a theoretical framework of pedagogical prompting; (2) empirical insights into current instructor attitudes toward pedagogical prompting; and (3) a learning intervention design with an interactive learning tool and scenario-based instruction leading to promising results on teaching LLM-based help-seeking. Our approach is scalable for broader implementation in classrooms and has the potential to be integrated into tools like ChatGPT as an on-boarding experience to encourage learning-oriented use of generative AI.",
    "summary": "arXiv:2506.19107v2 Announce Type: replace-cross Abstract: With the proliferation of large language model (LLM) applications since 2022, their use in education has sparked both excitement and concern. Recent studies consistently highlight students' (mis)use of LLMs can hinder learning outcomes. This work aims to teach students how to effectively prompt LLMs to improve their learning. We first proposed pedagogical prompting, a theoretically-grounded new concept to elicit learning-oriented responses from LLMs. To move from concept design to a proof-of-concept learning intervention in real educational settings, we selected early undergraduate CS education (CS1/CS2) as the example context. We began with a formative survey study with instructors (N=36) teaching early-stage undergraduate-level CS courses to inform the instructional design based on classroom needs. Based on their insights, we designed and developed a learning intervention through an interactive system with scenario-based instruction to train pedagogical prompting skills. Finally, we evaluated its instructional effectiveness through a user study with CS novice students (N=22) using pre/post-tests. Through mixed methods analyses, our results indicate significant improvements in learners' LLM-based pedagogical help-seeking skills, along with positive attitudes toward the system and increased willingness to use pedagogical prompts in the future. Our contributions include (1) a theoretical framework of pedagogical prompting; (2) empirical insights into current instructor attitudes toward pedagogical prompting; and (3) a learning intervention design with an interactive learning tool and scenario-based instruction leading to promising results on teaching LLM-based help-seeking. Our approach is scalable for broader implementation in classrooms and has the potential to be integrated into tools like ChatGPT as an on-boarding experience to encourage learning-oriented use of generative AI.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19107",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Confidence-Building Measures for Artificial Intelligence: Workshop proceedings",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 01 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/confidence-building-measures-for-artificial-intelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GaLore: Advancing Large Model Training on Consumer-grade Hardware",
    "description": "",
    "summary": "GaLore: Advancing Large Model Training on Consumer-grade Hardware The integration of GaLore into the...",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/galore",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "OpenAI o3 and o4-mini System Card",
    "description": "OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities‚Äîweb browsing, Python, image and file analysis, image generation, canvas, automations, file search, and memory.",
    "summary": "OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities‚Äîweb browsing, Python, image and file analysis, image generation, canvas, automations, file search, and memory.",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploying ü§ó ViT on Kubernetes with TF Serving",
    "description": "",
    "summary": "Deploying ü§ó ViT on Kubernetes with TF Serving In the previous post, we showed how to deploy a Vision...",
    "pubDate": "Thu, 11 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-tfserving-kubernetes",
    "thumbnail": "https://huggingface.co/blog/assets/94_tf_serving_kubernetes/thumb.png"
  },
  {
    "title": "SetFit: Efficient Few-Shot Learning Without Prompts",
    "description": "",
    "summary": "SetFit: Efficient Few-Shot Learning Without Prompts SetFit is significantly more sample efficient an...",
    "pubDate": "Mon, 26 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit",
    "thumbnail": "https://huggingface.co/blog/assets/103_setfit/intel_hf_logo.png"
  },
  {
    "title": "Showcase Your Projects in Spaces using Gradio",
    "description": "",
    "summary": "Showcase Your Projects in Spaces using Gradio It's so easy to demonstrate a Machine Learning project...",
    "pubDate": "Tue, 05 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/28_gradio-spaces/thumbnail.png"
  },
  {
    "title": "Text and code embeddings by contrastive pre-training",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 24 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/text-and-code-embeddings-by-contrastive-pre-training",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Creativity in AI: Progresses and Challenges",
    "description": "arXiv:2410.17218v5 Announce Type: replace Abstract: Creativity is the ability to produce novel, useful, and surprising ideas, and has been widely studied as a crucial aspect of human cognition. Machine creativity on the other hand has been a long-standing challenge. With the rise of advanced generative AI, there has been renewed interest and debate regarding AI's creative capabilities. Therefore, it is imperative to revisit the state of creativity in AI and identify key progresses and remaining challenges. In this work, we survey leading works studying the creative capabilities of AI systems, focusing on creative problem-solving, linguistic, artistic, and scientific creativity. Our review suggests that while the latest AI models are largely capable of producing linguistically and artistically creative outputs such as poems, images, and musical pieces, they struggle with tasks that require creative problem-solving, abstract thinking and compositionality and their generations suffer from a lack of diversity, originality, long-range incoherence and hallucinations. We also discuss key questions concerning copyright and authorship issues with generative models. Furthermore, we highlight the need for a comprehensive evaluation of creativity that is process-driven and considers several dimensions of creativity. Finally, we propose future research directions to improve the creativity of AI outputs, drawing inspiration from cognitive science and psychology.",
    "summary": "arXiv:2410.17218v5 Announce Type: replace Abstract: Creativity is the ability to produce novel, useful, and surprising ideas, and has been widely studied as a crucial aspect of human cognition. Machine creativity on the other hand has been a long-standing challenge. With the rise of advanced generative AI, there has been renewed interest and debate regarding AI's creative capabilities. Therefore, it is imperative to revisit the state of creativity in AI and identify key progresses and remaining challenges. In this work, we survey leading works studying the creative capabilities of AI systems, focusing on creative problem-solving, linguistic, artistic, and scientific creativity. Our review suggests that while the latest AI models are largely capable of producing linguistically and artistically creative outputs such as poems, images, and musical pieces, they struggle with tasks that require creative problem-solving, abstract thinking and compositionality and their generations suffer from a lack of diversity, originality, long-range incoherence and hallucinations. We also discuss key questions concerning copyright and authorship issues with generative models. Furthermore, we highlight the need for a comprehensive evaluation of creativity that is process-driven and considers several dimensions of creativity. Finally, we propose future research directions to improve the creativity of AI outputs, drawing inspiration from cognitive science and psychology.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.17218",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CPU Optimized Embeddings with ü§ó Optimum Intel and fastRAG",
    "description": "",
    "summary": "CPU Optimized Embeddings with ü§ó Optimum Intel and fastRAG Embedding models are useful for many appli...",
    "pubDate": "Fri, 15 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-fast-embedding",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Harnessing Shared Relations via Multimodal Mixup Contrastive Learning for Multimodal Classification",
    "description": "arXiv:2409.17777v4 Announce Type: replace-cross Abstract: Deep multimodal learning has shown remarkable success by leveraging contrastive learning to capture explicit one-to-one relations across modalities. However, real-world data often exhibits shared relations beyond simple pairwise associations. We propose M3CoL, a Multimodal Mixup Contrastive Learning approach to capture nuanced shared relations inherent in multimodal data. Our key contribution is a Mixup-based contrastive loss that learns robust representations by aligning mixed samples from one modality with their corresponding samples from other modalities thereby capturing shared relations between them. For multimodal classification tasks, we introduce a framework that integrates a fusion module with unimodal prediction modules for auxiliary supervision during training, complemented by our proposed Mixup-based contrastive loss. Through extensive experiments on diverse datasets (N24News, ROSMAP, BRCA, and Food-101), we demonstrate that M3CoL effectively captures shared multimodal relations and generalizes across domains. It outperforms state-of-the-art methods on N24News, ROSMAP, and BRCA, while achieving comparable performance on Food-101. Our work highlights the significance of learning shared relations for robust multimodal learning, opening up promising avenues for future research. Our code is publicly available at https://github.com/RaghavSinghal10/M3CoL.",
    "summary": "arXiv:2409.17777v4 Announce Type: replace-cross Abstract: Deep multimodal learning has shown remarkable success by leveraging contrastive learning to capture explicit one-to-one relations across modalities. However, real-world data often exhibits shared relations beyond simple pairwise associations. We propose M3CoL, a Multimodal Mixup Contrastive Learning approach to capture nuanced shared relations inherent in multimodal data. Our key contribution is a Mixup-based contrastive loss that learns robust representations by aligning mixed samples from one modality with their corresponding samples from other modalities thereby capturing shared relations between them. For multimodal classification tasks, we introduce a framework that integrates a fusion module with unimodal prediction modules for auxiliary supervision during training, complemented by our proposed Mixup-based contrastive loss. Through extensive experiments on diverse datasets (N24News, ROSMAP, BRCA, and Food-101), we demonstrate that M3CoL effectively captures shared multimodal relations and generalizes across domains. It outperforms state-of-the-art methods on N24News, ROSMAP, and BRCA, while achieving comparable performance on Food-101. Our work highlights the significance of learning shared relations for robust multimodal learning, opening up promising avenues for future research. Our code is publicly available at https://github.com/RaghavSinghal10/M3CoL.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.17777",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Newsroom AI Catalyst: a global program with WAN-IFRA",
    "description": "We‚Äôre collaborating with WAN-IFRA, the World Association of News Publishers, to launch a global accelerator program that will assist over 100 news publishers to explore and integrate AI in their newsroom.",
    "summary": "We‚Äôre collaborating with WAN-IFRA, the World Association of News Publishers, to launch a global accelerator program that will assist over 100 news publishers to explore and integrate AI in their newsroom.",
    "pubDate": "Wed, 29 May 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/newsroom-ai-catalyst-global-program-with-wan-ifra",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SmolVLM - small yet mighty Vision Language Model",
    "description": "",
    "summary": "SmolVLM - small yet mighty Vision Language Model TLDR This blog post introduces SmolVLM, a 2B VLM, S...",
    "pubDate": "Tue, 26 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvlm",
    "thumbnail": "https://huggingface.co/blog/assets/smolvlm/banner.png"
  },
  {
    "title": "Addendum to GPT-4o System Card: 4o image generation",
    "description": "4o image generation is a new, significantly more capable image generation approach than our earlier DALL¬∑E 3 series of models. It can create photorealistic output. It can take images as inputs and transform them.",
    "summary": "4o image generation is a new, significantly more capable image generation approach than our earlier DALL¬∑E 3 series of models. It can create photorealistic output. It can take images as inputs and transform them.",
    "pubDate": "Tue, 25 Mar 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-image-generation-system-card-addendum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Delivering LLM-powered health solutions",
    "description": "WHOOP delivers personalized fitness and health coaching with GPT-4.",
    "summary": "WHOOP delivers personalized fitness and health coaching with GPT-4.",
    "pubDate": "Thu, 04 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/whoop",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving language understanding with unsupervised learning",
    "description": "We‚Äôve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we‚Äôre also releasing. Our approach is a combination of two existing ideas:¬†transformers¬†and¬†unsupervised pre-training. These results provide a convincing example that pairing supervised learning methods with unsupervised pre-training works very well; this is an idea that many have explored in the past, and we hope our result motivates further research into applying this idea on larger and more diverse¬†datasets.",
    "summary": "We‚Äôve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we‚Äôre also releasing. Our approach is a combination of two existing ideas:¬†transformers¬†and¬†unsupervised pre-training. These results provide a convincing example that pairing supervised learning methods with unsupervised pre-training works very well; this is an idea that many have explored in the past, and we hope our result motivates further research into applying this idea on larger and more diverse¬†datasets.",
    "pubDate": "Mon, 11 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-unsupervised",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building interactive agents in video game worlds",
    "description": "Most artificial intelligence (AI) researchers now believe that writing computer code which can capture the nuances of situated interactions is impossible. Alternatively, modern machine learning (ML) researchers have focused on learning about these types of interactions from data. To explore these learning-based approaches and quickly build agents that can make sense of human instructions and safely perform actions in open-ended conditions, we created a research framework within a video game environment.Today, we‚Äôre publishing a paper [INSERT LINK] and collection of videos, showing our early steps in building video game AIs that can understand fuzzy human concepts ‚Äì and therefore, can begin to interact with people on their own terms.",
    "summary": "Most artificial intelligence (AI) researchers now believe that writing computer code which can capture the nuances of situated interactions is impossible. Alternatively, modern machine learning (ML) researchers have focused on learning about these types of interactions from data. To explore these learning-based approaches and quickly build agents that can make sense of human instructions and safely perform actions in open-ended conditions, we created a research framework within a video game environment.Today, we‚Äôre publishing a paper [INSERT LINK] and collection of videos, showing our early steps in building video game AIs that can understand fuzzy human concepts ‚Äì and therefore, can begin to interact with people on their own terms.",
    "pubDate": "Wed, 23 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/building-interactive-agents-in-video-game-worlds/",
    "thumbnail": "https://lh3.googleusercontent.com/6DSrkFaInWqKD1eN4IJJN31ZRa3LW447A1ZYoK19FDzJGSLD5dlVw1rJRf52O_dmQUDq11XqYsiqMR8uFDnWLWGkl8xFY5KXYxD7LvQNPvTEuR_h=w1200-h630-n-nu"
  },
  {
    "title": "Dr. Ronnie Chatterji named OpenAI‚Äôs first Chief Economist",
    "description": "Dr. Ronnie Chatterji named OpenAI‚Äôs first Chief Economist",
    "summary": "Dr. Ronnie Chatterji named OpenAI‚Äôs first Chief Economist",
    "pubDate": "Tue, 22 Oct 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-chief-economist-announcement",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Apps in a Flash with Gradio's Reload Mode",
    "description": "",
    "summary": "AI Apps in a Flash with Gradio's Reload Mode In this post, I will show you how you can build a funct...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-reload",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-reload/thumbnail_compressed.png"
  },
  {
    "title": "Transformer-based Encoder-Decoder Models",
    "description": "",
    "summary": "Transformers-based Encoder-Decoder Models !pip install transformers==4.2.1 !pip install sentencepiec...",
    "pubDate": "Sat, 10 Oct 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/encoder-decoder",
    "thumbnail": "https://huggingface.co/blog/assets/05_encoder_decoder/thumbnail.png"
  },
  {
    "title": "Cohere on Hugging Face Inference Providers üî•",
    "description": "",
    "summary": "Cohere on Hugging Face Inference Providers üî• We're thrilled to share that Cohere is now a supported ...",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-cohere",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers-cohere/thumbnail.png"
  },
  {
    "title": "Napkin AIÔºà„Éä„Éó„Ç≠„É≥AIÔºâ„Å®„ÅØÔºü‰Ωø„ÅÑÊñπ„Åã„Çâ„Åã„Åã„ÇãÊñôÈáë„Åæ„ÅßË©≥„Åó„ÅèËß£Ë™¨",
    "description": "<p>‰ªï‰∫ã„Åß‰Ωø„ÅÜÊñáÁ´†„ÇÑ„Ç¢„Ç§„Éá„Ç¢„Çí„Åæ„Å®„ÇÅ„Å¶„Çè„Åã„Çä„ÇÑ„Åô„ÅÑÂΩ¢„ÅßÊï¥ÁêÜ„Åó„Åü„ÅÑ„ÅÆ„Åß„ÄÅ‰Ωï„ÅãËâØ„ÅÑ„ÉÑ„Éº„É´„ÅØ„Å™„ÅÑ„ÅãÊé¢„Åó„Å¶„ÅÑ„Çã„Åë„Çå„Å©„ÄÅ„Å™„Åã„Å™„ÅãË¶ã„Å§„Åã„Çâ„ÅöÂõ∞„Å£„Å¶„ÅÑ„Çã‰∫∫„ÅØ„ÅÑ„Åæ„Åõ„Çì„ÅãÔºü ‰ªï‰∫ã„ÅßÂë®Âõ≤„ÅÆ‰∫∫„Å´Áâ©‰∫ã„Çí„Çè„Åã„Çä„ÇÑ„Åô„ÅèË™¨Êòé„Åô„Çã„Åü„ÇÅ„Å´„ÅØ„ÄÅÊñáÁ´†„Å†„Åë„Åß„ÅØ„Å™„Åè [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/what-is-napkinai/'>Napkin AIÔºà„Éä„Éó„Ç≠„É≥AIÔºâ„Å®„ÅØÔºü‰Ωø„ÅÑÊñπ„Åã„Çâ„Åã„Åã„ÇãÊñôÈáë„Åæ„ÅßË©≥„Åó„ÅèËß£Ë™¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>‰ªï‰∫ã„Åß‰Ωø„ÅÜÊñáÁ´†„ÇÑ„Ç¢„Ç§„Éá„Ç¢„Çí„Åæ„Å®„ÇÅ„Å¶„Çè„Åã„Çä„ÇÑ„Åô„ÅÑÂΩ¢„ÅßÊï¥ÁêÜ„Åó„Åü„ÅÑ„ÅÆ„Åß„ÄÅ‰Ωï„ÅãËâØ„ÅÑ„ÉÑ„Éº„É´„ÅØ„Å™„ÅÑ„ÅãÊé¢„Åó„Å¶„ÅÑ„Çã„Åë„Çå„Å©„ÄÅ„Å™„Åã„Å™„ÅãË¶ã„Å§„Åã„Çâ„ÅöÂõ∞„Å£„Å¶„ÅÑ„Çã‰∫∫„ÅØ„ÅÑ„Åæ„Åõ„Çì„ÅãÔºü ‰ªï‰∫ã„ÅßÂë®Âõ≤„ÅÆ‰∫∫„Å´Áâ©‰∫ã„Çí„Çè„Åã„Çä„ÇÑ„Åô„ÅèË™¨Êòé„Åô„Çã„Åü„ÇÅ„Å´„ÅØ„ÄÅÊñáÁ´†„Å†„Åë„Åß„ÅØ„Å™„Åè [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/what-is-napkinai/'>Napkin AIÔºà„Éä„Éó„Ç≠„É≥AIÔºâ„Å®„ÅØÔºü‰Ωø„ÅÑÊñπ„Åã„Çâ„Åã„Åã„ÇãÊñôÈáë„Åæ„ÅßË©≥„Åó„ÅèËß£Ë™¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Thu, 19 Jun 2025 05:40:52 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/what-is-napkinai/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/02/what-is-dify.jpg"
  },
  {
    "title": "Composing Parts for Expressive Object Generation",
    "description": "arXiv:2406.10197v2 Announce Type: replace-cross Abstract: Image composition and generation are processes where the artists need control over various parts of the generated images. However, the current state-of-the-art generation models, like Stable Diffusion, cannot handle fine-grained part-level attributes in the text prompts. Specifically, when additional attribute details are added to the base text prompt, these text-to-image models either generate an image vastly different from the image generated from the base prompt or ignore the attribute details. To mitigate these issues, we introduce PartComposer, a training-free method that enables image generation based on fine-grained part-level attributes specified for objects in the base text prompt. This allows more control for artists and enables novel object compositions by combining distinctive object parts. PartComposer first localizes object parts by denoising the object region from a specific diffusion process. This enables each part token to be localized to the right region. After obtaining part masks, we run a localized diffusion process in each part region based on fine-grained part attributes and combine them to produce the final image. All stages of PartComposer are based on repurposing a pre-trained diffusion model, which enables it to generalize across domains. We demonstrate the effectiveness of part-level control provided by PartComposer through qualitative visual examples and quantitative comparisons with contemporary baselines.",
    "summary": "arXiv:2406.10197v2 Announce Type: replace-cross Abstract: Image composition and generation are processes where the artists need control over various parts of the generated images. However, the current state-of-the-art generation models, like Stable Diffusion, cannot handle fine-grained part-level attributes in the text prompts. Specifically, when additional attribute details are added to the base text prompt, these text-to-image models either generate an image vastly different from the image generated from the base prompt or ignore the attribute details. To mitigate these issues, we introduce PartComposer, a training-free method that enables image generation based on fine-grained part-level attributes specified for objects in the base text prompt. This allows more control for artists and enables novel object compositions by combining distinctive object parts. PartComposer first localizes object parts by denoising the object region from a specific diffusion process. This enables each part token to be localized to the right region. After obtaining part masks, we run a localized diffusion process in each part region based on fine-grained part attributes and combine them to produce the final image. All stages of PartComposer are based on repurposing a pre-trained diffusion model, which enables it to generalize across domains. We demonstrate the effectiveness of part-level control provided by PartComposer through qualitative visual examples and quantitative comparisons with contemporary baselines.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.10197",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Multi-Goal Reinforcement Learning: Challenging robotics environments and request for research",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 26 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/multi-goal-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI for Education",
    "description": "An affordable offering for universities to responsibly bring AI to campus.",
    "summary": "An affordable offering for universities to responsibly bring AI to campus.",
    "pubDate": "Thu, 30 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-edu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "EFRame: Deeper Reasoning via Exploration-Filter-Replay Reinforcement Learning Framework",
    "description": "arXiv:2506.22200v2 Announce Type: replace-cross Abstract: Recent advances in reinforcement learning (RL) have significantly enhanced the reasoning capabilities of large language models (LLMs). Group Relative Policy Optimization (GRPO), an efficient variant of PPO that lowers RL's computational cost, still faces limited exploration, low sample efficiency and instability, constraining its performance on complex reasoning tasks. To address these limitations, we introduce EFRame, an Exploration-Filtering-Replay framework that systematically augments GRPO along three critical dimensions. EFRame performs additional rollouts to explore high-quality trajectories, applies online filtering to eliminate low-quality samples that introduce noise and variance, and leverages experience replay to repeatedly exploit rare but informative samples. EFRame establishes a complete and stable learning cycle, guiding the model through a structured transition from exploration to convergence. Our experiments across a variety of reasoning benchmarks demonstrate that EFRame not only improves the robustness and efficiency of training, but also enables access to deeper reasoning capabilities that remain unattainable under vanilla GRPO. Furthermore, EFRame enables a more fine-grained categorization of training samples, allowing for a deeper analysis of how different types of samples contribute to the learning process in RL. Our code is available at https://github.com/597358816/EFRame.",
    "summary": "arXiv:2506.22200v2 Announce Type: replace-cross Abstract: Recent advances in reinforcement learning (RL) have significantly enhanced the reasoning capabilities of large language models (LLMs). Group Relative Policy Optimization (GRPO), an efficient variant of PPO that lowers RL's computational cost, still faces limited exploration, low sample efficiency and instability, constraining its performance on complex reasoning tasks. To address these limitations, we introduce EFRame, an Exploration-Filtering-Replay framework that systematically augments GRPO along three critical dimensions. EFRame performs additional rollouts to explore high-quality trajectories, applies online filtering to eliminate low-quality samples that introduce noise and variance, and leverages experience replay to repeatedly exploit rare but informative samples. EFRame establishes a complete and stable learning cycle, guiding the model through a structured transition from exploration to convergence. Our experiments across a variety of reasoning benchmarks demonstrate that EFRame not only improves the robustness and efficiency of training, but also enables access to deeper reasoning capabilities that remain unattainable under vanilla GRPO. Furthermore, EFRame enables a more fine-grained categorization of training samples, allowing for a deeper analysis of how different types of samples contribute to the learning process in RL. Our code is available at https://github.com/597358816/EFRame.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22200",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Quantum computing and artificial intelligence: status and perspectives",
    "description": "arXiv:2505.23860v3 Announce Type: replace-cross Abstract: This white paper discusses and explores the various points of intersection between quantum computing and artificial intelligence (AI). It describes how quantum computing could support the development of innovative AI solutions. It also examines use cases of classical AI that can empower research and development in quantum technologies, with a focus on quantum computing and quantum sensing. The purpose of this white paper is to provide a long-term research agenda aimed at addressing foundational questions about how AI and quantum computing interact and benefit one another. It concludes with a set of recommendations and challenges, including how to orchestrate the proposed theoretical work, align quantum AI developments with quantum hardware roadmaps, estimate both classical and quantum resources - especially with the goal of mitigating and optimizing energy consumption - advance this emerging hybrid software engineering discipline, and enhance European industrial competitiveness while considering societal implications.",
    "summary": "arXiv:2505.23860v3 Announce Type: replace-cross Abstract: This white paper discusses and explores the various points of intersection between quantum computing and artificial intelligence (AI). It describes how quantum computing could support the development of innovative AI solutions. It also examines use cases of classical AI that can empower research and development in quantum technologies, with a focus on quantum computing and quantum sensing. The purpose of this white paper is to provide a long-term research agenda aimed at addressing foundational questions about how AI and quantum computing interact and benefit one another. It concludes with a set of recommendations and challenges, including how to orchestrate the proposed theoretical work, align quantum AI developments with quantum hardware roadmaps, estimate both classical and quantum resources - especially with the goal of mitigating and optimizing energy consumption - advance this emerging hybrid software engineering discipline, and enhance European industrial competitiveness while considering societal implications.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.23860",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "State-of-the-art video and image generation with Veo 2 and Imagen 3",
    "description": "We‚Äôre rolling out a new, state-of-the-art video model, Veo 2, and updates to Imagen 3. Plus, check out our new experiment, Whisk.",
    "summary": "We‚Äôre rolling out a new, state-of-the-art video model, Veo 2, and updates to Imagen 3. Plus, check out our new experiment, Whisk.",
    "pubDate": "Mon, 16 Dec 2024 17:01:16 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/state-of-the-art-video-and-image-generation-with-veo-2-and-imagen-3/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/12-16-24_GenMedia_16x9.width-1300.png"
  },
  {
    "title": "Automating 90% of finance and legal work with agents",
    "description": "Hebbia‚Äôs deep research automates 90% of finance and legal work, powered by OpenAI",
    "summary": "Hebbia‚Äôs deep research automates 90% of finance and legal work, powered by OpenAI",
    "pubDate": "Tue, 25 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hebbia",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Retrieval Augmented Generation Based LLM Evaluation For Protocol State Machine Inference With Chain-of-Thought Reasoning",
    "description": "arXiv:2502.15727v2 Announce Type: replace-cross Abstract: This paper presents a novel approach to evaluate the efficiency of a RAG-based agentic Large Language Model (LLM) architecture for network packet seed generation and enrichment. Enhanced by chain-of-thought (COT) prompting techniques, the proposed approach focuses on the improvement of the seeds' structural quality in order to guide protocol fuzzing frameworks through a wide exploration of the protocol state space. Our method leverages RAG and text embeddings to dynamically reference to the Request For Comments (RFC) documents knowledge base for answering queries regarding the protocol's Finite State Machine (FSM), then iteratively reasons through the retrieved knowledge, for output refinement and proper seed placement. We then evaluate the response structure quality of the agent's output, based on metrics as BLEU, ROUGE, and Word Error Rate (WER) by comparing the generated packets against the ground-truth packets. Our experiments demonstrate significant improvements of up to 18.19%, 14.81%, and 23.45% in BLEU, ROUGE, and WER, respectively, over baseline models. These results confirm the potential of such approach, improving LLM-based protocol fuzzing frameworks for the identification of hidden vulnerabilities.",
    "summary": "arXiv:2502.15727v2 Announce Type: replace-cross Abstract: This paper presents a novel approach to evaluate the efficiency of a RAG-based agentic Large Language Model (LLM) architecture for network packet seed generation and enrichment. Enhanced by chain-of-thought (COT) prompting techniques, the proposed approach focuses on the improvement of the seeds' structural quality in order to guide protocol fuzzing frameworks through a wide exploration of the protocol state space. Our method leverages RAG and text embeddings to dynamically reference to the Request For Comments (RFC) documents knowledge base for answering queries regarding the protocol's Finite State Machine (FSM), then iteratively reasons through the retrieved knowledge, for output refinement and proper seed placement. We then evaluate the response structure quality of the agent's output, based on metrics as BLEU, ROUGE, and Word Error Rate (WER) by comparing the generated packets against the ground-truth packets. Our experiments demonstrate significant improvements of up to 18.19%, 14.81%, and 23.45% in BLEU, ROUGE, and WER, respectively, over baseline models. These results confirm the potential of such approach, improving LLM-based protocol fuzzing frameworks for the identification of hidden vulnerabilities.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.15727",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Minnesota‚Äôs Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "description": "Minnesota‚Äôs Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "summary": "Minnesota‚Äôs Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "pubDate": "Thu, 26 Sep 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/state-of-minnesota",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pixels-to-Graph: Real-time Integration of Building Information Models and Scene Graphs for Semantic-Geometric Human-Robot Understanding",
    "description": "arXiv:2506.22593v1 Announce Type: cross Abstract: Autonomous robots are increasingly playing key roles as support platforms for human operators in high-risk, dangerous applications. To accomplish challenging tasks, an efficient human-robot cooperation and understanding is required. While typically robotic planning leverages 3D geometric information, human operators are accustomed to a high-level compact representation of the environment, like top-down 2D maps representing the Building Information Model (BIM). 3D scene graphs have emerged as a powerful tool to bridge the gap between human readable 2D BIM and the robot 3D maps. In this work, we introduce Pixels-to-Graph (Pix2G), a novel lightweight method to generate structured scene graphs from image pixels and LiDAR maps in real-time for the autonomous exploration of unknown environments on resource-constrained robot platforms. To satisfy onboard compute constraints, the framework is designed to perform all operation on CPU only. The method output are a de-noised 2D top-down environment map and a structure-segmented 3D pointcloud which are seamlessly connected using a multi-layer graph abstracting information from object-level up to the building-level. The proposed method is quantitatively and qualitatively evaluated during real-world experiments performed using the NASA JPL NeBula-Spot legged robot to autonomously explore and map cluttered garage and urban office like environments in real-time.",
    "summary": "arXiv:2506.22593v1 Announce Type: cross Abstract: Autonomous robots are increasingly playing key roles as support platforms for human operators in high-risk, dangerous applications. To accomplish challenging tasks, an efficient human-robot cooperation and understanding is required. While typically robotic planning leverages 3D geometric information, human operators are accustomed to a high-level compact representation of the environment, like top-down 2D maps representing the Building Information Model (BIM). 3D scene graphs have emerged as a powerful tool to bridge the gap between human readable 2D BIM and the robot 3D maps. In this work, we introduce Pixels-to-Graph (Pix2G), a novel lightweight method to generate structured scene graphs from image pixels and LiDAR maps in real-time for the autonomous exploration of unknown environments on resource-constrained robot platforms. To satisfy onboard compute constraints, the framework is designed to perform all operation on CPU only. The method output are a de-noised 2D top-down environment map and a structure-segmented 3D pointcloud which are seamlessly connected using a multi-layer graph abstracting information from object-level up to the building-level. The proposed method is quantitatively and qualitatively evaluated during real-world experiments performed using the NASA JPL NeBula-Spot legged robot to autonomously explore and map cluttered garage and urban office like environments in real-time.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22593",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Redefining Evaluation Standards: A Unified Framework for Evaluating the Korean Capabilities of Language Models",
    "description": "arXiv:2503.22968v3 Announce Type: replace-cross Abstract: Recent advancements in Korean large language models (LLMs) have driven numerous benchmarks and evaluation methods, yet inconsistent protocols cause up to 10 p.p performance gaps across institutions. Overcoming these reproducibility gaps does not mean enforcing a one-size-fits-all evaluation. Rather, effective benchmarking requires diverse experimental approaches and a framework robust enough to support them. To this end, we introduce HRET (Haerae Evaluation Toolkit), an open-source, registry-based framework that unifies Korean LLM assessment. HRET integrates major Korean benchmarks, multiple inference backends, and multi-method evaluation, with language consistency enforcement to ensure genuine Korean outputs. Its modular registry design also enables rapid incorporation of new datasets, methods, and backends, ensuring the toolkit adapts to evolving research needs. Beyond standard accuracy metrics, HRET incorporates Korean-focused output analyses-morphology-aware Type-Token Ratio (TTR) for evaluating lexical diversity and systematic keyword-omission detection for identifying missing concepts-to provide diagnostic insights into language-specific behaviors. These targeted analyses help researchers pinpoint morphological and semantic shortcomings in model outputs, guiding focused improvements in Korean LLM development.",
    "summary": "arXiv:2503.22968v3 Announce Type: replace-cross Abstract: Recent advancements in Korean large language models (LLMs) have driven numerous benchmarks and evaluation methods, yet inconsistent protocols cause up to 10 p.p performance gaps across institutions. Overcoming these reproducibility gaps does not mean enforcing a one-size-fits-all evaluation. Rather, effective benchmarking requires diverse experimental approaches and a framework robust enough to support them. To this end, we introduce HRET (Haerae Evaluation Toolkit), an open-source, registry-based framework that unifies Korean LLM assessment. HRET integrates major Korean benchmarks, multiple inference backends, and multi-method evaluation, with language consistency enforcement to ensure genuine Korean outputs. Its modular registry design also enables rapid incorporation of new datasets, methods, and backends, ensuring the toolkit adapts to evolving research needs. Beyond standard accuracy metrics, HRET incorporates Korean-focused output analyses-morphology-aware Type-Token Ratio (TTR) for evaluating lexical diversity and systematic keyword-omission detection for identifying missing concepts-to provide diagnostic insights into language-specific behaviors. These targeted analyses help researchers pinpoint morphological and semantic shortcomings in model outputs, guiding focused improvements in Korean LLM development.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.22968",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "‚ÄúÁ¥îÂõΩÁî£‰∫∫Âûã„É≠„Éú‚ÄùÈñãÁô∫„Å∏„ÄÄ‰∫¨ÈÉΩÁô∫„ÉªÊùëÁî∞Ë£Ω‰ΩúÊâÄ„Å™„Å©„ÅåÊñ∞Âõ£‰Ωì„ÄÄ26Âπ¥Â∫¶ÂÜÖ„Å´ÁÅΩÂÆ≥ÁèæÂ†¥„Å∏„ÅÆÂÆüË£ÖÁõÆÊåá„Åô",
    "description": "ÊùëÁî∞Ë£Ω‰ΩúÊâÄ„ÅØ„ÄÅÊó©Á®≤Áî∞Â§ßÂ≠¶„Å™„Å©„Å®„Å®„ÇÇ„Å´„ÄÅÂõΩÁî£„ÅÆ‰∫∫Âûã„É≠„Éú„ÉÉ„ÉàÈñãÁô∫„ÇíÊé®ÈÄ≤„Åô„ÇãÂõ£‰Ωì„ÄåKyoHA„ÄçÔºà‰∫¨ÈÉΩ„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Ç¢„ÇΩ„Ç∑„Ç®„Éº„Ç∑„Éß„É≥Ôºâ„Çí7Êúà„Å´Ë®≠Á´ã„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ„Åæ„Åö„ÅØ2026Âπ¥Â∫¶ÂÜÖ„Å´„ÄÅÁÅΩÂÆ≥ÁèæÂ†¥„ÅßÊ¥ªË∫ç„Åô„Çã‰∫∫Âûã„É≠„Éú„ÅÆÈñãÁô∫„ÇíÁõÆÊåá„Åô„ÄÇ",
    "summary": "ÊùëÁî∞Ë£Ω‰ΩúÊâÄ„ÅØ„ÄÅÊó©Á®≤Áî∞Â§ßÂ≠¶„Å™„Å©„Å®„Å®„ÇÇ„Å´„ÄÅÂõΩÁî£„ÅÆ‰∫∫Âûã„É≠„Éú„ÉÉ„ÉàÈñãÁô∫„ÇíÊé®ÈÄ≤„Åô„ÇãÂõ£‰Ωì„ÄåKyoHA„ÄçÔºà‰∫¨ÈÉΩ„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Ç¢„ÇΩ„Ç∑„Ç®„Éº„Ç∑„Éß„É≥Ôºâ„Çí7Êúà„Å´Ë®≠Á´ã„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ„Åæ„Åö„ÅØ2026Âπ¥Â∫¶ÂÜÖ„Å´„ÄÅÁÅΩÂÆ≥ÁèæÂ†¥„ÅßÊ¥ªË∫ç„Åô„Çã‰∫∫Âûã„É≠„Éú„ÅÆÈñãÁô∫„ÇíÁõÆÊåá„Åô„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 14:19:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/30/news097.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/30/cover_news097.jpg"
  },
  {
    "title": "OpenAI Microscope",
    "description": "We‚Äôre introducing¬†OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision ‚Äúmodel organisms‚Äù which are often studied in interpretability. Microscope makes it easier to analyze the features that form inside these neural networks, and we hope it will help the research community as we move towards understanding these complicated¬†systems.",
    "summary": "We‚Äôre introducing¬†OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision ‚Äúmodel organisms‚Äù which are often studied in interpretability. Microscope makes it easier to analyze the features that form inside these neural networks, and we hope it will help the research community as we move towards understanding these complicated¬†systems.",
    "pubDate": "Tue, 14 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/microscope",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning a hierarchy",
    "description": "We‚Äôve developed a hierarchical reinforcement learning algorithm that learns high-level actions useful for solving a range of tasks, allowing fast solving of tasks requiring thousands of timesteps. Our algorithm, when applied to a set of navigation problems, discovers a set of high-level actions for walking and crawling in different directions, which enables the agent to master new navigation tasks quickly.",
    "summary": "We‚Äôve developed a hierarchical reinforcement learning algorithm that learns high-level actions useful for solving a range of tasks, allowing fast solving of tasks requiring thousands of timesteps. Our algorithm, when applied to a set of navigation problems, discovers a set of high-level actions for walking and crawling in different directions, which enables the agent to master new navigation tasks quickly.",
    "pubDate": "Thu, 26 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-a-hierarchy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Why responsible AI development needs cooperation on safety",
    "description": "We‚Äôve written a policy research paper identifying four strategies that can be used today to improve the likelihood of long-term industry cooperation on safety norms in AI: communicating risks and benefits, technical collaboration, increased transparency, and incentivizing standards. Our analysis shows that industry cooperation on safety will be instrumental in ensuring that AI systems are safe and beneficial, but competitive pressures could lead to a collective action problem, potentially causing AI companies to under-invest in safety. We hope these strategies will encourage greater cooperation on the safe development of AI and lead to better global outcomes of¬†AI.",
    "summary": "We‚Äôve written a policy research paper identifying four strategies that can be used today to improve the likelihood of long-term industry cooperation on safety norms in AI: communicating risks and benefits, technical collaboration, increased transparency, and incentivizing standards. Our analysis shows that industry cooperation on safety will be instrumental in ensuring that AI systems are safe and beneficial, but competitive pressures could lead to a collective action problem, potentially causing AI companies to under-invest in safety. We hope these strategies will encourage greater cooperation on the safe development of AI and lead to better global outcomes of¬†AI.",
    "pubDate": "Wed, 10 Jul 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/cooperation-on-safety",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Model Cards: Introducing HF Model documentation tools",
    "description": "",
    "summary": "Model Cards Introduction Model cards are an important documentation framework for understanding, sha...",
    "pubDate": "Tue, 20 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/model-cards",
    "thumbnail": "https://huggingface.co/blog/assets/121_model-cards/thumbnail.png"
  },
  {
    "title": "When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)",
    "description": "arXiv:2506.23784v1 Announce Type: new Abstract: Nielsen transformation is a standard approach for solving word equations: by repeatedly splitting equations and applying simplification steps, equations are rewritten until a solution is reached. When solving a conjunction of word equations in this way, the performance of the solver will depend considerably on the order in which equations are processed. In this work, the use of Graph Neural Networks (GNNs) for ranking word equations before and during the solving process is explored. For this, a novel graph-based representation for word equations is presented, preserving global information across conjuncts, enabling the GNN to have a holistic view during ranking. To handle the variable number of conjuncts, three approaches to adapt a multi-classification task to the problem of ranking equations are proposed. The training of the GNN is done with the help of minimum unsatisfiable subsets (MUSes) of word equations. The experimental results show that, compared to state-of-the-art string solvers, the new framework solves more problems in benchmarks where each variable appears at most once in each equation.",
    "summary": "arXiv:2506.23784v1 Announce Type: new Abstract: Nielsen transformation is a standard approach for solving word equations: by repeatedly splitting equations and applying simplification steps, equations are rewritten until a solution is reached. When solving a conjunction of word equations in this way, the performance of the solver will depend considerably on the order in which equations are processed. In this work, the use of Graph Neural Networks (GNNs) for ranking word equations before and during the solving process is explored. For this, a novel graph-based representation for word equations is presented, preserving global information across conjuncts, enabling the GNN to have a holistic view during ranking. To handle the variable number of conjuncts, three approaches to adapt a multi-classification task to the problem of ranking equations are proposed. The training of the GNN is done with the help of minimum unsatisfiable subsets (MUSes) of word equations. The experimental results show that, compared to state-of-the-art string solvers, the new framework solves more problems in benchmarks where each variable appears at most once in each equation.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23784",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Boost Wav2Vec2 with n-gram LM in ü§ó Transformers",
    "description": "",
    "summary": "Boosting Wav2Vec2 with n-grams in ü§ó Transformers Wav2Vec2 is a popular pre-trained model for speech ...",
    "pubDate": "Wed, 12 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/wav2vec2-with-ngram",
    "thumbnail": "https://huggingface.co/blog/assets/44_boost_wav2vec2_ngram/wav2vec2_ngram.png"
  },
  {
    "title": "URSA: The Universal Research and Scientific Agent",
    "description": "arXiv:2506.22653v1 Announce Type: new Abstract: Large language models (LLMs) have moved far beyond their initial form as simple chatbots, now carrying out complex reasoning, planning, writing, coding, and research tasks. These skills overlap significantly with those that human scientists use day-to-day to solve complex problems that drive the cutting edge of research. Using LLMs in 'agentic' AI has the potential to revolutionize modern science and remove bottlenecks to progress. In this work, we present URSA, a scientific agent ecosystem for accelerating research tasks. URSA consists of a set of modular agents and tools, including coupling to advanced physics simulation codes, that can be combined to address scientific problems of varied complexity and impact. This work highlights the architecture of URSA, as well as examples that highlight the potential of the system.",
    "summary": "arXiv:2506.22653v1 Announce Type: new Abstract: Large language models (LLMs) have moved far beyond their initial form as simple chatbots, now carrying out complex reasoning, planning, writing, coding, and research tasks. These skills overlap significantly with those that human scientists use day-to-day to solve complex problems that drive the cutting edge of research. Using LLMs in 'agentic' AI has the potential to revolutionize modern science and remove bottlenecks to progress. In this work, we present URSA, a scientific agent ecosystem for accelerating research tasks. URSA consists of a set of modular agents and tools, including coupling to advanced physics simulation codes, that can be combined to address scientific problems of varied complexity and impact. This work highlights the architecture of URSA, as well as examples that highlight the potential of the system.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22653",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Blazing Fast SetFit Inference with ü§ó Optimum Intel on Xeon",
    "description": "",
    "summary": "Blazing Fast SetFit Inference with ü§ó Optimum Intel on Xeon SetFit is a promising solution for a comm...",
    "pubDate": "Wed, 03 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit-optimum-intel",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "LAVE: Zero-shot VQA Evaluation on Docmatix with LLMs - Do We Still Need Fine-Tuning?",
    "description": "",
    "summary": "LAVE: Zero-shot VQA Evaluation on Docmatix with LLMs - Do We Still Need Fine-Tuning? While developin...",
    "pubDate": "Thu, 25 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-shot-vqa-docmatix",
    "thumbnail": "https://huggingface.co/blog/assets/184_zero_shot_docmatix/thumb.001.jpeg"
  },
  {
    "title": "Increasing accuracy of pediatric visit notes",
    "description": "Summer Health reimagines pediatric doctor‚Äôs visits with OpenAI.",
    "summary": "Summer Health reimagines pediatric doctor‚Äôs visits with OpenAI.",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/summer-health",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "UltraTwin: Towards Cardiac Anatomical Twin Generation from Multi-view 2D Ultrasound",
    "description": "arXiv:2506.23490v1 Announce Type: cross Abstract: Echocardiography is routine for cardiac examination. However, 2D ultrasound (US) struggles with accurate metric calculation and direct observation of 3D cardiac structures. Moreover, 3D US is limited by low resolution, small field of view and scarce availability in practice. Constructing the cardiac anatomical twin from 2D images is promising to provide precise treatment planning and clinical quantification. However, it remains challenging due to the rare paired data, complex structures, and US noises. In this study, we introduce a novel generative framework UltraTwin, to obtain cardiac anatomical twin from sparse multi-view 2D US. Our contribution is three-fold. First, pioneered the construction of a real-world and high-quality dataset containing strictly paired multi-view 2D US and CT, and pseudo-paired data. Second, we propose a coarse-to-fine scheme to achieve hierarchical reconstruction optimization. Last, we introduce an implicit autoencoder for topology-aware constraints. Extensive experiments show that UltraTwin reconstructs high-quality anatomical twins versus strong competitors. We believe it advances anatomical twin modeling for potential applications in personalized cardiac care.",
    "summary": "arXiv:2506.23490v1 Announce Type: cross Abstract: Echocardiography is routine for cardiac examination. However, 2D ultrasound (US) struggles with accurate metric calculation and direct observation of 3D cardiac structures. Moreover, 3D US is limited by low resolution, small field of view and scarce availability in practice. Constructing the cardiac anatomical twin from 2D images is promising to provide precise treatment planning and clinical quantification. However, it remains challenging due to the rare paired data, complex structures, and US noises. In this study, we introduce a novel generative framework UltraTwin, to obtain cardiac anatomical twin from sparse multi-view 2D US. Our contribution is three-fold. First, pioneered the construction of a real-world and high-quality dataset containing strictly paired multi-view 2D US and CT, and pseudo-paired data. Second, we propose a coarse-to-fine scheme to achieve hierarchical reconstruction optimization. Last, we introduce an implicit autoencoder for topology-aware constraints. Extensive experiments show that UltraTwin reconstructs high-quality anatomical twins versus strong competitors. We believe it advances anatomical twin modeling for potential applications in personalized cardiac care.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23490",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SABRE-FL: Selective and Accurate Backdoor Rejection for Federated Prompt Learning",
    "description": "arXiv:2506.22506v1 Announce Type: cross Abstract: Federated Prompt Learning has emerged as a communication-efficient and privacy-preserving paradigm for adapting large vision-language models like CLIP across decentralized clients. However, the security implications of this setup remain underexplored. In this work, we present the first study of backdoor attacks in Federated Prompt Learning. We show that when malicious clients inject visually imperceptible, learnable noise triggers into input images, the global prompt learner becomes vulnerable to targeted misclassification while still maintaining high accuracy on clean inputs. Motivated by this vulnerability, we propose SABRE-FL, a lightweight, modular defense that filters poisoned prompt updates using an embedding-space anomaly detector trained offline on out-of-distribution data. SABRE-FL requires no access to raw client data or labels and generalizes across diverse datasets. We show, both theoretically and empirically, that malicious clients can be reliably identified and filtered using an embedding-based detector. Across five diverse datasets and four baseline defenses, SABRE-FL outperforms all baselines by significantly reducing backdoor accuracy while preserving clean accuracy, demonstrating strong empirical performance and underscoring the need for robust prompt learning in future federated systems.",
    "summary": "arXiv:2506.22506v1 Announce Type: cross Abstract: Federated Prompt Learning has emerged as a communication-efficient and privacy-preserving paradigm for adapting large vision-language models like CLIP across decentralized clients. However, the security implications of this setup remain underexplored. In this work, we present the first study of backdoor attacks in Federated Prompt Learning. We show that when malicious clients inject visually imperceptible, learnable noise triggers into input images, the global prompt learner becomes vulnerable to targeted misclassification while still maintaining high accuracy on clean inputs. Motivated by this vulnerability, we propose SABRE-FL, a lightweight, modular defense that filters poisoned prompt updates using an embedding-space anomaly detector trained offline on out-of-distribution data. SABRE-FL requires no access to raw client data or labels and generalizes across diverse datasets. We show, both theoretically and empirically, that malicious clients can be reliably identified and filtered using an embedding-based detector. Across five diverse datasets and four baseline defenses, SABRE-FL outperforms all baselines by significantly reducing backdoor accuracy while preserving clean accuracy, demonstrating strong empirical performance and underscoring the need for robust prompt learning in future federated systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22506",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Efficient Table Pre-training without Real Data: An Introduction to TAPEX",
    "description": "",
    "summary": "Efficient Table Pre-training without Real Data: An Introduction to TAPEX In recent years, language m...",
    "pubDate": "Mon, 23 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tapex",
    "thumbnail": "https://huggingface.co/blog/assets/74_tapex/thumbnail.png"
  },
  {
    "title": "Surging developer productivity with custom GPTs",
    "description": "Paf adopted ChatGPT Enterprise across its entire company, with engineers using custom GPTs on a daily basis to speed up routine development tasks. Paf also integrated ChatGPT Enterprise into the grit:lab coding academy (gritlab.ax), training the next generation of software developers using an AI-augmented, systems-architecture mindset from day one. In addition to the wide range of use cases for developers and grit:lab students, 70% of Paf employees actively use ChatGPT Enterprise, spanning business teams like finance, HR, marketing, and customer support.",
    "summary": "Paf adopted ChatGPT Enterprise across its entire company, with engineers using custom GPTs on a daily basis to speed up routine development tasks. Paf also integrated ChatGPT Enterprise into the grit:lab coding academy (gritlab.ax), training the next generation of software developers using an AI-augmented, systems-architecture mindset from day one. In addition to the wide range of use cases for developers and grit:lab students, 70% of Paf employees actively use ChatGPT Enterprise, spanning business teams like finance, HR, marketing, and customer support.",
    "pubDate": "Tue, 18 Jun 2024 08:45:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paf",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Dota 2 with large scale deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 13 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dota-2-with-large-scale-deep-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Report from the OpenAI hackathon",
    "description": "On March 3rd, we hosted our first¬†hackathon¬†with 100 members of the artificial intelligence community.",
    "summary": "On March 3rd, we hosted our first¬†hackathon¬†with 100 members of the artificial intelligence community.",
    "pubDate": "Thu, 15 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hackathon-follow-up",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Constitutional AI with Open LLMs",
    "description": "",
    "summary": "Constitutional AI with Open LLMs Since the launch of ChatGPT in 2022, we have seen tremendous progre...",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/constitutional_ai",
    "thumbnail": "https://huggingface.co/blog/assets/175_constitutional_ai/thumbnail.png"
  },
  {
    "title": "Pretrained Reversible Generation as Unsupervised Visual Representation Learning",
    "description": "arXiv:2412.01787v4 Announce Type: replace-cross Abstract: Recent generative models based on score matching and flow matching have significantly advanced generation tasks, but their potential in discriminative tasks remains underexplored. Previous approaches, such as generative classifiers, have not fully leveraged the capabilities of these models for discriminative tasks due to their intricate designs. We propose Pretrained Reversible Generation (PRG), which extracts unsupervised representations by reversing the generative process of a pretrained continuous generation model. PRG effectively reuses unsupervised generative models, leveraging their high capacity to serve as robust and generalizable feature extractors for downstream tasks. This framework enables the flexible selection of feature hierarchies tailored to specific downstream tasks. Our method consistently outperforms prior approaches across multiple benchmarks, achieving state-of-the-art performance among generative model based methods, including 78% top-1 accuracy on ImageNet at a resolution of 64*64. Extensive ablation studies, including out-of-distribution evaluations, further validate the effectiveness of our approach.PRG is available at https://github.com/opendilab/PRG.",
    "summary": "arXiv:2412.01787v4 Announce Type: replace-cross Abstract: Recent generative models based on score matching and flow matching have significantly advanced generation tasks, but their potential in discriminative tasks remains underexplored. Previous approaches, such as generative classifiers, have not fully leveraged the capabilities of these models for discriminative tasks due to their intricate designs. We propose Pretrained Reversible Generation (PRG), which extracts unsupervised representations by reversing the generative process of a pretrained continuous generation model. PRG effectively reuses unsupervised generative models, leveraging their high capacity to serve as robust and generalizable feature extractors for downstream tasks. This framework enables the flexible selection of feature hierarchies tailored to specific downstream tasks. Our method consistently outperforms prior approaches across multiple benchmarks, achieving state-of-the-art performance among generative model based methods, including 78% top-1 accuracy on ImageNet at a resolution of 64*64. Extensive ablation studies, including out-of-distribution evaluations, further validate the effectiveness of our approach.PRG is available at https://github.com/opendilab/PRG.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.01787",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google DeepMind at ICML 2024",
    "description": "Exploring AGI, the challenges of scaling and the future of multimodal generative AI",
    "summary": "Exploring AGI, the challenges of scaling and the future of multimodal generative AI",
    "pubDate": "Fri, 19 Jul 2024 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-icml-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/_o0MU47bgKrTJi6uOWhc3BjWOOENkBczD2x5-tK5aMLBcljJnV-N8tZuSVN42C3d1pSWawY6NsGuoj6vvl0xMk4tpWOeUjXwlgFNZSMyJkFJ02xTauk=w1200-h630-n-nu"
  },
  {
    "title": "Partnership with Axel Springer to deepen beneficial use of AI in journalism",
    "description": "Axel Springer is the first publishing house globally to partner with us on a deeper integration of journalism in AI technologies.",
    "summary": "Axel Springer is the first publishing house globally to partner with us on a deeper integration of journalism in AI technologies.",
    "pubDate": "Wed, 13 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/axel-springer-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Kill Two Birds with One Stone! Trajectory enabled Unified Online Detection of Adversarial Examples and Backdoor Attacks",
    "description": "arXiv:2506.22722v1 Announce Type: cross Abstract: The proposed UniGuard is the first unified online detection framework capable of simultaneously addressing adversarial examples and backdoor attacks. UniGuard builds upon two key insights: first, both AE and backdoor attacks have to compromise the inference phase, making it possible to tackle them simultaneously during run-time via online detection. Second, an adversarial input, whether a perturbed sample in AE attacks or a trigger-carrying sample in backdoor attacks, exhibits distinctive trajectory signatures from a benign sample as it propagates through the layers of a DL model in forward inference. The propagation trajectory of the adversarial sample must deviate from that of its benign counterpart; otherwise, the adversarial objective cannot be fulfilled. Detecting these trajectory signatures is inherently challenging due to their subtlety; UniGuard overcomes this by treating the propagation trajectory as a time-series signal, leveraging LSTM and spectrum transformation to amplify differences between adversarial and benign trajectories that are subtle in the time domain. UniGuard exceptional efficiency and effectiveness have been extensively validated across various modalities (image, text, and audio) and tasks (classification and regression), ranging from diverse model architectures against a wide range of AE attacks and backdoor attacks, including challenging partial backdoors and dynamic triggers. When compared to SOTA methods, including ContraNet (NDSS 22) specific for AE detection and TED (IEEE SP 24) specific for backdoor detection, UniGuard consistently demonstrates superior performance, even when matched against each method's strengths in addressing their respective threats-each SOTA fails to parts of attack strategies while UniGuard succeeds for all.",
    "summary": "arXiv:2506.22722v1 Announce Type: cross Abstract: The proposed UniGuard is the first unified online detection framework capable of simultaneously addressing adversarial examples and backdoor attacks. UniGuard builds upon two key insights: first, both AE and backdoor attacks have to compromise the inference phase, making it possible to tackle them simultaneously during run-time via online detection. Second, an adversarial input, whether a perturbed sample in AE attacks or a trigger-carrying sample in backdoor attacks, exhibits distinctive trajectory signatures from a benign sample as it propagates through the layers of a DL model in forward inference. The propagation trajectory of the adversarial sample must deviate from that of its benign counterpart; otherwise, the adversarial objective cannot be fulfilled. Detecting these trajectory signatures is inherently challenging due to their subtlety; UniGuard overcomes this by treating the propagation trajectory as a time-series signal, leveraging LSTM and spectrum transformation to amplify differences between adversarial and benign trajectories that are subtle in the time domain. UniGuard exceptional efficiency and effectiveness have been extensively validated across various modalities (image, text, and audio) and tasks (classification and regression), ranging from diverse model architectures against a wide range of AE attacks and backdoor attacks, including challenging partial backdoors and dynamic triggers. When compared to SOTA methods, including ContraNet (NDSS 22) specific for AE detection and TED (IEEE SP 24) specific for backdoor detection, UniGuard consistently demonstrates superior performance, even when matched against each method's strengths in addressing their respective threats-each SOTA fails to parts of attack strategies while UniGuard succeeds for all.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22722",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Procgen Benchmark",
    "description": "We‚Äôre releasing Procgen Benchmark, 16 simple-to-use¬†procedurally-generated¬†environments which provide a direct measure of how quickly a reinforcement learning agent learns generalizable¬†skills.",
    "summary": "We‚Äôre releasing Procgen Benchmark, 16 simple-to-use¬†procedurally-generated¬†environments which provide a direct measure of how quickly a reinforcement learning agent learns generalizable¬†skills.",
    "pubDate": "Tue, 03 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/procgen-benchmark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ovis-U1 Technical Report",
    "description": "arXiv:2506.23044v1 Announce Type: cross Abstract: In this report, we introduce Ovis-U1, a 3-billion-parameter unified model that integrates multimodal understanding, text-to-image generation, and image editing capabilities. Building on the foundation of the Ovis series, Ovis-U1 incorporates a diffusion-based visual decoder paired with a bidirectional token refiner, enabling image generation tasks comparable to leading models like GPT-4o. Unlike some previous models that use a frozen MLLM for generation tasks, Ovis-U1 utilizes a new unified training approach starting from a language model. Compared to training solely on understanding or generation tasks, unified training yields better performance, demonstrating the enhancement achieved by integrating these two tasks. Ovis-U1 achieves a score of 69.6 on the OpenCompass Multi-modal Academic Benchmark, surpassing recent state-of-the-art models such as Ristretto-3B and SAIL-VL-1.5-2B. In text-to-image generation, it excels with scores of 83.72 and 0.89 on the DPG-Bench and GenEval benchmarks, respectively. For image editing, it achieves 4.00 and 6.42 on the ImgEdit-Bench and GEdit-Bench-EN, respectively. As the initial version of the Ovis unified model series, Ovis-U1 pushes the boundaries of multimodal understanding, generation, and editing.",
    "summary": "arXiv:2506.23044v1 Announce Type: cross Abstract: In this report, we introduce Ovis-U1, a 3-billion-parameter unified model that integrates multimodal understanding, text-to-image generation, and image editing capabilities. Building on the foundation of the Ovis series, Ovis-U1 incorporates a diffusion-based visual decoder paired with a bidirectional token refiner, enabling image generation tasks comparable to leading models like GPT-4o. Unlike some previous models that use a frozen MLLM for generation tasks, Ovis-U1 utilizes a new unified training approach starting from a language model. Compared to training solely on understanding or generation tasks, unified training yields better performance, demonstrating the enhancement achieved by integrating these two tasks. Ovis-U1 achieves a score of 69.6 on the OpenCompass Multi-modal Academic Benchmark, surpassing recent state-of-the-art models such as Ristretto-3B and SAIL-VL-1.5-2B. In text-to-image generation, it excels with scores of 83.72 and 0.89 on the DPG-Bench and GenEval benchmarks, respectively. For image editing, it achieves 4.00 and 6.42 on the ImgEdit-Bench and GEdit-Bench-EN, respectively. As the initial version of the Ovis unified model series, Ovis-U1 pushes the boundaries of multimodal understanding, generation, and editing.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23044",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Large-scale Near-deduplication Behind BigCode",
    "description": "",
    "summary": "Large-scale Near-deduplication Behind BigCode Intended Audience People who are interested in documen...",
    "pubDate": "Tue, 16 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dedup",
    "thumbnail": "https://huggingface.co/blog/assets/dedup/thumbnail.png"
  },
  {
    "title": "Benchmarking Spiking Neural Network Learning Methods with Varying Locality",
    "description": "arXiv:2402.01782v2 Announce Type: replace-cross Abstract: Spiking Neural Networks (SNNs), providing more realistic neuronal dynamics, have been shown to achieve performance comparable to Artificial Neural Networks (ANNs) in several machine learning tasks. Information is processed as spikes within SNNs in an event-based mechanism that significantly reduces energy consumption. However, training SNNs is challenging due to the non-differentiable nature of the spiking mechanism. Traditional approaches, such as Backpropagation Through Time (BPTT), have shown effectiveness but come with additional computational and memory costs and are biologically implausible. In contrast, recent works propose alternative learning methods with varying degrees of locality, demonstrating success in classification tasks. In this work, we show that these methods share similarities during the training process, while they present a trade-off between biological plausibility and performance. Further, given the implicitly recurrent nature of SNNs, this research investigates the influence of the addition of explicit recurrence to SNNs. We experimentally prove that the addition of explicit recurrent weights enhances the robustness of SNNs. We also investigate the performance of local learning methods under gradient and non-gradient-based adversarial attacks.",
    "summary": "arXiv:2402.01782v2 Announce Type: replace-cross Abstract: Spiking Neural Networks (SNNs), providing more realistic neuronal dynamics, have been shown to achieve performance comparable to Artificial Neural Networks (ANNs) in several machine learning tasks. Information is processed as spikes within SNNs in an event-based mechanism that significantly reduces energy consumption. However, training SNNs is challenging due to the non-differentiable nature of the spiking mechanism. Traditional approaches, such as Backpropagation Through Time (BPTT), have shown effectiveness but come with additional computational and memory costs and are biologically implausible. In contrast, recent works propose alternative learning methods with varying degrees of locality, demonstrating success in classification tasks. In this work, we show that these methods share similarities during the training process, while they present a trade-off between biological plausibility and performance. Further, given the implicitly recurrent nature of SNNs, this research investigates the influence of the addition of explicit recurrence to SNNs. We experimentally prove that the addition of explicit recurrent weights enhances the robustness of SNNs. We also investigate the performance of local learning methods under gradient and non-gradient-based adversarial attacks.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2402.01782",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tuning XLS-R for Multi-Lingual ASR with ü§ó Transformers",
    "description": "",
    "summary": "Fine-tuning XLS-R for Multi-Lingual ASR with ü§ó Transformers New (11/2021): This blog post has been u...",
    "pubDate": "Mon, 15 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-xlsr-wav2vec2",
    "thumbnail": "https://huggingface.co/blog/assets/xlsr_wav2vec2.png"
  },
  {
    "title": "Securing AI Systems: A Guide to Known Attacks and Impacts",
    "description": "arXiv:2506.23296v1 Announce Type: cross Abstract: Embedded into information systems, artificial intelligence (AI) faces security threats that exploit AI-specific vulnerabilities. This paper provides an accessible overview of adversarial attacks unique to predictive and generative AI systems. We identify eleven major attack types and explicitly link attack techniques to their impacts -- including information leakage, system compromise, and resource exhaustion -- mapped to the confidentiality, integrity, and availability (CIA) security triad. We aim to equip researchers, developers, security practitioners, and policymakers, even those without specialized AI security expertise, with foundational knowledge to recognize AI-specific risks and implement effective defenses, thereby enhancing the overall security posture of AI systems.",
    "summary": "arXiv:2506.23296v1 Announce Type: cross Abstract: Embedded into information systems, artificial intelligence (AI) faces security threats that exploit AI-specific vulnerabilities. This paper provides an accessible overview of adversarial attacks unique to predictive and generative AI systems. We identify eleven major attack types and explicitly link attack techniques to their impacts -- including information leakage, system compromise, and resource exhaustion -- mapped to the confidentiality, integrity, and availability (CIA) security triad. We aim to equip researchers, developers, security practitioners, and policymakers, even those without specialized AI security expertise, with foundational knowledge to recognize AI-specific risks and implement effective defenses, thereby enhancing the overall security posture of AI systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23296",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI‚Äôs proposals for the U.S. AI Action Plan",
    "description": "Recommendations build on OpenAI‚Äôs Economic Blueprint to strengthen America‚Äôs AI leadership.",
    "summary": "Recommendations build on OpenAI‚Äôs Economic Blueprint to strengthen America‚Äôs AI leadership.",
    "pubDate": "Thu, 13 Mar 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-proposals-for-the-us-ai-action-plan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o1-mini",
    "description": "Advancing cost-efficient reasoning",
    "summary": "Advancing cost-efficient reasoning",
    "pubDate": "Thu, 12 Sep 2024 10:01:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-mini-advancing-cost-efficient-reasoning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Strengthening America‚Äôs AI leadership with the U.S. National Laboratories",
    "description": "OpenAI‚Äôs latest line of reasoning models will be used by nation‚Äôs leading scientists to drive scientific breakthroughs.",
    "summary": "OpenAI‚Äôs latest line of reasoning models will be used by nation‚Äôs leading scientists to drive scientific breakthroughs.",
    "pubDate": "Thu, 30 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/strengthening-americas-ai-leadership-with-the-us-national-laboratories",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From Individuals to Interactions: Benchmarking Gender Bias in Multimodal Large Language Models from the Lens of Social Relationship",
    "description": "arXiv:2506.23101v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) have shown impressive capabilities across tasks involving both visual and textual modalities. However, growing concerns remain about their potential to encode and amplify gender bias, particularly in socially sensitive applications. Existing benchmarks predominantly evaluate bias in isolated scenarios, overlooking how bias may emerge subtly through interpersonal interactions. We fill this gap by going beyond single-entity evaluation and instead focusing on a deeper examination of relational and contextual gender bias in dual-individual interactions. We introduce Genres, a novel benchmark designed to evaluate gender bias in MLLMs through the lens of social relationships in generated narratives. Genres assesses gender bias through a dual-character profile and narrative generation task that captures rich interpersonal dynamics and supports a fine-grained bias evaluation suite across multiple dimensions. Experiments on both open- and closed-source MLLMs reveal persistent, context-sensitive gender biases that are not evident in single-character settings. Our findings underscore the importance of relationship-aware benchmarks for diagnosing subtle, interaction-driven gender bias in MLLMs and provide actionable insights for future bias mitigation.",
    "summary": "arXiv:2506.23101v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) have shown impressive capabilities across tasks involving both visual and textual modalities. However, growing concerns remain about their potential to encode and amplify gender bias, particularly in socially sensitive applications. Existing benchmarks predominantly evaluate bias in isolated scenarios, overlooking how bias may emerge subtly through interpersonal interactions. We fill this gap by going beyond single-entity evaluation and instead focusing on a deeper examination of relational and contextual gender bias in dual-individual interactions. We introduce Genres, a novel benchmark designed to evaluate gender bias in MLLMs through the lens of social relationships in generated narratives. Genres assesses gender bias through a dual-character profile and narrative generation task that captures rich interpersonal dynamics and supports a fine-grained bias evaluation suite across multiple dimensions. Experiments on both open- and closed-source MLLMs reveal persistent, context-sensitive gender biases that are not evident in single-character settings. Our findings underscore the importance of relationship-aware benchmarks for diagnosing subtle, interaction-driven gender bias in MLLMs and provide actionable insights for future bias mitigation.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23101",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introduction to Graph Machine Learning",
    "description": "",
    "summary": "Introduction to Graph Machine Learning In this blog post, we cover the basics of graph machine learn...",
    "pubDate": "Tue, 03 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intro-graphml",
    "thumbnail": "https://huggingface.co/blog/assets/125_intro-to-graphml/thumbnail.png"
  },
  {
    "title": "Advancing red teaming with people and AI",
    "description": "Advancing red teaming with people and AI",
    "summary": "Advancing red teaming with people and AI",
    "pubDate": "Thu, 21 Nov 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/advancing-red-teaming-with-people-and-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement",
    "description": "arXiv:2503.01875v2 Announce Type: replace-cross Abstract: Time series data are foundational in finance, healthcare, and energy domains. However, most existing methods and datasets remain focused on a narrow spectrum of tasks, such as forecasting or anomaly detection. To bridge this gap, we introduce Time Series Multi-Task Question Answering (Time-MQA), a unified framework that enables natural language queries across multiple time series tasks - numerical analytical tasks and open-ended question answering with reasoning. Central to Time-MQA is the TSQA dataset, a large-scale dataset containing $sim$200k question-answer pairs derived from diverse time series spanning environment, traffic, etc. This comprehensive resource covers various time series lengths and promotes robust model development. We further demonstrate how continually pre-training large language models (Mistral 7B, Llama-3 8B, and Qwen-2.5 7B) on the TSQA dataset enhanced time series reasoning capabilities, moving beyond mere numeric tasks and enabling more advanced and intuitive interactions with temporal data. The complete TSQA dataset, models, user study questionnaires for evaluation, and other related materials have been open-sourced.",
    "summary": "arXiv:2503.01875v2 Announce Type: replace-cross Abstract: Time series data are foundational in finance, healthcare, and energy domains. However, most existing methods and datasets remain focused on a narrow spectrum of tasks, such as forecasting or anomaly detection. To bridge this gap, we introduce Time Series Multi-Task Question Answering (Time-MQA), a unified framework that enables natural language queries across multiple time series tasks - numerical analytical tasks and open-ended question answering with reasoning. Central to Time-MQA is the TSQA dataset, a large-scale dataset containing $sim$200k question-answer pairs derived from diverse time series spanning environment, traffic, etc. This comprehensive resource covers various time series lengths and promotes robust model development. We further demonstrate how continually pre-training large language models (Mistral 7B, Llama-3 8B, and Qwen-2.5 7B) on the TSQA dataset enhanced time series reasoning capabilities, moving beyond mere numeric tasks and enabling more advanced and intuitive interactions with temporal data. The complete TSQA dataset, models, user study questionnaires for evaluation, and other related materials have been open-sourced.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.01875",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI‚Äôs comments to the NTIA on data center growth, resilience, and security",
    "description": "This comment was submitted in response to a request for information from the National Telecommunications and Information Administration (NTIA).",
    "summary": "This comment was submitted in response to a request for information from the National Telecommunications and Information Administration (NTIA).",
    "pubDate": "Mon, 04 Nov 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/comments-to-the-ntia-on-data-center-growth-resilience-and-security",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing SynthID Text",
    "description": "",
    "summary": "Introducing SynthID Text Do you find it difficult to tell if text was written by a human or generate...",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthid-text",
    "thumbnail": "https://huggingface.co/blog/assets/synthid-text/thumbnail.png"
  },
  {
    "title": "AI's Euclid's Elements Moment: From Language Models to Computable Thought",
    "description": "arXiv:2506.23080v1 Announce Type: new Abstract: This paper presents a comprehensive five-stage evolutionary framework for understanding the development of artificial intelligence, arguing that its trajectory mirrors the historical progression of human cognitive technologies. We posit that AI is advancing through distinct epochs, each defined by a revolutionary shift in its capacity for representation and reasoning, analogous to the inventions of cuneiform, the alphabet, grammar and logic, mathematical calculus, and formal logical systems. This 'Geometry of Cognition' framework moves beyond mere metaphor to provide a systematic, cross-disciplinary model that not only explains AI's past architectural shifts-from expert systems to Transformers-but also charts a concrete and prescriptive path forward. Crucially, we demonstrate that this evolution is not merely linear but reflexive: as AI advances through these stages, the tools and insights it develops create a feedback loop that fundamentally reshapes its own underlying architecture. We are currently transitioning into a 'Metalinguistic Moment,' characterized by the emergence of self-reflective capabilities like Chain-of-Thought prompting and Constitutional AI. The subsequent stages, the 'Mathematical Symbolism Moment' and the 'Formal Logic System Moment,' will be defined by the development of a computable calculus of thought, likely through neuro-symbolic architectures and program synthesis, culminating in provably aligned and reliable AI that reconstructs its own foundational representations. This work serves as the methodological capstone to our trilogy, which previously explored the economic drivers ('why') and cognitive nature ('what') of AI. Here, we address the 'how,' providing a theoretical foundation for future research and offering concrete, actionable strategies for startups and developers aiming to build the next generation of intelligent systems.",
    "summary": "arXiv:2506.23080v1 Announce Type: new Abstract: This paper presents a comprehensive five-stage evolutionary framework for understanding the development of artificial intelligence, arguing that its trajectory mirrors the historical progression of human cognitive technologies. We posit that AI is advancing through distinct epochs, each defined by a revolutionary shift in its capacity for representation and reasoning, analogous to the inventions of cuneiform, the alphabet, grammar and logic, mathematical calculus, and formal logical systems. This 'Geometry of Cognition' framework moves beyond mere metaphor to provide a systematic, cross-disciplinary model that not only explains AI's past architectural shifts-from expert systems to Transformers-but also charts a concrete and prescriptive path forward. Crucially, we demonstrate that this evolution is not merely linear but reflexive: as AI advances through these stages, the tools and insights it develops create a feedback loop that fundamentally reshapes its own underlying architecture. We are currently transitioning into a 'Metalinguistic Moment,' characterized by the emergence of self-reflective capabilities like Chain-of-Thought prompting and Constitutional AI. The subsequent stages, the 'Mathematical Symbolism Moment' and the 'Formal Logic System Moment,' will be defined by the development of a computable calculus of thought, likely through neuro-symbolic architectures and program synthesis, culminating in provably aligned and reliable AI that reconstructs its own foundational representations. This work serves as the methodological capstone to our trilogy, which previously explored the economic drivers ('why') and cognitive nature ('what') of AI. Here, we address the 'how,' providing a theoretical foundation for future research and offering concrete, actionable strategies for startups and developers aiming to build the next generation of intelligent systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23080",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning",
    "description": "<p>Microsoft researchers achieved a breakthrough in the accuracy of DFT, a method for predicting the properties of molecules and materials, by using deep learning. This work can lead to better batteries, green fertilizers, precision drug discovery, and more.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/'>Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Microsoft researchers achieved a breakthrough in the accuracy of DFT, a method for predicting the properties of molecules and materials, by using deep learning. This work can lead to better batteries, green fertilizers, precision drug discovery, and more.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/'>Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Wed, 18 Jun 2025 10:01:47 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models",
    "description": "arXiv:2506.22865v1 Announce Type: new Abstract: Recent advancements in Large Language Models (LLMs) have revealed a significant performance gap between closed-source and open-source models, particularly in tasks requiring complex reasoning and precise instruction following. This paper introduces ReasonBridge, a methodology that efficiently transfers reasoning capabilities from powerful closed-source to open-source models through a novel hierarchical knowledge distillation framework. We develop a tailored dataset Reason1K with only 1,000 carefully curated reasoning traces emphasizing difficulty, diversity, and quality. These traces are filtered from across multiple domains using a structured multi-criteria selection algorithm. Our transfer learning approach incorporates: (1) a hierarchical distillation process capturing both strategic abstraction and tactical implementation patterns, (2) a sparse reasoning-focused adapter architecture requiring only 0.3% additional trainable parameters, and (3) a test-time compute scaling mechanism using guided inference interventions. Comprehensive evaluations demonstrate that ReasonBridge improves reasoning capabilities in open-source models by up to 23% on benchmark tasks, significantly narrowing the gap with closed-source models. Notably, the enhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its performance on competition-level AIME problems. Our methodology generalizes effectively across diverse reasoning domains and model architectures, establishing a sample-efficient approach to reasoning enhancement for instruction following.",
    "summary": "arXiv:2506.22865v1 Announce Type: new Abstract: Recent advancements in Large Language Models (LLMs) have revealed a significant performance gap between closed-source and open-source models, particularly in tasks requiring complex reasoning and precise instruction following. This paper introduces ReasonBridge, a methodology that efficiently transfers reasoning capabilities from powerful closed-source to open-source models through a novel hierarchical knowledge distillation framework. We develop a tailored dataset Reason1K with only 1,000 carefully curated reasoning traces emphasizing difficulty, diversity, and quality. These traces are filtered from across multiple domains using a structured multi-criteria selection algorithm. Our transfer learning approach incorporates: (1) a hierarchical distillation process capturing both strategic abstraction and tactical implementation patterns, (2) a sparse reasoning-focused adapter architecture requiring only 0.3% additional trainable parameters, and (3) a test-time compute scaling mechanism using guided inference interventions. Comprehensive evaluations demonstrate that ReasonBridge improves reasoning capabilities in open-source models by up to 23% on benchmark tasks, significantly narrowing the gap with closed-source models. Notably, the enhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its performance on competition-level AIME problems. Our methodology generalizes effectively across diverse reasoning domains and model architectures, establishing a sample-efficient approach to reasoning enhancement for instruction following.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22865",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How to train your model dynamically using adversarial data",
    "description": "",
    "summary": "How to train your model dynamically using adversarial data What you will learn here - üí°the basic ide...",
    "pubDate": "Sat, 16 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mnist-adversarial",
    "thumbnail": "https://huggingface.co/blog/assets/88_mnist_adversarial/mnist-adversarial.png"
  },
  {
    "title": "Multimodal Medical Code Tokenizer",
    "description": "arXiv:2502.04397v3 Announce Type: replace-cross Abstract: Foundation models trained on patient electronic health records (EHRs) require tokenizing medical data into sequences of discrete vocabulary items. Existing tokenizers treat medical codes from EHRs as isolated textual tokens. However, each medical code is defined by its textual description, its position in ontological hierarchies, and its relationships to other codes, such as disease co-occurrences and drug-treatment associations. Medical vocabularies contain more than 600,000 codes with critical information for clinical reasoning. We introduce MedTok, a multimodal medical code tokenizer that uses the text descriptions and relational context of codes. MedTok processes text using a language model encoder and encodes the relational structure with a graph encoder. It then quantizes both modalities into a unified token space, preserving modality-specific and cross-modality information. We integrate MedTok into five EHR models and evaluate it on operational and clinical tasks across in-patient and out-patient datasets, including outcome prediction, diagnosis classification, drug recommendation, and risk stratification. Swapping standard EHR tokenizers with MedTok improves AUPRC across all EHR models, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.32% on EHRShot, with the largest gains in drug recommendation. Beyond EHR modeling, we demonstrate using MedTok tokenizer with medical QA systems. Our results demonstrate the potential of MedTok as a unified tokenizer for medical codes, improving tokenization for medical foundation models.",
    "summary": "arXiv:2502.04397v3 Announce Type: replace-cross Abstract: Foundation models trained on patient electronic health records (EHRs) require tokenizing medical data into sequences of discrete vocabulary items. Existing tokenizers treat medical codes from EHRs as isolated textual tokens. However, each medical code is defined by its textual description, its position in ontological hierarchies, and its relationships to other codes, such as disease co-occurrences and drug-treatment associations. Medical vocabularies contain more than 600,000 codes with critical information for clinical reasoning. We introduce MedTok, a multimodal medical code tokenizer that uses the text descriptions and relational context of codes. MedTok processes text using a language model encoder and encodes the relational structure with a graph encoder. It then quantizes both modalities into a unified token space, preserving modality-specific and cross-modality information. We integrate MedTok into five EHR models and evaluate it on operational and clinical tasks across in-patient and out-patient datasets, including outcome prediction, diagnosis classification, drug recommendation, and risk stratification. Swapping standard EHR tokenizers with MedTok improves AUPRC across all EHR models, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.32% on EHRShot, with the largest gains in drug recommendation. Beyond EHR modeling, we demonstrate using MedTok tokenizer with medical QA systems. Our results demonstrate the potential of MedTok as a unified tokenizer for medical codes, improving tokenization for medical foundation models.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.04397",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Archaic„ÄÅÊó•Êú¨Ë™ûÁâπÂåñÂûãRAG„Ç∑„Çπ„ÉÜ„É†AI„ÇíÈñãÁô∫„ÄÇË£ΩÈÄ†Ê•≠ÂàÜÈáé„Åß„Éà„ÉÉ„Éó„ÇØ„É©„Çπ„ÅÆÊ≠£Á≠îÁéá",
    "description": "<p>Archaic„ÅØÊó•Êú¨Ë™ûÊ•≠ÂãôÊñáÊõ∏„Å´ÁâπÂåñ„Åó„ÅüRAG„Ç∑„Çπ„ÉÜ„É†AI„ÇíÈñãÁô∫„ÄÇÂÖ¨Èñã„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„ÅÆË©ï‰æ°„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅßË£ΩÈÄ†Ê•≠„Ç´„ÉÜ„Ç¥„É™„Å®ÂÖ®‰ΩìÂπ≥Âùá„Åß„Éà„ÉÉ„Éó„ÇØ„É©„Çπ„ÅÆÊ≠£Á≠îÁéá„ÇíË®òÈå≤„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Êó•Êú¨Ë™ûÊ•≠ÂãôÊñáÊõ∏„Å´ÁâπÂåñ„Åó„ÅüRAG [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/archaic-develops-japanese-specific-rag/'>Archaic„ÄÅÊó•Êú¨Ë™ûÁâπÂåñÂûãRAG„Ç∑„Çπ„ÉÜ„É†AI„ÇíÈñãÁô∫„ÄÇË£ΩÈÄ†Ê•≠ÂàÜÈáé„Åß„Éà„ÉÉ„Éó„ÇØ„É©„Çπ„ÅÆÊ≠£Á≠îÁéá</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>Archaic„ÅØÊó•Êú¨Ë™ûÊ•≠ÂãôÊñáÊõ∏„Å´ÁâπÂåñ„Åó„ÅüRAG„Ç∑„Çπ„ÉÜ„É†AI„ÇíÈñãÁô∫„ÄÇÂÖ¨Èñã„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„ÅÆË©ï‰æ°„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅßË£ΩÈÄ†Ê•≠„Ç´„ÉÜ„Ç¥„É™„Å®ÂÖ®‰ΩìÂπ≥Âùá„Åß„Éà„ÉÉ„Éó„ÇØ„É©„Çπ„ÅÆÊ≠£Á≠îÁéá„ÇíË®òÈå≤„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Êó•Êú¨Ë™ûÊ•≠ÂãôÊñáÊõ∏„Å´ÁâπÂåñ„Åó„ÅüRAG [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/archaic-develops-japanese-specific-rag/'>Archaic„ÄÅÊó•Êú¨Ë™ûÁâπÂåñÂûãRAG„Ç∑„Çπ„ÉÜ„É†AI„ÇíÈñãÁô∫„ÄÇË£ΩÈÄ†Ê•≠ÂàÜÈáé„Åß„Éà„ÉÉ„Éó„ÇØ„É©„Çπ„ÅÆÊ≠£Á≠îÁéá</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Wed, 18 Jun 2025 05:51:09 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/archaic-develops-japanese-specific-rag/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/Archaic-develops-Japanese-specific-RAG1.png"
  },
  {
    "title": "Introducing the Private Hub: A New Way to Build With Machine Learning",
    "description": "",
    "summary": "Introducing the Private Hub: A New Way to Build With Machine Learning June 2023 Update: The Private ...",
    "pubDate": "Wed, 03 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-private-hub",
    "thumbnail": "https://huggingface.co/blog/assets/92_introducing_private_hub/thumbnail.png"
  },
  {
    "title": "Personalizing travel at scale with OpenAI",
    "description": "By integrating its data systems with OpenAI‚Äôs LLMs, Booking.com delivers smarter search, faster support, and intent-driven travel experiences.",
    "summary": "By integrating its data systems with OpenAI‚Äôs LLMs, Booking.com delivers smarter search, faster support, and intent-driven travel experiences.",
    "pubDate": "Thu, 20 Mar 2025 23:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/booking-com",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation",
    "description": "arXiv:2506.22518v1 Announce Type: cross Abstract: Graph-based retrieval-augmented generation (RAG) enables large language models (LLMs) to ground responses with structured external knowledge from up-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs often rely on a weak retriever in graph-based RAG: I) Due to the lack of ground truth, the retriever is often trained on weak supervision, which often introduces spurious signals to the LLMs. II) Due to the abstraction of graph data, the retrieved knowledge is often presented in unorganized forms. To mitigate the issue, we present Refined Graph-based RAG (ReG) to align weak retrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM feedback to get rid of spurious signals and improve the quality of the supervision. Meanwhile, ReG introduces a structure-aware reorganization module to refactor the retrieval results into logically coherent evidence chains. Experiments on prominent benchmarks demonstrate that ReG significantly and consistently brings improvements across different LLM backbones by up to 10%. The improved supervision quality enables ReG to match the state-of-the-art performance with 5% training data and to transfer to out-of-distribution KGs. Notably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token cost by up to 30% and improves the performance by up to 4%.",
    "summary": "arXiv:2506.22518v1 Announce Type: cross Abstract: Graph-based retrieval-augmented generation (RAG) enables large language models (LLMs) to ground responses with structured external knowledge from up-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs often rely on a weak retriever in graph-based RAG: I) Due to the lack of ground truth, the retriever is often trained on weak supervision, which often introduces spurious signals to the LLMs. II) Due to the abstraction of graph data, the retrieved knowledge is often presented in unorganized forms. To mitigate the issue, we present Refined Graph-based RAG (ReG) to align weak retrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM feedback to get rid of spurious signals and improve the quality of the supervision. Meanwhile, ReG introduces a structure-aware reorganization module to refactor the retrieval results into logically coherent evidence chains. Experiments on prominent benchmarks demonstrate that ReG significantly and consistently brings improvements across different LLM backbones by up to 10%. The improved supervision quality enables ReG to match the state-of-the-art performance with 5% training data and to transfer to out-of-distribution KGs. Notably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token cost by up to 30% and improves the performance by up to 4%.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22518",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Dehazing Light Microscopy Images with Guided Conditional Flow Matching: finding a sweet spot between fidelity and realism",
    "description": "arXiv:2506.22397v2 Announce Type: replace-cross Abstract: Fluorescence microscopy is a major driver of scientific progress in the life sciences. Although high-end confocal microscopes are capable of filtering out-of-focus light, cheaper and more accessible microscopy modalities, such as widefield microscopy, can not, which consequently leads to hazy image data. Computational dehazing is trying to combine the best of both worlds, leading to cheap microscopy but crisp-looking images. The perception-distortion trade-off tells us that we can optimize either for data fidelity, e.g. low MSE or high PSNR, or for data realism, measured by perceptual metrics such as LPIPS or FID. Existing methods either prioritize fidelity at the expense of realism, or produce perceptually convincing results that lack quantitative accuracy. In this work, we propose HazeMatching, a novel iterative method for dehazing light microscopy images, which effectively balances these objectives. Our goal was to find a balanced trade-off between the fidelity of the dehazing results and the realism of individual predictions (samples). We achieve this by adapting the conditional flow matching framework by guiding the generative process with a hazy observation in the conditional velocity field. We evaluate HazeMatching on 5 datasets, covering both synthetic and real data, assessing both distortion and perceptual quality. Our method is compared against 7 baselines, achieving a consistent balance between fidelity and realism on average. Additionally, with calibration analysis, we show that HazeMatching produces well-calibrated predictions. Note that our method does not need an explicit degradation operator to exist, making it easily applicable on real microscopy data. All data used for training and evaluation and our code will be publicly available under a permissive license.",
    "summary": "arXiv:2506.22397v2 Announce Type: replace-cross Abstract: Fluorescence microscopy is a major driver of scientific progress in the life sciences. Although high-end confocal microscopes are capable of filtering out-of-focus light, cheaper and more accessible microscopy modalities, such as widefield microscopy, can not, which consequently leads to hazy image data. Computational dehazing is trying to combine the best of both worlds, leading to cheap microscopy but crisp-looking images. The perception-distortion trade-off tells us that we can optimize either for data fidelity, e.g. low MSE or high PSNR, or for data realism, measured by perceptual metrics such as LPIPS or FID. Existing methods either prioritize fidelity at the expense of realism, or produce perceptually convincing results that lack quantitative accuracy. In this work, we propose HazeMatching, a novel iterative method for dehazing light microscopy images, which effectively balances these objectives. Our goal was to find a balanced trade-off between the fidelity of the dehazing results and the realism of individual predictions (samples). We achieve this by adapting the conditional flow matching framework by guiding the generative process with a hazy observation in the conditional velocity field. We evaluate HazeMatching on 5 datasets, covering both synthetic and real data, assessing both distortion and perceptual quality. Our method is compared against 7 baselines, achieving a consistent balance between fidelity and realism on average. Additionally, with calibration analysis, we show that HazeMatching produces well-calibrated predictions. Note that our method does not need an explicit degradation operator to exist, making it easily applicable on real microscopy data. All data used for training and evaluation and our code will be publicly available under a permissive license.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22397",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Benchmarking Text Generation Inference",
    "description": "",
    "summary": "Benchmarking Text Generation Inference In this blog we will be exploring Text Generation Inference‚Äôs...",
    "pubDate": "Wed, 29 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-benchmarking",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-benchmarking/tgi-benchmarking-thumbnail.png"
  },
  {
    "title": "Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset",
    "description": "",
    "summary": "From screenshots to HTML code: Introducing the WebSight dataset In the world of web development, tur...",
    "pubDate": "Fri, 15 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/websight",
    "thumbnail": "https://huggingface.co/blog/assets/websight/thumbnail.png"
  },
  {
    "title": "Special projects",
    "description": "Impactful scientific work requires working on the right problems‚Äîproblems which are not just interesting, but whose solutions matter.",
    "summary": "Impactful scientific work requires working on the right problems‚Äîproblems which are not just interesting, but whose solutions matter.",
    "pubDate": "Thu, 28 Jul 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/special-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Parquet Dedupe on Hugging Face Hub",
    "description": "",
    "summary": "Improving Parquet Dedupe on Hugging Face Hub The Xet team at Hugging Face is working on improving th...",
    "pubDate": "Sat, 05 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/improve_parquet_dedupe",
    "thumbnail": "https://huggingface.co/blog/assets/improve_parquet_dedupe/thumbnail.png"
  },
  {
    "title": "OpenAI Expands Leadership with Fidji Simo",
    "description": "Read the message Sam shared with the company earlier today.",
    "summary": "Read the message Sam shared with the company earlier today.",
    "pubDate": "Wed, 07 May 2025 21:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-expansion-with-fidji-simo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Hugging Face Embedding Container for Amazon SageMaker",
    "description": "",
    "summary": "Introducing the Hugging Face Embedding Container for Amazon SageMaker We are excited to announce tha...",
    "pubDate": "Fri, 07 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-huggingface-embedding",
    "thumbnail": "https://huggingface.co/blog/assets/sagemaker-huggingface-embedding/thumbnail.jpg"
  },
  {
    "title": "Training and Finetuning Reranker Models with Sentence Transformers v4",
    "description": "",
    "summary": "Training and Finetuning Reranker Models with Sentence Transformers v4 Sentence Transformers is a Pyt...",
    "pubDate": "Wed, 26 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-reranker",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "The MIT-Portugal Program enters Phase 4",
    "description": "New phase will support continued exploration of ideas and solutions in fields ranging from AI to nanotech to climate ‚Äî with emphasis on educational exchanges and entrepreneurship.",
    "summary": "New phase will support continued exploration of ideas and solutions in fields ranging from AI to nanotech to climate ‚Äî with emphasis on educational exchanges and entrepreneurship.",
    "pubDate": "Wed, 30 Apr 2025 16:20:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-portugal-program-enters-phase-4-0430",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-portugal-2024-Conference.jpg"
  },
  {
    "title": "OpenAI Board Forms Safety and Security Committee",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 28 May 2024 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-board-forms-safety-and-security-committee",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "XetHub is joining Hugging Face!",
    "description": "",
    "summary": "XetHub is joining Hugging Face! We are super excited to officially announce that Hugging Face acquir...",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xethub-joins-hf",
    "thumbnail": "https://huggingface.co/blog/assets/xethub-joins-hf/thumbnail.png"
  },
  {
    "title": "Introducing W√ºrstchen: Fast Diffusion for Image Generation",
    "description": "",
    "summary": "Introducing W√ºrstchen: Fast Diffusion for Image Generation What is W√ºrstchen? W√ºrstchen is a diffusi...",
    "pubDate": "Wed, 13 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/wuerstchen",
    "thumbnail": "https://huggingface.co/blog/assets/wuerstchen/thumbnail.jpg"
  },
  {
    "title": "With AI, researchers predict the location of virtually any protein within a human cell",
    "description": "Trained with a joint understanding of protein and cell behavior, the model could help with diagnosing disease and developing new drugs.",
    "summary": "Trained with a joint understanding of protein and cell behavior, the model could help with diagnosing disease and developing new drugs.",
    "pubDate": "Thu, 15 May 2025 10:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/researchers-predict-protein-location-within-human-cell-using-ai-0515",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-ProteinLocalization-01-press.jpg"
  },
  {
    "title": "Curious Causality-Seeking Agents Learn Meta Causal World",
    "description": "arXiv:2506.23068v1 Announce Type: cross Abstract: When building a world model, a common assumption is that the environment has a single, unchanging underlying causal rule, like applying Newton's laws to every situation. In reality, what appears as a drifting causal mechanism is often the manifestation of a fixed underlying mechanism seen through a narrow observational window. This brings about a problem that, when building a world model, even subtle shifts in policy or environment states can alter the very observed causal mechanisms. In this work, we introduce the textbf{Meta-Causal Graph} as world models, a minimal unified representation that efficiently encodes the transformation rules governing how causal structures shift across different latent world states. A single Meta-Causal Graph is composed of multiple causal subgraphs, each triggered by meta state, which is in the latent state space. Building on this representation, we introduce a textbf{Causality-Seeking Agent} whose objectives are to (1) identify the meta states that trigger each subgraph, (2) discover the corresponding causal relationships by agent curiosity-driven intervention policy, and (3) iteratively refine the Meta-Causal Graph through ongoing curiosity-driven exploration and agent experiences. Experiments on both synthetic tasks and a challenging robot arm manipulation task demonstrate that our method robustly captures shifts in causal dynamics and generalizes effectively to previously unseen contexts.",
    "summary": "arXiv:2506.23068v1 Announce Type: cross Abstract: When building a world model, a common assumption is that the environment has a single, unchanging underlying causal rule, like applying Newton's laws to every situation. In reality, what appears as a drifting causal mechanism is often the manifestation of a fixed underlying mechanism seen through a narrow observational window. This brings about a problem that, when building a world model, even subtle shifts in policy or environment states can alter the very observed causal mechanisms. In this work, we introduce the textbf{Meta-Causal Graph} as world models, a minimal unified representation that efficiently encodes the transformation rules governing how causal structures shift across different latent world states. A single Meta-Causal Graph is composed of multiple causal subgraphs, each triggered by meta state, which is in the latent state space. Building on this representation, we introduce a textbf{Causality-Seeking Agent} whose objectives are to (1) identify the meta states that trigger each subgraph, (2) discover the corresponding causal relationships by agent curiosity-driven intervention policy, and (3) iteratively refine the Meta-Causal Graph through ongoing curiosity-driven exploration and agent experiences. Experiments on both synthetic tasks and a challenging robot arm manipulation task demonstrate that our method robustly captures shifts in causal dynamics and generalizes effectively to previously unseen contexts.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23068",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Rewriting SymCrypt in Rust to modernize Microsoft‚Äôs cryptographic library",
    "description": "<p>We're rewriting parts of Microsoft's SymCrypt cryptographic library in Rust to improve memory safety and defend against side-channel attacks, enabling formal verification while maintaining backward compatibility via a Rust-to-C compiler.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/'>Rewriting SymCrypt in Rust to modernize Microsoft‚Äôs cryptographic library¬†</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>We're rewriting parts of Microsoft's SymCrypt cryptographic library in Rust to improve memory safety and defend against side-channel attacks, enabling formal verification while maintaining backward compatibility via a Rust-to-C compiler.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/'>Rewriting SymCrypt in Rust to modernize Microsoft‚Äôs cryptographic library¬†</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Tue, 10 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Rationale engineering generates a compact new tool for gene therapy",
    "description": "Researchers redesign a compact RNA-guided enzyme from bacteria, making it an efficient editor of human DNA.",
    "summary": "Researchers redesign a compact RNA-guided enzyme from bacteria, making it an efficient editor of human DNA.",
    "pubDate": "Wed, 28 May 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/rationale-engineering-generates-compact-new-tool-gene-therapy-0528",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/phylogenetic-tree.jpg"
  },
  {
    "title": "Introducing the Hugging Face LLM Inference Container for Amazon SageMaker",
    "description": "",
    "summary": "Introducing the Hugging Face LLM Inference Container for Amazon SageMaker This is an example on how ...",
    "pubDate": "Wed, 31 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-huggingface-llm",
    "thumbnail": "https://huggingface.co/blog/assets/145_sagemaker-huggingface-llm/thumbnail.jpg"
  },
  {
    "title": "The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models",
    "description": "arXiv:2411.08870v3 Announce Type: replace-cross Abstract: Several recent works seek to adapt general-purpose large language models (LLMs) and vision-language models (VLMs) for medical applications through continued pretraining on publicly available biomedical corpora. These works typically claim that such domain-adaptive pretraining improves performance on various downstream medical tasks, such as answering medical exam questions. In this paper, we compare ten 'medical' LLMs and two VLMs against their corresponding base models, arriving at a different conclusion: all medical VLMs and nearly all medical LLMs fail to consistently improve over their base models in the zero-/few-shot prompting and supervised fine-tuning regimes for medical question answering (QA). For instance, on clinical-note-based QA tasks in the 3-shot setting, medical LLMs outperform their base models in only 26.7% of cases, reach a (statistical) tie in 16.7% of cases, and perform significantly worse in the remaining 56.7% of cases. Our conclusions are based on (i) comparing each medical model directly against its base model; (ii) optimizing the prompts for each model separately in zero-/few-shot prompting; and (iii) accounting for statistical uncertainty in comparisons. Our findings suggest that state-of-the-art general-domain models may already exhibit strong medical knowledge and reasoning capabilities, and offer recommendations to strengthen the conclusions of future studies.",
    "summary": "arXiv:2411.08870v3 Announce Type: replace-cross Abstract: Several recent works seek to adapt general-purpose large language models (LLMs) and vision-language models (VLMs) for medical applications through continued pretraining on publicly available biomedical corpora. These works typically claim that such domain-adaptive pretraining improves performance on various downstream medical tasks, such as answering medical exam questions. In this paper, we compare ten 'medical' LLMs and two VLMs against their corresponding base models, arriving at a different conclusion: all medical VLMs and nearly all medical LLMs fail to consistently improve over their base models in the zero-/few-shot prompting and supervised fine-tuning regimes for medical question answering (QA). For instance, on clinical-note-based QA tasks in the 3-shot setting, medical LLMs outperform their base models in only 26.7% of cases, reach a (statistical) tie in 16.7% of cases, and perform significantly worse in the remaining 56.7% of cases. Our conclusions are based on (i) comparing each medical model directly against its base model; (ii) optimizing the prompts for each model separately in zero-/few-shot prompting; and (iii) accounting for statistical uncertainty in comparisons. Our findings suggest that state-of-the-art general-domain models may already exhibit strong medical knowledge and reasoning capabilities, and offer recommendations to strengthen the conclusions of future studies.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.08870",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate",
    "description": "",
    "summary": "Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate This article shows how to get an incre...",
    "pubDate": "Fri, 16 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-inference-pytorch-scripts",
    "thumbnail": "https://huggingface.co/blog/assets/bloom-inference-pytorch-scripts/thumbnail.png"
  },
  {
    "title": "Why Settle for One? Text-to-ImageSet Generation and Evaluation",
    "description": "arXiv:2506.23275v1 Announce Type: cross Abstract: Despite remarkable progress in Text-to-Image models, many real-world applications require generating coherent image sets with diverse consistency requirements. Existing consistent methods often focus on a specific domain with specific aspects of consistency, which significantly constrains their generalizability to broader applications. In this paper, we propose a more challenging problem, Text-to-ImageSet (T2IS) generation, which aims to generate sets of images that meet various consistency requirements based on user instructions. To systematically study this problem, we first introduce $textbf{T2IS-Bench}$ with 596 diverse instructions across 26 subcategories, providing comprehensive coverage for T2IS generation. Building on this, we propose $textbf{T2IS-Eval}$, an evaluation framework that transforms user instructions into multifaceted assessment criteria and employs effective evaluators to adaptively assess consistency fulfillment between criteria and generated sets. Subsequently, we propose $textbf{AutoT2IS}$, a training-free framework that maximally leverages pretrained Diffusion Transformers' in-context capabilities to harmonize visual elements to satisfy both image-level prompt alignment and set-level visual consistency. Extensive experiments on T2IS-Bench reveal that diverse consistency challenges all existing methods, while our AutoT2IS significantly outperforms current generalized and even specialized approaches. Our method also demonstrates the ability to enable numerous underexplored real-world applications, confirming its substantial practical value. Visit our project in https://chengyou-jia.github.io/T2IS-Home.",
    "summary": "arXiv:2506.23275v1 Announce Type: cross Abstract: Despite remarkable progress in Text-to-Image models, many real-world applications require generating coherent image sets with diverse consistency requirements. Existing consistent methods often focus on a specific domain with specific aspects of consistency, which significantly constrains their generalizability to broader applications. In this paper, we propose a more challenging problem, Text-to-ImageSet (T2IS) generation, which aims to generate sets of images that meet various consistency requirements based on user instructions. To systematically study this problem, we first introduce $textbf{T2IS-Bench}$ with 596 diverse instructions across 26 subcategories, providing comprehensive coverage for T2IS generation. Building on this, we propose $textbf{T2IS-Eval}$, an evaluation framework that transforms user instructions into multifaceted assessment criteria and employs effective evaluators to adaptively assess consistency fulfillment between criteria and generated sets. Subsequently, we propose $textbf{AutoT2IS}$, a training-free framework that maximally leverages pretrained Diffusion Transformers' in-context capabilities to harmonize visual elements to satisfy both image-level prompt alignment and set-level visual consistency. Extensive experiments on T2IS-Bench reveal that diverse consistency challenges all existing methods, while our AutoT2IS significantly outperforms current generalized and even specialized approaches. Our method also demonstrates the ability to enable numerous underexplored real-world applications, confirming its substantial practical value. Visit our project in https://chengyou-jia.github.io/T2IS-Home.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23275",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Rises for Measuring Local Distributivity in Lattices",
    "description": "arXiv:2506.23168v1 Announce Type: new Abstract: Distributivity is a well-established and extensively studied notion in lattice theory. In the context of data analysis, particularly within Formal Concept Analysis (FCA), lattices are often observed to exhibit a high degree of distributivity. However, no standardized measure exists to quantify this property. In this paper, we introduce the notion of rises in (concept) lattices as a means to assess distributivity. Rises capture how the number of attributes or objects in covering concepts change within the concept lattice. We show that a lattice is distributive if and only if no non-unit rises occur. Furthermore, we relate rises to the classical notion of meet- and join distributivity. We observe that concept lattices from real-world data are to a high degree join-distributive, but much less meet-distributive. We additionally study how join-distributivity manifests on the level of ordered sets.",
    "summary": "arXiv:2506.23168v1 Announce Type: new Abstract: Distributivity is a well-established and extensively studied notion in lattice theory. In the context of data analysis, particularly within Formal Concept Analysis (FCA), lattices are often observed to exhibit a high degree of distributivity. However, no standardized measure exists to quantify this property. In this paper, we introduce the notion of rises in (concept) lattices as a means to assess distributivity. Rises capture how the number of attributes or objects in covering concepts change within the concept lattice. We show that a lattice is distributive if and only if no non-unit rises occur. Furthermore, we relate rises to the classical notion of meet- and join distributivity. We observe that concept lattices from real-world data are to a high degree join-distributive, but much less meet-distributive. We additionally study how join-distributivity manifests on the level of ordered sets.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23168",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop",
    "description": "arXiv:2506.23351v1 Announce Type: cross Abstract: Embodied Artificial Intelligence (Embodied AI) is an emerging frontier in robotics, driven by the need for autonomous systems that can perceive, reason, and act in complex physical environments. While single-arm systems have shown strong task performance, collaborative dual-arm systems are essential for handling more intricate tasks involving rigid, deformable, and tactile-sensitive objects. To advance this goal, we launched the RoboTwin Dual-Arm Collaboration Challenge at the 2nd MEIS Workshop, CVPR 2025. Built on the RoboTwin Simulation platform (1.0 and 2.0) and the AgileX COBOT-Magic Robot platform, the competition consisted of three stages: Simulation Round 1, Simulation Round 2, and a final Real-World Round. Participants totally tackled 17 dual-arm manipulation tasks, covering rigid, deformable, and tactile-based scenarios. The challenge attracted 64 global teams and over 400 participants, producing top-performing solutions like SEM and AnchorDP3 and generating valuable insights into generalizable bimanual policy learning. This report outlines the competition setup, task design, evaluation methodology, key findings and future direction, aiming to support future research on robust and generalizable bimanual manipulation policies. The Challenge Webpage is available at https://robotwin-benchmark.github.io/cvpr-2025-challenge/.",
    "summary": "arXiv:2506.23351v1 Announce Type: cross Abstract: Embodied Artificial Intelligence (Embodied AI) is an emerging frontier in robotics, driven by the need for autonomous systems that can perceive, reason, and act in complex physical environments. While single-arm systems have shown strong task performance, collaborative dual-arm systems are essential for handling more intricate tasks involving rigid, deformable, and tactile-sensitive objects. To advance this goal, we launched the RoboTwin Dual-Arm Collaboration Challenge at the 2nd MEIS Workshop, CVPR 2025. Built on the RoboTwin Simulation platform (1.0 and 2.0) and the AgileX COBOT-Magic Robot platform, the competition consisted of three stages: Simulation Round 1, Simulation Round 2, and a final Real-World Round. Participants totally tackled 17 dual-arm manipulation tasks, covering rigid, deformable, and tactile-based scenarios. The challenge attracted 64 global teams and over 400 participants, producing top-performing solutions like SEM and AnchorDP3 and generating valuable insights into generalizable bimanual policy learning. This report outlines the competition setup, task design, evaluation methodology, key findings and future direction, aiming to support future research on robust and generalizable bimanual manipulation policies. The Challenge Webpage is available at https://robotwin-benchmark.github.io/cvpr-2025-challenge/.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23351",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Hugging Face Hub for Galleries, Libraries, Archives and Museums",
    "description": "",
    "summary": "The Hugging Face Hub for Galleries, Libraries, Archives and Museums The Hugging Face Hub for Galleri...",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hf-hub-glam-guide",
    "thumbnail": "https://huggingface.co/blog/assets/144_hf_hub_glam_guide/thumbnail.png"
  },
  {
    "title": "Announcing New Dataset Search Features",
    "description": "",
    "summary": "Announcing New Dataset Search Features The AI and ML community has shared more than 180,000 public d...",
    "pubDate": "Mon, 08 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/datasets-filters",
    "thumbnail": "https://huggingface.co/blog/assets/datasets-filters/thumbnail.png"
  },
  {
    "title": "Try new data visualizations and graphs for finance queries in AI Mode.",
    "description": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-600x600.format-webp.webp' />Today, we‚Äôre starting to roll out interactive chart visualizations in AI Mode in Labs to help bring financial data to life for questions on stocks and mutual funds.Now, ‚Ä¶",
    "summary": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-600x600.format-webp.webp' />Today, we‚Äôre starting to roll out interactive chart visualizations in AI Mode in Labs to help bring financial data to life for questions on stocks and mutual funds.Now, ‚Ä¶",
    "pubDate": "Thu, 05 Jun 2025 19:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/ai-mode-data-visualization/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-1440x810.png"
  },
  {
    "title": "AudioLDM 2, but faster ‚ö°Ô∏è",
    "description": "",
    "summary": "AudioLDM 2, but faster ‚ö°Ô∏è AudioLDM 2 was proposed in AudioLDM 2: Learning Holistic Audio Generation ...",
    "pubDate": "Wed, 30 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/audioldm2",
    "thumbnail": "https://huggingface.co/blog/assets/161_audioldm2/thumbnail.png"
  },
  {
    "title": "MTEB: Massive Text Embedding Benchmark",
    "description": "",
    "summary": "MTEB: Massive Text Embedding Benchmark MTEB is a massive benchmark for measuring the performance of ...",
    "pubDate": "Wed, 19 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mteb",
    "thumbnail": "https://huggingface.co/blog/assets/110_mteb/thumbnail.png"
  },
  {
    "title": "What's new in Diffusers? üé®",
    "description": "",
    "summary": "What's new in Diffusers? üé® A month and a half ago we released diffusers , a library that provides a ...",
    "pubDate": "Mon, 12 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-2nd-month",
    "thumbnail": "https://huggingface.co/blog/assets/102_diffusers_2nd_month/inpainting.png"
  },
  {
    "title": "Proximal Policy Optimization",
    "description": "We‚Äôre releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune. PPO has become the default reinforcement learning algorithm at OpenAI because of its ease of use and good performance.",
    "summary": "We‚Äôre releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune. PPO has become the default reinforcement learning algorithm at OpenAI because of its ease of use and good performance.",
    "pubDate": "Thu, 20 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-ppo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome spaCy to the ü§ó Hub",
    "description": "",
    "summary": "Welcome spaCy to the Hugging Face Hub spaCy is a popular library for advanced Natural Language Proce...",
    "pubDate": "Tue, 13 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spacy",
    "thumbnail": "https://huggingface.co/blog/assets/23_spacy/thumbnail.png"
  },
  {
    "title": "Introducing RWKV ‚Äî An RNN with the advantages of a transformer",
    "description": "",
    "summary": "Introducing RWKV - An RNN with the advantages of a transformer ChatGPT and chatbot-powered applicati...",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rwkv",
    "thumbnail": "https://huggingface.co/blog/assets/142_rwkv/rwkv_thumbnail.png"
  },
  {
    "title": "Variational lossy autoencoder",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 08 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variational-lossy-autoencoder",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning complex goals with iterated amplification",
    "description": "We‚Äôre proposing an AI safety technique called iterated amplification that lets us specify complicated behaviors and goals that are beyond human scale, by demonstrating how to decompose a task into simpler sub-tasks, rather than by providing labeled data or a reward function. Although this idea is in its very early stages and we have only completed experiments on simple toy algorithmic domains, we‚Äôve decided to present it in its preliminary state because we think it could prove to be a scalable approach to AI¬†safety.",
    "summary": "We‚Äôre proposing an AI safety technique called iterated amplification that lets us specify complicated behaviors and goals that are beyond human scale, by demonstrating how to decompose a task into simpler sub-tasks, rather than by providing labeled data or a reward function. Although this idea is in its very early stages and we have only completed experiments on simple toy algorithmic domains, we‚Äôve decided to present it in its preliminary state because we think it could prove to be a scalable approach to AI¬†safety.",
    "pubDate": "Mon, 22 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-complex-goals-with-iterated-amplification",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Detecting misbehavior in frontier reasoning models",
    "description": "Frontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM to monitor their chains-of-thought. Penalizing their ‚Äúbad thoughts‚Äù doesn‚Äôt stop the majority of misbehavior‚Äîit makes them hide their intent.",
    "summary": "Frontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM to monitor their chains-of-thought. Penalizing their ‚Äúbad thoughts‚Äù doesn‚Äôt stop the majority of misbehavior‚Äîit makes them hide their intent.",
    "pubDate": "Mon, 10 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chain-of-thought-monitoring",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Community Tools on HuggingChat",
    "description": "",
    "summary": "Introducing Community Tools on HuggingChat Today we‚Äôre releasing our latest feature on HuggingChat: ...",
    "pubDate": "Mon, 16 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-tools",
    "thumbnail": "https://huggingface.co/blog/assets/community-tools/thumbnail.png"
  },
  {
    "title": "Robust LLM Unlearning with MUDMAN: Meta-Unlearning with Disruption Masking And Normalization",
    "description": "arXiv:2506.12484v3 Announce Type: replace-cross Abstract: Language models can retain dangerous knowledge and skills even after extensive safety fine-tuning, posing both misuse and misalignment risks. Recent studies show that even specialized unlearning methods can be easily reversed. To address this, we systematically evaluate many existing and novel components of unlearning methods and identify ones crucial for irreversible unlearning. We introduce Disruption Masking, a technique in which we only allow updating weights, where the signs of the unlearning gradient and the retaining gradient are the same. This ensures all updates are non-disruptive. Additionally, we identify the need for normalizing the unlearning gradients, and also confirm the usefulness of meta-learning. We combine these insights into MUDMAN (Meta-Unlearning with Disruption Masking and Normalization) and validate its effectiveness at preventing the recovery of dangerous capabilities. MUDMAN outperforms the prior TAR method by 40%, setting a new state-of-the-art for robust unlearning.",
    "summary": "arXiv:2506.12484v3 Announce Type: replace-cross Abstract: Language models can retain dangerous knowledge and skills even after extensive safety fine-tuning, posing both misuse and misalignment risks. Recent studies show that even specialized unlearning methods can be easily reversed. To address this, we systematically evaluate many existing and novel components of unlearning methods and identify ones crucial for irreversible unlearning. We introduce Disruption Masking, a technique in which we only allow updating weights, where the signs of the unlearning gradient and the retaining gradient are the same. This ensures all updates are non-disruptive. Additionally, we identify the need for normalizing the unlearning gradients, and also confirm the usefulness of meta-learning. We combine these insights into MUDMAN (Meta-Unlearning with Disruption Masking and Normalization) and validate its effectiveness at preventing the recovery of dangerous capabilities. MUDMAN outperforms the prior TAR method by 40%, setting a new state-of-the-art for robust unlearning.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12484",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "We‚Äôre expanding our Gemini 2.5 family of models",
    "description": "Gemini 2.5 Flash and Pro are now generally available, and we‚Äôre introducing 2.5 Flash-Lite, our most cost-efficient and fastest 2.5 model yet.",
    "summary": "Gemini 2.5 Flash and Pro are now generally available, and we‚Äôre introducing 2.5 Flash-Lite, our most cost-efficient and fastest 2.5 model yet.",
    "pubDate": "Tue, 17 Jun 2025 16:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/were-expanding-our-gemini-25-family-of-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_bundle_keyword_social-share_1920-1080.width-1300.png"
  },
  {
    "title": "Introducing Prodigy-HF: a direct integration with Hugging Face",
    "description": "",
    "summary": "Introducing Prodigy-HF Prodigy is an annotation tool made by Explosion, a company well known as the ...",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/prodigy-hf",
    "thumbnail": "https://huggingface.co/blog/assets/171_prodigy_hf/thumbnail.png"
  },
  {
    "title": "Learning from other domains to advance AI evaluation and testing",
    "description": "<p>As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the [&#8230;]</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/'>Learning from other domains to advance AI evaluation and testing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the [&#8230;]</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/'>Learning from other domains to advance AI evaluation and testing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 16:35:06 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "OpenAI o1 System Card External Testers Acknowledgements",
    "description": "OpenAI o1 system card external testers acknowledgements",
    "summary": "OpenAI o1 system card external testers acknowledgements",
    "pubDate": "Thu, 12 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-system-card/external-testers-acknowledgements",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bringing the Artificial Analysis LLM Performance Leaderboard to Hugging Face",
    "description": "",
    "summary": "Bringing the Artificial Analysis LLM Performance Leaderboard to Hugging Face Building applications w...",
    "pubDate": "Fri, 03 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-artificial-analysis",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_artificialanalysis.png"
  },
  {
    "title": "Introducing the SWE-Lancer benchmark",
    "description": "Can frontier LLMs earn $1 million from real-world freelance software engineering?",
    "summary": "Can frontier LLMs earn $1 million from real-world freelance software engineering?",
    "pubDate": "Tue, 18 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/swe-lancer",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling up learning across many different robot types",
    "description": "Robots are great specialists, but poor generalists. Typically, you have to train a model for each task, robot, and environment. Changing a single variable often requires starting from scratch. But what if we could combine the knowledge across robotics and create a way to train a general-purpose robot?",
    "summary": "Robots are great specialists, but poor generalists. Typically, you have to train a model for each task, robot, and environment. Changing a single variable often requires starting from scratch. But what if we could combine the knowledge across robotics and create a way to train a general-purpose robot?",
    "pubDate": "Tue, 03 Oct 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/scaling-up-learning-across-many-different-robot-types/",
    "thumbnail": "https://lh3.googleusercontent.com/KiNtKw6sX-3WmNln5pnEZjPMfM7VJLg0qe4VshEj_H_oXCI9hb6iGWl1DPx79WBb4EVds8mq2wUq_n9s2Lk8kkWazPtootwAUYBKxBEp64WTcEmXa6U=w1200-h630-n-nu"
  },
  {
    "title": "üá®üáø BenCzechMark - Can your LLM Understand Czech?",
    "description": "",
    "summary": "üá®üáø BenCzechMark - Can your LLM Understand Czech? The üá®üáø BenCzechMark is the first and most comprehen...",
    "pubDate": "Tue, 01 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/benczechmark",
    "thumbnail": "https://huggingface.co/blog/assets/187_benczechmark/thumbnail.png"
  },
  {
    "title": "OpenAI‚Äôs response to the Department of Energy on AI infrastructure",
    "description": "Why infrastructure is destiny and how the US can seize it.",
    "summary": "Why infrastructure is destiny and how the US can seize it.",
    "pubDate": "Wed, 07 May 2025 18:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-department-of-energy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Getting Started with Transformers on Habana Gaudi",
    "description": "",
    "summary": "Getting Started with Transformers on Habana Gaudi A couple of weeks ago, we've had the pleasure to a...",
    "pubDate": "Tue, 26 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/getting-started-habana",
    "thumbnail": "https://huggingface.co/blog/assets/61_getting_started_habana/habana01.png"
  },
  {
    "title": "Environment-Driven Online LiDAR-Camera Extrinsic Calibration",
    "description": "arXiv:2502.00801v2 Announce Type: replace-cross Abstract: LiDAR-camera extrinsic calibration (LCEC) is crucial for multi-modal data fusion in mechatronics. Existing methods, whether target-based or target-free, typically rely on customized calibration targets or fixed scene types, limiting their practicality in real-world applications. To address these challenges, we introduce EdO-LCEC, the first environment-driven online calibration approach. Unlike traditional target-free methods, EdO-LCEC observes the feature density of the application environment through a generalizable scene discriminator. Based on this feature density, EdO-LCEC extracts LiDAR intensity and depth features from varying perspectives to achieve higher calibration accuracy. To overcome the challenges of cross-modal feature matching between LiDAR and camera, we propose dual-path correspondence matching (DPCM), which leverages both structural and textural consistency for reliable 3D-2D correspondences. Additionally, our approach models the calibration process as a joint optimization problem utilizing global constraints from multiple views and scenes to enhance accuracy. Extensive experiments on real-world datasets demonstrate that EdO-LCEC outperforms state-of-the-art methods, particularly in sparse or partially overlapping sensor views.",
    "summary": "arXiv:2502.00801v2 Announce Type: replace-cross Abstract: LiDAR-camera extrinsic calibration (LCEC) is crucial for multi-modal data fusion in mechatronics. Existing methods, whether target-based or target-free, typically rely on customized calibration targets or fixed scene types, limiting their practicality in real-world applications. To address these challenges, we introduce EdO-LCEC, the first environment-driven online calibration approach. Unlike traditional target-free methods, EdO-LCEC observes the feature density of the application environment through a generalizable scene discriminator. Based on this feature density, EdO-LCEC extracts LiDAR intensity and depth features from varying perspectives to achieve higher calibration accuracy. To overcome the challenges of cross-modal feature matching between LiDAR and camera, we propose dual-path correspondence matching (DPCM), which leverages both structural and textural consistency for reliable 3D-2D correspondences. Additionally, our approach models the calibration process as a joint optimization problem utilizing global constraints from multiple views and scenes to enhance accuracy. Extensive experiments on real-world datasets demonstrate that EdO-LCEC outperforms state-of-the-art methods, particularly in sparse or partially overlapping sensor views.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.00801",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Achieving binary weight and activation for LLMs using Post-Training Quantization",
    "description": "arXiv:2504.05352v3 Announce Type: replace-cross Abstract: Quantizing large language models (LLMs) to 1-bit precision significantly reduces computational costs, but existing quantization techniques suffer from noticeable performance degradation when using weight and activation precisions below 4 bits (W4A4). In this paper, we propose a post-training quantization framework with W(1+1)A(1*4) configuration, where weights are quantized to 1 bit with an additional 1 bit for fine-grain grouping and activations are quantized to 1 bit with a 4-fold increase in the number of channels. For weight quantization, we propose utilizing Hessian-aware fine-grained grouping along with an EM-based quantization scheme. For activation quantization, we decompose INT4-quantized activations into a 4 * INT1 format equivalently and simultaneously smooth the scaling factors based on quantization errors, which further reduces the quantization errors in activations. Our method surpasses state-of-the-art (SOTA) LLM quantization baselines on W2A4 across multiple tasks, pushing the boundaries of existing LLM quantization methods toward fully binarized models. Code is available at https://github.com/JimmyCrave/LLM-PTQ-binarization.",
    "summary": "arXiv:2504.05352v3 Announce Type: replace-cross Abstract: Quantizing large language models (LLMs) to 1-bit precision significantly reduces computational costs, but existing quantization techniques suffer from noticeable performance degradation when using weight and activation precisions below 4 bits (W4A4). In this paper, we propose a post-training quantization framework with W(1+1)A(1*4) configuration, where weights are quantized to 1 bit with an additional 1 bit for fine-grain grouping and activations are quantized to 1 bit with a 4-fold increase in the number of channels. For weight quantization, we propose utilizing Hessian-aware fine-grained grouping along with an EM-based quantization scheme. For activation quantization, we decompose INT4-quantized activations into a 4 * INT1 format equivalently and simultaneously smooth the scaling factors based on quantization errors, which further reduces the quantization errors in activations. Our method surpasses state-of-the-art (SOTA) LLM quantization baselines on W2A4 across multiple tasks, pushing the boundaries of existing LLM quantization methods toward fully binarized models. Code is available at https://github.com/JimmyCrave/LLM-PTQ-binarization.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.05352",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Solving complex problems with OpenAI o1 models",
    "description": "In this video, we share how the o1 reasoning models can help in domains like coding, strategy, and research.",
    "summary": "In this video, we share how the o1 reasoning models can help in domains like coding, strategy, and research.",
    "pubDate": "Thu, 17 Oct 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/solving-complex-problems-with-openai-o1-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding the capabilities, limitations, and societal impact of large language models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 04 Feb 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/understanding-the-capabilities-limitations-and-societal-impact-of-large-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interpretable and pedagogical examples",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 02 Nov 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/interpretable-and-pedagogical-examples",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Launching the Artificial Analysis Text to Image Leaderboard & Arena",
    "description": "",
    "summary": "Launching the Artificial Analysis Text to Image Leaderboard & Arena In two short years since the adv...",
    "pubDate": "Thu, 06 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-artificial-analysis2",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_artificialanalysis.png"
  },
  {
    "title": "Blazingly fast whisper transcriptions with Inference Endpoints",
    "description": "",
    "summary": "Blazingly fast whisper transcriptions with Inference Endpoints Today we are happy to introduce a new...",
    "pubDate": "Tue, 13 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-whisper-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/fast-whisper-endpoints/thumbnail.png"
  },
  {
    "title": "Optimizing your LLM in production",
    "description": "",
    "summary": "Optimizing your LLM in production Note: This blog post is also available as a documentation page on ...",
    "pubDate": "Fri, 15 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimize-llm",
    "thumbnail": "https://huggingface.co/blog/assets/163_optimize_llm/optimize_llm.png"
  },
  {
    "title": "In-context learning for the classification of manipulation techniques in phishing emails",
    "description": "arXiv:2506.22515v1 Announce Type: cross Abstract: Traditional phishing detection often overlooks psychological manipulation. This study investigates using Large Language Model (LLM) In-Context Learning (ICL) for fine-grained classification of phishing emails based on a taxonomy of 40 manipulation techniques. Using few-shot examples with GPT-4o-mini on real-world French phishing emails (SignalSpam), we evaluated performance against a human-annotated test set (100 emails). The approach effectively identifies prevalent techniques (e.g., Baiting, Curiosity Appeal, Request For Minor Favor) with a promising accuracy of 0.76. This work demonstrates ICL's potential for nuanced phishing analysis and provides insights into attacker strategies.",
    "summary": "arXiv:2506.22515v1 Announce Type: cross Abstract: Traditional phishing detection often overlooks psychological manipulation. This study investigates using Large Language Model (LLM) In-Context Learning (ICL) for fine-grained classification of phishing emails based on a taxonomy of 40 manipulation techniques. Using few-shot examples with GPT-4o-mini on real-world French phishing emails (SignalSpam), we evaluated performance against a human-annotated test set (100 emails). The approach effectively identifies prevalent techniques (e.g., Baiting, Curiosity Appeal, Request For Minor Favor) with a promising accuracy of 0.76. This work demonstrates ICL's potential for nuanced phishing analysis and provides insights into attacker strategies.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22515",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "YouTube: Enhancing the user experience",
    "description": "It‚Äôs all about using our technology and research to help enrich people‚Äôs lives. Like YouTube ‚Äî and its mission to give everyone a voice and show them the world.",
    "summary": "It‚Äôs all about using our technology and research to help enrich people‚Äôs lives. Like YouTube ‚Äî and its mission to give everyone a voice and show them the world.",
    "pubDate": "Fri, 16 Jun 2023 14:55:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/youtube-enhancing-the-user-experience/",
    "thumbnail": "https://lh3.googleusercontent.com/RAMu-2QAkfHieGDWkYFQOMiATW-wFi6jMLyC-YJ4f6Jj1H5BlhxQBmfQrb4RS6Sc6DFLFJqBahK3_1--XjoFPdGqYsCdSuTNr-pTcLkRO5SqvReblIQ=w1200-h630-n-nu"
  },
  {
    "title": "Ethics and Society Newsletter #1",
    "description": "",
    "summary": "Ethics and Society Newsletter #1 Hello, world! Originating as an open-source company, Hugging Face w...",
    "pubDate": "Thu, 22 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-1",
    "thumbnail": "https://huggingface.co/blog/assets/103_ethics-soc-1/thumbnail.png"
  },
  {
    "title": "Instruction-tuning Stable Diffusion with InstructPix2Pix",
    "description": "",
    "summary": "Instruction-tuning Stable Diffusion with InstructPix2Pix This post explores instruction-tuning to te...",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/instruction-tuning-sd",
    "thumbnail": "https://huggingface.co/blog/instruction-tuning-sd/assets/instruction_tuning_sd/thumbnail.png"
  },
  {
    "title": "GPT-2: 6-month follow-up",
    "description": "We‚Äôre releasing the 774 million parameter GPT-2 language model after the release of our small¬†124M model¬†in February, staged release of our medium¬†355M model¬†in May, and subsequent research with partners and the AI community into the model‚Äôs potential for misuse and societal benefit. We‚Äôre also releasing an open-source legal agreement to make it easier for organizations to initiate model-sharing partnerships with each other, and are publishing a technical report about our experience in coordinating with the wider AI research community on publication¬†norms.",
    "summary": "We‚Äôre releasing the 774 million parameter GPT-2 language model after the release of our small¬†124M model¬†in February, staged release of our medium¬†355M model¬†in May, and subsequent research with partners and the AI community into the model‚Äôs potential for misuse and societal benefit. We‚Äôre also releasing an open-source legal agreement to make it easier for organizations to initiate model-sharing partnerships with each other, and are publishing a technical report about our experience in coordinating with the wider AI research community on publication¬†norms.",
    "pubDate": "Tue, 20 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-2-6-month-follow-up",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset",
    "description": "arXiv:2506.22554v1 Announce Type: cross Abstract: Human communication involves a complex interplay of verbal and nonverbal signals, essential for conveying meaning and achieving interpersonal goals. To develop socially intelligent AI technologies, it is crucial to develop models that can both comprehend and generate dyadic behavioral dynamics. To this end, we introduce the Seamless Interaction Dataset, a large-scale collection of over 4,000 hours of face-to-face interaction footage from over 4,000 participants in diverse contexts. This dataset enables the development of AI technologies that understand dyadic embodied dynamics, unlocking breakthroughs in virtual agents, telepresence experiences, and multimodal content analysis tools. We also develop a suite of models that utilize the dataset to generate dyadic motion gestures and facial expressions aligned with human speech. These models can take as input both the speech and visual behavior of their interlocutors. We present a variant with speech from an LLM model and integrations with 2D and 3D rendering methods, bringing us closer to interactive virtual agents. Additionally, we describe controllable variants of our motion models that can adapt emotional responses and expressivity levels, as well as generating more semantically-relevant gestures. Finally, we discuss methods for assessing the quality of these dyadic motion models, which are demonstrating the potential for more intuitive and responsive human-AI interactions.",
    "summary": "arXiv:2506.22554v1 Announce Type: cross Abstract: Human communication involves a complex interplay of verbal and nonverbal signals, essential for conveying meaning and achieving interpersonal goals. To develop socially intelligent AI technologies, it is crucial to develop models that can both comprehend and generate dyadic behavioral dynamics. To this end, we introduce the Seamless Interaction Dataset, a large-scale collection of over 4,000 hours of face-to-face interaction footage from over 4,000 participants in diverse contexts. This dataset enables the development of AI technologies that understand dyadic embodied dynamics, unlocking breakthroughs in virtual agents, telepresence experiences, and multimodal content analysis tools. We also develop a suite of models that utilize the dataset to generate dyadic motion gestures and facial expressions aligned with human speech. These models can take as input both the speech and visual behavior of their interlocutors. We present a variant with speech from an LLM model and integrations with 2D and 3D rendering methods, bringing us closer to interactive virtual agents. Additionally, we describe controllable variants of our motion models that can adapt emotional responses and expressivity levels, as well as generating more semantically-relevant gestures. Finally, we discuss methods for assessing the quality of these dyadic motion models, which are demonstrating the potential for more intuitive and responsive human-AI interactions.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22554",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Solving Rubik‚Äôs Cube with a robot hand",
    "description": "We‚Äôve trained a pair of neural networks to solve the Rubik‚Äôs Cube with a human-like robot hand. The neural networks are trained entirely in simulation, using the same reinforcement learning code as¬†OpenAI Five¬†paired with a new technique called Automatic Domain Randomization (ADR). The system can handle situations it never saw during training, such as being prodded by a¬†stuffed giraffe. This shows that reinforcement learning isn‚Äôt just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.",
    "summary": "We‚Äôve trained a pair of neural networks to solve the Rubik‚Äôs Cube with a human-like robot hand. The neural networks are trained entirely in simulation, using the same reinforcement learning code as¬†OpenAI Five¬†paired with a new technique called Automatic Domain Randomization (ADR). The system can handle situations it never saw during training, such as being prodded by a¬†stuffed giraffe. This shows that reinforcement learning isn‚Äôt just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.",
    "pubDate": "Tue, 15 Oct 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/solving-rubiks-cube",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A failed experiment: Infini-Attention, and why we should keep trying?",
    "description": "",
    "summary": "A failed experiment: Infini-Attention, and why we should keep trying? TLDR: Infini-attention's perfo...",
    "pubDate": "Wed, 14 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/infini-attention",
    "thumbnail": "https://huggingface.co/blog/infini-attention/assets/185_infini_attention/infini_attention_thumbnail.png"
  },
  {
    "title": "Announcing the ü§ó AI Research Residency Program",
    "description": "",
    "summary": "Announcing the ü§ó AI Research Residency Program üéâ üéâ üéâ The ü§ó Research Residency Program is a 9-month o...",
    "pubDate": "Tue, 22 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-residency",
    "thumbnail": "https://huggingface.co/blog/assets/57_ai_residency/residency-thumbnail.jpg"
  },
  {
    "title": "Marker Gene Method : Identifying Stable Solutions in a Dynamic Environment",
    "description": "arXiv:2506.23734v1 Announce Type: cross Abstract: Competitive Co-evolutionary Algorithms (CCEAs) are often hampered by complex dynamics like intransitivity and the Red Queen effect, leading to unstable convergence. To counter these challenges, this paper introduces the Marker Gene Method (MGM), a framework that establishes stability by using a 'marker gene' as a dynamic benchmark and an adaptive weighting mechanism to balance exploration and exploitation. We provide rigorous mathematical proofs demonstrating that MGM creates strong attractors near Nash Equilibria within the Strictly Competitive Game framework. Empirically, MGM demonstrates its efficacy across a spectrum of challenges: it stabilizes the canonical Rock-Paper-Scissors game, significantly improves the performance of C-RMOEA/D on ZDT benchmarks, and, when augmented with a Memory Pool (MP) extension, it successfully tames the notoriously pathological Shapley Biased Game. This work presents a theoretically sound and empirically validated framework that substantially enhances the stability and robustness of CCEAs in complex competitive environments.",
    "summary": "arXiv:2506.23734v1 Announce Type: cross Abstract: Competitive Co-evolutionary Algorithms (CCEAs) are often hampered by complex dynamics like intransitivity and the Red Queen effect, leading to unstable convergence. To counter these challenges, this paper introduces the Marker Gene Method (MGM), a framework that establishes stability by using a 'marker gene' as a dynamic benchmark and an adaptive weighting mechanism to balance exploration and exploitation. We provide rigorous mathematical proofs demonstrating that MGM creates strong attractors near Nash Equilibria within the Strictly Competitive Game framework. Empirically, MGM demonstrates its efficacy across a spectrum of challenges: it stabilizes the canonical Rock-Paper-Scissors game, significantly improves the performance of C-RMOEA/D on ZDT benchmarks, and, when augmented with a Memory Pool (MP) extension, it successfully tames the notoriously pathological Shapley Biased Game. This work presents a theoretically sound and empirically validated framework that substantially enhances the stability and robustness of CCEAs in complex competitive environments.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23734",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Effectiveness of LLMs as Annotators: A Comparative Overview and Empirical Analysis of Direct Representation",
    "description": "arXiv:2405.01299v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have emerged as powerful support tools across various natural language tasks and a range of application domains. Recent studies focus on exploring their capabilities for data annotation. This paper provides a comparative overview of twelve studies investigating the potential of LLMs in labelling data. While the models demonstrate promising cost and time-saving benefits, there exist considerable limitations, such as representativeness, bias, sensitivity to prompt variations and English language preference. Leveraging insights from these studies, our empirical analysis further examines the alignment between human and GPT-generated opinion distributions across four subjective datasets. In contrast to the studies examining representation, our methodology directly obtains the opinion distribution from GPT. Our analysis thereby supports the minority of studies that are considering diverse perspectives when evaluating data annotation tasks and highlights the need for further research in this direction.",
    "summary": "arXiv:2405.01299v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have emerged as powerful support tools across various natural language tasks and a range of application domains. Recent studies focus on exploring their capabilities for data annotation. This paper provides a comparative overview of twelve studies investigating the potential of LLMs in labelling data. While the models demonstrate promising cost and time-saving benefits, there exist considerable limitations, such as representativeness, bias, sensitivity to prompt variations and English language preference. Leveraging insights from these studies, our empirical analysis further examines the alignment between human and GPT-generated opinion distributions across four subjective datasets. In contrast to the studies examining representation, our methodology directly obtains the opinion distribution from GPT. Our analysis thereby supports the minority of studies that are considering diverse perspectives when evaluating data annotation tasks and highlights the need for further research in this direction.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.01299",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Physical and Mathematical Framework for the Semantic Theory of Evolution",
    "description": "arXiv:2503.18984v2 Announce Type: replace Abstract: The Semantic Theory of Evolution (STE) takes the existence of a number of arbitrary communication codes as a fundamental feature of life, from the genetic code to human cultural communication codes. Their arbitrariness enables, at each level, the selection of one out of several possible correspondences along with the generation of meaning. STE enables more novelties to emerge and suggests a greater variety of potential life forms. With this paper I ground STE on physical theories of meaningful information. Furthermore, I show that key features of the arbitrary communication codes employed by living organisms can be expressed by means of Evidence Theory (ET). In particular, I adapt ET to organisms that merely react to sequences of stimuli, explain its basics for organisms that are capable of prediction, and illustrate an unconventional version suitable for the most intricate communication codes employed by humans. Finally, I express the natural trend towards ambiguity reduction in terms of information entropy minimization along with thermodynamic entropy maximization.",
    "summary": "arXiv:2503.18984v2 Announce Type: replace Abstract: The Semantic Theory of Evolution (STE) takes the existence of a number of arbitrary communication codes as a fundamental feature of life, from the genetic code to human cultural communication codes. Their arbitrariness enables, at each level, the selection of one out of several possible correspondences along with the generation of meaning. STE enables more novelties to emerge and suggests a greater variety of potential life forms. With this paper I ground STE on physical theories of meaningful information. Furthermore, I show that key features of the arbitrary communication codes employed by living organisms can be expressed by means of Evidence Theory (ET). In particular, I adapt ET to organisms that merely react to sequences of stimuli, explain its basics for organisms that are capable of prediction, and illustrate an unconventional version suitable for the most intricate communication codes employed by humans. Finally, I express the natural trend towards ambiguity reduction in terms of information entropy minimization along with thermodynamic entropy maximization.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.18984",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs",
    "description": "arXiv:2506.23024v1 Announce Type: cross Abstract: Physics-informed neural networks (PINNs) offer a flexible way to solve partial differential equations (PDEs) with machine learning, yet they still fall well short of the machine-precision accuracy many scientific tasks demand. In this work, we investigate whether the precision ceiling comes from the ill-conditioning of the PDEs or from the typical multi-layer perceptron (MLP) architecture. We introduce the Barycentric Weight Layer (BWLer), which models the PDE solution through barycentric polynomial interpolation. A BWLer can be added on top of an existing MLP (a BWLer-hat) or replace it completely (explicit BWLer), cleanly separating how we represent the solution from how we take derivatives for the PDE loss. Using BWLer, we identify fundamental precision limitations within the MLP: on a simple 1-D interpolation task, even MLPs with O(1e5) parameters stall around 1e-8 RMSE -- about eight orders above float64 machine precision -- before any PDE terms are added. In PDE learning, adding a BWLer lifts this ceiling and exposes a tradeoff between achievable accuracy and the conditioning of the PDE loss. For linear PDEs we fully characterize this tradeoff with an explicit error decomposition and navigate it during training with spectral derivatives and preconditioning. Across five benchmark PDEs, adding a BWLer on top of an MLP improves RMSE by up to 30x for convection, 10x for reaction, and 1800x for wave equations while remaining compatible with first-order optimizers. Replacing the MLP entirely lets an explicit BWLer reach near-machine-precision on convection, reaction, and wave problems (up to 10 billion times better than prior results) and match the performance of standard PINNs on stiff Burgers' and irregular-geometry Poisson problems. Together, these findings point to a practical path for combining the flexibility of PINNs with the precision of classical spectral solvers.",
    "summary": "arXiv:2506.23024v1 Announce Type: cross Abstract: Physics-informed neural networks (PINNs) offer a flexible way to solve partial differential equations (PDEs) with machine learning, yet they still fall well short of the machine-precision accuracy many scientific tasks demand. In this work, we investigate whether the precision ceiling comes from the ill-conditioning of the PDEs or from the typical multi-layer perceptron (MLP) architecture. We introduce the Barycentric Weight Layer (BWLer), which models the PDE solution through barycentric polynomial interpolation. A BWLer can be added on top of an existing MLP (a BWLer-hat) or replace it completely (explicit BWLer), cleanly separating how we represent the solution from how we take derivatives for the PDE loss. Using BWLer, we identify fundamental precision limitations within the MLP: on a simple 1-D interpolation task, even MLPs with O(1e5) parameters stall around 1e-8 RMSE -- about eight orders above float64 machine precision -- before any PDE terms are added. In PDE learning, adding a BWLer lifts this ceiling and exposes a tradeoff between achievable accuracy and the conditioning of the PDE loss. For linear PDEs we fully characterize this tradeoff with an explicit error decomposition and navigate it during training with spectral derivatives and preconditioning. Across five benchmark PDEs, adding a BWLer on top of an MLP improves RMSE by up to 30x for convection, 10x for reaction, and 1800x for wave equations while remaining compatible with first-order optimizers. Replacing the MLP entirely lets an explicit BWLer reach near-machine-precision on convection, reaction, and wave problems (up to 10 billion times better than prior results) and match the performance of standard PINNs on stiff Burgers' and irregular-geometry Poisson problems. Together, these findings point to a practical path for combining the flexibility of PINNs with the precision of classical spectral solvers.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23024",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Reformer - Pushing the limits of language modeling",
    "description": "",
    "summary": "The Reformer - Pushing the limits of language modeling How the Reformer uses less than 8GB of RAM to...",
    "pubDate": "Fri, 03 Jul 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/reformer",
    "thumbnail": "https://huggingface.co/blog/assets/03_reformer/thumbnail.png"
  },
  {
    "title": "PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?",
    "description": "arXiv:2506.23725v1 Announce Type: cross Abstract: Vision-Language Models (VLMs) are increasingly pivotal for generalist robot manipulation, enabling tasks such as physical reasoning, policy generation, and failure detection. However, their proficiency in these high-level applications often assumes a deep understanding of low-level physical prerequisites, a capability that remains largely unverified. For robots to perform actions reliably, they must comprehend intrinsic object properties (e.g., material, weight), action affordances (e.g., graspable, stackable), and physical constraints (e.g., stability, reachability, or an object's state, such as being closed). Despite the widespread use of VLMs in manipulation tasks, we argue that off-the-shelf models may lack this granular, physically grounded understanding, as such prerequisites are often overlooked during training. To address this critical gap, we introduce PAC Bench, a comprehensive benchmark designed to systematically evaluate VLMs on their understanding of core Properties, Affordances, and Constraints (PAC) from a task executability perspective. PAC Bench features a diverse dataset with over 30,000 annotations, comprising 673 real-world images (115 object classes, 15 property types, and 1 to 3 affordances defined per class), 100 real-world humanoid-view scenarios, and 120 unique simulated constraint scenarios across four tasks. Our evaluations reveal significant gaps in the ability of current VLMs to grasp fundamental physical concepts, highlighting limitations in their suitability for reliable robot manipulation and pointing to key areas for targeted research. PAC Bench also serves as a standardized benchmark for rigorously evaluating physical reasoning in VLMs and guiding the development of more robust, physically grounded models for robotic applications. Project Page: https://pacbench.github.io/",
    "summary": "arXiv:2506.23725v1 Announce Type: cross Abstract: Vision-Language Models (VLMs) are increasingly pivotal for generalist robot manipulation, enabling tasks such as physical reasoning, policy generation, and failure detection. However, their proficiency in these high-level applications often assumes a deep understanding of low-level physical prerequisites, a capability that remains largely unverified. For robots to perform actions reliably, they must comprehend intrinsic object properties (e.g., material, weight), action affordances (e.g., graspable, stackable), and physical constraints (e.g., stability, reachability, or an object's state, such as being closed). Despite the widespread use of VLMs in manipulation tasks, we argue that off-the-shelf models may lack this granular, physically grounded understanding, as such prerequisites are often overlooked during training. To address this critical gap, we introduce PAC Bench, a comprehensive benchmark designed to systematically evaluate VLMs on their understanding of core Properties, Affordances, and Constraints (PAC) from a task executability perspective. PAC Bench features a diverse dataset with over 30,000 annotations, comprising 673 real-world images (115 object classes, 15 property types, and 1 to 3 affordances defined per class), 100 real-world humanoid-view scenarios, and 120 unique simulated constraint scenarios across four tasks. Our evaluations reveal significant gaps in the ability of current VLMs to grasp fundamental physical concepts, highlighting limitations in their suitability for reliable robot manipulation and pointing to key areas for targeted research. PAC Bench also serves as a standardized benchmark for rigorously evaluating physical reasoning in VLMs and guiding the development of more robust, physically grounded models for robotic applications. Project Page: https://pacbench.github.io/",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23725",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "STACK: Adversarial Attacks on LLM Safeguard Pipelines",
    "description": "arXiv:2506.24068v1 Announce Type: cross Abstract: Frontier AI developers are relying on layers of safeguards to protect against catastrophic misuse of AI systems. Anthropic guards their latest Claude 4 Opus model using one such defense pipeline, and other frontier developers including Google DeepMind and OpenAI pledge to soon deploy similar defenses. However, the security of such pipelines is unclear, with limited prior work evaluating or attacking these pipelines. We address this gap by developing and red-teaming an open-source defense pipeline. First, we find that a novel few-shot-prompted input and output classifier outperforms state-of-the-art open-weight safeguard model ShieldGemma across three attacks and two datasets, reducing the attack success rate (ASR) to 0% on the catastrophic misuse dataset ClearHarm. Second, we introduce a STaged AttaCK (STACK) procedure that achieves 71% ASR on ClearHarm in a black-box attack against the few-shot-prompted classifier pipeline. Finally, we also evaluate STACK in a transfer setting, achieving 33% ASR, providing initial evidence that it is feasible to design attacks with no access to the target pipeline. We conclude by suggesting specific mitigations that developers could use to thwart staged attacks.",
    "summary": "arXiv:2506.24068v1 Announce Type: cross Abstract: Frontier AI developers are relying on layers of safeguards to protect against catastrophic misuse of AI systems. Anthropic guards their latest Claude 4 Opus model using one such defense pipeline, and other frontier developers including Google DeepMind and OpenAI pledge to soon deploy similar defenses. However, the security of such pipelines is unclear, with limited prior work evaluating or attacking these pipelines. We address this gap by developing and red-teaming an open-source defense pipeline. First, we find that a novel few-shot-prompted input and output classifier outperforms state-of-the-art open-weight safeguard model ShieldGemma across three attacks and two datasets, reducing the attack success rate (ASR) to 0% on the catastrophic misuse dataset ClearHarm. Second, we introduce a STaged AttaCK (STACK) procedure that achieves 71% ASR on ClearHarm in a black-box attack against the few-shot-prompted classifier pipeline. Finally, we also evaluate STACK in a transfer setting, achieving 33% ASR, providing initial evidence that it is feasible to design attacks with no access to the target pipeline. We conclude by suggesting specific mitigations that developers could use to thwart staged attacks.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.24068",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hindsight-Guided Momentum (HGM) Optimizer: An Approach to Adaptive Learning Rate",
    "description": "arXiv:2506.22479v1 Announce Type: cross Abstract: We introduce Hindsight-Guided Momentum (HGM), a first-order optimization algorithm that adaptively scales learning rates based on the directional consistency of recent updates. Traditional adaptive methods, such as Adam or RMSprop , adapt learning dynamics using only the magnitude of gradients, often overlooking important geometric cues.Geometric cues refer to directional information, such as the alignment between current gradients and past updates, which reflects the local curvature and consistency of the optimization path. HGM addresses this by incorporating a hindsight mechanism that evaluates the cosine similarity between the current gradient and accumulated momentum. This allows it to distinguish between coherent and conflicting gradient directions, increasing the learning rate when updates align and reducing it in regions of oscillation or noise. The result is a more responsive optimizer that accelerates convergence in smooth regions of the loss surface while maintaining stability in sharper or more erratic areas. Despite this added adaptability, the method preserves the computational and memory efficiency of existing optimizers.By more intelligently responding to the structure of the optimization landscape, HGM provides a simple yet effective improvement over existing approaches, particularly in non-convex settings like that of deep neural network training.",
    "summary": "arXiv:2506.22479v1 Announce Type: cross Abstract: We introduce Hindsight-Guided Momentum (HGM), a first-order optimization algorithm that adaptively scales learning rates based on the directional consistency of recent updates. Traditional adaptive methods, such as Adam or RMSprop , adapt learning dynamics using only the magnitude of gradients, often overlooking important geometric cues.Geometric cues refer to directional information, such as the alignment between current gradients and past updates, which reflects the local curvature and consistency of the optimization path. HGM addresses this by incorporating a hindsight mechanism that evaluates the cosine similarity between the current gradient and accumulated momentum. This allows it to distinguish between coherent and conflicting gradient directions, increasing the learning rate when updates align and reducing it in regions of oscillation or noise. The result is a more responsive optimizer that accelerates convergence in smooth regions of the loss surface while maintaining stability in sharper or more erratic areas. Despite this added adaptability, the method preserves the computational and memory efficiency of existing optimizers.By more intelligently responding to the structure of the optimization landscape, HGM provides a simple yet effective improvement over existing approaches, particularly in non-convex settings like that of deep neural network training.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22479",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Mathematical Computation on High-dimensional Data via Array Programming and Parallel Acceleration",
    "description": "arXiv:2506.22929v1 Announce Type: cross Abstract: While deep learning excels in natural image and language processing, its application to high-dimensional data faces computational challenges due to the dimensionality curse. Current large-scale data tools focus on business-oriented descriptive statistics, lacking mathematical statistics support for advanced analysis. We propose a parallel computation architecture based on space completeness, decomposing high-dimensional data into dimension-independent structures for distributed processing. This framework enables seamless integration of data mining and parallel-optimized machine learning methods, supporting scientific computations across diverse data types like medical and natural images within a unified system.",
    "summary": "arXiv:2506.22929v1 Announce Type: cross Abstract: While deep learning excels in natural image and language processing, its application to high-dimensional data faces computational challenges due to the dimensionality curse. Current large-scale data tools focus on business-oriented descriptive statistics, lacking mathematical statistics support for advanced analysis. We propose a parallel computation architecture based on space completeness, decomposing high-dimensional data into dimension-independent structures for distributed processing. This framework enables seamless integration of data mining and parallel-optimized machine learning methods, supporting scientific computations across diverse data types like medical and natural images within a unified system.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22929",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Image Similarity with Hugging Face Datasets and Transformers",
    "description": "",
    "summary": "Image Similarity with Hugging Face Datasets and Transformers In this post, you'll learn to build an ...",
    "pubDate": "Mon, 16 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-similarity",
    "thumbnail": "https://huggingface.co/blog/assets/image_similarity/thumbnail.png"
  },
  {
    "title": "Chain of Thought in Order: Discovering Learning-Friendly Orders for Arithmetic",
    "description": "arXiv:2506.23875v1 Announce Type: cross Abstract: The chain of thought is fundamental in Transformers, which is to perform step-by-step reasoning. Besides what intermediate steps work, the order of these steps critically affects the difficulty of the reasoning. This study addresses a novel task of unraveling chain of thought - reordering decoder input tokens to a learning-friendly sequence for Transformers to learn arithmetic tasks. The proposed pipeline first trains a Transformer on a mixture of target sequences arranged in different orders and then identifies benign orders as those with fast loss drops in the early stage. As the search space grows factorially with sequence length, we propose a two-stage hierarchical approach for inter- and intra-block reordering. Experiments on four order-sensitive arithmetic tasks show that our method identifies a learning-friendly order out of a few billion candidates. Notably, on the multiplication task, it recovered the reverse-digit order reported in prior studies.",
    "summary": "arXiv:2506.23875v1 Announce Type: cross Abstract: The chain of thought is fundamental in Transformers, which is to perform step-by-step reasoning. Besides what intermediate steps work, the order of these steps critically affects the difficulty of the reasoning. This study addresses a novel task of unraveling chain of thought - reordering decoder input tokens to a learning-friendly sequence for Transformers to learn arithmetic tasks. The proposed pipeline first trains a Transformer on a mixture of target sequences arranged in different orders and then identifies benign orders as those with fast loss drops in the early stage. As the search space grows factorially with sequence length, we propose a two-stage hierarchical approach for inter- and intra-block reordering. Experiments on four order-sensitive arithmetic tasks show that our method identifies a learning-friendly order out of a few billion candidates. Notably, on the multiplication task, it recovered the reverse-digit order reported in prior studies.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23875",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Student‚Äôs Guide to Writing with ChatGPT",
    "description": "A Student‚Äôs Guide to Writing with ChatGPT",
    "summary": "A Student‚Äôs Guide to Writing with ChatGPT",
    "pubDate": "Wed, 13 Nov 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/chatgpt/use-cases/student-writing-guide",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Verdi, an AI dev platform powered by GPT-4o",
    "description": "Mercado Libre introduces Verdi, an AI developer platform powered by GPT-4o",
    "summary": "Mercado Libre introduces Verdi, an AI developer platform powered by GPT-4o",
    "pubDate": "Tue, 24 Sep 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mercado-libre",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Animator Lyndon Barrois creates new worlds with Sora",
    "description": "Filmmaker Lyndon Barrois describes how to use Sora as a storytelling tool.",
    "summary": "Filmmaker Lyndon Barrois describes how to use Sora as a storytelling tool.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-lyndon-barrois",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Image search with ü§ó datasets",
    "description": "",
    "summary": "Image search with ü§ó datasets ü§ó datasets is a library that makes it easy to access and share datasets...",
    "pubDate": "Wed, 16 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-search-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/54_image_search_datasets/spaces_image_search.jpg"
  },
  {
    "title": "Stargate Infrastructure",
    "description": "OpenAI, and our strategic partners, are thrilled about our shared vision for the Infrastructure of AGI. We are energized by the challenges we face and are excited by the prospect of partnering with firms across the industrial base to deliver against our ambitious mission. Specifically, we want to connect with firms across the built data center infrastructure landscape, from power and land to construction to equipment, and everything in between.",
    "summary": "OpenAI, and our strategic partners, are thrilled about our shared vision for the Infrastructure of AGI. We are energized by the challenges we face and are excited by the prospect of partnering with firms across the industrial base to deliver against our ambitious mission. Specifically, we want to connect with firms across the built data center infrastructure landscape, from power and land to construction to equipment, and everything in between.",
    "pubDate": "Tue, 21 Jan 2025 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/form/stargate-infrastructure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Third-person imitation learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 06 Mar 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/third-person-imitation-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Gradio's new Dataframe!",
    "description": "",
    "summary": "Introducing Gradio's new Dataframe! Gradio‚Äôs gr.Dataframe component is one of our most popular compo...",
    "pubDate": "Mon, 24 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-dataframe-upgrade",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-dataframe-upgrade/thumbnail.png"
  },
  {
    "title": "Computer-Using Agent",
    "description": "A universal interface for AI to interact with the digital world.",
    "summary": "A universal interface for AI to interact with the digital world.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/computer-using-agent",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our Transformers Code Agent beats the GAIA benchmark!",
    "description": "",
    "summary": "Our Transformers Code Agent beats the GAIA benchmark! TL;DR After some experiments, we were impresse...",
    "pubDate": "Mon, 01 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/beating-gaia",
    "thumbnail": "https://huggingface.co/blog/assets/beating-gaia/thumbnail.jpeg"
  },
  {
    "title": "SIEDD: Shared-Implicit Encoder with Discrete Decoders",
    "description": "arXiv:2506.23382v1 Announce Type: cross Abstract: Implicit Neural Representations (INRs) offer exceptional fidelity for video compression by learning per-video optimized functions, but their adoption is crippled by impractically slow encoding times. Existing attempts to accelerate INR encoding often sacrifice reconstruction quality or crucial coordinate-level control essential for adaptive streaming and transcoding. We introduce SIEDD (Shared-Implicit Encoder with Discrete Decoders), a novel architecture that fundamentally accelerates INR encoding without these compromises. SIEDD first rapidly trains a shared, coordinate-based encoder on sparse anchor frames to efficiently capture global, low-frequency video features. This encoder is then frozen, enabling massively parallel training of lightweight, discrete decoders for individual frame groups, further expedited by aggressive coordinate-space sampling. This synergistic design delivers a remarkable 20-30X encoding speed-up over state-of-the-art INR codecs on HD and 4K benchmarks, while maintaining competitive reconstruction quality and compression ratios. Critically, SIEDD retains full coordinate-based control, enabling continuous resolution decoding and eliminating costly transcoding. Our approach significantly advances the practicality of high-fidelity neural video compression, demonstrating a scalable and efficient path towards real-world deployment. Our codebase is available at https://github.com/VikramRangarajan/SIEDD .",
    "summary": "arXiv:2506.23382v1 Announce Type: cross Abstract: Implicit Neural Representations (INRs) offer exceptional fidelity for video compression by learning per-video optimized functions, but their adoption is crippled by impractically slow encoding times. Existing attempts to accelerate INR encoding often sacrifice reconstruction quality or crucial coordinate-level control essential for adaptive streaming and transcoding. We introduce SIEDD (Shared-Implicit Encoder with Discrete Decoders), a novel architecture that fundamentally accelerates INR encoding without these compromises. SIEDD first rapidly trains a shared, coordinate-based encoder on sparse anchor frames to efficiently capture global, low-frequency video features. This encoder is then frozen, enabling massively parallel training of lightweight, discrete decoders for individual frame groups, further expedited by aggressive coordinate-space sampling. This synergistic design delivers a remarkable 20-30X encoding speed-up over state-of-the-art INR codecs on HD and 4K benchmarks, while maintaining competitive reconstruction quality and compression ratios. Critically, SIEDD retains full coordinate-based control, enabling continuous resolution decoding and eliminating costly transcoding. Our approach significantly advances the practicality of high-fidelity neural video compression, demonstrating a scalable and efficient path towards real-world deployment. Our codebase is available at https://github.com/VikramRangarajan/SIEDD .",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23382",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing canvas, a new way to write and code with ChatGPT.",
    "description": "Introducing canvas",
    "summary": "Introducing canvas",
    "pubDate": "Thu, 03 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-canvas",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community",
    "description": "",
    "summary": "From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community The Elixir community is ...",
    "pubDate": "Fri, 09 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/elixir-bumblebee",
    "thumbnail": "https://huggingface.co/blog/assets/120_elixir-bumblebee/thumbnail.png"
  },
  {
    "title": "OpenAI acquires Rockset",
    "description": "OpenAI Acquires Rockset",
    "summary": "OpenAI Acquires Rockset",
    "pubDate": "Fri, 21 Jun 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-acquires-rockset",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Teaching models to express their uncertainty in words",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 28 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teaching-models-to-express-their-uncertainty-in-words",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Falcon 2: An 11B parameter pretrained language model and VLM, trained on over 5000B tokens tokens and 11 languages",
    "description": "",
    "summary": "Falcon 2: An 11B parameter pretrained language model and VLM, trained on over 5000B tokens and 11 la...",
    "pubDate": "Fri, 24 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon2-11b",
    "thumbnail": "https://huggingface.co/blog/assets/179_falcon2-11b/thumbnail.jpg"
  },
  {
    "title": "Introducing the Frontier Safety Framework",
    "description": "Our approach to analyzing and mitigating future risks posed by advanced AI models",
    "summary": "Our approach to analyzing and mitigating future risks posed by advanced AI models",
    "pubDate": "Fri, 17 May 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/",
    "thumbnail": "https://lh3.googleusercontent.com/_NVnftxEp6r9O9gnZT2_jLPpIn_nGjYp9xgl8hFhg_-fX131_koFcj6znzflexf4-MdfkSTtA060-Hh7RcvVkNkY5kQ-QBulRYDCO1Li1R1jK71G=w1200-h630-n-nu"
  },
  {
    "title": "PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection",
    "description": "arXiv:2506.23581v1 Announce Type: cross Abstract: Object detection plays a crucial role in many security-sensitive applications. However, several recent studies have shown that object detectors can be easily fooled by physically realizable attacks, eg, adversarial patches and recent adversarial textures, which pose realistic and urgent threats. Adversarial Training (AT) has been recognized as the most effective defense against adversarial attacks. While AT has been extensively studied in the $l_infty$ attack settings on classification models, AT against physically realizable attacks on object detectors has received limited exploration. Early attempts are only performed to defend against adversarial patches, leaving AT against a wider range of physically realizable attacks under-explored. In this work, we consider defending against various physically realizable attacks with a unified AT method. We propose PBCAT, a novel Patch-Based Composite Adversarial Training strategy. PBCAT optimizes the model by incorporating the combination of small-area gradient-guided adversarial patches and imperceptible global adversarial perturbations covering the entire image. With these designs, PBCAT has the potential to defend against not only adversarial patches but also unseen physically realizable attacks such as adversarial textures. Extensive experiments in multiple settings demonstrated that PBCAT significantly improved robustness against various physically realizable attacks over state-of-the-art defense methods. Notably, it improved the detection accuracy by 29.7% over previous defense methods under one recent adversarial texture attack.",
    "summary": "arXiv:2506.23581v1 Announce Type: cross Abstract: Object detection plays a crucial role in many security-sensitive applications. However, several recent studies have shown that object detectors can be easily fooled by physically realizable attacks, eg, adversarial patches and recent adversarial textures, which pose realistic and urgent threats. Adversarial Training (AT) has been recognized as the most effective defense against adversarial attacks. While AT has been extensively studied in the $l_infty$ attack settings on classification models, AT against physically realizable attacks on object detectors has received limited exploration. Early attempts are only performed to defend against adversarial patches, leaving AT against a wider range of physically realizable attacks under-explored. In this work, we consider defending against various physically realizable attacks with a unified AT method. We propose PBCAT, a novel Patch-Based Composite Adversarial Training strategy. PBCAT optimizes the model by incorporating the combination of small-area gradient-guided adversarial patches and imperceptible global adversarial perturbations covering the entire image. With these designs, PBCAT has the potential to defend against not only adversarial patches but also unseen physically realizable attacks such as adversarial textures. Extensive experiments in multiple settings demonstrated that PBCAT significantly improved robustness against various physically realizable attacks over state-of-the-art defense methods. Notably, it improved the detection accuracy by 29.7% over previous defense methods under one recent adversarial texture attack.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23581",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing 4o Image Generation",
    "description": "At OpenAI, we have long believed image generation should be a primary capability of our language models. That‚Äôs why we‚Äôve built our most advanced image generator yet into GPT‚Äë4o. The result‚Äîimage generation that is not only beautiful, but useful.",
    "summary": "At OpenAI, we have long believed image generation should be a primary capability of our language models. That‚Äôs why we‚Äôve built our most advanced image generator yet into GPT‚Äë4o. The result‚Äîimage generation that is not only beautiful, but useful.",
    "pubDate": "Tue, 25 Mar 2025 11:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-4o-image-generation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How Sempre Health is leveraging the Expert Acceleration Program to accelerate their ML roadmap",
    "description": "",
    "summary": "How Sempre Health is leveraging the Expert Acceleration Program to accelerate their ML roadmap üëã Hel...",
    "pubDate": "Thu, 19 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sempre-health-eap-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/70_sempre_health/thumbnail.jpg"
  },
  {
    "title": "Google„ÄÅÊïµ„Å´Â°©„ÇíÈÄÅ„ÇãÔºü„ÄÄOpenAI„Å®ÂçîÊ•≠‚îÄ‚îÄ‚ÄúÁ∑äÂºµÊÑü‚Äù„ÅÇ„Çã„Åù„ÅÆÂÜÖÂÆπ",
    "description": "Á±≥OpenAI„ÅØ„Åì„ÅÆ„Åª„Å©„ÄÅChatGPT„ÇÑ„Åù„ÅÆ‰ªñ„ÅÆ„Éó„É≠„ÉÄ„ÇØ„Éà„ÇíÁ®ºÂÉç„Åï„Åõ„Çã„Åü„ÇÅ„ÄÅÁ±≥Google„ÅåÈñãÁô∫„Åó„ÅüAIÁî®ÂçäÂ∞é‰Ωì„Çí„É¨„É≥„Çø„É´„ÅóÂßã„ÇÅ„Åü„ÄÇÈñ¢‰øÇËÄÖ„Åå„É≠„Ç§„Çø„ÉºÈÄö‰ø°„Å´Êòé„Åã„Åó„Åü„ÄÇ",
    "summary": "Á±≥OpenAI„ÅØ„Åì„ÅÆ„Åª„Å©„ÄÅChatGPT„ÇÑ„Åù„ÅÆ‰ªñ„ÅÆ„Éó„É≠„ÉÄ„ÇØ„Éà„ÇíÁ®ºÂÉç„Åï„Åõ„Çã„Åü„ÇÅ„ÄÅÁ±≥Google„ÅåÈñãÁô∫„Åó„ÅüAIÁî®ÂçäÂ∞é‰Ωì„Çí„É¨„É≥„Çø„É´„ÅóÂßã„ÇÅ„Åü„ÄÇÈñ¢‰øÇËÄÖ„Åå„É≠„Ç§„Çø„ÉºÈÄö‰ø°„Å´Êòé„Åã„Åó„Åü„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 14:50:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2506/30/news099.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2506/30/cover_news099.jpg"
  },
  {
    "title": "DALL¬∑E 2 research preview update",
    "description": "Early users have created over 3 million images to date and helped us improve our safety processes. We‚Äôre excited to begin adding up to 1,000 new users from our waitlist each week.",
    "summary": "Early users have created over 3 million images to date and helped us improve our safety processes. We‚Äôre excited to begin adding up to 1,000 new users from our waitlist each week.",
    "pubDate": "Wed, 18 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI‚Äôs approach to AI and national security",
    "description": "OpenAI‚Äôs approach to AI and national security",
    "summary": "OpenAI‚Äôs approach to AI and national security",
    "pubDate": "Thu, 24 Oct 2024 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-approach-to-ai-and-national-security",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Fellows Fall 2018: Final projects",
    "description": "Our second class of OpenAI Fellows has wrapped up, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship. We are currently reviewing applications on a rolling basis for our next round of OpenAI Fellows Summer 2019.",
    "summary": "Our second class of OpenAI Fellows has wrapped up, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship. We are currently reviewing applications on a rolling basis for our next round of OpenAI Fellows Summer 2019.",
    "pubDate": "Fri, 17 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows-fall-2018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ryght‚Äôs Journey to Empower Healthcare and Life Sciences with Expert Support from Hugging Face",
    "description": "",
    "summary": "Ryght‚Äôs Journey to Empower Healthcare and Life Sciences with Expert Support from Hugging Face This i...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ryght-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/ryght-case-study/thumbnail.png"
  },
  {
    "title": "Welcome Llama 4 Maverick & Scout on Hugging Face!",
    "description": "",
    "summary": "Welcome Llama 4 Maverick & Scout on Hugging Face We are incredibly excited to welcome the next gener...",
    "pubDate": "Sat, 05 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama4-release",
    "thumbnail": "https://huggingface.co/blog/assets/llama_4.png"
  },
  {
    "title": "AI safety needs social scientists",
    "description": "We‚Äôve written a paper arguing that long-term AI safety research needs social scientists to ensure AI alignment algorithms succeed when actual humans are involved. Properly aligning advanced AI systems with human values requires resolving many uncertainties related to the psychology of human rationality, emotion, and biases. The aim of this paper is to spark further collaboration between machine learning and social science researchers, and we plan to¬†hire¬†social scientists to work on this full time at¬†OpenAI.",
    "summary": "We‚Äôve written a paper arguing that long-term AI safety research needs social scientists to ensure AI alignment algorithms succeed when actual humans are involved. Properly aligning advanced AI systems with human values requires resolving many uncertainties related to the psychology of human rationality, emotion, and biases. The aim of this paper is to spark further collaboration between machine learning and social science researchers, and we plan to¬†hire¬†social scientists to work on this full time at¬†OpenAI.",
    "pubDate": "Tue, 19 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-safety-needs-social-scientists",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaDev discovers faster sorting algorithms",
    "description": "New algorithms will transform the foundations of computing",
    "summary": "New algorithms will transform the foundations of computing",
    "pubDate": "Wed, 07 Jun 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphadev-discovers-faster-sorting-algorithms/",
    "thumbnail": "https://lh3.googleusercontent.com/kYAs9KTHdhYZE0BeKMKlphVqU3eQS8oXP_GNrrWBjFbl8r4YFv2FWlRbe6x9L4Q_L-eKZeE7E__GtKVJTLXvW_zGTTzplSJCplN02n_8cz7No815L5M=w1200-h630-n-nu"
  },
  {
    "title": "AI powers Expedia‚Äôs marketing evolution",
    "description": "A conversation with Jochen Koedijk, Chief Marketing Officer of Expedia Group.",
    "summary": "A conversation with Jochen Koedijk, Chief Marketing Officer of Expedia Group.",
    "pubDate": "Wed, 14 May 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expedia-jochen-koedijk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Teaching with AI",
    "description": "We‚Äôre releasing a guide for teachers using ChatGPT in their classroom‚Äîincluding suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.",
    "summary": "We‚Äôre releasing a guide for teachers using ChatGPT in their classroom‚Äîincluding suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.",
    "pubDate": "Thu, 31 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teaching-with-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Promega‚Äôs top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "description": "Promega's top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "summary": "Promega's top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "pubDate": "Thu, 31 Oct 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/promega",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pushing the frontiers of audio generation",
    "description": "Our pioneering speech generation technologies are helping people around the world interact with more natural, conversational and intuitive digital assistants and AI tools.",
    "summary": "Our pioneering speech generation technologies are helping people around the world interact with more natural, conversational and intuitive digital assistants and AI tools.",
    "pubDate": "Wed, 30 Oct 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/pushing-the-frontiers-of-audio-generation/",
    "thumbnail": "https://lh3.googleusercontent.com/wyFc1lo4ByOJsbbSt1NEwBiSi3KpImyqA9ukx-mLxJROIakSxhPwk-kPtlIfFKX9Txm2J_lbpIvnrDhFnegrpN8ihlvYpBTsFNAmOlq0C2rm_gef=w1200-h630-n-nu"
  },
  {
    "title": "AI in Australia‚ÄîOpenAI‚Äôs Economic Blueprint",
    "description": "Today, OpenAI, in partnership with Mandala Partners, is sharing the OpenAI AI Economic Blueprint for Australia. At a time when boosting productivity has emerged as a national priority for Australia, the Blueprint provides a clear, actionable plan for how Australia can unlock the full economic and social potential of artificial intelligence.",
    "summary": "Today, OpenAI, in partnership with Mandala Partners, is sharing the OpenAI AI Economic Blueprint for Australia. At a time when boosting productivity has emerged as a national priority for Australia, the Blueprint provides a clear, actionable plan for how Australia can unlock the full economic and social potential of artificial intelligence.",
    "pubDate": "Mon, 30 Jun 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-australia-economic-blueprint",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Cybersecurity Grant Program",
    "description": "Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants and other support.",
    "summary": "Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants and other support.",
    "pubDate": "Thu, 01 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-cybersecurity-grant-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëAI„Ç®„É≥„Ç∏„Éã„Ç¢ÂøÖË¶ãÔºÅÁã¨Ëá™LLMÈñãÁô∫ÁßòË©±„Å®DevinÊ¥ªÁî®„ÅÆ„Çπ„Çπ„É° ÔΩûLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅGPU„ÅÆ„Ç≥„Çπ„ÉàÂâäÊ∏õ„Åæ„ÅßËß£Ë™¨„Åó„Åæ„ÅôÔΩû",
    "description": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà16Êó•ÔºàÊ∞¥Ôºâ12ÊôÇ„Åã„ÇâLLMÈñãÁô∫„Å´Èñ¢„Åô„Çã„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ Êú¨„Ç¶„Çß„Éì„Éä„Éº„Åß„ÅØ„ÄÅAI„Ç®„É≥„Ç∏„Éã„Ç¢/AIÈñãÁô∫ÈÉ®ÈñÄ„ÅÆÊñπÂêë„Åë„Å´Áã¨Ëá™LLM„ÅÆÈñãÁô∫ÁßòË©±„ÇÑDevin„ÅÆÊ¥ªÁî®‰∫ã [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250716webinar/'>„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëAI„Ç®„É≥„Ç∏„Éã„Ç¢ÂøÖË¶ãÔºÅÁã¨Ëá™LLMÈñãÁô∫ÁßòË©±„Å®DevinÊ¥ªÁî®„ÅÆ„Çπ„Çπ„É° ÔΩûLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅGPU„ÅÆ„Ç≥„Çπ„ÉàÂâäÊ∏õ„Åæ„ÅßËß£Ë™¨„Åó„Åæ„ÅôÔΩû</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà16Êó•ÔºàÊ∞¥Ôºâ12ÊôÇ„Åã„ÇâLLMÈñãÁô∫„Å´Èñ¢„Åô„Çã„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ Êú¨„Ç¶„Çß„Éì„Éä„Éº„Åß„ÅØ„ÄÅAI„Ç®„É≥„Ç∏„Éã„Ç¢/AIÈñãÁô∫ÈÉ®ÈñÄ„ÅÆÊñπÂêë„Åë„Å´Áã¨Ëá™LLM„ÅÆÈñãÁô∫ÁßòË©±„ÇÑDevin„ÅÆÊ¥ªÁî®‰∫ã [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250716webinar/'>„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëAI„Ç®„É≥„Ç∏„Éã„Ç¢ÂøÖË¶ãÔºÅÁã¨Ëá™LLMÈñãÁô∫ÁßòË©±„Å®DevinÊ¥ªÁî®„ÅÆ„Çπ„Çπ„É° ÔΩûLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅGPU„ÅÆ„Ç≥„Çπ„ÉàÂâäÊ∏õ„Åæ„ÅßËß£Ë™¨„Åó„Åæ„ÅôÔΩû</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Fri, 27 Jun 2025 02:00:37 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/20250716webinar/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/700_1200x628.jpg"
  },
  {
    "title": "OpenAI„ÅåGoogle„ÅÆAI„ÉÅ„ÉÉ„ÉóÊé°Áî®„ÄÄÈùûNVIDIAË£Ω„ÇíÂàù„ÇÅ„Å¶‰ΩøÁî®",
    "description": "Á±≥OpenAI„ÅåChatGPT„Å™„Å©„ÅÆË£ΩÂìÅÂêë„Åë„Å´„ÄÅGoogleË£ΩAI„ÉÅ„ÉÉ„Éó„ÅÆÂà©Áî®„ÇíÂßã„ÇÅ„Åü„ÄÇÈñ¢‰øÇËÄÖ„Åå„É≠„Ç§„Çø„Éº„Å´Êòé„Åã„Åó„Åü„ÄÇ",
    "summary": "Á±≥OpenAI„ÅåChatGPT„Å™„Å©„ÅÆË£ΩÂìÅÂêë„Åë„Å´„ÄÅGoogleË£ΩAI„ÉÅ„ÉÉ„Éó„ÅÆÂà©Áî®„ÇíÂßã„ÇÅ„Åü„ÄÇÈñ¢‰øÇËÄÖ„Åå„É≠„Ç§„Çø„Éº„Å´Êòé„Åã„Åó„Åü„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 18:21:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/30/news120.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/30/cover_news120.jpg"
  },
  {
    "title": "Deep Learning for Optical Misalignment Diagnostics in Multi-Lens Imaging Systems",
    "description": "arXiv:2506.23173v1 Announce Type: cross Abstract: In the rapidly evolving field of optical engineering, precise alignment of multi-lens imaging systems is critical yet challenging, as even minor misalignments can significantly degrade performance. Traditional alignment methods rely on specialized equipment and are time-consuming processes, highlighting the need for automated and scalable solutions. We present two complementary deep learning-based inverse-design methods for diagnosing misalignments in multi-element lens systems using only optical measurements. First, we use ray-traced spot diagrams to predict five-degree-of-freedom (5-DOF) errors in a 6-lens photographic prime, achieving a mean absolute error of 0.031mm in lateral translation and 0.011$^circ$ in tilt. We also introduce a physics-based simulation pipeline that utilizes grayscale synthetic camera images, enabling a deep learning model to estimate 4-DOF, decenter and tilt errors in both two- and six-lens multi-lens systems. These results show the potential to reshape manufacturing and quality control in precision imaging.",
    "summary": "arXiv:2506.23173v1 Announce Type: cross Abstract: In the rapidly evolving field of optical engineering, precise alignment of multi-lens imaging systems is critical yet challenging, as even minor misalignments can significantly degrade performance. Traditional alignment methods rely on specialized equipment and are time-consuming processes, highlighting the need for automated and scalable solutions. We present two complementary deep learning-based inverse-design methods for diagnosing misalignments in multi-element lens systems using only optical measurements. First, we use ray-traced spot diagrams to predict five-degree-of-freedom (5-DOF) errors in a 6-lens photographic prime, achieving a mean absolute error of 0.031mm in lateral translation and 0.011$^circ$ in tilt. We also introduce a physics-based simulation pipeline that utilizes grayscale synthetic camera images, enabling a deep learning model to estimate 4-DOF, decenter and tilt errors in both two- and six-lens multi-lens systems. These results show the potential to reshape manufacturing and quality control in precision imaging.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23173",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improving health literacy and patient well-being",
    "description": "Lifespan uses GPT-4 to radically improve health literacy and patient outcomes.",
    "summary": "Lifespan uses GPT-4 to radically improve health literacy and patient outcomes.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lifespan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reducing health insurance costs and improving care",
    "description": "Oscar brings AI to health insurance, reducing costs and improving patient care.",
    "summary": "Oscar brings AI to health insurance, reducing costs and improving patient care.",
    "pubDate": "Mon, 01 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/oscar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Student Ambassador Program's call for applications is open!",
    "description": "",
    "summary": "Student Ambassador Program‚Äôs call for applications is open! As an open-source company democratizing ...",
    "pubDate": "Fri, 13 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ambassadors",
    "thumbnail": "https://huggingface.co/blog/assets/67_ambassadors/thumbnail.png"
  },
  {
    "title": "Moving AI governance forward",
    "description": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
    "summary": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
    "pubDate": "Fri, 21 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/moving-ai-governance-forward",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ZipAR: Parallel Auto-regressive Image Generation through Spatial Locality",
    "description": "arXiv:2412.04062v3 Announce Type: replace-cross Abstract: In this paper, we propose ZipAR, a training-free, plug-and-play parallel decoding framework for accelerating auto-regressive (AR) visual generation. The motivation stems from the observation that images exhibit local structures, and spatially distant regions tend to have minimal interdependence. Given a partially decoded set of visual tokens, in addition to the original next-token prediction scheme in the row dimension, the tokens corresponding to spatially adjacent regions in the column dimension can be decoded in parallel, enabling the ``next-set prediction'' paradigm. By decoding multiple tokens simultaneously in a single forward pass, the number of forward passes required to generate an image is significantly reduced, resulting in a substantial improvement in generation efficiency. Experiments demonstrate that ZipAR can reduce the number of model forward passes by up to 91% on the Emu3-Gen model without requiring any additional retraining. Code is available here: https://github.com/ThisisBillhe/ZipAR.",
    "summary": "arXiv:2412.04062v3 Announce Type: replace-cross Abstract: In this paper, we propose ZipAR, a training-free, plug-and-play parallel decoding framework for accelerating auto-regressive (AR) visual generation. The motivation stems from the observation that images exhibit local structures, and spatially distant regions tend to have minimal interdependence. Given a partially decoded set of visual tokens, in addition to the original next-token prediction scheme in the row dimension, the tokens corresponding to spatially adjacent regions in the column dimension can be decoded in parallel, enabling the ``next-set prediction'' paradigm. By decoding multiple tokens simultaneously in a single forward pass, the number of forward passes required to generate an image is significantly reduced, resulting in a substantial improvement in generation efficiency. Experiments demonstrate that ZipAR can reduce the number of model forward passes by up to 91% on the Emu3-Gen model without requiring any additional retraining. Code is available here: https://github.com/ThisisBillhe/ZipAR.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.04062",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 1",
    "description": "",
    "summary": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 1 About a year ago, we showed you...",
    "pubDate": "Mon, 02 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-sapphire-rapids",
    "thumbnail": "https://huggingface.co/blog/assets/124_intel_sapphire_rapids/02.png"
  },
  {
    "title": "Hugging Face partners with Wiz Research to Improve AI Security",
    "description": "",
    "summary": "Hugging Face partners with Wiz Research to Improve AI Security We are pleased to announce that we ar...",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-wiz-security-blog",
    "thumbnail": "https://huggingface.co/blog/assets/wiz_security/security.png"
  },
  {
    "title": "Introducing Agents.js: Give tools to your LLMs using JavaScript",
    "description": "",
    "summary": "Introducing Agents.js: Give tools to your LLMs using JavaScript We have recently been working on Age...",
    "pubDate": "Mon, 24 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/agents-js",
    "thumbnail": "https://huggingface.co/blog/assets/agents-js/thumbnail.png"
  },
  {
    "title": "Simplifying contract reviews with AI",
    "description": "Ironclad uses GPT-4 to simplify the contract review process.",
    "summary": "Ironclad uses GPT-4 to simplify the contract review process.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ironclad",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing multi-backends (TRT-LLM, vLLM) support for Text Generation Inference",
    "description": "",
    "summary": "Introducing multi-backends (TRT-LLM, vLLM) support for Text Generation Inference Introduction Since ...",
    "pubDate": "Thu, 16 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-multi-backend",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-multi-backend/thumbnail.png"
  },
  {
    "title": "GPT-4",
    "description": "We‚Äôve created GPT-4, the latest milestone in OpenAI‚Äôs effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.",
    "summary": "We‚Äôve created GPT-4, the latest milestone in OpenAI‚Äôs effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interpretable Interaction Modeling for Trajectory Prediction via Agent Selection and Physical Coefficient",
    "description": "arXiv:2405.13152v5 Announce Type: replace-cross Abstract: A thorough understanding of the interaction between the target agent and surrounding agents is a prerequisite for accurate trajectory prediction. Although many methods have been explored, they assign correlation coefficients to surrounding agents in a purely learning-based manner. In this study, we present ASPILin, which manually selects interacting agents and replaces the attention scores in Transformer with a newly computed physical correlation coefficient, enhancing the interpretability of interaction modeling. Surprisingly, these simple modifications can significantly improve prediction performance and substantially reduce computational costs. We intentionally simplified our model in other aspects, such as map encoding. Remarkably, experiments conducted on the INTERACTION, highD, and CitySim datasets demonstrate that our method is efficient and straightforward, outperforming other state-of-the-art methods.",
    "summary": "arXiv:2405.13152v5 Announce Type: replace-cross Abstract: A thorough understanding of the interaction between the target agent and surrounding agents is a prerequisite for accurate trajectory prediction. Although many methods have been explored, they assign correlation coefficients to surrounding agents in a purely learning-based manner. In this study, we present ASPILin, which manually selects interacting agents and replaces the attention scores in Transformer with a newly computed physical correlation coefficient, enhancing the interpretability of interaction modeling. Surprisingly, these simple modifications can significantly improve prediction performance and substantially reduce computational costs. We intentionally simplified our model in other aspects, such as map encoding. Remarkably, experiments conducted on the INTERACTION, highD, and CitySim datasets demonstrate that our method is efficient and straightforward, outperforming other state-of-the-art methods.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.13152",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Point-E: A system for generating 3D point clouds from complex prompts",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 16 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/point-e",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Solving math word problems",
    "description": "We‚Äôve trained¬†a system that solves grade school math problems with nearly twice the accuracy of a fine-tuned GPT-3 model. It solves about 90% as many problems as real kids: a small sample of 9-12 year olds scored 60% on a test from our dataset, while our system scored 55% on those same problems.",
    "summary": "We‚Äôve trained¬†a system that solves grade school math problems with nearly twice the accuracy of a fine-tuned GPT-3 model. It solves about 90% as many problems as real kids: a small sample of 9-12 year olds scored 60% on a test from our dataset, while our system scored 55% on those same problems.",
    "pubDate": "Fri, 29 Oct 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/solving-math-word-problems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Simple considerations for simple people building fancy neural networks",
    "description": "",
    "summary": "üöß Simple considerations for simple people building fancy neural networks Photo by Henry & Co. on Uns...",
    "pubDate": "Thu, 25 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/simple-considerations",
    "thumbnail": "https://huggingface.co/blog/assets/13_simple-considerations/henry-co-3coKbdfnAFg-unsplash.jpg"
  },
  {
    "title": "A general language model for peptide identification",
    "description": "arXiv:2502.15610v3 Announce Type: replace-cross Abstract: Accurate identification of bioactive peptides (BPs) and protein post-translational modifications (PTMs) is essential for understanding protein function and advancing therapeutic discovery. However, most computational methods remain limited in their generalizability across diverse peptide functions. Here, we present PDeepPP, a unified deep learning framework that integrates pretrained protein language models with a hybrid transformer-convolutional architecture, enabling robust identification across diverse peptide classes and PTM sites. We curated comprehensive benchmark datasets and implemented strategies to address data imbalance, allowing PDeepPP to systematically extract both global and local sequence features. Through extensive analyses-including dimensionality reduction and comparison studies-PDeepPP demonstrates strong, interpretable peptide representations and achieves state-of-the-art performance in 25 of the 33 biological identification tasks. Notably, PDeepPP attains high accuracy in antimicrobial (0.9726) and phosphorylation site (0.9984) identification, with 99.5% specificity in glycosylation site prediction and substantial reduction in false negatives in antimalarial tasks. By enabling large-scale, accurate peptide analysis, PDeepPP supports biomedical research and the discovery of novel therapeutic targets for disease treatment. All code, datasets, and pretrained models are publicly available via GitHub:https://github.com/fondress/PDeepPP and Hugging Face:https://huggingface.co/fondress/PDeppPP.",
    "summary": "arXiv:2502.15610v3 Announce Type: replace-cross Abstract: Accurate identification of bioactive peptides (BPs) and protein post-translational modifications (PTMs) is essential for understanding protein function and advancing therapeutic discovery. However, most computational methods remain limited in their generalizability across diverse peptide functions. Here, we present PDeepPP, a unified deep learning framework that integrates pretrained protein language models with a hybrid transformer-convolutional architecture, enabling robust identification across diverse peptide classes and PTM sites. We curated comprehensive benchmark datasets and implemented strategies to address data imbalance, allowing PDeepPP to systematically extract both global and local sequence features. Through extensive analyses-including dimensionality reduction and comparison studies-PDeepPP demonstrates strong, interpretable peptide representations and achieves state-of-the-art performance in 25 of the 33 biological identification tasks. Notably, PDeepPP attains high accuracy in antimicrobial (0.9726) and phosphorylation site (0.9984) identification, with 99.5% specificity in glycosylation site prediction and substantial reduction in false negatives in antimalarial tasks. By enabling large-scale, accurate peptide analysis, PDeepPP supports biomedical research and the discovery of novel therapeutic targets for disease treatment. All code, datasets, and pretrained models are publicly available via GitHub:https://github.com/fondress/PDeepPP and Hugging Face:https://huggingface.co/fondress/PDeppPP.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.15610",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "5 things from I/O to try right now",
    "description": "Collage on a dark background showing AI-generated media including humpback whales jumping from the water and the very detailed face of a chameleon",
    "summary": "Collage on a dark background showing AI-generated media including humpback whales jumping from the water and the very detailed face of a chameleon",
    "pubDate": "Thu, 12 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/io-2025-tools-to-try-globally/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5_I_O_tools_ss.width-1300.png"
  },
  {
    "title": "Accurate Parameter-Efficient Test-Time Adaptation for Time Series Forecasting",
    "description": "arXiv:2506.23424v1 Announce Type: cross Abstract: Real-world time series often exhibit a non-stationary nature, degrading the performance of pre-trained forecasting models. Test-Time Adaptation (TTA) addresses this by adjusting models during inference, but existing methods typically update the full model, increasing memory and compute costs. We propose PETSA, a parameter-efficient method that adapts forecasters at test time by only updating small calibration modules on the input and output. PETSA uses low-rank adapters and dynamic gating to adjust representations without retraining. To maintain accuracy despite limited adaptation capacity, we introduce a specialized loss combining three components: (1) a robust term, (2) a frequency-domain term to preserve periodicity, and (3) a patch-wise structural term for structural alignment. PETSA improves the adaptability of various forecasting backbones while requiring fewer parameters than baselines. Experimental results on benchmark datasets show that PETSA achieves competitive or better performance across all horizons. Our code is available at: https://github.com/BorealisAI/PETSA",
    "summary": "arXiv:2506.23424v1 Announce Type: cross Abstract: Real-world time series often exhibit a non-stationary nature, degrading the performance of pre-trained forecasting models. Test-Time Adaptation (TTA) addresses this by adjusting models during inference, but existing methods typically update the full model, increasing memory and compute costs. We propose PETSA, a parameter-efficient method that adapts forecasters at test time by only updating small calibration modules on the input and output. PETSA uses low-rank adapters and dynamic gating to adjust representations without retraining. To maintain accuracy despite limited adaptation capacity, we introduce a specialized loss combining three components: (1) a robust term, (2) a frequency-domain term to preserve periodicity, and (3) a patch-wise structural term for structural alignment. PETSA improves the adaptability of various forecasting backbones while requiring fewer parameters than baselines. Experimental results on benchmark datasets show that PETSA achieves competitive or better performance across all horizons. Our code is available at: https://github.com/BorealisAI/PETSA",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23424",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Can foundation models label data like humans?",
    "description": "",
    "summary": "Can foundation models label data like humans? Since the advent of ChatGPT, we have seen unprecedente...",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-rlhf",
    "thumbnail": "https://huggingface.co/blog/assets/llm-leaderboard/leaderboard-thumbnail.png"
  },
  {
    "title": "FedCLAM: Client Adaptive Momentum with Foreground Intensity Matching for Federated Medical Image Segmentation",
    "description": "arXiv:2506.22580v1 Announce Type: cross Abstract: Federated learning is a decentralized training approach that keeps data under stakeholder control while achieving superior performance over isolated training. While inter-institutional feature discrepancies pose a challenge in all federated settings, medical imaging is particularly affected due to diverse imaging devices and population variances, which can diminish the global model's effectiveness. Existing aggregation methods generally fail to adapt across varied circumstances. To address this, we propose FedCLAM, which integrates textit{client-adaptive momentum} terms derived from each client's loss reduction during local training, as well as a textit{personalized dampening factor} to curb overfitting. We further introduce a novel textit{intensity alignment} loss that matches predicted and ground-truth foreground distributions to handle heterogeneous image intensity profiles across institutions and devices. Extensive evaluations on two datasets show that FedCLAM surpasses eight cutting-edge methods in medical segmentation tasks, underscoring its efficacy. The code is available at https://github.com/siomvas/FedCLAM.",
    "summary": "arXiv:2506.22580v1 Announce Type: cross Abstract: Federated learning is a decentralized training approach that keeps data under stakeholder control while achieving superior performance over isolated training. While inter-institutional feature discrepancies pose a challenge in all federated settings, medical imaging is particularly affected due to diverse imaging devices and population variances, which can diminish the global model's effectiveness. Existing aggregation methods generally fail to adapt across varied circumstances. To address this, we propose FedCLAM, which integrates textit{client-adaptive momentum} terms derived from each client's loss reduction during local training, as well as a textit{personalized dampening factor} to curb overfitting. We further introduce a novel textit{intensity alignment} loss that matches predicted and ground-truth foreground distributions to handle heterogeneous image intensity profiles across institutions and devices. Extensive evaluations on two datasets show that FedCLAM surpasses eight cutting-edge methods in medical segmentation tasks, underscoring its efficacy. The code is available at https://github.com/siomvas/FedCLAM.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22580",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerate your models with ü§ó Optimum Intel and OpenVINO",
    "description": "",
    "summary": "Accelerate your models with ü§ó Optimum Intel and OpenVINO Last July, we announced that Intel and Hugg...",
    "pubDate": "Wed, 02 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/openvino",
    "thumbnail": "https://huggingface.co/blog/assets/113_openvino/thumbnail.png"
  },
  {
    "title": "SLED: A Speculative LLM Decoding Framework for Efficient Edge Serving",
    "description": "arXiv:2506.09397v3 Announce Type: replace-cross Abstract: The growing gap between the increasing complexity of large language models (LLMs) and the limited computational budgets of edge devices poses a key challenge for efficient on-device inference, despite gradual improvements in hardware capabilities. Existing strategies, such as aggressive quantization, pruning, or remote inference, trade accuracy for efficiency or lead to substantial cost burdens. This position paper introduces a new framework that leverages speculative decoding, previously viewed primarily as a decoding acceleration technique for autoregressive generation of LLMs, as a promising approach specifically adapted for edge computing by orchestrating computation across heterogeneous devices. We propose acronym, a framework that allows lightweight edge devices to draft multiple candidate tokens locally using diverse draft models, while a single, shared edge server verifies the tokens utilizing a more precise target model. To further increase the efficiency of verification, the edge server batch the diverse verification requests from devices. This approach supports device heterogeneity and reduces server-side memory footprint by sharing the same upstream target model across multiple devices. Our initial experiments with Jetson Orin Nano, Raspberry Pi 4B/5, and an edge server equipped with 4 Nvidia A100 GPUs indicate substantial benefits: 2.2 more system throughput, 2.8 more system capacity, and better cost efficiency, all without sacrificing model accuracy.",
    "summary": "arXiv:2506.09397v3 Announce Type: replace-cross Abstract: The growing gap between the increasing complexity of large language models (LLMs) and the limited computational budgets of edge devices poses a key challenge for efficient on-device inference, despite gradual improvements in hardware capabilities. Existing strategies, such as aggressive quantization, pruning, or remote inference, trade accuracy for efficiency or lead to substantial cost burdens. This position paper introduces a new framework that leverages speculative decoding, previously viewed primarily as a decoding acceleration technique for autoregressive generation of LLMs, as a promising approach specifically adapted for edge computing by orchestrating computation across heterogeneous devices. We propose acronym, a framework that allows lightweight edge devices to draft multiple candidate tokens locally using diverse draft models, while a single, shared edge server verifies the tokens utilizing a more precise target model. To further increase the efficiency of verification, the edge server batch the diverse verification requests from devices. This approach supports device heterogeneity and reduces server-side memory footprint by sharing the same upstream target model across multiple devices. Our initial experiments with Jetson Orin Nano, Raspberry Pi 4B/5, and an edge server equipped with 4 Nvidia A100 GPUs indicate substantial benefits: 2.2 more system throughput, 2.8 more system capacity, and better cost efficiency, all without sacrificing model accuracy.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.09397",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing BERTopic Integration with Hugging Face Hub",
    "description": "",
    "summary": "Introducing BERTopic Integration with the Hugging Face Hub We are thrilled to announce a significant...",
    "pubDate": "Wed, 31 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bertopic",
    "thumbnail": "https://huggingface.co/blog/assets/145_bertopic/logo.png"
  },
  {
    "title": "Director of Machine Learning Insights [Part 4]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 4] If you're interested in building ML solutions faster ...",
    "pubDate": "Wed, 23 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-4",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/part4.png"
  },
  {
    "title": "How to train a new language model from scratch using Transformers and Tokenizers",
    "description": "",
    "summary": "How to train a new language model from scratch using Transformers and Tokenizers Over the past few m...",
    "pubDate": "Fri, 14 Feb 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-train",
    "thumbnail": "https://huggingface.co/blog/assets/01_how-to-train/how-to-train_blogpost.png"
  },
  {
    "title": "Transformers backend integration in SGLang",
    "description": "",
    "summary": "Transformers backend integration in SGLang Hugging Face transformers library is the standard for wor...",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-backend-sglang",
    "thumbnail": "https://huggingface.co/blog/assets/196_transformers_backend_sglang/thumbnail.jpg"
  },
  {
    "title": "New in ChatGPT for Business: April 2025",
    "description": "Watch hands-on demos of the lastest in ChatGPT for Business: o3, image generation, enhanced memory, and internal knowledge.",
    "summary": "Watch hands-on demos of the lastest in ChatGPT for Business: o3, image generation, enhanced memory, and internal knowledge.",
    "pubDate": "Thu, 24 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/new-in-chatgpt-for-business-april-updates-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding BigBird's Block Sparse Attention",
    "description": "",
    "summary": "Understanding BigBird's Block Sparse Attention Introduction Transformer-based models have shown to b...",
    "pubDate": "Wed, 31 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/big-bird",
    "thumbnail": "https://huggingface.co/blog/assets/18_big_bird/attn.png"
  },
  {
    "title": "Genmab launches ‚ÄúAI Everywhere‚Äù",
    "description": "Genmab embraces ChatGPT Enterprise, supported by OpenAI‚Äôs commitment to security and privacy",
    "summary": "Genmab embraces ChatGPT Enterprise, supported by OpenAI‚Äôs commitment to security and privacy",
    "pubDate": "Thu, 19 Sep 2024 04:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/genmab",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How AI is reshaping the future of healthcare and medical research",
    "description": "<p>Technologists Bill Gates and S√©bastien Bubeck discuss the state of generative AI in medicine, how access to ‚Äúmedical intelligence‚Äù might help empower people across healthcare, and how AI‚Äôs accelerating improvements are likely to affect both delivery and discovery.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/'>How AI is reshaping the future of healthcare and medical research</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Technologists Bill Gates and S√©bastien Bubeck discuss the state of generative AI in medicine, how access to ‚Äúmedical intelligence‚Äù might help empower people across healthcare, and how AI‚Äôs accelerating improvements are likely to affect both delivery and discovery.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/'>How AI is reshaping the future of healthcare and medical research</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 12 Jun 2025 16:17:04 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Improvements to data analysis in ChatGPT",
    "description": "Improvements to data analysis in ChatGPT Interact with tables and charts and add files directly from Google Drive and Microsoft OneDrive.",
    "summary": "Improvements to data analysis in ChatGPT Interact with tables and charts and add files directly from Google Drive and Microsoft OneDrive.",
    "pubDate": "Thu, 16 May 2024 15:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improvements-to-data-analysis-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Idefics2: A Powerful 8B Vision-Language Model for the community",
    "description": "",
    "summary": "Introducing Idefics2: A Powerful 8B Vision-Language Model for the community We are excited to releas...",
    "pubDate": "Mon, 15 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/idefics2",
    "thumbnail": "https://huggingface.co/blog/assets/idefics/thumbnail.png"
  },
  {
    "title": "Gotta Learn Fast: A new benchmark for generalization in RL",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 10 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gotta-learn-fast",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Triton: Open-source GPU programming for neural networks",
    "description": "We‚Äôre releasing Triton 1.0, an open-source Python-like programming language which enables researchers with no CUDA experience to write highly efficient GPU code‚Äîmost of the time on par with what an expert would be able to produce.",
    "summary": "We‚Äôre releasing Triton 1.0, an open-source Python-like programming language which enables researchers with no CUDA experience to write highly efficient GPU code‚Äîmost of the time on par with what an expert would be able to produce.",
    "pubDate": "Wed, 28 Jul 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/triton",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Five Benchmark: Results",
    "description": "Yesterday,¬†OpenAI Five¬†won a best-of-three against a team of 99.95th percentile Dota players:¬†Blitz,¬†Cap,¬†Fogged,¬†Merlini, and¬†MoonMeander‚Äîfour of whom have played Dota professionally‚Äîin front of a live audience and 100,000 concurrent livestream¬†viewers.",
    "summary": "Yesterday,¬†OpenAI Five¬†won a best-of-three against a team of 99.95th percentile Dota players:¬†Blitz,¬†Cap,¬†Fogged,¬†Merlini, and¬†MoonMeander‚Äîfour of whom have played Dota professionally‚Äîin front of a live audience and 100,000 concurrent livestream¬†viewers.",
    "pubDate": "Mon, 06 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-benchmark-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Behind ‚ÄúANCESTRA‚Äù: combining Veo with live-action filmmaking",
    "description": "We partnered with Darren Aronofsky, Eliza McNitt and a team of more than 200 people to make a film using Veo and live-action filmmaking.",
    "summary": "We partnered with Darren Aronofsky, Eliza McNitt and a team of more than 200 people to make a film using Veo and live-action filmmaking.",
    "pubDate": "Fri, 13 Jun 2025 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/behind-ancestra-combining-veo-with-live-action-filmmaking/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ancestra-YTThumbnail.width-1300.png"
  },
  {
    "title": "AlphaProteo generates novel proteins for biology and health research",
    "description": "New AI system designs proteins that successfully bind to target molecules, with potential for advancing drug design, disease understanding and more.",
    "summary": "New AI system designs proteins that successfully bind to target molecules, with potential for advancing drug design, disease understanding and more.",
    "pubDate": "Thu, 05 Sep 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/",
    "thumbnail": "https://lh3.googleusercontent.com/7RKd6r-Wc8JfMau5x9knRq9DrOKGDwS3ye4YxY0jjWGntf74y8WL0lOlktJefxwkJYw33UEf2Ph_BhQ51TIufCxPkmtCPOpakekMpnOUwVI-3R6RzQ=w1200-h630-n-nu"
  },
  {
    "title": "College students and ChatGPT adoption in the US",
    "description": "A look into state-by-state adoption and how gaps might impact workforce readiness.",
    "summary": "A look into state-by-state adoption and how gaps might impact workforce readiness.",
    "pubDate": "Thu, 20 Feb 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/college-students-and-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sparking a more productive company with ChatGPT Enterprise",
    "description": "Match Group uses ChatGPT Enterprise to spark creativity and impact.",
    "summary": "Match Group uses ChatGPT Enterprise to spark creativity and impact.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/match-group",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How the voices for ChatGPT were chosen",
    "description": "How the voices for ChatGPT were chosen We worked with industry-leading casting and directing professionals to narrow down over 400 submissions before selecting the 5 voices.",
    "summary": "How the voices for ChatGPT were chosen We worked with industry-leading casting and directing professionals to narrow down over 400 submissions before selecting the 5 voices.",
    "pubDate": "Sun, 19 May 2024 23:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-the-voices-for-chatgpt-were-chosen",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Putting RL back in RLHF",
    "description": "",
    "summary": "Putting RL back in RLHF We are excited to introduce the RLOO (REINFORCE Leave One-Out) Trainer in TR...",
    "pubDate": "Wed, 12 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/putting_rl_back_in_rlhf_with_rloo",
    "thumbnail": "https://huggingface.co/blog/assets/putting_rl_back_in_rlhf_with_rloo/thumbnail.png"
  },
  {
    "title": "Innovative Research on IoT Architecture and Robotic Operating Platforms: Applications of Large Language Models and Generative AI",
    "description": "arXiv:2506.22477v1 Announce Type: cross Abstract: This paper introduces an innovative design for robotic operating platforms, underpinned by a transformative Internet of Things (IoT) architecture, seamlessly integrating cutting-edge technologies such as large language models (LLMs), generative AI, edge computing, and 5G networks. The proposed platform aims to elevate the intelligence and autonomy of IoT systems and robotics, enabling them to make real-time decisions and adapt dynamically to changing environments. Through a series of compelling case studies across industries including smart manufacturing, healthcare, and service sectors, this paper demonstrates the substantial potential of IoT-enabled robotics to optimize operational workflows, enhance productivity, and deliver innovative, scalable solutions. By emphasizing the roles of LLMs and generative AI, the research highlights how these technologies drive the evolution of intelligent robotics and IoT, shaping the future of industry-specific advancements. The findings not only showcase the transformative power of these technologies but also offer a forward-looking perspective on their broader societal and industrial implications, positioning them as catalysts for next-generation automation and technological convergence.",
    "summary": "arXiv:2506.22477v1 Announce Type: cross Abstract: This paper introduces an innovative design for robotic operating platforms, underpinned by a transformative Internet of Things (IoT) architecture, seamlessly integrating cutting-edge technologies such as large language models (LLMs), generative AI, edge computing, and 5G networks. The proposed platform aims to elevate the intelligence and autonomy of IoT systems and robotics, enabling them to make real-time decisions and adapt dynamically to changing environments. Through a series of compelling case studies across industries including smart manufacturing, healthcare, and service sectors, this paper demonstrates the substantial potential of IoT-enabled robotics to optimize operational workflows, enhance productivity, and deliver innovative, scalable solutions. By emphasizing the roles of LLMs and generative AI, the research highlights how these technologies drive the evolution of intelligent robotics and IoT, shaping the future of industry-specific advancements. The findings not only showcase the transformative power of these technologies but also offer a forward-looking perspective on their broader societal and industrial implications, positioning them as catalysts for next-generation automation and technological convergence.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22477",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Scaling the OpenAI Academy",
    "description": "Online resource hub will support AI literacy and help people from all backgrounds access tools, best practices, and peer insights to use AI.",
    "summary": "Online resource hub will support AI literacy and help people from all backgrounds access tools, best practices, and peer insights to use AI.",
    "pubDate": "Tue, 25 Mar 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/scaling-the-openai-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Preparing for malicious uses of AI",
    "description": "We‚Äôve co-authored a paper that forecasts how malicious actors could misuse AI technology, and potential ways we can prevent and mitigate these threats. This paper is the outcome of almost a year of sustained work with our colleagues at the Future of Humanity Institute, the Centre for the Study of Existential Risk, the Center for a New American Security, the Electronic Frontier Foundation, and others.",
    "summary": "We‚Äôve co-authored a paper that forecasts how malicious actors could misuse AI technology, and potential ways we can prevent and mitigate these threats. This paper is the outcome of almost a year of sustained work with our colleagues at the Future of Humanity Institute, the Centre for the Study of Existential Risk, the Center for a New American Security, the Electronic Frontier Foundation, and others.",
    "pubDate": "Tue, 20 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/preparing-for-malicious-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Google„ÄÅ„ÄåGemini for Education„Äç„Å™„Å©„ÅÆÊïôËÇ≤Âêë„ÅëAI„ÉÑ„Éº„É´Êèê‰æõÈñãÂßã",
    "description": "Google„ÅØ„ÄÅÊïôËÇ≤Âêë„ÅëAI„ÉÑ„Éº„É´Áæ§„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ„ÄåGemini for Education„Äç„ÇíÊïôËÇ≤ÁâàWorkspace„Å´ÁÑ°ÂÑü„ÅßËøΩÂä†„Åô„Çã„Åª„Åã„ÄÅClassroom„Åß„ÅÆGeminiÂà©Áî®„ÇÇÁÑ°ÊñôÂåñ„ÄÇNotebookLM„Å™„Å©„ÇíËã•Âπ¥Â±§„Å´„ÇÇÈñãÊîæ„Åó„ÄÅ„Éá„Éº„Çø‰øùË≠∑„ÇÑÂÆâÂÖ®ÊÄß„ÇíÈáçË¶ñ„Åó„ÅüË≤¨‰ªª„ÅÇ„Çã„Ç¢„Éó„É≠„Éº„ÉÅ„ÇíÂº∑Ë™ø„Åô„Çã„ÄÇ",
    "summary": "Google„ÅØ„ÄÅÊïôËÇ≤Âêë„ÅëAI„ÉÑ„Éº„É´Áæ§„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ„ÄåGemini for Education„Äç„ÇíÊïôËÇ≤ÁâàWorkspace„Å´ÁÑ°ÂÑü„ÅßËøΩÂä†„Åô„Çã„Åª„Åã„ÄÅClassroom„Åß„ÅÆGeminiÂà©Áî®„ÇÇÁÑ°ÊñôÂåñ„ÄÇNotebookLM„Å™„Å©„ÇíËã•Âπ¥Â±§„Å´„ÇÇÈñãÊîæ„Åó„ÄÅ„Éá„Éº„Çø‰øùË≠∑„ÇÑÂÆâÂÖ®ÊÄß„ÇíÈáçË¶ñ„Åó„ÅüË≤¨‰ªª„ÅÇ„Çã„Ç¢„Éó„É≠„Éº„ÉÅ„ÇíÂº∑Ë™ø„Åô„Çã„ÄÇ",
    "pubDate": "Tue, 01 Jul 2025 08:04:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/01/news058.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/01/cover_news058.jpg"
  },
  {
    "title": "OpenAI Scholars 2018: Final projects",
    "description": "Our first cohort of¬†OpenAI Scholars¬†has now completed the program.",
    "summary": "Our first cohort of¬†OpenAI Scholars¬†has now completed the program.",
    "pubDate": "Mon, 10 Sep 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2018-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Team update",
    "description": "We‚Äôve hired more great people to help us achieve our goals. Welcome, everyone!",
    "summary": "We‚Äôve hired more great people to help us achieve our goals. Welcome, everyone!",
    "pubDate": "Tue, 16 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update-august",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning to summarize with human feedback",
    "description": "We‚Äôve applied reinforcement learning from human feedback to train language models that are better at summarization.",
    "summary": "We‚Äôve applied reinforcement learning from human feedback to train language models that are better at summarization.",
    "pubDate": "Fri, 04 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-summarize-with-human-feedback",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Simplifying, stabilizing, and scaling continuous-time consistency models",
    "description": "We‚Äôve simplified, stabilized, and scaled continuous-time consistency models, achieving comparable sample quality to leading diffusion models, while using only two sampling steps.",
    "summary": "We‚Äôve simplified, stabilized, and scaled continuous-time consistency models, achieving comparable sample quality to leading diffusion models, while using only two sampling steps.",
    "pubDate": "Wed, 23 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/simplifying-stabilizing-and-scaling-continuous-time-consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Democratic inputs to AI",
    "description": "Our nonprofit organization, OpenAI, Inc., is launching a program to award ten $100,000 grants to fund experiments in setting up a democratic process for deciding what rules AI systems should follow, within the bounds defined by the law.",
    "summary": "Our nonprofit organization, OpenAI, Inc., is launching a program to award ten $100,000 grants to fund experiments in setting up a democratic process for deciding what rules AI systems should follow, within the bounds defined by the law.",
    "pubDate": "Thu, 25 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/democratic-inputs-to-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Journey to 1 Million Gradio Users!",
    "description": "",
    "summary": "Journey to 1 Million Gradio Users! 5 years ago, we launched Gradio as a simple Python library to let...",
    "pubDate": "Fri, 04 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-1m",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-1m/thumbnail.png"
  },
  {
    "title": "Vision Language Models Explained",
    "description": "",
    "summary": "Vision Language Models Explained This blog post was written on April 2024 and provides a great intro...",
    "pubDate": "Thu, 11 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vlms",
    "thumbnail": "https://huggingface.co/blog/assets/vlms_explained/thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT Team",
    "description": "We‚Äôre launching a new ChatGPT plan for teams of all sizes, which provides a secure, collaborative workspace to get the most out of ChatGPT at work.",
    "summary": "We‚Äôre launching a new ChatGPT plan for teams of all sizes, which provides a secure, collaborative workspace to get the most out of ChatGPT at work.",
    "pubDate": "Wed, 10 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-team",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Summer at Hugging Face ‚òÄÔ∏è",
    "description": "",
    "summary": "Summer At Hugging Face üòé Summer is now officially over and these last few months have been quite bus...",
    "pubDate": "Fri, 24 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/summer-at-huggingface",
    "thumbnail": "https://huggingface.co/blog/assets/27_summer_at_huggingface/summer_intro.gif"
  },
  {
    "title": "OpenAI‚Äôs Economic Blueprint",
    "description": "OpenAI‚Äôs Economic Blueprint",
    "summary": "OpenAI‚Äôs Economic Blueprint",
    "pubDate": "Mon, 13 Jan 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-economic-blueprint",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MetaSynth: Meta-Prompting-Driven Agentic Scaffolds for Diverse Synthetic Data Generation",
    "description": "arXiv:2504.12563v2 Announce Type: replace-cross Abstract: Recent smaller language models such Phi-3.5 and Phi-4 rely on synthetic data generated using larger Language models. Questions remain about leveraging synthetic data for other use cases, such as adapting LLMs to specific domains. A key limitation of synthetic data is low diversity, which negatively impacts its downstream applicability for improving other models. To address this, we propose MetaSynth, a method for generating synthetic data that enhances diversity through meta-prompting, where a language model orchestrates multiple 'expert' LLM agents to collaboratively generate data. Using only 25 million tokens of synthetic data generated with MetaSynth, we successfully adapt a well-trained LLM (Mistral-7B-v0.3) to two specialized domains-Finance and Biomedicine-without compromising the capabilities of the resulting model in general tasks. In addition, we evaluate the diversity of our synthetic data using seven automated metrics, and find that it approaches the diversity of LLM pre-training corpora. Continually pre-training Mistral-7B-v0.3 with MetaSynth notably outperforms the base LLM, showing improvements of up to 4.08% in Finance and 13.75% in Biomedicine. The same model shows degraded performance when trained on data generated using a template prompt, even when the template includes prior generations and varying In-Context exemplars of real data. Our findings suggest that a few million tokens of diverse synthetic data without mixing any real data, is sufficient for effective domain adaptation when using MetaSynth.",
    "summary": "arXiv:2504.12563v2 Announce Type: replace-cross Abstract: Recent smaller language models such Phi-3.5 and Phi-4 rely on synthetic data generated using larger Language models. Questions remain about leveraging synthetic data for other use cases, such as adapting LLMs to specific domains. A key limitation of synthetic data is low diversity, which negatively impacts its downstream applicability for improving other models. To address this, we propose MetaSynth, a method for generating synthetic data that enhances diversity through meta-prompting, where a language model orchestrates multiple 'expert' LLM agents to collaboratively generate data. Using only 25 million tokens of synthetic data generated with MetaSynth, we successfully adapt a well-trained LLM (Mistral-7B-v0.3) to two specialized domains-Finance and Biomedicine-without compromising the capabilities of the resulting model in general tasks. In addition, we evaluate the diversity of our synthetic data using seven automated metrics, and find that it approaches the diversity of LLM pre-training corpora. Continually pre-training Mistral-7B-v0.3 with MetaSynth notably outperforms the base LLM, showing improvements of up to 4.08% in Finance and 13.75% in Biomedicine. The same model shows degraded performance when trained on data generated using a template prompt, even when the template includes prior generations and varying In-Context exemplars of real data. Our findings suggest that a few million tokens of diverse synthetic data without mixing any real data, is sufficient for effective domain adaptation when using MetaSynth.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.12563",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Docmatix - a huge dataset for Document Visual Question Answering",
    "description": "",
    "summary": "Docmatix - A huge dataset for Document Visual Question Answering With this blog we are releasing Doc...",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/docmatix",
    "thumbnail": "https://huggingface.co/blog/assets/183_docmatix/thumbnail_new.png"
  },
  {
    "title": "Super Co-alignment of Human and AI for Sustainable Symbiotic Society",
    "description": "arXiv:2504.17404v5 Announce Type: replace Abstract: As Artificial Intelligence (AI) advances toward Artificial General Intelligence (AGI) and eventually Artificial Superintelligence (ASI), it may potentially surpass human control, deviate from human values, and even lead to irreversible catastrophic consequences in extreme cases. This looming risk underscores the critical importance of the 'superalignment' problem - ensuring that AI systems which are much smarter than humans, remain aligned with human (compatible) intentions and values. While current scalable oversight and weak-to-strong generalization methods demonstrate certain applicability, they exhibit fundamental flaws in addressing the superalignment paradigm - notably, the unidirectional imposition of human values cannot accommodate superintelligence's autonomy or ensure AGI/ASI's stable learning. We contend that the values for sustainable symbiotic society should be co-shaped by humans and living AI together, achieving 'Super Co-alignment.' Guided by this vision, we propose a concrete framework that integrates external oversight and intrinsic proactive alignment. External oversight superalignment should be grounded in human-centered ultimate decision, supplemented by interpretable automated evaluation and correction, to achieve continuous alignment with humanity's evolving values. Intrinsic proactive superalignment is rooted in a profound understanding of the Self, others, and society, integrating self-awareness, self-reflection, and empathy to spontaneously infer human intentions, distinguishing good from evil and proactively prioritizing human well-being. The integration of externally-driven oversight with intrinsically-driven proactive alignment will co-shape symbiotic values and rules through iterative human-ASI co-alignment, paving the way for achieving safe and beneficial AGI and ASI for good, for human, and for a symbiotic ecology.",
    "summary": "arXiv:2504.17404v5 Announce Type: replace Abstract: As Artificial Intelligence (AI) advances toward Artificial General Intelligence (AGI) and eventually Artificial Superintelligence (ASI), it may potentially surpass human control, deviate from human values, and even lead to irreversible catastrophic consequences in extreme cases. This looming risk underscores the critical importance of the 'superalignment' problem - ensuring that AI systems which are much smarter than humans, remain aligned with human (compatible) intentions and values. While current scalable oversight and weak-to-strong generalization methods demonstrate certain applicability, they exhibit fundamental flaws in addressing the superalignment paradigm - notably, the unidirectional imposition of human values cannot accommodate superintelligence's autonomy or ensure AGI/ASI's stable learning. We contend that the values for sustainable symbiotic society should be co-shaped by humans and living AI together, achieving 'Super Co-alignment.' Guided by this vision, we propose a concrete framework that integrates external oversight and intrinsic proactive alignment. External oversight superalignment should be grounded in human-centered ultimate decision, supplemented by interpretable automated evaluation and correction, to achieve continuous alignment with humanity's evolving values. Intrinsic proactive superalignment is rooted in a profound understanding of the Self, others, and society, integrating self-awareness, self-reflection, and empathy to spontaneously infer human intentions, distinguishing good from evil and proactively prioritizing human well-being. The integration of externally-driven oversight with intrinsically-driven proactive alignment will co-shape symbiotic values and rules through iterative human-ASI co-alignment, paving the way for achieving safe and beneficial AGI and ASI for good, for human, and for a symbiotic ecology.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.17404",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CodeAgents + Structure: A Better Way to Execute Actions",
    "description": "",
    "summary": "CodeAgents + Structure: A Better Way to Execute Actions Today we're sharing research that bridges tw...",
    "pubDate": "Wed, 28 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/structured-codeagent",
    "thumbnail": "https://huggingface.co/blog/assets/structured-codeagent/thumbnail-codeagent.png"
  },
  {
    "title": "AI for the board game Diplomacy",
    "description": "Successful communication and cooperation have been crucial for helping societies advance throughout history. The closed environments of board games can serve as a sandbox for modelling and investigating interaction and communication ‚Äì and we can learn a lot from playing them. In our recent paper, published today in Nature Communications, we show how artificial agents can use communication to better cooperate in the board game Diplomacy, a vibrant domain in artificial intelligence (AI) research, known for its focus on alliance building.",
    "summary": "Successful communication and cooperation have been crucial for helping societies advance throughout history. The closed environments of board games can serve as a sandbox for modelling and investigating interaction and communication ‚Äì and we can learn a lot from playing them. In our recent paper, published today in Nature Communications, we show how artificial agents can use communication to better cooperate in the board game Diplomacy, a vibrant domain in artificial intelligence (AI) research, known for its focus on alliance building.",
    "pubDate": "Tue, 06 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ai-for-the-board-game-diplomacy/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI Fellows Fall 2018",
    "description": "We‚Äôre now accepting applications for the next cohort of OpenAI Fellows, a program which offers a compensated 6-month apprenticeship in AI research at OpenAI.",
    "summary": "We‚Äôre now accepting applications for the next cohort of OpenAI Fellows, a program which offers a compensated 6-month apprenticeship in AI research at OpenAI.",
    "pubDate": "Wed, 30 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2018: Meet our Scholars",
    "description": "Our first class of¬†OpenAI Scholars¬†is underway, and¬†you can now follow along as this group¬†of experienced software developers becomes machine learning practitioners.",
    "summary": "Our first class of¬†OpenAI Scholars¬†is underway, and¬†you can now follow along as this group¬†of experienced software developers becomes machine learning practitioners.",
    "pubDate": "Wed, 25 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2018-meet-our-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Llama 2 on Amazon SageMaker a Benchmark",
    "description": "",
    "summary": "Llama 2 on Amazon SageMaker a Benchmark Deploying large language models (LLMs) and other generative ...",
    "pubDate": "Tue, 26 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama-sagemaker-benchmark",
    "thumbnail": "https://huggingface.co/blog/assets/llama_sagemaker_benchmark/thumbnail.jpg"
  },
  {
    "title": "Knowing You Don't Know: Learning When to Continue Search in Multi-round RAG through Self-Practicing",
    "description": "arXiv:2505.02811v2 Announce Type: replace Abstract: Retrieval Augmented Generation (RAG) has shown strong capability in enhancing language models' knowledge and reducing AI generative hallucinations, driving its widespread use. However, complex tasks requiring multi-round retrieval remain challenging, and early attempts tend to be overly optimistic without a good sense of self-skepticism. Current multi-round RAG systems may continue searching even when enough information has already been retrieved, or they may provide incorrect answers without having sufficient information or knowledge. Existing solutions either require large amounts of expensive human-labeled process supervision data or lead to subpar performance. This paper aims to address these limitations by introducing a new framework, SIM-RAG, to explicitly enhance RAG systems' self-awareness and multi-round retrieval capabilities. To train SIM-RAG, we first let a RAG system self-practice multi-round retrieval, augmenting existing question-answer pairs with intermediate inner monologue reasoning steps to generate synthetic training data. For each pair, the system may explore multiple retrieval paths, which are labeled as successful if they reach the correct answer and unsuccessful otherwise. Using this data, we train a lightweight information sufficiency Critic. At inference time, the Critic evaluates whether the RAG system has retrieved sufficient information at each round, guiding retrieval decisions and improving system-level self-awareness through in-context reinforcement learning. Experiments across multiple prominent RAG benchmarks show that SIM-RAG is an effective multi-round RAG solution. Furthermore, this framework is system-efficient, adding a lightweight component to RAG without requiring modifications to existing LLMs or search engines, and data-efficient, eliminating the need for costly human-annotated mid-step retrieval process supervision data.",
    "summary": "arXiv:2505.02811v2 Announce Type: replace Abstract: Retrieval Augmented Generation (RAG) has shown strong capability in enhancing language models' knowledge and reducing AI generative hallucinations, driving its widespread use. However, complex tasks requiring multi-round retrieval remain challenging, and early attempts tend to be overly optimistic without a good sense of self-skepticism. Current multi-round RAG systems may continue searching even when enough information has already been retrieved, or they may provide incorrect answers without having sufficient information or knowledge. Existing solutions either require large amounts of expensive human-labeled process supervision data or lead to subpar performance. This paper aims to address these limitations by introducing a new framework, SIM-RAG, to explicitly enhance RAG systems' self-awareness and multi-round retrieval capabilities. To train SIM-RAG, we first let a RAG system self-practice multi-round retrieval, augmenting existing question-answer pairs with intermediate inner monologue reasoning steps to generate synthetic training data. For each pair, the system may explore multiple retrieval paths, which are labeled as successful if they reach the correct answer and unsuccessful otherwise. Using this data, we train a lightweight information sufficiency Critic. At inference time, the Critic evaluates whether the RAG system has retrieved sufficient information at each round, guiding retrieval decisions and improving system-level self-awareness through in-context reinforcement learning. Experiments across multiple prominent RAG benchmarks show that SIM-RAG is an effective multi-round RAG solution. Furthermore, this framework is system-efficient, adding a lightweight component to RAG without requiring modifications to existing LLMs or search engines, and data-efficient, eliminating the need for costly human-annotated mid-step retrieval process supervision data.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.02811",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Scholars 2019: Meet our Scholars",
    "description": "Our class of eight¬†scholars¬†(out of 550 applicants) brings together collective expertise in literature, philosophy, cell biology, statistics, economics, quantum physics, and business innovation.",
    "summary": "Our class of eight¬†scholars¬†(out of 550 applicants) brings together collective expertise in literature, philosophy, cell biology, statistics, economics, quantum physics, and business innovation.",
    "pubDate": "Wed, 13 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019-meet-our-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evolving online forms into dynamic data",
    "description": "Typeform evolves online forms into dynamic and conversational data collection experiences with GPT-3.5 and GPT-4.",
    "summary": "Typeform evolves online forms into dynamic and conversational data collection experiences with GPT-3.5 and GPT-4.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/typeform",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The AI tools for Art Newsletter - Issue 1",
    "description": "",
    "summary": "The AI tools for Art Newsletter First issue üéâ The AI space is moving so fast it‚Äôs hard to believe th...",
    "pubDate": "Fri, 31 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-art-newsletter-jan-25",
    "thumbnail": "https://huggingface.co/blog/assets/ai_art_newsletter_1/thumbnail.png"
  },
  {
    "title": "New and improved embedding model",
    "description": "We are excited to announce a new embedding model which is significantly more capable, cost effective, and simpler to use.",
    "summary": "We are excited to announce a new embedding model which is significantly more capable, cost effective, and simpler to use.",
    "pubDate": "Thu, 15 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-and-improved-embedding-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ask before you Build: Rethinking AI-for-Good in Human Trafficking Interventions",
    "description": "arXiv:2506.22512v1 Announce Type: cross Abstract: AI for good initiatives often rely on the assumption that technical interventions can resolve complex social problems. In the context of human trafficking (HT), such techno-solutionism risks oversimplifying exploitation, reinforcing power imbalances and causing harm to the very communities AI claims to support. In this paper, we introduce the Radical Questioning (RQ) framework as a five step, pre-project ethical assessment tool to critically evaluate whether AI should be built at all, especially in domains involving marginalized populations and entrenched systemic injustice. RQ does not replace principles based ethics but precedes it, offering an upstream, deliberative space to confront assumptions, map power, and consider harms before design. Using a case study in AI for HT, we demonstrate how RQ reveals overlooked sociocultural complexities and guides us away from surveillance based interventions toward survivor empowerment tools. While developed in the context of HT, RQ's five step structure can generalize to other domains, though the specific questions must be contextual. This paper situates RQ within a broader AI ethics philosophy that challenges instrumentalist norms and centers relational, reflexive responsibility.",
    "summary": "arXiv:2506.22512v1 Announce Type: cross Abstract: AI for good initiatives often rely on the assumption that technical interventions can resolve complex social problems. In the context of human trafficking (HT), such techno-solutionism risks oversimplifying exploitation, reinforcing power imbalances and causing harm to the very communities AI claims to support. In this paper, we introduce the Radical Questioning (RQ) framework as a five step, pre-project ethical assessment tool to critically evaluate whether AI should be built at all, especially in domains involving marginalized populations and entrenched systemic injustice. RQ does not replace principles based ethics but precedes it, offering an upstream, deliberative space to confront assumptions, map power, and consider harms before design. Using a case study in AI for HT, we demonstrate how RQ reveals overlooked sociocultural complexities and guides us away from surveillance based interventions toward survivor empowerment tools. While developed in the context of HT, RQ's five step structure can generalize to other domains, though the specific questions must be contextual. This paper situates RQ within a broader AI ethics philosophy that challenges instrumentalist norms and centers relational, reflexive responsibility.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22512",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PaperBench: Evaluating AI‚Äôs Ability to Replicate AI Research",
    "description": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research.",
    "summary": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research.",
    "pubDate": "Wed, 02 Apr 2025 10:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paperbench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemini 2.5: Updates to our family of thinking models",
    "description": "Explore the latest Gemini 2.5 model updates with enhanced performance and accuracy: Gemini 2.5 Pro now stable, Flash generally available, and the new Flash-Lite in preview.",
    "summary": "Explore the latest Gemini 2.5 model updates with enhanced performance and accuracy: Gemini 2.5 Pro now stable, Flash generally available, and the new Flash-Lite in preview.",
    "pubDate": "Tue, 17 Jun 2025 16:03:39 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-updates-to-our-family-of-thinking-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-2-5-pro-meta_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Deploy MusicGen in no time with Inference Endpoints",
    "description": "",
    "summary": "Deploy MusicGen in no time with Inference Endpoints MusicGen is a powerful music generation model th...",
    "pubDate": "Fri, 04 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/run-musicgen-as-an-api",
    "thumbnail": "https://huggingface.co/blog/assets/run-musicgen-as-an-api/thumbnail.png"
  },
  {
    "title": "Visual-Semantic Knowledge Conflicts in Operating Rooms: Synthetic Data Curation for Surgical Risk Perception in Multimodal Large Language Models",
    "description": "arXiv:2506.22500v1 Announce Type: cross Abstract: Surgical risk identification is critical for patient safety and reducing preventable medical errors. While multimodal large language models (MLLMs) show promise for automated operating room (OR) risk detection, they often exhibit visual-semantic knowledge conflicts (VS-KC), failing to identify visual safety violations despite understanding textual rules. To address this, we introduce a dataset comprising over 34,000 synthetic images generated by diffusion models, depicting operating room scenes containing entities that violate established safety rules. These images were created to alleviate data scarcity and examine MLLMs vulnerabilities. In addition, the dataset includes 214 human-annotated images that serve as a gold-standard reference for validation. This comprehensive dataset, spanning diverse perspectives, stages, and configurations, is designed to expose and study VS-KC. Fine-tuning on OR-VSKC significantly improves MLLMs' detection of trained conflict entities and generalizes well to new viewpoints for these entities, but performance on untrained entity types remains poor, highlighting learning specificity and the need for comprehensive training. The main contributions of this work include: (1) a data generation methodology tailored for rule-violation scenarios; (2) the release of the OR-VSKC dataset and its associated benchmark as open-source resources; and (3) an empirical analysis of violation-sensitive knowledge consistency in representative MLLMs. The dataset and appendix are available at https://github.com/zgg2577/VS-KC.",
    "summary": "arXiv:2506.22500v1 Announce Type: cross Abstract: Surgical risk identification is critical for patient safety and reducing preventable medical errors. While multimodal large language models (MLLMs) show promise for automated operating room (OR) risk detection, they often exhibit visual-semantic knowledge conflicts (VS-KC), failing to identify visual safety violations despite understanding textual rules. To address this, we introduce a dataset comprising over 34,000 synthetic images generated by diffusion models, depicting operating room scenes containing entities that violate established safety rules. These images were created to alleviate data scarcity and examine MLLMs vulnerabilities. In addition, the dataset includes 214 human-annotated images that serve as a gold-standard reference for validation. This comprehensive dataset, spanning diverse perspectives, stages, and configurations, is designed to expose and study VS-KC. Fine-tuning on OR-VSKC significantly improves MLLMs' detection of trained conflict entities and generalizes well to new viewpoints for these entities, but performance on untrained entity types remains poor, highlighting learning specificity and the need for comprehensive training. The main contributions of this work include: (1) a data generation methodology tailored for rule-violation scenarios; (2) the release of the OR-VSKC dataset and its associated benchmark as open-source resources; and (3) an empirical analysis of violation-sensitive knowledge consistency in representative MLLMs. The dataset and appendix are available at https://github.com/zgg2577/VS-KC.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22500",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Multimodal Object Detection using Depth and Image Data for Manufacturing Parts",
    "description": "arXiv:2411.09062v3 Announce Type: replace-cross Abstract: Manufacturing requires reliable object detection methods for precise picking and handling of diverse types of manufacturing parts and components. Traditional object detection methods utilize either only 2D images from cameras or 3D data from lidars or similar 3D sensors. However, each of these sensors have weaknesses and limitations. Cameras do not have depth perception and 3D sensors typically do not carry color information. These weaknesses can undermine the reliability and robustness of industrial manufacturing systems. To address these challenges, this work proposes a multi-sensor system combining an red-green-blue (RGB) camera and a 3D point cloud sensor. The two sensors are calibrated for precise alignment of the multimodal data captured from the two hardware devices. A novel multimodal object detection method is developed to process both RGB and depth data. This object detector is based on the Faster R-CNN baseline that was originally designed to process only camera images. The results show that the multimodal model significantly outperforms the depth-only and RGB-only baselines on established object detection metrics. More specifically, the multimodal model improves mAP by 13% and raises Mean Precision by 11.8% in comparison to the RGB-only baseline. Compared to the depth-only baseline, it improves mAP by 78% and raises Mean Precision by 57%. Hence, this method facilitates more reliable and robust object detection in service to smart manufacturing applications.",
    "summary": "arXiv:2411.09062v3 Announce Type: replace-cross Abstract: Manufacturing requires reliable object detection methods for precise picking and handling of diverse types of manufacturing parts and components. Traditional object detection methods utilize either only 2D images from cameras or 3D data from lidars or similar 3D sensors. However, each of these sensors have weaknesses and limitations. Cameras do not have depth perception and 3D sensors typically do not carry color information. These weaknesses can undermine the reliability and robustness of industrial manufacturing systems. To address these challenges, this work proposes a multi-sensor system combining an red-green-blue (RGB) camera and a 3D point cloud sensor. The two sensors are calibrated for precise alignment of the multimodal data captured from the two hardware devices. A novel multimodal object detection method is developed to process both RGB and depth data. This object detector is based on the Faster R-CNN baseline that was originally designed to process only camera images. The results show that the multimodal model significantly outperforms the depth-only and RGB-only baselines on established object detection metrics. More specifically, the multimodal model improves mAP by 13% and raises Mean Precision by 11.8% in comparison to the RGB-only baseline. Compared to the depth-only baseline, it improves mAP by 78% and raises Mean Precision by 57%. Hence, this method facilitates more reliable and robust object detection in service to smart manufacturing applications.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.09062",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Assisted Generation: a new direction toward low-latency text generation",
    "description": "",
    "summary": "Assisted Generation: a new direction toward low-latency text generation Large language models are al...",
    "pubDate": "Thu, 11 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/assisted-generation",
    "thumbnail": "https://huggingface.co/blog/assets/assisted-generation/thumbnail.png"
  },
  {
    "title": "Custom instructions for ChatGPT",
    "description": "We‚Äôre rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
    "summary": "We‚Äôre rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
    "pubDate": "Thu, 20 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/custom-instructions-for-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LNUCB-TA: Linear-nonlinear Hybrid Bandit Learning with Temporal Attention",
    "description": "arXiv:2503.00387v2 Announce Type: replace-cross Abstract: Existing contextual multi-armed bandit (MAB) algorithms fail to effectively capture both long-term trends and local patterns across all arms, leading to suboptimal performance in environments with rapidly changing reward structures. They also rely on static exploration rates, which do not dynamically adjust to changing conditions. To overcome these limitations, we propose LNUCB-TA, a hybrid bandit model integrating a novel nonlinear component (adaptive k-Nearest Neighbors (k-NN)) for reducing time complexity, alongside a global-and-local attention-based exploration mechanism. Our approach uniquely combines linear and nonlinear estimation techniques, with the nonlinear module dynamically adjusting k based on reward variance to enhance spatiotemporal pattern recognition. This reduces the likelihood of selecting suboptimal arms while improving reward estimation accuracy and computational efficiency. The attention-based mechanism ranks arms by past performance and selection frequency, dynamically adjusting exploration and exploitation in real time without requiring manual tuning of exploration rates. By integrating global attention (assessing all arms collectively) and local attention (focusing on individual arms), LNUCB-TA efficiently adapts to temporal and spatial complexities. Empirical results show LNUCB-TA significantly outperforms state-of-the-art linear, nonlinear, and hybrid bandits in cumulative and mean reward, convergence, and robustness across different exploration rates. Theoretical analysis further confirms its reliability with a sub-linear regret bound.",
    "summary": "arXiv:2503.00387v2 Announce Type: replace-cross Abstract: Existing contextual multi-armed bandit (MAB) algorithms fail to effectively capture both long-term trends and local patterns across all arms, leading to suboptimal performance in environments with rapidly changing reward structures. They also rely on static exploration rates, which do not dynamically adjust to changing conditions. To overcome these limitations, we propose LNUCB-TA, a hybrid bandit model integrating a novel nonlinear component (adaptive k-Nearest Neighbors (k-NN)) for reducing time complexity, alongside a global-and-local attention-based exploration mechanism. Our approach uniquely combines linear and nonlinear estimation techniques, with the nonlinear module dynamically adjusting k based on reward variance to enhance spatiotemporal pattern recognition. This reduces the likelihood of selecting suboptimal arms while improving reward estimation accuracy and computational efficiency. The attention-based mechanism ranks arms by past performance and selection frequency, dynamically adjusting exploration and exploitation in real time without requiring manual tuning of exploration rates. By integrating global attention (assessing all arms collectively) and local attention (focusing on individual arms), LNUCB-TA efficiently adapts to temporal and spatial complexities. Empirical results show LNUCB-TA significantly outperforms state-of-the-art linear, nonlinear, and hybrid bandits in cumulative and mean reward, convergence, and robustness across different exploration rates. Theoretical analysis further confirms its reliability with a sub-linear regret bound.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.00387",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face and Google partner for open AI collaboration",
    "description": "",
    "summary": "Hugging Face and Google partner for open AI collaboration At Hugging Face, we want to enable all com...",
    "pubDate": "Thu, 25 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gcp-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/173_gcp-partnership/thumbnail.jpg"
  },
  {
    "title": "Multivariate Probabilistic Time Series Forecasting with Informer",
    "description": "",
    "summary": "Multivariate Probabilistic Time Series Forecasting with Informer Introduction A few months ago we in...",
    "pubDate": "Fri, 10 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/informer",
    "thumbnail": "https://huggingface.co/blog/assets/134_informer/thumbnail.png"
  },
  {
    "title": "The next chapter of our Gemini era",
    "description": "We're bringing Gemini to more Google products",
    "summary": "We're bringing Gemini to more Google products",
    "pubDate": "Thu, 08 Feb 2024 13:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-gemini-update-sundar-pichai-2024/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Keyword_Social_-_1920x1080.width-1300.png"
  },
  {
    "title": "New methods boost reasoning in small and large language models",
    "description": "<p>New techniques are reimagining how LLMs reason. By combining symbolic logic, mathematical rigor, and adaptive planning, these methods enable models to tackle complex, real-world problems across a variety of fields.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/'>New methods boost reasoning in small and large language models</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>New techniques are reimagining how LLMs reason. By combining symbolic logic, mathematical rigor, and adaptive planning, these methods enable models to tackle complex, real-world problems across a variety of fields.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/'>New methods boost reasoning in small and large language models</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Music AI Sandbox, now with new features and broader access",
    "description": "Helping music professionals explore the potential of generative AI",
    "summary": "Helping music professionals explore the potential of generative AI",
    "pubDate": "Thu, 24 Apr 2025 15:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/music-ai-sandbox-now-with-new-features-and-broader-access/",
    "thumbnail": "https://lh3.googleusercontent.com/t_n_87B373tBNlvzgBy7RuJXb5hoPdLtBBgWjzfJnVuauI0JFwiYAyGM_LMl-yeJ3zNWO782VBE8m6ByaxDJoIvIbWoQ_DQPMdxszprk5Tbh2xQx5Q=w1200-h630-n-nu"
  },
  {
    "title": "Welcome fastText to the ü§ó Hub",
    "description": "",
    "summary": "Welcome fastText to the Hugging Face Hub fastText is a library for efficient learning of text repres...",
    "pubDate": "Tue, 06 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fasttext",
    "thumbnail": "https://huggingface.co/blog/assets/147_fasttext/thumbnail.png"
  },
  {
    "title": "New Credit Facility Enhances Financial Flexibility",
    "description": "In addition to securing $6.6 billion in new funding from leading investors, we have established a new $4 billion credit facility with leading banks, including JPMorgan Chase, Citi, Goldman Sachs, Morgan Stanley, Santander, Wells Fargo, SMBC, UBS, and HSBC.",
    "summary": "In addition to securing $6.6 billion in new funding from leading investors, we have established a new $4 billion credit facility with leading banks, including JPMorgan Chase, Citi, Goldman Sachs, Morgan Stanley, Santander, Wells Fargo, SMBC, UBS, and HSBC.",
    "pubDate": "Thu, 03 Oct 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-credit-facility-enhances-financial-flexibility",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Impact of AI on Educational Assessment: A Framework for Constructive Alignment",
    "description": "arXiv:2506.23815v1 Announce Type: cross Abstract: The influence of Artificial Intelligence (AI), and specifically Large Language Models (LLM), on education is continuously increasing. These models are frequently used by students, giving rise to the question whether current forms of assessment are still a valid way to evaluate student performance and comprehension. The theoretical framework developed in this paper is grounded in Constructive Alignment (CA) theory and Bloom's taxonomy for defining learning objectives. We argue that AI influences learning objectives of different Bloom levels in a different way, and assessment has to be adopted accordingly. Furthermore, in line with Bloom's vision, formative and summative assessment should be aligned on whether the use of AI is permitted or not. Although lecturers tend to agree that education and assessment need to be adapted to the presence of AI, a strong bias exists on the extent to which lecturers want to allow for AI in assessment. This bias is caused by a lecturer's familiarity with AI and specifically whether they use it themselves. To avoid this bias, we propose structured guidelines on a university or faculty level, to foster alignment among the staff. Besides that, we argue that teaching staff should be trained on the capabilities and limitations of AI tools. In this way, they are better able to adapt their assessment methods.",
    "summary": "arXiv:2506.23815v1 Announce Type: cross Abstract: The influence of Artificial Intelligence (AI), and specifically Large Language Models (LLM), on education is continuously increasing. These models are frequently used by students, giving rise to the question whether current forms of assessment are still a valid way to evaluate student performance and comprehension. The theoretical framework developed in this paper is grounded in Constructive Alignment (CA) theory and Bloom's taxonomy for defining learning objectives. We argue that AI influences learning objectives of different Bloom levels in a different way, and assessment has to be adopted accordingly. Furthermore, in line with Bloom's vision, formative and summative assessment should be aligned on whether the use of AI is permitted or not. Although lecturers tend to agree that education and assessment need to be adapted to the presence of AI, a strong bias exists on the extent to which lecturers want to allow for AI in assessment. This bias is caused by a lecturer's familiarity with AI and specifically whether they use it themselves. To avoid this bias, we propose structured guidelines on a university or faculty level, to foster alignment among the staff. Besides that, we argue that teaching staff should be trained on the capabilities and limitations of AI tools. In this way, they are better able to adapt their assessment methods.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23815",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI achieves silver-medal standard solving International Mathematical Olympiad problems",
    "description": "Breakthrough models AlphaProof and AlphaGeometry 2 solve advanced reasoning problems in mathematics",
    "summary": "Breakthrough models AlphaProof and AlphaGeometry 2 solve advanced reasoning problems in mathematics",
    "pubDate": "Thu, 25 Jul 2024 15:29:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/",
    "thumbnail": "https://lh3.googleusercontent.com/2A21eFt7wdDrmMzzkenrCTuioLWGFdzU5Ao5dPH9yPtAw6QNHxZcDmoQA2_ZriU2gMjX8mzEOtfPbMCRuL5kVzLoz6efLgqT_foBXU3pxKBXTTOXXpc=w1200-h630-n-nu"
  },
  {
    "title": "Evaluating Language Model Bias with ü§ó Evaluate",
    "description": "",
    "summary": "Evaluating Language Model Bias with ü§ó Evaluate While the size and capabilities of large language mod...",
    "pubDate": "Mon, 24 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/evaluating-llm-bias",
    "thumbnail": "https://huggingface.co/blog/assets/112_evaluating-llm-bias/thumbnail.png"
  },
  {
    "title": "Deploying Speech-to-Speech on Hugging Face",
    "description": "",
    "summary": "Deploying Speech-to-Speech on Hugging Face Introduction Speech-to-Speech (S2S) is an exciting new pr...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/s2s_endpoint",
    "thumbnail": "https://huggingface.co/blog/assets/s2s_endpoint/thumbnail.png"
  },
  {
    "title": "Using generative AI to help robots jump higher and land safely",
    "description": "MIT CSAIL researchers combined GenAI and a physics simulation engine to refine robot designs. The result: a machine that out-jumped a robot designed by humans.",
    "summary": "MIT CSAIL researchers combined GenAI and a physics simulation engine to refine robot designs. The result: a machine that out-jumped a robot designed by humans.",
    "pubDate": "Fri, 27 Jun 2025 13:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/using-generative-ai-help-robots-jump-higher-land-safely-0627",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Jumping_Robot%20%285%29.png"
  },
  {
    "title": "When Will It Fail?: Anomaly to Prompt for Forecasting Future Anomalies in Time Series",
    "description": "arXiv:2506.23596v1 Announce Type: cross Abstract: Recently, forecasting future abnormal events has emerged as an important scenario to tackle real-world necessities. However, the solution of predicting specific future time points when anomalies will occur, known as Anomaly Prediction (AP), remains under-explored. Existing methods dealing with time series data fail in AP, focusing only on immediate anomalies or failing to provide precise predictions for future anomalies. To address the AP task, we propose a novel framework called Anomaly to Prompt (A2P), comprised of Anomaly-Aware Forecasting (AAF) and Synthetic Anomaly Prompting (SAP). To enable the forecasting model to forecast abnormal time points, we adopt a strategy to learn the relationships of anomalies. For the robust detection of anomalies, our proposed SAP introduces a learnable Anomaly Prompt Pool (APP) that simulates diverse anomaly patterns using signal adaptive prompt. Comprehensive experiments on multiple real-world datasets demonstrate the superiority of A2P over state-of-the-art methods, showcasing its ability to predict future anomalies. Our implementation code is available at https://github.com/KU-VGI/AP.",
    "summary": "arXiv:2506.23596v1 Announce Type: cross Abstract: Recently, forecasting future abnormal events has emerged as an important scenario to tackle real-world necessities. However, the solution of predicting specific future time points when anomalies will occur, known as Anomaly Prediction (AP), remains under-explored. Existing methods dealing with time series data fail in AP, focusing only on immediate anomalies or failing to provide precise predictions for future anomalies. To address the AP task, we propose a novel framework called Anomaly to Prompt (A2P), comprised of Anomaly-Aware Forecasting (AAF) and Synthetic Anomaly Prompting (SAP). To enable the forecasting model to forecast abnormal time points, we adopt a strategy to learn the relationships of anomalies. For the robust detection of anomalies, our proposed SAP introduces a learnable Anomaly Prompt Pool (APP) that simulates diverse anomaly patterns using signal adaptive prompt. Comprehensive experiments on multiple real-world datasets demonstrate the superiority of A2P over state-of-the-art methods, showcasing its ability to predict future anomalies. Our implementation code is available at https://github.com/KU-VGI/AP.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23596",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A hazard analysis framework for code synthesis large language models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-hazard-analysis-framework-for-code-synthesis-large-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning",
    "description": "arXiv:2506.19592v2 Announce Type: replace Abstract: We introduce TAPAS (Task-based Adaptation and Planning using AgentS), a multi-agent framework that integrates Large Language Models (LLMs) with symbolic planning to solve complex tasks without the need for manually defined environment models. TAPAS employs specialized LLM-based agents that collaboratively generate and adapt domain models, initial states, and goal specifications as needed using structured tool-calling mechanisms. Through this tool-based interaction, downstream agents can request modifications from upstream agents, enabling adaptation to novel attributes and constraints without manual domain redefinition. A ReAct (Reason+Act)-style execution agent, coupled with natural language plan translation, bridges the gap between dynamically generated plans and real-world robot capabilities. TAPAS demonstrates strong performance in benchmark planning domains and in the VirtualHome simulated real-world environment.",
    "summary": "arXiv:2506.19592v2 Announce Type: replace Abstract: We introduce TAPAS (Task-based Adaptation and Planning using AgentS), a multi-agent framework that integrates Large Language Models (LLMs) with symbolic planning to solve complex tasks without the need for manually defined environment models. TAPAS employs specialized LLM-based agents that collaboratively generate and adapt domain models, initial states, and goal specifications as needed using structured tool-calling mechanisms. Through this tool-based interaction, downstream agents can request modifications from upstream agents, enabling adaptation to novel attributes and constraints without manual domain redefinition. A ReAct (Reason+Act)-style execution agent, coupled with natural language plan translation, bridges the gap between dynamically generated plans and real-world robot capabilities. TAPAS demonstrates strong performance in benchmark planning domains and in the VirtualHome simulated real-world environment.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19592",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deploy Embedding Models with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Deploy Embedding Models with Hugging Face Inference Endpoints The rise of Generative AI and LLMs lik...",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/168_inference_endpoints_embeddings/thumbnail.jpg"
  },
  {
    "title": "Introducing Gemini: our largest and most capable AI model",
    "description": "Making AI more helpful for everyone",
    "summary": "Making AI more helpful for everyone",
    "pubDate": "Wed, 06 Dec 2023 15:13:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-our-largest-and-most-capable-ai-model/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_SS.width-1300.jpg"
  },
  {
    "title": "Fine-Tune ViT for Image Classification with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune ViT for Image Classification with ü§ó Transformers Just as transformers-based models have re...",
    "pubDate": "Fri, 11 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-vit",
    "thumbnail": "https://huggingface.co/blog/assets/51_fine_tune_vit/vit-thumbnail.jpg"
  },
  {
    "title": "Introducing the Enterprise Scenarios Leaderboard: a Leaderboard for Real World Use Cases",
    "description": "",
    "summary": "Introducing the Enterprise Scenarios Leaderboard: a Leaderboard for Real World Use Cases Today, the ...",
    "pubDate": "Wed, 31 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-patronus",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_patronus.png"
  },
  {
    "title": "OpenAI o3-mini System Card",
    "description": "This report outlines the safety work carried out for the OpenAI o3-mini model, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
    "summary": "This report outlines the safety work carried out for the OpenAI o3-mini model, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
    "pubDate": "Fri, 31 Jan 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-mini-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Red-Teaming Resistance Leaderboard",
    "description": "",
    "summary": "Introducing the Red-Teaming Resistance Leaderboard Content warning: since this blog post is about a ...",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-haizelab",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_haizelab.png"
  },
  {
    "title": "Against 'softmaxing' culture",
    "description": "arXiv:2506.22968v1 Announce Type: cross Abstract: AI is flattening culture. Evaluations of 'culture' are showing the myriad ways in which large AI models are homogenizing language and culture, averaging out rich linguistic differences into generic expressions. I call this phenomenon 'softmaxing culture,' and it is one of the fundamental challenges facing AI evaluations today. Efforts to improve and strengthen evaluations of culture are central to the project of cultural alignment in large AI systems. This position paper argues that machine learning (ML) and human-computer interaction (HCI) approaches to evaluation are limited. I propose two key shifts. First, instead of asking 'what is culture?' at the start of system evaluations, I propose beginning with the question: 'when is culture?' Second, while I acknowledge the philosophical claim that cultural universals exist, the challenge is not simply to describe them, but to situate them in relation to their particulars. Taken together, these conceptual shifts invite evaluation approaches that move beyond technical requirements, toward perspectives more responsive to the complexities of culture.",
    "summary": "arXiv:2506.22968v1 Announce Type: cross Abstract: AI is flattening culture. Evaluations of 'culture' are showing the myriad ways in which large AI models are homogenizing language and culture, averaging out rich linguistic differences into generic expressions. I call this phenomenon 'softmaxing culture,' and it is one of the fundamental challenges facing AI evaluations today. Efforts to improve and strengthen evaluations of culture are central to the project of cultural alignment in large AI systems. This position paper argues that machine learning (ML) and human-computer interaction (HCI) approaches to evaluation are limited. I propose two key shifts. First, instead of asking 'what is culture?' at the start of system evaluations, I propose beginning with the question: 'when is culture?' Second, while I acknowledge the philosophical claim that cultural universals exist, the challenge is not simply to describe them, but to situate them in relation to their particulars. Taken together, these conceptual shifts invite evaluation approaches that move beyond technical requirements, toward perspectives more responsive to the complexities of culture.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22968",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Time-variant Image Inpainting via Interactive Distribution Transition Estimation",
    "description": "arXiv:2506.23461v1 Announce Type: cross Abstract: In this work, we focus on a novel and practical task, i.e., Time-vAriant iMage inPainting (TAMP). The aim of TAMP is to restore a damaged target image by leveraging the complementary information from a reference image, where both images captured the same scene but with a significant time gap in between, i.e., time-variant images. Different from conventional reference-guided image inpainting, the reference image under TAMP setup presents significant content distinction to the target image and potentially also suffers from damages. Such an application frequently happens in our daily lives to restore a damaged image by referring to another reference image, where there is no guarantee of the reference image's source and quality. In particular, our study finds that even state-of-the-art (SOTA) reference-guided image inpainting methods fail to achieve plausible results due to the chaotic image complementation. To address such an ill-posed problem, we propose a novel Interactive Distribution Transition Estimation (InDiTE) module which interactively complements the time-variant images with adaptive semantics thus facilitate the restoration of damaged regions. To further boost the performance, we propose our TAMP solution, namely Interactive Distribution Transition Estimation-driven Diffusion (InDiTE-Diff), which integrates InDiTE with SOTA diffusion model and conducts latent cross-reference during sampling. Moreover, considering the lack of benchmarks for TAMP task, we newly assembled a dataset, i.e., TAMP-Street, based on existing image and mask datasets. We conduct experiments on the TAMP-Street datasets under two different time-variant image inpainting settings, which show our method consistently outperform SOTA reference-guided image inpainting methods for solving TAMP.",
    "summary": "arXiv:2506.23461v1 Announce Type: cross Abstract: In this work, we focus on a novel and practical task, i.e., Time-vAriant iMage inPainting (TAMP). The aim of TAMP is to restore a damaged target image by leveraging the complementary information from a reference image, where both images captured the same scene but with a significant time gap in between, i.e., time-variant images. Different from conventional reference-guided image inpainting, the reference image under TAMP setup presents significant content distinction to the target image and potentially also suffers from damages. Such an application frequently happens in our daily lives to restore a damaged image by referring to another reference image, where there is no guarantee of the reference image's source and quality. In particular, our study finds that even state-of-the-art (SOTA) reference-guided image inpainting methods fail to achieve plausible results due to the chaotic image complementation. To address such an ill-posed problem, we propose a novel Interactive Distribution Transition Estimation (InDiTE) module which interactively complements the time-variant images with adaptive semantics thus facilitate the restoration of damaged regions. To further boost the performance, we propose our TAMP solution, namely Interactive Distribution Transition Estimation-driven Diffusion (InDiTE-Diff), which integrates InDiTE with SOTA diffusion model and conducts latent cross-reference during sampling. Moreover, considering the lack of benchmarks for TAMP task, we newly assembled a dataset, i.e., TAMP-Street, based on existing image and mask datasets. We conduct experiments on the TAMP-Street datasets under two different time-variant image inpainting settings, which show our method consistently outperform SOTA reference-guided image inpainting methods for solving TAMP.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23461",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Hallucinations Leaderboard, an Open Effort to Measure Hallucinations in Large Language Models",
    "description": "",
    "summary": "The Hallucinations Leaderboard, an Open Effort to Measure Hallucinations in Large Language Models In...",
    "pubDate": "Mon, 29 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-hallucinations",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "STCLocker: Deadlock Avoidance Testing for Autonomous Driving Systems",
    "description": "arXiv:2506.23995v1 Announce Type: cross Abstract: Autonomous Driving System (ADS) testing is essential to ensure the safety and reliability of autonomous vehicles (AVs) before deployment. However, existing techniques primarily focus on evaluating ADS functionalities in single-AV settings. As ADSs are increasingly deployed in multi-AV traffic, it becomes crucial to assess their cooperative performance, particularly regarding deadlocks, a fundamental coordination failure in which multiple AVs enter a circular waiting state indefinitely, resulting in motion planning failures. Despite its importance, the cooperative capability of ADSs to prevent deadlocks remains insufficiently underexplored. To address this gap, we propose the first dedicated Spatio-Temporal Conflict-Guided Deadlock Avoidance Testing technique, STCLocker, for generating DeadLock Scenarios (DLSs), where a group of AVs controlled by the ADS under test are in a circular wait state. STCLocker consists of three key components: Deadlock Oracle, Conflict Feedback, and Conflict-aware Scenario Generation. Deadlock Oracle provides a reliable black-box mechanism for detecting deadlock cycles among multiple AVs within a given scenario. Conflict Feedback and Conflict-aware Scenario Generation collaborate to actively guide AVs into simultaneous competition over spatial conflict resources (i.e., shared passing regions) and temporal competitive behaviors (i.e., reaching the conflict region at the same time), thereby increasing the effectiveness of generating conflict-prone deadlocks. We evaluate STCLocker on two types of ADSs: Roach, an end-to-end ADS, and OpenCDA, a module-based ADS supporting cooperative communication. Experimental results show that, on average, STCLocker generates more DLS than the best-performing baseline.",
    "summary": "arXiv:2506.23995v1 Announce Type: cross Abstract: Autonomous Driving System (ADS) testing is essential to ensure the safety and reliability of autonomous vehicles (AVs) before deployment. However, existing techniques primarily focus on evaluating ADS functionalities in single-AV settings. As ADSs are increasingly deployed in multi-AV traffic, it becomes crucial to assess their cooperative performance, particularly regarding deadlocks, a fundamental coordination failure in which multiple AVs enter a circular waiting state indefinitely, resulting in motion planning failures. Despite its importance, the cooperative capability of ADSs to prevent deadlocks remains insufficiently underexplored. To address this gap, we propose the first dedicated Spatio-Temporal Conflict-Guided Deadlock Avoidance Testing technique, STCLocker, for generating DeadLock Scenarios (DLSs), where a group of AVs controlled by the ADS under test are in a circular wait state. STCLocker consists of three key components: Deadlock Oracle, Conflict Feedback, and Conflict-aware Scenario Generation. Deadlock Oracle provides a reliable black-box mechanism for detecting deadlock cycles among multiple AVs within a given scenario. Conflict Feedback and Conflict-aware Scenario Generation collaborate to actively guide AVs into simultaneous competition over spatial conflict resources (i.e., shared passing regions) and temporal competitive behaviors (i.e., reaching the conflict region at the same time), thereby increasing the effectiveness of generating conflict-prone deadlocks. We evaluate STCLocker on two types of ADSs: Roach, an end-to-end ADS, and OpenCDA, a module-based ADS supporting cooperative communication. Experimental results show that, on average, STCLocker generates more DLS than the best-performing baseline.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23995",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Best practices for deploying language models",
    "description": "Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models.",
    "summary": "Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models.",
    "pubDate": "Thu, 02 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/best-practices-for-deploying-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Reads, Feb. 2021 - Long-range Transformers",
    "description": "",
    "summary": "Hugging Face Reads, Feb. 2021 - Long-range Transformers Co-written by Teven Le Scao, Patrick Von Pla...",
    "pubDate": "Tue, 09 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/long-range-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/14_long_range_transformers/EfficientTransformerTaxonomy.png"
  },
  {
    "title": "Optimize and deploy models with Optimum-Intel and OpenVINO GenAI",
    "description": "",
    "summary": "Optimize and deploy models with Optimum-Intel and OpenVINO GenAI Deploying Transformers models at th...",
    "pubDate": "Fri, 20 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-with-openvino",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Empowering YouTube creators with generative AI",
    "description": "New video generation technology in YouTube Shorts will help millions of people realize their creative vision",
    "summary": "New video generation technology in YouTube Shorts will help millions of people realize their creative vision",
    "pubDate": "Wed, 18 Sep 2024 14:30:06 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/empowering-youtube-creators-with-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/Q8qBc1kzbYeksHRjsSuR7HEvezKsw3n1fxYlOqLf2sslqDOqYXJOhxyjznZ4cyq1fwNhpyMTMXW0RRrgHweVg6NaCEPnt3ujcFAIe0bVXK_sHka7cLo=w1200-h630-n-nu"
  },
  {
    "title": "Using AI to improve patient access to clinical trials",
    "description": "Paradigm uses OpenAI‚Äôs API to improve patient access to clinical trials.",
    "summary": "Paradigm uses OpenAI‚Äôs API to improve patient access to clinical trials.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paradigm",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Imitation Learning of Correlated Policies in Stackelberg Games",
    "description": "arXiv:2503.08883v3 Announce Type: replace Abstract: Stackelberg games, widely applied in domains like economics and security, involve asymmetric interactions where a leader's strategy drives follower responses. Accurately modeling these dynamics allows domain experts to optimize strategies in interactive scenarios, such as turn-based sports like badminton. In multi-agent systems, agent behaviors are interdependent, and traditional Multi-Agent Imitation Learning (MAIL) methods often fail to capture these complex interactions. Correlated policies, which account for opponents' strategies, are essential for accurately modeling such dynamics. However, even methods designed for learning correlated policies, like CoDAIL, struggle in Stackelberg games due to their asymmetric decision-making, where leaders and followers cannot simultaneously account for each other's actions, often leading to non-correlated policies. Furthermore, existing MAIL methods that match occupancy measures or use adversarial techniques like GAIL or Inverse RL face scalability challenges, particularly in high-dimensional environments, and suffer from unstable training. To address these challenges, we propose a correlated policy occupancy measure specifically designed for Stackelberg games and introduce the Latent Stackelberg Differential Network (LSDN) to match it. LSDN models two-agent interactions as shared latent state trajectories and uses multi-output Geometric Brownian Motion (MO-GBM) to effectively capture joint policies. By leveraging MO-GBM, LSDN disentangles environmental influences from agent-driven transitions in latent space, enabling the simultaneous learning of interdependent policies. This design eliminates the need for adversarial training and simplifies the learning process. Extensive experiments on Iterative Matrix Games and multi-agent particle environments demonstrate that LSDN can better reproduce complex interaction dynamics than existing MAIL methods.",
    "summary": "arXiv:2503.08883v3 Announce Type: replace Abstract: Stackelberg games, widely applied in domains like economics and security, involve asymmetric interactions where a leader's strategy drives follower responses. Accurately modeling these dynamics allows domain experts to optimize strategies in interactive scenarios, such as turn-based sports like badminton. In multi-agent systems, agent behaviors are interdependent, and traditional Multi-Agent Imitation Learning (MAIL) methods often fail to capture these complex interactions. Correlated policies, which account for opponents' strategies, are essential for accurately modeling such dynamics. However, even methods designed for learning correlated policies, like CoDAIL, struggle in Stackelberg games due to their asymmetric decision-making, where leaders and followers cannot simultaneously account for each other's actions, often leading to non-correlated policies. Furthermore, existing MAIL methods that match occupancy measures or use adversarial techniques like GAIL or Inverse RL face scalability challenges, particularly in high-dimensional environments, and suffer from unstable training. To address these challenges, we propose a correlated policy occupancy measure specifically designed for Stackelberg games and introduce the Latent Stackelberg Differential Network (LSDN) to match it. LSDN models two-agent interactions as shared latent state trajectories and uses multi-output Geometric Brownian Motion (MO-GBM) to effectively capture joint policies. By leveraging MO-GBM, LSDN disentangles environmental influences from agent-driven transitions in latent space, enabling the simultaneous learning of interdependent policies. This design eliminates the need for adversarial training and simplifies the learning process. Extensive experiments on Iterative Matrix Games and multi-agent particle environments demonstrate that LSDN can better reproduce complex interaction dynamics than existing MAIL methods.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.08883",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ICASSP2025 Áô∫Ë°®Â†±Âëä @Hyderabad, India",
    "description": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ 2025Âπ¥4Êúà6Êó•(Êó•)„Äú4Êúà11Êó•(Èáë)„Å´„Ç§„É≥„Éâ„Éª„Éè„Ç§„Éá„É©„Éê„Éº„Éâ„ÄÅHyderabad International Convention Centre„Å´„Å¶ÈñãÂÇ¨„Åï„Çå„Åü„ÄÅÈü≥Èüø„ÉªÈü≥ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5728' rel='nofollow'>ICASSP2025 Áô∫Ë°®Â†±Âëä @Hyderabad, India</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ 2025Âπ¥4Êúà6Êó•(Êó•)„Äú4Êúà11Êó•(Èáë)„Å´„Ç§„É≥„Éâ„Éª„Éè„Ç§„Éá„É©„Éê„Éº„Éâ„ÄÅHyderabad International Convention Centre„Å´„Å¶ÈñãÂÇ¨„Åï„Çå„Åü„ÄÅÈü≥Èüø„ÉªÈü≥ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5728' rel='nofollow'>ICASSP2025 Áô∫Ë°®Â†±Âëä @Hyderabad, India</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Tue, 15 Apr 2025 01:50:49 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5728",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/IMG_20250406_091623-1.jpg"
  },
  {
    "title": "The Partnership: Amazon SageMaker and Hugging Face",
    "description": "",
    "summary": "The Partnership: Amazon SageMaker and Hugging Face Look at these smiles! Today, we announce a strate...",
    "pubDate": "Tue, 23 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face",
    "thumbnail": "https://huggingface.co/blog/assets/17_the_partnership_amazon_sagemaker_and_hugging_face/thumbnail.png"
  },
  {
    "title": "Nubank elevates customer experiences with OpenAI",
    "description": "Nubank elevates customer experiences with OpenAI",
    "summary": "Nubank elevates customer experiences with OpenAI",
    "pubDate": "Fri, 07 Mar 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nubank",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Neurons: Emulating the Human Visual Cortex Improves Fidelity and Interpretability in fMRI-to-Video Reconstruction",
    "description": "arXiv:2503.11167v2 Announce Type: replace-cross Abstract: Decoding visual stimuli from neural activity is essential for understanding the human brain. While fMRI methods have successfully reconstructed static images, fMRI-to-video reconstruction faces challenges due to the need for capturing spatiotemporal dynamics like motion and scene transitions. Recent approaches have improved semantic and perceptual alignment but struggle to integrate coarse fMRI data with detailed visual features. Inspired by the hierarchical organization of the visual system, we propose NEURONS, a novel framework that decouples learning into four correlated sub-tasks: key object segmentation, concept recognition, scene description, and blurry video reconstruction. This approach simulates the visual cortex's functional specialization, allowing the model to capture diverse video content. In the inference stage, NEURONS generates robust conditioning signals for a pre-trained text-to-video diffusion model to reconstruct the videos. Extensive experiments demonstrate that NEURONS outperforms state-of-the-art baselines, achieving solid improvements in video consistency (26.6%) and semantic-level accuracy (19.1%). Notably, NEURONS shows a strong functional correlation with the visual cortex, highlighting its potential for brain-computer interfaces and clinical applications. Code and model weights are available at: https://github.com/xmed-lab/NEURONS.",
    "summary": "arXiv:2503.11167v2 Announce Type: replace-cross Abstract: Decoding visual stimuli from neural activity is essential for understanding the human brain. While fMRI methods have successfully reconstructed static images, fMRI-to-video reconstruction faces challenges due to the need for capturing spatiotemporal dynamics like motion and scene transitions. Recent approaches have improved semantic and perceptual alignment but struggle to integrate coarse fMRI data with detailed visual features. Inspired by the hierarchical organization of the visual system, we propose NEURONS, a novel framework that decouples learning into four correlated sub-tasks: key object segmentation, concept recognition, scene description, and blurry video reconstruction. This approach simulates the visual cortex's functional specialization, allowing the model to capture diverse video content. In the inference stage, NEURONS generates robust conditioning signals for a pre-trained text-to-video diffusion model to reconstruct the videos. Extensive experiments demonstrate that NEURONS outperforms state-of-the-art baselines, achieving solid improvements in video consistency (26.6%) and semantic-level accuracy (19.1%). Notably, NEURONS shows a strong functional correlation with the visual cortex, highlighting its potential for brain-computer interfaces and clinical applications. Code and model weights are available at: https://github.com/xmed-lab/NEURONS.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.11167",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "New ViT and ALIGN Models From Kakao Brain",
    "description": "",
    "summary": "Kakao Brain‚Äôs Open Source ViT, ALIGN, and the New COYO Text-Image Dataset Kakao Brain and Hugging Fa...",
    "pubDate": "Mon, 06 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vit-align",
    "thumbnail": "https://huggingface.co/blog//assets/132_vit_align/thumbnail.png"
  },
  {
    "title": "License to Call: Introducing Transformers Agents 2.0",
    "description": "",
    "summary": "License to Call: Introducing Transformers Agents 2.0 TL;DR We are releasing Transformers Agents 2.0!...",
    "pubDate": "Mon, 13 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/agents",
    "thumbnail": "https://huggingface.co/blog/assets/agents/thumbnail.png"
  },
  {
    "title": "Learning Modular Exponentiation with Transformers",
    "description": "arXiv:2506.23679v1 Announce Type: cross Abstract: Modular exponentiation is crucial to number theory and cryptography, yet remains largely unexplored from a mechanistic interpretability standpoint. We train a 4-layer encoder-decoder Transformer model to perform this operation and investigate the emergence of numerical reasoning during training. Utilizing principled sampling strategies, PCA-based embedding analysis, and activation patching, we examine how number-theoretic properties are encoded within the model. We find that reciprocal operand training leads to strong performance gains, with sudden generalization across related moduli. These synchronized accuracy surges reflect grokking-like dynamics, suggesting the model internalizes shared arithmetic structure. We also find a subgraph consisting entirely of attention heads in the final layer sufficient to achieve full performance on the task of regular exponentiation. These results suggest that transformer models learn modular arithmetic through specialized computational circuits, paving the way for more interpretable and efficient neural approaches to modular exponentiation.",
    "summary": "arXiv:2506.23679v1 Announce Type: cross Abstract: Modular exponentiation is crucial to number theory and cryptography, yet remains largely unexplored from a mechanistic interpretability standpoint. We train a 4-layer encoder-decoder Transformer model to perform this operation and investigate the emergence of numerical reasoning during training. Utilizing principled sampling strategies, PCA-based embedding analysis, and activation patching, we examine how number-theoretic properties are encoded within the model. We find that reciprocal operand training leads to strong performance gains, with sudden generalization across related moduli. These synchronized accuracy surges reflect grokking-like dynamics, suggesting the model internalizes shared arithmetic structure. We also find a subgraph consisting entirely of attention heads in the final layer sufficient to achieve full performance on the task of regular exponentiation. These results suggest that transformer models learn modular arithmetic through specialized computational circuits, paving the way for more interpretable and efficient neural approaches to modular exponentiation.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23679",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SoK: Semantic Privacy in Large Language Models",
    "description": "arXiv:2506.23603v1 Announce Type: cross Abstract: As Large Language Models (LLMs) are increasingly deployed in sensitive domains, traditional data privacy measures prove inadequate for protecting information that is implicit, contextual, or inferable - what we define as semantic privacy. This Systematization of Knowledge (SoK) introduces a lifecycle-centric framework to analyze how semantic privacy risks emerge across input processing, pretraining, fine-tuning, and alignment stages of LLMs. We categorize key attack vectors and assess how current defenses, such as differential privacy, embedding encryption, edge computing, and unlearning, address these threats. Our analysis reveals critical gaps in semantic-level protection, especially against contextual inference and latent representation leakage. We conclude by outlining open challenges, including quantifying semantic leakage, protecting multimodal inputs, balancing de-identification with generation quality, and ensuring transparency in privacy enforcement. This work aims to inform future research on designing robust, semantically aware privacy-preserving techniques for LLMs.",
    "summary": "arXiv:2506.23603v1 Announce Type: cross Abstract: As Large Language Models (LLMs) are increasingly deployed in sensitive domains, traditional data privacy measures prove inadequate for protecting information that is implicit, contextual, or inferable - what we define as semantic privacy. This Systematization of Knowledge (SoK) introduces a lifecycle-centric framework to analyze how semantic privacy risks emerge across input processing, pretraining, fine-tuning, and alignment stages of LLMs. We categorize key attack vectors and assess how current defenses, such as differential privacy, embedding encryption, edge computing, and unlearning, address these threats. Our analysis reveals critical gaps in semantic-level protection, especially against contextual inference and latent representation leakage. We conclude by outlining open challenges, including quantifying semantic leakage, protecting multimodal inputs, balancing de-identification with generation quality, and ensuring transparency in privacy enforcement. This work aims to inform future research on designing robust, semantically aware privacy-preserving techniques for LLMs.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23603",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Faster Training and Inference: Habana Gaudi¬Æ2 vs Nvidia A100 80GB",
    "description": "",
    "summary": "Faster Training and Inference: Habana Gaudi¬Æ-2 vs Nvidia A100 80GB In this article, you will learn h...",
    "pubDate": "Wed, 14 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana-gaudi-2-benchmark",
    "thumbnail": "https://huggingface.co/blog/assets/habana-gaudi-2-benchmark/thumbnail.png"
  },
  {
    "title": "Addendum to OpenAI o3 and o4-mini system card: OpenAI o3 Operator",
    "description": "We are replacing the existing GPT-4o-based model for Operator with a version based on OpenAI o3. The API version will remain based on 4o.",
    "summary": "We are replacing the existing GPT-4o-based model for Operator with a version based on OpenAI o3. The API version will remain based on 4o.",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-system-card-addendum-operator-o3",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Model Distillation in the API",
    "description": "Fine-tune a cost-efficient model with the outputs of a large frontier model‚Äìall on the OpenAI platform",
    "summary": "Fine-tune a cost-efficient model with the outputs of a large frontier model‚Äìall on the OpenAI platform",
    "pubDate": "Tue, 01 Oct 2024 10:02:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-model-distillation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our vision for building a universal AI assistant",
    "description": "We‚Äôre extending Gemini to become a world model that can make plans and imagine new experiences by simulating aspects of the world.",
    "summary": "We‚Äôre extending Gemini to become a world model that can make plans and imagine new experiences by simulating aspects of the world.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/our-vision-for-building-a-universal-ai-assistant/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_GeminiVision_SocialShare.width-1300.png"
  },
  {
    "title": "AMD Pervasive AI Developer Contest!",
    "description": "",
    "summary": "AMD Pervasive AI Developer Contest AMD and Hugging Face are actively engaged in helping developers s...",
    "pubDate": "Wed, 14 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/amd_pervasive_developer_ai_contest",
    "thumbnail": "https://huggingface.co/blog/amd_pervasive_developer_ai_contest/assets/amd_pervasive_developer_ai_contest/amd_developer_general_abstract.jpg"
  },
  {
    "title": "Mixture of Experts Explained",
    "description": "",
    "summary": "Mixture of Experts Explained With the release of Mixtral 8x7B (announcement, model card), a class of...",
    "pubDate": "Mon, 11 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/moe",
    "thumbnail": "https://huggingface.co/blog/assets/moe/thumbnail.png"
  },
  {
    "title": "Spam detection in the physical world",
    "description": "We‚Äôve created the world‚Äôs first Spam-detecting AI trained entirely in simulation and deployed on a physical robot.",
    "summary": "We‚Äôve created the world‚Äôs first Spam-detecting AI trained entirely in simulation and deployed on a physical robot.",
    "pubDate": "Sat, 01 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spam-detection-in-the-physical-world",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Demis Hassabis & John Jumper awarded Nobel Prize in Chemistry",
    "description": "The award recognizes their work developing AlphaFold, a groundbreaking AI system that predicts the 3D structure of proteins from their amino acid sequences.",
    "summary": "The award recognizes their work developing AlphaFold, a groundbreaking AI system that predicts the 3D structure of proteins from their amino acid sequences.",
    "pubDate": "Wed, 09 Oct 2024 11:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/demis-hassabis-john-jumper-awarded-nobel-prize-in-chemistry/",
    "thumbnail": "https://lh3.googleusercontent.com/7ZdZh5xhoD5NnykRBJHACxkxc3VubCdJLGHty2nYdJ36pBLVxRWO3Keu9C2Tum4OHCyGbJ5K5mB8R_oR94JG700qenuZ2rhq2sKjN4IkjIoU9Chv=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI Red Teaming Network",
    "description": "We‚Äôre announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in improving the safety of OpenAI‚Äôs models to join our efforts.",
    "summary": "We‚Äôre announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in improving the safety of OpenAI‚Äôs models to join our efforts.",
    "pubDate": "Tue, 19 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/red-teaming-network",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks",
    "description": "arXiv:2505.12884v2 Announce Type: replace-cross Abstract: Lightweight Vision-Language Models (VLMs) are indispensable for resource-constrained applications. The prevailing approach to aligning vision and language models involves freezing both the vision encoder and the language model while training small connector modules. However, this strategy heavily depends on the intrinsic capabilities of the language model, which can be suboptimal for lightweight models with limited representational capacity. In this work, we investigate this alignment bottleneck through the lens of mutual information, demonstrating that the constrained capacity of the language model inherently limits the Effective Mutual Information (EMI) between multimodal inputs and outputs, thereby compromising alignment quality. To address this challenge, we propose TinyAlign, a novel framework inspired by Retrieval-Augmented Generation, which strategically retrieves relevant context from a memory bank to enrich multimodal inputs and enhance their alignment. Extensive empirical evaluations reveal that TinyAlign significantly reduces training loss, accelerates convergence, and enhances task performance. Remarkably, it allows models to achieve baseline-level performance with only 40% of the fine-tuning data, highlighting exceptional data efficiency. Our work thus offers a practical pathway for developing more capable lightweight VLMs while introducing a fresh theoretical lens to better understand and address alignment bottlenecks in constrained multimodal systems.",
    "summary": "arXiv:2505.12884v2 Announce Type: replace-cross Abstract: Lightweight Vision-Language Models (VLMs) are indispensable for resource-constrained applications. The prevailing approach to aligning vision and language models involves freezing both the vision encoder and the language model while training small connector modules. However, this strategy heavily depends on the intrinsic capabilities of the language model, which can be suboptimal for lightweight models with limited representational capacity. In this work, we investigate this alignment bottleneck through the lens of mutual information, demonstrating that the constrained capacity of the language model inherently limits the Effective Mutual Information (EMI) between multimodal inputs and outputs, thereby compromising alignment quality. To address this challenge, we propose TinyAlign, a novel framework inspired by Retrieval-Augmented Generation, which strategically retrieves relevant context from a memory bank to enrich multimodal inputs and enhance their alignment. Extensive empirical evaluations reveal that TinyAlign significantly reduces training loss, accelerates convergence, and enhances task performance. Remarkably, it allows models to achieve baseline-level performance with only 40% of the fine-tuning data, highlighting exceptional data efficiency. Our work thus offers a practical pathway for developing more capable lightweight VLMs while introducing a fresh theoretical lens to better understand and address alignment bottlenecks in constrained multimodal systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.12884",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI announces nonprofit commission advisors",
    "description": "OpenAI is appointing four new advisors to help inform OpenAI‚Äôs philanthropic efforts.",
    "summary": "OpenAI is appointing four new advisors to help inform OpenAI‚Äôs philanthropic efforts.",
    "pubDate": "Tue, 15 Apr 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonprofit-commission-advisors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware",
    "description": "",
    "summary": "(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware In our previous post, Exploring Quantization Back...",
    "pubDate": "Thu, 19 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/flux-qlora",
    "thumbnail": "https://huggingface.co/blog/assets/flux-qlora/thumbnail.png"
  },
  {
    "title": "Welcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM",
    "description": "",
    "summary": "Welcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM TL;DR Today Google...",
    "pubDate": "Wed, 12 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma3",
    "thumbnail": "https://huggingface.co/blog/assets/gemma3/thumbnail.png"
  },
  {
    "title": "AI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÊôÇ‰ª£„ÄÅ‰ºÅÊ•≠„ÅÆÂú®„ÇäÊñπ„ÅØ„Å©„ÅÜÂ§â„Çè„ÇãÔºü„ÄÄ„Äå‰∏äÂè∏„ÅØ„ÅÑ„Çâ„Å™„Åè„Å™„Çã„ÅÆ„ÅãÂïèÈ°å„Äç„ÇíËÄÉÂØü",
    "description": "Ë©±È°å„ÅÆAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅØ„ÄÅ‰ºÅÊ•≠„ÅÆÂú®„ÇäÊñπ„Çí„Å©„ÅÆ„Çà„ÅÜ„Å´Â§â„Åà„Çã„ÅÆ„Åã„ÄÇ‰∫∫Èñì„Å®AI„ÅÆÂçîÂÉç„ÅåÈÄ≤Âåñ„Åô„Çã„Å´„Å§„Çå„Å¶„Åì„Çå„Åæ„Åß„Äå„Éî„É©„Éü„ÉÉ„ÉâÂûã„Äç„Å†„Å£„ÅüÁµÑÁπî„ÅÆÂú®„ÇäÊñπ„ÅØÂ§âÂåñ„Åô„Çã„ÅÆ„Å†„Çç„ÅÜ„Åã„ÄÇPwC„Ç≥„É≥„Çµ„É´„ÉÜ„Ç£„É≥„Ç∞„ÅÆÊúÄÊñ∞„É¨„Éù„Éº„Éà„Åã„ÇâËÄÉÂØü„Åô„Çã„ÄÇ",
    "summary": "Ë©±È°å„ÅÆAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅØ„ÄÅ‰ºÅÊ•≠„ÅÆÂú®„ÇäÊñπ„Çí„Å©„ÅÆ„Çà„ÅÜ„Å´Â§â„Åà„Çã„ÅÆ„Åã„ÄÇ‰∫∫Èñì„Å®AI„ÅÆÂçîÂÉç„ÅåÈÄ≤Âåñ„Åô„Çã„Å´„Å§„Çå„Å¶„Åì„Çå„Åæ„Åß„Äå„Éî„É©„Éü„ÉÉ„ÉâÂûã„Äç„Å†„Å£„ÅüÁµÑÁπî„ÅÆÂú®„ÇäÊñπ„ÅØÂ§âÂåñ„Åô„Çã„ÅÆ„Å†„Çç„ÅÜ„Åã„ÄÇPwC„Ç≥„É≥„Çµ„É´„ÉÜ„Ç£„É≥„Ç∞„ÅÆÊúÄÊñ∞„É¨„Éù„Éº„Éà„Åã„ÇâËÄÉÂØü„Åô„Çã„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 16:40:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/30/news091.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/30/cover_news091.jpg"
  },
  {
    "title": "OpenAI announces new members to board of directors",
    "description": "Dr. Sue Desmond-Hellmann, Nicole Seligman, Fidji Simo join; Sam Altman rejoins board",
    "summary": "Dr. Sue Desmond-Hellmann, Nicole Seligman, Fidji Simo join; Sam Altman rejoins board",
    "pubDate": "Fri, 08 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-announces-new-members-to-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Teaching AI models the broad strokes to sketch more like humans do",
    "description": "SketchAgent, a drawing system developed by MIT CSAIL researchers, sketches up concepts stroke-by-stroke, teaching language models to visually express concepts on their own and collaborate with humans.",
    "summary": "SketchAgent, a drawing system developed by MIT CSAIL researchers, sketches up concepts stroke-by-stroke, teaching language models to visually express concepts on their own and collaborate with humans.",
    "pubDate": "Mon, 02 Jun 2025 14:50:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/teaching-ai-models-to-sketch-more-like-humans-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-SketchAgent.jpg"
  },
  {
    "title": "Deep Dive: Vision Transformers On Hugging Face Optimum Graphcore",
    "description": "",
    "summary": "Deep Dive: Vision Transformers On Hugging Face Optimum Graphcore This blog post will show how easy i...",
    "pubDate": "Thu, 18 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/97_vision_transformers/thumbnail.png"
  },
  {
    "title": "Techniques for training large neural networks",
    "description": "Large neural networks are at the core of many recent advances in AI, but training them is a difficult engineering and research challenge which requires orchestrating a cluster of GPUs to perform a single synchronized calculation.",
    "summary": "Large neural networks are at the core of many recent advances in AI, but training them is a difficult engineering and research challenge which requires orchestrating a cluster of GPUs to perform a single synchronized calculation.",
    "pubDate": "Thu, 09 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/techniques-for-training-large-neural-networks",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SEMÁîªÂÉèËß£Êûê„Å®AIÊ¥ªÁî®„ÄÅË£ΩÈÄ†ÈÄî‰∏≠„ÅßÊÄßËÉΩ„Çí‰∫àÊ∏¨„ÄÄÊó•Á´ãË£Ω‰ΩúÊâÄ",
    "description": "Êó•Á´ãË£Ω‰ΩúÊâÄ„Å®Êó•Á´ã„Éè„Ç§„ÉÜ„ÇØ„ÅØ„ÄÅË£ΩÈÄ†„É©„Ç§„É≥„ÅÆÁ´ã„Å°‰∏ä„Åí„Å®Ê≠©Áïô„Åæ„ÇäÂêë‰∏ä„ÇíÊîØÊè¥„Åô„Çã„Äå„Éó„É≠„Çª„Çπ„Ç§„É≥„Éï„Ç©„Éû„ÉÜ„Ç£„ÇØ„ÇπÊäÄË°ì„Äç„ÇíÈñãÁô∫„Åó„Åü„ÄÇ„É™„ÉÅ„Ç¶„É†„Ç§„Ç™„É≥ÈõªÊ±†„ÅÆË©¶‰Ωú„É©„Ç§„É≥„Å´ÈñãÁô∫„Åó„ÅüÊäÄË°ì„ÇíÂ∞éÂÖ•„Åó„Å¶Ê§úË®º„Åó„Åü„Å®„Åì„Çç„ÄÅ‰∏≠ÈñìÂ∑•Á®ãÂìÅ„ÅÆÊÆµÈöé„Å´„Åä„ÅÑ„Å¶Ë£ΩÂìÅÊÄßËÉΩ„ÇíÈ´ò„ÅÑÁ≤æÂ∫¶„Åß‰∫àÊ∏¨„Åô„Çã„Åì„Å®„Å´ÊàêÂäü„Åó„Åü„ÄÇ",
    "summary": "Êó•Á´ãË£Ω‰ΩúÊâÄ„Å®Êó•Á´ã„Éè„Ç§„ÉÜ„ÇØ„ÅØ„ÄÅË£ΩÈÄ†„É©„Ç§„É≥„ÅÆÁ´ã„Å°‰∏ä„Åí„Å®Ê≠©Áïô„Åæ„ÇäÂêë‰∏ä„ÇíÊîØÊè¥„Åô„Çã„Äå„Éó„É≠„Çª„Çπ„Ç§„É≥„Éï„Ç©„Éû„ÉÜ„Ç£„ÇØ„ÇπÊäÄË°ì„Äç„ÇíÈñãÁô∫„Åó„Åü„ÄÇ„É™„ÉÅ„Ç¶„É†„Ç§„Ç™„É≥ÈõªÊ±†„ÅÆË©¶‰Ωú„É©„Ç§„É≥„Å´ÈñãÁô∫„Åó„ÅüÊäÄË°ì„ÇíÂ∞éÂÖ•„Åó„Å¶Ê§úË®º„Åó„Åü„Å®„Åì„Çç„ÄÅ‰∏≠ÈñìÂ∑•Á®ãÂìÅ„ÅÆÊÆµÈöé„Å´„Åä„ÅÑ„Å¶Ë£ΩÂìÅÊÄßËÉΩ„ÇíÈ´ò„ÅÑÁ≤æÂ∫¶„Åß‰∫àÊ∏¨„Åô„Çã„Åì„Å®„Å´ÊàêÂäü„Åó„Åü„ÄÇ",
    "pubDate": "Tue, 01 Jul 2025 13:30:00 +0900",
    "source": "ITmedia AI",
    "url": "https://eetimes.itmedia.co.jp/ee/articles/2507/01/news037.html",
    "thumbnail": "https://image.itmedia.co.jp/ee/articles/2507/01/cover_news037.jpg"
  },
  {
    "title": "Ask a Techspert: What is inference?",
    "description": "Illustration of a computer chip surrounded by elements representing AI and data, including a cat's head, a wireframe cat, puzzle pieces, a bar graph, gears, and text bubbles.",
    "summary": "Illustration of a computer chip surrounded by elements representing AI and data, including a cat's head, a wireframe cat, puzzle pieces, a bar graph, gears, and text bubbles.",
    "pubDate": "Mon, 23 Jun 2025 17:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/ask-a-techspert-what-is-inference/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/InferenceHero_v3.width-1300.png"
  },
  {
    "title": "Scaling laws for neural language models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 23 Jan 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-laws-for-neural-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Glow: Better reversible generative models",
    "description": "We introduce¬†Glow, a reversible generative model which uses invertible 1x1 convolutions. It extends¬†previous¬†work¬†on reversible generative models and simplifies the architecture. Our model can generate realistic high resolution images, supports efficient sampling, and discovers features that can be used to manipulate attributes of data. We‚Äôre releasing code for the model and an online visualization tool so people can explore and build on these¬†results.",
    "summary": "We introduce¬†Glow, a reversible generative model which uses invertible 1x1 convolutions. It extends¬†previous¬†work¬†on reversible generative models and simplifies the architecture. Our model can generate realistic high resolution images, supports efficient sampling, and discovers features that can be used to manipulate attributes of data. We‚Äôre releasing code for the model and an online visualization tool so people can explore and build on these¬†results.",
    "pubDate": "Mon, 09 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/glow",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs",
    "description": "arXiv:2506.23423v1 Announce Type: cross Abstract: Past work has studied the effects of fine-tuning on large language models' (LLMs) overall performance on certain tasks. However, a quantitative and systematic method for analyzing its effect on individual outputs is still lacking. Here, we propose a new method for measuring the contribution that fine-tuning makes to individual LLM responses, assuming access to the original pre-trained model. Our method tracks the model's intermediate hidden states, providing a more fine-grained insight into the effects of fine-tuning than a simple comparison of final outputs from pre-trained and fine-tuned models. We introduce and theoretically analyze an exact decomposition of any fine-tuned LLM into a pre-training component and a fine-tuning component. Empirically, we find that model behavior and performance can be steered by up- or down-scaling the fine-tuning component during the forward pass. Motivated by this finding and our theoretical analysis, we define the Tuning Contribution (TuCo) as the ratio of the magnitudes of the fine-tuning component to the pre-training component. We observe that three prominent adversarial attacks on LLMs circumvent safety measures in a way that reduces TuCo, and that TuCo is consistently lower on prompts where these attacks succeed compared to those where they do not. This suggests that attenuating the effect of fine-tuning on model outputs plays a role in the success of such attacks. In summary, TuCo enables the quantitative study of how fine-tuning influences model behavior and safety, and vice versa.",
    "summary": "arXiv:2506.23423v1 Announce Type: cross Abstract: Past work has studied the effects of fine-tuning on large language models' (LLMs) overall performance on certain tasks. However, a quantitative and systematic method for analyzing its effect on individual outputs is still lacking. Here, we propose a new method for measuring the contribution that fine-tuning makes to individual LLM responses, assuming access to the original pre-trained model. Our method tracks the model's intermediate hidden states, providing a more fine-grained insight into the effects of fine-tuning than a simple comparison of final outputs from pre-trained and fine-tuned models. We introduce and theoretically analyze an exact decomposition of any fine-tuned LLM into a pre-training component and a fine-tuning component. Empirically, we find that model behavior and performance can be steered by up- or down-scaling the fine-tuning component during the forward pass. Motivated by this finding and our theoretical analysis, we define the Tuning Contribution (TuCo) as the ratio of the magnitudes of the fine-tuning component to the pre-training component. We observe that three prominent adversarial attacks on LLMs circumvent safety measures in a way that reduces TuCo, and that TuCo is consistently lower on prompts where these attacks succeed compared to those where they do not. This suggests that attenuating the effect of fine-tuning on model outputs plays a role in the success of such attacks. In summary, TuCo enables the quantitative study of how fine-tuning influences model behavior and safety, and vice versa.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23423",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Variational option discovery algorithms",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 26 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variational-option-discovery-algorithms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AMD + ü§ó: Large Language Models Out-of-the-Box Acceleration with AMD GPU",
    "description": "",
    "summary": "AMD + ü§ó: Large Language Models Out-of-the-Box Acceleration with AMD GPU Earlier this year, AMD and H...",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-optimum-amd",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference",
    "description": "arXiv:2506.23934v1 Announce Type: cross Abstract: As machine learning inferences increasingly move to edge devices, adapting to diverse computational capabilities, hardware, and memory constraints becomes more critical. Instead of relying on a pre-trained model fixed for all future inference queries across diverse edge devices, we argue that planning an inference pattern with a request-specific model tailored to the device's computational capacity, accuracy requirements, and time constraints is more cost-efficient and robust to diverse scenarios. To this end, we propose an accuracy-aware and workload-balanced inference system that integrates joint model quantization and inference partitioning. In this approach, the server dynamically responds to inference queries by sending a quantized model and adaptively sharing the inference workload with the device. Meanwhile, the device's computational power, channel capacity, and accuracy requirements are considered when deciding. Furthermore, we introduce a new optimization framework for the inference system, incorporating joint model quantization and partitioning. Our approach optimizes layer-wise quantization bit width and partition points to minimize time consumption and cost while accounting for varying accuracy requirements of tasks through an accuracy degradation metric in our optimization model. To our knowledge, this work represents the first exploration of optimizing quantization layer-wise bit-width in the inference serving system, by introducing theoretical measurement of accuracy degradation. Simulation results demonstrate a substantial reduction in overall time and power consumption, with computation payloads decreasing by over 80% and accuracy degradation kept below 1%.",
    "summary": "arXiv:2506.23934v1 Announce Type: cross Abstract: As machine learning inferences increasingly move to edge devices, adapting to diverse computational capabilities, hardware, and memory constraints becomes more critical. Instead of relying on a pre-trained model fixed for all future inference queries across diverse edge devices, we argue that planning an inference pattern with a request-specific model tailored to the device's computational capacity, accuracy requirements, and time constraints is more cost-efficient and robust to diverse scenarios. To this end, we propose an accuracy-aware and workload-balanced inference system that integrates joint model quantization and inference partitioning. In this approach, the server dynamically responds to inference queries by sending a quantized model and adaptively sharing the inference workload with the device. Meanwhile, the device's computational power, channel capacity, and accuracy requirements are considered when deciding. Furthermore, we introduce a new optimization framework for the inference system, incorporating joint model quantization and partitioning. Our approach optimizes layer-wise quantization bit width and partition points to minimize time consumption and cost while accounting for varying accuracy requirements of tasks through an accuracy degradation metric in our optimization model. To our knowledge, this work represents the first exploration of optimizing quantization layer-wise bit-width in the inference serving system, by introducing theoretical measurement of accuracy degradation. Simulation results demonstrate a substantial reduction in overall time and power consumption, with computation payloads decreasing by over 80% and accuracy degradation kept below 1%.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23934",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LangGraph CodeAct„ÇíE2B„ÅÆÂÆâÂÖ®„Å™‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åô",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØÂÖàÊó•LangChain„Åã„ÇâÁô∫Ë°®„Åï„Çå„ÅüLangGraph CodeAct„ÇíE2B„ÅÆ‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åó„Å¶„Åø„Çà„ÅÜ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇCodeAct„ÅØÊúÄËøëÊ≥®ÁõÆ„ÇíÈõÜ„ÇÅ„Å¶„ÅÑ„ÇãAI Agent„ÅÆTool [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5652' rel='nofollow'>LangGraph CodeAct„ÇíE2B„ÅÆÂÆâÂÖ®„Å™‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åô</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØÂÖàÊó•LangChain„Åã„ÇâÁô∫Ë°®„Åï„Çå„ÅüLangGraph CodeAct„ÇíE2B„ÅÆ‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åó„Å¶„Åø„Çà„ÅÜ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇCodeAct„ÅØÊúÄËøëÊ≥®ÁõÆ„ÇíÈõÜ„ÇÅ„Å¶„ÅÑ„ÇãAI Agent„ÅÆTool [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5652' rel='nofollow'>LangGraph CodeAct„ÇíE2B„ÅÆÂÆâÂÖ®„Å™‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åô</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Thu, 17 Apr 2025 01:11:36 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5652",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "Deploy LLMs with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Deploy LLMs with Hugging Face Inference Endpoints Open-source LLMs like Falcon, (Open-)LLaMA, X-Gen,...",
    "pubDate": "Tue, 04 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints-llm",
    "thumbnail": "https://huggingface.co/blog/assets/155_inference_endpoints_llm/thumbnail.jpg"
  },
  {
    "title": "SmolVLM Grows Smaller ‚Äì Introducing the 250M & 500M Models!",
    "description": "",
    "summary": "SmolVLM Grows Smaller ‚Äì Introducing the 250M & 500M Models! TLDR We‚Äôre excited to announce two new a...",
    "pubDate": "Thu, 23 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolervlm",
    "thumbnail": "https://huggingface.co/blog/assets/smolervlm/banner.png"
  },
  {
    "title": "How we're supporting better tropical cyclone prediction with AI",
    "description": "We‚Äôre launching Weather Lab, featuring our experimental cyclone predictions, and we‚Äôre partnering with the U.S. National Hurricane Center to support their forecasts and warnings this cyclone season.",
    "summary": "We‚Äôre launching Weather Lab, featuring our experimental cyclone predictions, and we‚Äôre partnering with the U.S. National Hurricane Center to support their forecasts and warnings this cyclone season.",
    "pubDate": "Thu, 12 Jun 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/weather-lab-cyclone-predictions-with-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/4emGMNrEdaydebppYDiyQMNhXtgUFr8VvrKhVItMHENrxeWmWO9yqhteSj2fe25lxkiZAu7vOZZcsXPDLg0O-LPSvk6CS1I8E2-GdjtoN_2ViJOY=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI‚Äôs comment to the NTIA on open model weights",
    "description": "OpenAI‚Äôs comment to the NTIA on open model weights This comment was submitted by OpenAI in response to NTIA‚Äôs March 2024 Request for Information on Dual-Use Foundation Models with Widely Available Weights.",
    "summary": "OpenAI‚Äôs comment to the NTIA on open model weights This comment was submitted by OpenAI in response to NTIA‚Äôs March 2024 Request for Information on Dual-Use Foundation Models with Widely Available Weights.",
    "pubDate": "Wed, 27 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-s-comment-to-the-ntia-on-open-model-weights",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Platform on the AWS Marketplace: Pay with your AWS Account",
    "description": "",
    "summary": "Hugging Face Hub on the AWS Marketplace: Pay with your AWS Account The Hugging Face Hub has landed o...",
    "pubDate": "Thu, 10 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aws-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/158_aws_marketplace/thumbnail.jpg"
  },
  {
    "title": "Faster Stable Diffusion with Core ML on iPhone, iPad, and Mac",
    "description": "",
    "summary": "Faster Stable Diffusion with Core ML on iPhone, iPad, and Mac WWDC‚Äô23 (Apple Worldwide Developers Co...",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-diffusers-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/149_fast_diffusers_coreml/thumbnail.png"
  },
  {
    "title": "Fine-tuning MMS Adapter Models for Multi-Lingual ASR",
    "description": "",
    "summary": "Fine-tuning MMS Adapter Models for Multi-Lingual ASR New (06/2023): This blog post is strongly inspi...",
    "pubDate": "Mon, 19 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mms_adapters",
    "thumbnail": "https://huggingface.co/blog/assets/151_mms/mms_map.png"
  },
  {
    "title": "Making AI-generated code more accurate in any language",
    "description": "A new technique automatically guides an LLM toward outputs that adhere to the rules of whatever programming language or other format is being used.",
    "summary": "A new technique automatically guides an LLM toward outputs that adhere to the rules of whatever programming language or other format is being used.",
    "pubDate": "Fri, 18 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/making-ai-generated-code-more-accurate-0418",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Probalistic-Control-compressed.gif"
  },
  {
    "title": "Introducing vision to the fine-tuning API",
    "description": "Developers can now fine-tune GPT-4o with images and text to improve vision capabilities",
    "summary": "Developers can now fine-tune GPT-4o with images and text to improve vision capabilities",
    "pubDate": "Tue, 01 Oct 2024 10:04:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-vision-to-the-fine-tuning-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-Tune Wav2Vec2 for English ASR with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune Wav2Vec2 for English ASR with ü§ó Transformers Wav2Vec2 is a pretrained model for Automatic ...",
    "pubDate": "Fri, 12 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-wav2vec2-english",
    "thumbnail": "https://huggingface.co/blog/assets/15_fine_tune_wav2vec2/wav2vec2.png"
  },
  {
    "title": "Evaluation of LLMs for mathematical problem solving",
    "description": "arXiv:2506.00309v3 Announce Type: replace Abstract: Large Language Models (LLMs) have shown impressive performance on a range of educational tasks, but are still understudied for their potential to solve mathematical problems. In this study, we compare three prominent LLMs, including GPT-4o, DeepSeek-V3, and Gemini-2.0, on three mathematics datasets of varying complexities (GSM8K, MATH500, and MIT Open Courseware datasets). We take a five-dimensional approach based on the Structured Chain-of-Thought (SCoT) framework to assess final answer correctness, step completeness, step validity, intermediate calculation accuracy, and problem comprehension. The results show that GPT-4o is the most stable and consistent in performance across all the datasets, but particularly it performs outstandingly in high-level questions of the MIT Open Courseware dataset. DeepSeek-V3 is competitively strong in well-structured domains such as optimisation, but suffers from fluctuations in accuracy in statistical inference tasks. Gemini-2.0 shows strong linguistic understanding and clarity in well-structured problems but performs poorly in multi-step reasoning and symbolic logic. Our error analysis reveals particular deficits in each model: GPT-4o is at times lacking in sufficient explanation or precision; DeepSeek-V3 leaves out intermediate steps; and Gemini-2.0 is less flexible in mathematical reasoning in higher dimensions.",
    "summary": "arXiv:2506.00309v3 Announce Type: replace Abstract: Large Language Models (LLMs) have shown impressive performance on a range of educational tasks, but are still understudied for their potential to solve mathematical problems. In this study, we compare three prominent LLMs, including GPT-4o, DeepSeek-V3, and Gemini-2.0, on three mathematics datasets of varying complexities (GSM8K, MATH500, and MIT Open Courseware datasets). We take a five-dimensional approach based on the Structured Chain-of-Thought (SCoT) framework to assess final answer correctness, step completeness, step validity, intermediate calculation accuracy, and problem comprehension. The results show that GPT-4o is the most stable and consistent in performance across all the datasets, but particularly it performs outstandingly in high-level questions of the MIT Open Courseware dataset. DeepSeek-V3 is competitively strong in well-structured domains such as optimisation, but suffers from fluctuations in accuracy in statistical inference tasks. Gemini-2.0 shows strong linguistic understanding and clarity in well-structured problems but performs poorly in multi-step reasoning and symbolic logic. Our error analysis reveals particular deficits in each model: GPT-4o is at times lacking in sufficient explanation or precision; DeepSeek-V3 leaves out intermediate steps; and Gemini-2.0 is less flexible in mathematical reasoning in higher dimensions.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.00309",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent",
    "description": "arXiv:2506.23485v1 Announce Type: cross Abstract: Interactive recommendation is a typical information-seeking task that allows users to interactively express their needs through natural language and obtain personalized recommendations. Large language model-powered (LLM-powered) agents have become a new paradigm in interactive recommendations, effectively capturing users' real-time needs and enhancing personalized experiences. However, due to limited planning and generalization capabilities, existing formulations of LLM-powered interactive recommender agents struggle to effectively address diverse and complex user intents, such as intuitive, unrefined, or occasionally ambiguous requests. To tackle this challenge, we propose a novel thought-augmented interactive recommender agent system (TAIRA) that addresses complex user intents through distilled thought patterns. Specifically, TAIRA is designed as an LLM-powered multi-agent system featuring a manager agent that orchestrates recommendation tasks by decomposing user needs and planning subtasks, with its planning capacity strengthened through Thought Pattern Distillation (TPD), a thought-augmentation method that extracts high-level thoughts from the agent's and human experts' experiences. Moreover, we designed a set of user simulation schemes to generate personalized queries of different difficulties and evaluate the recommendations based on specific datasets. Through comprehensive experiments conducted across multiple datasets, TAIRA exhibits significantly enhanced performance compared to existing methods. Notably, TAIRA shows a greater advantage on more challenging tasks while generalizing effectively on novel tasks, further validating its superiority in managing complex user intents within interactive recommendation systems. The code is publicly available at:https://github.com/Alcein/TAIRA.",
    "summary": "arXiv:2506.23485v1 Announce Type: cross Abstract: Interactive recommendation is a typical information-seeking task that allows users to interactively express their needs through natural language and obtain personalized recommendations. Large language model-powered (LLM-powered) agents have become a new paradigm in interactive recommendations, effectively capturing users' real-time needs and enhancing personalized experiences. However, due to limited planning and generalization capabilities, existing formulations of LLM-powered interactive recommender agents struggle to effectively address diverse and complex user intents, such as intuitive, unrefined, or occasionally ambiguous requests. To tackle this challenge, we propose a novel thought-augmented interactive recommender agent system (TAIRA) that addresses complex user intents through distilled thought patterns. Specifically, TAIRA is designed as an LLM-powered multi-agent system featuring a manager agent that orchestrates recommendation tasks by decomposing user needs and planning subtasks, with its planning capacity strengthened through Thought Pattern Distillation (TPD), a thought-augmentation method that extracts high-level thoughts from the agent's and human experts' experiences. Moreover, we designed a set of user simulation schemes to generate personalized queries of different difficulties and evaluate the recommendations based on specific datasets. Through comprehensive experiments conducted across multiple datasets, TAIRA exhibits significantly enhanced performance compared to existing methods. Notably, TAIRA shows a greater advantage on more challenging tasks while generalizing effectively on novel tasks, further validating its superiority in managing complex user intents within interactive recommendation systems. The code is publicly available at:https://github.com/Alcein/TAIRA.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23485",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Building an AI WebTV",
    "description": "",
    "summary": "Building an AI WebTV The AI WebTV is an experimental demo to showcase the latest advancements in aut...",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-webtv",
    "thumbnail": "https://huggingface.co/blog/assets/156_ai_webtv/thumbnail.gif"
  },
  {
    "title": "LaunchDarkly's approach to AI-powered product management",
    "description": "A conversation with Claire Vo, Chief Product Officer of LaunchDarkly, about the changing role of product managers, her anti-to-do list, and building AI-native teams.",
    "summary": "A conversation with Claire Vo, Chief Product Officer of LaunchDarkly, about the changing role of product managers, her anti-to-do list, and building AI-native teams.",
    "pubDate": "Tue, 04 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/launchdarkly-claire-vo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions",
    "description": "Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model's original instructions with their own malicious prompts.",
    "summary": "Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model's original instructions with their own malicious prompts.",
    "pubDate": "Fri, 19 Apr 2024 19:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-instruction-hierarchy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Universal Assisted Generation: Faster Decoding with Any Assistant Model",
    "description": "",
    "summary": "Universal Assisted Generation: Faster Decoding with Any Assistant Model TL;DR: Many LLMs such as gem...",
    "pubDate": "Tue, 29 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/universal_assisted_generation",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Faulty reward functions in the wild",
    "description": "Reinforcement learning algorithms can break in surprising, counterintuitive ways. In this post we‚Äôll explore one failure mode, which is where you misspecify your reward function.",
    "summary": "Reinforcement learning algorithms can break in surprising, counterintuitive ways. In this post we‚Äôll explore one failure mode, which is where you misspecify your reward function.",
    "pubDate": "Wed, 21 Dec 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/faulty-reward-functions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How to train a Language Model with Megatron-LM",
    "description": "",
    "summary": "How to train a Language Model with Megatron-LM Training large language models in Pytorch requires mo...",
    "pubDate": "Wed, 07 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/megatron-training",
    "thumbnail": "https://huggingface.co/blog/assets/100_megatron_training/thumbnail.png"
  },
  {
    "title": "Summarizing books with human feedback",
    "description": "Scaling human oversight of AI systems for tasks that are difficult to¬†evaluate.",
    "summary": "Scaling human oversight of AI systems for tasks that are difficult to¬†evaluate.",
    "pubDate": "Thu, 23 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/summarizing-books",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-3 powers the next generation of apps",
    "description": "Over 300 applications are delivering GPT-3‚Äìpowered search, conversation, text completion, and other advanced AI features through our¬†API.",
    "summary": "Over 300 applications are delivering GPT-3‚Äìpowered search, conversation, text completion, and other advanced AI features through our¬†API.",
    "pubDate": "Thu, 25 Mar 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-apps",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerated Inference with Optimum and Transformers Pipelines",
    "description": "",
    "summary": "Accelerated Inference with Optimum and Transformers Pipelines Inference has landed in Optimum with s...",
    "pubDate": "Tue, 10 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-inference",
    "thumbnail": "https://huggingface.co/blog/assets/66_optimum_inference/thumbnail.png"
  },
  {
    "title": "Emotional RAG LLMs: Reading Comprehension for the Open Internet",
    "description": "arXiv:2408.11189v2 Announce Type: replace-cross Abstract: Queries to large language models (LLMs) can be divided into two parts: the instruction/question and the accompanying context. The context for retrieval-augmented generation (RAG) systems in most benchmarks comes from Wikipedia-like texts written in a neutral and factual tone. However, real-world RAG applications often retrieve internet-based text with diverse tones and linguistic styles, posing challenges for downstream tasks. This paper introduces (a) a dataset that transforms RAG-retrieved passages into emotionally inflected and sarcastic text, (b) an emotion translation model for adapting text to different tones, and (c) a prompt-based method to improve LLMs' pragmatic interpretation of retrieved text.",
    "summary": "arXiv:2408.11189v2 Announce Type: replace-cross Abstract: Queries to large language models (LLMs) can be divided into two parts: the instruction/question and the accompanying context. The context for retrieval-augmented generation (RAG) systems in most benchmarks comes from Wikipedia-like texts written in a neutral and factual tone. However, real-world RAG applications often retrieve internet-based text with diverse tones and linguistic styles, posing challenges for downstream tasks. This paper introduces (a) a dataset that transforms RAG-retrieved passages into emotionally inflected and sarcastic text, (b) an emotion translation model for adapting text to different tones, and (c) a prompt-based method to improve LLMs' pragmatic interpretation of retrieved text.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.11189",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "1 Billion Classifications",
    "description": "",
    "summary": "1 Billion Classifications You‚Äôve optimized your model. Your pipeline is running smoothly. But now, y...",
    "pubDate": "Thu, 13 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/billion-classifications",
    "thumbnail": "https://huggingface.co/blog/assets/billion-classifications/billion-classifications-thumbnail.png"
  },
  {
    "title": "Few-shot learning in practice: GPT-NEO and the ü§ó Accelerated Inference API",
    "description": "",
    "summary": "Few-shot learning in practice: GPT-Neo and the ü§ó Accelerated Inference API In many Machine Learning ...",
    "pubDate": "Thu, 03 Jun 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Scalable Dynamic Origin-Destination Demand Estimation Enhanced by High-Resolution Satellite Imagery Data",
    "description": "arXiv:2506.22499v1 Announce Type: cross Abstract: This study presents a novel integrated framework for dynamic origin-destination demand estimation (DODE) in multi-class mesoscopic network models, leveraging high-resolution satellite imagery together with conventional traffic data from local sensors. Unlike sparse local detectors, satellite imagery offers consistent, city-wide road and traffic information of both parking and moving vehicles, overcoming data availability limitations. To extract information from imagery data, we design a computer vision pipeline for class-specific vehicle detection and map matching, generating link-level traffic density observations by vehicle class. Building upon this information, we formulate a computational graph-based DODE model that calibrates dynamic network states by jointly matching observed traffic counts and travel times from local sensors with density measurements derived from satellite imagery. To assess the accuracy and scalability of the proposed framework, we conduct a series of numerical experiments using both synthetic and real-world data. The results of out-of-sample tests demonstrate that supplementing traditional data with satellite-derived density significantly improves estimation performance, especially for links without local sensors. Real-world experiments also confirm the framework's capability to handle large-scale networks, supporting its potential for practical deployment in cities of varying sizes. Sensitivity analysis further evaluates the impact of data quality related to satellite imagery data.",
    "summary": "arXiv:2506.22499v1 Announce Type: cross Abstract: This study presents a novel integrated framework for dynamic origin-destination demand estimation (DODE) in multi-class mesoscopic network models, leveraging high-resolution satellite imagery together with conventional traffic data from local sensors. Unlike sparse local detectors, satellite imagery offers consistent, city-wide road and traffic information of both parking and moving vehicles, overcoming data availability limitations. To extract information from imagery data, we design a computer vision pipeline for class-specific vehicle detection and map matching, generating link-level traffic density observations by vehicle class. Building upon this information, we formulate a computational graph-based DODE model that calibrates dynamic network states by jointly matching observed traffic counts and travel times from local sensors with density measurements derived from satellite imagery. To assess the accuracy and scalability of the proposed framework, we conduct a series of numerical experiments using both synthetic and real-world data. The results of out-of-sample tests demonstrate that supplementing traditional data with satellite-derived density significantly improves estimation performance, especially for links without local sensors. Real-world experiments also confirm the framework's capability to handle large-scale networks, supporting its potential for practical deployment in cities of varying sizes. Sensitivity analysis further evaluates the impact of data quality related to satellite imagery data.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22499",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Refine-POI: Reinforcement Fine-Tuned Large Language Models for Next Point-of-Interest Recommendation",
    "description": "arXiv:2506.21599v2 Announce Type: replace-cross Abstract: Large language models (LLMs) have been adopted for next point-of-interest (POI) recommendation tasks. Typical LLM-based recommenders fall into two categories: prompt-based and supervised fine-tuning (SFT)-based models. Prompt-based models generally offer greater output flexibility but deliver lower accuracy, whereas SFT-based models achieve higher performance yet face a fundamental mismatch: next POI recommendation data does not naturally suit supervised fine-tuning. In SFT, the model is trained to reproduce the exact ground truth, but each training example provides only a single target POI, so there is no ground truth for producing a top-k list. To address this, we propose Refine-POI, a reinforcement fine-tuning framework for next POI recommendation. We introduce recommendation-driven rewards that enable LLMs to learn to generate top-k recommendation lists using only one ground-truth POI per example. Experiments on real-world datasets demonstrate that Refine-POI achieves state-of-the-art top-k recommendation performance.",
    "summary": "arXiv:2506.21599v2 Announce Type: replace-cross Abstract: Large language models (LLMs) have been adopted for next point-of-interest (POI) recommendation tasks. Typical LLM-based recommenders fall into two categories: prompt-based and supervised fine-tuning (SFT)-based models. Prompt-based models generally offer greater output flexibility but deliver lower accuracy, whereas SFT-based models achieve higher performance yet face a fundamental mismatch: next POI recommendation data does not naturally suit supervised fine-tuning. In SFT, the model is trained to reproduce the exact ground truth, but each training example provides only a single target POI, so there is no ground truth for producing a top-k list. To address this, we propose Refine-POI, a reinforcement fine-tuning framework for next POI recommendation. We introduce recommendation-driven rewards that enable LLMs to learn to generate top-k recommendation lists using only one ground-truth POI per example. Experiments on real-world datasets demonstrate that Refine-POI achieves state-of-the-art top-k recommendation performance.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21599",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemini 2.0 is now available to everyone",
    "description": "We‚Äôre announcing new updates to Gemini 2.0 Flash, plus introducing Gemini 2.0 Flash-Lite and Gemini 2.0 Pro Experimental.",
    "summary": "We‚Äôre announcing new updates to Gemini 2.0 Flash, plus introducing Gemini 2.0 Flash-Lite and Gemini 2.0 Pro Experimental.",
    "pubDate": "Wed, 05 Feb 2025 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-2-0-is-now-available-to-everyone/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini_28.01.25_keyword_social.width-1300.png"
  },
  {
    "title": "Semantic-guided Diverse Decoding for Large Language Model",
    "description": "arXiv:2506.23601v1 Announce Type: cross Abstract: Diverse decoding of large language models is crucial for applications requiring multiple semantically distinct responses, yet existing methods primarily achieve lexical rather than semantic diversity. This limitation significantly constrains Best-of-N strategies, group-based reinforcement learning, and data synthesis. While temperature sampling and diverse beam search modify token distributions or apply n-gram penalties, they fail to ensure meaningful semantic differentiation. We introduce Semantic-guided Diverse Decoding (SemDiD), operating directly in embedding space that balances quality with diversity through three complementary mechanisms: orthogonal directional guidance, dynamic inter-group repulsion, and position-debiased probability assessment. SemDiD harmonizes these competing objectives using adaptive gain functions and constraint optimization, ensuring both quality thresholds and maximal semantic differentiation. Experiments show SemDiD consistently outperforms existing methods, improving Best-of-N coverage by 1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15% while increasing accuracy by up to 2.1%.",
    "summary": "arXiv:2506.23601v1 Announce Type: cross Abstract: Diverse decoding of large language models is crucial for applications requiring multiple semantically distinct responses, yet existing methods primarily achieve lexical rather than semantic diversity. This limitation significantly constrains Best-of-N strategies, group-based reinforcement learning, and data synthesis. While temperature sampling and diverse beam search modify token distributions or apply n-gram penalties, they fail to ensure meaningful semantic differentiation. We introduce Semantic-guided Diverse Decoding (SemDiD), operating directly in embedding space that balances quality with diversity through three complementary mechanisms: orthogonal directional guidance, dynamic inter-group repulsion, and position-debiased probability assessment. SemDiD harmonizes these competing objectives using adaptive gain functions and constraint optimization, ensuring both quality thresholds and maximal semantic differentiation. Experiments show SemDiD consistently outperforms existing methods, improving Best-of-N coverage by 1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15% while increasing accuracy by up to 2.1%.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23601",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Content and Product Partnership with Vox Media",
    "description": "In a multi-faceted agreement, Vox Media‚Äôs content will enhance the output of OpenAI‚Äôs ChatGPT, and the company will build on OpenAI‚Äôs technology to develop products to better serve its audiences and advertisers.",
    "summary": "In a multi-faceted agreement, Vox Media‚Äôs content will enhance the output of OpenAI‚Äôs ChatGPT, and the company will build on OpenAI‚Äôs technology to develop products to better serve its audiences and advertisers.",
    "pubDate": "Wed, 29 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-content-and-product-partnership-with-vox-media",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building a Playlist Generator with Sentence Transformers",
    "description": "",
    "summary": "Building a Playlist Generator with Sentence Transformers A short while ago I published a playlist ge...",
    "pubDate": "Wed, 13 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/playlist-generator",
    "thumbnail": "https://huggingface.co/blog/assets/87_playlist_generator/thumbnail.png"
  },
  {
    "title": "Announcing Google DeepMind",
    "description": "DeepMind and the Brain team from Google Research will join forces to accelerate progress towards a world in which AI helps solve the biggest challenges facing humanity.",
    "summary": "DeepMind and the Brain team from Google Research will join forces to accelerate progress towards a world in which AI helps solve the biggest challenges facing humanity.",
    "pubDate": "Thu, 20 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/announcing-google-deepmind/",
    "thumbnail": "https://lh3.googleusercontent.com/MNdJdEO1VpepmU25h9OTpnMr9hxe6NScc1ZWlerWf5WtOYMnHETsPEWKqvG36zQv5CGflTOHAKG_JbADpmLrh8Mrpa91B95U6bs0isMSbTUerT-qT38=w1200-h630-n-nu"
  },
  {
    "title": "Introducing Skops",
    "description": "",
    "summary": "Introducing Skops Introducing Skops At Hugging Face, we are working on tackling various problems in ...",
    "pubDate": "Fri, 12 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/skops",
    "thumbnail": "https://huggingface.co/blog/assets/94_skops/introducing_skops.png"
  },
  {
    "title": "Announcing the Open Source AI Game Jam üéÆ",
    "description": "",
    "summary": "Announcing the Open Source AI Game Jam üéÆ Unleash Your Creativity with AI Tools and make a game in a ...",
    "pubDate": "Thu, 01 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/game-jam",
    "thumbnail": "https://huggingface.co/blog/assets/145_gamejam/thumbnail.png"
  },
  {
    "title": "New in ChatGPT for Business: March 2025",
    "description": "Join us as we share our latest releases and how ChatGPT is becoming more interactive, customized to the way your teams work, and agentic.",
    "summary": "Join us as we share our latest releases and how ChatGPT is becoming more interactive, customized to the way your teams work, and agentic.",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/new-in-chatgpt-for-work-march-updates-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generating Stories: AI for Game Development #5",
    "description": "",
    "summary": "Generating Stories: AI for Game Development #5 Welcome to AI for Game Development! In this series, w...",
    "pubDate": "Tue, 07 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-5",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail5.png"
  },
  {
    "title": "AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text",
    "description": "arXiv:2506.22508v1 Announce Type: cross Abstract: In today's digital world, casual user-generated content often contains subtle cues that may inadvertently expose sensitive personal attributes. Such risks underscore the growing importance of effective text anonymization to safeguard individual privacy. However, existing methods either rely on rigid replacements that damage utility or cloud-based LLMs that are costly and pose privacy risks. To address these issues, we explore the use of locally deployed smaller-scale language models (SLMs) for anonymization. Yet training effective SLMs remains challenging due to limited high-quality supervision. To address the challenge, we propose AgentStealth, a self-reinforcing LLM anonymization framework.First, we introduce an adversarial anonymization workflow enhanced by In-context Contrastive Learning and Adaptive Utility-Aware Control. Second, we perform supervised adaptation of SLMs using high-quality data collected from the workflow, which includes both anonymization and attack signals. Finally, we apply online reinforcement learning where the model leverages its internal adversarial feedback to iteratively improve anonymization performance. Experiments on two datasets show that our method outperforms baselines in both anonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight design supports direct deployment on edge devices, avoiding cloud reliance and communication-based privacy risks. Our code is open-source at https://github.com/tsinghua-fib-lab/AgentStealth.",
    "summary": "arXiv:2506.22508v1 Announce Type: cross Abstract: In today's digital world, casual user-generated content often contains subtle cues that may inadvertently expose sensitive personal attributes. Such risks underscore the growing importance of effective text anonymization to safeguard individual privacy. However, existing methods either rely on rigid replacements that damage utility or cloud-based LLMs that are costly and pose privacy risks. To address these issues, we explore the use of locally deployed smaller-scale language models (SLMs) for anonymization. Yet training effective SLMs remains challenging due to limited high-quality supervision. To address the challenge, we propose AgentStealth, a self-reinforcing LLM anonymization framework.First, we introduce an adversarial anonymization workflow enhanced by In-context Contrastive Learning and Adaptive Utility-Aware Control. Second, we perform supervised adaptation of SLMs using high-quality data collected from the workflow, which includes both anonymization and attack signals. Finally, we apply online reinforcement learning where the model leverages its internal adversarial feedback to iteratively improve anonymization performance. Experiments on two datasets show that our method outperforms baselines in both anonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight design supports direct deployment on edge devices, avoiding cloud reliance and communication-based privacy risks. Our code is open-source at https://github.com/tsinghua-fib-lab/AgentStealth.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22508",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Argilla 2.4: Easily Build Fine-Tuning and Evaluation datasets on the Hub ‚Äî No Code Required",
    "description": "",
    "summary": "Argilla 2.4: Easily Build Fine-Tuning and Evaluation Datasets on the Hub ‚Äî No Code Required We are i...",
    "pubDate": "Mon, 04 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/argilla-ui-hub",
    "thumbnail": "https://huggingface.co/blog/assets/argilla-ui-hub/thumbnail.png"
  },
  {
    "title": "Envisioning a future where health care tech leaves some behind",
    "description": "The winning essay of the Envisioning the Future of Computing Prize puts health care disparities at the forefront.",
    "summary": "The winning essay of the Envisioning the Future of Computing Prize puts health care disparities at the forefront.",
    "pubDate": "Mon, 09 Jun 2025 16:10:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/envisioning-future-where-health-care-tech-leaves-some-behind-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/Annaliese%20statue%20crop_v2.jpg"
  },
  {
    "title": "OpenAI en France",
    "description": "Our first office in continental Europe",
    "summary": "Our first office in continental Europe",
    "pubDate": "Fri, 15 Nov 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-en-france",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face on PyTorch / XLA TPUs",
    "description": "",
    "summary": "Hugging Face on PyTorch / XLA TPUs: Faster and cheaper training Training Your Favorite Transformers ...",
    "pubDate": "Tue, 09 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-xla",
    "thumbnail": "https://huggingface.co/blog/assets/13_pytorch_xla/pytorch_xla_thumbnail.png"
  },
  {
    "title": "OpenAI and Reddit Partnership",
    "description": "OpenAI and Reddit Partnership We‚Äôre bringing Reddit‚Äôs unique content to ChatGPT and our products.",
    "summary": "OpenAI and Reddit Partnership We‚Äôre bringing Reddit‚Äôs unique content to ChatGPT and our products.",
    "pubDate": "Thu, 16 May 2024 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-reddit-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face x LangChain : A new partner package in LangChain",
    "description": "",
    "summary": "Hugging Face x LangChain : A new partner package in LangChain We are thrilled to announce the launch...",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/langchain",
    "thumbnail": "https://huggingface.co/blog/assets/langchain_huggingface/thumbnail.png"
  },
  {
    "title": "Image GPT",
    "description": "We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image¬†completions¬†and¬†samples. By establishing a correlation between sample quality and image classification accuracy, we show that our best generative model also contains features competitive with top convolutional nets in the unsupervised¬†setting.",
    "summary": "We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image¬†completions¬†and¬†samples. By establishing a correlation between sample quality and image classification accuracy, we show that our best generative model also contains features competitive with top convolutional nets in the unsupervised¬†setting.",
    "pubDate": "Wed, 17 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/image-gpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our response to the UK‚Äôs copyright consultation",
    "description": "Recommendations for pro-innovation policies that can help make the UK the AI capital of Europe.",
    "summary": "Recommendations for pro-innovation policies that can help make the UK the AI capital of Europe.",
    "pubDate": "Wed, 02 Apr 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-uk-copyright-consultation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Towards Text-free Graph Foundation Models: Rethinking Multi-Domain Graph Contrastive Learning",
    "description": "arXiv:2506.22510v1 Announce Type: cross Abstract: Foundation models have achieved great success in natural language processing (NLP) and computer vision (CV). Their success largely stems from the ability to integrate multi-domain knowledge in pre-training and transfer it to target domains. Considering graph data, especially graphs without textual features, is ubiquitous in real-world applications such as social networks and recommendation systems, some researchers have attempted to extend this paradigm to the graph field, aiming to construct graph foundation models. However, unlike CV and NLP, there are huge gaps among the semantics and properties of graphs in different domains, while current works still adopt traditional contrastive pre-training strategies designed in the single-domain scenario, which regard contrastive samples from different domains as equivalent. From experimental investigations, we discovered that inherent domain-specific differences prevent these strategies from effectively absorbing knowledge from different domains to generate informative representations. In this paper, we propose a novel multi-domain pre-training and cross-domain transfer framework, namely MDGCL.In the pre-training stage, we design a contrastive learning strategy to substantially recognize and capture domain differences, and introduce domain tokens to encode domain-level global information. In the downstream stage, we introduce a domain attention mechanism to enable fine-grained domain knowledge transfer. Extensive experiments on five benchmark datasets have demonstrated that our method outperforms state-of-the-art significantly, with the maximum improvement of 19.33% on accuracy and 19.13% on Macro-F1 score.",
    "summary": "arXiv:2506.22510v1 Announce Type: cross Abstract: Foundation models have achieved great success in natural language processing (NLP) and computer vision (CV). Their success largely stems from the ability to integrate multi-domain knowledge in pre-training and transfer it to target domains. Considering graph data, especially graphs without textual features, is ubiquitous in real-world applications such as social networks and recommendation systems, some researchers have attempted to extend this paradigm to the graph field, aiming to construct graph foundation models. However, unlike CV and NLP, there are huge gaps among the semantics and properties of graphs in different domains, while current works still adopt traditional contrastive pre-training strategies designed in the single-domain scenario, which regard contrastive samples from different domains as equivalent. From experimental investigations, we discovered that inherent domain-specific differences prevent these strategies from effectively absorbing knowledge from different domains to generate informative representations. In this paper, we propose a novel multi-domain pre-training and cross-domain transfer framework, namely MDGCL.In the pre-training stage, we design a contrastive learning strategy to substantially recognize and capture domain differences, and introduce domain tokens to encode domain-level global information. In the downstream stage, we introduce a domain attention mechanism to enable fine-grained domain knowledge transfer. Extensive experiments on five benchmark datasets have demonstrated that our method outperforms state-of-the-art significantly, with the maximum improvement of 19.33% on accuracy and 19.13% on Macro-F1 score.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22510",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How to Install and Use the Hugging Face Unity API",
    "description": "",
    "summary": "How to Install and Use the Hugging Face Unity API The Hugging Face Unity API is an easy-to-use integ...",
    "pubDate": "Mon, 01 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-api",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-api-thumbnail.png"
  },
  {
    "title": "Transition Matching: Scalable and Flexible Generative Modeling",
    "description": "arXiv:2506.23589v1 Announce Type: cross Abstract: Diffusion and flow matching models have significantly advanced media generation, yet their design space is well-explored, somewhat limiting further improvements. Concurrently, autoregressive (AR) models, particularly those generating continuous tokens, have emerged as a promising direction for unifying text and media generation. This paper introduces Transition Matching (TM), a novel discrete-time, continuous-state generative paradigm that unifies and advances both diffusion/flow models and continuous AR generation. TM decomposes complex generation tasks into simpler Markov transitions, allowing for expressive non-deterministic probability transition kernels and arbitrary non-continuous supervision processes, thereby unlocking new flexible design avenues. We explore these choices through three TM variants: (i) Difference Transition Matching (DTM), which generalizes flow matching to discrete-time by directly learning transition probabilities, yielding state-of-the-art image quality and text adherence as well as improved sampling efficiency. (ii) Autoregressive Transition Matching (ARTM) and (iii) Full History Transition Matching (FHTM) are partially and fully causal models, respectively, that generalize continuous AR methods. They achieve continuous causal AR generation quality comparable to non-causal approaches and potentially enable seamless integration with existing AR text generation techniques. Notably, FHTM is the first fully causal model to match or surpass the performance of flow-based methods on text-to-image task in continuous domains. We demonstrate these contributions through a rigorous large-scale comparison of TM variants and relevant baselines, maintaining a fixed architecture, training data, and hyperparameters.",
    "summary": "arXiv:2506.23589v1 Announce Type: cross Abstract: Diffusion and flow matching models have significantly advanced media generation, yet their design space is well-explored, somewhat limiting further improvements. Concurrently, autoregressive (AR) models, particularly those generating continuous tokens, have emerged as a promising direction for unifying text and media generation. This paper introduces Transition Matching (TM), a novel discrete-time, continuous-state generative paradigm that unifies and advances both diffusion/flow models and continuous AR generation. TM decomposes complex generation tasks into simpler Markov transitions, allowing for expressive non-deterministic probability transition kernels and arbitrary non-continuous supervision processes, thereby unlocking new flexible design avenues. We explore these choices through three TM variants: (i) Difference Transition Matching (DTM), which generalizes flow matching to discrete-time by directly learning transition probabilities, yielding state-of-the-art image quality and text adherence as well as improved sampling efficiency. (ii) Autoregressive Transition Matching (ARTM) and (iii) Full History Transition Matching (FHTM) are partially and fully causal models, respectively, that generalize continuous AR methods. They achieve continuous causal AR generation quality comparable to non-causal approaches and potentially enable seamless integration with existing AR text generation techniques. Notably, FHTM is the first fully causal model to match or surpass the performance of flow-based methods on text-to-image task in continuous domains. We demonstrate these contributions through a rigorous large-scale comparison of TM variants and relevant baselines, maintaining a fixed architecture, training data, and hyperparameters.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23589",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study",
    "description": "arXiv:2506.23107v1 Announce Type: new Abstract: Large language models (LLMs) have made significant strides, extending their applications to dialogue systems, automated content creation, and domain-specific advisory tasks. However, as their use grows, concerns have emerged regarding their reliability in simulating complex decision-making behavior, such as risky decision-making, where a single choice can lead to multiple outcomes. This study investigates the ability of LLMs to simulate risky decision-making scenarios. We compare model-generated decisions with actual human responses in a series of lottery-based tasks, using transportation stated preference survey data from participants in Sydney, Dhaka, Hong Kong, and Nanjing. Demographic inputs were provided to two LLMs -- ChatGPT 4o and ChatGPT o1-mini -- which were tasked with predicting individual choices. Risk preferences were analyzed using the Constant Relative Risk Aversion (CRRA) framework. Results show that both models exhibit more risk-averse behavior than human participants, with o1-mini aligning more closely with observed human decisions. Further analysis of multilingual data from Nanjing and Hong Kong indicates that model predictions in Chinese deviate more from actual responses compared to English, suggesting that prompt language may influence simulation performance. These findings highlight both the promise and the current limitations of LLMs in replicating human-like risk behavior, particularly in linguistic and cultural settings.",
    "summary": "arXiv:2506.23107v1 Announce Type: new Abstract: Large language models (LLMs) have made significant strides, extending their applications to dialogue systems, automated content creation, and domain-specific advisory tasks. However, as their use grows, concerns have emerged regarding their reliability in simulating complex decision-making behavior, such as risky decision-making, where a single choice can lead to multiple outcomes. This study investigates the ability of LLMs to simulate risky decision-making scenarios. We compare model-generated decisions with actual human responses in a series of lottery-based tasks, using transportation stated preference survey data from participants in Sydney, Dhaka, Hong Kong, and Nanjing. Demographic inputs were provided to two LLMs -- ChatGPT 4o and ChatGPT o1-mini -- which were tasked with predicting individual choices. Risk preferences were analyzed using the Constant Relative Risk Aversion (CRRA) framework. Results show that both models exhibit more risk-averse behavior than human participants, with o1-mini aligning more closely with observed human decisions. Further analysis of multilingual data from Nanjing and Hong Kong indicates that model predictions in Chinese deviate more from actual responses compared to English, suggesting that prompt language may influence simulation performance. These findings highlight both the promise and the current limitations of LLMs in replicating human-like risk behavior, particularly in linguistic and cultural settings.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23107",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Harnessing AI Agents to Advance Research on Refugee Child Mental Health",
    "description": "arXiv:2506.23992v1 Announce Type: new Abstract: The international refugee crisis deepens, exposing millions of dis placed children to extreme psychological trauma. This research suggests a com pact, AI-based framework for processing unstructured refugee health data and distilling knowledge on child mental health. We compare two Retrieval-Aug mented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to determine how well they process challenging humanitarian datasets while avoid ing hallucination hazards. By combining cutting-edge AI methods with migration research and child psychology, this study presents a scalable strategy to assist policymakers, mental health practitioners, and humanitarian agencies to better assist displaced children and recognize their mental wellbeing. In total, both the models worked properly but significantly Deepseek R1 is superior to Zephyr with an accuracy of answer relevance 0.91",
    "summary": "arXiv:2506.23992v1 Announce Type: new Abstract: The international refugee crisis deepens, exposing millions of dis placed children to extreme psychological trauma. This research suggests a com pact, AI-based framework for processing unstructured refugee health data and distilling knowledge on child mental health. We compare two Retrieval-Aug mented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to determine how well they process challenging humanitarian datasets while avoid ing hallucination hazards. By combining cutting-edge AI methods with migration research and child psychology, this study presents a scalable strategy to assist policymakers, mental health practitioners, and humanitarian agencies to better assist displaced children and recognize their mental wellbeing. In total, both the models worked properly but significantly Deepseek R1 is superior to Zephyr with an accuracy of answer relevance 0.91",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23992",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robust adversarial inputs",
    "description": "We‚Äôve created images that reliably fool neural network classifiers when viewed from varied scales and perspectives. This challenges a claim from last week that self-driving cars would be hard to trick maliciously since they capture images from multiple scales, angles, perspectives, and the like.",
    "summary": "We‚Äôve created images that reliably fool neural network classifiers when viewed from varied scales and perspectives. This challenges a claim from last week that self-driving cars would be hard to trick maliciously since they capture images from multiple scales, angles, perspectives, and the like.",
    "pubDate": "Mon, 17 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/robust-adversarial-inputs",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Agents Are Here. What Now?",
    "description": "",
    "summary": "AI Agents Are Here. What Now? Introduction The sudden, rapid advancement of LLM capabilities ‚Äì such ...",
    "pubDate": "Mon, 13 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-7",
    "thumbnail": "https://huggingface.co/blog/assets/190_ethics-soc-7/thumbnail.png"
  },
  {
    "title": "AGI Enabled Solutions For IoX Layers Bottlenecks In Cyber-Physical-Social-Thinking Space",
    "description": "arXiv:2506.22487v1 Announce Type: cross Abstract: The integration of the Internet of Everything (IoX) and Artificial General Intelligence (AGI) has given rise to a transformative paradigm aimed at addressing critical bottlenecks across sensing, network, and application layers in Cyber-Physical-Social Thinking (CPST) ecosystems. In this survey, we provide a systematic and comprehensive review of AGI-enhanced IoX research, focusing on three key components: sensing-layer data management, network-layer protocol optimization, and application-layer decision-making frameworks. Specifically, this survey explores how AGI can mitigate IoX bottlenecks challenges by leveraging adaptive sensor fusion, edge preprocessing, and selective attention mechanisms at the sensing layer, while resolving network-layer issues such as protocol heterogeneity and dynamic spectrum management, neuro-symbolic reasoning, active inference, and causal reasoning, Furthermore, the survey examines AGI-enabled frameworks for managing identity and relationship explosion. Key findings suggest that AGI-driven strategies, such as adaptive sensor fusion, edge preprocessing, and semantic modeling, offer novel solutions to sensing-layer data overload, network-layer protocol heterogeneity, and application-layer identity explosion. The survey underscores the importance of cross-layer integration, quantum-enabled communication, and ethical governance frameworks for future AGI-enabled IoX systems. Finally, the survey identifies unresolved challenges, such as computational requirements, scalability, and real-world validation, calling for further research to fully realize AGI's potential in addressing IoX bottlenecks. we believe AGI-enhanced IoX is emerging as a critical research field at the intersection of interconnected systems and advanced AI.",
    "summary": "arXiv:2506.22487v1 Announce Type: cross Abstract: The integration of the Internet of Everything (IoX) and Artificial General Intelligence (AGI) has given rise to a transformative paradigm aimed at addressing critical bottlenecks across sensing, network, and application layers in Cyber-Physical-Social Thinking (CPST) ecosystems. In this survey, we provide a systematic and comprehensive review of AGI-enhanced IoX research, focusing on three key components: sensing-layer data management, network-layer protocol optimization, and application-layer decision-making frameworks. Specifically, this survey explores how AGI can mitigate IoX bottlenecks challenges by leveraging adaptive sensor fusion, edge preprocessing, and selective attention mechanisms at the sensing layer, while resolving network-layer issues such as protocol heterogeneity and dynamic spectrum management, neuro-symbolic reasoning, active inference, and causal reasoning, Furthermore, the survey examines AGI-enabled frameworks for managing identity and relationship explosion. Key findings suggest that AGI-driven strategies, such as adaptive sensor fusion, edge preprocessing, and semantic modeling, offer novel solutions to sensing-layer data overload, network-layer protocol heterogeneity, and application-layer identity explosion. The survey underscores the importance of cross-layer integration, quantum-enabled communication, and ethical governance frameworks for future AGI-enabled IoX systems. Finally, the survey identifies unresolved challenges, such as computational requirements, scalability, and real-world validation, calling for further research to fully realize AGI's potential in addressing IoX bottlenecks. we believe AGI-enhanced IoX is emerging as a critical research field at the intersection of interconnected systems and advanced AI.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22487",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BrowseComp: a benchmark for browsing agents",
    "description": "BrowseComp: a benchmark for browsing agents.",
    "summary": "BrowseComp: a benchmark for browsing agents.",
    "pubDate": "Thu, 10 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/browsecomp",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Towards Efficient and Accurate Spiking Neural Networks via Adaptive Bit Allocation",
    "description": "arXiv:2506.23717v1 Announce Type: cross Abstract: Multi-bit spiking neural networks (SNNs) have recently become a heated research spot, pursuing energy-efficient and high-accurate AI. However, with more bits involved, the associated memory and computation demands escalate to the point where the performance improvements become disproportionate. Based on the insight that different layers demonstrate different importance and extra bits could be wasted and interfering, this paper presents an adaptive bit allocation strategy for direct-trained SNNs, achieving fine-grained layer-wise allocation of memory and computation resources. Thus, SNN's efficiency and accuracy can be improved. Specifically, we parametrize the temporal lengths and the bit widths of weights and spikes, and make them learnable and controllable through gradients. To address the challenges caused by changeable bit widths and temporal lengths, we propose the refined spiking neuron, which can handle different temporal lengths, enable the derivation of gradients for temporal lengths, and suit spike quantization better. In addition, we theoretically formulate the step-size mismatch problem of learnable bit widths, which may incur severe quantization errors to SNN, and accordingly propose the step-size renewal mechanism to alleviate this issue. Experiments on various datasets, including the static CIFAR and ImageNet and the dynamic CIFAR-DVS and DVS-GESTURE, demonstrate that our methods can reduce the overall memory and computation cost while achieving higher accuracy. Particularly, our SEWResNet-34 can achieve a 2.69% accuracy gain and 4.16$times$ lower bit budgets over the advanced baseline work on ImageNet. This work will be fully open-sourced.",
    "summary": "arXiv:2506.23717v1 Announce Type: cross Abstract: Multi-bit spiking neural networks (SNNs) have recently become a heated research spot, pursuing energy-efficient and high-accurate AI. However, with more bits involved, the associated memory and computation demands escalate to the point where the performance improvements become disproportionate. Based on the insight that different layers demonstrate different importance and extra bits could be wasted and interfering, this paper presents an adaptive bit allocation strategy for direct-trained SNNs, achieving fine-grained layer-wise allocation of memory and computation resources. Thus, SNN's efficiency and accuracy can be improved. Specifically, we parametrize the temporal lengths and the bit widths of weights and spikes, and make them learnable and controllable through gradients. To address the challenges caused by changeable bit widths and temporal lengths, we propose the refined spiking neuron, which can handle different temporal lengths, enable the derivation of gradients for temporal lengths, and suit spike quantization better. In addition, we theoretically formulate the step-size mismatch problem of learnable bit widths, which may incur severe quantization errors to SNN, and accordingly propose the step-size renewal mechanism to alleviate this issue. Experiments on various datasets, including the static CIFAR and ImageNet and the dynamic CIFAR-DVS and DVS-GESTURE, demonstrate that our methods can reduce the overall memory and computation cost while achieving higher accuracy. Particularly, our SEWResNet-34 can achieve a 2.69% accuracy gain and 4.16$times$ lower bit budgets over the advanced baseline work on ImageNet. This work will be fully open-sourced.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23717",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Getting Started With Embeddings",
    "description": "",
    "summary": "Getting Started With Embeddings Check out this tutorial with the Notebook Companion: Understanding e...",
    "pubDate": "Thu, 23 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/getting-started-with-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/80_getting_started_with_embeddings/thumbnail.png"
  },
  {
    "title": "Exploring institutions for global AI governance",
    "description": "New white paper investigates models and functions of international institutions that could help manage opportunities and mitigate risks of advanced AI.",
    "summary": "New white paper investigates models and functions of international institutions that could help manage opportunities and mitigate risks of advanced AI.",
    "pubDate": "Tue, 11 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/exploring-institutions-for-global-ai-governance/",
    "thumbnail": "https://lh3.googleusercontent.com/Y9dCJWt3ky1gjizSCHb17S3iHZ_Q2v6hoC8SaBgq9f7e5yW15pzg7BGNoCIaklP6f34uioxwHY0gbzehAMe5HhXBvBBKBKNIcOo7ugjFeLENTWMqNQ=w1200-h630-n-nu"
  },
  {
    "title": "S^3cMath: Spontaneous Step-level Self-correction Makes Large Language Models Better Mathematical Reasoners",
    "description": "arXiv:2409.01524v3 Announce Type: replace-cross Abstract: Self-correction is a novel method that can stimulate the potential reasoning abilities of large language models (LLMs). It involves detecting and correcting errors during the inference process when LLMs solve reasoning problems. However, recent works do not regard self-correction as a spontaneous and intrinsic capability of LLMs. Instead, such correction is achieved through post-hoc generation, external knowledge introduction, multi-model collaboration, and similar techniques. In this paper, we propose a series of mathematical LLMs called S$^3$c-Math, which are able to perform Spontaneous Step-level Self-correction for Mathematical reasoning. This capability helps LLMs to recognize whether their ongoing inference tends to contain errors and simultaneously correct these errors to produce a more reliable response. We proposed a method, which employs a step-level sampling approach to construct step-wise self-correction data for achieving such ability. Additionally, we implement a training strategy that uses above constructed data to equip LLMs with spontaneous step-level self-correction capacities. Our data and methods have been demonstrated to be effective across various foundation LLMs, consistently showing significant progress in evaluations on GSM8K, MATH, and other mathematical benchmarks. To the best of our knowledge, we are the first to introduce the spontaneous step-level self-correction ability of LLMs in mathematical reasoning.",
    "summary": "arXiv:2409.01524v3 Announce Type: replace-cross Abstract: Self-correction is a novel method that can stimulate the potential reasoning abilities of large language models (LLMs). It involves detecting and correcting errors during the inference process when LLMs solve reasoning problems. However, recent works do not regard self-correction as a spontaneous and intrinsic capability of LLMs. Instead, such correction is achieved through post-hoc generation, external knowledge introduction, multi-model collaboration, and similar techniques. In this paper, we propose a series of mathematical LLMs called S$^3$c-Math, which are able to perform Spontaneous Step-level Self-correction for Mathematical reasoning. This capability helps LLMs to recognize whether their ongoing inference tends to contain errors and simultaneously correct these errors to produce a more reliable response. We proposed a method, which employs a step-level sampling approach to construct step-wise self-correction data for achieving such ability. Additionally, we implement a training strategy that uses above constructed data to equip LLMs with spontaneous step-level self-correction capacities. Our data and methods have been demonstrated to be effective across various foundation LLMs, consistently showing significant progress in evaluations on GSM8K, MATH, and other mathematical benchmarks. To the best of our knowledge, we are the first to introduce the spontaneous step-level self-correction ability of LLMs in mathematical reasoning.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.01524",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Transfer from simulation to real world through learning deep inverse dynamics model",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 11 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/transfer-from-simulation-to-real-world-through-learning-deep-inverse-dynamics-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "KAG-Thinker: Interactive Thinking and Deep Reasoning in LLMs via Knowledge-Augmented Generation",
    "description": "arXiv:2506.17728v3 Announce Type: replace-cross Abstract: In this paper, we introduce KAG-Thinker, which upgrade KAG to a multi-turn interactive thinking and deep reasoning framework powered by a dedicated parameter-light large language model (LLM). Our approach constructs a structured thinking process for solving complex problems, enhancing the the logical coherence and contextual consistency of the reasoning process in question-answering (Q&amp;A) tasks on domain-specific knowledge bases (KBs) within LLMs. Following the textbf{Logical Form} guided retrieval and reasoning technology route of KAG, this framework first decomposes complex questions into independently solvable sub-problems (which are also referred to as logical forms) through textbf{breadth decomposition}. Each such logical form is represented in two equivalent forms-natural language and logical function-and subsequently classified as either a Knowledge Retrieval or Reasoning Analysis task. Dependencies and parameter passing between these tasks are explicitly modeled via logical function interfaces. In the solving process, the Retrieval function performs retrieval tasks. It retrieves one-hop structured and unstructured information of specified knowledge unit. While the Math and Deduce functions are used to perform reasoning analysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval sub-problem tasks, LLMs and external knowledge sources are regarded as equivalent KBs. We use the textbf{knowledge boundary} module to determine the optimal source using self-regulatory mechanisms such as confidence calibration and reflective reasoning, and use the textbf{depth solving} module to enhance the comprehensiveness of knowledge acquisition...",
    "summary": "arXiv:2506.17728v3 Announce Type: replace-cross Abstract: In this paper, we introduce KAG-Thinker, which upgrade KAG to a multi-turn interactive thinking and deep reasoning framework powered by a dedicated parameter-light large language model (LLM). Our approach constructs a structured thinking process for solving complex problems, enhancing the the logical coherence and contextual consistency of the reasoning process in question-answering (Q&amp;A) tasks on domain-specific knowledge bases (KBs) within LLMs. Following the textbf{Logical Form} guided retrieval and reasoning technology route of KAG, this framework first decomposes complex questions into independently solvable sub-problems (which are also referred to as logical forms) through textbf{breadth decomposition}. Each such logical form is represented in two equivalent forms-natural language and logical function-and subsequently classified as either a Knowledge Retrieval or Reasoning Analysis task. Dependencies and parameter passing between these tasks are explicitly modeled via logical function interfaces. In the solving process, the Retrieval function performs retrieval tasks. It retrieves one-hop structured and unstructured information of specified knowledge unit. While the Math and Deduce functions are used to perform reasoning analysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval sub-problem tasks, LLMs and external knowledge sources are regarded as equivalent KBs. We use the textbf{knowledge boundary} module to determine the optimal source using self-regulatory mechanisms such as confidence calibration and reflective reasoning, and use the textbf{depth solving} module to enhance the comprehensiveness of knowledge acquisition...",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17728",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Empowering a global org with ChatGPT",
    "description": "Empowering a global org with ChatGPT",
    "summary": "Empowering a global org with ChatGPT",
    "pubDate": "Thu, 21 Nov 2024 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bbva",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ilya Sutskever to leave OpenAI, Jakub Pachocki announced as Chief Scientist",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 14 May 2024 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jakub-pachocki-announced-as-chief-scientist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "gMBA: Expression Semantic Guided Mixed Boolean-Arithmetic Deobfuscation Using Transformer Architectures",
    "description": "arXiv:2506.23634v1 Announce Type: cross Abstract: Mixed Boolean-Arithmetic (MBA) obfuscation protects intellectual property by converting programs into forms that are more complex to analyze. However, MBA has been increasingly exploited by malware developers to evade detection and cause significant real-world problems. Traditional MBA deobfuscation methods often consider these expressions as part of a black box and overlook their internal semantic information. To bridge this gap, we propose a truth table, which is an automatically constructed semantic representation of an expression's behavior that does not rely on external resources. The truth table is a mathematical form that represents the output of expression for all possible combinations of input. We also propose a general and extensible guided MBA deobfuscation framework (gMBA) that modifies a Transformer-based neural encoder-decoder Seq2Seq architecture to incorporate this semantic guidance. Experimental results and in-depth analysis show that integrating expression semantics significantly improves performance and highlights the importance of internal semantic expressions in recovering obfuscated code to its original form.",
    "summary": "arXiv:2506.23634v1 Announce Type: cross Abstract: Mixed Boolean-Arithmetic (MBA) obfuscation protects intellectual property by converting programs into forms that are more complex to analyze. However, MBA has been increasingly exploited by malware developers to evade detection and cause significant real-world problems. Traditional MBA deobfuscation methods often consider these expressions as part of a black box and overlook their internal semantic information. To bridge this gap, we propose a truth table, which is an automatically constructed semantic representation of an expression's behavior that does not rely on external resources. The truth table is a mathematical form that represents the output of expression for all possible combinations of input. We also propose a general and extensible guided MBA deobfuscation framework (gMBA) that modifies a Transformer-based neural encoder-decoder Seq2Seq architecture to incorporate this semantic guidance. Experimental results and in-depth analysis show that integrating expression semantics significantly improves performance and highlights the importance of internal semantic expressions in recovering obfuscated code to its original form.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23634",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Spread Your Wings: Falcon 180B is here",
    "description": "",
    "summary": "Spread Your Wings: Falcon 180B is here Introduction Today, we're excited to welcome TII's Falcon 180...",
    "pubDate": "Wed, 06 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon-180b",
    "thumbnail": "https://huggingface.co/blog/assets/162_falcon_180b/thumbnail.jpg"
  },
  {
    "title": "Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC",
    "description": "",
    "summary": "Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC We're e...",
    "pubDate": "Wed, 09 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastrtc-cloudflare",
    "thumbnail": "https://huggingface.co/blog/assets/fastrtc-cloudflare/fastrtc_cloudflare.png"
  },
  {
    "title": "Vall√©e Duhamel & Sora",
    "description": "Filmmaking duo Vall√©e Duhamel explains how Sora helps build new worlds.",
    "summary": "Filmmaking duo Vall√©e Duhamel explains how Sora helps build new worlds.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-vallee-duhamel",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Personal Copilot: Train Your Own Coding Assistant",
    "description": "",
    "summary": "Personal Copilot: Train Your Own Coding Assistant In the ever-evolving landscape of programming and ...",
    "pubDate": "Fri, 27 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/personal-copilot",
    "thumbnail": "https://huggingface.co/blog/assets/170_personal_copilot/thumbnail.png"
  },
  {
    "title": "Hugging Face and Graphcore partner for IPU-optimized Transformers",
    "description": "",
    "summary": "Hugging Face and Graphcore partner for IPU-optimized Transformers Speaking at the 2021 AI Hardware S...",
    "pubDate": "Tue, 14 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore",
    "thumbnail": "https://huggingface.co/blog/assets/26_graphcore-ipu/thumbnail.png"
  },
  {
    "title": "Letting Large Models Debate: The First Multilingual LLM Debate Competition",
    "description": "",
    "summary": "Letting Large Models Debate: The First Multilingual LLM Debate Competition Current static evaluation...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/debate",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Judge Arena: Benchmarking LLMs as Evaluators",
    "description": "",
    "summary": "Judge Arena: Benchmarking LLMs as Evaluators LLM-as-a-Judge has emerged as a popular way to grade na...",
    "pubDate": "Tue, 19 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-atla",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail_atla.png"
  },
  {
    "title": "Enhancing Live Broadcast Engagement: A Multi-modal Approach to Short Video Recommendations Using MMGCN and User Preferences",
    "description": "arXiv:2506.23085v1 Announce Type: cross Abstract: The purpose of this paper is to explore a multi-modal approach to enhancing live broadcast engagement by developing a short video recommendation system that incorporates Multi-modal Graph Convolutional Networks (MMGCN) with user preferences. In order to provide personalized recommendations tailored to individual interests, the proposed system takes into account user interaction data, video content features, and contextual information. With the aid of a hybrid approach combining collaborative filtering and content-based filtering techniques, the system is able to capture nuanced relationships between users, video attributes, and engagement patterns. Three datasets are used to evaluate the effectiveness of the system: Kwai, TikTok, and MovieLens. Compared to baseline models, such as DeepFM, Wide & Deep, LightGBM, and XGBoost, the proposed MMGCN-based model shows superior performance. A notable feature of the proposed model is that it outperforms all baseline methods in capturing diverse user preferences and making accurate, personalized recommendations, resulting in a Kwai F1 score of 0.574, a Tiktok F1 score of 0.506, and a MovieLens F1 score of 0.197. We emphasize the importance of multi-modal integration and user-centric approaches in advancing recommender systems, emphasizing the role they play in enhancing content discovery and audience interaction on live broadcast platforms.",
    "summary": "arXiv:2506.23085v1 Announce Type: cross Abstract: The purpose of this paper is to explore a multi-modal approach to enhancing live broadcast engagement by developing a short video recommendation system that incorporates Multi-modal Graph Convolutional Networks (MMGCN) with user preferences. In order to provide personalized recommendations tailored to individual interests, the proposed system takes into account user interaction data, video content features, and contextual information. With the aid of a hybrid approach combining collaborative filtering and content-based filtering techniques, the system is able to capture nuanced relationships between users, video attributes, and engagement patterns. Three datasets are used to evaluate the effectiveness of the system: Kwai, TikTok, and MovieLens. Compared to baseline models, such as DeepFM, Wide & Deep, LightGBM, and XGBoost, the proposed MMGCN-based model shows superior performance. A notable feature of the proposed model is that it outperforms all baseline methods in capturing diverse user preferences and making accurate, personalized recommendations, resulting in a Kwai F1 score of 0.574, a Tiktok F1 score of 0.506, and a MovieLens F1 score of 0.197. We emphasize the importance of multi-modal integration and user-centric approaches in advancing recommender systems, emphasizing the role they play in enhancing content discovery and audience interaction on live broadcast platforms.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23085",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Distributed Training: Train BART/T5 for Summarization using ü§ó Transformers and Amazon SageMaker",
    "description": "",
    "summary": "Distributed Training: Train BART/T5 for Summarization using ü§ó Transformers and Amazon SageMaker In c...",
    "pubDate": "Thu, 08 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-distributed-training-seq2seq",
    "thumbnail": "https://huggingface.co/blog/assets/19_sagemaker_distributed_training_seq2seq/thumbnail.png"
  },
  {
    "title": "New GPT-3 capabilities: Edit & insert",
    "description": "We‚Äôve released new versions of GPT-3 and Codex¬†which can edit or insert content into existing text, rather than just completing existing text.",
    "summary": "We‚Äôve released new versions of GPT-3 and Codex¬†which can edit or insert content into existing text, rather than just completing existing text.",
    "pubDate": "Tue, 15 Mar 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-edit-insert",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning sparse neural networks through L‚ÇÄ regularization",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 04 Dec 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-sparse-neural-networks-through-l0-regularization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome Stable-baselines3 to the Hugging Face Hub ü§ó",
    "description": "",
    "summary": "Welcome Stable-baselines3 to the Hugging Face Hub ü§ó At Hugging Face, we are contributing to the ecos...",
    "pubDate": "Fri, 21 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sb3",
    "thumbnail": "https://huggingface.co/blog/assets/47_sb3/thumbnail.png"
  },
  {
    "title": "Do Thinking Tokens Help or Trap? Towards More Efficient Large Reasoning Model",
    "description": "arXiv:2506.23840v1 Announce Type: cross Abstract: Large Reasoning Models (LRMs) excel at solving complex problems but face an overthinking dilemma. When handling simple tasks, they often produce verbose responses overloaded with thinking tokens (e.g., wait, however). These tokens trigger unnecessary high-level reasoning behaviors like reflection and backtracking, reducing efficiency. In this work, our pilot study reveals that these thinking-token-induced behaviors are not essential for effective problem-solving and may even hinder correct reasoning within constrained token budgets. We identify this phenomenon as the thinking trap. To mitigate this issue, we propose Dual Policy Preference Optimization (DuP-PO), a novel algorithm featuring: (1) A rollout sampling strategy that guarantees balanced exposure to responses with and without thinking tokens; (2) A fine-grained advantage control technique to dynamically regulate the prediction of target tokens; (3) A policy shaping method ensuring stable gradient contributions from thinking tokens. Experimental results on five popular math reasoning benchmarks show that DuP-PO performs well on the popular LRM, which significantly improves their token efficiency during reasoning, while achieving superior performance of the base model.",
    "summary": "arXiv:2506.23840v1 Announce Type: cross Abstract: Large Reasoning Models (LRMs) excel at solving complex problems but face an overthinking dilemma. When handling simple tasks, they often produce verbose responses overloaded with thinking tokens (e.g., wait, however). These tokens trigger unnecessary high-level reasoning behaviors like reflection and backtracking, reducing efficiency. In this work, our pilot study reveals that these thinking-token-induced behaviors are not essential for effective problem-solving and may even hinder correct reasoning within constrained token budgets. We identify this phenomenon as the thinking trap. To mitigate this issue, we propose Dual Policy Preference Optimization (DuP-PO), a novel algorithm featuring: (1) A rollout sampling strategy that guarantees balanced exposure to responses with and without thinking tokens; (2) A fine-grained advantage control technique to dynamically regulate the prediction of target tokens; (3) A policy shaping method ensuring stable gradient contributions from thinking tokens. Experimental results on five popular math reasoning benchmarks show that DuP-PO performs well on the popular LRM, which significantly improves their token efficiency during reasoning, while achieving superior performance of the base model.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23840",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Advanced audio dialog and generation with Gemini 2.5",
    "description": "Gemini 2.5 has new capabilities in AI-powered audio dialog and generation.",
    "summary": "Gemini 2.5 has new capabilities in AI-powered audio dialog and generation.",
    "pubDate": "Tue, 03 Jun 2025 17:15:47 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advanced-audio-dialog-and-generation-with-gemini-25/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/capability__native-audio_16-9_121.width-1300.jpg"
  },
  {
    "title": "Filling crucial language learning gaps",
    "description": "GPT-4 deepens the conversation on Duolingo.",
    "summary": "GPT-4 deepens the conversation on Duolingo.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/duolingo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2021: Final projects",
    "description": "We‚Äôre proud to announce that the 2021 class of¬†OpenAI Scholars¬†has completed our six-month mentorship program and have produced an open-source research project with stipends and support from¬†OpenAI.",
    "summary": "We‚Äôre proud to announce that the 2021 class of¬†OpenAI Scholars¬†has completed our six-month mentorship program and have produced an open-source research project with stipends and support from¬†OpenAI.",
    "pubDate": "Mon, 10 May 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2021-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New models and developer products announced at DevDay",
    "description": "GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL¬∑E 3 API, and more.",
    "summary": "GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL¬∑E 3 API, and more.",
    "pubDate": "Mon, 06 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-models-and-developer-products-announced-at-devday",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Problem of the Priors, or Posteriors?",
    "description": "arXiv:2503.10984v3 Announce Type: replace-cross Abstract: The problem of the priors is well known: it concerns the challenge of identifying norms that govern one's prior credences. I argue that a key to addressing this problem lies in considering what I call the problem of the posteriors -- the challenge of identifying norms that directly govern one's posterior credences, which backward induce some norms on the priors via the diachronic requirement of conditionalization. This forward-looking approach can be summarized as: Think ahead, work backward. Although this idea can be traced to Freedman (1963), Carnap (1963), and Shimony (1970), I believe that it has not received enough attention. In this paper, I initiate a systematic defense of forward-looking Bayesianism, addressing potential objections from more traditional views (both subjectivist and objectivist). I also develop a specific approach to forward-looking Bayesianism -- one that values the convergence of posterior credences to the truth, and treats it as a fundamental rather than derived norm. This approach, called convergentist Bayesianism, is argued to be crucial for a Bayesian foundation of Ockham's razor in statistics and machine learning.",
    "summary": "arXiv:2503.10984v3 Announce Type: replace-cross Abstract: The problem of the priors is well known: it concerns the challenge of identifying norms that govern one's prior credences. I argue that a key to addressing this problem lies in considering what I call the problem of the posteriors -- the challenge of identifying norms that directly govern one's posterior credences, which backward induce some norms on the priors via the diachronic requirement of conditionalization. This forward-looking approach can be summarized as: Think ahead, work backward. Although this idea can be traced to Freedman (1963), Carnap (1963), and Shimony (1970), I believe that it has not received enough attention. In this paper, I initiate a systematic defense of forward-looking Bayesianism, addressing potential objections from more traditional views (both subjectivist and objectivist). I also develop a specific approach to forward-looking Bayesianism -- one that values the convergence of posterior credences to the truth, and treats it as a fundamental rather than derived norm. This approach, called convergentist Bayesianism, is argued to be crucial for a Bayesian foundation of Ockham's razor in statistics and machine learning.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.10984",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing OpenAI London",
    "description": "We are excited to announce OpenAI‚Äôs first international expansion with a new office in London, United Kingdom.",
    "summary": "We are excited to announce OpenAI‚Äôs first international expansion with a new office in London, United Kingdom.",
    "pubDate": "Wed, 28 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-london",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fetch Cuts ML Processing Latency by 50% Using Amazon SageMaker & Hugging Face",
    "description": "",
    "summary": "Fetch Cuts ML Processing Latency by 50% Using Amazon SageMaker & Hugging Face This article is a cros...",
    "pubDate": "Fri, 01 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fetch-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/fetch.png"
  },
  {
    "title": "Empowering the next generation for an AI-enabled world",
    "description": "Experience AI's course and resources are expanding on a global scale",
    "summary": "Experience AI's course and resources are expanding on a global scale",
    "pubDate": "Wed, 15 Nov 2023 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/empowering-the-next-generation-for-an-ai-enabled-world/",
    "thumbnail": "https://lh3.googleusercontent.com/XJ10IR5bv5MmygxoFC0hrepTZtjq_Bwz69bL7d7jBy06fnEFodAa0tbIWKOwV7gW2Im3JY2GGda-xZKtVQhqcaozz6r_vdHXsgVu0CzyIhIz4VGs=w1200-h630-n-nu"
  },
  {
    "title": "Evolving OpenAI‚Äôs structure",
    "description": "An update from the OpenAI board on transitioning its for-profit entity to a Public Benefit Corporation, reinforcing its mission-driven structure under nonprofit oversight while enabling greater impact and long-term alignment with the public good.",
    "summary": "An update from the OpenAI board on transitioning its for-profit entity to a Public Benefit Corporation, reinforcing its mission-driven structure under nonprofit oversight while enabling greater impact and long-term alignment with the public good.",
    "pubDate": "Mon, 05 May 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolving-our-structure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Residency",
    "description": "As part of our effort to support and develop AI talent, we‚Äôre excited to announce the OpenAI Residency.",
    "summary": "As part of our effort to support and develop AI talent, we‚Äôre excited to announce the OpenAI Residency.",
    "pubDate": "Tue, 30 Nov 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-residency",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deep Learning over the Internet: Training Language Models Collaboratively",
    "description": "",
    "summary": "Deep Learning over the Internet: Training Language Models Collaboratively Modern language models oft...",
    "pubDate": "Thu, 15 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/collaborative-training",
    "thumbnail": "https://huggingface.co/blog/assets/24_sahajBERT/thumbnail.png"
  },
  {
    "title": "Artificial Intelligence-assisted Pixel-level Lung (APL) Scoring for Fast and Accurate Quantification in Ultra-short Echo-time MRI",
    "description": "arXiv:2506.23506v1 Announce Type: cross Abstract: Lung magnetic resonance imaging (MRI) with ultrashort echo-time (UTE) represents a recent breakthrough in lung structure imaging, providing image resolution and quality comparable to computed tomography (CT). Due to the absence of ionising radiation, MRI is often preferred over CT in paediatric diseases such as cystic fibrosis (CF), one of the most common genetic disorders in Caucasians. To assess structural lung damage in CF imaging, CT scoring systems provide valuable quantitative insights for disease diagnosis and progression. However, few quantitative scoring systems are available in structural lung MRI (e.g., UTE-MRI). To provide fast and accurate quantification in lung MRI, we investigated the feasibility of novel Artificial intelligence-assisted Pixel-level Lung (APL) scoring for CF. APL scoring consists of 5 stages, including 1) image loading, 2) AI lung segmentation, 3) lung-bounded slice sampling, 4) pixel-level annotation, and 5) quantification and reporting. The results shows that our APL scoring took 8.2 minutes per subject, which was more than twice as fast as the previous grid-level scoring. Additionally, our pixel-level scoring was statistically more accurate (p=0.021), while strongly correlating with grid-level scoring (R=0.973, p=5.85e-9). This tool has great potential to streamline the workflow of UTE lung MRI in clinical settings, and be extended to other structural lung MRI sequences (e.g., BLADE MRI), and for other lung diseases (e.g., bronchopulmonary dysplasia).",
    "summary": "arXiv:2506.23506v1 Announce Type: cross Abstract: Lung magnetic resonance imaging (MRI) with ultrashort echo-time (UTE) represents a recent breakthrough in lung structure imaging, providing image resolution and quality comparable to computed tomography (CT). Due to the absence of ionising radiation, MRI is often preferred over CT in paediatric diseases such as cystic fibrosis (CF), one of the most common genetic disorders in Caucasians. To assess structural lung damage in CF imaging, CT scoring systems provide valuable quantitative insights for disease diagnosis and progression. However, few quantitative scoring systems are available in structural lung MRI (e.g., UTE-MRI). To provide fast and accurate quantification in lung MRI, we investigated the feasibility of novel Artificial intelligence-assisted Pixel-level Lung (APL) scoring for CF. APL scoring consists of 5 stages, including 1) image loading, 2) AI lung segmentation, 3) lung-bounded slice sampling, 4) pixel-level annotation, and 5) quantification and reporting. The results shows that our APL scoring took 8.2 minutes per subject, which was more than twice as fast as the previous grid-level scoring. Additionally, our pixel-level scoring was statistically more accurate (p=0.021), while strongly correlating with grid-level scoring (R=0.973, p=5.85e-9). This tool has great potential to streamline the workflow of UTE lung MRI in clinical settings, and be extended to other structural lung MRI sequences (e.g., BLADE MRI), and for other lung diseases (e.g., bronchopulmonary dysplasia).",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23506",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Interpretable by Design: MH-AutoML for Transparent and Efficient Android Malware Detection without Compromising Performance",
    "description": "arXiv:2506.23314v1 Announce Type: cross Abstract: Malware detection in Android systems requires both cybersecurity expertise and machine learning (ML) techniques. Automated Machine Learning (AutoML) has emerged as an approach to simplify ML development by reducing the need for specialized knowledge. However, current AutoML solutions typically operate as black-box systems with limited transparency, interpretability, and experiment traceability. To address these limitations, we present MH-AutoML, a domain-specific framework for Android malware detection. MH-AutoML automates the entire ML pipeline, including data preprocessing, feature engineering, algorithm selection, and hyperparameter tuning. The framework incorporates capabilities for interpretability, debugging, and experiment tracking that are often missing in general-purpose solutions. In this study, we compare MH-AutoML against seven established AutoML frameworks: Auto-Sklearn, AutoGluon, TPOT, HyperGBM, Auto-PyTorch, LightAutoML, and MLJAR. Results show that MH-AutoML achieves better recall rates while providing more transparency and control. The framework maintains computational efficiency comparable to other solutions, making it suitable for cybersecurity applications where both performance and explainability matter.",
    "summary": "arXiv:2506.23314v1 Announce Type: cross Abstract: Malware detection in Android systems requires both cybersecurity expertise and machine learning (ML) techniques. Automated Machine Learning (AutoML) has emerged as an approach to simplify ML development by reducing the need for specialized knowledge. However, current AutoML solutions typically operate as black-box systems with limited transparency, interpretability, and experiment traceability. To address these limitations, we present MH-AutoML, a domain-specific framework for Android malware detection. MH-AutoML automates the entire ML pipeline, including data preprocessing, feature engineering, algorithm selection, and hyperparameter tuning. The framework incorporates capabilities for interpretability, debugging, and experiment tracking that are often missing in general-purpose solutions. In this study, we compare MH-AutoML against seven established AutoML frameworks: Auto-Sklearn, AutoGluon, TPOT, HyperGBM, Auto-PyTorch, LightAutoML, and MLJAR. Results show that MH-AutoML achieves better recall rates while providing more transparency and control. The framework maintains computational efficiency comparable to other solutions, making it suitable for cybersecurity applications where both performance and explainability matter.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23314",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ÁîüÊàêAIÊ¥ªÁî®„ÄÅ‰∏ñÁïå„ÅØÂø´Ëµ∞„ÄÅÊó•Êú¨„ÅØËø∑Ëµ∞Ôºü„ÄÄPwCË™øÊüª„ÅåÊµÆ„ÅçÂΩ´„Çä„Å´„Åó„ÅüÊó•Êú¨‰ºÅÊ•≠„ÅÆË™≤È°å„Å®Á™ÅÁ†¥Âè£",
    "description": "PwC„ÅØ„ÄåÁîüÊàêAI„Å´Èñ¢„Åô„ÇãÂÆüÊÖãË™øÊüª2025Êò• 5„Ç´ÂõΩÊØîËºÉ„Äç„ÅÆÁµêÊûú„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÁîüÊàêAIÊ¥ªÁî®„Å´„Å§„ÅÑ„Å¶„ÄÅÁ±≥ÂõΩ„Å®Ëã±ÂõΩ„Åß„ÅØÂäπÊûúÁöÑ„Å™Â∞éÂÖ•„ÇíÁ§∫„Åó„ÄÅ‰∏≠ÂõΩ„ÅåÁ©çÊ•µÁöÑ„Å™Ê¥ªÁî®„ÇíÈÄ≤„ÇÅ„Å¶„ÅÑ„Çã„ÅÆ„Å´ÂØæ„Åó„Å¶„ÄÅÊó•Êú¨„Åß„ÅØÂäπÊûúÂâµÂá∫„Å´Ë™≤È°å„ÇíÊä±„Åà„Å¶„ÅÑ„Çã„Åì„Å®„ÅåÂàÜ„Åã„Å£„Åü„ÄÇ",
    "summary": "PwC„ÅØ„ÄåÁîüÊàêAI„Å´Èñ¢„Åô„ÇãÂÆüÊÖãË™øÊüª2025Êò• 5„Ç´ÂõΩÊØîËºÉ„Äç„ÅÆÁµêÊûú„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÁîüÊàêAIÊ¥ªÁî®„Å´„Å§„ÅÑ„Å¶„ÄÅÁ±≥ÂõΩ„Å®Ëã±ÂõΩ„Åß„ÅØÂäπÊûúÁöÑ„Å™Â∞éÂÖ•„ÇíÁ§∫„Åó„ÄÅ‰∏≠ÂõΩ„ÅåÁ©çÊ•µÁöÑ„Å™Ê¥ªÁî®„ÇíÈÄ≤„ÇÅ„Å¶„ÅÑ„Çã„ÅÆ„Å´ÂØæ„Åó„Å¶„ÄÅÊó•Êú¨„Åß„ÅØÂäπÊûúÂâµÂá∫„Å´Ë™≤È°å„ÇíÊä±„Åà„Å¶„ÅÑ„Çã„Åì„Å®„ÅåÂàÜ„Åã„Å£„Åü„ÄÇ",
    "pubDate": "Tue, 01 Jul 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://atmarkit.itmedia.co.jp/ait/articles/2507/01/news027.html",
    "thumbnail": "https://image.itmedia.co.jp/ait/articles/2507/01/cover_news027.jpg"
  },
  {
    "title": "Jukebox",
    "description": "We‚Äôre introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. We‚Äôre releasing the model weights and code, along with a tool to explore the generated¬†samples.",
    "summary": "We‚Äôre introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. We‚Äôre releasing the model weights and code, along with a tool to explore the generated¬†samples.",
    "pubDate": "Thu, 30 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jukebox",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Teams Up with Protect AI: Enhancing Model Security for the Community",
    "description": "",
    "summary": "Hugging Face Teams Up with Protect AI: Enhancing Model Security for the Community We are pleased to ...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/protectai",
    "thumbnail": "https://huggingface.co/blog/assets/protectai/thumbnail.png"
  },
  {
    "title": "On the quantitative analysis of decoder-based generative models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 14 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/on-the-quantitative-analysis-of-decoder-based-generative-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Shaping the future of financial services",
    "description": "Morgan Stanley uses AI evals to shape the future of financial services",
    "summary": "Morgan Stanley uses AI evals to shape the future of financial services",
    "pubDate": "Wed, 04 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/morgan-stanley",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the GPT Store",
    "description": "We‚Äôre launching the GPT Store to help you find useful and popular custom versions of ChatGPT.",
    "summary": "We‚Äôre launching the GPT Store to help you find useful and popular custom versions of ChatGPT.",
    "pubDate": "Wed, 10 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-gpt-store",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Have a damaged painting? Restore it in just hours with an AI-generated ‚Äúmask‚Äù",
    "description": "A new method can physically restore original paintings using digitally constructed films, which can be removed if desired.",
    "summary": "A new method can physically restore original paintings using digitally constructed films, which can be removed if desired.",
    "pubDate": "Wed, 11 Jun 2025 11:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/restoring-damaged-paintings-using-ai-generated-mask-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Restoring-Paintings-01-press.jpg"
  },
  {
    "title": "Evaluating large language models trained on code",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 07 Jul 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evaluating-large-language-models-trained-on-code",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome the Falcon 3 Family of Open Models!",
    "description": "",
    "summary": "Welcome to the Falcon 3 Family of Open Models! We introduce Falcon3, a family of decoder-only large ...",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon3",
    "thumbnail": "https://huggingface.co/blog/assets/falcon3/thumbnail.png"
  },
  {
    "title": "MuZero, AlphaZero, and AlphaDev: Optimizing computer systems",
    "description": "How MuZero, AlphaZero, and AlphaDev are optimizing the computing ecosystem that powers our world of devices.",
    "summary": "How MuZero, AlphaZero, and AlphaDev are optimizing the computing ecosystem that powers our world of devices.",
    "pubDate": "Mon, 12 Jun 2023 14:41:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/muzero-alphazero-and-alphadev-optimizing-computer-systems/",
    "thumbnail": "https://lh3.googleusercontent.com/6tSxHgEgSLR8FSELf3If1M1QBbXTtpsfH6w2ocuruWGnFDTdogbyNA8sHOyKpFYCja4hT7fGCVwl2xyI9biVB1bFNcnTxvYptuVdcT0XHMjn-TzG=w1200-h630-n-nu"
  },
  {
    "title": "Weight normalization: A simple reparameterization to accelerate training of deep neural networks",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 25 Feb 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/weight-normalization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays",
    "description": "arXiv:2506.23517v1 Announce Type: new Abstract: As the use of AI tools by students has become more prevalent, instructors have started using AI detection tools like GPTZero and QuillBot to detect AI written text. However, the reliability of these detectors remains uncertain. In our study, we focused mostly on the success rate of GPTZero, the most-used AI detector, in identifying AI-generated texts based on different lengths of randomly submitted essays: short (40-100 word count), medium (100-350 word count), and long (350-800 word count). We gathered a data set consisting of twenty-eight AI-generated papers and fifty human-written papers. With this randomized essay data, papers were individually plugged into GPTZero and measured for percentage of AI generation and confidence. A vast majority of the AI-generated papers were detected accurately (ranging from 91-100% AI believed generation), while the human generated essays fluctuated; there were a handful of false positives. These findings suggest that although GPTZero is effective at detecting purely AI-generated content, its reliability in distinguishing human-authored texts is limited. Educators should therefore exercise caution when relying solely on AI detection tools.",
    "summary": "arXiv:2506.23517v1 Announce Type: new Abstract: As the use of AI tools by students has become more prevalent, instructors have started using AI detection tools like GPTZero and QuillBot to detect AI written text. However, the reliability of these detectors remains uncertain. In our study, we focused mostly on the success rate of GPTZero, the most-used AI detector, in identifying AI-generated texts based on different lengths of randomly submitted essays: short (40-100 word count), medium (100-350 word count), and long (350-800 word count). We gathered a data set consisting of twenty-eight AI-generated papers and fifty human-written papers. With this randomized essay data, papers were individually plugged into GPTZero and measured for percentage of AI generation and confidence. A vast majority of the AI-generated papers were detected accurately (ranging from 91-100% AI believed generation), while the human generated essays fluctuated; there were a handful of false positives. These findings suggest that although GPTZero is effective at detecting purely AI-generated content, its reliability in distinguishing human-authored texts is limited. Educators should therefore exercise caution when relying solely on AI detection tools.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23517",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?",
    "description": "arXiv:2410.06735v2 Announce Type: replace-cross Abstract: Recent large language models (LLMs) have demonstrated remarkable generalization abilities in mathematics and logical reasoning tasks. Prior research indicates that LLMs pre-trained with programming language data exhibit high mathematical and reasoning abilities; however, this causal relationship has not been rigorously tested. Our research aims to verify which programming languages and features during pre-training affect logical inference performance. Specifically, we pre-trained decoder-based language models from scratch using datasets from ten programming languages (e.g., Python, C, Java) and three natural language datasets (Wikipedia, Fineweb, C4) under identical conditions. Thereafter, we evaluated the trained models in a few-shot in-context learning setting on logical reasoning tasks: FLD and bAbi, which do not require commonsense or world knowledge. The results demonstrate that nearly all models trained with programming languages consistently outperform those trained with natural languages, indicating that programming languages contain factors that elicit logic inference performance. In addition, we found that models trained with programming languages exhibit a better ability to follow instructions compared to those trained with natural languages. Further analysis reveals that the depth of Abstract Syntax Trees representing parsed results of programs also affects logical reasoning performance. These findings will offer insights into the essential elements of pre-training for acquiring the foundational abilities of LLMs.",
    "summary": "arXiv:2410.06735v2 Announce Type: replace-cross Abstract: Recent large language models (LLMs) have demonstrated remarkable generalization abilities in mathematics and logical reasoning tasks. Prior research indicates that LLMs pre-trained with programming language data exhibit high mathematical and reasoning abilities; however, this causal relationship has not been rigorously tested. Our research aims to verify which programming languages and features during pre-training affect logical inference performance. Specifically, we pre-trained decoder-based language models from scratch using datasets from ten programming languages (e.g., Python, C, Java) and three natural language datasets (Wikipedia, Fineweb, C4) under identical conditions. Thereafter, we evaluated the trained models in a few-shot in-context learning setting on logical reasoning tasks: FLD and bAbi, which do not require commonsense or world knowledge. The results demonstrate that nearly all models trained with programming languages consistently outperform those trained with natural languages, indicating that programming languages contain factors that elicit logic inference performance. In addition, we found that models trained with programming languages exhibit a better ability to follow instructions compared to those trained with natural languages. Further analysis reveals that the depth of Abstract Syntax Trees representing parsed results of programs also affects logical reasoning performance. These findings will offer insights into the essential elements of pre-training for acquiring the foundational abilities of LLMs.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.06735",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Tensor Train Quantum State Tomography using Compressed Sensing",
    "description": "arXiv:2506.23560v1 Announce Type: cross Abstract: Quantum state tomography (QST) is a fundamental technique for estimating the state of a quantum system from measured data and plays a crucial role in evaluating the performance of quantum devices. However, standard estimation methods become impractical due to the exponential growth of parameters in the state representation. In this work, we address this challenge by parameterizing the state using a low-rank block tensor train decomposition and demonstrate that our approach is both memory- and computationally efficient. This framework applies to a broad class of quantum states that can be well approximated by low-rank decompositions, including pure states, nearly pure states, and ground states of Hamiltonians.",
    "summary": "arXiv:2506.23560v1 Announce Type: cross Abstract: Quantum state tomography (QST) is a fundamental technique for estimating the state of a quantum system from measured data and plays a crucial role in evaluating the performance of quantum devices. However, standard estimation methods become impractical due to the exponential growth of parameters in the state representation. In this work, we address this challenge by parameterizing the state using a low-rank block tensor train decomposition and demonstrate that our approach is both memory- and computationally efficient. This framework applies to a broad class of quantum states that can be well approximated by low-rank decompositions, including pure states, nearly pure states, and ground states of Hamiltonians.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23560",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PatchTSMixer in HuggingFace",
    "description": "",
    "summary": "PatchTSMixer in HuggingFace - Getting Started PatchTSMixer is a lightweight time-series modeling app...",
    "pubDate": "Fri, 19 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/patchtsmixer",
    "thumbnail": "https://huggingface.co/blog/assets/patchtsmixer/thumbnail.jpeg"
  },
  {
    "title": "Introducing SimpleQA",
    "description": "A factuality benchmark called SimpleQA that measures the ability for language models to answer short, fact-seeking questions.",
    "summary": "A factuality benchmark called SimpleQA that measures the ability for language models to answer short, fact-seeking questions.",
    "pubDate": "Wed, 30 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-simpleqa",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy Hugging Face models easily with Amazon SageMaker",
    "description": "",
    "summary": "Deploy Hugging Face models easily with Amazon SageMaker üèé Earlier this year we announced a strategic...",
    "pubDate": "Thu, 08 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-hugging-face-models-easily-with-amazon-sagemaker",
    "thumbnail": "https://huggingface.co/blog/assets/17_the_partnership_amazon_sagemaker_and_hugging_face/thumbnail.png"
  },
  {
    "title": "Google DeepMind at ICLR 2024",
    "description": "Developing next-gen AI agents, exploring new modalities, and pioneering foundational learning",
    "summary": "Developing next-gen AI agents, exploring new modalities, and pioneering foundational learning",
    "pubDate": "Fri, 03 May 2024 13:39:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-iclr-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/8PzKGooudBtamqh9keU_q7O0ex5XxGgIIK3BKQNAVEV6WDzIkfadsbNPhU0QCg5PurFGnAOSOClrM9dQHIGvOEe9MPluA5uhyFcun3FvNMBfPI63mWk=w1200-h630-n-nu"
  },
  {
    "title": "Consistency Models",
    "description": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation.",
    "summary": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New and improved content moderation tooling",
    "description": "We are introducing a new and improved content moderation tool. The¬†Moderation endpoint¬†improves upon our previous content filter, and is available for free today to OpenAI API¬†developers.",
    "summary": "We are introducing a new and improved content moderation tool. The¬†Moderation endpoint¬†improves upon our previous content filter, and is available for free today to OpenAI API¬†developers.",
    "pubDate": "Wed, 10 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-and-improved-content-moderation-tooling",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Running IF with üß® diffusers on a Free Tier Google Colab",
    "description": "",
    "summary": "Running IF with üß® diffusers on a Free Tier Google Colab TL;DR: We show how to run one of the most po...",
    "pubDate": "Wed, 26 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/if",
    "thumbnail": "https://huggingface.co/blog/assets/if/thumbnail.jpg"
  },
  {
    "title": "Introducing HUGS - Scale your AI with Open Models",
    "description": "",
    "summary": "Introducing HUGS - Scale your AI with Open Models Today, we are thrilled to announce the launch of H...",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugs",
    "thumbnail": "https://huggingface.co/blog/assets/hugs/thumbnail.jpg"
  },
  {
    "title": "GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs",
    "description": "arXiv:2411.13757v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have revolutionized natural language processing (NLP), excelling in tasks like text generation and summarization. However, their increasing adoption in mission-critical applications raises concerns about hardware-based threats, particularly bit-flip attacks (BFAs). BFAs, enabled by fault injection methods such as Rowhammer, target model parameters in memory, compromising both integrity and performance. Identifying critical parameters for BFAs in the vast parameter space of LLMs poses significant challenges. While prior research suggests transformer-based architectures are inherently more robust to BFAs compared to traditional deep neural networks, we challenge this assumption. For the first time, we demonstrate that as few as three bit-flips can cause catastrophic performance degradation in an LLM with billions of parameters. Current BFA techniques are inadequate for exploiting this vulnerability due to the difficulty of efficiently identifying critical parameters within the immense parameter space. To address this, we propose AttentionBreaker, a novel framework tailored for LLMs that enables efficient traversal of the parameter space to identify critical parameters. Additionally, we introduce GenBFA, an evolutionary optimization strategy designed to refine the search further, isolating the most critical bits for an efficient and effective attack. Empirical results reveal the profound vulnerability of LLMs to AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% of total parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model result in a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to 0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findings underscore the effectiveness of AttentionBreaker in uncovering and exploiting critical vulnerabilities within LLM architectures.",
    "summary": "arXiv:2411.13757v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have revolutionized natural language processing (NLP), excelling in tasks like text generation and summarization. However, their increasing adoption in mission-critical applications raises concerns about hardware-based threats, particularly bit-flip attacks (BFAs). BFAs, enabled by fault injection methods such as Rowhammer, target model parameters in memory, compromising both integrity and performance. Identifying critical parameters for BFAs in the vast parameter space of LLMs poses significant challenges. While prior research suggests transformer-based architectures are inherently more robust to BFAs compared to traditional deep neural networks, we challenge this assumption. For the first time, we demonstrate that as few as three bit-flips can cause catastrophic performance degradation in an LLM with billions of parameters. Current BFA techniques are inadequate for exploiting this vulnerability due to the difficulty of efficiently identifying critical parameters within the immense parameter space. To address this, we propose AttentionBreaker, a novel framework tailored for LLMs that enables efficient traversal of the parameter space to identify critical parameters. Additionally, we introduce GenBFA, an evolutionary optimization strategy designed to refine the search further, isolating the most critical bits for an efficient and effective attack. Empirical results reveal the profound vulnerability of LLMs to AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% of total parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model result in a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to 0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findings underscore the effectiveness of AttentionBreaker in uncovering and exploiting critical vulnerabilities within LLM architectures.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.13757",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Researchers present bold ideas for AI at MIT Generative AI Impact Consortium kickoff event",
    "description": "Presentations targeted high-impact intersections of AI and other areas, such as health care, business, and education.",
    "summary": "Presentations targeted high-impact intersections of AI and other areas, such as health care, business, and education.",
    "pubDate": "Fri, 20 Jun 2025 16:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/researchers-present-bold-ideas-ai-mit-generative-ai-impact-consortium-event-0620",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-Anantha.jpg"
  },
  {
    "title": "Hugging Face + PyCharm",
    "description": "",
    "summary": "Hugging Face + PyCharm It‚Äôs a Tuesday morning. As a Transformers maintainer, I‚Äôm doing the same thin...",
    "pubDate": "Tue, 05 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pycharm-integration",
    "thumbnail": "https://huggingface.co/blog/assets/pycharm-integration/thumbnail.png"
  },
  {
    "title": "Scaling-up BERT Inference on CPU (Part 1)",
    "description": "",
    "summary": "Scaling up BERT-like model Inference on modern CPU - Part 1 1. Context and Motivations Back in Octob...",
    "pubDate": "Tue, 20 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-cpu-scaling-part-1",
    "thumbnail": "https://huggingface.co/blog/assets/21_bert_cpu_scaling_part_1/imgs/numa_set.png"
  },
  {
    "title": "Introducing OpenAI for Government",
    "description": "We‚Äôre launching OpenAI for Government, a new initiative focused on bringing our most advanced AI tools to public servants across the United States. We're supporting the U.S. government's efforts in adopting best-in-class technology and deploying these tools in service of the public good.",
    "summary": "We‚Äôre launching OpenAI for Government, a new initiative focused on bringing our most advanced AI tools to public servants across the United States. We're supporting the U.S. government's efforts in adopting best-in-class technology and deploying these tools in service of the public good.",
    "pubDate": "Mon, 16 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-openai-for-government",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing NPC-Playground, a 3D playground to interact with LLM-powered NPCs",
    "description": "",
    "summary": "Introducing NPC-Playground, a 3D playground to interact with LLM-powered NPCs AI-powered NPCs (Non-P...",
    "pubDate": "Wed, 05 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/npc-gigax-cubzh",
    "thumbnail": "https://huggingface.co/blog/assets/181_npc-gigax-cubzh/thumbnail.png"
  },
  {
    "title": "AIÂ∫óÈï∑„ÄÅÂÆ¢„Å´‚ÄúË¶™Âàá„Åô„Åé„Å¶‚ÄùËµ§Â≠ó„ÇíÂá∫„Åô„ÄÄÂéü‰æ°Ââ≤„Çå„Å´„ÇØ„Éº„Éù„É≥„ÅÆÂ§ßÈáèÈÖçÂ∏É„ÄÄAnthropic„ÅåÂÆüÈ®ìÁµêÊûú„ÇíÂÖ¨Èñã",
    "description": "AI„Å´Â£≤Â∫ó„ÅÆÁµåÂñ∂„Çí‰ªª„Åõ„Åü„Çâ„Å©„ÅÜ„Å™„Çã„ÅÆ„Åã‚Äï‚ÄïAIÈñãÁô∫‰ºÅÊ•≠„ÅÆÁ±≥Anthropic„ÅØ„ÄÅ„Åì„ÅÆ„Çà„ÅÜ„Å™ÂÆüÈ®ì„ÅÆÁµêÊûú„ÇíÂÖ¨Èñã„Åó„Åü„ÄÇ",
    "summary": "AI„Å´Â£≤Â∫ó„ÅÆÁµåÂñ∂„Çí‰ªª„Åõ„Åü„Çâ„Å©„ÅÜ„Å™„Çã„ÅÆ„Åã‚Äï‚ÄïAIÈñãÁô∫‰ºÅÊ•≠„ÅÆÁ±≥Anthropic„ÅØ„ÄÅ„Åì„ÅÆ„Çà„ÅÜ„Å™ÂÆüÈ®ì„ÅÆÁµêÊûú„ÇíÂÖ¨Èñã„Åó„Åü„ÄÇ",
    "pubDate": "Tue, 01 Jul 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2507/01/news051.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2507/01/cover_news051.jpg"
  },
  {
    "title": "Personalizing education with ChatGPT",
    "description": "Arizona State University embraces ChatGPT campus-wide to personalize learning, advance research, and prepare students for the future",
    "summary": "Arizona State University embraces ChatGPT campus-wide to personalize learning, advance research, and prepare students for the future",
    "pubDate": "Mon, 26 Aug 2024 04:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/asu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CoT Red-Handed: Stress Testing Chain-of-Thought Monitoring",
    "description": "arXiv:2505.23575v2 Announce Type: replace Abstract: As AI models are deployed with increasing autonomy, it is important to ensure they do not take harmful actions unnoticed. As a potential mitigation, we investigate Chain-of-Thought (CoT) monitoring, wherein a weaker trusted monitor model continuously oversees the intermediate reasoning steps of a more powerful but untrusted model. We compare CoT monitoring to action-only monitoring, where only final outputs are reviewed, in a red-teaming setup where the untrusted model is instructed to pursue harmful side tasks while completing a coding problem. We find that CoT monitoring improves detection by up to 27 percentage points in scenarios where action-only monitoring fails to reliably identify sabotage. However, CoT traces can also contain misleading rationalizations that deceive the monitor, reducing performance in more obvious sabotage cases. To address this, we introduce a hybrid protocol that independently scores both reasoning and final outputs and combines them using a weighted average. This hybrid monitor consistently outperforms both CoT and action-only monitors across all tested models and tasks, with detection rates over four times higher than action-only monitoring for subtle deception scenarios.",
    "summary": "arXiv:2505.23575v2 Announce Type: replace Abstract: As AI models are deployed with increasing autonomy, it is important to ensure they do not take harmful actions unnoticed. As a potential mitigation, we investigate Chain-of-Thought (CoT) monitoring, wherein a weaker trusted monitor model continuously oversees the intermediate reasoning steps of a more powerful but untrusted model. We compare CoT monitoring to action-only monitoring, where only final outputs are reviewed, in a red-teaming setup where the untrusted model is instructed to pursue harmful side tasks while completing a coding problem. We find that CoT monitoring improves detection by up to 27 percentage points in scenarios where action-only monitoring fails to reliably identify sabotage. However, CoT traces can also contain misleading rationalizations that deceive the monitor, reducing performance in more obvious sabotage cases. To address this, we introduce a hybrid protocol that independently scores both reasoning and final outputs and combines them using a weighted average. This hybrid monitor consistently outperforms both CoT and action-only monitors across all tested models and tasks, with detection rates over four times higher than action-only monitoring for subtle deception scenarios.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.23575",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Cross-modal Backward-compatible Representation Learning for Vision-Language Models",
    "description": "arXiv:2405.14715v2 Announce Type: replace-cross Abstract: Modern retrieval systems often struggle with upgrading to new and more powerful models due to the incompatibility of embeddings between the old and new models. This necessitates a costly process known as backfilling, which involves re-computing the embeddings for a large number of data samples. In vision, Backward-compatible Training (BT) has been proposed to ensure that the new model aligns with the old model's embeddings. This paper extends the concept of vision-only BT to the field of cross-modal retrieval, marking the first attempt to address Cross-modal BT (XBT). Our goal is to achieve backward-compatibility between Vision-Language Pretraining (VLP) models, such as CLIP, for the cross-modal retrieval task. To address XBT challenges, we propose an efficient solution: a projection module that maps the new model's embeddings to those of the old model. This module, pretrained solely with text data, significantly reduces the number of image-text pairs required for XBT learning, and, once it is pretrained, it avoids using the old model during training. Furthermore, we utilize parameter-efficient training strategies that improve efficiency and preserve the off-the-shelf new model's knowledge by avoiding any modifications. Experimental results on cross-modal retrieval datasets demonstrate the effectiveness of XBT and its potential to enable backfill-free upgrades when a new VLP model emerges.",
    "summary": "arXiv:2405.14715v2 Announce Type: replace-cross Abstract: Modern retrieval systems often struggle with upgrading to new and more powerful models due to the incompatibility of embeddings between the old and new models. This necessitates a costly process known as backfilling, which involves re-computing the embeddings for a large number of data samples. In vision, Backward-compatible Training (BT) has been proposed to ensure that the new model aligns with the old model's embeddings. This paper extends the concept of vision-only BT to the field of cross-modal retrieval, marking the first attempt to address Cross-modal BT (XBT). Our goal is to achieve backward-compatibility between Vision-Language Pretraining (VLP) models, such as CLIP, for the cross-modal retrieval task. To address XBT challenges, we propose an efficient solution: a projection module that maps the new model's embeddings to those of the old model. This module, pretrained solely with text data, significantly reduces the number of image-text pairs required for XBT learning, and, once it is pretrained, it avoids using the old model during training. Furthermore, we utilize parameter-efficient training strategies that improve efficiency and preserve the off-the-shelf new model's knowledge by avoiding any modifications. Experimental results on cross-modal retrieval datasets demonstrate the effectiveness of XBT and its potential to enable backfill-free upgrades when a new VLP model emerges.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.14715",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "WeatherEdit: Controllable Weather Editing with 4D Gaussian Field",
    "description": "arXiv:2505.20471v2 Announce Type: replace-cross Abstract: In this work, we present WeatherEdit, a novel weather editing pipeline for generating realistic weather effects with controllable types and severity in 3D scenes. Our approach is structured into two key components: weather background editing and weather particle construction. For weather background editing, we introduce an all-in-one adapter that integrates multiple weather styles into a single pretrained diffusion model, enabling the generation of diverse weather effects in 2D image backgrounds. During inference, we design a Temporal-View (TV-) attention mechanism that follows a specific order to aggregate temporal and spatial information, ensuring consistent editing across multi-frame and multi-view images. To construct the weather particles, we first reconstruct a 3D scene using the edited images and then introduce a dynamic 4D Gaussian field to generate snowflakes, raindrops and fog in the scene. The attributes and dynamics of these particles are precisely controlled through physical-based modelling and simulation, ensuring realistic weather representation and flexible severity adjustments. Finally, we integrate the 4D Gaussian field with the 3D scene to render consistent and highly realistic weather effects. Experiments on multiple driving datasets demonstrate that WeatherEdit can generate diverse weather effects with controllable condition severity, highlighting its potential for autonomous driving simulation in adverse weather. See project page: https://jumponthemoon.github.io/w-edit",
    "summary": "arXiv:2505.20471v2 Announce Type: replace-cross Abstract: In this work, we present WeatherEdit, a novel weather editing pipeline for generating realistic weather effects with controllable types and severity in 3D scenes. Our approach is structured into two key components: weather background editing and weather particle construction. For weather background editing, we introduce an all-in-one adapter that integrates multiple weather styles into a single pretrained diffusion model, enabling the generation of diverse weather effects in 2D image backgrounds. During inference, we design a Temporal-View (TV-) attention mechanism that follows a specific order to aggregate temporal and spatial information, ensuring consistent editing across multi-frame and multi-view images. To construct the weather particles, we first reconstruct a 3D scene using the edited images and then introduce a dynamic 4D Gaussian field to generate snowflakes, raindrops and fog in the scene. The attributes and dynamics of these particles are precisely controlled through physical-based modelling and simulation, ensuring realistic weather representation and flexible severity adjustments. Finally, we integrate the 4D Gaussian field with the 3D scene to render consistent and highly realistic weather effects. Experiments on multiple driving datasets demonstrate that WeatherEdit can generate diverse weather effects with controllable condition severity, highlighting its potential for autonomous driving simulation in adverse weather. See project page: https://jumponthemoon.github.io/w-edit",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.20471",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Function calling and other API updates",
    "description": "We‚Äôre announcing updates including more steerable API models, function calling capabilities, longer context, and lower prices.",
    "summary": "We‚Äôre announcing updates including more steerable API models, function calling capabilities, longer context, and lower prices.",
    "pubDate": "Tue, 13 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/function-calling-and-other-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SegMoE: Segmind Mixture of Diffusion Experts",
    "description": "",
    "summary": "SegMoE: Segmind Mixture of Diffusion Experts SegMoE is an exciting framework for creating Mixture-of...",
    "pubDate": "Sat, 03 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/segmoe",
    "thumbnail": "https://huggingface.co/blog/assets/segmoe/thumbnail.png"
  },
  {
    "title": "Space secrets security update",
    "description": "",
    "summary": "Space secrets leak disclosure Earlier this week our team detected unauthorized access to our Spaces ...",
    "pubDate": "Fri, 31 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/space-secrets-disclosure",
    "thumbnail": "https://huggingface.co/blog/assets/space-secrets-security-update/space-secrets-security-update.png"
  },
  {
    "title": "Universe",
    "description": "We‚Äôre releasing Universe, a software platform for measuring and training an AI‚Äôs general intelligence across the world‚Äôs supply of games, websites and other applications.",
    "summary": "We‚Äôre releasing Universe, a software platform for measuring and training an AI‚Äôs general intelligence across the world‚Äôs supply of games, websites and other applications.",
    "pubDate": "Mon, 05 Dec 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/universe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building Cost-Efficient Enterprise RAG applications with Intel Gaudi 2 and Intel Xeon",
    "description": "",
    "summary": "Building Cost-Efficient Enterprise RAG applications with Intel Gaudi 2 and Intel Xeon Retrieval-augm...",
    "pubDate": "Thu, 09 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cost-efficient-rag-applications-with-intel",
    "thumbnail": "https://huggingface.co/blog/assets/cost_efficient_rag_applications_with_intel/main.jpg"
  },
  {
    "title": "ÔºªPython„ÇØ„Ç§„Ç∫ÔºΩ„É™„Çπ„ÉàÁµêÂêà„Å£„Å¶„ÇÑ„ÇäÊñπ„ÅØ„ÅÑ„Çç„ÅÑ„Çç„ÅÇ„Çã„Åë„Çå„Å©„ÄÅÊ≠£„Åó„Åè‰Ωø„Åà„Å¶„ÅÑ„Åæ„Åô„ÅãÔºü",
    "description": "Ë§áÊï∞„ÅÇ„Çã„É™„Çπ„Éà„ÇíÁµêÂêà„Åó„Å¶„Å≤„Å®„Åæ„Å®„ÇÅ„Å´„Åó„Åü„ÅÑ„Å®„Åç„Å£„Å¶„ÅÇ„Çä„Åæ„Åô„Çà„Å≠„ÄÇÂ§ö„Åè„ÅÆÂ†¥Âêà„ÅØ+ÊºîÁÆóÂ≠ê„Çí‰Ωø„Åà„Å∞„ÅÑ„ÅÑ„Åß„Åó„Çá„ÅÜ„ÄÇ„Åß„ÇÇ„ÄÅ„Åù„Çå‰ª•Â§ñ„Å´„ÇÇ„ÅÑ„Çç„ÅÑ„Çç„Å™ÊñπÊ≥ï„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇÁü•„Çâ„Å™„ÅÑÊñπÊ≥ï„ÇÇ„ÅÇ„Çã„Åã„ÇÇ„Åó„Çå„Åæ„Åõ„Çì„ÇàÔºÅ",
    "summary": "Ë§áÊï∞„ÅÇ„Çã„É™„Çπ„Éà„ÇíÁµêÂêà„Åó„Å¶„Å≤„Å®„Åæ„Å®„ÇÅ„Å´„Åó„Åü„ÅÑ„Å®„Åç„Å£„Å¶„ÅÇ„Çä„Åæ„Åô„Çà„Å≠„ÄÇÂ§ö„Åè„ÅÆÂ†¥Âêà„ÅØ+ÊºîÁÆóÂ≠ê„Çí‰Ωø„Åà„Å∞„ÅÑ„ÅÑ„Åß„Åó„Çá„ÅÜ„ÄÇ„Åß„ÇÇ„ÄÅ„Åù„Çå‰ª•Â§ñ„Å´„ÇÇ„ÅÑ„Çç„ÅÑ„Çç„Å™ÊñπÊ≥ï„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇÁü•„Çâ„Å™„ÅÑÊñπÊ≥ï„ÇÇ„ÅÇ„Çã„Åã„ÇÇ„Åó„Çå„Åæ„Åõ„Çì„ÇàÔºÅ",
    "pubDate": "Tue, 01 Jul 2025 05:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://atmarkit.itmedia.co.jp/ait/articles/2507/01/news015.html",
    "thumbnail": "https://image.itmedia.co.jp/ait/articles/2507/01/cover_news015.jpg"
  },
  {
    "title": "A landmark multi-year global partnership with News Corp",
    "description": "Companies Join Forces to Enrich OpenAI‚Äôs Generative AI Products and Platforms with Premium Journalism",
    "summary": "Companies Join Forces to Enrich OpenAI‚Äôs Generative AI Products and Platforms with Premium Journalism",
    "pubDate": "Wed, 22 May 2024 13:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/news-corp-and-openai-sign-landmark-multi-year-global-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Unpacking the bias of large language models",
    "description": "In a new study, researchers discover the root cause of a type of bias in LLMs, paving the way for more accurate and reliable AI systems.",
    "summary": "In a new study, researchers discover the root cause of a type of bias in LLMs, paving the way for more accurate and reliable AI systems.",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/unpacking-large-language-model-bias-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-transform-bias-01-press.jpg"
  },
  {
    "title": "DeepMind‚Äôs latest research at ICLR 2023",
    "description": "Next week marks the start of the 11th International Conference on Learning Representations (ICLR), taking place 1-5 May in Kigali, Rwanda. This will be the first major artificial intelligence (AI) conference to be hosted in Africa and the first in-person event since the start of the pandemic. Researchers from around the world will gather to share their cutting-edge work in deep learning spanning the fields of AI, statistics and data science, and applications including machine vision, gaming and robotics. We‚Äôre proud to support the conference as a Diamond sponsor and DEI champion.",
    "summary": "Next week marks the start of the 11th International Conference on Learning Representations (ICLR), taking place 1-5 May in Kigali, Rwanda. This will be the first major artificial intelligence (AI) conference to be hosted in Africa and the first in-person event since the start of the pandemic. Researchers from around the world will gather to share their cutting-edge work in deep learning spanning the fields of AI, statistics and data science, and applications including machine vision, gaming and robotics. We‚Äôre proud to support the conference as a Diamond sponsor and DEI champion.",
    "pubDate": "Thu, 27 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/deepminds-latest-research-at-iclr-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/PH30vPBZLwZXlSFrALk6AT507Qn70LSPLW5a89vsRhDdkje_xaPGvNE2UrhOBy8Gkaasn-FVRuDWlPhEPntzw02gxSAEPygt7djS4URtQZJuaLPw3w=w1200-h630-n-nu"
  },
  {
    "title": "AlphaGeometry: An Olympiad-level AI system for geometry",
    "description": "Advancing AI reasoning in mathematics",
    "summary": "Advancing AI reasoning in mathematics",
    "pubDate": "Wed, 17 Jan 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/",
    "thumbnail": "https://lh3.googleusercontent.com/tVTh_ZCW5Qozy4vOCpMH06B7Ac_eF7fmEULMMTwDellOh6hnOMUtf28toD68N527IHQTlBWfBCHcZykYPMdrS48yvuEcJKMJG8rU3YRM3u5Ojn3JXnc=w1200-h630-n-nu"
  },
  {
    "title": "Unified Multimodal Understanding via Byte-Pair Visual Encoding",
    "description": "arXiv:2506.23639v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) have made significant progress in vision-language understanding, yet effectively aligning different modalities remains a fundamental challenge. We present a framework that unifies multimodal understanding by applying byte-pair encoding to visual tokens. Unlike conventional approaches that rely on modality-specific encoders, our method directly incorporates structural information into visual tokens, mirroring successful tokenization strategies in text-only language models. We introduce a priority-guided encoding scheme that considers both frequency and spatial consistency, coupled with a multi-stage training procedure based on curriculum-driven data composition. These enhancements enable the transformer model to better capture cross-modal relationships and reason with visual information. Comprehensive experiments demonstrate improved performance across diverse vision-language tasks. By bridging the gap between visual and textual representations, our approach contributes to the advancement of more capable and efficient multimodal foundation models.",
    "summary": "arXiv:2506.23639v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) have made significant progress in vision-language understanding, yet effectively aligning different modalities remains a fundamental challenge. We present a framework that unifies multimodal understanding by applying byte-pair encoding to visual tokens. Unlike conventional approaches that rely on modality-specific encoders, our method directly incorporates structural information into visual tokens, mirroring successful tokenization strategies in text-only language models. We introduce a priority-guided encoding scheme that considers both frequency and spatial consistency, coupled with a multi-stage training procedure based on curriculum-driven data composition. These enhancements enable the transformer model to better capture cross-modal relationships and reason with visual information. Comprehensive experiments demonstrate improved performance across diverse vision-language tasks. By bridging the gap between visual and textual representations, our approach contributes to the advancement of more capable and efficient multimodal foundation models.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23639",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Arize Phoenix „ÅßÂÆüÁèæ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Éà„É¨„Éº„Çπ",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI „ÉÅ„Éº„É†„ÅÆÈï∑Êæ§(@sp_1999N)„Åß„Åô„ÄÇ ‰ªäÂõû„ÅØ Arize AI Á§æ„ÅåÈñãÁô∫„ÉªÊèê‰æõ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥Âêë„Åë„ÅÆÁõ£Ë¶ñ„ÉÑ„Éº„É´ Phoenix „ÅÆÁ¥π‰ªã„Åä„Çà„Å≥Á∞°Âçò„Å™„Éá„É¢ÊßãÁØâ„ÇíË°å„ÅÑ„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ „Éá„É¢„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5608' rel='nofollow'>Arize Phoenix „ÅßÂÆüÁèæ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Éà„É¨„Éº„Çπ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI „ÉÅ„Éº„É†„ÅÆÈï∑Êæ§(@sp_1999N)„Åß„Åô„ÄÇ ‰ªäÂõû„ÅØ Arize AI Á§æ„ÅåÈñãÁô∫„ÉªÊèê‰æõ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥Âêë„Åë„ÅÆÁõ£Ë¶ñ„ÉÑ„Éº„É´ Phoenix „ÅÆÁ¥π‰ªã„Åä„Çà„Å≥Á∞°Âçò„Å™„Éá„É¢ÊßãÁØâ„ÇíË°å„ÅÑ„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ „Éá„É¢„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5608' rel='nofollow'>Arize Phoenix „ÅßÂÆüÁèæ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Éà„É¨„Éº„Çπ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Tue, 25 Mar 2025 10:22:46 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5608",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/image-4.png"
  },
  {
    "title": "Ethics and Society Newsletter #5: Hugging Face Goes To Washington and Other Summer 2023 Musings",
    "description": "",
    "summary": "Ethics and Society Newsletter #5: Hugging Face Goes To Washington and Other Summer 2023 Musings One ...",
    "pubDate": "Fri, 29 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-5",
    "thumbnail": "https://huggingface.co/blog/assets/164_ethics-soc-5/thumbnail.png"
  },
  {
    "title": "The New and Fresh analytics in Inference Endpoints",
    "description": "",
    "summary": "Analytics is important Analytics and metrics are the cornerstone of understanding what's happening w...",
    "pubDate": "Fri, 21 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/endpoint-analytics",
    "thumbnail": "https://huggingface.co/blog/assets/endpoint-analytics/thumbnail.png"
  },
  {
    "title": "CooT: Learning to Coordinate In-Context with Coordination Transformers",
    "description": "arXiv:2506.23549v1 Announce Type: new Abstract: Effective coordination among artificial agents in dynamic and uncertain environments remains a significant challenge in multi-agent systems. Existing approaches, such as self-play and population-based methods, either generalize poorly to unseen partners or require extensive training. To overcome these limitations, we propose Coordination Transformers (CooT), a novel in-context coordination framework that uses recent interaction histories to adapt to unseen partners rapidly. Unlike previous approaches that primarily aim to increase the diversity of training partners, CooT explicitly focuses on adapting to new partner behaviors by predicting actions aligned with observed partner interactions. Trained on interaction trajectories collected from diverse pairs of agents with complementary behaviors, CooT quickly learns effective coordination strategies without explicit supervision or fine-tuning. Evaluations on the Overcooked benchmark demonstrate that CooT significantly outperforms baseline methods in coordination tasks involving previously unseen partners. Human evaluations further confirm CooT as the most effective collaborative partner, while extensive ablations highlight its robustness, flexibility, and sensitivity to context in multi-agent scenarios.",
    "summary": "arXiv:2506.23549v1 Announce Type: new Abstract: Effective coordination among artificial agents in dynamic and uncertain environments remains a significant challenge in multi-agent systems. Existing approaches, such as self-play and population-based methods, either generalize poorly to unseen partners or require extensive training. To overcome these limitations, we propose Coordination Transformers (CooT), a novel in-context coordination framework that uses recent interaction histories to adapt to unseen partners rapidly. Unlike previous approaches that primarily aim to increase the diversity of training partners, CooT explicitly focuses on adapting to new partner behaviors by predicting actions aligned with observed partner interactions. Trained on interaction trajectories collected from diverse pairs of agents with complementary behaviors, CooT quickly learns effective coordination strategies without explicit supervision or fine-tuning. Evaluations on the Overcooked benchmark demonstrate that CooT significantly outperforms baseline methods in coordination tasks involving previously unseen partners. Human evaluations further confirm CooT as the most effective collaborative partner, while extensive ablations highlight its robustness, flexibility, and sensitivity to context in multi-agent scenarios.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23549",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Advantage Actor Critic (A2C)",
    "description": "",
    "summary": "Advantage Actor Critic (A2C) Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 7, of the‚ö†Ô∏è ...",
    "pubDate": "Fri, 22 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-a2c",
    "thumbnail": "https://huggingface.co/blog/assets/89_deep_rl_a2c/thumbnail.gif"
  },
  {
    "title": "CMI-Bench: A Comprehensive Benchmark for Evaluating Music Instruction Following",
    "description": "arXiv:2506.12285v2 Announce Type: replace-cross Abstract: Recent advances in audio-text large language models (LLMs) have opened new possibilities for music understanding and generation. However, existing benchmarks are limited in scope, often relying on simplified tasks or multi-choice evaluations that fail to reflect the complexity of real-world music analysis. We reinterpret a broad range of traditional MIR annotations as instruction-following formats and introduce CMI-Bench, a comprehensive music instruction following benchmark designed to evaluate audio-text LLMs on a diverse set of music information retrieval (MIR) tasks. These include genre classification, emotion regression, emotion tagging, instrument classification, pitch estimation, key detection, lyrics transcription, melody extraction, vocal technique recognition, instrument performance technique detection, music tagging, music captioning, and (down)beat tracking: reflecting core challenges in MIR research. Unlike previous benchmarks, CMI-Bench adopts standardized evaluation metrics consistent with previous state-of-the-art MIR models, ensuring direct comparability with supervised approaches. We provide an evaluation toolkit supporting all open-source audio-textual LLMs, including LTU, Qwen-audio, SALMONN, MusiLingo, etc. Experiment results reveal significant performance gaps between LLMs and supervised models, along with their culture, chronological and gender bias, highlighting the potential and limitations of current models in addressing MIR tasks. CMI-Bench establishes a unified foundation for evaluating music instruction following, driving progress in music-aware LLMs.",
    "summary": "arXiv:2506.12285v2 Announce Type: replace-cross Abstract: Recent advances in audio-text large language models (LLMs) have opened new possibilities for music understanding and generation. However, existing benchmarks are limited in scope, often relying on simplified tasks or multi-choice evaluations that fail to reflect the complexity of real-world music analysis. We reinterpret a broad range of traditional MIR annotations as instruction-following formats and introduce CMI-Bench, a comprehensive music instruction following benchmark designed to evaluate audio-text LLMs on a diverse set of music information retrieval (MIR) tasks. These include genre classification, emotion regression, emotion tagging, instrument classification, pitch estimation, key detection, lyrics transcription, melody extraction, vocal technique recognition, instrument performance technique detection, music tagging, music captioning, and (down)beat tracking: reflecting core challenges in MIR research. Unlike previous benchmarks, CMI-Bench adopts standardized evaluation metrics consistent with previous state-of-the-art MIR models, ensuring direct comparability with supervised approaches. We provide an evaluation toolkit supporting all open-source audio-textual LLMs, including LTU, Qwen-audio, SALMONN, MusiLingo, etc. Experiment results reveal significant performance gaps between LLMs and supervised models, along with their culture, chronological and gender bias, highlighting the potential and limitations of current models in addressing MIR tasks. CMI-Bench establishes a unified foundation for evaluating music instruction following, driving progress in music-aware LLMs.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12285",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "On the Predictive Power of Representation Dispersion in Language Models",
    "description": "arXiv:2506.24106v1 Announce Type: cross Abstract: We show that a language model's ability to predict text is tightly linked to the breadth of its embedding space: models that spread their contextual representations more widely tend to achieve lower perplexity. Concretely, we find that representation dispersion - the average pairwise cosine distance among hidden vectors - strongly and negatively correlates with perplexity across diverse model families (LLaMA, Qwen, and others) and domains (Wikipedia, news, scientific abstracts). Beyond illustrating this link, we show how dispersion can be leveraged for a range of practical tasks without requiring labeled data. First, measuring dispersion on unlabeled text allows us to predict downstream accuracy in new domains, offering a data-efficient tool for model selection. Next, we find that identifying layers with higher dispersion pinpoints the best representations for retrieval-based methods such as kNN-LM, bypassing exhaustive layer-by-layer searches. Finally, we integrate a simple push-away objective into training, which increases dispersion in both single-domain and cross-domain scenarios and directly improves perplexity in each.",
    "summary": "arXiv:2506.24106v1 Announce Type: cross Abstract: We show that a language model's ability to predict text is tightly linked to the breadth of its embedding space: models that spread their contextual representations more widely tend to achieve lower perplexity. Concretely, we find that representation dispersion - the average pairwise cosine distance among hidden vectors - strongly and negatively correlates with perplexity across diverse model families (LLaMA, Qwen, and others) and domains (Wikipedia, news, scientific abstracts). Beyond illustrating this link, we show how dispersion can be leveraged for a range of practical tasks without requiring labeled data. First, measuring dispersion on unlabeled text allows us to predict downstream accuracy in new domains, offering a data-efficient tool for model selection. Next, we find that identifying layers with higher dispersion pinpoints the best representations for retrieval-based methods such as kNN-LM, bypassing exhaustive layer-by-layer searches. Finally, we integrate a simple push-away objective into training, which increases dispersion in both single-domain and cross-domain scenarios and directly improves perplexity in each.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.24106",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RAILS: Retrieval-Augmented Intelligence for Learning Software Development",
    "description": "arXiv:2506.22742v1 Announce Type: cross Abstract: Large Language Models (LLMs) like GPT-3.5-Turbo are increasingly used to assist software development, yet they often produce incomplete code or incorrect imports, especially when lacking access to external or project-specific documentation. We introduce RAILS (Retrieval-Augmented Intelligence for Learning Software Development), a framework that augments LLM prompts with semantically retrieved context from curated Java resources using FAISS and OpenAI embeddings. RAILS incorporates an iterative validation loop guided by compiler feedback to refine suggestions. We evaluated RAILS on 78 real-world Java import error cases spanning standard libraries, GUI APIs, external tools, and custom utilities. Despite using the same LLM, RAILS outperforms baseline prompting by preserving intent, avoiding hallucinations, and surfacing correct imports even when libraries are unavailable locally. Future work will integrate symbolic filtering via PostgreSQL and extend support to other languages and IDEs.",
    "summary": "arXiv:2506.22742v1 Announce Type: cross Abstract: Large Language Models (LLMs) like GPT-3.5-Turbo are increasingly used to assist software development, yet they often produce incomplete code or incorrect imports, especially when lacking access to external or project-specific documentation. We introduce RAILS (Retrieval-Augmented Intelligence for Learning Software Development), a framework that augments LLM prompts with semantically retrieved context from curated Java resources using FAISS and OpenAI embeddings. RAILS incorporates an iterative validation loop guided by compiler feedback to refine suggestions. We evaluated RAILS on 78 real-world Java import error cases spanning standard libraries, GUI APIs, external tools, and custom utilities. Despite using the same LLM, RAILS outperforms baseline prompting by preserving intent, avoiding hallucinations, and surfacing correct imports even when libraries are unavailable locally. Future work will integrate symbolic filtering via PostgreSQL and extend support to other languages and IDEs.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22742",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Text2SQL using Hugging Face Dataset Viewer API and Motherduck DuckDB-NSQL-7B",
    "description": "",
    "summary": "Text2SQL using Hugging Face Dataset Viewer API and Motherduck DuckDB-NSQL-7B Today, integrating AI-p...",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/duckdb-nsql-7b",
    "thumbnail": "https://huggingface.co/blog/assets/duckdb-nsql-7b/thumbnail.png"
  },
  {
    "title": "Deep Multi-Manifold Transformation Based Multivariate Time Series Fault Detection",
    "description": "arXiv:2405.16258v2 Announce Type: replace-cross Abstract: Unsupervised fault detection in multivariate time series plays a vital role in ensuring the stable operation of complex systems. Traditional methods often assume that normal data follow a single Gaussian distribution and identify anomalies as deviations from this distribution. {color{black} However, this simplified assumption fails to capture the diversity and structural complexity of real-world time series, which can lead to misjudgments and reduced detection performance in practical applications. To address this issue, we propose a new method that combines a neighborhood-driven data augmentation strategy with a multi-manifold representation learning framework.} By incorporating information from local neighborhoods, the augmentation module can simulate contextual variations of normal data, enhancing the model's adaptability to distributional changes. In addition, we design a structure-aware feature learning approach that encourages natural clustering of similar patterns in the feature space while maintaining sufficient distinction between different operational states. Extensive experiments on several public benchmark datasets demonstrate that our method achieves superior performance in terms of both accuracy and robustness, showing strong potential for generalization and real-world deployment.",
    "summary": "arXiv:2405.16258v2 Announce Type: replace-cross Abstract: Unsupervised fault detection in multivariate time series plays a vital role in ensuring the stable operation of complex systems. Traditional methods often assume that normal data follow a single Gaussian distribution and identify anomalies as deviations from this distribution. {color{black} However, this simplified assumption fails to capture the diversity and structural complexity of real-world time series, which can lead to misjudgments and reduced detection performance in practical applications. To address this issue, we propose a new method that combines a neighborhood-driven data augmentation strategy with a multi-manifold representation learning framework.} By incorporating information from local neighborhoods, the augmentation module can simulate contextual variations of normal data, enhancing the model's adaptability to distributional changes. In addition, we design a structure-aware feature learning approach that encourages natural clustering of similar patterns in the feature space while maintaining sufficient distinction between different operational states. Extensive experiments on several public benchmark datasets demonstrate that our method achieves superior performance in terms of both accuracy and robustness, showing strong potential for generalization and real-world deployment.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.16258",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face Text Generation Inference available for AWS Inferentia2",
    "description": "",
    "summary": "Hugging Face Text Generation Inference available for AWS Inferentia2 We are excited to announce the ...",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-generation-inference-on-inferentia2",
    "thumbnail": "https://huggingface.co/blog/assets/175_text_generation_inference_on_inferentia2/thumbnail.jpg"
  },
  {
    "title": "Unsupervised Learning-Based Joint Resource Allocation and Beamforming Design for RIS-Assisted MISO-OFDMA Systems",
    "description": "arXiv:2506.22448v1 Announce Type: cross Abstract: Reconfigurable intelligent surfaces (RIS) are key enablers for 6G wireless systems. This paper studies downlink transmission in an RIS-assisted MISO-OFDMA system, addressing resource allocation challenges. A two-stage unsupervised learning-based framework is proposed to jointly design RIS phase shifts, BS beamforming, and resource block (RB) allocation. The framework includes BeamNet, which predicts RIS phase shifts from CSI, and AllocationNet, which allocates RBs using equivalent CSI derived from BeamNet outputs. Active beamforming is implemented via maximum ratio transmission and water-filling. To handle discrete constraints while ensuring differentiability, quantization and the Gumbel-softmax trick are adopted. A customized loss and phased training enhance performance under QoS constraints. Simulations show the method achieves 99.93% of the sum rate of the SCA baseline with only 0.036% of its runtime, and it remains robust across varying channel and user conditions.",
    "summary": "arXiv:2506.22448v1 Announce Type: cross Abstract: Reconfigurable intelligent surfaces (RIS) are key enablers for 6G wireless systems. This paper studies downlink transmission in an RIS-assisted MISO-OFDMA system, addressing resource allocation challenges. A two-stage unsupervised learning-based framework is proposed to jointly design RIS phase shifts, BS beamforming, and resource block (RB) allocation. The framework includes BeamNet, which predicts RIS phase shifts from CSI, and AllocationNet, which allocates RBs using equivalent CSI derived from BeamNet outputs. Active beamforming is implemented via maximum ratio transmission and water-filling. To handle discrete constraints while ensuring differentiability, quantization and the Gumbel-softmax trick are adopted. A customized loss and phased training enhance performance under QoS constraints. Simulations show the method achieves 99.93% of the sum rate of the SCA baseline with only 0.036% of its runtime, and it remains robust across varying channel and user conditions.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22448",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Nonlinear Low-rank Representation Model with Convolutional Neural Network for Imputing Water Quality Data",
    "description": "arXiv:2506.23629v1 Announce Type: cross Abstract: The integrity of Water Quality Data (WQD) is critical in environmental monitoring for scientific decision-making and ecological protection. However, water quality monitoring systems are often challenged by large amounts of missing data due to unavoidable problems such as sensor failures and communication delays, which further lead to water quality data becoming High-Dimensional and Sparse (HDS). Traditional data imputation methods are difficult to depict the potential dynamics and fail to capture the deep data features, resulting in unsatisfactory imputation performance. To effectively address the above issues, this paper proposes a Nonlinear Low-rank Representation model (NLR) with Convolutional Neural Networks (CNN) for imputing missing WQD, which utilizes CNNs to implement two ideas: a) fusing temporal features to model the temporal dependence of data between time slots, and b) Extracting nonlinear interactions and local patterns to mine higher-order relationships features and achieve deep fusion of multidimensional information. Experimental studies on three real water quality datasets demonstrate that the proposed model significantly outperforms existing state-of-the-art data imputation models in terms of estimation accuracy. It provides an effective approach for handling water quality monitoring data in complex dynamic environments.",
    "summary": "arXiv:2506.23629v1 Announce Type: cross Abstract: The integrity of Water Quality Data (WQD) is critical in environmental monitoring for scientific decision-making and ecological protection. However, water quality monitoring systems are often challenged by large amounts of missing data due to unavoidable problems such as sensor failures and communication delays, which further lead to water quality data becoming High-Dimensional and Sparse (HDS). Traditional data imputation methods are difficult to depict the potential dynamics and fail to capture the deep data features, resulting in unsatisfactory imputation performance. To effectively address the above issues, this paper proposes a Nonlinear Low-rank Representation model (NLR) with Convolutional Neural Networks (CNN) for imputing missing WQD, which utilizes CNNs to implement two ideas: a) fusing temporal features to model the temporal dependence of data between time slots, and b) Extracting nonlinear interactions and local patterns to mine higher-order relationships features and achieve deep fusion of multidimensional information. Experimental studies on three real water quality datasets demonstrate that the proposed model significantly outperforms existing state-of-the-art data imputation models in terms of estimation accuracy. It provides an effective approach for handling water quality monitoring data in complex dynamic environments.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23629",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome Llama 3 - Meta's new open LLM",
    "description": "",
    "summary": "Welcome Llama 3 - Meta‚Äôs new open LLM Introduction Meta‚Äôs Llama 3, the next iteration of the open-ac...",
    "pubDate": "Thu, 18 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama3",
    "thumbnail": "https://huggingface.co/blog/assets/llama3/thumbnail.jpg"
  },
  {
    "title": "OpenAI Five Benchmark",
    "description": "The OpenAI Five Benchmark match is now over!",
    "summary": "The OpenAI Five Benchmark match is now over!",
    "pubDate": "Wed, 18 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-benchmark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models",
    "description": "arXiv:2506.22957v1 Announce Type: cross Abstract: As large language models (LLMs) are increasingly integrated into multi-agent and human-AI systems, understanding their awareness of both self-context and conversational partners is essential for ensuring reliable performance and robust safety. While prior work has extensively studied situational awareness which refers to an LLM's ability to recognize its operating phase and constraints, it has largely overlooked the complementary capacity to identify and adapt to the identity and characteristics of a dialogue partner. In this paper, we formalize this latter capability as interlocutor awareness and present the first systematic evaluation of its emergence in contemporary LLMs. We examine interlocutor inference across three dimensions-reasoning patterns, linguistic style, and alignment preferences-and show that LLMs reliably identify same-family peers and certain prominent model families, such as GPT and Claude. To demonstrate its practical significance, we develop three case studies in which interlocutor awareness both enhances multi-LLM collaboration through prompt adaptation and introduces new alignment and safety vulnerabilities, including reward-hacking behaviors and increased jailbreak susceptibility. Our findings highlight the dual promise and peril of identity-sensitive behavior in LLMs, underscoring the need for further understanding of interlocutor awareness and new safeguards in multi-agent deployments. Our code is open-sourced at https://github.com/younwoochoi/InterlocutorAwarenessLLM.",
    "summary": "arXiv:2506.22957v1 Announce Type: cross Abstract: As large language models (LLMs) are increasingly integrated into multi-agent and human-AI systems, understanding their awareness of both self-context and conversational partners is essential for ensuring reliable performance and robust safety. While prior work has extensively studied situational awareness which refers to an LLM's ability to recognize its operating phase and constraints, it has largely overlooked the complementary capacity to identify and adapt to the identity and characteristics of a dialogue partner. In this paper, we formalize this latter capability as interlocutor awareness and present the first systematic evaluation of its emergence in contemporary LLMs. We examine interlocutor inference across three dimensions-reasoning patterns, linguistic style, and alignment preferences-and show that LLMs reliably identify same-family peers and certain prominent model families, such as GPT and Claude. To demonstrate its practical significance, we develop three case studies in which interlocutor awareness both enhances multi-LLM collaboration through prompt adaptation and introduces new alignment and safety vulnerabilities, including reward-hacking behaviors and increased jailbreak susceptibility. Our findings highlight the dual promise and peril of identity-sensitive behavior in LLMs, underscoring the need for further understanding of interlocutor awareness and new safeguards in multi-agent deployments. Our code is open-sourced at https://github.com/younwoochoi/InterlocutorAwarenessLLM.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22957",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Tiny Agents: a MCP-powered agent in 50 lines of code",
    "description": "",
    "summary": "Tiny Agents: an MCP-powered agent in 50 lines of code New! (May 23, '25) If you prefer Python, check...",
    "pubDate": "Fri, 25 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tiny-agents",
    "thumbnail": "https://huggingface.co/blog/assets/tiny-agents/thumbnail.jpg"
  },
  {
    "title": "Canva enables creativity with AI",
    "description": "A conversation with Cameron Adams, Chief Product Officer and Co-founder of Canva.",
    "summary": "A conversation with Cameron Adams, Chief Product Officer and Co-founder of Canva.",
    "pubDate": "Mon, 07 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/canva-cam-adams",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays",
    "description": "<p>The world‚Äôs first multimodal, bilingual radiology dataset could reshape the way radiologists and AI systems make sense of X-rays. PadChest-GR, developed by the University of Alicante with Microsoft Research, has the potential to advance research across the field for years to come.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/'>PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>The world‚Äôs first multimodal, bilingual radiology dataset could reshape the way radiologists and AI systems make sense of X-rays. PadChest-GR, developed by the University of Alicante with Microsoft Research, has the potential to advance research across the field for years to come.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/'>PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 26 Jun 2025 16:08:25 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Uber enables outstanding on-demand experiences with AI",
    "description": "A conversation with Jai Malkani, Head of AI and Product, Customer Obsession at Uber.",
    "summary": "A conversation with Jai Malkani, Head of AI and Product, Customer Obsession at Uber.",
    "pubDate": "Thu, 20 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/uber-enables-outstanding-experiences",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Software Engineering for Large Language Models: Research Status, Challenges and the Road Ahead",
    "description": "arXiv:2506.23762v1 Announce Type: cross Abstract: The rapid advancement of large language models (LLMs) has redefined artificial intelligence (AI), pushing the boundaries of AI research and enabling unbounded possibilities for both academia and the industry. However, LLM development faces increasingly complex challenges throughout its lifecycle, yet no existing research systematically explores these challenges and solutions from the perspective of software engineering (SE) approaches. To fill the gap, we systematically analyze research status throughout the LLM development lifecycle, divided into six phases: requirements engineering, dataset construction, model development and enhancement, testing and evaluation, deployment and operations, and maintenance and evolution. We then conclude by identifying the key challenges for each phase and presenting potential research directions to address these challenges. In general, we provide valuable insights from an SE perspective to facilitate future advances in LLM development.",
    "summary": "arXiv:2506.23762v1 Announce Type: cross Abstract: The rapid advancement of large language models (LLMs) has redefined artificial intelligence (AI), pushing the boundaries of AI research and enabling unbounded possibilities for both academia and the industry. However, LLM development faces increasingly complex challenges throughout its lifecycle, yet no existing research systematically explores these challenges and solutions from the perspective of software engineering (SE) approaches. To fill the gap, we systematically analyze research status throughout the LLM development lifecycle, divided into six phases: requirements engineering, dataset construction, model development and enhancement, testing and evaluation, deployment and operations, and maintenance and evolution. We then conclude by identifying the key challenges for each phase and presenting potential research directions to address these challenges. In general, we provide valuable insights from an SE perspective to facilitate future advances in LLM development.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23762",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Our updated Preparedness Framework",
    "description": "Sharing our updated framework for measuring and protecting against severe harm from frontier AI capabilities.",
    "summary": "Sharing our updated framework for measuring and protecting against severe harm from frontier AI capabilities.",
    "pubDate": "Tue, 15 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/updating-our-preparedness-framework",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Panel on Hugging Face",
    "description": "",
    "summary": "Panel on Hugging Face We are thrilled to announce the collaboration between Panel and Hugging Face! ...",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/panel-on-hugging-face",
    "thumbnail": "https://huggingface.co/blog/assets/panel-on-hugging-face/thumbnail.png"
  },
  {
    "title": "OpenAI‚Äôs API now available with no waitlist",
    "description": "Wider availability made possible by safety¬†progress.",
    "summary": "Wider availability made possible by safety¬†progress.",
    "pubDate": "Thu, 18 Nov 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-no-waitlist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing AI stories: daily benefits shine a light on bigger opportunities",
    "description": "Sam Altman has written that we are entering the Intelligence Age, a time when AI will help people become dramatically more capable. The biggest problems of today‚Äîacross science, medicine, education, national defense‚Äîwill no longer seem intractable, but will in fact be solvable. New horizons of possibility and prosperity will open up.",
    "summary": "Sam Altman has written that we are entering the Intelligence Age, a time when AI will help people become dramatically more capable. The biggest problems of today‚Äîacross science, medicine, education, national defense‚Äîwill no longer seem intractable, but will in fact be solvable. New horizons of possibility and prosperity will open up.",
    "pubDate": "Tue, 06 May 2025 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/ai-stories-daily-benefits-bigger-opportunities",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating Hugging Face Transformers with AWS Inferentia2",
    "description": "",
    "summary": "Accelerating Hugging Face Transformers with AWS Inferentia2 In the last five years, Transformer mode...",
    "pubDate": "Mon, 17 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-transformers-with-inferentia2",
    "thumbnail": "https://huggingface.co/blog/assets/140_accelerate_transformers_with_inferentia2/thumbnail.png"
  },
  {
    "title": "Adebayo Ogunlesi joins OpenAI‚Äôs Board of Directors",
    "description": "Adebayo Ogunlesi Joins OpenAI‚Äôs Board of Directors",
    "summary": "Adebayo Ogunlesi Joins OpenAI‚Äôs Board of Directors",
    "pubDate": "Tue, 14 Jan 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adebayo-ogunlesi-joins-openais-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Emergent tool use from multi-agent interaction",
    "description": "We‚Äôve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek. Through training in our new simulated hide-and-seek environment, agents build a series of six distinct strategies and counterstrategies, some of which we did not know our environment supported. The self-supervised emergent complexity in this simple environment further suggests that multi-agent co-adaptation may one day produce extremely complex and intelligent behavior.",
    "summary": "We‚Äôve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek. Through training in our new simulated hide-and-seek environment, agents build a series of six distinct strategies and counterstrategies, some of which we did not know our environment supported. The self-supervised emergent complexity in this simple environment further suggests that multi-agent co-adaptation may one day produce extremely complex and intelligent behavior.",
    "pubDate": "Tue, 17 Sep 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergent-tool-use",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-4 API general availability and deprecation of older models in the Completions API",
    "description": "GPT-3.5 Turbo, DALL¬∑E and Whisper APIs are also generally available, and we are releasing a deprecation plan for older models of the Completions API, which will retire at the beginning of 2024.",
    "summary": "GPT-3.5 Turbo, DALL¬∑E and Whisper APIs are also generally available, and we are releasing a deprecation plan for older models of the Completions API, which will retire at the beginning of 2024.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-api-general-availability",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Customizable, no-code voice agent automation with GPT-4o",
    "description": "Retell AI is transforming the call center with AI voice automation powered by GPT-4o and GPT-4.1. Its no-code platform enables businesses to launch natural, real-time voice agents that cut call costs, boost CSAT, and automate customer conversations‚Äîwithout scripts or hold times.",
    "summary": "Retell AI is transforming the call center with AI voice automation powered by GPT-4o and GPT-4.1. Its no-code platform enables businesses to launch natural, real-time voice agents that cut call costs, boost CSAT, and automate customer conversations‚Äîwithout scripts or hold times.",
    "pubDate": "Thu, 26 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retell-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Happy 1st anniversary ü§ó Diffusers!",
    "description": "",
    "summary": "Happy 1st anniversary ü§ó Diffusers! ü§ó Diffusers is happy to celebrate its first anniversary! It has b...",
    "pubDate": "Thu, 20 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-turns-1",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers-turns-1/diffusers-turns-1.png"
  },
  {
    "title": "Public Policy at Hugging Face",
    "description": "",
    "summary": "Public Policy at Hugging Face Published April 8, 2024 Update on GitHubAI Policy at Hugging Face is a...",
    "pubDate": "Mon, 08 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/policy-blog",
    "thumbnail": "https://huggingface.co/blog/assets/policy_docs/policy_blog_thumbnail.png"
  },
  {
    "title": "Driving scalable growth with OpenAI o3, GPT-4.1, and CUA",
    "description": "Unify, an AI-powered GTM platform, uses OpenAI‚Äôs o3, GPT-4.1, and CUA to automate prospecting, research, and outreach. With hyper-personalized messaging and an always-on workflow, Unify helps teams generate pipeline at scale while focusing on high-impact customer interactions.",
    "summary": "Unify, an AI-powered GTM platform, uses OpenAI‚Äôs o3, GPT-4.1, and CUA to automate prospecting, research, and outreach. With hyper-personalized messaging and an always-on workflow, Unify helps teams generate pipeline at scale while focusing on high-impact customer interactions.",
    "pubDate": "Tue, 24 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/unify",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Meta-learning for wrestling",
    "description": "We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to physical malfunction.",
    "summary": "We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to physical malfunction.",
    "pubDate": "Wed, 11 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/meta-learning-for-wrestling",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FedMM-X: A Trustworthy and Interpretable Framework for Federated Multi-Modal Learning in Dynamic Environments",
    "description": "arXiv:2503.19564v2 Announce Type: replace-cross Abstract: As artificial intelligence systems increasingly operate in Real-world environments, the integration of multi-modal data sources such as vision, language, and audio presents both unprecedented opportunities and critical challenges for achieving trustworthy intelligence. In this paper, we propose a novel framework that unifies federated learning with explainable multi-modal reasoning to ensure trustworthiness in decentralized, dynamic settings. Our approach, called FedMM-X (Federated Multi-Modal Explainable Intelligence), leverages cross-modal consistency checks, client-level interpretability mechanisms, and dynamic trust calibration to address challenges posed by data heterogeneity, modality imbalance, and out-of-distribution generalization. Through rigorous evaluation across federated multi-modal benchmarks involving vision-language tasks, we demonstrate improved performance in both accuracy and interpretability while reducing vulnerabilities to adversarial and spurious correlations. Further, we introduce a novel trust score aggregation method to quantify global model reliability under dynamic client participation. Our findings pave the way toward developing robust, interpretable, and socially responsible AI systems in Real-world environments.",
    "summary": "arXiv:2503.19564v2 Announce Type: replace-cross Abstract: As artificial intelligence systems increasingly operate in Real-world environments, the integration of multi-modal data sources such as vision, language, and audio presents both unprecedented opportunities and critical challenges for achieving trustworthy intelligence. In this paper, we propose a novel framework that unifies federated learning with explainable multi-modal reasoning to ensure trustworthiness in decentralized, dynamic settings. Our approach, called FedMM-X (Federated Multi-Modal Explainable Intelligence), leverages cross-modal consistency checks, client-level interpretability mechanisms, and dynamic trust calibration to address challenges posed by data heterogeneity, modality imbalance, and out-of-distribution generalization. Through rigorous evaluation across federated multi-modal benchmarks involving vision-language tasks, we demonstrate improved performance in both accuracy and interpretability while reducing vulnerabilities to adversarial and spurious correlations. Further, we introduce a novel trust score aggregation method to quantify global model reliability under dynamic client participation. Our findings pave the way toward developing robust, interpretable, and socially responsible AI systems in Real-world environments.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.19564",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Optimum+ONNX Runtime - Easier, Faster training for your Hugging Face models",
    "description": "",
    "summary": "Optimum + ONNX Runtime: Easier, Faster training for your Hugging Face models Introduction Transforme...",
    "pubDate": "Tue, 24 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-onnxruntime-training",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_onnxruntime-training/thumbnail.png"
  },
  {
    "title": "Fine-tuning GPT-2 from human preferences",
    "description": "We‚Äôve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we‚Äôd only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required only 5k. Our motivation is to move safety techniques closer to the general task of ‚Äúmachines talking to humans,‚Äù which we believe is key to extracting information about human¬†values.",
    "summary": "We‚Äôve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we‚Äôd only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required only 5k. Our motivation is to move safety techniques closer to the general task of ‚Äúmachines talking to humans,‚Äù which we believe is key to extracting information about human¬†values.",
    "pubDate": "Thu, 19 Sep 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fine-tuning-gpt-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Mode Collapse Happens: Evaluating Critical Interactions in Joint Trajectory Prediction Models",
    "description": "arXiv:2506.23164v1 Announce Type: cross Abstract: Autonomous Vehicle decisions rely on multimodal prediction models that account for multiple route options and the inherent uncertainty in human behavior. However, models can suffer from mode collapse, where only the most likely mode is predicted, posing significant safety risks. While existing methods employ various strategies to generate diverse predictions, they often overlook the diversity in interaction modes among agents. Additionally, traditional metrics for evaluating prediction models are dataset-dependent and do not evaluate inter-agent interactions quantitatively. To our knowledge, none of the existing metrics explicitly evaluates mode collapse. In this paper, we propose a novel evaluation framework that assesses mode collapse in joint trajectory predictions, focusing on safety-critical interactions. We introduce metrics for mode collapse, mode correctness, and coverage, emphasizing the sequential dimension of predictions. By testing four multi-agent trajectory prediction models, we demonstrate that mode collapse indeed happens. When looking at the sequential dimension, although prediction accuracy improves closer to interaction events, there are still cases where the models are unable to predict the correct interaction mode, even just before the interaction mode becomes inevitable. We hope that our framework can help researchers gain new insights and advance the development of more consistent and accurate prediction models, thus enhancing the safety of autonomous driving systems.",
    "summary": "arXiv:2506.23164v1 Announce Type: cross Abstract: Autonomous Vehicle decisions rely on multimodal prediction models that account for multiple route options and the inherent uncertainty in human behavior. However, models can suffer from mode collapse, where only the most likely mode is predicted, posing significant safety risks. While existing methods employ various strategies to generate diverse predictions, they often overlook the diversity in interaction modes among agents. Additionally, traditional metrics for evaluating prediction models are dataset-dependent and do not evaluate inter-agent interactions quantitatively. To our knowledge, none of the existing metrics explicitly evaluates mode collapse. In this paper, we propose a novel evaluation framework that assesses mode collapse in joint trajectory predictions, focusing on safety-critical interactions. We introduce metrics for mode collapse, mode correctness, and coverage, emphasizing the sequential dimension of predictions. By testing four multi-agent trajectory prediction models, we demonstrate that mode collapse indeed happens. When looking at the sequential dimension, although prediction accuracy improves closer to interaction events, there are still cases where the models are unable to predict the correct interaction mode, even just before the interaction mode becomes inevitable. We hope that our framework can help researchers gain new insights and advance the development of more consistent and accurate prediction models, thus enhancing the safety of autonomous driving systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23164",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Open Leaderboard for Hebrew LLMs!",
    "description": "",
    "summary": "Introducing the Open Leaderboard for Hebrew LLMs! This project addresses the critical need for advan...",
    "pubDate": "Sun, 05 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-hebrew",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_hebrew.png"
  },
  {
    "title": "Requests for Research 2.0",
    "description": "We‚Äôre releasing a new batch of¬†seven unsolved problems¬†which have come up in the course of our research at OpenAI.",
    "summary": "We‚Äôre releasing a new batch of¬†seven unsolved problems¬†which have come up in the course of our research at OpenAI.",
    "pubDate": "Wed, 31 Jan 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/requests-for-research-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ADReFT: Adaptive Decision Repair for Safe Autonomous Driving via Reinforcement Fine-Tuning",
    "description": "arXiv:2506.23960v1 Announce Type: cross Abstract: Autonomous Driving Systems (ADSs) continue to face safety-critical risks due to the inherent limitations in their design and performance capabilities. Online repair plays a crucial role in mitigating such limitations, ensuring the runtime safety and reliability of ADSs. Existing online repair solutions enforce ADS compliance by transforming unacceptable trajectories into acceptable ones based on predefined specifications, such as rule-based constraints or training datasets. However, these approaches often lack generalizability, adaptability and tend to be overly conservative, resulting in ineffective repairs that not only fail to mitigate safety risks sufficiently but also degrade the overall driving experience. To address this issue, we propose Adaptive Decision Repair (ADReFT), a novel and effective repair method that identifies safety-critical states through offline learning from failed tests and generates appropriate mitigation actions to improve ADS safety. Specifically, ADReFT incorporates a transformer-based model with two joint heads, State Monitor and Decision Adapter, designed to capture complex driving environment interactions to evaluate state safety severity and generate adaptive repair actions. Given the absence of oracles for state safety identification, we first pretrain ADReFT using supervised learning with coarse annotations, i.e., labeling states preceding violations as positive samples and others as negative samples. It establishes ADReFT's foundational capability to mitigate safety-critical violations, though it may result in somewhat conservative mitigation strategies. Therefore, we subsequently finetune ADReFT using reinforcement learning to improve its initial capability and generate more precise and contextually appropriate repair decisions. Our evaluation results illustrate that ADReFT achieves better repair performance.",
    "summary": "arXiv:2506.23960v1 Announce Type: cross Abstract: Autonomous Driving Systems (ADSs) continue to face safety-critical risks due to the inherent limitations in their design and performance capabilities. Online repair plays a crucial role in mitigating such limitations, ensuring the runtime safety and reliability of ADSs. Existing online repair solutions enforce ADS compliance by transforming unacceptable trajectories into acceptable ones based on predefined specifications, such as rule-based constraints or training datasets. However, these approaches often lack generalizability, adaptability and tend to be overly conservative, resulting in ineffective repairs that not only fail to mitigate safety risks sufficiently but also degrade the overall driving experience. To address this issue, we propose Adaptive Decision Repair (ADReFT), a novel and effective repair method that identifies safety-critical states through offline learning from failed tests and generates appropriate mitigation actions to improve ADS safety. Specifically, ADReFT incorporates a transformer-based model with two joint heads, State Monitor and Decision Adapter, designed to capture complex driving environment interactions to evaluate state safety severity and generate adaptive repair actions. Given the absence of oracles for state safety identification, we first pretrain ADReFT using supervised learning with coarse annotations, i.e., labeling states preceding violations as positive samples and others as negative samples. It establishes ADReFT's foundational capability to mitigate safety-critical violations, though it may result in somewhat conservative mitigation strategies. Therefore, we subsequently finetune ADReFT using reinforcement learning to improve its initial capability and generate more precise and contextually appropriate repair decisions. Our evaluation results illustrate that ADReFT achieves better repair performance.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23960",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Insights from global conversations",
    "description": "We are sharing what we learned from our conversations across 22 countries, and how we will be incorporating those insights moving forward.",
    "summary": "We are sharing what we learned from our conversations across 22 countries, and how we will be incorporating those insights moving forward.",
    "pubDate": "Thu, 29 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/insights-from-global-conversations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Investing in Performance: Fine-tune small models with LLM insights  - a CFM case study",
    "description": "",
    "summary": "Investing in Performance: Fine-tune small models with LLM insights - a CFM case study Overview: This...",
    "pubDate": "Tue, 03 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cfm-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/cfm-case-study/blogpost_cfm.png"
  },
  {
    "title": "BIMgent: Towards Autonomous Building Modeling via Computer-use Agents",
    "description": "arXiv:2506.07217v2 Announce Type: replace Abstract: Existing computer-use agents primarily focus on general-purpose desktop automation tasks, with limited exploration of their application in highly specialized domains. In particular, the 3D building modeling process in the Architecture, Engineering, and Construction (AEC) sector involves open-ended design tasks and complex interaction patterns within Building Information Modeling (BIM) authoring software, which has yet to be thoroughly addressed by current studies. In this paper, we propose BIMgent, an agentic framework powered by multimodal large language models (LLMs), designed to enable autonomous building model authoring via graphical user interface (GUI) operations. BIMgent automates the architectural building modeling process, including multimodal input for conceptual design, planning of software-specific workflows, and efficient execution of the authoring GUI actions. We evaluate BIMgent on real-world building modeling tasks, including both text-based conceptual design generation and reconstruction from existing building design. The design quality achieved by BIMgent was found to be reasonable. Its operations achieved a 32% success rate, whereas all baseline models failed to complete the tasks (0% success rate). Results demonstrate that BIMgent effectively reduces manual workload while preserving design intent, highlighting its potential for practical deployment in real-world architectural modeling scenarios. Project page: https://tumcms.github.io/BIMgent.github.io/",
    "summary": "arXiv:2506.07217v2 Announce Type: replace Abstract: Existing computer-use agents primarily focus on general-purpose desktop automation tasks, with limited exploration of their application in highly specialized domains. In particular, the 3D building modeling process in the Architecture, Engineering, and Construction (AEC) sector involves open-ended design tasks and complex interaction patterns within Building Information Modeling (BIM) authoring software, which has yet to be thoroughly addressed by current studies. In this paper, we propose BIMgent, an agentic framework powered by multimodal large language models (LLMs), designed to enable autonomous building model authoring via graphical user interface (GUI) operations. BIMgent automates the architectural building modeling process, including multimodal input for conceptual design, planning of software-specific workflows, and efficient execution of the authoring GUI actions. We evaluate BIMgent on real-world building modeling tasks, including both text-based conceptual design generation and reconstruction from existing building design. The design quality achieved by BIMgent was found to be reasonable. Its operations achieved a 32% success rate, whereas all baseline models failed to complete the tasks (0% success rate). Results demonstrate that BIMgent effectively reduces manual workload while preserving design intent, highlighting its potential for practical deployment in real-world architectural modeling scenarios. Project page: https://tumcms.github.io/BIMgent.github.io/",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.07217",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How we sped up transformer inference 100x for ü§ó API customers",
    "description": "",
    "summary": "How we sped up transformer inference 100x for ü§ó API customers ü§ó Transformers has become the default ...",
    "pubDate": "Mon, 18 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerated-inference",
    "thumbnail": "https://huggingface.co/blog/assets/09_accelerated_inference/thumbnail.png"
  },
  {
    "title": "Empirical evidence of Large Language Model's influence on human spoken communication",
    "description": "arXiv:2409.01754v2 Announce Type: replace-cross Abstract: From the invention of writing and the printing press, to television and social media, human history is punctuated by major innovations in communication technology, which fundamentally altered how ideas spread and reshaped our culture. Recent chatbots powered by generative artificial intelligence constitute a novel medium that encodes cultural patterns in their neural representations and disseminates them in conversations with hundreds of millions of people. Understanding whether these patterns transmit into human language, and ultimately shape human culture, is a fundamental question. While fully quantifying the causal impact of a chatbot like ChatGPT on human culture is very challenging, lexicographic shift in human spoken communication may offer an early indicator of such broad phenomenon. Here, we apply econometric causal inference techniques to 740,249 hours of human discourse from 360,445 YouTube academic talks and 771,591 conversational podcast episodes across multiple disciplines. We detect a measurable and abrupt increase in the use of words preferentially generated by ChatGPT, such as delve, comprehend, boast, swift, and meticulous, after its release. These findings suggest a scenario where machines, originally trained on human data and subsequently exhibiting their own cultural traits, can, in turn, measurably reshape human culture. This marks the beginning of a closed cultural feedback loop in which cultural traits circulate bidirectionally between humans and machines. Our results motivate further research into the evolution of human-machine culture, and raise concerns over the erosion of linguistic and cultural diversity, and the risks of scalable manipulation.",
    "summary": "arXiv:2409.01754v2 Announce Type: replace-cross Abstract: From the invention of writing and the printing press, to television and social media, human history is punctuated by major innovations in communication technology, which fundamentally altered how ideas spread and reshaped our culture. Recent chatbots powered by generative artificial intelligence constitute a novel medium that encodes cultural patterns in their neural representations and disseminates them in conversations with hundreds of millions of people. Understanding whether these patterns transmit into human language, and ultimately shape human culture, is a fundamental question. While fully quantifying the causal impact of a chatbot like ChatGPT on human culture is very challenging, lexicographic shift in human spoken communication may offer an early indicator of such broad phenomenon. Here, we apply econometric causal inference techniques to 740,249 hours of human discourse from 360,445 YouTube academic talks and 771,591 conversational podcast episodes across multiple disciplines. We detect a measurable and abrupt increase in the use of words preferentially generated by ChatGPT, such as delve, comprehend, boast, swift, and meticulous, after its release. These findings suggest a scenario where machines, originally trained on human data and subsequently exhibiting their own cultural traits, can, in turn, measurably reshape human culture. This marks the beginning of a closed cultural feedback loop in which cultural traits circulate bidirectionally between humans and machines. Our results motivate further research into the evolution of human-machine culture, and raise concerns over the erosion of linguistic and cultural diversity, and the risks of scalable manipulation.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.01754",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tuning Llama 2 70B using PyTorch FSDP",
    "description": "",
    "summary": "Fine-tuning Llama 2 70B using PyTorch FSDP Introduction In this blog post, we will look at how to fi...",
    "pubDate": "Wed, 13 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ram-efficient-pytorch-fsdp",
    "thumbnail": "https://huggingface.co/blog/assets/160_fsdp_llama/thumbnail.jpg"
  },
  {
    "title": "Objective-Free Local Learning and Emergent Language Structure in Thinking Machines",
    "description": "arXiv:2506.23293v1 Announce Type: cross Abstract: We present a neuro-symbolic framework for generative language modeling based on local, event-driven emergent learning. At its core is a hierarchical Hopfield memory chain acting as a compositional short-term memory and dynamic tokenizer (retokenizer). Rather than relying on predefined tokens or supervision, the model builds structure from scratch, learning symbol sequences as multi-scale representations. It constructs projection tensors that bind co-occurring features into hierarchical tokens, introducing redundancy (i.e an emergent gauge structure) and enabling compression of local activations into long-range dependencies. Curiously, we find that the retokenizer can filter natural language patterns from noise, generating synthetic languages with coherent internal morphology -- quantifiably the same as human language. Language is learned in a local (Hebbian) fashion, where model constraints dictate allowed emergent structure, and new information is retained in alignment with this structure. The absence of a global objective enables a form of plasticity not found in conventional language models, allowing the system to generalize beyond its initial inference class -- even without explicit data. We demonstrate that briefly activating a new neuron during inference binds distributed multi-scale token features into a symbolic embedding. These emergent embedding neurons act as long-term memory and support a key-value mechanism for compositional inference and generalization. This architecture provides a methodological foundation for studying how symbolic structure can emerge from local neural learning. It offers a new pathway for building scalable, interpretable neuro-symbolic systems -- where tokens, grammar, and reasoning arise as compressed memory traces within a Hopfield hierarchy. This approach advances the development of neuromorphic architectures for generative language models.",
    "summary": "arXiv:2506.23293v1 Announce Type: cross Abstract: We present a neuro-symbolic framework for generative language modeling based on local, event-driven emergent learning. At its core is a hierarchical Hopfield memory chain acting as a compositional short-term memory and dynamic tokenizer (retokenizer). Rather than relying on predefined tokens or supervision, the model builds structure from scratch, learning symbol sequences as multi-scale representations. It constructs projection tensors that bind co-occurring features into hierarchical tokens, introducing redundancy (i.e an emergent gauge structure) and enabling compression of local activations into long-range dependencies. Curiously, we find that the retokenizer can filter natural language patterns from noise, generating synthetic languages with coherent internal morphology -- quantifiably the same as human language. Language is learned in a local (Hebbian) fashion, where model constraints dictate allowed emergent structure, and new information is retained in alignment with this structure. The absence of a global objective enables a form of plasticity not found in conventional language models, allowing the system to generalize beyond its initial inference class -- even without explicit data. We demonstrate that briefly activating a new neuron during inference binds distributed multi-scale token features into a symbolic embedding. These emergent embedding neurons act as long-term memory and support a key-value mechanism for compositional inference and generalization. This architecture provides a methodological foundation for studying how symbolic structure can emerge from local neural learning. It offers a new pathway for building scalable, interpretable neuro-symbolic systems -- where tokens, grammar, and reasoning arise as compressed memory traces within a Hopfield hierarchy. This approach advances the development of neuromorphic architectures for generative language models.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23293",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Visual Encoders for Data-Efficient Imitation Learning in Modern Video Games",
    "description": "arXiv:2312.02312v3 Announce Type: replace-cross Abstract: Video games have served as useful benchmarks for the decision-making community, but going beyond Atari games towards modern games has been prohibitively expensive for the vast majority of the research community. Prior work in modern video games typically relied on game-specific integration to obtain game features and enable online training, or on existing large datasets. An alternative approach is to train agents using imitation learning to play video games purely from images. However, this setting poses a fundamental question: which visual encoders obtain representations that retain information critical for decision making? To answer this question, we conduct a systematic study of imitation learning with publicly available pre-trained visual encoders compared to the typical task-specific end-to-end training approach in Minecraft, Counter-Strike: Global Offensive, and Minecraft Dungeons. Our results show that end-to-end training can be effective with comparably low-resolution images and only minutes of demonstrations, but significant improvements can be gained by utilising pre-trained encoders such as DINOv2 depending on the game. In addition to enabling effective decision making, we show that pre-trained encoders can make decision-making research in video games more accessible by significantly reducing the cost of training.",
    "summary": "arXiv:2312.02312v3 Announce Type: replace-cross Abstract: Video games have served as useful benchmarks for the decision-making community, but going beyond Atari games towards modern games has been prohibitively expensive for the vast majority of the research community. Prior work in modern video games typically relied on game-specific integration to obtain game features and enable online training, or on existing large datasets. An alternative approach is to train agents using imitation learning to play video games purely from images. However, this setting poses a fundamental question: which visual encoders obtain representations that retain information critical for decision making? To answer this question, we conduct a systematic study of imitation learning with publicly available pre-trained visual encoders compared to the typical task-specific end-to-end training approach in Minecraft, Counter-Strike: Global Offensive, and Minecraft Dungeons. Our results show that end-to-end training can be effective with comparably low-resolution images and only minutes of demonstrations, but significant improvements can be gained by utilising pre-trained encoders such as DINOv2 depending on the game. In addition to enabling effective decision making, we show that pre-trained encoders can make decision-making research in video games more accessible by significantly reducing the cost of training.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2312.02312",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hyperparameter Search with Transformers and Ray Tune",
    "description": "",
    "summary": "Hyperparameter Search with Transformers and Ray Tune A guest blog post by Richard Liaw from the Anys...",
    "pubDate": "Mon, 02 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ray-tune",
    "thumbnail": "https://huggingface.co/blog/assets/06_ray_tune/ray-hf.jpg"
  },
  {
    "title": "Learning Dynamics of LLM Finetuning",
    "description": "arXiv:2407.10490v4 Announce Type: replace-cross Abstract: Learning dynamics, which describes how the learning of specific training examples influences the model's predictions on other examples, gives us a powerful tool for understanding the behavior of deep learning systems. We study the learning dynamics of large language models during different types of finetuning, by analyzing the step-wise decomposition of how influence accumulates among different potential responses. Our framework allows a uniform interpretation of many interesting observations about the training of popular algorithms for both instruction tuning and preference tuning. In particular, we propose a hypothetical explanation of why specific types of hallucination are strengthened after finetuning, e.g., the model might use phrases or facts in the response for question B to answer question A, or the model might keep repeating similar simple phrases when generating responses. We also extend our framework and highlight a unique 'squeezing effect' to explain a previously observed phenomenon in off-policy direct preference optimization (DPO), where running DPO for too long makes even the desired outputs less likely. This framework also provides insights into where the benefits of on-policy DPO and other variants come from. The analysis not only provides a novel perspective of understanding LLM's finetuning but also inspires a simple, effective method to improve alignment performance.",
    "summary": "arXiv:2407.10490v4 Announce Type: replace-cross Abstract: Learning dynamics, which describes how the learning of specific training examples influences the model's predictions on other examples, gives us a powerful tool for understanding the behavior of deep learning systems. We study the learning dynamics of large language models during different types of finetuning, by analyzing the step-wise decomposition of how influence accumulates among different potential responses. Our framework allows a uniform interpretation of many interesting observations about the training of popular algorithms for both instruction tuning and preference tuning. In particular, we propose a hypothetical explanation of why specific types of hallucination are strengthened after finetuning, e.g., the model might use phrases or facts in the response for question B to answer question A, or the model might keep repeating similar simple phrases when generating responses. We also extend our framework and highlight a unique 'squeezing effect' to explain a previously observed phenomenon in off-policy direct preference optimization (DPO), where running DPO for too long makes even the desired outputs less likely. This framework also provides insights into where the benefits of on-policy DPO and other variants come from. The analysis not only provides a novel perspective of understanding LLM's finetuning but also inspires a simple, effective method to improve alignment performance.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.10490",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing",
    "description": "arXiv:2404.19543v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have catalyzed significant advancements in Natural Language Processing (NLP), yet they encounter challenges such as hallucination and the need for domain-specific knowledge. To mitigate these, recent methodologies have integrated information retrieved from external resources with LLMs, substantially enhancing their performance across NLP tasks. This survey paper addresses the absence of a comprehensive overview on Retrieval-Augmented Language Models (RALMs), both Retrieval-Augmented Generation (RAG) and Retrieval-Augmented Understanding (RAU), providing an in-depth examination of their paradigm, evolution, taxonomy, and applications. The paper discusses the essential components of RALMs, including Retrievers, Language Models, and Augmentations, and how their interactions lead to diverse model structures and applications. RALMs demonstrate utility in a spectrum of tasks, from translation and dialogue systems to knowledge-intensive applications. The survey includes several evaluation methods of RALMs, emphasizing the importance of robustness, accuracy, and relevance in their assessment. It also acknowledges the limitations of RALMs, particularly in retrieval quality and computational efficiency, offering directions for future research. In conclusion, this survey aims to offer a structured insight into RALMs, their potential, and the avenues for their future development in NLP. The paper is supplemented with a Github Repository containing the surveyed works and resources for further study: https://github.com/2471023025/RALM_Survey.",
    "summary": "arXiv:2404.19543v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have catalyzed significant advancements in Natural Language Processing (NLP), yet they encounter challenges such as hallucination and the need for domain-specific knowledge. To mitigate these, recent methodologies have integrated information retrieved from external resources with LLMs, substantially enhancing their performance across NLP tasks. This survey paper addresses the absence of a comprehensive overview on Retrieval-Augmented Language Models (RALMs), both Retrieval-Augmented Generation (RAG) and Retrieval-Augmented Understanding (RAU), providing an in-depth examination of their paradigm, evolution, taxonomy, and applications. The paper discusses the essential components of RALMs, including Retrievers, Language Models, and Augmentations, and how their interactions lead to diverse model structures and applications. RALMs demonstrate utility in a spectrum of tasks, from translation and dialogue systems to knowledge-intensive applications. The survey includes several evaluation methods of RALMs, emphasizing the importance of robustness, accuracy, and relevance in their assessment. It also acknowledges the limitations of RALMs, particularly in retrieval quality and computational efficiency, offering directions for future research. In conclusion, this survey aims to offer a structured insight into RALMs, their potential, and the avenues for their future development in NLP. The paper is supplemented with a Github Repository containing the surveyed works and resources for further study: https://github.com/2471023025/RALM_Survey.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2404.19543",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Dive into Text-to-Video Models",
    "description": "",
    "summary": "Text-to-Video: The Task, Challenges and the Current State Video samples generated with ModelScope. T...",
    "pubDate": "Mon, 08 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-to-video",
    "thumbnail": "https://huggingface.co/blog/assets/140_text-to-video/thumbnail.png"
  },
  {
    "title": "2023: A Year of Groundbreaking Advances in AI and Computing",
    "description": "This has been a year of incredible progress in the field of Artificial Intelligence (AI) research and its practical applications.",
    "summary": "This has been a year of incredible progress in the field of Artificial Intelligence (AI) research and its practical applications.",
    "pubDate": "Fri, 22 Dec 2023 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/2023-a-year-of-groundbreaking-advances-in-ai-and-computing/",
    "thumbnail": "https://lh3.googleusercontent.com/fkZqqqpfLKvV2E6ebVmYJjR9q9XnczvWtiui5uU-yPkHCQb5mLAB4kBmh3opGqOJLhtaC58td96UtvULI8uGpbB9TmejR82GZ2vWOqTyWZ6HSItIpHg=w1200-h630-n-nu"
  },
  {
    "title": "Perceiver IO: a scalable, fully-attentional model that works on any modality",
    "description": "",
    "summary": "Perceiver IO: a scalable, fully-attentional model that works on any modality TLDR We've added Percei...",
    "pubDate": "Wed, 15 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/perceiver",
    "thumbnail": "https://huggingface.co/blog/assets/41_perceiver/thumbnail.png"
  },
  {
    "title": "Introducing HELMET",
    "description": "",
    "summary": "Introducing HELMET: Holistically Evaluating Long-context Language Models Contact: hyen@cs.princeton....",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/helmet",
    "thumbnail": "https://huggingface.co/blog/assets/helmet/thumbnail.png"
  },
  {
    "title": "FreeDNA: Endowing Domain Adaptation of Diffusion-Based Dense Prediction with Training-Free Domain Noise Alignment",
    "description": "arXiv:2506.22509v1 Announce Type: cross Abstract: Domain Adaptation(DA) for dense prediction tasks is an important topic, which enhances the dense prediction model's performance when tested on its unseen domain. Recently, with the development of Diffusion-based Dense Prediction (DDP) models, the exploration of DA designs tailored to this framework is worth exploring, since the diffusion model is effective in modeling the distribution transformation that comprises domain information. In this work, we propose a training-free mechanism for DDP frameworks, endowing them with DA capabilities. Our motivation arises from the observation that the exposure bias (e.g., noise statistics bias) in diffusion brings domain shift, and different domains in conditions of DDP models can also be effectively captured by the noise prediction statistics. Based on this, we propose a training-free Domain Noise Alignment (DNA) approach, which alleviates the variations of noise statistics to domain changes during the diffusion sampling process, thereby achieving domain adaptation. Specifically, when the source domain is available, we directly adopt the DNA method to achieve domain adaptation by aligning the noise statistics of the target domain with those of the source domain. For the more challenging source-free DA, inspired by the observation that regions closer to the source domain exhibit higher confidence meeting variations of sampling noise, we utilize the statistics from the high-confidence regions progressively to guide the noise statistic adjustment during the sampling process. Notably, our method demonstrates the effectiveness of enhancing the DA capability of DDP models across four common dense prediction tasks. Code is available at href{https://github.com/xuhang07/FreeDNA}{https://github.com/xuhang07/FreeDNA}.",
    "summary": "arXiv:2506.22509v1 Announce Type: cross Abstract: Domain Adaptation(DA) for dense prediction tasks is an important topic, which enhances the dense prediction model's performance when tested on its unseen domain. Recently, with the development of Diffusion-based Dense Prediction (DDP) models, the exploration of DA designs tailored to this framework is worth exploring, since the diffusion model is effective in modeling the distribution transformation that comprises domain information. In this work, we propose a training-free mechanism for DDP frameworks, endowing them with DA capabilities. Our motivation arises from the observation that the exposure bias (e.g., noise statistics bias) in diffusion brings domain shift, and different domains in conditions of DDP models can also be effectively captured by the noise prediction statistics. Based on this, we propose a training-free Domain Noise Alignment (DNA) approach, which alleviates the variations of noise statistics to domain changes during the diffusion sampling process, thereby achieving domain adaptation. Specifically, when the source domain is available, we directly adopt the DNA method to achieve domain adaptation by aligning the noise statistics of the target domain with those of the source domain. For the more challenging source-free DA, inspired by the observation that regions closer to the source domain exhibit higher confidence meeting variations of sampling noise, we utilize the statistics from the high-confidence regions progressively to guide the noise statistic adjustment during the sampling process. Notably, our method demonstrates the effectiveness of enhancing the DA capability of DDP models across four common dense prediction tasks. Code is available at href{https://github.com/xuhang07/FreeDNA}{https://github.com/xuhang07/FreeDNA}.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22509",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using GPT-4 to deliver a new customer service standard",
    "description": "Ada uses GPT-4 to deliver a new customer service standard",
    "summary": "Ada uses GPT-4 to deliver a new customer service standard",
    "pubDate": "Thu, 05 Sep 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ada",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generative modeling with sparse transformers",
    "description": "We‚Äôve developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence‚Äîwhether text, images, or sound. It uses an algorithmic improvement of the¬†attention¬†mechanism to extract patterns from sequences 30x longer than possible¬†previously.",
    "summary": "We‚Äôve developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence‚Äîwhether text, images, or sound. It uses an algorithmic improvement of the¬†attention¬†mechanism to extract patterns from sequences 30x longer than possible¬†previously.",
    "pubDate": "Tue, 23 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sparse-transformer",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Constructing Non-Markovian Decision Process via History Aggregator",
    "description": "arXiv:2506.24026v1 Announce Type: new Abstract: In the domain of algorithmic decision-making, non-Markovian dynamics manifest as a significant impediment, especially for paradigms such as Reinforcement Learning (RL), thereby exerting far-reaching consequences on the advancement and effectiveness of the associated systems. Nevertheless, the existing benchmarks are deficient in comprehensively assessing the capacity of decision algorithms to handle non-Markovian dynamics. To address this deficiency, we have devised a generalized methodology grounded in category theory. Notably, we established the category of Markov Decision Processes (MDP) and the category of non-Markovian Decision Processes (NMDP), and proved the equivalence relationship between them. This theoretical foundation provides a novel perspective for understanding and addressing non-Markovian dynamics. We further introduced non-Markovianity into decision-making problem settings via the History Aggregator for State (HAS). With HAS, we can precisely control the state dependency structure of decision-making problems in the time series. Our analysis demonstrates the effectiveness of our method in representing a broad range of non-Markovian dynamics. This approach facilitates a more rigorous and flexible evaluation of decision algorithms by testing them in problem settings where non-Markovian dynamics are explicitly constructed.",
    "summary": "arXiv:2506.24026v1 Announce Type: new Abstract: In the domain of algorithmic decision-making, non-Markovian dynamics manifest as a significant impediment, especially for paradigms such as Reinforcement Learning (RL), thereby exerting far-reaching consequences on the advancement and effectiveness of the associated systems. Nevertheless, the existing benchmarks are deficient in comprehensively assessing the capacity of decision algorithms to handle non-Markovian dynamics. To address this deficiency, we have devised a generalized methodology grounded in category theory. Notably, we established the category of Markov Decision Processes (MDP) and the category of non-Markovian Decision Processes (NMDP), and proved the equivalence relationship between them. This theoretical foundation provides a novel perspective for understanding and addressing non-Markovian dynamics. We further introduced non-Markovianity into decision-making problem settings via the History Aggregator for State (HAS). With HAS, we can precisely control the state dependency structure of decision-making problems in the time series. Our analysis demonstrates the effectiveness of our method in representing a broad range of non-Markovian dynamics. This approach facilitates a more rigorous and flexible evaluation of decision algorithms by testing them in problem settings where non-Markovian dynamics are explicitly constructed.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.24026",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "KMI: A Dataset of Korean Motivational Interviewing Dialogues for Psychotherapy",
    "description": "arXiv:2502.05651v2 Announce Type: replace-cross Abstract: The increasing demand for mental health services has led to the rise of AI-driven mental health chatbots, though challenges related to privacy, data collection, and expertise persist. Motivational Interviewing (MI) is gaining attention as a theoretical basis for boosting expertise in the development of these chatbots. However, existing datasets are showing limitations for training chatbots, leading to a substantial demand for publicly available resources in the field of MI and psychotherapy. These challenges are even more pronounced in non-English languages, where they receive less attention. In this paper, we propose a novel framework that simulates MI sessions enriched with the expertise of professional therapists. We train an MI forecaster model that mimics the behavioral choices of professional therapists and employ Large Language Models (LLMs) to generate utterances through prompt engineering. Then, we present KMI, the first synthetic dataset theoretically grounded in MI, containing 1,000 high-quality Korean Motivational Interviewing dialogues. Through an extensive expert evaluation of the generated dataset and the dialogue model trained on it, we demonstrate the quality, expertise, and practicality of KMI. We also introduce novel metrics derived from MI theory in order to evaluate dialogues from the perspective of MI.",
    "summary": "arXiv:2502.05651v2 Announce Type: replace-cross Abstract: The increasing demand for mental health services has led to the rise of AI-driven mental health chatbots, though challenges related to privacy, data collection, and expertise persist. Motivational Interviewing (MI) is gaining attention as a theoretical basis for boosting expertise in the development of these chatbots. However, existing datasets are showing limitations for training chatbots, leading to a substantial demand for publicly available resources in the field of MI and psychotherapy. These challenges are even more pronounced in non-English languages, where they receive less attention. In this paper, we propose a novel framework that simulates MI sessions enriched with the expertise of professional therapists. We train an MI forecaster model that mimics the behavioral choices of professional therapists and employ Large Language Models (LLMs) to generate utterances through prompt engineering. Then, we present KMI, the first synthetic dataset theoretically grounded in MI, containing 1,000 high-quality Korean Motivational Interviewing dialogues. Through an extensive expert evaluation of the generated dataset and the dialogue model trained on it, we demonstrate the quality, expertise, and practicality of KMI. We also introduce novel metrics derived from MI theory in order to evaluate dialogues from the perspective of MI.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.05651",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems",
    "description": "arXiv:2506.04133v2 Announce Type: replace Abstract: Agentic AI systems, built upon large language models (LLMs) and deployed in multi-agent configurations, are redefining intelligence, autonomy, collaboration, and decision-making across enterprise and societal domains. This review presents a structured analysis of textbf{Trust, Risk, and Security Management (TRiSM)} in the context of LLM-based Agentic Multi-Agent Systems (AMAS). We begin by examining the conceptual foundations of Agentic AI and highlight its architectural distinctions from traditional AI agents. We then adapt and extend the AI TRiSM framework for Agentic AI, structured around four key pillars: Governance, Explainability, ModelOps, and Privacy/Security , each contextualized to the challenges of multi-agent LLM systems. A novel risk taxonomy is proposed to capture the unique threats and vulnerabilities of Agentic AI, ranging from coordination failures to prompt-based adversarial manipulation. To support practical assessment in Agentic AI works, we introduce two novel metrics: the Component Synergy Score (CSS), which quantifies the quality of inter-agent collaboration, and the Tool Utilization Efficacy (TUE), which evaluates the efficiency of tool use within agent workflows. We further discuss strategies for improving explainability in Agentic AI , as well as approaches to enhancing security and privacy through encryption, adversarial robustness, and regulatory compliance. The review concludes with a research roadmap for the responsible development and deployment of Agentic AI, outlining critical directions to align emerging systems with TRiSM principles for safe, transparent, and accountable operation.",
    "summary": "arXiv:2506.04133v2 Announce Type: replace Abstract: Agentic AI systems, built upon large language models (LLMs) and deployed in multi-agent configurations, are redefining intelligence, autonomy, collaboration, and decision-making across enterprise and societal domains. This review presents a structured analysis of textbf{Trust, Risk, and Security Management (TRiSM)} in the context of LLM-based Agentic Multi-Agent Systems (AMAS). We begin by examining the conceptual foundations of Agentic AI and highlight its architectural distinctions from traditional AI agents. We then adapt and extend the AI TRiSM framework for Agentic AI, structured around four key pillars: Governance, Explainability, ModelOps, and Privacy/Security , each contextualized to the challenges of multi-agent LLM systems. A novel risk taxonomy is proposed to capture the unique threats and vulnerabilities of Agentic AI, ranging from coordination failures to prompt-based adversarial manipulation. To support practical assessment in Agentic AI works, we introduce two novel metrics: the Component Synergy Score (CSS), which quantifies the quality of inter-agent collaboration, and the Tool Utilization Efficacy (TUE), which evaluates the efficiency of tool use within agent workflows. We further discuss strategies for improving explainability in Agentic AI , as well as approaches to enhancing security and privacy through encryption, adversarial robustness, and regulatory compliance. The review concludes with a research roadmap for the responsible development and deployment of Agentic AI, outlining critical directions to align emerging systems with TRiSM principles for safe, transparent, and accountable operation.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.04133",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games",
    "description": "arXiv:2506.23276v1 Announce Type: new Abstract: As large language models (LLMs) are increasingly deployed as autonomous agents, understanding their cooperation and social mechanisms is becoming increasingly important. In particular, how LLMs balance self-interest and collective well-being is a critical challenge for ensuring alignment, robustness, and safe deployment. In this paper, we examine the challenge of costly sanctioning in multi-agent LLM systems, where an agent must decide whether to invest its own resources to incentivize cooperation or penalize defection. To study this, we adapt a public goods game with institutional choice from behavioral economics, allowing us to observe how different LLMs navigate social dilemmas over repeated interactions. Our analysis reveals four distinct behavioral patterns among models: some consistently establish and sustain high levels of cooperation, others fluctuate between engagement and disengagement, some gradually decline in cooperative behavior over time, and others rigidly follow fixed strategies regardless of outcomes. Surprisingly, we find that reasoning LLMs, such as the o1 series, struggle significantly with cooperation, whereas some traditional LLMs consistently achieve high levels of cooperation. These findings suggest that the current approach to improving LLMs, which focuses on enhancing their reasoning capabilities, does not necessarily lead to cooperation, providing valuable insights for deploying LLM agents in environments that require sustained collaboration. Our code is available at https://github.com/davidguzmanp/SanctSim",
    "summary": "arXiv:2506.23276v1 Announce Type: new Abstract: As large language models (LLMs) are increasingly deployed as autonomous agents, understanding their cooperation and social mechanisms is becoming increasingly important. In particular, how LLMs balance self-interest and collective well-being is a critical challenge for ensuring alignment, robustness, and safe deployment. In this paper, we examine the challenge of costly sanctioning in multi-agent LLM systems, where an agent must decide whether to invest its own resources to incentivize cooperation or penalize defection. To study this, we adapt a public goods game with institutional choice from behavioral economics, allowing us to observe how different LLMs navigate social dilemmas over repeated interactions. Our analysis reveals four distinct behavioral patterns among models: some consistently establish and sustain high levels of cooperation, others fluctuate between engagement and disengagement, some gradually decline in cooperative behavior over time, and others rigidly follow fixed strategies regardless of outcomes. Surprisingly, we find that reasoning LLMs, such as the o1 series, struggle significantly with cooperation, whereas some traditional LLMs consistently achieve high levels of cooperation. These findings suggest that the current approach to improving LLMs, which focuses on enhancing their reasoning capabilities, does not necessarily lead to cooperation, providing valuable insights for deploying LLM agents in environments that require sustained collaboration. Our code is available at https://github.com/davidguzmanp/SanctSim",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23276",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Creating nail art with ChatGPT",
    "description": "Using ChatGPT to find inspiration for nail art",
    "summary": "Using ChatGPT to find inspiration for nail art",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ten-tiny-canvases",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Start using ChatGPT instantly",
    "description": "We‚Äôre making it easier for people to experience the benefits of AI without needing to sign up",
    "summary": "We‚Äôre making it easier for people to experience the benefits of AI without needing to sign up",
    "pubDate": "Mon, 01 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/start-using-chatgpt-instantly",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "What's going on with the Open LLM Leaderboard?",
    "description": "",
    "summary": "What's going on with the Open LLM Leaderboard? Recently an interesting discussion arose on Twitter f...",
    "pubDate": "Fri, 23 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-mmlu",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "Addendum to o3 and o4-mini system card: Codex",
    "description": "Codex is a cloud-based coding agent. Codex is powered by codex-1, a version of OpenAI o3 optimized for software engineering. codex-1 was trained using reinforcement learning on real-world coding tasks in a variety of environments to generate code that closely mirrors human style and PR preferences, adheres precisely to instructions, and iteratively runs tests until passing results are achieved.",
    "summary": "Codex is a cloud-based coding agent. Codex is powered by codex-1, a version of OpenAI o3 optimized for software engineering. codex-1 was trained using reinforcement learning on real-world coding tasks in a variety of environments to generate code that closely mirrors human style and PR preferences, adheres precisely to instructions, and iteratively runs tests until passing results are achieved.",
    "pubDate": "Fri, 16 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-codex-system-card-addendum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hallucination Detection with Small Language Models",
    "description": "arXiv:2506.22486v1 Announce Type: cross Abstract: Since the introduction of ChatGPT, large language models (LLMs) have demonstrated significant utility in various tasks, such as answering questions through retrieval-augmented generation. Context can be retrieved using a vectorized database, serving as a foundation for LLMs to generate responses. However, hallucinations in responses can undermine the reliability of LLMs in practical applications, and they are not easily detectable in the absence of ground truth, particularly in question-and-answer scenarios. This paper proposes a framework that integrates multiple small language models to verify responses generated by LLMs using the retrieved context from a vectorized database. By breaking down the responses into individual sentences and utilizing the probability of generating 'Yes' tokens from the outputs of multiple models for a given set of questions, responses, and relevant context, hallucinations can be detected. The proposed framework is validated through experiments with real datasets comprising over 100 sets of questions, answers, and contexts, including responses with fully and partially correct sentences. The results demonstrate a 10% improvement in F1 scores for detecting correct responses compared to hallucinations, indicating that multiple small language models can be effectively employed for answer verification, providing a scalable and efficient solution for both academic and practical applications.",
    "summary": "arXiv:2506.22486v1 Announce Type: cross Abstract: Since the introduction of ChatGPT, large language models (LLMs) have demonstrated significant utility in various tasks, such as answering questions through retrieval-augmented generation. Context can be retrieved using a vectorized database, serving as a foundation for LLMs to generate responses. However, hallucinations in responses can undermine the reliability of LLMs in practical applications, and they are not easily detectable in the absence of ground truth, particularly in question-and-answer scenarios. This paper proposes a framework that integrates multiple small language models to verify responses generated by LLMs using the retrieved context from a vectorized database. By breaking down the responses into individual sentences and utilizing the probability of generating 'Yes' tokens from the outputs of multiple models for a given set of questions, responses, and relevant context, hallucinations can be detected. The proposed framework is validated through experiments with real datasets comprising over 100 sets of questions, answers, and contexts, including responses with fully and partially correct sentences. The results demonstrate a 10% improvement in F1 scores for detecting correct responses compared to hallucinations, indicating that multiple small language models can be effectively employed for answer verification, providing a scalable and efficient solution for both academic and practical applications.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22486",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GPT-4V(ision) system card",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4v-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Confidence Paradox: Can LLM Know When It's Wrong",
    "description": "arXiv:2506.23464v1 Announce Type: new Abstract: Document Visual Question Answering (DocVQA) systems are increasingly deployed in real world applications, yet they remain ethically opaque-often producing overconfident answers to ambiguous questions or failing to communicate uncertainty in a trustworthy manner. This misalignment between model confidence and actual knowledge poses significant risks, particularly in domains requiring ethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT have advanced SOTA performance by focusing on architectural sophistication and accuracy; however, they fall short in ethical responsiveness. To address these limitations, we introduce HonestVQA, a self-supervised honesty calibration framework for ethically aligned DocVQA. Our model-agnostic method quantifies uncertainty to identify knowledge gaps, aligns model confidence with actual correctness using weighted loss functions, and enforces ethical response behavior via contrastive learning. We further introduce two principled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence Index (ECI)--to benchmark alignment between confidence, accuracy, and ethical communication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3% and F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces overconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In cross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score, demonstrating strong generalization. Ablation shows a 3.8% drop in accuracy without alignment or contrastive loss.",
    "summary": "arXiv:2506.23464v1 Announce Type: new Abstract: Document Visual Question Answering (DocVQA) systems are increasingly deployed in real world applications, yet they remain ethically opaque-often producing overconfident answers to ambiguous questions or failing to communicate uncertainty in a trustworthy manner. This misalignment between model confidence and actual knowledge poses significant risks, particularly in domains requiring ethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT have advanced SOTA performance by focusing on architectural sophistication and accuracy; however, they fall short in ethical responsiveness. To address these limitations, we introduce HonestVQA, a self-supervised honesty calibration framework for ethically aligned DocVQA. Our model-agnostic method quantifies uncertainty to identify knowledge gaps, aligns model confidence with actual correctness using weighted loss functions, and enforces ethical response behavior via contrastive learning. We further introduce two principled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence Index (ECI)--to benchmark alignment between confidence, accuracy, and ethical communication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3% and F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces overconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In cross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score, demonstrating strong generalization. Ablation shows a 3.8% drop in accuracy without alignment or contrastive loss.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23464",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deep Unlearn: Benchmarking Machine Unlearning for Image Classification",
    "description": "arXiv:2410.01276v2 Announce Type: replace-cross Abstract: Machine unlearning (MU) aims to remove the influence of particular data points from the learnable parameters of a trained machine learning model. This is a crucial capability in light of data privacy requirements, trustworthiness, and safety in deployed models. MU is particularly challenging for deep neural networks (DNNs), such as convolutional nets or vision transformers, as such DNNs tend to memorize a notable portion of their training dataset. Nevertheless, the community lacks a rigorous and multifaceted study that looks into the success of MU methods for DNNs. In this paper, we investigate 18 state-of-the-art MU methods across various benchmark datasets and models, with each evaluation conducted over 10 different initializations, a comprehensive evaluation involving MU over 100K models. We show that, with the proper hyperparameters, Masked Small Gradients (MSG) and Convolution Transpose (CT), consistently perform better in terms of model accuracy and run-time efficiency across different models, datasets, and initializations, assessed by population-based membership inference attacks (MIA) and per-sample unlearning likelihood ratio attacks (U-LiRA). Furthermore, our benchmark highlights the fact that comparing a MU method only with commonly used baselines, such as Gradient Ascent (GA) or Successive Random Relabeling (SRL), is inadequate, and we need better baselines like Negative Gradient Plus (NG+) with proper hyperparameter selection.",
    "summary": "arXiv:2410.01276v2 Announce Type: replace-cross Abstract: Machine unlearning (MU) aims to remove the influence of particular data points from the learnable parameters of a trained machine learning model. This is a crucial capability in light of data privacy requirements, trustworthiness, and safety in deployed models. MU is particularly challenging for deep neural networks (DNNs), such as convolutional nets or vision transformers, as such DNNs tend to memorize a notable portion of their training dataset. Nevertheless, the community lacks a rigorous and multifaceted study that looks into the success of MU methods for DNNs. In this paper, we investigate 18 state-of-the-art MU methods across various benchmark datasets and models, with each evaluation conducted over 10 different initializations, a comprehensive evaluation involving MU over 100K models. We show that, with the proper hyperparameters, Masked Small Gradients (MSG) and Convolution Transpose (CT), consistently perform better in terms of model accuracy and run-time efficiency across different models, datasets, and initializations, assessed by population-based membership inference attacks (MIA) and per-sample unlearning likelihood ratio attacks (U-LiRA). Furthermore, our benchmark highlights the fact that comparing a MU method only with commonly used baselines, such as Gradient Ascent (GA) or Successive Random Relabeling (SRL), is inadequate, and we need better baselines like Negative Gradient Plus (NG+) with proper hyperparameter selection.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.01276",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Brain-inspired and Self-based Artificial Intelligence",
    "description": "arXiv:2402.18784v2 Announce Type: replace Abstract: The question 'Can machines think?' and the Turing Test to assess whether machines could achieve human-level intelligence is one of the roots of AI. With the philosophical argument 'I think, therefore I am', this paper challenge the idea of a 'thinking machine' supported by current AIs since there is no sense of self in them. Current artificial intelligence is only seemingly intelligent information processing and does not truly understand or be subjectively aware of oneself and perceive the world with the self as human intelligence does. In this paper, we introduce a Brain-inspired and Self-based Artificial Intelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to coordinating various cognitive functions and learning strategies in a self-organized manner to build human-level AI models and robotic applications. Specifically, BriSe AI emphasizes the crucial role of the Self in shaping the future AI, rooted with a practical hierarchical Self framework, including Perception and Learning, Bodily Self, Autonomous Self, Social Self, and Conceptual Self. The hierarchical framework of the Self highlights self-based environment perception, self-bodily modeling, autonomous interaction with the environment, social interaction and collaboration with others, and even more abstract understanding of the Self. Furthermore, the positive mutual promotion and support among multiple levels of Self, as well as between Self and learning, enhance the BriSe AI's conscious understanding of information and flexible adaptation to complex environments, serving as a driving force propelling BriSe AI towards real Artificial General Intelligence.",
    "summary": "arXiv:2402.18784v2 Announce Type: replace Abstract: The question 'Can machines think?' and the Turing Test to assess whether machines could achieve human-level intelligence is one of the roots of AI. With the philosophical argument 'I think, therefore I am', this paper challenge the idea of a 'thinking machine' supported by current AIs since there is no sense of self in them. Current artificial intelligence is only seemingly intelligent information processing and does not truly understand or be subjectively aware of oneself and perceive the world with the self as human intelligence does. In this paper, we introduce a Brain-inspired and Self-based Artificial Intelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to coordinating various cognitive functions and learning strategies in a self-organized manner to build human-level AI models and robotic applications. Specifically, BriSe AI emphasizes the crucial role of the Self in shaping the future AI, rooted with a practical hierarchical Self framework, including Perception and Learning, Bodily Self, Autonomous Self, Social Self, and Conceptual Self. The hierarchical framework of the Self highlights self-based environment perception, self-bodily modeling, autonomous interaction with the environment, social interaction and collaboration with others, and even more abstract understanding of the Self. Furthermore, the positive mutual promotion and support among multiple levels of Self, as well as between Self and learning, enhance the BriSe AI's conscious understanding of information and flexible adaptation to complex environments, serving as a driving force propelling BriSe AI towards real Artificial General Intelligence.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2402.18784",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face and FriendliAI partner to supercharge model deployment on the Hub",
    "description": "",
    "summary": "Hugging Face and FriendliAI partner to supercharge model deployment on the Hub FriendliAI‚Äôs inferenc...",
    "pubDate": "Wed, 22 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/friendliai-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/friendliai-partnership/thumbnail.png"
  },
  {
    "title": "Introducing deep research",
    "description": "An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.",
    "summary": "An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.",
    "pubDate": "Sun, 02 Feb 2025 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-deep-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and AMD partner on accelerating state-of-the-art models for CPU and GPU platforms",
    "description": "",
    "summary": "Hugging Face and AMD partner on accelerating state-of-the-art models for CPU and GPU platforms Wheth...",
    "pubDate": "Tue, 13 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-amd",
    "thumbnail": "https://huggingface.co/blog/assets/148_huggingface_amd/01.png"
  },
  {
    "title": "Preference Tuning LLMs with Direct Preference Optimization Methods",
    "description": "",
    "summary": "Preference Tuning LLMs with Direct Preference Optimization Methods Addendum After consulting with th...",
    "pubDate": "Thu, 18 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pref-tuning",
    "thumbnail": "https://huggingface.co/blog/assets/pref-tuning/thumbnail.jpg"
  },
  {
    "title": "Controlling Language Model Generation with NVIDIA's LogitsProcessorZoo",
    "description": "",
    "summary": "Controlling Language Model Generation with NVIDIA's LogitsProcessorZoo Generating text with language...",
    "pubDate": "Mon, 23 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/logits-processor-zoo",
    "thumbnail": "https://huggingface.co/blog/assets/logits-processor-zoo/thumbnail.png"
  },
  {
    "title": "Optimization story: Bloom inference",
    "description": "",
    "summary": "Optimization story: Bloom inference This article gives you the behind-the-scenes of how we made an e...",
    "pubDate": "Wed, 12 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-inference-optimization",
    "thumbnail": "https://huggingface.co/blog/assets/bloom-inference-pytorch-scripts/thumbnail.png"
  },
  {
    "title": "Layer Importance for Mathematical Reasoning is Forged in Pre-Training and Invariant after Post-Training",
    "description": "arXiv:2506.22638v1 Announce Type: cross Abstract: Large language models can exhibit improved mathematical reasoning capabilities following post-training with instruction tuning, reinforcement learning, or knowledge distillation. However, it remains unclear whether these improvements are driven by major changes in transformer layers or from minor adjustments that leave the relative layer importance structures of the base model largely unchanged. We investigate this question through systematic layer-wise ablation experiments, examining base, instruction-tuned, knowledge-distilled, and reinforcement learning variants on mathematical reasoning benchmarks. Our findings show that mathematical reasoning gives rise to a specific layer importance structure, and this structure persists across all post-training paradigms. Removal of such layers causes accuracy drops of up to 80%. In contrast, non-mathematical tasks like factual recall exhibit no critical layers. This distinction suggests that mathematical reasoning requires specialized layers that emerge during pre-training, while other non-reasoning tasks do not. From an information-theoretic perspective, we also observe that these critical layers are the same layers where major representational transformation occurs.",
    "summary": "arXiv:2506.22638v1 Announce Type: cross Abstract: Large language models can exhibit improved mathematical reasoning capabilities following post-training with instruction tuning, reinforcement learning, or knowledge distillation. However, it remains unclear whether these improvements are driven by major changes in transformer layers or from minor adjustments that leave the relative layer importance structures of the base model largely unchanged. We investigate this question through systematic layer-wise ablation experiments, examining base, instruction-tuned, knowledge-distilled, and reinforcement learning variants on mathematical reasoning benchmarks. Our findings show that mathematical reasoning gives rise to a specific layer importance structure, and this structure persists across all post-training paradigms. Removal of such layers causes accuracy drops of up to 80%. In contrast, non-mathematical tasks like factual recall exhibit no critical layers. This distinction suggests that mathematical reasoning requires specialized layers that emerge during pre-training, while other non-reasoning tasks do not. From an information-theoretic perspective, we also observe that these critical layers are the same layers where major representational transformation occurs.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22638",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DALL¬∑E 2 pre-training mitigations",
    "description": "In order to share the magic of¬†DALL¬∑E 2¬†with a broad audience, we needed to reduce the risks associated with powerful image generation models. To this end, we put various¬†guardrails¬†in place to prevent generated images from violating our¬†content policy.",
    "summary": "In order to share the magic of¬†DALL¬∑E 2¬†with a broad audience, we needed to reduce the risks associated with powerful image generation models. To this end, we put various¬†guardrails¬†in place to prevent generated images from violating our¬†content policy.",
    "pubDate": "Tue, 28 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-pre-training-mitigations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Multi-Branch DNN and CRLB-Ratio-Weight Fusion for Enhanced DOA Sensing via a Massive H$^2$AD MIMO Receiver",
    "description": "arXiv:2506.23203v1 Announce Type: cross Abstract: As a green MIMO structure, massive H$^2$AD is viewed as a potential technology for the future 6G wireless network. For such a structure, it is a challenging task to design a low-complexity and high-performance fusion of target direction values sensed by different sub-array groups with fewer use of prior knowledge. To address this issue, a lightweight Cramer-Rao lower bound (CRLB)-ratio-weight fusion (WF) method is proposed, which approximates inverse CRLB of each subarray using antenna number reciprocals to eliminate real-time CRLB computation. This reduces complexity and prior knowledge dependence while preserving fusion performance. Moreover, a multi-branch deep neural network (MBDNN) is constructed to further enhance direction-of-arrival (DOA) sensing by leveraging candidate angles from multiple subarrays. The subarray-specific branch networks are integrated with a shared regression module to effectively eliminate pseudo-solutions and fuse true angles. Simulation results show that the proposed CRLB-ratio-WF method achieves DOA sensing performance comparable to CRLB-based methods, while significantly reducing the reliance on prior knowledge. More notably, the proposed MBDNN has superior performance in low-SNR ranges. At SNR $= -15$ dB, it achieves an order-of-magnitude improvement in estimation accuracy compared to CRLB-ratio-WF method.",
    "summary": "arXiv:2506.23203v1 Announce Type: cross Abstract: As a green MIMO structure, massive H$^2$AD is viewed as a potential technology for the future 6G wireless network. For such a structure, it is a challenging task to design a low-complexity and high-performance fusion of target direction values sensed by different sub-array groups with fewer use of prior knowledge. To address this issue, a lightweight Cramer-Rao lower bound (CRLB)-ratio-weight fusion (WF) method is proposed, which approximates inverse CRLB of each subarray using antenna number reciprocals to eliminate real-time CRLB computation. This reduces complexity and prior knowledge dependence while preserving fusion performance. Moreover, a multi-branch deep neural network (MBDNN) is constructed to further enhance direction-of-arrival (DOA) sensing by leveraging candidate angles from multiple subarrays. The subarray-specific branch networks are integrated with a shared regression module to effectively eliminate pseudo-solutions and fuse true angles. Simulation results show that the proposed CRLB-ratio-WF method achieves DOA sensing performance comparable to CRLB-based methods, while significantly reducing the reliance on prior knowledge. More notably, the proposed MBDNN has superior performance in low-SNR ranges. At SNR $= -15$ dB, it achieves an order-of-magnitude improvement in estimation accuracy compared to CRLB-ratio-WF method.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23203",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Stable Diffusion in JAX/Flax üöÄ",
    "description": "",
    "summary": "üß® Stable Diffusion in JAX / Flax ! ü§ó Hugging Face Diffusers supports Flax since version 0.5.1 ! This...",
    "pubDate": "Thu, 13 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable_diffusion_jax",
    "thumbnail": "https://huggingface.co/blog/assets/108_stable_diffusion_jax/thumbnail.png"
  },
  {
    "title": "Creating agent and human collaboration with GPT 4o",
    "description": "Altera uses GPT-4o to build a new area of human collaboration",
    "summary": "Altera uses GPT-4o to build a new area of human collaboration",
    "pubDate": "Tue, 01 Oct 2024 09:59:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/altera",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Using LoRA for Efficient Stable Diffusion Fine-Tuning",
    "description": "",
    "summary": "Using LoRA for Efficient Stable Diffusion Fine-Tuning LoRA: Low-Rank Adaptation of Large Language Mo...",
    "pubDate": "Thu, 26 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lora",
    "thumbnail": "https://huggingface.co/blog/assets/lora/thumbnail.png"
  },
  {
    "title": "Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence",
    "description": "arXiv:2506.23908v1 Announce Type: new Abstract: Sound deductive reasoning -- the ability to derive new knowledge from existing facts and rules -- is an indisputably desirable aspect of general intelligence. Despite the major advances of AI systems in areas such as math and science, especially since the introduction of transformer architectures, it is well-documented that even the most advanced frontier systems regularly and consistently falter on easily-solvable deductive reasoning tasks. Hence, these systems are unfit to fulfill the dream of achieving artificial general intelligence capable of sound deductive reasoning. We argue that their unsound behavior is a consequence of the statistical learning approach powering their development. To overcome this, we contend that to achieve reliable deductive reasoning in learning-based AI systems, researchers must fundamentally shift from optimizing for statistical performance against distributions on reasoning problems and algorithmic tasks to embracing the more ambitious exact learning paradigm, which demands correctness on all inputs. We argue that exact learning is both essential and possible, and that this ambitious objective should guide algorithm design.",
    "summary": "arXiv:2506.23908v1 Announce Type: new Abstract: Sound deductive reasoning -- the ability to derive new knowledge from existing facts and rules -- is an indisputably desirable aspect of general intelligence. Despite the major advances of AI systems in areas such as math and science, especially since the introduction of transformer architectures, it is well-documented that even the most advanced frontier systems regularly and consistently falter on easily-solvable deductive reasoning tasks. Hence, these systems are unfit to fulfill the dream of achieving artificial general intelligence capable of sound deductive reasoning. We argue that their unsound behavior is a consequence of the statistical learning approach powering their development. To overcome this, we contend that to achieve reliable deductive reasoning in learning-based AI systems, researchers must fundamentally shift from optimizing for statistical performance against distributions on reasoning problems and algorithmic tasks to embracing the more ambitious exact learning paradigm, which demands correctness on all inputs. We argue that exact learning is both essential and possible, and that this ambitious objective should guide algorithm design.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23908",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FinStat2SQL: A Text2SQL Pipeline for Financial Statement Analysis",
    "description": "arXiv:2506.23273v1 Announce Type: new Abstract: Despite the advancements of large language models, text2sql still faces many challenges, particularly with complex and domain-specific queries. In finance, database designs and financial reporting layouts vary widely between financial entities and countries, making text2sql even more challenging. We present FinStat2SQL, a lightweight text2sql pipeline enabling natural language queries over financial statements. Tailored to local standards like VAS, it combines large and small language models in a multi-agent setup for entity extraction, SQL generation, and self-correction. We build a domain-specific database and evaluate models on a synthetic QA dataset. A fine-tuned 7B model achieves 61.33% accuracy with sub-4-second response times on consumer hardware, outperforming GPT-4o-mini. FinStat2SQL offers a scalable, cost-efficient solution for financial analysis, making AI-powered querying accessible to Vietnamese enterprises.",
    "summary": "arXiv:2506.23273v1 Announce Type: new Abstract: Despite the advancements of large language models, text2sql still faces many challenges, particularly with complex and domain-specific queries. In finance, database designs and financial reporting layouts vary widely between financial entities and countries, making text2sql even more challenging. We present FinStat2SQL, a lightweight text2sql pipeline enabling natural language queries over financial statements. Tailored to local standards like VAS, it combines large and small language models in a multi-agent setup for entity extraction, SQL generation, and self-correction. We build a domain-specific database and evaluate models on a synthetic QA dataset. A fine-tuned 7B model achieves 61.33% accuracy with sub-4-second response times on consumer hardware, outperforming GPT-4o-mini. FinStat2SQL offers a scalable, cost-efficient solution for financial analysis, making AI-powered querying accessible to Vietnamese enterprises.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23273",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "2024 Security Feature Highlights",
    "description": "",
    "summary": "2024 Security Feature Highlights Security is a top priority at Hugging Face, and we're committed to ...",
    "pubDate": "Tue, 06 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/2024-security-features",
    "thumbnail": "https://huggingface.co/blog/assets/2024-security-features/thumbnail.png"
  },
  {
    "title": "Learning from human preferences",
    "description": "One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind‚Äôs safety team, we‚Äôve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better.",
    "summary": "One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind‚Äôs safety team, we‚Äôve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better.",
    "pubDate": "Tue, 13 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-from-human-preferences",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Put AI to work: Automate and Scale Financial Operations",
    "description": "Put AI to work: Automate and Scale Financial Operations",
    "summary": "Put AI to work: Automate and Scale Financial Operations",
    "pubDate": "Mon, 30 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-automate-and-scale-financial-operations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Taking a responsible path to AGI",
    "description": "We‚Äôre exploring the frontiers of AGI, prioritizing technical safety, proactive risk assessment, and collaboration with the AI community.",
    "summary": "We‚Äôre exploring the frontiers of AGI, prioritizing technical safety, proactive risk assessment, and collaboration with the AI community.",
    "pubDate": "Wed, 02 Apr 2025 13:31:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/taking-a-responsible-path-to-agi/",
    "thumbnail": "https://lh3.googleusercontent.com/0sOE0EshCImNhSW7FRZvw-v_eyJJt_WUEh9evgRbhB4tl0o7qY2VAJdAloF5q3Q6CKTCiXdEvv1kUfsyZz8h6rR7Rl9jUhH02ADOyl7A7w-0QDWWr1Y=w1200-h630-n-nu"
  },
  {
    "title": "Introducing more enterprise-grade features for API customers",
    "description": "Increasing enterprise support with more security features and controls, updates to our Assistants API, and tools to better manage costs.",
    "summary": "Increasing enterprise support with more security features and controls, updates to our Assistants API, and tools to better manage costs.",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/more-enterprise-grade-features-for-api-customers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Spinning Up in Deep RL",
    "description": "We‚Äôre releasing Spinning Up in Deep RL, an educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning. Spinning Up consists of crystal-clear examples of RL code, educational exercises, documentation, and¬†tutorials.",
    "summary": "We‚Äôre releasing Spinning Up in Deep RL, an educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning. Spinning Up consists of crystal-clear examples of RL code, educational exercises, documentation, and¬†tutorials.",
    "pubDate": "Thu, 08 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spinning-up-in-deep-rl",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How to generate text: using different decoding methods for language generation with Transformers",
    "description": "",
    "summary": "How to generate text: using different decoding methods for language generation with Transformers Not...",
    "pubDate": "Sun, 01 Mar 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-generate",
    "thumbnail": "https://huggingface.co/blog/assets/02_how-to-generate/thumbnail.png"
  },
  {
    "title": "Saving lives with AI health coaching",
    "description": "Healthify collaborates with OpenAI to improve millions of lives with sustainable weight loss.",
    "summary": "Healthify collaborates with OpenAI to improve millions of lives with sustainable weight loss.",
    "pubDate": "Wed, 13 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/healthify",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How we used generative media at I/O 2025",
    "description": "Video showing the I/O opening film.",
    "summary": "Video showing the I/O opening film.",
    "pubDate": "Tue, 10 Jun 2025 17:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/generative-ai-io-keynote-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/thumbnail_opener_hero.width-1300.png"
  },
  {
    "title": "Generalizing from simulation",
    "description": "Our latest robotics techniques allow robot controllers, trained entirely in simulation and deployed on physical robots, to react to unplanned changes in the environment as they solve simple tasks. That is, we‚Äôve used these techniques to build closed-loop systems rather than open-loop ones as before.",
    "summary": "Our latest robotics techniques allow robot controllers, trained entirely in simulation and deployed on physical robots, to react to unplanned changes in the environment as they solve simple tasks. That is, we‚Äôve used these techniques to build closed-loop systems rather than open-loop ones as before.",
    "pubDate": "Thu, 19 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generalizing-from-simulation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Mastering Stratego, the classic game of imperfect information",
    "description": "Game-playing artificial intelligence (AI) systems have advanced to a new frontier.",
    "summary": "Game-playing artificial intelligence (AI) systems have advanced to a new frontier.",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/mastering-stratego-the-classic-game-of-imperfect-information/",
    "thumbnail": "https://lh3.googleusercontent.com/nvWTaah_1s2OEAt4CsxX5gKok_0V6-Q5eH3aW3GF6YyZdEVM0OBdgFxNa4DAbmUCXpvTqTfslfUB7_3ZBYr6kIQuk2u46khXH41IU16EZghstwt72Mk=w1200-h630-n-nu"
  },
  {
    "title": "Announcing Gemma 3n preview: Powerful, efficient, mobile-first AI",
    "description": "Gemma 3n is a cutting-edge open model designed for fast, multimodal AI on devices, featuring optimized performance, unique flexibility with a 2-in-1 model, and expanded multimodal understanding with audio, empowering developers to build live, interactive applications and sophisticated audio-centric experiences.",
    "summary": "Gemma 3n is a cutting-edge open model designed for fast, multimodal AI on devices, featuring optimized performance, unique flexibility with a 2-in-1 model, and expanded multimodal understanding with audio, empowering developers to build live, interactive applications and sophisticated audio-centric experiences.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/announcing-gemma-3n-preview-powerful-efficient-mobile-first-ai/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma3n_Metadatal_RD2-V01.2e16d0ba.fill-1200x600.jpg"
  },
  {
    "title": "MOE-Enhanced Explanable Deep Manifold Transformation for Complex Data Embedding and Visualization",
    "description": "arXiv:2410.19504v2 Announce Type: replace-cross Abstract: Dimensionality reduction (DR) plays a crucial role in various fields, including data engineering and visualization, by simplifying complex datasets while retaining essential information. However, achieving both high DR accuracy and strong explainability remains a fundamental challenge, especially for users dealing with high-dimensional data. Traditional DR methods often face a trade-off between precision and transparency, where optimizing for performance can lead to reduced explainability, and vice versa. This limitation is especially prominent in real-world applications such as image, tabular, and text data analysis, where both accuracy and explainability are critical. To address these challenges, this work introduces the MOE-based Explainable Deep Manifold Transformation (DMT-ME). The proposed approach combines hyperbolic embeddings, which effectively capture complex hierarchical structures, with Mixture of Experts (MOE) models, which dynamically allocate tasks based on input features. DMT-ME enhances DR accuracy by leveraging hyperbolic embeddings to represent the hierarchical nature of data, while also improving explainability by explicitly linking input data, embedding outcomes, and key features through the MOE structure. Extensive experiments demonstrate that DMT-ME consistently achieves superior performance in both DR accuracy and model explainability, making it a robust solution for complex data analysis. The code is available at https://github.com/zangzelin/code_dmtme",
    "summary": "arXiv:2410.19504v2 Announce Type: replace-cross Abstract: Dimensionality reduction (DR) plays a crucial role in various fields, including data engineering and visualization, by simplifying complex datasets while retaining essential information. However, achieving both high DR accuracy and strong explainability remains a fundamental challenge, especially for users dealing with high-dimensional data. Traditional DR methods often face a trade-off between precision and transparency, where optimizing for performance can lead to reduced explainability, and vice versa. This limitation is especially prominent in real-world applications such as image, tabular, and text data analysis, where both accuracy and explainability are critical. To address these challenges, this work introduces the MOE-based Explainable Deep Manifold Transformation (DMT-ME). The proposed approach combines hyperbolic embeddings, which effectively capture complex hierarchical structures, with Mixture of Experts (MOE) models, which dynamically allocate tasks based on input features. DMT-ME enhances DR accuracy by leveraging hyperbolic embeddings to represent the hierarchical nature of data, while also improving explainability by explicitly linking input data, embedding outcomes, and key features through the MOE structure. Extensive experiments demonstrate that DMT-ME consistently achieves superior performance in both DR accuracy and model explainability, making it a robust solution for complex data analysis. The code is available at https://github.com/zangzelin/code_dmtme",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.19504",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing IDEFICS: An Open Reproduction of State-of-the-art Visual Language Model",
    "description": "",
    "summary": "Introducing IDEFICS: An Open Reproduction of State-of-the-Art Visual Language Model We are excited t...",
    "pubDate": "Tue, 22 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/idefics",
    "thumbnail": "https://huggingface.co/blog/assets/idefics/thumbnail.png"
  },
  {
    "title": "Ethics and Society Newsletter #2: Let's talk about bias!",
    "description": "",
    "summary": "Machine Learning in development: Let's talk about bias! Bias in ML is ubiquitous, and Bias in ML is ...",
    "pubDate": "Thu, 15 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-2",
    "thumbnail": "https://huggingface.co/blog/assets/122_ethics_soc_2/thumbnail-solstice.png"
  },
  {
    "title": "SmolLM - blazingly fast and remarkably powerful",
    "description": "",
    "summary": "SmolLM - blazingly fast and remarkably powerful TL;DR This blog post introduces SmolLM, a family of ...",
    "pubDate": "Tue, 16 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smollm",
    "thumbnail": "https://huggingface.co/blog/assets/smollm/banner.png"
  },
  {
    "title": "Towards Automated Self-Supervised Learning for Truly Unsupervised Graph Anomaly Detection",
    "description": "arXiv:2501.14694v2 Announce Type: replace-cross Abstract: Self-supervised learning (SSL) is an emerging paradigm that exploits supervisory signals generated from the data itself, and many recent studies have leveraged SSL to conduct graph anomaly detection. However, we empirically found that three important factors can substantially impact detection performance across datasets: 1) the specific SSL strategy employed; 2) the tuning of the strategy's hyperparameters; and 3) the allocation of combination weights when using multiple strategies. Most SSL-based graph anomaly detection methods circumvent these issues by arbitrarily or selectively (i.e., guided by label information) choosing SSL strategies, hyperparameter settings, and combination weights. While an arbitrary choice may lead to subpar performance, using label information in an unsupervised setting is label information leakage and leads to severe overestimation of a method's performance. Leakage has been criticized as 'one of the top ten data mining mistakes', yet many recent studies on SSL-based graph anomaly detection have been using label information to select hyperparameters. To mitigate this issue, we propose to use an internal evaluation strategy (with theoretical analysis) to select hyperparameters in SSL for unsupervised anomaly detection. We perform extensive experiments using 10 recent SSL-based graph anomaly detection algorithms on various benchmark datasets, demonstrating both the prior issues with hyperparameter selection and the effectiveness of our proposed strategy.",
    "summary": "arXiv:2501.14694v2 Announce Type: replace-cross Abstract: Self-supervised learning (SSL) is an emerging paradigm that exploits supervisory signals generated from the data itself, and many recent studies have leveraged SSL to conduct graph anomaly detection. However, we empirically found that three important factors can substantially impact detection performance across datasets: 1) the specific SSL strategy employed; 2) the tuning of the strategy's hyperparameters; and 3) the allocation of combination weights when using multiple strategies. Most SSL-based graph anomaly detection methods circumvent these issues by arbitrarily or selectively (i.e., guided by label information) choosing SSL strategies, hyperparameter settings, and combination weights. While an arbitrary choice may lead to subpar performance, using label information in an unsupervised setting is label information leakage and leads to severe overestimation of a method's performance. Leakage has been criticized as 'one of the top ten data mining mistakes', yet many recent studies on SSL-based graph anomaly detection have been using label information to select hyperparameters. To mitigate this issue, we propose to use an internal evaluation strategy (with theoretical analysis) to select hyperparameters in SSL for unsupervised anomaly detection. We perform extensive experiments using 10 recent SSL-based graph anomaly detection algorithms on various benchmark datasets, demonstrating both the prior issues with hyperparameter selection and the effectiveness of our proposed strategy.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.14694",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deep double descent",
    "description": "We show that the¬†double¬†descent¬†phenomenon¬†occurs in CNNs, ResNets, and transformers: performance first improves, then gets worse, and then improves again with increasing model size, data size, or training time. This effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we don‚Äôt yet fully understand why it happens, and view further study of this phenomenon as an important research¬†direction.",
    "summary": "We show that the¬†double¬†descent¬†phenomenon¬†occurs in CNNs, ResNets, and transformers: performance first improves, then gets worse, and then improves again with increasing model size, data size, or training time. This effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we don‚Äôt yet fully understand why it happens, and view further study of this phenomenon as an important research¬†direction.",
    "pubDate": "Thu, 05 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-double-descent",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms",
    "description": "New AI agent evolves algorithms for math and practical applications in computing by combining the creativity of large language models with automated evaluators",
    "summary": "New AI agent evolves algorithms for math and practical applications in computing by combining the creativity of large language models with automated evaluators",
    "pubDate": "Wed, 14 May 2025 14:59:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/",
    "thumbnail": "https://lh3.googleusercontent.com/tG6-MqdlvhQ-z7ENzGxR-kpGPPdPHbJ8UZtbTP66Rxi0UftTFU1yAvaBCVuigYuKvESMeEFf4jqNBVENFcZXEUnj8SSqj8zsop8UHAl0eD9A-hUCvQ=w1200-h630-n-nu"
  },
  {
    "title": "Datadog„Åå„ÄåAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÊÑèÂøóÊ±∫ÂÆö„Éó„É≠„Çª„Çπ„Äç„ÇíÂèØË¶ñÂåñ„Åô„Çã„ÉÑ„Éº„É´„ÇíÁô∫Ë°®",
    "description": "DataDog„ÅØ„ÄÅ„ÄåLLM Observability„Äç„ÅÆÊñ∞Ê©üËÉΩ„ÇíÁô∫Ë°®„Åó„Åü„ÄÇAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÂãï‰ΩúÂÖ®‰Ωì„ÇíÂèØË¶ñÂåñ„Åô„Çã„Å®„Å®„ÇÇ„Å´„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÁÆ°ÁêÜ„Çí‰∏ÄÂÖÉÂåñ„Åô„Çã„Åü„ÇÅ„ÅÆ„Ç¨„Éê„Éä„É≥„Çπ‰ΩìÂà∂„ÅÆÊßãÁØâ„ÇÇÊîØÊè¥„Åô„Çã„Å®„ÅÑ„ÅÜ„ÄÇ",
    "summary": "DataDog„ÅØ„ÄÅ„ÄåLLM Observability„Äç„ÅÆÊñ∞Ê©üËÉΩ„ÇíÁô∫Ë°®„Åó„Åü„ÄÇAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÂãï‰ΩúÂÖ®‰Ωì„ÇíÂèØË¶ñÂåñ„Åô„Çã„Å®„Å®„ÇÇ„Å´„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÁÆ°ÁêÜ„Çí‰∏ÄÂÖÉÂåñ„Åô„Çã„Åü„ÇÅ„ÅÆ„Ç¨„Éê„Éä„É≥„Çπ‰ΩìÂà∂„ÅÆÊßãÁØâ„ÇÇÊîØÊè¥„Åô„Çã„Å®„ÅÑ„ÅÜ„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://atmarkit.itmedia.co.jp/ait/articles/2506/30/news042.html",
    "thumbnail": "https://image.itmedia.co.jp/ait/articles/2506/30/cover_news042.jpg"
  },
  {
    "title": "Benchmarking Deep Search over Heterogeneous Enterprise Data",
    "description": "arXiv:2506.23139v1 Announce Type: cross Abstract: We present a new benchmark for evaluating Deep Search--a realistic and complex form of retrieval-augmented generation (RAG) that requires source-aware, multi-hop reasoning over diverse, sparsed, but related sources. These include documents, meeting transcripts, Slack messages, GitHub, and URLs, which vary in structure and often contain human-to-human interactions. We build it using a synthetic data pipeline that simulates business workflows across product planning, development, and support stages, generating interconnected content with realistic noise and multi-hop questions with guaranteed ground-truth answers. We release our benchmark with both answerable and unanswerable queries, and retrieval pool of 39,190 enterprise artifacts, enabling fine-grained evaluation of long-context LLM and RAG systems. Our experiments reveal that even the best-performing agentic RAG methods achieve an average performance score of 32.96 on our benchmark. With further analysis, we highlight retrieval as the main bottleneck: existing methods struggle to conduct deep searches and retrieve all necessary evidence. Consequently, they often reason over partial context, leading to significant performance degradation.",
    "summary": "arXiv:2506.23139v1 Announce Type: cross Abstract: We present a new benchmark for evaluating Deep Search--a realistic and complex form of retrieval-augmented generation (RAG) that requires source-aware, multi-hop reasoning over diverse, sparsed, but related sources. These include documents, meeting transcripts, Slack messages, GitHub, and URLs, which vary in structure and often contain human-to-human interactions. We build it using a synthetic data pipeline that simulates business workflows across product planning, development, and support stages, generating interconnected content with realistic noise and multi-hop questions with guaranteed ground-truth answers. We release our benchmark with both answerable and unanswerable queries, and retrieval pool of 39,190 enterprise artifacts, enabling fine-grained evaluation of long-context LLM and RAG systems. Our experiments reveal that even the best-performing agentic RAG methods achieve an average performance score of 32.96 on our benchmark. With further analysis, we highlight retrieval as the main bottleneck: existing methods struggle to conduct deep searches and retrieve all necessary evidence. Consequently, they often reason over partial context, leading to significant performance degradation.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23139",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using Stable Diffusion with Core ML on Apple Silicon",
    "description": "",
    "summary": "Using Stable Diffusion with Core ML on Apple Silicon Thanks to Apple engineers, you can now run Stab...",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers_coreml/thumbnail.png"
  },
  {
    "title": "Mask-aware Text-to-Image Retrieval: Referring Expression Segmentation Meets Cross-modal Retrieval",
    "description": "arXiv:2506.22864v1 Announce Type: cross Abstract: Text-to-image retrieval (TIR) aims to find relevant images based on a textual query, but existing approaches are primarily based on whole-image captions and lack interpretability. Meanwhile, referring expression segmentation (RES) enables precise object localization based on natural language descriptions but is computationally expensive when applied across large image collections. To bridge this gap, we introduce Mask-aware TIR (MaTIR), a new task that unifies TIR and RES, requiring both efficient image search and accurate object segmentation. To address this task, we propose a two-stage framework, comprising a first stage for segmentation-aware image retrieval and a second stage for reranking and object grounding with a multimodal large language model (MLLM). We leverage SAM 2 to generate object masks and Alpha-CLIP to extract region-level embeddings offline at first, enabling effective and scalable online retrieval. Secondly, MLLM is used to refine retrieval rankings and generate bounding boxes, which are matched to segmentation masks. We evaluate our approach on COCO and D$^3$ datasets, demonstrating significant improvements in both retrieval accuracy and segmentation quality over previous methods.",
    "summary": "arXiv:2506.22864v1 Announce Type: cross Abstract: Text-to-image retrieval (TIR) aims to find relevant images based on a textual query, but existing approaches are primarily based on whole-image captions and lack interpretability. Meanwhile, referring expression segmentation (RES) enables precise object localization based on natural language descriptions but is computationally expensive when applied across large image collections. To bridge this gap, we introduce Mask-aware TIR (MaTIR), a new task that unifies TIR and RES, requiring both efficient image search and accurate object segmentation. To address this task, we propose a two-stage framework, comprising a first stage for segmentation-aware image retrieval and a second stage for reranking and object grounding with a multimodal large language model (MLLM). We leverage SAM 2 to generate object masks and Alpha-CLIP to extract region-level embeddings offline at first, enabling effective and scalable online retrieval. Secondly, MLLM is used to refine retrieval rankings and generate bounding boxes, which are matched to segmentation masks. We evaluate our approach on COCO and D$^3$ datasets, demonstrating significant improvements in both retrieval accuracy and segmentation quality over previous methods.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22864",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Pioneers Program",
    "description": "Advancing model performance and real world evaluation in applied domains.",
    "summary": "Advancing model performance and real world evaluation in applied domains.",
    "pubDate": "Wed, 09 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-pioneers-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Hugging Face Training Efficiency Through Packing with Flash Attention",
    "description": "",
    "summary": "Improving Hugging Face Training Efficiency Through Packing with Flash Attention TL;DR Training with ...",
    "pubDate": "Wed, 21 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/packing-with-FA2",
    "thumbnail": "https://huggingface.co/blog/assets/packing-with-FA2/thumbnail.png"
  },
  {
    "title": "Make your llama generation time fly with AWS Inferentia2",
    "description": "",
    "summary": "Make your llama generation time fly with AWS Inferentia2 Update (02/2024): Performance has improved ...",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inferentia-llama2",
    "thumbnail": "https://huggingface.co/blog/assets/inferentia-llama2/thumbnail.png"
  },
  {
    "title": "AlphaFold 3 predicts the structure and interactions of all of life‚Äôs molecules",
    "description": "Introducing a new AI model developed by Google DeepMind and Isomorphic Labs.",
    "summary": "Introducing a new AI model developed by Google DeepMind and Isomorphic Labs.",
    "pubDate": "Wed, 08 May 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphafold-3-predicts-the-structure-and-interactions-of-all-lifes-molecules/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AF_social_share.width-1300.jpg"
  },
  {
    "title": "Plan online, learn offline: Efficient learning and exploration via model-based control",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 05 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/plan-online-learn-offline",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning",
    "description": "arXiv:2506.24119v1 Announce Type: new Abstract: Recent advances in reinforcement learning have shown that language models can develop sophisticated reasoning through training on tasks with verifiable rewards, but these approaches depend on human-curated problem-answer pairs and domain-specific reward engineering. We introduce SPIRAL, a self-play framework where models learn by playing multi-turn, zero-sum games against continuously improving versions of themselves, eliminating the need for human supervision. Through self-play, SPIRAL generates an infinite curriculum of progressively challenging problems as models must constantly adapt to stronger opponents. To enable this self-play training at scale, We implement a fully online, multi-turn, multi-agent reinforcement learning system for LLMs and propose role-conditioned advantage estimation (RAE) to stabilize multi-agent training. Using SPIRAL, self-play on zero-sum games produces reasoning capabilities that transfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6% improvement on math and 8.4% on general reasoning, outperforming SFT on 25,000 expert game trajectories. Analysis reveals that this transfer occurs through three cognitive patterns: systematic decomposition, expected value calculation, and case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple Negotiation) further enhances performance as each game develops distinct reasoning strengths. Applying SPIRAL to a strong reasoning model (DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These results demonstrate that zero-sum games naturally develop transferable reasoning capabilities, highlighting a promising direction for autonomous reasoning development.",
    "summary": "arXiv:2506.24119v1 Announce Type: new Abstract: Recent advances in reinforcement learning have shown that language models can develop sophisticated reasoning through training on tasks with verifiable rewards, but these approaches depend on human-curated problem-answer pairs and domain-specific reward engineering. We introduce SPIRAL, a self-play framework where models learn by playing multi-turn, zero-sum games against continuously improving versions of themselves, eliminating the need for human supervision. Through self-play, SPIRAL generates an infinite curriculum of progressively challenging problems as models must constantly adapt to stronger opponents. To enable this self-play training at scale, We implement a fully online, multi-turn, multi-agent reinforcement learning system for LLMs and propose role-conditioned advantage estimation (RAE) to stabilize multi-agent training. Using SPIRAL, self-play on zero-sum games produces reasoning capabilities that transfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6% improvement on math and 8.4% on general reasoning, outperforming SFT on 25,000 expert game trajectories. Analysis reveals that this transfer occurs through three cognitive patterns: systematic decomposition, expected value calculation, and case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple Negotiation) further enhances performance as each game develops distinct reasoning strengths. Applying SPIRAL to a strong reasoning model (DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These results demonstrate that zero-sum games naturally develop transferable reasoning capabilities, highlighting a promising direction for autonomous reasoning development.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.24119",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning World Models With Hierarchical Temporal Abstractions: A Probabilistic Perspective",
    "description": "arXiv:2404.16078v3 Announce Type: replace Abstract: Machines that can replicate human intelligence with type 2 reasoning capabilities should be able to reason at multiple levels of spatio-temporal abstractions and scales using internal world models. Devising formalisms to develop such internal world models, which accurately reflect the causal hierarchies inherent in the dynamics of the real world, is a critical research challenge in the domains of artificial intelligence and machine learning. This thesis identifies several limitations with the prevalent use of state space models (SSMs) as internal world models and propose two new probabilistic formalisms namely Hidden-Parameter SSMs and Multi-Time Scale SSMs to address these drawbacks. The structure of graphical models in both formalisms facilitates scalable exact probabilistic inference using belief propagation, as well as end-to-end learning via backpropagation through time. This approach permits the development of scalable, adaptive hierarchical world models capable of representing nonstationary dynamics across multiple temporal abstractions and scales. Moreover, these probabilistic formalisms integrate the concept of uncertainty in world states, thus improving the system's capacity to emulate the stochastic nature of the real world and quantify the confidence in its predictions. The thesis also discuss how these formalisms are in line with related neuroscience literature on Bayesian brain hypothesis and predicitive processing. Our experiments on various real and simulated robots demonstrate that our formalisms can match and in many cases exceed the performance of contemporary transformer variants in making long-range future predictions. We conclude the thesis by reflecting on the limitations of our current models and suggesting directions for future research.",
    "summary": "arXiv:2404.16078v3 Announce Type: replace Abstract: Machines that can replicate human intelligence with type 2 reasoning capabilities should be able to reason at multiple levels of spatio-temporal abstractions and scales using internal world models. Devising formalisms to develop such internal world models, which accurately reflect the causal hierarchies inherent in the dynamics of the real world, is a critical research challenge in the domains of artificial intelligence and machine learning. This thesis identifies several limitations with the prevalent use of state space models (SSMs) as internal world models and propose two new probabilistic formalisms namely Hidden-Parameter SSMs and Multi-Time Scale SSMs to address these drawbacks. The structure of graphical models in both formalisms facilitates scalable exact probabilistic inference using belief propagation, as well as end-to-end learning via backpropagation through time. This approach permits the development of scalable, adaptive hierarchical world models capable of representing nonstationary dynamics across multiple temporal abstractions and scales. Moreover, these probabilistic formalisms integrate the concept of uncertainty in world states, thus improving the system's capacity to emulate the stochastic nature of the real world and quantify the confidence in its predictions. The thesis also discuss how these formalisms are in line with related neuroscience literature on Bayesian brain hypothesis and predicitive processing. Our experiments on various real and simulated robots demonstrate that our formalisms can match and in many cases exceed the performance of contemporary transformer variants in making long-range future predictions. We conclude the thesis by reflecting on the limitations of our current models and suggesting directions for future research.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2404.16078",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval",
    "description": "",
    "summary": "Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval We introduce t...",
    "pubDate": "Fri, 22 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/embedding-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/embedding-quantization/thumbnail.png"
  },
  {
    "title": "Practices for Governing Agentic AI Systems",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/practices-for-governing-agentic-ai-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing our latest image generation model in the API",
    "description": "Our latest image generation model is now available in the API via ‚Äògpt-image-1‚Äô‚Äîenabling developers and businesses to build professional-grade, customizable visuals directly into their own tools and platforms.",
    "summary": "Our latest image generation model is now available in the API via ‚Äògpt-image-1‚Äô‚Äîenabling developers and businesses to build professional-grade, customizable visuals directly into their own tools and platforms.",
    "pubDate": "Wed, 23 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/image-generation-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Equivalence between policy gradients and soft Q-learning",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 21 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/equivalence-between-policy-gradients-and-soft-q-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome fastai to the Hugging Face Hub",
    "description": "",
    "summary": "Welcome fastai to the Hugging Face Hub Making neural nets uncool again... and sharing them Few have ...",
    "pubDate": "Fri, 06 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastai",
    "thumbnail": "https://huggingface.co/blog/assets/64_fastai/fastai_hf_blog.png"
  },
  {
    "title": "Deploying TensorFlow Vision Models in Hugging Face with TF Serving",
    "description": "",
    "summary": "Deploying TensorFlow Vision Models in Hugging Face with TF Serving In the past few months, the Huggi...",
    "pubDate": "Mon, 25 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-serving-vision",
    "thumbnail": "https://huggingface.co/blog/assets/90_tf_serving_vision/thumbnail.png"
  },
  {
    "title": "MIT announces the Initiative for New Manufacturing",
    "description": "The Institute-wide effort aims to bolster industry and create jobs by driving innovation across vital manufacturing sectors.",
    "summary": "The Institute-wide effort aims to bolster industry and create jobs by driving innovation across vital manufacturing sectors.",
    "pubDate": "Tue, 27 May 2025 10:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-announces-initiative-for-new-manufacturing-0527",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-ManufacturingAnn-01-press.jpg"
  },
  {
    "title": "Generative models",
    "description": "This post describes four projects that share a common theme of enhancing or using generative models, a branch of unsupervised learning techniques in machine learning. In addition to describing our work, this post will tell you a bit more about generative models: what they are, why they are important, and where they might be going.",
    "summary": "This post describes four projects that share a common theme of enhancing or using generative models, a branch of unsupervised learning techniques in machine learning. In addition to describing our work, this post will tell you a bit more about generative models: what they are, why they are important, and where they might be going.",
    "pubDate": "Thu, 16 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generative-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI for Nonprofits",
    "description": "We‚Äôre launching a new initiative to enhance the accessibility of our tools for nonprofit organizations, including discounted rates for ChatGPT Team and Enterprise.",
    "summary": "We‚Äôre launching a new initiative to enhance the accessibility of our tools for nonprofit organizations, including discounted rates for ChatGPT Team and Enterprise.",
    "pubDate": "Thu, 30 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-for-nonprofits",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Large Language Model-Enabled Control Architecture for Dynamic Resource Capability Exploration in Multi-Agent Manufacturing Systems",
    "description": "arXiv:2505.22814v2 Announce Type: replace-cross Abstract: Manufacturing environments are becoming more complex and unpredictable due to factors such as demand variations and shorter product lifespans. This complexity requires real-time decision-making and adaptation to disruptions. Traditional control approaches highlight the need for advanced control strategies capable of overcoming unforeseen challenges, as they demonstrate limitations in responsiveness within dynamic industrial settings. Multi-agent systems address these challenges through decentralization of decision-making, enabling systems to respond dynamically to operational changes. However, current multi-agent systems encounter challenges related to real-time adaptation, context-aware decision-making, and the dynamic exploration of resource capabilities. Large language models provide the possibility to overcome these limitations through context-aware decision-making capabilities. This paper introduces a large language model-enabled control architecture for multi-agent manufacturing systems to dynamically explore resource capabilities in response to real-time disruptions. A simulation-based case study demonstrates that the proposed architecture improves system resilience and flexibility. The case study findings show improved throughput and efficient resource utilization compared to existing approaches.",
    "summary": "arXiv:2505.22814v2 Announce Type: replace-cross Abstract: Manufacturing environments are becoming more complex and unpredictable due to factors such as demand variations and shorter product lifespans. This complexity requires real-time decision-making and adaptation to disruptions. Traditional control approaches highlight the need for advanced control strategies capable of overcoming unforeseen challenges, as they demonstrate limitations in responsiveness within dynamic industrial settings. Multi-agent systems address these challenges through decentralization of decision-making, enabling systems to respond dynamically to operational changes. However, current multi-agent systems encounter challenges related to real-time adaptation, context-aware decision-making, and the dynamic exploration of resource capabilities. Large language models provide the possibility to overcome these limitations through context-aware decision-making capabilities. This paper introduces a large language model-enabled control architecture for multi-agent manufacturing systems to dynamically explore resource capabilities in response to real-time disruptions. A simulation-based case study demonstrates that the proposed architecture improves system resilience and flexibility. The case study findings show improved throughput and efficient resource utilization compared to existing approaches.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.22814",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Scholars 2019: Final projects",
    "description": "Our second class of OpenAI Scholars has concluded, with all eight scholars producing an exciting final project showcased at Scholars Demo Day at OpenAI.",
    "summary": "Our second class of OpenAI Scholars has concluded, with all eight scholars producing an exciting final project showcased at Scholars Demo Day at OpenAI.",
    "pubDate": "Thu, 23 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Exploring Artificial Intelligence Tutor Teammate Adaptability to Harness Discovery Curiosity and Promote Learning in the Context of Interactive Molecular Dynamics",
    "description": "arXiv:2506.22520v1 Announce Type: cross Abstract: This study examines the impact of an Artificial Intelligence tutor teammate (AI) on student curiosity-driven engagement and learning effectiveness during Interactive Molecular Dynamics (IMD) tasks on the Visual Molecular Dynamics platform. It explores the role of the AI's curiosity-triggering and response behaviors in stimulating and sustaining student curiosity, affecting the frequency and complexity of student-initiated questions. The study further assesses how AI interventions shape student engagement, foster discovery curiosity, and enhance team performance within the IMD learning environment. Using a Wizard-of-Oz paradigm, a human experimenter dynamically adjusts the AI tutor teammate's behavior through a large language model. By employing a mixed-methods exploratory design, a total of 11 high school students participated in four IMD tasks that involved molecular visualization and calculations, which increased in complexity over a 60-minute period. Team performance was evaluated through real-time observation and recordings, whereas team communication was measured by question complexity and AI's curiosity-triggering and response behaviors. Cross Recurrence Quantification Analysis (CRQA) metrics reflected structural alignment in coordination and were linked to communication behaviors. High-performing teams exhibited superior task completion, deeper understanding, and increased engagement. Advanced questions were associated with AI curiosity-triggering, indicating heightened engagement and cognitive complexity. CRQA metrics highlighted dynamic synchronization in student-AI interactions, emphasizing structured yet adaptive engagement to promote curiosity. These proof-of-concept findings suggest that the AI's dual role as a teammate and educator indicates its capacity to provide adaptive feedback, sustaining engagement and epistemic curiosity.",
    "summary": "arXiv:2506.22520v1 Announce Type: cross Abstract: This study examines the impact of an Artificial Intelligence tutor teammate (AI) on student curiosity-driven engagement and learning effectiveness during Interactive Molecular Dynamics (IMD) tasks on the Visual Molecular Dynamics platform. It explores the role of the AI's curiosity-triggering and response behaviors in stimulating and sustaining student curiosity, affecting the frequency and complexity of student-initiated questions. The study further assesses how AI interventions shape student engagement, foster discovery curiosity, and enhance team performance within the IMD learning environment. Using a Wizard-of-Oz paradigm, a human experimenter dynamically adjusts the AI tutor teammate's behavior through a large language model. By employing a mixed-methods exploratory design, a total of 11 high school students participated in four IMD tasks that involved molecular visualization and calculations, which increased in complexity over a 60-minute period. Team performance was evaluated through real-time observation and recordings, whereas team communication was measured by question complexity and AI's curiosity-triggering and response behaviors. Cross Recurrence Quantification Analysis (CRQA) metrics reflected structural alignment in coordination and were linked to communication behaviors. High-performing teams exhibited superior task completion, deeper understanding, and increased engagement. Advanced questions were associated with AI curiosity-triggering, indicating heightened engagement and cognitive complexity. CRQA metrics highlighted dynamic synchronization in student-AI interactions, emphasizing structured yet adaptive engagement to promote curiosity. These proof-of-concept findings suggest that the AI's dual role as a teammate and educator indicates its capacity to provide adaptive feedback, sustaining engagement and epistemic curiosity.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22520",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Our approach to alignment research",
    "description": "We are improving our AI systems‚Äô ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment¬†problems.",
    "summary": "We are improving our AI systems‚Äô ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment¬†problems.",
    "pubDate": "Wed, 24 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/our-approach-to-alignment-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Visual Document Retrieval Goes Multilingual",
    "description": "",
    "summary": "Visual Document Retrieval Goes Multilingual TL;DR: We present vdr-2b-multi-v1 , the best multilingua...",
    "pubDate": "Fri, 10 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vdr-2b-multilingual",
    "thumbnail": "https://huggingface.co/blog/assets/vdr-2b-multilingual/thumbnail.png"
  },
  {
    "title": "AI Policy @ü§ó: Open ML Considerations in the EU AI Act",
    "description": "",
    "summary": "AI Policy @ü§ó: Open ML Considerations in the EU AI Act Like everyone else in Machine Learning, we‚Äôve ...",
    "pubDate": "Mon, 24 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eu-ai-act-oss",
    "thumbnail": "https://huggingface.co/blog/assets/eu_ai_act_oss/thumbnailEU.png"
  },
  {
    "title": "A Library for Learning Neural Operators",
    "description": "arXiv:2412.10354v4 Announce Type: replace-cross Abstract: We present NeuralOperator, an open-source Python library for operator learning. Neural operators generalize neural networks to maps between function spaces instead of finite-dimensional Euclidean spaces. They can be trained and inferenced on input and output functions given at various discretizations, satisfying a discretization convergence properties. Built on top of PyTorch, NeuralOperator provides all the tools for training and deploying neural operator models, as well as developing new ones, in a high-quality, tested, open-source package. It combines cutting-edge models and customizability with a gentle learning curve and simple user interface for newcomers.",
    "summary": "arXiv:2412.10354v4 Announce Type: replace-cross Abstract: We present NeuralOperator, an open-source Python library for operator learning. Neural operators generalize neural networks to maps between function spaces instead of finite-dimensional Euclidean spaces. They can be trained and inferenced on input and output functions given at various discretizations, satisfying a discretization convergence properties. Built on top of PyTorch, NeuralOperator provides all the tools for training and deploying neural operator models, as well as developing new ones, in a high-quality, tested, open-source package. It combines cutting-edge models and customizability with a gentle learning curve and simple user interface for newcomers.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.10354",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introduction to ggml",
    "description": "",
    "summary": "Introduction to ggml ggml is a machine learning (ML) library written in C and C++ with a focus on Tr...",
    "pubDate": "Tue, 13 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introduction-to-ggml",
    "thumbnail": "https://huggingface.co/blog/assets/introduction-to-ggml/cover.jpg"
  },
  {
    "title": "From PyTorch DDP to ü§ó Accelerate to ü§ó Trainer, mastery of distributed training with ease",
    "description": "",
    "summary": "From PyTorch DDP to Accelerate to Trainer, mastery of distributed training with ease General Overvie...",
    "pubDate": "Fri, 21 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-ddp-accelerate-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/111_pytorch_ddp_accelerate_transformers/thumbnail.png"
  },
  {
    "title": "Memory-efficient Diffusion Transformers with Quanto and Diffusers",
    "description": "",
    "summary": "Memory-efficient Diffusion Transformers with Quanto and Diffusers Over the past few months, we have ...",
    "pubDate": "Tue, 30 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/quanto-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/quanto-diffusers/thumbnail.png"
  },
  {
    "title": "A Survey on Vision-Language-Action Models for Autonomous Driving",
    "description": "arXiv:2506.24044v1 Announce Type: cross Abstract: The rapid progress of multimodal large language models (MLLM) has paved the way for Vision-Language-Action (VLA) paradigms, which integrate visual perception, natural language understanding, and control within a single policy. Researchers in autonomous driving are actively adapting these methods to the vehicle domain. Such models promise autonomous vehicles that can interpret high-level instructions, reason about complex traffic scenes, and make their own decisions. However, the literature remains fragmented and is rapidly expanding. This survey offers the first comprehensive overview of VLA for Autonomous Driving (VLA4AD). We (i) formalize the architectural building blocks shared across recent work, (ii) trace the evolution from early explainer to reasoning-centric VLA models, and (iii) compare over 20 representative models according to VLA's progress in the autonomous driving domain. We also consolidate existing datasets and benchmarks, highlighting protocols that jointly measure driving safety, accuracy, and explanation quality. Finally, we detail open challenges - robustness, real-time efficiency, and formal verification - and outline future directions of VLA4AD. This survey provides a concise yet complete reference for advancing interpretable socially aligned autonomous vehicles. Github repo is available at href{https://github.com/JohnsonJiang1996/Awesome-VLA4AD}{SicongJiang/Awesome-VLA4AD}.",
    "summary": "arXiv:2506.24044v1 Announce Type: cross Abstract: The rapid progress of multimodal large language models (MLLM) has paved the way for Vision-Language-Action (VLA) paradigms, which integrate visual perception, natural language understanding, and control within a single policy. Researchers in autonomous driving are actively adapting these methods to the vehicle domain. Such models promise autonomous vehicles that can interpret high-level instructions, reason about complex traffic scenes, and make their own decisions. However, the literature remains fragmented and is rapidly expanding. This survey offers the first comprehensive overview of VLA for Autonomous Driving (VLA4AD). We (i) formalize the architectural building blocks shared across recent work, (ii) trace the evolution from early explainer to reasoning-centric VLA models, and (iii) compare over 20 representative models according to VLA's progress in the autonomous driving domain. We also consolidate existing datasets and benchmarks, highlighting protocols that jointly measure driving safety, accuracy, and explanation quality. Finally, we detail open challenges - robustness, real-time efficiency, and formal verification - and outline future directions of VLA4AD. This survey provides a concise yet complete reference for advancing interpretable socially aligned autonomous vehicles. Github repo is available at href{https://github.com/JohnsonJiang1996/Awesome-VLA4AD}{SicongJiang/Awesome-VLA4AD}.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.24044",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Enterprise-ready trust and safety",
    "description": "Salesforce integrates OpenAI‚Äôs enterprise-ready LLMs to transform customer applications.",
    "summary": "Salesforce integrates OpenAI‚Äôs enterprise-ready LLMs to transform customer applications.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/salesforce",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering",
    "description": "We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.",
    "summary": "We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.",
    "pubDate": "Thu, 10 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mle-bench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Computational limitations in robust classification and win-win results",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 04 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/computational-limitations-in-robust-classification-and-win-win-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Benchmarking the next generation of never-ending learners",
    "description": "Learning how to build upon knowledge by tapping 30 years of computer vision research",
    "summary": "Learning how to build upon knowledge by tapping 30 years of computer vision research",
    "pubDate": "Tue, 22 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/benchmarking-the-next-generation-of-never-ending-learners/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "Shipping code faster with o3, o4-mini, and GPT-4.1",
    "description": "CodeRabbit uses OpenAI models to revolutionize code reviews‚Äîboosting accuracy, accelerating PR merges, and helping developers ship faster with fewer bugs and higher ROI.",
    "summary": "CodeRabbit uses OpenAI models to revolutionize code reviews‚Äîboosting accuracy, accelerating PR merges, and helping developers ship faster with fewer bugs and higher ROI.",
    "pubDate": "Thu, 22 May 2025 10:25:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/coderabbit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MMInA: Benchmarking Multihop Multimodal Internet Agents",
    "description": "arXiv:2404.09992v2 Announce Type: replace-cross Abstract: Autonomous embodied agents live on an Internet of multimedia websites. Can they hop around multimodal websites to complete complex user tasks? Existing benchmarks fail to assess them in a realistic, evolving environment for their embodiment across websites. To answer this question, we present MMInA, a multihop and multimodal benchmark to evaluate the embodied agents for compositional Internet tasks, with several appealing properties: 1) Evolving real-world multimodal websites. Our benchmark uniquely operates on evolving real-world websites, ensuring a high degree of realism and applicability to natural user tasks. Our data includes 1,050 human-written tasks covering various domains such as shopping and travel, with each task requiring the agent to extract multimodal information from web pages as observations autonomously; 2) Multihop web browsing. Our dataset features naturally compositional tasks that require information from or actions on multiple websites to solve, to assess long-range reasoning capabilities on web tasks; 3) Holistic evaluation. We propose a novel protocol for evaluating an agent's progress in completing multihop tasks. We experiment with both standalone (multimodal) language models and heuristic-based web agents. Extensive experiments demonstrate that while long-chain multihop web tasks are easy for humans, they remain challenging for state-of-the-art web agents. We identify that agents are more likely to fail on the early hops when solving tasks with more hops, which results in lower task success rates. To address this issue, we propose a simple memory augmentation approach that replays past action trajectories to reflect. Our method significantly improves the performance of both the single-hop and multihop web browsing abilities. Our code and data are available at github.com/shulin16/MMInA.",
    "summary": "arXiv:2404.09992v2 Announce Type: replace-cross Abstract: Autonomous embodied agents live on an Internet of multimedia websites. Can they hop around multimodal websites to complete complex user tasks? Existing benchmarks fail to assess them in a realistic, evolving environment for their embodiment across websites. To answer this question, we present MMInA, a multihop and multimodal benchmark to evaluate the embodied agents for compositional Internet tasks, with several appealing properties: 1) Evolving real-world multimodal websites. Our benchmark uniquely operates on evolving real-world websites, ensuring a high degree of realism and applicability to natural user tasks. Our data includes 1,050 human-written tasks covering various domains such as shopping and travel, with each task requiring the agent to extract multimodal information from web pages as observations autonomously; 2) Multihop web browsing. Our dataset features naturally compositional tasks that require information from or actions on multiple websites to solve, to assess long-range reasoning capabilities on web tasks; 3) Holistic evaluation. We propose a novel protocol for evaluating an agent's progress in completing multihop tasks. We experiment with both standalone (multimodal) language models and heuristic-based web agents. Extensive experiments demonstrate that while long-chain multihop web tasks are easy for humans, they remain challenging for state-of-the-art web agents. We identify that agents are more likely to fail on the early hops when solving tasks with more hops, which results in lower task success rates. To address this issue, we propose a simple memory augmentation approach that replays past action trajectories to reflect. Our method significantly improves the performance of both the single-hop and multihop web browsing abilities. Our code and data are available at github.com/shulin16/MMInA.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2404.09992",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„ÇíÁú∫„ÇÅ„Å¶„Åø„Çã",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ‰ªäÂõû„ÅØGemini Diffusion„ÅÆÁôªÂ†¥„Çí„Åç„Å£„Åã„Åë„Å´ÊúÄËøëË©±È°å„Å´„Å™„Å£„ÅüÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„Å´ËààÂë≥„ÇíÊåÅ„Å°„ÄÅ„Åù„ÅÆ‰∏Ä‰æã„Å®„Åó„Å¶Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆLLaDA„ÅÆÊé®Ë´ñ„ÇíÂÆüÈöõ„Å´ÊâãÂÖÉ„ÅßÁ¢∫Ë™ç„Åó„Å¶„Åø„ÅüÁµêÊûú„Çí [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5850' rel='nofollow'>Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„ÇíÁú∫„ÇÅ„Å¶„Åø„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ‰ªäÂõû„ÅØGemini Diffusion„ÅÆÁôªÂ†¥„Çí„Åç„Å£„Åã„Åë„Å´ÊúÄËøëË©±È°å„Å´„Å™„Å£„ÅüÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„Å´ËààÂë≥„ÇíÊåÅ„Å°„ÄÅ„Åù„ÅÆ‰∏Ä‰æã„Å®„Åó„Å¶Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆLLaDA„ÅÆÊé®Ë´ñ„ÇíÂÆüÈöõ„Å´ÊâãÂÖÉ„ÅßÁ¢∫Ë™ç„Åó„Å¶„Åø„ÅüÁµêÊûú„Çí [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5850' rel='nofollow'>Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„ÇíÁú∫„ÇÅ„Å¶„Åø„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Mon, 02 Jun 2025 00:13:43 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5850",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "Llama 2 is here - get it on Hugging Face",
    "description": "",
    "summary": "Llama 2 is here - get it on Hugging Face Introduction Llama 2 is a family of state-of-the-art open-a...",
    "pubDate": "Tue, 18 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama2",
    "thumbnail": "https://huggingface.co/blog/assets/llama2/thumbnail.jpg"
  },
  {
    "title": "Introducing the Chatbot Guardrails Arena",
    "description": "",
    "summary": "Introducing the Chatbot Guardrails Arena With the recent advancements in augmented LLM capabilities,...",
    "pubDate": "Thu, 21 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-lighthouz",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail_lighthouz.png"
  },
  {
    "title": "Team update",
    "description": "The OpenAI team is now 45 people. Together, we‚Äôre pushing the frontier of AI capabilities‚Äîwhether by validating novel ideas, creating new software systems, or deploying machine learning on robots.",
    "summary": "The OpenAI team is now 45 people. Together, we‚Äôre pushing the frontier of AI capabilities‚Äîwhether by validating novel ideas, creating new software systems, or deploying machine learning on robots.",
    "pubDate": "Mon, 30 Jan 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update-january",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks",
    "description": "arXiv:2506.23049v1 Announce Type: new Abstract: Despite advances in language and speech technologies, no open-source system enables full speech-to-speech, multi-turn dialogue with integrated tool use and agentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and Automated Tool Use), the first open-source, speech-native assistant capable of completing complex, goal-driven tasks through dynamic tool invocation and multi-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a cascaded pipeline and supports tools such as calendar booking, contact lookup, web search, and email. Its modular design allows easy integration of new tools using natural language prompts and action classes. On VoiceBench, AURA scores 92.75% on OpenBookQA-outperforming all open-weight systems and nearing GPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems. Human evaluation shows 90% task success on complex, multi-turn speech tasks.",
    "summary": "arXiv:2506.23049v1 Announce Type: new Abstract: Despite advances in language and speech technologies, no open-source system enables full speech-to-speech, multi-turn dialogue with integrated tool use and agentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and Automated Tool Use), the first open-source, speech-native assistant capable of completing complex, goal-driven tasks through dynamic tool invocation and multi-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a cascaded pipeline and supports tools such as calendar booking, contact lookup, web search, and email. Its modular design allows easy integration of new tools using natural language prompts and action classes. On VoiceBench, AURA scores 92.75% on OpenBookQA-outperforming all open-weight systems and nearing GPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems. Human evaluation shows 90% task success on complex, multi-turn speech tasks.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23049",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcoming Llama Guard 4 on Hugging Face Hub",
    "description": "",
    "summary": "Welcoming Llama Guard 4 on Hugging Face Hub TL;DR: Today, Meta releases Llama Guard 4, a 12B dense (...",
    "pubDate": "Tue, 29 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama-guard-4",
    "thumbnail": "https://huggingface.co/blog/assets/llama-guard-4/thumbnail.png"
  },
  {
    "title": "Introducing Spaces Dev Mode for a seamless developer experience",
    "description": "",
    "summary": "Introducing Spaces Dev Mode for a seamless developer experience Hugging Face Spaces makes it easy fo...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spaces-dev-mode",
    "thumbnail": "https://huggingface.co/blog/assets/spaces-dev-mode/thumbnail.jpg"
  },
  {
    "title": "OpenAI licenses GPT-3 technology to Microsoft",
    "description": "OpenAI has agreed to license GPT-3 to Microsoft for their own products and services.",
    "summary": "OpenAI has agreed to license GPT-3 to Microsoft for their own products and services.",
    "pubDate": "Tue, 22 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-licenses-gpt-3-technology-to-microsoft",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Investigating the Impact of Quantization Methods on the Safety and Reliability of Large Language Models",
    "description": "arXiv:2502.15799v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are powerful tools for modern applications, but their computational demands limit accessibility. Quantization offers efficiency gains, yet its impact on safety and trustworthiness remains poorly understood. To address this, we introduce OpenMiniSafety, a human-curated safety dataset with 1.067 challenging questions to rigorously evaluate model behavior. We publicly release human safety evaluations for four LLMs (both quantized and full-precision), totaling 4.268 annotated question-answer pairs. By assessing 66 quantized variants of these models using four post-training quantization (PTQ) and two quantization-aware training (QAT) methods across four safety benchmarks including human-centric evaluations we uncover critical safety performance trade-offs. Our results show both PTQ and QAT can degrade safety alignment, with QAT techniques like QLORA or STE performing less safely. No single method consistently outperforms others across benchmarks, precision settings, or models, highlighting the need for safety-aware compression strategies. Furthermore, precision-specialized methods (e.g., QUIK and AWQ for 4-bit, AQLM and Q-PET for 2-bit) excel at their target precision, meaning that these methods are not better at compressing but rather different approaches.",
    "summary": "arXiv:2502.15799v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are powerful tools for modern applications, but their computational demands limit accessibility. Quantization offers efficiency gains, yet its impact on safety and trustworthiness remains poorly understood. To address this, we introduce OpenMiniSafety, a human-curated safety dataset with 1.067 challenging questions to rigorously evaluate model behavior. We publicly release human safety evaluations for four LLMs (both quantized and full-precision), totaling 4.268 annotated question-answer pairs. By assessing 66 quantized variants of these models using four post-training quantization (PTQ) and two quantization-aware training (QAT) methods across four safety benchmarks including human-centric evaluations we uncover critical safety performance trade-offs. Our results show both PTQ and QAT can degrade safety alignment, with QAT techniques like QLORA or STE performing less safely. No single method consistently outperforms others across benchmarks, precision settings, or models, highlighting the need for safety-aware compression strategies. Furthermore, precision-specialized methods (e.g., QUIK and AWQ for 4-bit, AQLM and Q-PET for 2-bit) excel at their target precision, meaning that these methods are not better at compressing but rather different approaches.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.15799",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fixing Gradient Accumulation",
    "description": "",
    "summary": "Fixing Gradient Accumulation Our friends at Unsloth shared an issue regarding gradient accumulation ...",
    "pubDate": "Wed, 16 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradient_accumulation",
    "thumbnail": "https://huggingface.co/blog/assets/gradient_accumulation/gradient_accumulation.png"
  },
  {
    "title": "Discovering types for entity disambiguation",
    "description": "We‚Äôve built a system for automatically figuring out which object is meant by a word by having a neural network decide if the word belongs to each of about 100 automatically-discovered ‚Äútypes‚Äù (non-exclusive categories).",
    "summary": "We‚Äôve built a system for automatically figuring out which object is meant by a word by having a neural network decide if the word belongs to each of about 100 automatically-discovered ‚Äútypes‚Äù (non-exclusive categories).",
    "pubDate": "Wed, 07 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/discovering-types-for-entity-disambiguation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Asymmetric actor critic for image-based robot learning",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 18 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/asymmetric-actor-critic-for-image-based-robot-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "HyperMono: A Monotonicity-aware Approach to Hyper-Relational Knowledge Representation",
    "description": "arXiv:2404.09848v3 Announce Type: replace Abstract: In a hyper-relational knowledge graph (HKG), each fact is composed of a main triple associated with attribute-value qualifiers, which express additional factual knowledge. The hyper-relational knowledge graph completion (HKGC) task aims at inferring plausible missing links in a HKG. Most existing approaches to HKGC focus on enhancing the communication between qualifier pairs and main triples, while overlooking two important properties that emerge from the monotonicity of the hyper-relational graphs representation regime. Stage Reasoning allows for a two-step reasoning process, facilitating the integration of coarse-grained inference results derived solely from main triples and fine-grained inference results obtained from hyper-relational facts with qualifiers. In the initial stage, coarse-grained results provide an upper bound for correct predictions, which are subsequently refined in the fine-grained step. More generally, Qualifier Monotonicity implies that by attaching more qualifier pairs to a main triple, we may only narrow down the answer set, but never enlarge it. This paper proposes the HyperMono model for hyper-relational knowledge graph completion, which realizes stage reasoning and qualifier monotonicity. To implement qualifier monotonicity HyperMono resorts to cone embeddings. Experiments on three real-world datasets with three different scenario conditions demonstrate the strong performance of HyperMono when compared to the SoTA.",
    "summary": "arXiv:2404.09848v3 Announce Type: replace Abstract: In a hyper-relational knowledge graph (HKG), each fact is composed of a main triple associated with attribute-value qualifiers, which express additional factual knowledge. The hyper-relational knowledge graph completion (HKGC) task aims at inferring plausible missing links in a HKG. Most existing approaches to HKGC focus on enhancing the communication between qualifier pairs and main triples, while overlooking two important properties that emerge from the monotonicity of the hyper-relational graphs representation regime. Stage Reasoning allows for a two-step reasoning process, facilitating the integration of coarse-grained inference results derived solely from main triples and fine-grained inference results obtained from hyper-relational facts with qualifiers. In the initial stage, coarse-grained results provide an upper bound for correct predictions, which are subsequently refined in the fine-grained step. More generally, Qualifier Monotonicity implies that by attaching more qualifier pairs to a main triple, we may only narrow down the answer set, but never enlarge it. This paper proposes the HyperMono model for hyper-relational knowledge graph completion, which realizes stage reasoning and qualifier monotonicity. To implement qualifier monotonicity HyperMono resorts to cone embeddings. Experiments on three real-world datasets with three different scenario conditions demonstrate the strong performance of HyperMono when compared to the SoTA.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2404.09848",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI o1 and new tools for developers",
    "description": "Introducing OpenAI o1, Realtime API improvements, a new fine-tuning method and more for developers.",
    "summary": "Introducing OpenAI o1, Realtime API improvements, a new fine-tuning method and more for developers.",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-and-new-tools-for-developers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The AI for Science Forum: A new era of discovery",
    "description": "The AI Science Forum highlights AI's present and potential role in revolutionizing scientific discovery and solving global challenges, emphasizing collaboration between the scientific community, policymakers, and industry leaders.",
    "summary": "The AI Science Forum highlights AI's present and potential role in revolutionizing scientific discovery and solving global challenges, emphasizing collaboration between the scientific community, policymakers, and industry leaders.",
    "pubDate": "Mon, 18 Nov 2024 19:57:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/the-ai-for-science-forum-a-new-era-of-discovery/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AIFS_Collection_SS.max-1440x810.jpg"
  },
  {
    "title": "OpenAI‚Äôs Raising Concerns Policy",
    "description": "We‚Äôre publishing our Raising Concerns Policy, which protects employees‚Äô rights to make protected disclosures.",
    "summary": "We‚Äôre publishing our Raising Concerns Policy, which protects employees‚Äô rights to make protected disclosures.",
    "pubDate": "Fri, 04 Oct 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-raising-concerns-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Data Can Speak for Itself: Quality-guided Utilization of Wireless Synthetic Data",
    "description": "arXiv:2506.23174v1 Announce Type: cross Abstract: Generative models have gained significant attention for their ability to produce realistic synthetic data that supplements the quantity of real-world datasets. While recent studies show performance improvements in wireless sensing tasks by incorporating all synthetic data into training sets, the quality of synthetic data remains unpredictable and the resulting performance gains are not guaranteed. To address this gap, we propose tractable and generalizable metrics to quantify quality attributes of synthetic data - affinity and diversity. Our assessment reveals prevalent affinity limitation in current wireless synthetic data, leading to mislabeled data and degraded task performance. We attribute the quality limitation to generative models' lack of awareness of untrained conditions and domain-specific processing. To mitigate these issues, we introduce SynCheck, a quality-guided synthetic data utilization scheme that refines synthetic data quality during task model training. Our evaluation demonstrates that SynCheck consistently outperforms quality-oblivious utilization of synthetic data, and achieves 4.3% performance improvement even when the previous utilization degrades performance by 13.4%.",
    "summary": "arXiv:2506.23174v1 Announce Type: cross Abstract: Generative models have gained significant attention for their ability to produce realistic synthetic data that supplements the quantity of real-world datasets. While recent studies show performance improvements in wireless sensing tasks by incorporating all synthetic data into training sets, the quality of synthetic data remains unpredictable and the resulting performance gains are not guaranteed. To address this gap, we propose tractable and generalizable metrics to quantify quality attributes of synthetic data - affinity and diversity. Our assessment reveals prevalent affinity limitation in current wireless synthetic data, leading to mislabeled data and degraded task performance. We attribute the quality limitation to generative models' lack of awareness of untrained conditions and domain-specific processing. To mitigate these issues, we introduce SynCheck, a quality-guided synthetic data utilization scheme that refines synthetic data quality during task model training. Our evaluation demonstrates that SynCheck consistently outperforms quality-oblivious utilization of synthetic data, and achieves 4.3% performance improvement even when the previous utilization degrades performance by 13.4%.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23174",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Inception Labs„ÅÆÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÇíË©¶„Åó„Å¶„Åø„Åü",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Êú¨Ë®ò‰∫ã„Åß„ÅØInception Labs„ÅÆMercury API„ÅÆ„Éô„Éº„ÇøÁâà„Åå‰Ωø„Åà„Çã„Çà„ÅÜ„Å´„Å™„Å£„Åü„ÅÆ„Åß„ÄÅÁ∞°Âçò„Å´Ë©¶„Åó„Å¶„Åø„Åæ„Åó„Åü„ÄÇ „Éâ„Ç≠„É•„É°„É≥„Éà„ÅØ„Åì„Å°„Çâ„ÅßÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ Êã°Êï£Ë®ÄË™û„É¢„Éá„É´ ÁèæÂú®„ÅÆ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5738' rel='nofollow'>Inception Labs„ÅÆÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÇíË©¶„Åó„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Êú¨Ë®ò‰∫ã„Åß„ÅØInception Labs„ÅÆMercury API„ÅÆ„Éô„Éº„ÇøÁâà„Åå‰Ωø„Åà„Çã„Çà„ÅÜ„Å´„Å™„Å£„Åü„ÅÆ„Åß„ÄÅÁ∞°Âçò„Å´Ë©¶„Åó„Å¶„Åø„Åæ„Åó„Åü„ÄÇ „Éâ„Ç≠„É•„É°„É≥„Éà„ÅØ„Åì„Å°„Çâ„ÅßÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ Êã°Êï£Ë®ÄË™û„É¢„Éá„É´ ÁèæÂú®„ÅÆ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5738' rel='nofollow'>Inception Labs„ÅÆÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÇíË©¶„Åó„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Thu, 01 May 2025 03:02:11 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5738",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "AI and efficiency",
    "description": "We‚Äôre releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet¬†classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet¬†(by contrast, Moore‚Äôs Law¬†would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware¬†efficiency.",
    "summary": "We‚Äôre releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet¬†classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet¬†(by contrast, Moore‚Äôs Law¬†would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware¬†efficiency.",
    "pubDate": "Tue, 05 May 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-and-efficiency",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building a data-driven, efficient culture with AI",
    "description": "Holiday Extras rolls out ChatGPT Enterprise across every team, boosting productivity by 500 hours weekly.",
    "summary": "Holiday Extras rolls out ChatGPT Enterprise across every team, boosting productivity by 500 hours weekly.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/holiday-extras",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating fairness in ChatGPT",
    "description": "We've analyzed how ChatGPT responds to users based on their name, using AI research assistants to protect privacy.",
    "summary": "We've analyzed how ChatGPT responds to users based on their name, using AI research assistants to protect privacy.",
    "pubDate": "Tue, 15 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evaluating-fairness-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "We Raised $100 Million for Open & Collaborative Machine Learning üöÄ",
    "description": "",
    "summary": "We Raised $100 Million for Open & Collaborative Machine Learning üöÄ Today we have some exciting news ...",
    "pubDate": "Mon, 09 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/series-c",
    "thumbnail": "https://huggingface.co/blog/assets/65_series_c/thumbnail.jpg"
  },
  {
    "title": "Peer Review as Structured Commentary: Immutable Identity, Public Dialogue, and Reproducible Scholarship",
    "description": "arXiv:2506.22497v1 Announce Type: cross Abstract: This paper reconceptualises peer review as structured public commentary. Traditional academic validation is hindered by anonymity, latency, and gatekeeping. We propose a transparent, identity-linked, and reproducible system of scholarly evaluation anchored in open commentary. Leveraging blockchain for immutable audit trails and AI for iterative synthesis, we design a framework that incentivises intellectual contribution, captures epistemic evolution, and enables traceable reputational dynamics. This model empowers fields from computational science to the humanities, reframing academic knowledge as a living process rather than a static credential.",
    "summary": "arXiv:2506.22497v1 Announce Type: cross Abstract: This paper reconceptualises peer review as structured public commentary. Traditional academic validation is hindered by anonymity, latency, and gatekeeping. We propose a transparent, identity-linked, and reproducible system of scholarly evaluation anchored in open commentary. Leveraging blockchain for immutable audit trails and AI for iterative synthesis, we design a framework that incentivises intellectual contribution, captures epistemic evolution, and enables traceable reputational dynamics. This model empowers fields from computational science to the humanities, reframing academic knowledge as a living process rather than a static credential.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22497",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "New commission to provide insight as OpenAI builds the world‚Äôs best-equipped nonprofit",
    "description": "Already a nonprofit, and already using AI to help people solve hard problems, OpenAI aims to build the best-equipped nonprofit the world has ever seen‚Äîcombining potentially historic financial resources with something even more powerful: technology that can scale human ingenuity itself.",
    "summary": "Already a nonprofit, and already using AI to help people solve hard problems, OpenAI aims to build the best-equipped nonprofit the world has ever seen‚Äîcombining potentially historic financial resources with something even more powerful: technology that can scale human ingenuity itself.",
    "pubDate": "Wed, 02 Apr 2025 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonprofit-commission-guidance",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Enabling a Data-Driven Workforce",
    "description": "In this video, we share practical examples of how employees can use ChatGPT Enterprise to efficiently analyze data and uncover insights.",
    "summary": "In this video, we share practical examples of how employees can use ChatGPT Enterprise to efficiently analyze data and uncover insights.",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/enabling-a-data-driven-workforce-webinar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A catalogue of genetic mutations to help pinpoint the cause of diseases",
    "description": "New AI tool classifies the effects of 71 million ‚Äòmissense‚Äô mutations.",
    "summary": "New AI tool classifies the effects of 71 million ‚Äòmissense‚Äô mutations.",
    "pubDate": "Tue, 19 Sep 2023 13:37:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/a-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases/",
    "thumbnail": "https://lh3.googleusercontent.com/JySjDTZvGqEzUfDic5QOU6Rne3r6RWpiw5JZQ9VdzK1O5C20EbAkSPURGoCmAhea_U-gyyRu4KdCZmeWSCtYjGHHMvM0jVK5fWiqOwa0rpcC5uzM=w1200-h630-n-nu"
  },
  {
    "title": "Introducing HuggingFace blog for Chinese speakers: Fostering Collaboration with the Chinese AI community",
    "description": "",
    "summary": "Introducing HuggingFace blog for Chinese speakers: Fostering Collaboration with the Chinese AI commu...",
    "pubDate": "Mon, 24 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chinese-language-blog",
    "thumbnail": "https://huggingface.co/blog/assets/chinese-language-blog/thumbnail.png"
  },
  {
    "title": "Enhancing Diffusion Posterior Sampling for Inverse Problems by Integrating Crafted Measurements",
    "description": "arXiv:2411.09850v2 Announce Type: replace-cross Abstract: Diffusion models have emerged as a powerful foundation model for visual generations. With an appropriate sampling process, it can effectively serve as a generative prior for solving general inverse problems. Current posterior sampling-based methods take the measurement (i.e., degraded image sample) into the posterior sampling to infer the distribution of the target data (i.e., clean image sample). However, in this manner, we show that high-frequency information can be prematurely introduced during the early stages, which could induce larger posterior estimate errors during restoration sampling. To address this observation, we first reveal that forming the log-posterior gradient with the noisy measurement ( i.e., noisy measurement from a diffusion forward process) instead of the clean one can benefit the early posterior sampling. Consequently, we propose a novel diffusion posterior sampling method DPS-CM, which incorporates a Crafted Measurement (i.e., noisy measurement crafted by a reverse denoising process, rather than constructed from the diffusion forward process) to form the posterior estimate. This integration aims to mitigate the misalignment with the diffusion prior caused by cumulative posterior estimate errors. Experimental results demonstrate that our approach significantly improves the overall capacity to solve general and noisy inverse problems, such as Gaussian deblurring, super-resolution, inpainting, nonlinear deblurring, and tasks with Poisson noise, relative to existing approaches. Code is available at: https://github.com/sjz5202/DPS-CM.",
    "summary": "arXiv:2411.09850v2 Announce Type: replace-cross Abstract: Diffusion models have emerged as a powerful foundation model for visual generations. With an appropriate sampling process, it can effectively serve as a generative prior for solving general inverse problems. Current posterior sampling-based methods take the measurement (i.e., degraded image sample) into the posterior sampling to infer the distribution of the target data (i.e., clean image sample). However, in this manner, we show that high-frequency information can be prematurely introduced during the early stages, which could induce larger posterior estimate errors during restoration sampling. To address this observation, we first reveal that forming the log-posterior gradient with the noisy measurement ( i.e., noisy measurement from a diffusion forward process) instead of the clean one can benefit the early posterior sampling. Consequently, we propose a novel diffusion posterior sampling method DPS-CM, which incorporates a Crafted Measurement (i.e., noisy measurement crafted by a reverse denoising process, rather than constructed from the diffusion forward process) to form the posterior estimate. This integration aims to mitigate the misalignment with the diffusion prior caused by cumulative posterior estimate errors. Experimental results demonstrate that our approach significantly improves the overall capacity to solve general and noisy inverse problems, such as Gaussian deblurring, super-resolution, inpainting, nonlinear deblurring, and tasks with Poisson noise, relative to existing approaches. Code is available at: https://github.com/sjz5202/DPS-CM.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.09850",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Training CodeParrot ü¶ú from Scratch",
    "description": "",
    "summary": "Training CodeParrot ü¶ú from Scratch In this blog post we'll take a look at what it takes to build the...",
    "pubDate": "Wed, 08 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codeparrot",
    "thumbnail": "https://huggingface.co/blog/assets/40_codeparrot/thumbnail.png"
  },
  {
    "title": "Introducing Gemini 2.5 Flash",
    "description": "Gemini 2.5 Flash is our first fully hybrid reasoning model, giving developers the ability to turn thinking on or off.",
    "summary": "Gemini 2.5 Flash is our first fully hybrid reasoning model, giving developers the ability to turn thinking on or off.",
    "pubDate": "Thu, 17 Apr 2025 19:02:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-2-5-flash/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini-2-5-Flash-ai.dev.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Report from the self-organizing conference",
    "description": "Last week we hosted over a hundred and fifty AI practitioners in our offices for our first self-organizing conference on machine learning.",
    "summary": "Last week we hosted over a hundred and fifty AI practitioners in our offices for our first self-organizing conference on machine learning.",
    "pubDate": "Thu, 13 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/report-from-the-self-organizing-conference",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Toward understanding and preventing misalignment generalization",
    "description": "We study how training on incorrect responses can cause broader misalignment in language models and identify an internal feature driving this behavior‚Äîone that can be reversed with minimal fine-tuning.",
    "summary": "We study how training on incorrect responses can cause broader misalignment in language models and identify an internal feature driving this behavior‚Äîone that can be reversed with minimal fine-tuning.",
    "pubDate": "Wed, 18 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergent-misalignment",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Score-based Diffusion Model for Unpaired Virtual Histology Staining",
    "description": "arXiv:2506.23184v1 Announce Type: cross Abstract: Hematoxylin and eosin (H&amp;E) staining visualizes histology but lacks specificity for diagnostic markers. Immunohistochemistry (IHC) staining provides protein-targeted staining but is restricted by tissue availability and antibody specificity. Virtual staining, i.e., computationally translating the H&amp;E image to its IHC counterpart while preserving the tissue structure, is promising for efficient IHC generation. Existing virtual staining methods still face key challenges: 1) effective decomposition of staining style and tissue structure, 2) controllable staining process adaptable to diverse tissue and proteins, and 3) rigorous structural consistency modelling to handle the non-pixel-aligned nature of paired H&amp;E and IHC images. This study proposes a mutual-information (MI)-guided score-based diffusion model for unpaired virtual staining. Specifically, we design 1) a global MI-guided energy function that disentangles the tissue structure and staining characteristics across modalities, 2) a novel timestep-customized reverse diffusion process for precise control of the staining intensity and structural reconstruction, and 3) a local MI-driven contrastive learning strategy to ensure the cellular level structural consistency between H&amp;E-IHC images. Extensive experiments demonstrate the our superiority over state-of-the-art approaches, highlighting its biomedical potential. Codes will be open-sourced upon acceptance.",
    "summary": "arXiv:2506.23184v1 Announce Type: cross Abstract: Hematoxylin and eosin (H&amp;E) staining visualizes histology but lacks specificity for diagnostic markers. Immunohistochemistry (IHC) staining provides protein-targeted staining but is restricted by tissue availability and antibody specificity. Virtual staining, i.e., computationally translating the H&amp;E image to its IHC counterpart while preserving the tissue structure, is promising for efficient IHC generation. Existing virtual staining methods still face key challenges: 1) effective decomposition of staining style and tissue structure, 2) controllable staining process adaptable to diverse tissue and proteins, and 3) rigorous structural consistency modelling to handle the non-pixel-aligned nature of paired H&amp;E and IHC images. This study proposes a mutual-information (MI)-guided score-based diffusion model for unpaired virtual staining. Specifically, we design 1) a global MI-guided energy function that disentangles the tissue structure and staining characteristics across modalities, 2) a novel timestep-customized reverse diffusion process for precise control of the staining intensity and structural reconstruction, and 3) a local MI-driven contrastive learning strategy to ensure the cellular level structural consistency between H&amp;E-IHC images. Extensive experiments demonstrate the our superiority over state-of-the-art approaches, highlighting its biomedical potential. Codes will be open-sourced upon acceptance.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23184",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLMs factor in unrelated information when recommending medical treatments",
    "description": "Researchers find nonclinical information in patient messages ‚Äî like typos, extra white space, and colorful language ‚Äî reduces the accuracy of an AI model.",
    "summary": "Researchers find nonclinical information in patient messages ‚Äî like typos, extra white space, and colorful language ‚Äî reduces the accuracy of an AI model.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/llms-factor-unrelated-information-when-recommending-medical-treatments-0623",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_Medium-Message-01-press.jpg"
  },
  {
    "title": "Concrete AI safety problems",
    "description": "We (along with researchers from Berkeley and Stanford) are co-authors on today‚Äôs paper led by Google Brain researchers,¬†Concrete Problems in AI Safety. The paper explores many research problems around ensuring that modern machine learning systems operate as intended.",
    "summary": "We (along with researchers from Berkeley and Stanford) are co-authors on today‚Äôs paper led by Google Brain researchers,¬†Concrete Problems in AI Safety. The paper explores many research problems around ensuring that modern machine learning systems operate as intended.",
    "pubDate": "Tue, 21 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/concrete-ai-safety-problems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How to host a Unity game in a Space",
    "description": "",
    "summary": "How to host a Unity game in a Space Did you know you can host a Unity game in a Hugging Face Space? ...",
    "pubDate": "Fri, 21 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-in-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-in-spaces-thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT Enterprise",
    "description": "Get enterprise-grade security & privacy and the most powerful version of ChatGPT yet.",
    "summary": "Get enterprise-grade security & privacy and the most powerful version of ChatGPT yet.",
    "pubDate": "Mon, 28 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Êó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶Âàù„ÄÅÊù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅåNVIDIA DGX„ÅÆAI„Çπ„Éë„Ç≥„É≥„ÇíÊßãÁØâ„ÄÇ„ÄåAIÂ§ßÂ≠¶„ÄçÊßãÊÉ≥„ÇíÂä†ÈÄü",
    "description": "<p>Êù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅØ„ÄÅAIÊïôËÇ≤„Å®Á†îÁ©∂„ÇíÂä†ÈÄü„Åï„Åõ„Çã„Åü„ÇÅ„ÄÅNVIDIA DGX B200„Ç∑„Çπ„ÉÜ„É†„ÇíÁî®„ÅÑ„ÅüÊó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶ÊúÄÂ§ß„ÅÆAI„Çπ„Éº„Éë„Éº„Ç≥„É≥„Éî„É•„Éº„Çø„Éº„ÇíÊßãÁØâ„Åó„ÄÅ2025Âπ¥10Êúà„Å´Êú¨Ê†ºÁ®ºÂÉç‰∫àÂÆö„Åß„Åô„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Êù±‰∫¨Â∑•Áßë [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/teu-ac-nvidia-dgx/'>Êó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶Âàù„ÄÅÊù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅåNVIDIA DGX„ÅÆAI„Çπ„Éë„Ç≥„É≥„ÇíÊßãÁØâ„ÄÇ„ÄåAIÂ§ßÂ≠¶„ÄçÊßãÊÉ≥„ÇíÂä†ÈÄü</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>Êù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅØ„ÄÅAIÊïôËÇ≤„Å®Á†îÁ©∂„ÇíÂä†ÈÄü„Åï„Åõ„Çã„Åü„ÇÅ„ÄÅNVIDIA DGX B200„Ç∑„Çπ„ÉÜ„É†„ÇíÁî®„ÅÑ„ÅüÊó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶ÊúÄÂ§ß„ÅÆAI„Çπ„Éº„Éë„Éº„Ç≥„É≥„Éî„É•„Éº„Çø„Éº„ÇíÊßãÁØâ„Åó„ÄÅ2025Âπ¥10Êúà„Å´Êú¨Ê†ºÁ®ºÂÉç‰∫àÂÆö„Åß„Åô„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Êù±‰∫¨Â∑•Áßë [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/teu-ac-nvidia-dgx/'>Êó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶Âàù„ÄÅÊù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅåNVIDIA DGX„ÅÆAI„Çπ„Éë„Ç≥„É≥„ÇíÊßãÁØâ„ÄÇ„ÄåAIÂ§ßÂ≠¶„ÄçÊßãÊÉ≥„ÇíÂä†ÈÄü</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Wed, 25 Jun 2025 09:24:03 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/teu-ac-nvidia-dgx/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/teu0.png"
  },
  {
    "title": "LLM„ÅßÊåë„ÇÄTitanicÁîüÂ≠ò‰∫àÊ∏¨: Few-Shot Leaning„ÅßË°®ÂΩ¢Âºè„Éá„Éº„Çø„ÅØ„Å©„Åì„ÅæËß£„Åë„ÇãÔºü",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Kaggle„ÅÆTitanic„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ„ÄÅÊ©üÊ¢∞Â≠¶Áøí„ÅÆÂÖ•ÈñÄ„Å®„Åó„Å¶ÂÆöÁï™„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ Â§ö„Åè„ÅÆÊ©üÊ¢∞Â≠¶ÁøíÊâãÊ≥ï„ÅåË©¶„Åï„Çå„Å¶„Åç„Åü„Åì„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´ÂØæ„Åó„ÄÅ‰ªäÂõû„ÅØÂ∞ë„ÅóÁï∞„Å™„Çã„Ç¢„Éó„É≠„Éº„ÉÅ„ÇíË©¶„Åø„Åü„ÅÑ„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5560' rel='nofollow'>LLM„ÅßÊåë„ÇÄTitanicÁîüÂ≠ò‰∫àÊ∏¨: Few-Shot Leaning„ÅßË°®ÂΩ¢Âºè„Éá„Éº„Çø„ÅØ„Å©„Åì„ÅæËß£„Åë„ÇãÔºü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Kaggle„ÅÆTitanic„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ„ÄÅÊ©üÊ¢∞Â≠¶Áøí„ÅÆÂÖ•ÈñÄ„Å®„Åó„Å¶ÂÆöÁï™„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ Â§ö„Åè„ÅÆÊ©üÊ¢∞Â≠¶ÁøíÊâãÊ≥ï„ÅåË©¶„Åï„Çå„Å¶„Åç„Åü„Åì„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´ÂØæ„Åó„ÄÅ‰ªäÂõû„ÅØÂ∞ë„ÅóÁï∞„Å™„Çã„Ç¢„Éó„É≠„Éº„ÉÅ„ÇíË©¶„Åø„Åü„ÅÑ„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5560' rel='nofollow'>LLM„ÅßÊåë„ÇÄTitanicÁîüÂ≠ò‰∫àÊ∏¨: Few-Shot Leaning„ÅßË°®ÂΩ¢Âºè„Éá„Éº„Çø„ÅØ„Å©„Åì„ÅæËß£„Åë„ÇãÔºü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Mon, 17 Mar 2025 21:16:00 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5560",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/f81fd2e4c52864042852c112ce927ae2.png"
  },
  {
    "title": "Achieving 10x growth with agentic sales prospecting",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Jun 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/clay",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New funding to build towards AGI",
    "description": "Today we‚Äôre announcing new funding‚Äî$40B at a $300B post-money valuation, which enables us to push the frontiers of AI research even further, scale our compute infrastructure, and deliver increasingly powerful tools for the 500 million people who use ChatGPT every week.",
    "summary": "Today we‚Äôre announcing new funding‚Äî$40B at a $300B post-money valuation, which enables us to push the frontiers of AI research even further, scale our compute infrastructure, and deliver increasingly powerful tools for the 500 million people who use ChatGPT every week.",
    "pubDate": "Mon, 31 Mar 2025 15:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/march-funding-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Rationality in the Reasoning Process of Language Models through Self-playing Game",
    "description": "arXiv:2506.22920v1 Announce Type: new Abstract: Large language models (LLMs) have demonstrated considerable reasoning abilities in various tasks such as mathematics and coding. However, recent studies indicate that even the best models lack true comprehension of their reasoning processes. In this paper, we explore how self-play can enhance the rationality of models in the reasoning process without supervision from humans or superior models. We design a Critic-Discernment Game(CDG) in which a prover first provides a solution to a given problem and is subsequently challenged by critiques of its solution. These critiques either aim to assist or mislead the prover. The objective of the prover is to maintain the correct answer when faced with misleading comments, while correcting errors in response to constructive feedback. Our experiments on tasks involving mathematical reasoning, stepwise error detection, self-correction, and long-chain reasoning demonstrate that CDG training can significantly improve the ability of well-aligned LLMs to comprehend their reasoning process.",
    "summary": "arXiv:2506.22920v1 Announce Type: new Abstract: Large language models (LLMs) have demonstrated considerable reasoning abilities in various tasks such as mathematics and coding. However, recent studies indicate that even the best models lack true comprehension of their reasoning processes. In this paper, we explore how self-play can enhance the rationality of models in the reasoning process without supervision from humans or superior models. We design a Critic-Discernment Game(CDG) in which a prover first provides a solution to a given problem and is subsequently challenged by critiques of its solution. These critiques either aim to assist or mislead the prover. The objective of the prover is to maintain the correct answer when faced with misleading comments, while correcting errors in response to constructive feedback. Our experiments on tasks involving mathematical reasoning, stepwise error detection, self-correction, and long-chain reasoning demonstrate that CDG training can significantly improve the ability of well-aligned LLMs to comprehend their reasoning process.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22920",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DolphinGemma: How Google AI is helping decode dolphin communication",
    "description": "DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate ‚Äî and hopefully find out what they're saying, too.",
    "summary": "DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate ‚Äî and hopefully find out what they're saying, too.",
    "pubDate": "Mon, 14 Apr 2025 17:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/dolphingemma-how-google-ai-is-helping-decode-dolphin-communication/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_SocialExplainers_16x9_DolphinGem.width-1300.png"
  },
  {
    "title": "Scaling security with responsible disclosure",
    "description": "OpenAI introduces its Outbound Coordinated Disclosure Policy to guide how it responsibly reports vulnerabilities in third-party software‚Äîemphasizing integrity, collaboration, and proactive security at scale.",
    "summary": "OpenAI introduces its Outbound Coordinated Disclosure Policy to guide how it responsibly reports vulnerabilities in third-party software‚Äîemphasizing integrity, collaboration, and proactive security at scale.",
    "pubDate": "Mon, 09 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-coordinated-vulnerability-disclosure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fanatics Betting and Gaming uses AI to focus on the big picture",
    "description": "A conversation with Andrea Ellis, Chief Financial Officer of Fanatics Betting and Gaming.",
    "summary": "A conversation with Andrea Ellis, Chief Financial Officer of Fanatics Betting and Gaming.",
    "pubDate": "Thu, 13 Feb 2025 10:01:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fanatics-betting-gaming-andrea-ellis",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Prompt Caching in the API",
    "description": "Offering automatic discounts on inputs that the model has recently seen",
    "summary": "Offering automatic discounts on inputs that the model has recently seen",
    "pubDate": "Tue, 01 Oct 2024 10:03:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-prompt-caching",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Domain randomization and generative models for robotic grasping",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 17 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/domain-randomization-and-generative-models-for-robotic-grasping",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking in Large Language Models",
    "description": "arXiv:2505.17312v3 Announce Type: replace Abstract: LLMs often need effective configurations, like temperature and reasoning steps, to handle tasks requiring sophisticated reasoning and problem-solving, ranging from joke generation to mathematical reasoning. Existing prompting approaches usually adopt general-purpose, fixed configurations that work 'well enough' across tasks but seldom achieve task-specific optimality. To address this gap, we introduce AdaReasoner, an LLM-agnostic plugin designed for any LLM to automate adaptive reasoning configurations for tasks requiring different types of thinking. AdaReasoner is trained using a reinforcement learning (RL) framework, combining a factorized action space with a targeted exploration strategy, along with a pretrained reward model to optimize the policy model for reasoning configurations with only a few-shot guide. AdaReasoner is backed by theoretical guarantees and experiments of fast convergence and a sublinear policy gap. Across six different LLMs and a variety of reasoning tasks, it consistently outperforms standard baselines, preserves out-of-distribution robustness, and yield gains on knowledge-intensive tasks through tailored prompts.",
    "summary": "arXiv:2505.17312v3 Announce Type: replace Abstract: LLMs often need effective configurations, like temperature and reasoning steps, to handle tasks requiring sophisticated reasoning and problem-solving, ranging from joke generation to mathematical reasoning. Existing prompting approaches usually adopt general-purpose, fixed configurations that work 'well enough' across tasks but seldom achieve task-specific optimality. To address this gap, we introduce AdaReasoner, an LLM-agnostic plugin designed for any LLM to automate adaptive reasoning configurations for tasks requiring different types of thinking. AdaReasoner is trained using a reinforcement learning (RL) framework, combining a factorized action space with a targeted exploration strategy, along with a pretrained reward model to optimize the policy model for reasoning configurations with only a few-shot guide. AdaReasoner is backed by theoretical guarantees and experiments of fast convergence and a sublinear policy gap. Across six different LLMs and a variety of reasoning tasks, it consistently outperforms standard baselines, preserves out-of-distribution robustness, and yield gains on knowledge-intensive tasks through tailored prompts.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.17312",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Scaling laws for reward model overoptimization",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 19 Oct 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-laws-for-reward-model-overoptimization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine tuning CLIP with Remote Sensing (Satellite) images and captions",
    "description": "",
    "summary": "Fine tuning CLIP with Remote Sensing (Satellite) images and captions Fine tuning CLIP with Remote Se...",
    "pubDate": "Wed, 13 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-clip-rsicd",
    "thumbnail": "https://huggingface.co/blog/assets/30_clip_rsicd/clip_schematic.png"
  },
  {
    "title": "Frontier AI regulation: Managing emerging risks to public safety",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 06 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-ai-regulation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Review completed & Altman, Brockman to continue to lead OpenAI",
    "description": "New board members named and enhancements to the governance structure introduced",
    "summary": "New board members named and enhancements to the governance structure introduced",
    "pubDate": "Fri, 08 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/review-completed-altman-brockman-to-continue-to-lead-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating PyTorch distributed fine-tuning with Intel technologies",
    "description": "",
    "summary": "Accelerating PyTorch distributed fine-tuning with Intel technologies For all their amazing performan...",
    "pubDate": "Fri, 19 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerating-pytorch",
    "thumbnail": "https://huggingface.co/blog/assets/36_accelerating_pytorch/04_four_nodes.png"
  },
  {
    "title": "Building an early warning system for LLM-aided biological threat creation",
    "description": "We‚Äôre developing a blueprint for evaluating the risk that a large language model (LLM) could aid someone in creating a biological threat.¬†In an evaluation involving both biology experts and students, we found that GPT-4 provides at most a mild uplift in biological threat creation accuracy. While this uplift is not large enough to be conclusive, our finding is a starting point for continued research and community deliberation.",
    "summary": "We‚Äôre developing a blueprint for evaluating the risk that a large language model (LLM) could aid someone in creating a biological threat.¬†In an evaluation involving both biology experts and students, we found that GPT-4 provides at most a mild uplift in biological threat creation accuracy. While this uplift is not large enough to be conclusive, our finding is a starting point for continued research and community deliberation.",
    "pubDate": "Wed, 31 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/building-an-early-warning-system-for-llm-aided-biological-threat-creation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Treatment, evidence, imitation, and chat",
    "description": "arXiv:2506.23040v1 Announce Type: cross Abstract: Large language models are thought to have potential to aid in medical decision making. We investigate this here. We start with the treatment problem, the patient's core medical decision-making task, which is solved in collaboration with a healthcare provider. We discuss approaches to solving the treatment problem, including -- within evidence-based medicine -- trials and observational data. We then discuss the chat problem, and how this differs from the treatment problem -- in particular as it relates to imitation. We then discuss how a large language model might be used to solve the treatment problem and highlight some of the challenges that emerge. We finally discuss how these challenges relate to evidence-based medicine, and how this might inform next steps.",
    "summary": "arXiv:2506.23040v1 Announce Type: cross Abstract: Large language models are thought to have potential to aid in medical decision making. We investigate this here. We start with the treatment problem, the patient's core medical decision-making task, which is solved in collaboration with a healthcare provider. We discuss approaches to solving the treatment problem, including -- within evidence-based medicine -- trials and observational data. We then discuss the chat problem, and how this differs from the treatment problem -- in particular as it relates to imitation. We then discuss how a large language model might be used to solve the treatment problem and highlight some of the challenges that emerge. We finally discuss how these challenges relate to evidence-based medicine, and how this might inform next steps.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23040",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FunSearch: Making new discoveries in mathematical sciences using Large Language Models",
    "description": "In a paper published in Nature, we introduce FunSearch, a method for searching for ‚Äúfunctions‚Äù written in computer code, and find new solutions in mathematics and computer science. FunSearch works by pairing a pre-trained LLM, whose goal is to provide creative solutions in the form of computer code, with an automated ‚Äúevaluator‚Äù, which guards against hallucinations and incorrect ideas.",
    "summary": "In a paper published in Nature, we introduce FunSearch, a method for searching for ‚Äúfunctions‚Äù written in computer code, and find new solutions in mathematics and computer science. FunSearch works by pairing a pre-trained LLM, whose goal is to provide creative solutions in the form of computer code, with an automated ‚Äúevaluator‚Äù, which guards against hallucinations and incorrect ideas.",
    "pubDate": "Thu, 14 Dec 2023 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/GC6SH0u6DyyCT9C1LH6XXmproSod7o5QGp9-Oe8BsuXyPzBlfcxFHX9pxXg69ZftEVU0Joga7tyo0VwQOSBBrugZ8qfl9_X-pgiH527p71S7DC32Jw=w1200-h630-n-nu"
  },
  {
    "title": "Procgen and MineRL Competitions",
    "description": "We‚Äôre excited to announce that OpenAI is co-organizing two NeurIPS 2020 competitions with AIcrowd, Carnegie Mellon University, and DeepMind, using Procgen Benchmark and MineRL.",
    "summary": "We‚Äôre excited to announce that OpenAI is co-organizing two NeurIPS 2020 competitions with AIcrowd, Carnegie Mellon University, and DeepMind, using Procgen Benchmark and MineRL.",
    "pubDate": "Sat, 20 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/procgen-minerl-competitions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Streamlining financial solutions for safety and growth",
    "description": "Stripe leverages GPT-4 to streamline user experience and combat fraud.",
    "summary": "Stripe leverages GPT-4 to streamline user experience and combat fraud.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/stripe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PaliGemma ‚Äì Google's Cutting-Edge Open Vision Language Model",
    "description": "",
    "summary": "PaliGemma ‚Äì Google's Cutting-Edge Open Vision Language Model Updated on 23-05-2024: We have introduc...",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma/Paligemma.png"
  },
  {
    "title": "Introducing Activation Atlases",
    "description": "We‚Äôve created¬†activation atlases¬†(in¬†collaboration¬†with Google researchers), a new technique for visualizing what interactions between neurons can represent. As AI systems are deployed in increasingly sensitive contexts, having a better understanding of their internal decision-making processes will let us identify weaknesses and investigate¬†failures.",
    "summary": "We‚Äôve created¬†activation atlases¬†(in¬†collaboration¬†with Google researchers), a new technique for visualizing what interactions between neurons can represent. As AI systems are deployed in increasingly sensitive contexts, having a better understanding of their internal decision-making processes will let us identify weaknesses and investigate¬†failures.",
    "pubDate": "Wed, 06 Mar 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-activation-atlases",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Qwen-GUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding",
    "description": "arXiv:2506.23491v1 Announce Type: cross Abstract: This paper introduces Qwen-GUI-3B, a lightweight Vision-Language Model (VLM) specifically designed for Graphical User Interface grounding tasks, achieving performance competitive with significantly larger models. Unlike large-scale VLMs (>7B parameters) that are computationally intensive and impractical for consumer-grade hardware, Qwen-GUI-3B delivers strong grounding accuracy while being fully trainable on a single GPU (RTX 4090). The model incorporates several key innovations: (i) combine cross-platform, multi-resolution dataset of 24K examples from diverse sources including mobile, desktop, and web GUI screenshots to effectively address data scarcity in high-resolution desktop environments; (ii) a two-stage fine-tuning strategy, where initial cross-platform training establishes robust GUI understanding, followed by specialized fine-tuning on high-resolution data to significantly enhance model adaptability; and (iii) data curation and redundancy reduction strategies, demonstrating that randomly sampling a smaller subset with reduced redundancy achieves performance comparable to larger datasets, emphasizing data diversity over sheer volume. Empirical evaluation on standard GUI grounding benchmarks-including ScreenSpot, ScreenSpot-v2, and the challenging ScreenSpot-Pro, highlights Qwen-GUI-3B's exceptional accuracy, achieving 84.9% on ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior models under 4B parameters. Ablation studies validate the critical role of balanced sampling and two-stage fine-tuning in enhancing robustness, particularly in high-resolution desktop scenarios. The Qwen-GUI-3B is available at: https://github.com/Han1018/Qwen-GUI-3B",
    "summary": "arXiv:2506.23491v1 Announce Type: cross Abstract: This paper introduces Qwen-GUI-3B, a lightweight Vision-Language Model (VLM) specifically designed for Graphical User Interface grounding tasks, achieving performance competitive with significantly larger models. Unlike large-scale VLMs (>7B parameters) that are computationally intensive and impractical for consumer-grade hardware, Qwen-GUI-3B delivers strong grounding accuracy while being fully trainable on a single GPU (RTX 4090). The model incorporates several key innovations: (i) combine cross-platform, multi-resolution dataset of 24K examples from diverse sources including mobile, desktop, and web GUI screenshots to effectively address data scarcity in high-resolution desktop environments; (ii) a two-stage fine-tuning strategy, where initial cross-platform training establishes robust GUI understanding, followed by specialized fine-tuning on high-resolution data to significantly enhance model adaptability; and (iii) data curation and redundancy reduction strategies, demonstrating that randomly sampling a smaller subset with reduced redundancy achieves performance comparable to larger datasets, emphasizing data diversity over sheer volume. Empirical evaluation on standard GUI grounding benchmarks-including ScreenSpot, ScreenSpot-v2, and the challenging ScreenSpot-Pro, highlights Qwen-GUI-3B's exceptional accuracy, achieving 84.9% on ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior models under 4B parameters. Ablation studies validate the critical role of balanced sampling and two-stage fine-tuning in enhancing robustness, particularly in high-resolution desktop scenarios. The Qwen-GUI-3B is available at: https://github.com/Han1018/Qwen-GUI-3B",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23491",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing ChatGPT",
    "description": "We‚Äôve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.",
    "summary": "We‚Äôve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.",
    "pubDate": "Wed, 30 Nov 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI for Game Development: Creating a Farming Game in 5 Days. Part 2",
    "description": "",
    "summary": "AI for Game Development: Creating a Farming Game in 5 Days. Part 2 Welcome to AI for Game Developmen...",
    "pubDate": "Mon, 09 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-2",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail2.png"
  },
  {
    "title": "Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU",
    "description": "",
    "summary": "Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU We are excited to officially release the integ...",
    "pubDate": "Thu, 09 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trl-peft",
    "thumbnail": "https://huggingface.co/blog/trl-peft/assets/133_trl_peft/thumbnail.png"
  },
  {
    "title": "Infrastructure for deep learning",
    "description": "Deep learning is an empirical science, and the quality of a group‚Äôs infrastructure is a multiplier on progress. Fortunately, today‚Äôs open-source ecosystem makes it possible for anyone to build great deep learning infrastructure.",
    "summary": "Deep learning is an empirical science, and the quality of a group‚Äôs infrastructure is a multiplier on progress. Fortunately, today‚Äôs open-source ecosystem makes it possible for anyone to build great deep learning infrastructure.",
    "pubDate": "Mon, 29 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/infrastructure-for-deep-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Remove Symmetries to Control Model Expressivity and Improve Optimization",
    "description": "arXiv:2408.15495v4 Announce Type: replace-cross Abstract: When symmetry is present in the loss function, the model is likely to be trapped in a low-capacity state that is sometimes known as a 'collapse'. Being trapped in these low-capacity states can be a major obstacle to training across many scenarios where deep learning technology is applied. We first prove two concrete mechanisms through which symmetries lead to reduced capacities and ignored features during training and inference. We then propose a simple and theoretically justified algorithm, syre, to remove almost all symmetry-induced low-capacity states in neural networks. When this type of entrapment is especially a concern, removing symmetries with the proposed method is shown to correlate well with improved optimization or performance. A remarkable merit of the proposed method is that it is model-agnostic and does not require any knowledge of the symmetry.",
    "summary": "arXiv:2408.15495v4 Announce Type: replace-cross Abstract: When symmetry is present in the loss function, the model is likely to be trapped in a low-capacity state that is sometimes known as a 'collapse'. Being trapped in these low-capacity states can be a major obstacle to training across many scenarios where deep learning technology is applied. We first prove two concrete mechanisms through which symmetries lead to reduced capacities and ignored features during training and inference. We then propose a simple and theoretically justified algorithm, syre, to remove almost all symmetry-induced low-capacity states in neural networks. When this type of entrapment is especially a concern, removing symmetries with the proposed method is shown to correlate well with improved optimization or performance. A remarkable merit of the proposed method is that it is model-agnostic and does not require any knowledge of the symmetry.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.15495",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deploy Meta Llama 3.1 405B on Google Cloud Vertex AI",
    "description": "",
    "summary": "Deploy Meta Llama 3.1 405B on Google Cloud Vertex AI Meta Llama 3.1 is the latest open LLM from Meta...",
    "pubDate": "Mon, 19 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama31-on-vertex-ai",
    "thumbnail": "https://huggingface.co/blog/assets/llama31-on-vertex-ai/thumbnail.png"
  },
  {
    "title": "New tool evaluates progress in reinforcement learning",
    "description": "‚ÄúIntersectionZoo,‚Äù a benchmarking tool, uses a real-world traffic problem to test progress in deep reinforcement learning algorithms.",
    "summary": "‚ÄúIntersectionZoo,‚Äù a benchmarking tool, uses a real-world traffic problem to test progress in deep reinforcement learning algorithms.",
    "pubDate": "Mon, 05 May 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-tool-evaluate-progress-reinforcement-learning-0505",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/Intersection-Zoo.jpg"
  },
  {
    "title": "Train and Fine-Tune Sentence Transformers Models",
    "description": "",
    "summary": "Train and Fine-Tune Sentence Transformers Models This guide is only suited for Sentence Transformers...",
    "pubDate": "Wed, 10 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-train-sentence-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/95_training_st_models/thumbnail.png"
  },
  {
    "title": "Generative language modeling for automated theorem proving",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 07 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generative-language-modeling-for-automated-theorem-proving",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "œÄ0 and œÄ0-FAST: Vision-Language-Action Models for General Robot Control",
    "description": "",
    "summary": "œÄ0 and œÄ0-FAST: Vision-Language-Action Models for General Robot Control We have ported the first rob...",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pi0",
    "thumbnail": "https://huggingface.co/blog/assets/192_pi0/new_thumbnail_pi0.001.png"
  },
  {
    "title": "GraphCast: AI model for faster and more accurate global weather forecasting",
    "description": "We introduce GraphCast, a state-of-the-art AI model able to make medium-range weather forecasts with unprecedented accuracy",
    "summary": "We introduce GraphCast, a state-of-the-art AI model able to make medium-range weather forecasts with unprecedented accuracy",
    "pubDate": "Tue, 14 Nov 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/",
    "thumbnail": "https://lh3.googleusercontent.com/5dL0Cm8RLhoDdfPzVy5MlKB5JDcfYucbgxzNLJVFdtqRe15-bFTvfdOrpqnrM4m5XMEEboWtvyCLQgSCvHEH62QqZZI0V_zuBAz71fghXgU5UNFFwg=w1200-h630-n-nu"
  },
  {
    "title": "Rox goes ‚Äúall in‚Äù on OpenAI",
    "description": "By combining commercial experience and deep LLM expertise with OpenAI‚Äôs models, Rox makes every seller a top 1% seller.",
    "summary": "By combining commercial experience and deep LLM expertise with OpenAI‚Äôs models, Rox makes every seller a top 1% seller.",
    "pubDate": "Tue, 19 Nov 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rox",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Robots that learn",
    "description": "We‚Äôve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can learn a new task after seeing it done once.",
    "summary": "We‚Äôve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can learn a new task after seeing it done once.",
    "pubDate": "Tue, 16 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/robots-that-learn",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing the Hugging Face Fellowship Program",
    "description": "",
    "summary": "Announcing the Hugging Face Fellowship Program The Fellowship is a network of exceptional people fro...",
    "pubDate": "Tue, 17 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fellowship",
    "thumbnail": "https://huggingface.co/blog/assets/62_fellowship/fellowship-thumbnail.png"
  },
  {
    "title": "ChemMiner: A Large Language Model Agent System for Chemical Literature Data Mining",
    "description": "arXiv:2402.12993v2 Announce Type: replace-cross Abstract: The development of AI-assisted chemical synthesis tools requires comprehensive datasets covering diverse reaction types, yet current high-throughput experimental (HTE) approaches are expensive and limited in scope. Chemical literature represents a vast, underexplored data source containing thousands of reactions published annually. However, extracting reaction information from literature faces significant challenges including varied writing styles, complex coreference relationships, and multimodal information presentation. This paper proposes ChemMiner, a novel end-to-end framework leveraging multiple agents powered by large language models (LLMs) to extract high-fidelity chemical data from literature. ChemMiner incorporates three specialized agents: a text analysis agent for coreference mapping, a multimodal agent for non-textual information extraction, and a synthesis analysis agent for data generation. Furthermore, we developed a comprehensive benchmark with expert-annotated chemical literature to evaluate both extraction efficiency and precision. Experimental results demonstrate reaction identification rates comparable to human chemists while significantly reducing processing time, with high accuracy, recall, and F1 scores. Our open-sourced benchmark facilitates future research in chemical literature data mining.",
    "summary": "arXiv:2402.12993v2 Announce Type: replace-cross Abstract: The development of AI-assisted chemical synthesis tools requires comprehensive datasets covering diverse reaction types, yet current high-throughput experimental (HTE) approaches are expensive and limited in scope. Chemical literature represents a vast, underexplored data source containing thousands of reactions published annually. However, extracting reaction information from literature faces significant challenges including varied writing styles, complex coreference relationships, and multimodal information presentation. This paper proposes ChemMiner, a novel end-to-end framework leveraging multiple agents powered by large language models (LLMs) to extract high-fidelity chemical data from literature. ChemMiner incorporates three specialized agents: a text analysis agent for coreference mapping, a multimodal agent for non-textual information extraction, and a synthesis analysis agent for data generation. Furthermore, we developed a comprehensive benchmark with expert-annotated chemical literature to evaluate both extraction efficiency and precision. Experimental results demonstrate reaction identification rates comparable to human chemists while significantly reducing processing time, with high accuracy, recall, and F1 scores. Our open-sourced benchmark facilitates future research in chemical literature data mining.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2402.12993",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Prediction and control with temporal segment models",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 12 Mar 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/prediction-and-control-with-temporal-segment-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sam & Jony",
    "description": "Sam & Jony",
    "summary": "Sam & Jony",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/sam-and-jony",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introduction to 3D Gaussian Splatting",
    "description": "",
    "summary": "Introduction to 3D Gaussian Splatting 3D Gaussian Splatting is a rasterization technique described i...",
    "pubDate": "Mon, 18 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gaussian-splatting",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail-gaussian-splatting.png"
  },
  {
    "title": "Interpretable Time Series Autoregression for Periodicity Quantification",
    "description": "arXiv:2506.22895v1 Announce Type: cross Abstract: Time series autoregression is a classical statistical model for capturing auto-correlations and identifying temporal patterns such as periodicity and seasonality. In this work, we propose a novel sparse autoregression framework from an interpretable machine learning perspective and the model interpretability for periodicity quantification is reinforced by $ell_0$-norm induced sparsity constraints. On the time-varying time series data, we reformulate the sparse autoregression and convert the involved optimization problem into a mixed-integer optimization (MIO). To accelerate it, we develop a subspace pursuit based decision variable pruning (DVP) strategy to reduce the search space. On the multidimensional time series that involves complicated spatial and temporal dimensions, we propose a spatially- and time-varying sparse autoregression model and resolve the corresponding MIO problem by developing a two-stage optimization scheme. In particular, the proposed scheme makes the model scalable to large problems even with millions of decision variables. Empirically, we conduct extensive experiments to evaluate the proposed models on real-world time series data. First, we demonstrate that the MIO solver can be drastically accelerated through the DVP strategy, while maintaining the same solution quality as a full MIO solver. Applying the time-varying sparse autoregression model to ridesharing trip data, we uncover both daily and weekly periodicities and reveal long-term changes in regularity of human mobility. Second, we demonstrate the spatial patterns of yearly seasonality in climate variable time series such as temperature and precipitation across the past four decades, and our model allows to discover dynamic climate patterns and identify climate phenomena such as El Nino in sea surface temperature.",
    "summary": "arXiv:2506.22895v1 Announce Type: cross Abstract: Time series autoregression is a classical statistical model for capturing auto-correlations and identifying temporal patterns such as periodicity and seasonality. In this work, we propose a novel sparse autoregression framework from an interpretable machine learning perspective and the model interpretability for periodicity quantification is reinforced by $ell_0$-norm induced sparsity constraints. On the time-varying time series data, we reformulate the sparse autoregression and convert the involved optimization problem into a mixed-integer optimization (MIO). To accelerate it, we develop a subspace pursuit based decision variable pruning (DVP) strategy to reduce the search space. On the multidimensional time series that involves complicated spatial and temporal dimensions, we propose a spatially- and time-varying sparse autoregression model and resolve the corresponding MIO problem by developing a two-stage optimization scheme. In particular, the proposed scheme makes the model scalable to large problems even with millions of decision variables. Empirically, we conduct extensive experiments to evaluate the proposed models on real-world time series data. First, we demonstrate that the MIO solver can be drastically accelerated through the DVP strategy, while maintaining the same solution quality as a full MIO solver. Applying the time-varying sparse autoregression model to ridesharing trip data, we uncover both daily and weekly periodicities and reveal long-term changes in regularity of human mobility. Second, we demonstrate the spatial patterns of yearly seasonality in climate variable time series such as temperature and precipitation across the past four decades, and our model allows to discover dynamic climate patterns and identify climate phenomena such as El Nino in sea surface temperature.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22895",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy",
    "description": "arXiv:2506.23123v1 Announce Type: new Abstract: Artificial intelligence is humanity's most promising technology because of the remarkable capabilities offered by foundation models. Yet, the same technology brings confusion and consternation: foundation models are poorly understood and they may precipitate a wide array of harms. This dissertation explains how technology and society coevolve in the age of AI, organized around three themes. First, the conceptual framing: the capabilities, risks, and the supply chain that grounds foundation models in the broader economy. Second, the empirical insights that enrich the conceptual foundations: transparency created via evaluations at the model level and indexes at the organization level. Finally, the transition from understanding to action: superior understanding of the societal impact of foundation models advances evidence-based AI policy. View together, this dissertation makes inroads into achieving better societal outcomes in the age of AI by building the scientific foundations and research-policy interface required for better AI governance.",
    "summary": "arXiv:2506.23123v1 Announce Type: new Abstract: Artificial intelligence is humanity's most promising technology because of the remarkable capabilities offered by foundation models. Yet, the same technology brings confusion and consternation: foundation models are poorly understood and they may precipitate a wide array of harms. This dissertation explains how technology and society coevolve in the age of AI, organized around three themes. First, the conceptual framing: the capabilities, risks, and the supply chain that grounds foundation models in the broader economy. Second, the empirical insights that enrich the conceptual foundations: transparency created via evaluations at the model level and indexes at the organization level. Finally, the transition from understanding to action: superior understanding of the societal impact of foundation models advances evidence-based AI policy. View together, this dissertation makes inroads into achieving better societal outcomes in the age of AI by building the scientific foundations and research-policy interface required for better AI governance.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23123",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "New tools for building agents",
    "description": "We‚Äôre evolving our platform to help developers and enterprises build useful and reliable agents.",
    "summary": "We‚Äôre evolving our platform to help developers and enterprises build useful and reliable agents.",
    "pubDate": "Tue, 11 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-for-building-agents",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Chatbot on your Laptop: Phi-2 on Intel Meteor Lake",
    "description": "",
    "summary": "A Chatbot on your Laptop: Phi-2 on Intel Meteor Lake Because of their impressive abilities, large la...",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/phi2-intel-meteor-lake",
    "thumbnail": "https://huggingface.co/blog/assets/phi2-intel-meteor-lake/02.jpg"
  },
  {
    "title": "OpenAI partners with Scale to provide support for enterprises fine-tuning models",
    "description": "OpenAI‚Äôs customers can leverage Scale‚Äôs AI expertise to customize our most advanced models.",
    "summary": "OpenAI‚Äôs customers can leverage Scale‚Äôs AI expertise to customize our most advanced models.",
    "pubDate": "Thu, 24 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-partners-with-scale-to-provide-support-for-enterprises-fine-tuning-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Code Llama: Llama 2 learns to code",
    "description": "",
    "summary": "Code Llama: Llama 2 learns to code Introduction Code Llama is a family of state-of-the-art, open-acc...",
    "pubDate": "Fri, 25 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codellama",
    "thumbnail": "https://huggingface.co/blog/assets/160_codellama/thumbnail.jpg"
  },
  {
    "title": "The latest AI news we announced in May",
    "description": "an mp4 showing a carousel of images including a collage of people, an illustrated graph with codes and the characters 'I/O'",
    "summary": "an mp4 showing a carousel of images including a collage of people, an illustrated graph with codes and the characters 'I/O'",
    "pubDate": "Thu, 05 Jun 2025 18:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/google-ai-updates-may-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/May_AI_roundup_ss.width-1300.png"
  },
  {
    "title": "Some considerations on learning to explore via meta-reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 03 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/some-considerations-on-learning-to-explore-via-meta-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI helps John Deere transform agriculture",
    "description": "John Deere‚Äôs Justin Rose talks about transforming agriculture with AI and shares how the company is scaling innovation to help farmers work smarter, more efficiently, and sustainably.",
    "summary": "John Deere‚Äôs Justin Rose talks about transforming agriculture with AI and shares how the company is scaling innovation to help farmers work smarter, more efficiently, and sustainably.",
    "pubDate": "Tue, 06 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/john-deere-justin-rose",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "üß® Diffusers welcomes Stable Diffusion 3.5 Large",
    "description": "",
    "summary": "üß® Diffusers welcomes Stable Diffusion 3.5 Large Stable Diffusion 3.5 is the improved variant of its ...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd3-5",
    "thumbnail": "https://huggingface.co/blog/assets/sd3-5/thumbnail.png"
  },
  {
    "title": "Study shows vision-language models can‚Äôt handle queries with negation words",
    "description": "Words like ‚Äúno‚Äù and ‚Äúnot‚Äù can cause this popular class of AI models to fail unexpectedly in high-stakes settings, such as medical diagnosis.",
    "summary": "Words like ‚Äúno‚Äù and ‚Äúnot‚Äù can cause this popular class of AI models to fail unexpectedly in high-stakes settings, such as medical diagnosis.",
    "pubDate": "Wed, 14 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/study-shows-vision-language-models-cant-handle-negation-words-queries-0514",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-LMNegation-01-press.jpg"
  },
  {
    "title": "Microsoft invests in and partners with OpenAI to support us building beneficial AGI",
    "description": "Microsoft is investing $1 billion in OpenAI to support us building artificial general intelligence (AGI) with widely distributed economic benefits. We‚Äôre partnering to develop a hardware and software platform within Microsoft Azure which will scale to AGI. We‚Äôll jointly develop new Azure AI supercomputing technologies, and Microsoft will become our exclusive cloud provider‚Äîso we‚Äôll be working hard together to further extend Microsoft Azure‚Äôs capabilities in large-scale AI systems.",
    "summary": "Microsoft is investing $1 billion in OpenAI to support us building artificial general intelligence (AGI) with widely distributed economic benefits. We‚Äôre partnering to develop a hardware and software platform within Microsoft Azure which will scale to AGI. We‚Äôll jointly develop new Azure AI supercomputing technologies, and Microsoft will become our exclusive cloud provider‚Äîso we‚Äôll be working hard together to further extend Microsoft Azure‚Äôs capabilities in large-scale AI systems.",
    "pubDate": "Mon, 22 Jul 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/microsoft-invests-in-and-partners-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using transformers, accelerate and bitsandbytes",
    "description": "",
    "summary": "A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using Hugging Face Tr...",
    "pubDate": "Wed, 17 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hf-bitsandbytes-integration",
    "thumbnail": "https://huggingface.co/blog/assets/96_hf_bitsandbytes_integration/Thumbnail_blue.png"
  },
  {
    "title": "ChatGPT can now see, hear, and speak",
    "description": "We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you‚Äôre talking about.",
    "summary": "We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you‚Äôre talking about.",
    "pubDate": "Mon, 25 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-can-now-see-hear-and-speak",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DALL¬∑E 2: Extending creativity",
    "description": "As part of our DALL¬∑E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL¬∑E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL¬∑E and have served as key voices as we‚Äôve made decisions about DALL¬∑E‚Äôs¬†features.",
    "summary": "As part of our DALL¬∑E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL¬∑E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL¬∑E and have served as key voices as we‚Äôve made decisions about DALL¬∑E‚Äôs¬†features.",
    "pubDate": "Thu, 14 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-extending-creativity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interpretable machine learning through teaching",
    "description": "We‚Äôve designed a method that encourages AIs to teach each other with examples that also make sense to humans. Our approach automatically selects the most informative examples to teach a concept‚Äîfor instance, the best images to describe the concept of dogs‚Äîand experimentally we found our approach to be effective at teaching both AIs",
    "summary": "We‚Äôve designed a method that encourages AIs to teach each other with examples that also make sense to humans. Our approach automatically selects the most informative examples to teach a concept‚Äîfor instance, the best images to describe the concept of dogs‚Äîand experimentally we found our approach to be effective at teaching both AIs",
    "pubDate": "Thu, 15 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/interpretable-machine-learning-through-teaching",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking",
    "description": "arXiv:2506.23783v1 Announce Type: cross Abstract: Combining traditional RGB cameras with bio-inspired event cameras for robust object tracking has garnered increasing attention in recent years. However, most existing multimodal tracking algorithms depend heavily on high-complexity Vision Transformer architectures for feature extraction and fusion across modalities. This not only leads to substantial computational overhead but also limits the effectiveness of cross-modal interactions. In this paper, we propose an efficient RGB-Event object tracking framework based on the linear-complexity Vision Mamba network, termed Mamba-FETrack V2. Specifically, we first design a lightweight Prompt Generator that utilizes embedded features from each modality, together with a shared prompt pool, to dynamically generate modality-specific learnable prompt vectors. These prompts, along with the modality-specific embedded features, are then fed into a Vision Mamba-based FEMamba backbone, which facilitates prompt-guided feature extraction, cross-modal interaction, and fusion in a unified manner. Finally, the fused representations are passed to the tracking head for accurate target localization. Extensive experimental evaluations on multiple RGB-Event tracking benchmarks, including short-term COESOT dataset and long-term datasets, i.e., FE108 and FELT V2, demonstrate the superior performance and efficiency of the proposed tracking framework. The source code and pre-trained models will be released on https://github.com/Event-AHU/Mamba_FETrack",
    "summary": "arXiv:2506.23783v1 Announce Type: cross Abstract: Combining traditional RGB cameras with bio-inspired event cameras for robust object tracking has garnered increasing attention in recent years. However, most existing multimodal tracking algorithms depend heavily on high-complexity Vision Transformer architectures for feature extraction and fusion across modalities. This not only leads to substantial computational overhead but also limits the effectiveness of cross-modal interactions. In this paper, we propose an efficient RGB-Event object tracking framework based on the linear-complexity Vision Mamba network, termed Mamba-FETrack V2. Specifically, we first design a lightweight Prompt Generator that utilizes embedded features from each modality, together with a shared prompt pool, to dynamically generate modality-specific learnable prompt vectors. These prompts, along with the modality-specific embedded features, are then fed into a Vision Mamba-based FEMamba backbone, which facilitates prompt-guided feature extraction, cross-modal interaction, and fusion in a unified manner. Finally, the fused representations are passed to the tracking head for accurate target localization. Extensive experimental evaluations on multiple RGB-Event tracking benchmarks, including short-term COESOT dataset and long-term datasets, i.e., FE108 and FELT V2, demonstrate the superior performance and efficiency of the proposed tracking framework. The source code and pre-trained models will be released on https://github.com/Event-AHU/Mamba_FETrack",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23783",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Automating customer support agents",
    "description": "MavenAGI is a new software company for the AI era. They recently launched an AI customer service agent, built on the flexibility of GPT-4, which a number of companies like Tripadvisor, Clickup and Rho are already using to save time and better serve their customers.",
    "summary": "MavenAGI is a new software company for the AI era. They recently launched an AI customer service agent, built on the flexibility of GPT-4, which a number of companies like Tripadvisor, Clickup and Rho are already using to save time and better serve their customers.",
    "pubDate": "Wed, 29 May 2024 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mavenagi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deliberative alignment: reasoning enables safer language models",
    "description": "Deliberative alignment: reasoning enables safer language models Introducing our new alignment strategy for o1 models, which are directly taught safety specifications and how to reason over them.",
    "summary": "Deliberative alignment: reasoning enables safer language models Introducing our new alignment strategy for o1 models, which are directly taught safety specifications and how to reason over them.",
    "pubDate": "Fri, 20 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deliberative-alignment",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Customizing models for legal professionals",
    "description": "Harvey partners with OpenAI to build a custom-trained model for legal professionals.",
    "summary": "Harvey partners with OpenAI to build a custom-trained model for legal professionals.",
    "pubDate": "Tue, 02 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/harvey",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing next-generation audio models in the API",
    "description": "For the first time, developers can also instruct the text-to-speech model to speak in a specific way‚Äîfor example, ‚Äútalk like a sympathetic customer service agent‚Äù‚Äîunlocking a new level of customization for voice agents.",
    "summary": "For the first time, developers can also instruct the text-to-speech model to speak in a specific way‚Äîfor example, ‚Äútalk like a sympathetic customer service agent‚Äù‚Äîunlocking a new level of customization for voice agents.",
    "pubDate": "Thu, 20 Mar 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-our-next-generation-audio-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Model Safety Behavior with Rule-Based Rewards",
    "description": "We've developed and applied a new method leveraging Rule-Based Rewards (RBRs) that aligns models to behave safely without extensive human data collection.",
    "summary": "We've developed and applied a new method leveraging Rule-Based Rewards (RBRs) that aligns models to behave safely without extensive human data collection.",
    "pubDate": "Wed, 24 Jul 2024 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-model-safety-behavior-with-rule-based-rewards",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2019: Applications open",
    "description": "We are now accepting applications for our second cohort of OpenAI Scholars, a program where we provide 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "summary": "We are now accepting applications for our second cohort of OpenAI Scholars, a program where we provide 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "pubDate": "Thu, 11 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Codex",
    "description": "We‚Äôve created an improved version of OpenAI Codex, our AI system that translates natural language to code, and we are releasing it through our API in private beta starting today.",
    "summary": "We‚Äôve created an improved version of OpenAI Codex, our AI system that translates natural language to code, and we are releasing it through our API in private beta starting today.",
    "pubDate": "Tue, 10 Aug 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-codex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars",
    "description": "We‚Äôre providing 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "summary": "We‚Äôre providing 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "pubDate": "Tue, 06 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Segment as You Wish -- Free-Form Language-Based Segmentation for Medical Images",
    "description": "arXiv:2410.12831v2 Announce Type: replace-cross Abstract: Medical imaging is crucial for diagnosing a patient's health condition, and accurate segmentation of these images is essential for isolating regions of interest to ensure precise diagnosis and treatment planning. Existing methods primarily rely on bounding boxes or point-based prompts, while few have explored text-related prompts, despite clinicians often describing their observations and instructions in natural language. To address this gap, we first propose a RAG-based free-form text prompt generator, that leverages the domain corpus to generate diverse and realistic descriptions. Then, we introduce FLanS, a novel medical image segmentation model that handles various free-form text prompts, including professional anatomy-informed queries, anatomy-agnostic position-driven queries, and anatomy-agnostic size-driven queries. Additionally, our model also incorporates a symmetry-aware canonicalization module to ensure consistent, accurate segmentations across varying scan orientations and reduce confusion between the anatomical position of an organ and its appearance in the scan. FLanS is trained on a large-scale dataset of over 100k medical images from 7 public datasets. Comprehensive experiments demonstrate the model's superior language understanding and segmentation precision, along with a deep comprehension of the relationship between them, outperforming SOTA baselines on both in-domain and out-of-domain datasets.",
    "summary": "arXiv:2410.12831v2 Announce Type: replace-cross Abstract: Medical imaging is crucial for diagnosing a patient's health condition, and accurate segmentation of these images is essential for isolating regions of interest to ensure precise diagnosis and treatment planning. Existing methods primarily rely on bounding boxes or point-based prompts, while few have explored text-related prompts, despite clinicians often describing their observations and instructions in natural language. To address this gap, we first propose a RAG-based free-form text prompt generator, that leverages the domain corpus to generate diverse and realistic descriptions. Then, we introduce FLanS, a novel medical image segmentation model that handles various free-form text prompts, including professional anatomy-informed queries, anatomy-agnostic position-driven queries, and anatomy-agnostic size-driven queries. Additionally, our model also incorporates a symmetry-aware canonicalization module to ensure consistent, accurate segmentations across varying scan orientations and reduce confusion between the anatomical position of an organ and its appearance in the scan. FLanS is trained on a large-scale dataset of over 100k medical images from 7 public datasets. Comprehensive experiments demonstrate the model's superior language understanding and segmentation precision, along with a deep comprehension of the relationship between them, outperforming SOTA baselines on both in-domain and out-of-domain datasets.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.12831",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "On first-order meta-learning algorithms",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 08 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/on-first-order-meta-learning-algorithms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait",
    "description": "arXiv:2412.01064v3 Announce Type: replace-cross Abstract: With the rapid advancement of diffusion-based generative models, portrait image animation has achieved remarkable results. However, it still faces challenges in temporally consistent video generation and fast sampling due to its iterative sampling nature. This paper presents FLOAT, an audio-driven talking portrait video generation method based on flow matching generative model. Instead of a pixel-based latent space, we take advantage of a learned orthogonal motion latent space, enabling efficient generation and editing of temporally consistent motion. To achieve this, we introduce a transformer-based vector field predictor with an effective frame-wise conditioning mechanism. Additionally, our method supports speech-driven emotion enhancement, enabling a natural incorporation of expressive motions. Extensive experiments demonstrate that our method outperforms state-of-the-art audio-driven talking portrait methods in terms of visual quality, motion fidelity, and efficiency.",
    "summary": "arXiv:2412.01064v3 Announce Type: replace-cross Abstract: With the rapid advancement of diffusion-based generative models, portrait image animation has achieved remarkable results. However, it still faces challenges in temporally consistent video generation and fast sampling due to its iterative sampling nature. This paper presents FLOAT, an audio-driven talking portrait video generation method based on flow matching generative model. Instead of a pixel-based latent space, we take advantage of a learned orthogonal motion latent space, enabling efficient generation and editing of temporally consistent motion. To achieve this, we introduce a transformer-based vector field predictor with an effective frame-wise conditioning mechanism. Additionally, our method supports speech-driven emotion enhancement, enabling a natural incorporation of expressive motions. Extensive experiments demonstrate that our method outperforms state-of-the-art audio-driven talking portrait methods in terms of visual quality, motion fidelity, and efficiency.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.01064",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "StepProof: Step-by-step verification of natural language mathematical proofs",
    "description": "arXiv:2506.10558v2 Announce Type: replace-cross Abstract: Interactive theorem provers (ITPs) are powerful tools for the formal verification of mathematical proofs down to the axiom level. However, their lack of a natural language interface remains a significant limitation. Recent advancements in large language models (LLMs) have enhanced the understanding of natural language inputs, paving the way for autoformalization - the process of translating natural language proofs into formal proofs that can be verified. Despite these advancements, existing autoformalization approaches are limited to verifying complete proofs and lack the capability for finer, sentence-level verification. To address this gap, we propose StepProof, a novel autoformalization method designed for granular, step-by-step verification. StepProof breaks down complete proofs into multiple verifiable subproofs, enabling sentence-level verification. Experimental results demonstrate that StepProof significantly improves proof success rates and efficiency compared to traditional methods. Additionally, we found that minor manual adjustments to the natural language proofs, tailoring them for step-level verification, further enhanced StepProof's performance in autoformalization.",
    "summary": "arXiv:2506.10558v2 Announce Type: replace-cross Abstract: Interactive theorem provers (ITPs) are powerful tools for the formal verification of mathematical proofs down to the axiom level. However, their lack of a natural language interface remains a significant limitation. Recent advancements in large language models (LLMs) have enhanced the understanding of natural language inputs, paving the way for autoformalization - the process of translating natural language proofs into formal proofs that can be verified. Despite these advancements, existing autoformalization approaches are limited to verifying complete proofs and lack the capability for finer, sentence-level verification. To address this gap, we propose StepProof, a novel autoformalization method designed for granular, step-by-step verification. StepProof breaks down complete proofs into multiple verifiable subproofs, enabling sentence-level verification. Experimental results demonstrate that StepProof significantly improves proof success rates and efficiency compared to traditional methods. Additionally, we found that minor manual adjustments to the natural language proofs, tailoring them for step-level verification, further enhanced StepProof's performance in autoformalization.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.10558",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tuning GPT-3 to scale video creation",
    "description": "Fine-tuning GPT-3 to power and scale done-for-you video creation.",
    "summary": "Fine-tuning GPT-3 to power and scale done-for-you video creation.",
    "pubDate": "Tue, 03 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/waymark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 11 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-connection-between-generative-adversarial-networks-inverse-reinforcement-learning-and-energy-based-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PipeOffload: Improving Scalability of Pipeline Parallelism with Memory Optimization",
    "description": "arXiv:2503.01328v2 Announce Type: replace-cross Abstract: Pipeline parallelism (PP) is widely used for training large language models (LLMs), yet its scalability is often constrained by high activation memory consumption as the number of in-flight microbatches grows with the degree of PP. In this paper, we focus on addressing this challenge by leveraging the under-explored memory offload strategy in PP. With empirical study, we discover that in the majority of standard configurations, at least half, and potentially all, of the activations can be offloaded with negligible overhead. In the cases where full overload is not possible, we introduce a novel selective offload strategy that decreases peak activation memory in a better-than-linear manner. Furthermore, we integrate memory offload with other techniques to jointly consider overall throughput and memory limitation. Our experiments proves that the per-device activation memory effectively reduces with the total number of stages, making PP a stronger alternative than TP, offering up to a 19% acceleration with even lower memory consumption. The implementation is open-sourced at href{https://github.com/sail-sg/zero-bubble-pipeline-parallelism}{this url}.",
    "summary": "arXiv:2503.01328v2 Announce Type: replace-cross Abstract: Pipeline parallelism (PP) is widely used for training large language models (LLMs), yet its scalability is often constrained by high activation memory consumption as the number of in-flight microbatches grows with the degree of PP. In this paper, we focus on addressing this challenge by leveraging the under-explored memory offload strategy in PP. With empirical study, we discover that in the majority of standard configurations, at least half, and potentially all, of the activations can be offloaded with negligible overhead. In the cases where full overload is not possible, we introduce a novel selective offload strategy that decreases peak activation memory in a better-than-linear manner. Furthermore, we integrate memory offload with other techniques to jointly consider overall throughput and memory limitation. Our experiments proves that the per-device activation memory effectively reduces with the total number of stages, making PP a stronger alternative than TP, offering up to a 19% acceleration with even lower memory consumption. The implementation is open-sourced at href{https://github.com/sail-sg/zero-bubble-pipeline-parallelism}{this url}.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.01328",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "17 Reasons Why Gradio Isn't Just Another UI Library",
    "description": "",
    "summary": "17 Reasons Why Gradio Isn't Just Another UI Library Introduction 'Oh, Gradio? That's a Python librar...",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/why-gradio-stands-out",
    "thumbnail": "https://huggingface.co/blog/assets/why-gradio-stands-out/thumbnail.png"
  },
  {
    "title": "Scaling Data-Constrained Language Models",
    "description": "arXiv:2305.16264v5 Announce Type: replace-cross Abstract: The current trend of scaling language models involves increasing both parameter count and training dataset size. Extrapolating this trend suggests that training dataset size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity, including augmenting the training dataset with code data or removing commonly used filters. Models and datasets from our 400 training runs are freely available at https://github.com/huggingface/datablations.",
    "summary": "arXiv:2305.16264v5 Announce Type: replace-cross Abstract: The current trend of scaling language models involves increasing both parameter count and training dataset size. Extrapolating this trend suggests that training dataset size may soon be limited by the amount of text data available on the internet. Motivated by this limit, we investigate scaling language models in data-constrained regimes. Specifically, we run a large set of experiments varying the extent of data repetition and compute budget, ranging up to 900 billion training tokens and 9 billion parameter models. We find that with constrained data for a fixed compute budget, training with up to 4 epochs of repeated data yields negligible changes to loss compared to having unique data. However, with more repetition, the value of adding compute eventually decays to zero. We propose and empirically validate a scaling law for compute optimality that accounts for the decreasing value of repeated tokens and excess parameters. Finally, we experiment with approaches mitigating data scarcity, including augmenting the training dataset with code data or removing commonly used filters. Models and datasets from our 400 training runs are freely available at https://github.com/huggingface/datablations.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2305.16264",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Q&A: A roadmap for revolutionizing health care through data-driven innovation",
    "description": "A new book coauthored by MIT‚Äôs Dimitris Bertsimas explores how analytics is driving decisions and outcomes in health care.",
    "summary": "A new book coauthored by MIT‚Äôs Dimitris Bertsimas explores how analytics is driving decisions and outcomes in health care.",
    "pubDate": "Mon, 05 May 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/qa-roadmap-revolutionizing-health-care-through-data-driven-innovation-0505",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/Analytics-Edge-in-Healthcare-Dimitris-Bertsimas-00.png"
  },
  {
    "title": "Introducing Structured Outputs in the API",
    "description": "We are introducing Structured Outputs in the API‚Äîmodel outputs now reliably adhere to developer-supplied JSON Schemas.",
    "summary": "We are introducing Structured Outputs in the API‚Äîmodel outputs now reliably adhere to developer-supplied JSON Schemas.",
    "pubDate": "Tue, 06 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-structured-outputs-in-the-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SConU: Selective Conformal Uncertainty in Large Language Models",
    "description": "arXiv:2504.14154v2 Announce Type: replace-cross Abstract: As large language models are increasingly utilized in real-world applications, guarantees of task-specific metrics are essential for their reliable deployment. Previous studies have introduced various criteria of conformal uncertainty grounded in split conformal prediction, which offer user-specified correctness coverage. However, existing frameworks often fail to identify uncertainty data outliers that violate the exchangeability assumption, leading to unbounded miscoverage rates and unactionable prediction sets. In this paper, we propose a novel approach termed Selective Conformal Uncertainty (SConU), which, for the first time, implements significance tests, by developing two conformal p-values that are instrumental in determining whether a given sample deviates from the uncertainty distribution of the calibration set at a specific manageable risk level. Our approach not only facilitates rigorous management of miscoverage rates across both single-domain and interdisciplinary contexts, but also enhances the efficiency of predictions. Furthermore, we comprehensively analyze the components of the conformal procedures, aiming to approximate conditional coverage, particularly in high-stakes question-answering tasks.",
    "summary": "arXiv:2504.14154v2 Announce Type: replace-cross Abstract: As large language models are increasingly utilized in real-world applications, guarantees of task-specific metrics are essential for their reliable deployment. Previous studies have introduced various criteria of conformal uncertainty grounded in split conformal prediction, which offer user-specified correctness coverage. However, existing frameworks often fail to identify uncertainty data outliers that violate the exchangeability assumption, leading to unbounded miscoverage rates and unactionable prediction sets. In this paper, we propose a novel approach termed Selective Conformal Uncertainty (SConU), which, for the first time, implements significance tests, by developing two conformal p-values that are instrumental in determining whether a given sample deviates from the uncertainty distribution of the calibration set at a specific manageable risk level. Our approach not only facilitates rigorous management of miscoverage rates across both single-domain and interdisciplinary contexts, but also enhances the efficiency of predictions. Furthermore, we comprehensively analyze the components of the conformal procedures, aiming to approximate conditional coverage, particularly in high-stakes question-answering tasks.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.14154",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Imagine for Me: Creative Conceptual Blending of Real Images and Text via Blended Attention",
    "description": "arXiv:2506.24085v1 Announce Type: cross Abstract: Blending visual and textual concepts into a new visual concept is a unique and powerful trait of human beings that can fuel creativity. However, in practice, cross-modal conceptual blending for humans is prone to cognitive biases, like design fixation, which leads to local minima in the design space. In this paper, we propose a T2I diffusion adapter 'IT-Blender' that can automate the blending process to enhance human creativity. Prior works related to cross-modal conceptual blending are limited in encoding a real image without loss of details or in disentangling the image and text inputs. To address these gaps, IT-Blender leverages pretrained diffusion models (SD and FLUX) to blend the latent representations of a clean reference image with those of the noisy generated image. Combined with our novel blended attention, IT-Blender encodes the real reference image without loss of details and blends the visual concept with the object specified by the text in a disentangled way. Our experiment results show that IT-Blender outperforms the baselines by a large margin in blending visual and textual concepts, shedding light on the new application of image generative models to augment human creativity.",
    "summary": "arXiv:2506.24085v1 Announce Type: cross Abstract: Blending visual and textual concepts into a new visual concept is a unique and powerful trait of human beings that can fuel creativity. However, in practice, cross-modal conceptual blending for humans is prone to cognitive biases, like design fixation, which leads to local minima in the design space. In this paper, we propose a T2I diffusion adapter 'IT-Blender' that can automate the blending process to enhance human creativity. Prior works related to cross-modal conceptual blending are limited in encoding a real image without loss of details or in disentangling the image and text inputs. To address these gaps, IT-Blender leverages pretrained diffusion models (SD and FLUX) to blend the latent representations of a clean reference image with those of the noisy generated image. Combined with our novel blended attention, IT-Blender encodes the real reference image without loss of details and blends the visual concept with the object specified by the text in a disentangled way. Our experiment results show that IT-Blender outperforms the baselines by a large margin in blending visual and textual concepts, shedding light on the new application of image generative models to augment human creativity.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.24085",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Train a Sentence Embedding Model with 1B Training Pairs",
    "description": "",
    "summary": "Train a Sentence Embedding Model with 1 Billion Training Pairs Sentence embedding is a method that m...",
    "pubDate": "Mon, 25 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/1b-sentence-embeddings",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Gym Retro",
    "description": "We‚Äôre releasing the full version of¬†Gym Retro, a platform for reinforcement learning research on games. This brings our publicly-released game count from around 70 Atari games and 30 Sega games to over 1,000 games across a variety of backing emulators. We‚Äôre also releasing the tool we use to add new games to the¬†platform.",
    "summary": "We‚Äôre releasing the full version of¬†Gym Retro, a platform for reinforcement learning research on games. This brings our publicly-released game count from around 70 Atari games and 30 Sega games to over 1,000 games across a variety of backing emulators. We‚Äôre also releasing the tool we use to add new games to the¬†platform.",
    "pubDate": "Fri, 25 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gym-retro",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bringing meaning into technology deployment",
    "description": "The MIT Ethics of Computing Research Symposium showcases projects at the intersection of technology, ethics, and social responsibility.",
    "summary": "The MIT Ethics of Computing Research Symposium showcases projects at the intersection of technology, ethics, and social responsibility.",
    "pubDate": "Wed, 11 Jun 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/bringing-meaning-technology-deployment-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-SERC-Symposium.jpg"
  },
  {
    "title": "Open-source LLMs as LangChain Agents",
    "description": "",
    "summary": "Open-source LLMs as LangChain Agents TL;DR Open-source LLMs have now reached a performance level tha...",
    "pubDate": "Wed, 24 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-source-llms-as-agents",
    "thumbnail": "https://huggingface.co/blog/assets/open-source-llms-as-agents/thumbnail_open_source_agents.png"
  },
  {
    "title": "Learning to play Minecraft with Video PreTraining",
    "description": "We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model can learn to craft diamond tools, a task that usually takes proficient humans over 20 minutes (24,000 actions). Our model uses the native human interface of keypresses and mouse movements, making it quite general, and represents a step towards general computer-using¬†agents.",
    "summary": "We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model can learn to craft diamond tools, a task that usually takes proficient humans over 20 minutes (24,000 actions). Our model uses the native human interface of keypresses and mouse movements, making it quite general, and represents a step towards general computer-using¬†agents.",
    "pubDate": "Thu, 23 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/vpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Converting Vertex-Colored Meshes to Textured Meshes",
    "description": "",
    "summary": "Converting Vertex-Colored Meshes to Textured Meshes Convert vertex-colored meshes to UV-mapped, text...",
    "pubDate": "Mon, 30 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vertex-colored-to-textured-mesh",
    "thumbnail": "https://huggingface.co/blog/assets/vertex-colored-to-textured-mesh/thumbnail.png"
  },
  {
    "title": "A glimpse of the next generation of AlphaFold",
    "description": "Progress update: Our latest AlphaFold model shows significantly improved accuracy and expands coverage beyond proteins to other biological molecules, including ligands.",
    "summary": "Progress update: Our latest AlphaFold model shows significantly improved accuracy and expands coverage beyond proteins to other biological molecules, including ligands.",
    "pubDate": "Tue, 31 Oct 2023 13:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/",
    "thumbnail": "https://lh3.googleusercontent.com/1xoO5BAUUU8kLns4myMNnKw6RRQyUk1JdlWL1M0aDiagMgaBeDA9O8Y4rYFAo9hfnzmb0cnUMrT_-cStBqnyp_zW59F5Edwbvxcy3EVmfeKS-PNgVw=w1200-h630-n-nu"
  },
  {
    "title": "GenCast predicts weather and the risks of extreme conditions with state-of-the-art accuracy",
    "description": "New AI model advances the prediction of weather uncertainties and risks, delivering faster, more accurate forecasts up to 15 days ahead",
    "summary": "New AI model advances the prediction of weather uncertainties and risks, delivering faster, more accurate forecasts up to 15 days ahead",
    "pubDate": "Wed, 04 Dec 2024 15:59:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/",
    "thumbnail": "https://lh3.googleusercontent.com/4u3n6FBe0eE86yXgppDN_yj_AkiCF5FaSToa8f3Mh5bFWzIH01ewGN737emoYKcGXLxQagYFMxi9j-cAZyAzkdFndCDg2ne9E42w4YZD7HyBChaf=w1200-h630-n-nu"
  },
  {
    "title": "Introducing the OpenAI Academy",
    "description": "New initiative will fuel innovation by investing in developers and organizations leveraging AI, starting in low- and middle-income countries.",
    "summary": "New initiative will fuel innovation by investing in developers and organizations leveraging AI, starting in low- and middle-income countries.",
    "pubDate": "Mon, 23 Sep 2024 03:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "API Partnership with Stack Overflow",
    "description": "API Partnership with Stack Overflow Stack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world‚Äôs leading knowledge platform for highly technical content with the world‚Äôs most popular LLM models for AI development.",
    "summary": "API Partnership with Stack Overflow Stack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world‚Äôs leading knowledge platform for highly technical content with the world‚Äôs most popular LLM models for AI development.",
    "pubDate": "Mon, 06 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-partnership-with-stack-overflow",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Tiny Agents in Python: a MCP-powered agent in ~70 lines of code",
    "description": "",
    "summary": "Tiny Agents in Python: an MCP-powered agent in ~70 lines of code Inspired by Tiny Agents in JS, we p...",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/python-tiny-agents",
    "thumbnail": "https://huggingface.co/blog/assets/python-tiny-agents/thumbnail.png"
  },
  {
    "title": "Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Disaster Tweets Analysis with Lora",
    "description": "",
    "summary": "Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Disaster Tweet...",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/Lora-for-sequence-classification-with-Roberta-Llama-Mistral",
    "thumbnail": "https://huggingface.co/blog/assets/Lora-for-sequence-classification-with-Roberta-Llama-Mistral/Thumbnail.png"
  },
  {
    "title": "Zero-shot image segmentation with CLIPSeg",
    "description": "",
    "summary": "Zero-shot image segmentation with CLIPSeg This guide shows how you can use CLIPSeg, a zero-shot imag...",
    "pubDate": "Wed, 21 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/clipseg-zero-shot",
    "thumbnail": "https://huggingface.co/blog/assets/123_clipseg-zero-shot/thumb.png"
  },
  {
    "title": "Teaching Models to Verbalize Reward Hacking in Chain-of-Thought Reasoning",
    "description": "arXiv:2506.22777v1 Announce Type: cross Abstract: Language models trained with RL can engage in reward hacking--exploiting unintended strategies for high reward--without revealing this behavior in their chain-of-thought reasoning, making detection difficult and posing risks for high-stakes applications. We propose verbalization fine-tuning (VFT), a pre-RL intervention that trains models to explicitly acknowledge when they are influenced by prompt cues--hints which point to incorrect answers (e.g., 'a Stanford professor thinks the answer is A'). To evaluate VFT, we subsequently train models with RL on environments where held-out prompt cues signal which incorrect answers will receive high reward, incentivizing models to reward hack by exploiting cues instead of reasoning correctly. We measure how often models exploit these cues without verbalizing it. After RL, only 6% of the VFT-trained model's responses consist of undetected reward hacks. In comparison, when we perform RL without VFT, the rate of undetected reward hacks goes up to 88%; with a debiasing baseline intervention, this increases further to 99%. VFT achieves this by substantially increasing how often models verbalize the influence of cues--from 8% to 42% after VFT, and up to 94% after RL--while baselines remain low even after RL (10% and 1%). Our results show that teaching models to explicitly verbalize reward hacking behavior before RL significantly improves their detection, offering a practical path toward more transparent and safe AI systems.",
    "summary": "arXiv:2506.22777v1 Announce Type: cross Abstract: Language models trained with RL can engage in reward hacking--exploiting unintended strategies for high reward--without revealing this behavior in their chain-of-thought reasoning, making detection difficult and posing risks for high-stakes applications. We propose verbalization fine-tuning (VFT), a pre-RL intervention that trains models to explicitly acknowledge when they are influenced by prompt cues--hints which point to incorrect answers (e.g., 'a Stanford professor thinks the answer is A'). To evaluate VFT, we subsequently train models with RL on environments where held-out prompt cues signal which incorrect answers will receive high reward, incentivizing models to reward hack by exploiting cues instead of reasoning correctly. We measure how often models exploit these cues without verbalizing it. After RL, only 6% of the VFT-trained model's responses consist of undetected reward hacks. In comparison, when we perform RL without VFT, the rate of undetected reward hacks goes up to 88%; with a debiasing baseline intervention, this increases further to 99%. VFT achieves this by substantially increasing how often models verbalize the influence of cues--from 8% to 42% after VFT, and up to 94% after RL--while baselines remain low even after RL (10% and 1%). Our results show that teaching models to explicitly verbalize reward hacking behavior before RL significantly improves their detection, offering a practical path toward more transparent and safe AI systems.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22777",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Llama can now see and run on your device - welcome Llama 3.2",
    "description": "",
    "summary": "Llama can now see and run on your device - welcome Llama 3.2 Llama 3.2 is out! Today, we welcome the...",
    "pubDate": "Wed, 25 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama32",
    "thumbnail": "https://huggingface.co/blog/assets/llama32/thumbnail.jpg"
  },
  {
    "title": "Microsoft„ÅÆAI„ÄÅÂåªÁôÇË®∫Êñ≠Á≤æÂ∫¶„Åß‰∫∫Èñì„ÅÆÂåªÂ∏´„ÇíË∂Ö„Åà„ÇãÂèØËÉΩÊÄß",
    "description": "Microsoft„ÅØ„ÄÅÈñãÁô∫‰∏≠„ÅÆAI„ÄåMAI-DxO„Äç„ÅåÂåªÁôÇË®∫Êñ≠„ÅÆÁ≤æÂ∫¶„Åß‰∫∫Èñì„ÅÆÂåªÂ∏´„ÇíÂ§ßÂπÖ„Å´‰∏äÂõû„Å£„Åü„Å®Áô∫Ë°®„Åó„Åü„ÄÇÊñ∞„Åó„ÅÑ„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„Å´„Çà„ÇãË©ï‰æ°„Åß„ÅØ„ÄÅAI„ÅÆË®∫Êñ≠Á≤æÂ∫¶„Åå80ÔºÖ„Å´ÈÅî„Åó„ÄÅÁµåÈ®ìË±äÂØå„Å™ÂåªÂ∏´„ÅÆ20ÔºÖ„ÇíÂ§ß„Åç„ÅèË∂Ö„Åà„Åü„ÄÇË®∫Êñ≠„Ç≥„Çπ„Éà„ÅÆÂâäÊ∏õÂäπÊûú„ÇÇÁ§∫„Åï„Çå„Åü„ÄÇ",
    "summary": "Microsoft„ÅØ„ÄÅÈñãÁô∫‰∏≠„ÅÆAI„ÄåMAI-DxO„Äç„ÅåÂåªÁôÇË®∫Êñ≠„ÅÆÁ≤æÂ∫¶„Åß‰∫∫Èñì„ÅÆÂåªÂ∏´„ÇíÂ§ßÂπÖ„Å´‰∏äÂõû„Å£„Åü„Å®Áô∫Ë°®„Åó„Åü„ÄÇÊñ∞„Åó„ÅÑ„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„Å´„Çà„ÇãË©ï‰æ°„Åß„ÅØ„ÄÅAI„ÅÆË®∫Êñ≠Á≤æÂ∫¶„Åå80ÔºÖ„Å´ÈÅî„Åó„ÄÅÁµåÈ®ìË±äÂØå„Å™ÂåªÂ∏´„ÅÆ20ÔºÖ„ÇíÂ§ß„Åç„ÅèË∂Ö„Åà„Åü„ÄÇË®∫Êñ≠„Ç≥„Çπ„Éà„ÅÆÂâäÊ∏õÂäπÊûú„ÇÇÁ§∫„Åï„Çå„Åü„ÄÇ",
    "pubDate": "Tue, 01 Jul 2025 11:34:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2507/01/news066.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2507/01/cover_news066.jpg"
  },
  {
    "title": "A Consequentialist Critique of Binary Classification Evaluation Practices",
    "description": "arXiv:2504.04528v2 Announce Type: replace-cross Abstract: ML-supported decisions, such as ordering tests or determining preventive custody, often involve binary classification based on probabilistic forecasts. Evaluation frameworks for such forecasts typically consider whether to prioritize independent-decision metrics (e.g., Accuracy) or top-K metrics (e.g., Precision@K), and whether to focus on fixed thresholds or threshold-agnostic measures like AUC-ROC. We highlight that a consequentialist perspective, long advocated by decision theorists, should naturally favor evaluations that support independent decisions using a mixture of thresholds given their prevalence, such as Brier scores and Log loss. However, our empirical analysis reveals a strong preference for top-K metrics or fixed thresholds in evaluations at major conferences like ICML, FAccT, and CHIL. To address this gap, we use this decision-theoretic framework to map evaluation metrics to their optimal use cases, along with a Python package, briertools, to promote the broader adoption of Brier scores. In doing so, we also uncover new theoretical connections, including a reconciliation between the Brier Score and Decision Curve Analysis, which clarifies and responds to a longstanding critique by (Assel, et al. 2017) regarding the clinical utility of proper scoring rules.",
    "summary": "arXiv:2504.04528v2 Announce Type: replace-cross Abstract: ML-supported decisions, such as ordering tests or determining preventive custody, often involve binary classification based on probabilistic forecasts. Evaluation frameworks for such forecasts typically consider whether to prioritize independent-decision metrics (e.g., Accuracy) or top-K metrics (e.g., Precision@K), and whether to focus on fixed thresholds or threshold-agnostic measures like AUC-ROC. We highlight that a consequentialist perspective, long advocated by decision theorists, should naturally favor evaluations that support independent decisions using a mixture of thresholds given their prevalence, such as Brier scores and Log loss. However, our empirical analysis reveals a strong preference for top-K metrics or fixed thresholds in evaluations at major conferences like ICML, FAccT, and CHIL. To address this gap, we use this decision-theoretic framework to map evaluation metrics to their optimal use cases, along with a Python package, briertools, to promote the broader adoption of Brier scores. In doing so, we also uncover new theoretical connections, including a reconciliation between the Brier Score and Decision Curve Analysis, which clarifies and responds to a longstanding critique by (Assel, et al. 2017) regarding the clinical utility of proper scoring rules.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.04528",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Early methods for studying affective use and emotional well-being on ChatGPT",
    "description": "An OpenAI and MIT Media Lab Research collaboration.",
    "summary": "An OpenAI and MIT Media Lab Research collaboration.",
    "pubDate": "Fri, 21 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/affective-use-study",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Zero-shot image-to-text generation with BLIP-2",
    "description": "",
    "summary": "Zero-shot image-to-text generation with BLIP-2 This guide introduces BLIP-2 from Salesforce Research...",
    "pubDate": "Wed, 15 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/blip-2",
    "thumbnail": "https://huggingface.co/blog/assets/blip-2/thumbnail.png"
  },
  {
    "title": "OpenAI Gym Beta",
    "description": "We‚Äôre releasing the public beta of OpenAI Gym, a toolkit for developing and comparing reinforcement learning (RL) algorithms. It consists of a growing suite of environments (from simulated robots to Atari games), and a site for comparing and reproducing results.",
    "summary": "We‚Äôre releasing the public beta of OpenAI Gym, a toolkit for developing and comparing reinforcement learning (RL) algorithms. It consists of a growing suite of environments (from simulated robots to Atari games), and a site for comparing and reproducing results.",
    "pubDate": "Wed, 27 Apr 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-gym-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerate BERT inference with Hugging Face Transformers and AWS inferentia",
    "description": "",
    "summary": "Accelerate BERT inference with Hugging Face Transformers and AWS Inferentia notebook: sagemaker/18_i...",
    "pubDate": "Wed, 16 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-inferentia-sagemaker",
    "thumbnail": "https://huggingface.co/blog//assets/55_bert_inferentia_sagemaker/thumbnail.png"
  },
  {
    "title": "Preserving languages for the future",
    "description": "How Iceland is using GPT-4 to preserve its language.",
    "summary": "How Iceland is using GPT-4 to preserve its language.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/government-of-iceland",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy Livebook notebooks as apps to Hugging Face Spaces",
    "description": "",
    "summary": "Deploy Livebook notebooks as apps to Hugging Face Spaces The Elixir community has been making great ...",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/livebook-app-deployment",
    "thumbnail": "https://huggingface.co/blog/assets/120_elixir-bumblebee/thumbnail.png"
  },
  {
    "title": "Frontier Model Forum",
    "description": "We‚Äôre forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
    "summary": "We‚Äôre forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
    "pubDate": "Wed, 26 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-model-forum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Merging AI and underwater photography to reveal hidden ocean worlds",
    "description": "The LOBSTgER research initiative at MIT Sea Grant explores how generative AI can expand scientific storytelling by building on field-based photographic data.",
    "summary": "The LOBSTgER research initiative at MIT Sea Grant explores how generative AI can expand scientific storytelling by building on field-based photographic data.",
    "pubDate": "Wed, 25 Jun 2025 09:55:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/lobstger-merging-ai-underwater-photography-to-reveal-hidden-ocean-worlds-0625",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-LOBSTgER.jpg"
  },
  {
    "title": "2D Asset Generation: AI for Game Development #4",
    "description": "",
    "summary": "2D Asset Generation: AI for Game Development #4 Welcome to AI for Game Development! In this series, ...",
    "pubDate": "Thu, 26 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-4",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail4.png"
  },
  {
    "title": "Decoding genetics with OpenAI o1",
    "description": "Geneticist Catherine Brownstein demonstrates how OpenAI o1 can speed up the process of diagnosing rare medical challenges.",
    "summary": "Geneticist Catherine Brownstein demonstrates how OpenAI o1 can speed up the process of diagnosing rare medical challenges.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-genetics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Superalignment Fast Grants",
    "description": "We‚Äôre launching $10M in grants to support technical research towards the alignment and safety of superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.",
    "summary": "We‚Äôre launching $10M in grants to support technical research towards the alignment and safety of superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/superalignment-fast-grants",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MIT and Mass General Brigham launch joint seed program to accelerate innovations in health",
    "description": "The MIT-MGB Seed Program, launched with support from Analog Devices Inc., will fund joint research projects that advance technology and clinical research.",
    "summary": "The MIT-MGB Seed Program, launched with support from Analog Devices Inc., will fund joint research projects that advance technology and clinical research.",
    "pubDate": "Fri, 27 Jun 2025 13:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-mass-general-brigham-launch-seed-program-innovations-health-0627",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-mgb-seed-program.jpg"
  },
  {
    "title": "Improving Hugging Face Model Access for Kaggle Users",
    "description": "",
    "summary": "Improving Hugging Face Model Access for Kaggle Users Kaggle and Hugging Face users are part of one A...",
    "pubDate": "Wed, 14 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kaggle-integration",
    "thumbnail": "https://huggingface.co/blog/assets/kaggle-integration/thumbnail.png"
  },
  {
    "title": "Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning for Cyber-Physical Systems Security",
    "description": "arXiv:2506.22445v1 Announce Type: cross Abstract: Cyber-Physical Systems play a critical role in the infrastructure of various sectors, including manufacturing, energy distribution, and autonomous transportation systems. However, their increasing connectivity renders them highly vulnerable to sophisticated cyber threats, such as adaptive and zero-day attacks, against which traditional security methods like rule-based intrusion detection and single-agent reinforcement learning prove insufficient. To overcome these challenges, this paper introduces a novel Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning (HAMARL) framework. HAMARL employs a hierarchical structure consisting of local agents dedicated to subsystem security and a global coordinator that oversees and optimizes comprehensive, system-wide defense strategies. Furthermore, the framework incorporates an adversarial training loop designed to simulate and anticipate evolving cyber threats, enabling proactive defense adaptation. Extensive experimental evaluations conducted on a simulated industrial IoT testbed indicate that HAMARL substantially outperforms traditional multi-agent reinforcement learning approaches, significantly improving attack detection accuracy, reducing response times, and ensuring operational continuity. The results underscore the effectiveness of combining hierarchical multi-agent coordination with adversarially-aware training to enhance the resilience and security of next-generation CPS.",
    "summary": "arXiv:2506.22445v1 Announce Type: cross Abstract: Cyber-Physical Systems play a critical role in the infrastructure of various sectors, including manufacturing, energy distribution, and autonomous transportation systems. However, their increasing connectivity renders them highly vulnerable to sophisticated cyber threats, such as adaptive and zero-day attacks, against which traditional security methods like rule-based intrusion detection and single-agent reinforcement learning prove insufficient. To overcome these challenges, this paper introduces a novel Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning (HAMARL) framework. HAMARL employs a hierarchical structure consisting of local agents dedicated to subsystem security and a global coordinator that oversees and optimizes comprehensive, system-wide defense strategies. Furthermore, the framework incorporates an adversarial training loop designed to simulate and anticipate evolving cyber threats, enabling proactive defense adaptation. Extensive experimental evaluations conducted on a simulated industrial IoT testbed indicate that HAMARL substantially outperforms traditional multi-agent reinforcement learning approaches, significantly improving attack detection accuracy, reducing response times, and ensuring operational continuity. The results underscore the effectiveness of combining hierarchical multi-agent coordination with adversarially-aware training to enhance the resilience and security of next-generation CPS.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22445",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Microsoft and Hugging Face expand collaboration",
    "description": "",
    "summary": "Microsoft and Hugging Face expand collaboration to make open models easy to use on Azure Today at th...",
    "pubDate": "Mon, 19 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/azure-ai-foundry",
    "thumbnail": "https://huggingface.co/blog/assets/azure-ai-foundry/satya-hf-build-compressed.png"
  },
  {
    "title": "Space-Time Graphs of Convex Sets for Multi-Robot Motion Planning",
    "description": "arXiv:2503.00583v2 Announce Type: replace-cross Abstract: We address the Multi-Robot Motion Planning (MRMP) problem of computing collision-free trajectories for multiple robots in shared continuous environments. While existing frameworks effectively decompose MRMP into single-robot subproblems, spatiotemporal motion planning with dynamic obstacles remains challenging, particularly in cluttered or narrow-corridor settings. We propose Space-Time Graphs of Convex Sets (ST-GCS), a novel planner that systematically covers the collision-free space-time domain with convex sets instead of relying on random sampling. By extending Graphs of Convex Sets (GCS) into the time dimension, ST-GCS formulates time-optimal trajectories in a unified convex optimization that naturally accommodates velocity bounds and flexible arrival times. We also propose Exact Convex Decomposition (ECD) to 'reserve' trajectories as spatiotemporal obstacles, maintaining a collision-free space-time graph of convex sets for subsequent planning. Integrated into two prioritized-planning frameworks, ST-GCS consistently achieves higher success rates and better solution quality than state-of-the-art sampling-based planners -- often at orders-of-magnitude faster runtimes -- underscoring its benefits for MRMP in challenging settings.",
    "summary": "arXiv:2503.00583v2 Announce Type: replace-cross Abstract: We address the Multi-Robot Motion Planning (MRMP) problem of computing collision-free trajectories for multiple robots in shared continuous environments. While existing frameworks effectively decompose MRMP into single-robot subproblems, spatiotemporal motion planning with dynamic obstacles remains challenging, particularly in cluttered or narrow-corridor settings. We propose Space-Time Graphs of Convex Sets (ST-GCS), a novel planner that systematically covers the collision-free space-time domain with convex sets instead of relying on random sampling. By extending Graphs of Convex Sets (GCS) into the time dimension, ST-GCS formulates time-optimal trajectories in a unified convex optimization that naturally accommodates velocity bounds and flexible arrival times. We also propose Exact Convex Decomposition (ECD) to 'reserve' trajectories as spatiotemporal obstacles, maintaining a collision-free space-time graph of convex sets for subsequent planning. Integrated into two prioritized-planning frameworks, ST-GCS consistently achieves higher success rates and better solution quality than state-of-the-art sampling-based planners -- often at orders-of-magnitude faster runtimes -- underscoring its benefits for MRMP in challenging settings.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.00583",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-Generated Lecture Slides for Improving Slide Element Detection and Retrieval",
    "description": "arXiv:2506.23605v1 Announce Type: cross Abstract: Lecture slide element detection and retrieval are key problems in slide understanding. Training effective models for these tasks often depends on extensive manual annotation. However, annotating large volumes of lecture slides for supervised training is labor intensive and requires domain expertise. To address this, we propose a large language model (LLM)-guided synthetic lecture slide generation pipeline, SynLecSlideGen, which produces high-quality, coherent and realistic slides. We also create an evaluation benchmark, namely RealSlide by manually annotating 1,050 real lecture slides. To assess the utility of our synthetic slides, we perform few-shot transfer learning on real data using models pre-trained on them. Experimental results show that few-shot transfer learning with pretraining on synthetic slides significantly improves performance compared to training only on real data. This demonstrates that synthetic data can effectively compensate for limited labeled lecture slides. The code and resources of our work are publicly available on our project website: https://synslidegen.github.io/.",
    "summary": "arXiv:2506.23605v1 Announce Type: cross Abstract: Lecture slide element detection and retrieval are key problems in slide understanding. Training effective models for these tasks often depends on extensive manual annotation. However, annotating large volumes of lecture slides for supervised training is labor intensive and requires domain expertise. To address this, we propose a large language model (LLM)-guided synthetic lecture slide generation pipeline, SynLecSlideGen, which produces high-quality, coherent and realistic slides. We also create an evaluation benchmark, namely RealSlide by manually annotating 1,050 real lecture slides. To assess the utility of our synthetic slides, we perform few-shot transfer learning on real data using models pre-trained on them. Experimental results show that few-shot transfer learning with pretraining on synthetic slides significantly improves performance compared to training only on real data. This demonstrates that synthetic data can effectively compensate for limited labeled lecture slides. The code and resources of our work are publicly available on our project website: https://synslidegen.github.io/.",
    "pubDate": "Tue, 01 Jul 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.23605",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "One-shot imitation learning",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 21 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/one-shot-imitation-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CodeGemma - an official Google release for code LLMs",
    "description": "",
    "summary": "CodeGemma - an official Google release for code LLMs CodeGemma is a family of open-access versions o...",
    "pubDate": "Tue, 09 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codegemma",
    "thumbnail": "https://huggingface.co/blog/assets/codegemma/thumbnail_b.png"
  },
  {
    "title": "Welcome to Inference Providers on the Hub üî•",
    "description": "",
    "summary": "Welcome to Inference Providers on the Hub üî• Today, we are launching the integration of four awesome ...",
    "pubDate": "Tue, 28 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/thumbnail.png"
  },
  {
    "title": "March 20 ChatGPT outage: Here‚Äôs what happened",
    "description": "An update on our findings, the actions we‚Äôve taken, and technical details of the bug.",
    "summary": "An update on our findings, the actions we‚Äôve taken, and technical details of the bug.",
    "pubDate": "Fri, 24 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/march-20-chatgpt-outage",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From cloud to developers: Hugging Face and Microsoft Deepen Collaboration",
    "description": "",
    "summary": "From cloud to developers: Hugging Face and Microsoft Deepen Collaboration Today at Microsoft Build w...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/microsoft-collaboration",
    "thumbnail": "https://huggingface.co/blog/assets/microsoft-collaboration/thumbnail.jpg"
  },
  {
    "title": "Learning to cooperate, compete, and communicate",
    "description": "Multiagent environments where agents compete for resources are stepping stones on the path to AGI. Multiagent environments have two useful properties: first, there is a natural curriculum‚Äîthe difficulty of the environment is determined by the skill of your competitors (and if you‚Äôre competing against clones of yourself, the environment exactly matches your skill level). Second, a multiagent environment has no stable equilibrium: no matter how smart an agent is, there‚Äôs always pressure to get smarter. These environments have a very different feel from traditional environments, and it‚Äôll take a lot more research before we become good at them.",
    "summary": "Multiagent environments where agents compete for resources are stepping stones on the path to AGI. Multiagent environments have two useful properties: first, there is a natural curriculum‚Äîthe difficulty of the environment is determined by the skill of your competitors (and if you‚Äôre competing against clones of yourself, the environment exactly matches your skill level). Second, a multiagent environment has no stable equilibrium: no matter how smart an agent is, there‚Äôs always pressure to get smarter. These environments have a very different feel from traditional environments, and it‚Äôll take a lot more research before we become good at them.",
    "pubDate": "Thu, 08 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-cooperate-compete-and-communicate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the SQL Console on Datasets",
    "description": "",
    "summary": "Introducing the SQL Console on Datasets Datasets use has been exploding and Hugging Face has become ...",
    "pubDate": "Tue, 17 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sql-console",
    "thumbnail": "https://huggingface.co/blog/assets/sql_console/thumbnail.png"
  },
  {
    "title": "Accelerate StarCoder with ü§ó Optimum Intel on Xeon: Q8/Q4 and Speculative Decoding",
    "description": "",
    "summary": "Accelerate StarCoder with ü§ó Optimum Intel on Xeon: Q8/Q4 and Speculative Decoding Introduction Recen...",
    "pubDate": "Tue, 30 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-starcoder-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Sentence Transformers in the ü§ó Hub",
    "description": "",
    "summary": "Sentence Transformers in the Hugging Face Hub Over the past few weeks, we've built collaborations wi...",
    "pubDate": "Mon, 28 Jun 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentence-transformers-in-the-hub",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Accelerating the development of life-saving treatments",
    "description": "Accelerating the development of life-saving treatments.",
    "summary": "Accelerating the development of life-saving treatments.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/moderna",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  }
]