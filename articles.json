[
  {
    "title": "A faster way to solve complex planning problems",
    "description": "By eliminating redundant computations, a new data-driven method can streamline processes like scheduling trains, routing delivery drivers, or assigning airline crews.",
    "summary": "By eliminating redundant computations, a new data-driven method can streamline processes like scheduling trains, routing delivery drivers, or assigning airline crews.",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/faster-way-solve-complex-planning-problems-0416",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Long-Horizon-01.jpg"
  },
  {
    "title": "‰∫∫„Å®„ÉÜ„ÇØ„Éé„É≠„Ç∏„Éº„ÅÆËûçÂêà„Åß„Ç∑„Éä„Ç∏„ÉºÂâµÂá∫„ÄÄ„Éâ„Ç≥„É¢„Éª„Éï„Ç°„Ç§„Éä„É≥„Çπ„ÄåBPO„Çª„É≥„Çø„Éº„Äç„ÅÆÊà¶Áï•„ÅØÔºü",
    "description": "ÁîüÊàêAI„ÇíÊ¥ªÁî®„Åó„ÅüÊ•≠Âãô„ÅÆÂäπÁéáÂåñ„ÇÇÈÄ≤„ÇÄ‰∏≠„ÄÅ„Ç≥„É≥„Çø„ÇØ„Éà„Çª„É≥„Çø„Éº„ÅÆÁèæÂ†¥„ÅßËµ∑„Åì„Çã„É™„Ç¢„É´„Å™Ë™≤È°å„ÇÑ„ÄÅÊ¨°‰∏ñ‰ª£„Ç≥„É≥„Çø„ÇØ„Éà„Çª„É≥„Çø„Éº„ÅÆÊßãÊÉ≥„Çí„Éâ„Ç≥„É¢„Éª„Éï„Ç°„Ç§„Éä„É≥„Çπ„ÅÆBPO„Çª„É≥„Çø„ÉºÈï∑„Å´ËÅû„ÅÑ„Åü„ÄÇ",
    "summary": "ÁîüÊàêAI„ÇíÊ¥ªÁî®„Åó„ÅüÊ•≠Âãô„ÅÆÂäπÁéáÂåñ„ÇÇÈÄ≤„ÇÄ‰∏≠„ÄÅ„Ç≥„É≥„Çø„ÇØ„Éà„Çª„É≥„Çø„Éº„ÅÆÁèæÂ†¥„ÅßËµ∑„Åì„Çã„É™„Ç¢„É´„Å™Ë™≤È°å„ÇÑ„ÄÅÊ¨°‰∏ñ‰ª£„Ç≥„É≥„Çø„ÇØ„Éà„Çª„É≥„Çø„Éº„ÅÆÊßãÊÉ≥„Çí„Éâ„Ç≥„É¢„Éª„Éï„Ç°„Ç§„Éä„É≥„Çπ„ÅÆBPO„Çª„É≥„Çø„ÉºÈï∑„Å´ËÅû„ÅÑ„Åü„ÄÇ",
    "pubDate": "Fri, 27 Jun 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2506/27/news044.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2506/27/cover_news044.jpg"
  },
  {
    "title": "Building networks of data science talent",
    "description": "Through collaborations with organizations like BREIT in Peru, the MIT Institute for Data, Systems, and Society is upskilling hundreds of learners around the world in data science and machine learning.",
    "summary": "Through collaborations with organizations like BREIT in Peru, the MIT Institute for Data, Systems, and Society is upskilling hundreds of learners around the world in data science and machine learning.",
    "pubDate": "Tue, 27 May 2025 16:11:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/building-networks-data-science-talent-0527",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-breit-idss-killian.jpg"
  },
  {
    "title": "üêØ Liger GRPO meets TRL",
    "description": "",
    "summary": "üêØ Liger GRPO meets TRL TL; DR Liger supercharges TRL‚Äôs Group Relative Policy Optimization GRPO Train...",
    "pubDate": "Sun, 25 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/liger-grpo",
    "thumbnail": "https://huggingface.co/blog/assets/liger-grpo/thumbnail.png"
  },
  {
    "title": "Groq on Hugging Face Inference Providers üî•",
    "description": "",
    "summary": "Groq on Hugging Face Inference Providers üî• We're thrilled to share that Groq is now a supported Infe...",
    "pubDate": "Mon, 16 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-groq",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-groq.jpg"
  },
  {
    "title": "Interactively explore your Huggingface dataset with one line of code",
    "description": "",
    "summary": "Interactively explore your Huggingface dataset with one line of code The Hugging Face datasets libra...",
    "pubDate": "Wed, 25 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/scalable-data-inspection",
    "thumbnail": "https://huggingface.co/blog/assets/scalable-data-inspection/thumbnail.png"
  },
  {
    "title": "FAF: A Feature-Adaptive Framework for Few-Shot Time Series Forecasting",
    "description": "arXiv:2506.19567v1 Announce Type: cross Abstract: Multi-task and few-shot time series forecasting tasks are commonly encountered in scenarios such as the launch of new products in different cities. However, traditional time series forecasting methods suffer from insufficient historical data, which stems from a disregard for the generalized and specific features among different tasks. For the aforementioned challenges, we propose the Feature-Adaptive Time Series Forecasting Framework (FAF), which consists of three key components: the Generalized Knowledge Module (GKM), the Task-Specific Module (TSM), and the Rank Module (RM). During training phase, the GKM is updated through a meta-learning mechanism that enables the model to extract generalized features across related tasks. Meanwhile, the TSM is trained to capture diverse local dynamics through multiple functional regions, each of which learns specific features from individual tasks. During testing phase, the RM dynamically selects the most relevant functional region from the TSM based on input sequence features, which is then combined with the generalized knowledge learned by the GKM to generate accurate forecasts. This design enables FAF to achieve robust and personalized forecasting even with sparse historical observations We evaluate FAF on five diverse real-world datasets under few-shot time series forecasting settings. Experimental results demonstrate that FAF consistently outperforms baselines that include three categories of time series forecasting methods. In particular, FAF achieves a 41.81% improvement over the best baseline, iTransformer, on the CO$_2$ emissions dataset.",
    "summary": "arXiv:2506.19567v1 Announce Type: cross Abstract: Multi-task and few-shot time series forecasting tasks are commonly encountered in scenarios such as the launch of new products in different cities. However, traditional time series forecasting methods suffer from insufficient historical data, which stems from a disregard for the generalized and specific features among different tasks. For the aforementioned challenges, we propose the Feature-Adaptive Time Series Forecasting Framework (FAF), which consists of three key components: the Generalized Knowledge Module (GKM), the Task-Specific Module (TSM), and the Rank Module (RM). During training phase, the GKM is updated through a meta-learning mechanism that enables the model to extract generalized features across related tasks. Meanwhile, the TSM is trained to capture diverse local dynamics through multiple functional regions, each of which learns specific features from individual tasks. During testing phase, the RM dynamically selects the most relevant functional region from the TSM based on input sequence features, which is then combined with the generalized knowledge learned by the GKM to generate accurate forecasts. This design enables FAF to achieve robust and personalized forecasting even with sparse historical observations We evaluate FAF on five diverse real-world datasets under few-shot time series forecasting settings. Experimental results demonstrate that FAF consistently outperforms baselines that include three categories of time series forecasting methods. In particular, FAF achieves a 41.81% improvement over the best baseline, iTransformer, on the CO$_2$ emissions dataset.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19567",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Éû„Éç„Ç∏„É£„Éº„ÅåÁîüÊàêAIÂ∞éÂÖ•„ÅÆ„Åü„ÇÅ„Å´‚Äú‰ªä„Åô„Åê„Åß„Åç„Çã‚Äù3„Å§„ÅÆ„Åì„Å®„ÄÄGoogle„Åå„Éñ„É≠„Ç∞„ÅßÁ¥π‰ªã",
    "description": "„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Éû„Éç„Ç∏„É£„ÉºÔºàPMÔºâ„ÅåÁµÑÁπî„Å´ÁîüÊàêAI„ÇíÂ∞éÂÖ•„Åô„Çã„Åü„ÇÅ‚Äú‰ªä„Åô„Åê„Åß„Åç„Çã‚Äù3„Å§„ÅÆ„Åì„Å®‚Äï‚ÄïÁ±≥Google„ÅåÂÖ¨Âºè„Éñ„É≠„Ç∞„Åß„ÄÅ„Åì„Çì„Å™„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„Éà„ÇíÂÖ¨Èñã„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Éû„Éç„Ç∏„É£„ÉºÔºàPMÔºâ„ÅåÁµÑÁπî„Å´ÁîüÊàêAI„ÇíÂ∞éÂÖ•„Åô„Çã„Åü„ÇÅ‚Äú‰ªä„Åô„Åê„Åß„Åç„Çã‚Äù3„Å§„ÅÆ„Åì„Å®‚Äï‚ÄïÁ±≥Google„ÅåÂÖ¨Âºè„Éñ„É≠„Ç∞„Åß„ÄÅ„Åì„Çì„Å™„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„Éà„ÇíÂÖ¨Èñã„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Fri, 20 Jun 2025 07:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/19/news110.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/19/cover_news110.jpg"
  },
  {
    "title": "Towards AI Search Paradigm",
    "description": "arXiv:2506.17188v1 Announce Type: cross Abstract: In this paper, we introduce the AI Search Paradigm, a comprehensive blueprint for next-generation search systems capable of emulating human information processing and decision-making. The paradigm employs a modular architecture of four LLM-powered agents (Master, Planner, Executor and Writer) that dynamically adapt to the full spectrum of information needs, from simple factual queries to complex multi-stage reasoning tasks. These agents collaborate dynamically through coordinated workflows to evaluate query complexity, decompose problems into executable plans, and orchestrate tool usage, task execution, and content synthesis. We systematically present key methodologies for realizing this paradigm, including task planning and tool integration, execution strategies, aligned and robust retrieval-augmented generation, and efficient LLM inference, spanning both algorithmic techniques and infrastructure-level optimizations. By providing an in-depth guide to these foundational components, this work aims to inform the development of trustworthy, adaptive, and scalable AI search systems.",
    "summary": "arXiv:2506.17188v1 Announce Type: cross Abstract: In this paper, we introduce the AI Search Paradigm, a comprehensive blueprint for next-generation search systems capable of emulating human information processing and decision-making. The paradigm employs a modular architecture of four LLM-powered agents (Master, Planner, Executor and Writer) that dynamically adapt to the full spectrum of information needs, from simple factual queries to complex multi-stage reasoning tasks. These agents collaborate dynamically through coordinated workflows to evaluate query complexity, decompose problems into executable plans, and orchestrate tool usage, task execution, and content synthesis. We systematically present key methodologies for realizing this paradigm, including task planning and tool integration, execution strategies, aligned and robust retrieval-augmented generation, and efficient LLM inference, spanning both algorithmic techniques and infrastructure-level optimizations. By providing an in-depth guide to these foundational components, this work aims to inform the development of trustworthy, adaptive, and scalable AI search systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17188",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Stable Diffusion XL on Mac with Advanced Core ML Quantization",
    "description": "",
    "summary": "Stable Diffusion XL on Mac with Advanced Core ML Quantization Stable Diffusion XL was released yeste...",
    "pubDate": "Thu, 27 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-xl-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/stable-diffusion-xl-coreml/thumbnail.png"
  },
  {
    "title": "New tools and features in the Responses API",
    "description": "New features in the Responses API: Remote MCP, image gen, Code Interpreter, and more. Powering faster, smarter agents with GPT-4o & o-series models, plus new features for reliability and efficiency.",
    "summary": "New features in the Responses API: Remote MCP, image gen, Code Interpreter, and more. Powering faster, smarter agents with GPT-4o & o-series models, plus new features for reliability and efficiency.",
    "pubDate": "Wed, 21 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-and-features-in-the-responses-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bayesian Epistemology with Weighted Authority: A Formal Architecture for Truth-Promoting Autonomous Scientific Reasoning",
    "description": "arXiv:2506.16015v1 Announce Type: new Abstract: The exponential expansion of scientific literature has surpassed the epistemic processing capabilities of both human experts and current artificial intelligence systems. This paper introduces Bayesian Epistemology with Weighted Authority (BEWA), a formally structured architecture that operationalises belief as a dynamic, probabilistically coherent function over structured scientific claims. Each claim is contextualised, author-attributed, and evaluated through a system of replication scores, citation weighting, and temporal decay. Belief updates are performed via evidence-conditioned Bayesian inference, contradiction processing, and epistemic decay mechanisms. The architecture supports graph-based claim propagation, authorial credibility modelling, cryptographic anchoring, and zero-knowledge audit verification. By formalising scientific reasoning into a computationally verifiable epistemic network, BEWA advances the foundation for machine reasoning systems that promote truth utility, rational belief convergence, and audit-resilient integrity across dynamic scientific domains.",
    "summary": "arXiv:2506.16015v1 Announce Type: new Abstract: The exponential expansion of scientific literature has surpassed the epistemic processing capabilities of both human experts and current artificial intelligence systems. This paper introduces Bayesian Epistemology with Weighted Authority (BEWA), a formally structured architecture that operationalises belief as a dynamic, probabilistically coherent function over structured scientific claims. Each claim is contextualised, author-attributed, and evaluated through a system of replication scores, citation weighting, and temporal decay. Belief updates are performed via evidence-conditioned Bayesian inference, contradiction processing, and epistemic decay mechanisms. The architecture supports graph-based claim propagation, authorial credibility modelling, cryptographic anchoring, and zero-knowledge audit verification. By formalising scientific reasoning into a computationally verifiable epistemic network, BEWA advances the foundation for machine reasoning systems that promote truth utility, rational belief convergence, and audit-resilient integrity across dynamic scientific domains.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16015",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Lessons learned on language model safety and misuse",
    "description": "We describe our latest thinking in the hope of helping other AI developers address safety and misuse of deployed¬†models.",
    "summary": "We describe our latest thinking in the hope of helping other AI developers address safety and misuse of deployed¬†models.",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-model-safety-and-misuse",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Memory and new controls for ChatGPT",
    "description": "We‚Äôre testing the ability for ChatGPT to remember things you discuss to make future chats more helpful. You‚Äôre in control of ChatGPT‚Äôs memory.",
    "summary": "We‚Äôre testing the ability for ChatGPT to remember things you discuss to make future chats more helpful. You‚Äôre in control of ChatGPT‚Äôs memory.",
    "pubDate": "Tue, 13 Feb 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/memory-and-new-controls-for-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The N Implementation Details of RLHF with PPO",
    "description": "",
    "summary": "The N Implementation Details of RLHF with PPO RLHF / ChatGPT has been a popular research topic these...",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo",
    "thumbnail": "https://huggingface.co/blog/assets/167_the_n_implementation_details_of_rlhf_with_ppo/thumbnail.png"
  },
  {
    "title": "Gradio 3.0 is Out!",
    "description": "",
    "summary": "Gradio 3.0 is Out! Machine Learning Demos Machine learning demos are an increasingly vital part of r...",
    "pubDate": "Mon, 16 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-blocks",
    "thumbnail": "https://huggingface.co/blog/assets/68_gradio_blocks/block-party.png"
  },
  {
    "title": "Getting started with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Getting Started with Hugging Face Inference Endpoints Training machine learning models has become qu...",
    "pubDate": "Fri, 14 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/109_inference_endpoints/endpoints05.png"
  },
  {
    "title": "Helen Toner joins OpenAI‚Äôs board of directors",
    "description": "Today, we‚Äôre excited to announce the appointment of Helen Toner to our board of directors.",
    "summary": "Today, we‚Äôre excited to announce the appointment of Helen Toner to our board of directors.",
    "pubDate": "Wed, 08 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/helen-toner-joins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The 5 Most Under-Rated Tools on Hugging Face",
    "description": "",
    "summary": "The 5 Most Under-Rated Tools on Hugging Face The Hugging Face Hub boasts over 850K public models, wi...",
    "pubDate": "Thu, 22 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unsung-heroes",
    "thumbnail": "https://huggingface.co/blog/assets/unsung-heroes/new-thumbnail.png"
  },
  {
    "title": "Economics and reasoning with OpenAI o1",
    "description": "Economist Tyler Cowen explains how OpenAI o1 tackles complex economic questions.",
    "summary": "Economist Tyler Cowen explains how OpenAI o1 tackles complex economic questions.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-economics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SDXL in 4 steps with Latent Consistency LoRAs",
    "description": "",
    "summary": "SDXL in 4 steps with Latent Consistency LoRAs Latent Consistency Models (LCM) are a way to decrease ...",
    "pubDate": "Thu, 09 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lcm_lora",
    "thumbnail": "https://huggingface.co/blog/assets/lcm_sdxl/lcm_thumbnail.png"
  },
  {
    "title": "Frequency-Semantic Enhanced Variational Autoencoder for Zero-Shot Skeleton-based Action Recognition",
    "description": "arXiv:2506.22179v1 Announce Type: cross Abstract: Zero-shot skeleton-based action recognition aims to develop models capable of identifying actions beyond the categories encountered during training. Previous approaches have primarily focused on aligning visual and semantic representations but often overlooked the importance of fine-grained action patterns in the semantic space (e.g., the hand movements in drinking water and brushing teeth). To address these limitations, we propose a Frequency-Semantic Enhanced Variational Autoencoder (FS-VAE) to explore the skeleton semantic representation learning with frequency decomposition. FS-VAE consists of three key components: 1) a frequency-based enhancement module with high- and low-frequency adjustments to enrich the skeletal semantics learning and improve the robustness of zero-shot action recognition; 2) a semantic-based action description with multilevel alignment to capture both local details and global correspondence, effectively bridging the semantic gap and compensating for the inherent loss of information in skeleton sequences; 3) a calibrated cross-alignment loss that enables valid skeleton-text pairs to counterbalance ambiguous ones, mitigating discrepancies and ambiguities in skeleton and text features, thereby ensuring robust alignment. Evaluations on the benchmarks demonstrate the effectiveness of our approach, validating that frequency-enhanced semantic features enable robust differentiation of visually and semantically similar action clusters, improving zero-shot action recognition.",
    "summary": "arXiv:2506.22179v1 Announce Type: cross Abstract: Zero-shot skeleton-based action recognition aims to develop models capable of identifying actions beyond the categories encountered during training. Previous approaches have primarily focused on aligning visual and semantic representations but often overlooked the importance of fine-grained action patterns in the semantic space (e.g., the hand movements in drinking water and brushing teeth). To address these limitations, we propose a Frequency-Semantic Enhanced Variational Autoencoder (FS-VAE) to explore the skeleton semantic representation learning with frequency decomposition. FS-VAE consists of three key components: 1) a frequency-based enhancement module with high- and low-frequency adjustments to enrich the skeletal semantics learning and improve the robustness of zero-shot action recognition; 2) a semantic-based action description with multilevel alignment to capture both local details and global correspondence, effectively bridging the semantic gap and compensating for the inherent loss of information in skeleton sequences; 3) a calibrated cross-alignment loss that enables valid skeleton-text pairs to counterbalance ambiguous ones, mitigating discrepancies and ambiguities in skeleton and text features, thereby ensuring robust alignment. Evaluations on the benchmarks demonstrate the effectiveness of our approach, validating that frequency-enhanced semantic features enable robust differentiation of visually and semantically similar action clusters, improving zero-shot action recognition.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22179",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ContactDexNet: Multi-fingered Robotic Hand Grasping in Cluttered Environments through Hand-object Contact Semantic Mapping",
    "description": "arXiv:2404.08844v3 Announce Type: replace-cross Abstract: The deep learning models has significantly advanced dexterous manipulation techniques for multi-fingered hand grasping. However, the contact information-guided grasping in cluttered environments remains largely underexplored. To address this gap, we have developed a method for generating multi-fingered hand grasp samples in cluttered settings through contact semantic map. We introduce a contact semantic conditional variational autoencoder network (CoSe-CVAE) for creating comprehensive contact semantic map from object point cloud. We utilize grasp detection method to estimate hand grasp poses from the contact semantic map. Finally, an unified grasp evaluation model PointNetGPD++ is designed to assess grasp quality and collision probability, substantially improving the reliability of identifying optimal grasps in cluttered scenarios. Our grasp generation method has demonstrated remarkable success, outperforming state-of-the-art methods by at least 4.65% with 81.0% average grasping success rate in real-world single-object environment and 75.3% grasping success rate in cluttered scenes. We also proposed the multi-modal multi-fingered grasping dataset generation method. Our multi-fingered hand grasping dataset outperforms previous datasets in scene diversity, modality diversity. The dataset, code and supplementary materials can be found at https://sites.google.com/view/contact-dexnet.",
    "summary": "arXiv:2404.08844v3 Announce Type: replace-cross Abstract: The deep learning models has significantly advanced dexterous manipulation techniques for multi-fingered hand grasping. However, the contact information-guided grasping in cluttered environments remains largely underexplored. To address this gap, we have developed a method for generating multi-fingered hand grasp samples in cluttered settings through contact semantic map. We introduce a contact semantic conditional variational autoencoder network (CoSe-CVAE) for creating comprehensive contact semantic map from object point cloud. We utilize grasp detection method to estimate hand grasp poses from the contact semantic map. Finally, an unified grasp evaluation model PointNetGPD++ is designed to assess grasp quality and collision probability, substantially improving the reliability of identifying optimal grasps in cluttered scenarios. Our grasp generation method has demonstrated remarkable success, outperforming state-of-the-art methods by at least 4.65% with 81.0% average grasping success rate in real-world single-object environment and 75.3% grasping success rate in cluttered scenes. We also proposed the multi-modal multi-fingered grasping dataset generation method. Our multi-fingered hand grasping dataset outperforms previous datasets in scene diversity, modality diversity. The dataset, code and supplementary materials can be found at https://sites.google.com/view/contact-dexnet.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2404.08844",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence",
    "description": "arXiv:2506.15677v2 Announce Type: replace Abstract: AI agents today are mostly siloed - they either retrieve and reason over vast amount of digital information and knowledge obtained online; or interact with the physical world through embodied perception, planning and action - but rarely both. This separation limits their ability to solve tasks that require integrated physical and digital intelligence, such as cooking from online recipes, navigating with dynamic map data, or interpreting real-world landmarks using web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI agents that fluidly bridge embodiment and web-scale reasoning. To operationalize this concept, we first develop the Embodied Web Agents task environments, a unified simulation platform that tightly integrates realistic 3D indoor and outdoor environments with functional web interfaces. Building upon this platform, we construct and release the Embodied Web Agents Benchmark, which encompasses a diverse suite of tasks including cooking, navigation, shopping, tourism, and geolocation - all requiring coordinated reasoning across physical and digital realms for systematic assessment of cross-domain intelligence. Experimental results reveal significant performance gaps between state-of-the-art AI systems and human capabilities, establishing both challenges and opportunities at the intersection of embodied cognition and web-scale knowledge access. All datasets, codes and websites are publicly available at our project page https://embodied-web-agent.github.io/.",
    "summary": "arXiv:2506.15677v2 Announce Type: replace Abstract: AI agents today are mostly siloed - they either retrieve and reason over vast amount of digital information and knowledge obtained online; or interact with the physical world through embodied perception, planning and action - but rarely both. This separation limits their ability to solve tasks that require integrated physical and digital intelligence, such as cooking from online recipes, navigating with dynamic map data, or interpreting real-world landmarks using web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI agents that fluidly bridge embodiment and web-scale reasoning. To operationalize this concept, we first develop the Embodied Web Agents task environments, a unified simulation platform that tightly integrates realistic 3D indoor and outdoor environments with functional web interfaces. Building upon this platform, we construct and release the Embodied Web Agents Benchmark, which encompasses a diverse suite of tasks including cooking, navigation, shopping, tourism, and geolocation - all requiring coordinated reasoning across physical and digital realms for systematic assessment of cross-domain intelligence. Experimental results reveal significant performance gaps between state-of-the-art AI systems and human capabilities, establishing both challenges and opportunities at the intersection of embodied cognition and web-scale knowledge access. All datasets, codes and websites are publicly available at our project page https://embodied-web-agent.github.io/.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15677",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "UniCA: Adapting Time Series Foundation Model to General Covariate-Aware Forecasting",
    "description": "arXiv:2506.22039v1 Announce Type: cross Abstract: Time Series Foundation Models (TSFMs) have achieved remarkable success through large-scale pretraining. However, their design primarily targets real-valued series, limiting their ability to handle general forecasting tasks involving diverse and often heterogeneous covariates--such as categorical variables and multimodal data (e.g., images, text)--which are typically task-specific and difficult to leverage during pretraining. To address this gap, we propose Unified Covariate Adaptation (UniCA), a framework to bridge TSFMs with general covariate-aware forecasting. UniCA first performs covariate homogenization to transform heterogeneous covariates into high-level homogeneous series representations and then fuses them via a unified attention-based fusion mechanism. UniCA is compatible and universal for adaptation with both homogeneous and heterogeneous covariates, incorporating extra covariate information while preserving the generalization ability of TSFMs.Extensive experiments on multiple unimodal and multimodal covariate-aware forecasting benchmarks demonstrate the superiority of UniCA, highlighting the promise of covariate-aware TSFM adaptation in real-world forecasting scenarios. Codes are released on https://github.com/hanlu-nju/UniCA.",
    "summary": "arXiv:2506.22039v1 Announce Type: cross Abstract: Time Series Foundation Models (TSFMs) have achieved remarkable success through large-scale pretraining. However, their design primarily targets real-valued series, limiting their ability to handle general forecasting tasks involving diverse and often heterogeneous covariates--such as categorical variables and multimodal data (e.g., images, text)--which are typically task-specific and difficult to leverage during pretraining. To address this gap, we propose Unified Covariate Adaptation (UniCA), a framework to bridge TSFMs with general covariate-aware forecasting. UniCA first performs covariate homogenization to transform heterogeneous covariates into high-level homogeneous series representations and then fuses them via a unified attention-based fusion mechanism. UniCA is compatible and universal for adaptation with both homogeneous and heterogeneous covariates, incorporating extra covariate information while preserving the generalization ability of TSFMs.Extensive experiments on multiple unimodal and multimodal covariate-aware forecasting benchmarks demonstrate the superiority of UniCA, highlighting the promise of covariate-aware TSFM adaptation in real-world forecasting scenarios. Codes are released on https://github.com/hanlu-nju/UniCA.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22039",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Pre-Train BERT with Hugging Face Transformers and Habana Gaudi",
    "description": "",
    "summary": "Pre-Training BERT with Hugging Face Transformers and Habana Gaudi In this Tutorial, you will learn h...",
    "pubDate": "Mon, 22 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pretraining-bert",
    "thumbnail": "https://huggingface.co/blog/assets/99_pretraining_bert/thumbnail.png"
  },
  {
    "title": "OpenAI and Microsoft extend partnership",
    "description": "We‚Äôre happy to announce that OpenAI and¬†Microsoft¬†are extending our¬†partnership.",
    "summary": "We‚Äôre happy to announce that OpenAI and¬†Microsoft¬†are extending our¬†partnership.",
    "pubDate": "Mon, 23 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-microsoft-extend-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Communication-Efficient Heterogeneous Federated Learning with Generalized Heavy-Ball Momentum",
    "description": "arXiv:2311.18578v3 Announce Type: replace-cross Abstract: Federated Learning (FL) has emerged as the state-of-the-art approach for learning from decentralized data in privacy-constrained scenarios.However, system and statistical challenges hinder its real-world applicability, requiring efficient learning from edge devices and robustness to data heterogeneity. Despite significant research efforts, existing approaches often degrade severely due to the joint effect of heterogeneity and partial client participation. In particular, while momentum appears as a promising approach for overcoming statistical heterogeneity, in current approaches its update is biased towards the most recently sampled clients. As we show in this work, this is the reason why it fails to outperform FedAvg, preventing its effective use in real-world large-scale scenarios. In this work, we propose a novel Generalized Heavy-Ball Momentum (GHBM) and theoretically prove it enables convergence under unbounded data heterogeneity in cyclic partial participation, thereby advancing the understanding of momentum's effectiveness in FL. We then introduce adaptive and communication-efficient variants of GHBM that match the communication complexity of FedAvg in settings where clients can be stateful. Extensive experiments on vision and language tasks confirm our theoretical findings, demonstrating that GHBM substantially improves state-of-the-art performance under random uniform client sampling, particularly in large-scale settings with high data heterogeneity and low client participation. Code is available at https://rickzack.github.io/GHBM.",
    "summary": "arXiv:2311.18578v3 Announce Type: replace-cross Abstract: Federated Learning (FL) has emerged as the state-of-the-art approach for learning from decentralized data in privacy-constrained scenarios.However, system and statistical challenges hinder its real-world applicability, requiring efficient learning from edge devices and robustness to data heterogeneity. Despite significant research efforts, existing approaches often degrade severely due to the joint effect of heterogeneity and partial client participation. In particular, while momentum appears as a promising approach for overcoming statistical heterogeneity, in current approaches its update is biased towards the most recently sampled clients. As we show in this work, this is the reason why it fails to outperform FedAvg, preventing its effective use in real-world large-scale scenarios. In this work, we propose a novel Generalized Heavy-Ball Momentum (GHBM) and theoretically prove it enables convergence under unbounded data heterogeneity in cyclic partial participation, thereby advancing the understanding of momentum's effectiveness in FL. We then introduce adaptive and communication-efficient variants of GHBM that match the communication complexity of FedAvg in settings where clients can be stateful. Extensive experiments on vision and language tasks confirm our theoretical findings, demonstrating that GHBM substantially improves state-of-the-art performance under random uniform client sampling, particularly in large-scale settings with high data heterogeneity and low client participation. Code is available at https://rickzack.github.io/GHBM.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2311.18578",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Navigating the challenges and opportunities of synthetic voices",
    "description": "We‚Äôre sharing lessons from a small scale preview of Voice Engine, a model for creating custom voices.",
    "summary": "We‚Äôre sharing lessons from a small scale preview of Voice Engine, a model for creating custom voices.",
    "pubDate": "Fri, 29 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/navigating-the-challenges-and-opportunities-of-synthetic-voices",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-Tuning GPT-4o Webinar",
    "description": "Fine-Tuning GPT-4o Webinar",
    "summary": "Fine-Tuning GPT-4o Webinar",
    "pubDate": "Mon, 26 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/fine-tuning-gpt-4o-webinar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Maximizing Confidence Alone Improves Reasoning",
    "description": "arXiv:2505.22660v4 Announce Type: replace-cross Abstract: Reinforcement learning (RL) has enabled machine learning models to achieve significant advances in many fields. Most recently, RL has empowered frontier language models to solve challenging math, science, and coding problems. However, central to any RL algorithm is the reward function, and reward engineering is a notoriously difficult problem in any domain. In this paper, we propose RENT: Reinforcement Learning via Entropy Minimization -- a fully unsupervised RL method that requires no external reward or ground-truth answers, and instead uses the model's entropy of its underlying distribution as an intrinsic reward. We find that by reinforcing the chains of thought that yield high model confidence on its generated answers, the model improves its reasoning ability. In our experiments, we showcase these improvements on an extensive suite of commonly-used reasoning benchmarks, including GSM8K, MATH500, AMC, AIME, and GPQA, and models of varying sizes from the Qwen, Mistral, and Llama families. The generality of our unsupervised learning method lends itself to applicability in a wide range of domains where external supervision is unavailable.",
    "summary": "arXiv:2505.22660v4 Announce Type: replace-cross Abstract: Reinforcement learning (RL) has enabled machine learning models to achieve significant advances in many fields. Most recently, RL has empowered frontier language models to solve challenging math, science, and coding problems. However, central to any RL algorithm is the reward function, and reward engineering is a notoriously difficult problem in any domain. In this paper, we propose RENT: Reinforcement Learning via Entropy Minimization -- a fully unsupervised RL method that requires no external reward or ground-truth answers, and instead uses the model's entropy of its underlying distribution as an intrinsic reward. We find that by reinforcing the chains of thought that yield high model confidence on its generated answers, the model improves its reasoning ability. In our experiments, we showcase these improvements on an extensive suite of commonly-used reasoning benchmarks, including GSM8K, MATH500, AMC, AIME, and GPQA, and models of varying sizes from the Qwen, Mistral, and Llama families. The generality of our unsupervised learning method lends itself to applicability in a wide range of domains where external supervision is unavailable.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.22660",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "State of open video generation models in Diffusers",
    "description": "",
    "summary": "State of open video generation models in Diffusers OpenAI‚Äôs Sora demo marked a striking advance in A...",
    "pubDate": "Mon, 27 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/video_gen",
    "thumbnail": "https://huggingface.co/blog/assets/video_gen/thumbnail.png"
  },
  {
    "title": "Data Efficacy for Language Model Training",
    "description": "arXiv:2506.21545v1 Announce Type: cross Abstract: Data is fundamental to the training of language models (LM). Recent research has been dedicated to data efficiency, which aims to maximize performance by selecting a minimal or optimal subset of training data. Techniques such as data filtering, sampling, and selection play a crucial role in this area. To complement it, we define Data Efficacy, which focuses on maximizing performance by optimizing the organization of training data and remains relatively underexplored. This work introduces a general paradigm, DELT, for considering data efficacy in LM training, which highlights the significance of training data organization. DELT comprises three components: Data Scoring, Data Selection, and Data Ordering. Among these components, we design Learnability-Quality Scoring (LQS), as a new instance of Data Scoring, which considers both the learnability and quality of each data sample from the gradient consistency perspective. We also devise Folding Ordering (FO), as a novel instance of Data Ordering, which addresses issues such as model forgetting and data distribution bias. Comprehensive experiments validate the data efficacy in LM training, which demonstrates the following: Firstly, various instances of the proposed DELT enhance LM performance to varying degrees without increasing the data scale and model size. Secondly, among these instances, the combination of our proposed LQS for data scoring and Folding for data ordering achieves the most significant improvement. Lastly, data efficacy can be achieved together with data efficiency by applying data selection. Therefore, we believe that data efficacy is a promising foundational area in LM training.",
    "summary": "arXiv:2506.21545v1 Announce Type: cross Abstract: Data is fundamental to the training of language models (LM). Recent research has been dedicated to data efficiency, which aims to maximize performance by selecting a minimal or optimal subset of training data. Techniques such as data filtering, sampling, and selection play a crucial role in this area. To complement it, we define Data Efficacy, which focuses on maximizing performance by optimizing the organization of training data and remains relatively underexplored. This work introduces a general paradigm, DELT, for considering data efficacy in LM training, which highlights the significance of training data organization. DELT comprises three components: Data Scoring, Data Selection, and Data Ordering. Among these components, we design Learnability-Quality Scoring (LQS), as a new instance of Data Scoring, which considers both the learnability and quality of each data sample from the gradient consistency perspective. We also devise Folding Ordering (FO), as a novel instance of Data Ordering, which addresses issues such as model forgetting and data distribution bias. Comprehensive experiments validate the data efficacy in LM training, which demonstrates the following: Firstly, various instances of the proposed DELT enhance LM performance to varying degrees without increasing the data scale and model size. Secondly, among these instances, the combination of our proposed LQS for data scoring and Folding for data ordering achieves the most significant improvement. Lastly, data efficacy can be achieved together with data efficiency by applying data selection. Therefore, we believe that data efficacy is a promising foundational area in LM training.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21545",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From Data Quality for AI to AI for Data Quality: A Systematic Review of Tools for AI-Augmented Data Quality Management in Data Warehouses",
    "description": "arXiv:2406.10940v3 Announce Type: replace-cross Abstract: While high data quality (DQ) is critical for analytics, compliance, and AI performance, data quality management (DQM) remains a complex, resource-intensive, and often manual process. This study investigates the extent to which existing tools support AI-augmented data quality management (DQM) in data warehouse environments. To this end, we conduct a systematic review of 151 DQ tools to evaluate their automation capabilities, particularly in detecting and recommending DQ rules in data warehouses -- a key component of modern data ecosystems. Using a multi-phase screening process based on functionality, trialability, regulatory compliance (e.g., GDPR), and architectural compatibility with data warehouses, only 10 tools met the criteria for AI-augmented DQM. The analysis reveals that most tools emphasize data cleansing and preparation for AI, rather than leveraging AI to improve DQ itself. Although metadata- and ML-based rule detection techniques are present, features such as SQL-based rule specification, reconciliation logic, and explainability of AI-driven recommendations remain scarce. This study offers practical guidance for tool selection and outlines critical design requirements for next-generation AI-driven DQ solutions -- advocating a paradigm shift from ``data quality for AI'' to ``AI for data quality management''.",
    "summary": "arXiv:2406.10940v3 Announce Type: replace-cross Abstract: While high data quality (DQ) is critical for analytics, compliance, and AI performance, data quality management (DQM) remains a complex, resource-intensive, and often manual process. This study investigates the extent to which existing tools support AI-augmented data quality management (DQM) in data warehouse environments. To this end, we conduct a systematic review of 151 DQ tools to evaluate their automation capabilities, particularly in detecting and recommending DQ rules in data warehouses -- a key component of modern data ecosystems. Using a multi-phase screening process based on functionality, trialability, regulatory compliance (e.g., GDPR), and architectural compatibility with data warehouses, only 10 tools met the criteria for AI-augmented DQM. The analysis reveals that most tools emphasize data cleansing and preparation for AI, rather than leveraging AI to improve DQ itself. Although metadata- and ML-based rule detection techniques are present, features such as SQL-based rule specification, reconciliation logic, and explainability of AI-driven recommendations remain scarce. This study offers practical guidance for tool selection and outlines critical design requirements for next-generation AI-driven DQ solutions -- advocating a paradigm shift from ``data quality for AI'' to ``AI for data quality management''.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.10940",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MuBench: Assessment of Multilingual Capabilities of Large Language Models Across 61 Languages",
    "description": "arXiv:2506.19468v1 Announce Type: cross Abstract: Multilingual large language models (LLMs) are advancing rapidly, with new models frequently claiming support for an increasing number of languages. However, existing evaluation datasets are limited and lack cross-lingual alignment, leaving assessments of multilingual capabilities fragmented in both language and skill coverage. To address this, we introduce MuBench, a benchmark covering 61 languages and evaluating a broad range of capabilities. We evaluate several state-of-the-art multilingual LLMs and find notable gaps between claimed and actual language coverage, particularly a persistent performance disparity between English and low-resource languages. Leveraging MuBench's alignment, we propose Multilingual Consistency (MLC) as a complementary metric to accuracy for analyzing performance bottlenecks and guiding model improvement. Finally, we pretrain a suite of 1.2B-parameter models on English and Chinese with 500B tokens, varying language ratios and parallel data proportions to investigate cross-lingual transfer dynamics.",
    "summary": "arXiv:2506.19468v1 Announce Type: cross Abstract: Multilingual large language models (LLMs) are advancing rapidly, with new models frequently claiming support for an increasing number of languages. However, existing evaluation datasets are limited and lack cross-lingual alignment, leaving assessments of multilingual capabilities fragmented in both language and skill coverage. To address this, we introduce MuBench, a benchmark covering 61 languages and evaluating a broad range of capabilities. We evaluate several state-of-the-art multilingual LLMs and find notable gaps between claimed and actual language coverage, particularly a persistent performance disparity between English and low-resource languages. Leveraging MuBench's alignment, we propose Multilingual Consistency (MLC) as a complementary metric to accuracy for analyzing performance bottlenecks and guiding model improvement. Finally, we pretrain a suite of 1.2B-parameter models on English and Chinese with 500B tokens, varying language ratios and parallel data proportions to investigate cross-lingual transfer dynamics.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19468",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Questions for the Record",
    "description": "The following are the Questions for the Record following Sam Altman's testimony before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "summary": "The following are the Questions for the Record following Sam Altman's testimony before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/sam-altman-senate-questions-for-the-record",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerate Large Model Training using DeepSpeed",
    "description": "",
    "summary": "Accelerate Large Model Training using DeepSpeed In this post we will look at how we can leverage the...",
    "pubDate": "Tue, 28 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-deepspeed",
    "thumbnail": "https://huggingface.co/blog/assets/83_accelerate_deepspeed/deepspeed-thumbnail.png"
  },
  {
    "title": "Rethinking Fine-Tuning when Scaling Test-Time Compute: Limiting Confidence Improves Mathematical Reasoning",
    "description": "arXiv:2502.07154v3 Announce Type: replace-cross Abstract: Recent progress in large language models (LLMs) highlights the power of scaling test-time compute to achieve strong performance on complex tasks, such as mathematical reasoning and code generation. This raises a critical question: how should model training be modified to optimize performance under a subsequent test-time compute strategy and budget? To explore this, we focus on pass@N, a simple test-time strategy that searches for a correct answer in $N$ independent samples. We show, surprisingly, that training with cross-entropy (CE) loss can be ${it misaligned}$ with pass@N in that pass@N accuracy ${it decreases}$ with longer training. We explain the origins of this misalignment in terms of model overconfidence induced by CE, and experimentally verify our prediction of overconfidence as an impediment to scaling test-time compute via pass@N. Furthermore we suggest a principled, modified training loss that is better aligned to pass@N by limiting model confidence and rescuing pass@N test performance. Our algorithm demonstrates improved mathematical reasoning on MATH and MiniF2F benchmarks under several scenarios: (1) providing answers to math questions; and (2) proving theorems by searching over proof trees of varying shapes. Overall our work underscores the importance of co-designing two traditionally separate phases of LLM development: training-time protocols and test-time search and reasoning strategies.",
    "summary": "arXiv:2502.07154v3 Announce Type: replace-cross Abstract: Recent progress in large language models (LLMs) highlights the power of scaling test-time compute to achieve strong performance on complex tasks, such as mathematical reasoning and code generation. This raises a critical question: how should model training be modified to optimize performance under a subsequent test-time compute strategy and budget? To explore this, we focus on pass@N, a simple test-time strategy that searches for a correct answer in $N$ independent samples. We show, surprisingly, that training with cross-entropy (CE) loss can be ${it misaligned}$ with pass@N in that pass@N accuracy ${it decreases}$ with longer training. We explain the origins of this misalignment in terms of model overconfidence induced by CE, and experimentally verify our prediction of overconfidence as an impediment to scaling test-time compute via pass@N. Furthermore we suggest a principled, modified training loss that is better aligned to pass@N by limiting model confidence and rescuing pass@N test performance. Our algorithm demonstrates improved mathematical reasoning on MATH and MiniF2F benchmarks under several scenarios: (1) providing answers to math questions; and (2) proving theorems by searching over proof trees of varying shapes. Overall our work underscores the importance of co-designing two traditionally separate phases of LLM development: training-time protocols and test-time search and reasoning strategies.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.07154",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "7/9ÈñãÂÇ¨„ÄêÁîüÊàêAIÂìÅË≥™ÊîπÂñÑ„Ç¶„Çß„Éì„Éä„Éº„Äë Êú¨Áï™ÂìÅË≥™„ÅÆÁîüÊàêAI„Çí„Å©„ÅÜ‰Ωú„ÇãÔºüLLMOps√óÈ´òÁ≤æÂ∫¶„Éá„Éº„Çø„ÅßÂÆüÁèæ„Åô„ÇãÊîπÂñÑ„Éó„É≠„Çª„Çπ",
    "description": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà9Êó•ÔºàÊ∞¥Ôºâ12ÊôÇ„Åã„ÇâÁîüÊàêAIÊ¥ªÁî®„Çí„ÉÜ„Éº„Éû„Å´„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ Êú¨„Ç¶„Çß„Éì„Éä„Éº„Åß„ÅØ„ÄÅÁîüÊàêAIÊ¥ªÁî®„ÅÆ„Éù„Ç§„É≥„Éà„Å´„Å§„ÅÑ„Å¶„ÅîÁ¥π‰ªã„ÄÇÁîüÊàêAI„ÇíÊú¨Áï™ÂìÅË≥™„Å∏ÊîπÂñÑ„Åô„Çã„Éù„Ç§„É≥„Éà„Åã [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250709webinar/'>7/9ÈñãÂÇ¨„ÄêÁîüÊàêAIÂìÅË≥™ÊîπÂñÑ„Ç¶„Çß„Éì„Éä„Éº„Äë Êú¨Áï™ÂìÅË≥™„ÅÆÁîüÊàêAI„Çí„Å©„ÅÜ‰Ωú„ÇãÔºüLLMOps√óÈ´òÁ≤æÂ∫¶„Éá„Éº„Çø„ÅßÂÆüÁèæ„Åô„ÇãÊîπÂñÑ„Éó„É≠„Çª„Çπ</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà9Êó•ÔºàÊ∞¥Ôºâ12ÊôÇ„Åã„ÇâÁîüÊàêAIÊ¥ªÁî®„Çí„ÉÜ„Éº„Éû„Å´„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ Êú¨„Ç¶„Çß„Éì„Éä„Éº„Åß„ÅØ„ÄÅÁîüÊàêAIÊ¥ªÁî®„ÅÆ„Éù„Ç§„É≥„Éà„Å´„Å§„ÅÑ„Å¶„ÅîÁ¥π‰ªã„ÄÇÁîüÊàêAI„ÇíÊú¨Áï™ÂìÅË≥™„Å∏ÊîπÂñÑ„Åô„Çã„Éù„Ç§„É≥„Éà„Åã [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250709webinar/'>7/9ÈñãÂÇ¨„ÄêÁîüÊàêAIÂìÅË≥™ÊîπÂñÑ„Ç¶„Çß„Éì„Éä„Éº„Äë Êú¨Áï™ÂìÅË≥™„ÅÆÁîüÊàêAI„Çí„Å©„ÅÜ‰Ωú„ÇãÔºüLLMOps√óÈ´òÁ≤æÂ∫¶„Éá„Éº„Çø„ÅßÂÆüÁèæ„Åô„ÇãÊîπÂñÑ„Éó„É≠„Çª„Çπ</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Mon, 16 Jun 2025 01:37:40 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/20250709webinar/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/699_1200x628_2.jpg"
  },
  {
    "title": "A standard transformer and attention with linear biases for molecular conformer generation",
    "description": "arXiv:2506.19834v1 Announce Type: cross Abstract: Sampling low-energy molecular conformations, spatial arrangements of atoms in a molecule, is a critical task for many different calculations performed in the drug discovery and optimization process. Numerous specialized equivariant networks have been designed to generate molecular conformations from 2D molecular graphs. Recently, non-equivariant transformer models have emerged as a viable alternative due to their capability to scale to improve generalization. However, the concern has been that non-equivariant models require a large model size to compensate the lack of equivariant bias. In this paper, we demonstrate that a well-chosen positional encoding effectively addresses these size limitations. A standard transformer model incorporating relative positional encoding for molecular graphs when scaled to 25 million parameters surpasses the current state-of-the-art non-equivariant base model with 64 million parameters on the GEOM-DRUGS benchmark. We implemented relative positional encoding as a negative attention bias that linearly increases with the shortest path distances between graph nodes at varying slopes for different attention heads, similar to ALiBi, a widely adopted relative positional encoding technique in the NLP domain. This architecture has the potential to serve as a foundation for a novel class of generative models for molecular conformations.",
    "summary": "arXiv:2506.19834v1 Announce Type: cross Abstract: Sampling low-energy molecular conformations, spatial arrangements of atoms in a molecule, is a critical task for many different calculations performed in the drug discovery and optimization process. Numerous specialized equivariant networks have been designed to generate molecular conformations from 2D molecular graphs. Recently, non-equivariant transformer models have emerged as a viable alternative due to their capability to scale to improve generalization. However, the concern has been that non-equivariant models require a large model size to compensate the lack of equivariant bias. In this paper, we demonstrate that a well-chosen positional encoding effectively addresses these size limitations. A standard transformer model incorporating relative positional encoding for molecular graphs when scaled to 25 million parameters surpasses the current state-of-the-art non-equivariant base model with 64 million parameters on the GEOM-DRUGS benchmark. We implemented relative positional encoding as a negative attention bias that linearly increases with the shortest path distances between graph nodes at varying slopes for different attention heads, similar to ALiBi, a widely adopted relative positional encoding technique in the NLP domain. This architecture has the potential to serve as a foundation for a novel class of generative models for molecular conformations.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19834",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration",
    "description": "",
    "summary": "Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration The mission of ...",
    "pubDate": "Wed, 15 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel",
    "thumbnail": "https://huggingface.co/blog/assets/80_intel/01.png"
  },
  {
    "title": "From Chunks to Blocks: Accelerating Uploads and Downloads on the Hub",
    "description": "",
    "summary": "From Chunks to Blocks: Accelerating Uploads and Downloads on the Hub Content-defined chunking (CDC) ...",
    "pubDate": "Wed, 12 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/from-chunks-to-blocks",
    "thumbnail": "https://huggingface.co/blog/assets/from-chunks-to-blocks/thumbnail.png"
  },
  {
    "title": "A Deepdive into Aya Vision: Advancing the Frontier of Multilingual Multimodality",
    "description": "",
    "summary": "A Deepdive into Aya Vision: Advancing the Frontier of Multilingual Multimodality With the release of...",
    "pubDate": "Tue, 04 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aya-vision",
    "thumbnail": "https://huggingface.co/blog/assets/aya-vision/thumbnail.png"
  },
  {
    "title": "Gemini Robotics brings AI into the physical world",
    "description": "Introducing Gemini Robotics and Gemini Robotics-ER, AI models designed for robots to understand, act and react to the physical world.",
    "summary": "Introducing Gemini Robotics and Gemini Robotics-ER, AI models designed for robots to understand, act and react to the physical world.",
    "pubDate": "Wed, 12 Mar 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-robotics-brings-ai-into-the-physical-world/",
    "thumbnail": "https://lh3.googleusercontent.com/J74rVi68EPPNMBLxhxI76Bli7QggLtYRYfp5Pk2HVPtSt2NIIk2VmLktQbwDZeIlZiW3AHwlpLNcswHuz_ecR-oj4kI-mtF53yYsGJKfvPugAw5ulQ=w1200-h630-n-nu"
  },
  {
    "title": "ClimateIQA: A New Dataset and Benchmark to Advance Vision-Language Models in Meteorology Anomalies Analysis",
    "description": "arXiv:2406.09838v2 Announce Type: replace-cross Abstract: Meteorological heatmaps play a vital role in deciphering extreme weather phenomena, yet their inherent complexities marked by irregular contours, unstructured patterns, and complex color variations present unique analytical hurdles for state-of-the-art Vision-Language Models (VLMs). Current state-of-the-art models like GPT-4o, Qwen-VL, and LLaVA 1.6 struggle with tasks such as precise color identification and spatial localization, resulting in inaccurate or incomplete interpretations. To address these challenges, we introduce Sparse Position and Outline Tracking (SPOT), a novel algorithm specifically designed to process irregularly shaped colored regions in visual data. SPOT identifies and localizes these regions by extracting their spatial coordinates, enabling structured representations of irregular shapes. Building on SPOT, we construct ClimateIQA, a novel meteorological visual question answering (VQA) dataset, comprising 26,280 high-resolution heatmaps and 762,120 instruction samples for wind gust, total precipitation, wind chill index and heat index analysis. ClimateIQA enhances VLM training by incorporating spatial cues, geographic metadata, and reanalysis data, improving model accuracy in interpreting and describing extreme weather features. Furthermore, we develop Climate-Zoo, a suite of fine-tuned VLMs based on SPOT-empowered ClimateIQA, which significantly outperforms existing models in meteorological heatmap tasks.",
    "summary": "arXiv:2406.09838v2 Announce Type: replace-cross Abstract: Meteorological heatmaps play a vital role in deciphering extreme weather phenomena, yet their inherent complexities marked by irregular contours, unstructured patterns, and complex color variations present unique analytical hurdles for state-of-the-art Vision-Language Models (VLMs). Current state-of-the-art models like GPT-4o, Qwen-VL, and LLaVA 1.6 struggle with tasks such as precise color identification and spatial localization, resulting in inaccurate or incomplete interpretations. To address these challenges, we introduce Sparse Position and Outline Tracking (SPOT), a novel algorithm specifically designed to process irregularly shaped colored regions in visual data. SPOT identifies and localizes these regions by extracting their spatial coordinates, enabling structured representations of irregular shapes. Building on SPOT, we construct ClimateIQA, a novel meteorological visual question answering (VQA) dataset, comprising 26,280 high-resolution heatmaps and 762,120 instruction samples for wind gust, total precipitation, wind chill index and heat index analysis. ClimateIQA enhances VLM training by incorporating spatial cues, geographic metadata, and reanalysis data, improving model accuracy in interpreting and describing extreme weather features. Furthermore, we develop Climate-Zoo, a suite of fine-tuned VLMs based on SPOT-empowered ClimateIQA, which significantly outperforms existing models in meteorological heatmap tasks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.09838",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Extracting Concepts from GPT-4",
    "description": "Using new techniques for scaling sparse autoencoders, we automatically identified 16 million patterns in GPT-4's computations.",
    "summary": "Using new techniques for scaling sparse autoencoders, we automatically identified 16 million patterns in GPT-4's computations.",
    "pubDate": "Thu, 06 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/extracting-concepts-from-gpt-4",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeRobot goes to driving school: World‚Äôs largest open-source self-driving dataset",
    "description": "",
    "summary": "LeRobot goes to driving school TL;DR of L2D, the world's largest self-driving dataset! - 90+ TeraByt...",
    "pubDate": "Tue, 11 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lerobot-goes-to-driving-school",
    "thumbnail": "https://huggingface.co/blog/assets/193_l2d/lerobot-driver.gif"
  },
  {
    "title": "Long-Context Generalization with Sparse Attention",
    "description": "arXiv:2506.16640v2 Announce Type: replace-cross Abstract: Transformer-based architectures traditionally employ softmax to compute attention weights, which produces dense distributions over all tokens in a sequence. While effective in many settings, this density has been shown to be detrimental for tasks that demand precise focus on fixed-size patterns: as sequence length increases, non-informative tokens accumulate attention probability mass, leading to dispersion and representational collapse. We show in this paper that sparse attention mechanisms using $alpha$-entmax can avoid these issues, due to their ability to assign exact zeros to irrelevant tokens. Furthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows $alpha$-entmax with a learnable temperature parameter, allowing the attention distribution to interpolate between sparse (pattern-focused) and dense (softmax-like) regimes. Finally, we show that the ability to locate and generalize fixed-size patterns can be further improved through a careful design of position encodings, which impacts both dense and sparse attention methods. By integrating ASEntmax into standard transformer layers alongside proper positional encodings, we show that our models greatly outperform softmax, scalable softmax, and fixed-temperature $alpha$-entmax baselines on long-context generalization.",
    "summary": "arXiv:2506.16640v2 Announce Type: replace-cross Abstract: Transformer-based architectures traditionally employ softmax to compute attention weights, which produces dense distributions over all tokens in a sequence. While effective in many settings, this density has been shown to be detrimental for tasks that demand precise focus on fixed-size patterns: as sequence length increases, non-informative tokens accumulate attention probability mass, leading to dispersion and representational collapse. We show in this paper that sparse attention mechanisms using $alpha$-entmax can avoid these issues, due to their ability to assign exact zeros to irrelevant tokens. Furthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows $alpha$-entmax with a learnable temperature parameter, allowing the attention distribution to interpolate between sparse (pattern-focused) and dense (softmax-like) regimes. Finally, we show that the ability to locate and generalize fixed-size patterns can be further improved through a careful design of position encodings, which impacts both dense and sparse attention methods. By integrating ASEntmax into standard transformer layers alongside proper positional encodings, we show that our models greatly outperform softmax, scalable softmax, and fixed-temperature $alpha$-entmax baselines on long-context generalization.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16640",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Distributed Neural Architectures",
    "description": "arXiv:2506.22389v1 Announce Type: cross Abstract: We introduce and train distributed neural architectures (DNA) in vision and language domains. DNAs are initialized with a proto-architecture that consists of (transformer, MLP, attention, etc.) modules and routers. Any token (or patch) can traverse any series of modules in any order. DNAs are a natural generalization of the sparse methods such as Mixture-of-Experts, Mixture-of-Depths, parameter sharing, etc. Computation and communication patterns of DNA modules are learnt end-to-end during training and depend on the content and context of each token (or patch). These patterns can be shaped by further requirements added to the optimization objective such as compute/memory efficiency or load balancing. We empirically show that (i) trained DNAs are competitive with the dense baselines in both domains and (ii) compute efficiency/parameter sharing can be learnt from data. Next, we analyze the emergent connectivity and computation patterns in the trained DNAs. We find that the paths that tokens take through the models are themselves distributed according to a power-law. We show that some paths (or, equivalently, groups of modules) show emergent specialization. Finally, we demonstrate that models learn to allocate compute and active parameters in an interpretable way.",
    "summary": "arXiv:2506.22389v1 Announce Type: cross Abstract: We introduce and train distributed neural architectures (DNA) in vision and language domains. DNAs are initialized with a proto-architecture that consists of (transformer, MLP, attention, etc.) modules and routers. Any token (or patch) can traverse any series of modules in any order. DNAs are a natural generalization of the sparse methods such as Mixture-of-Experts, Mixture-of-Depths, parameter sharing, etc. Computation and communication patterns of DNA modules are learnt end-to-end during training and depend on the content and context of each token (or patch). These patterns can be shaped by further requirements added to the optimization objective such as compute/memory efficiency or load balancing. We empirically show that (i) trained DNAs are competitive with the dense baselines in both domains and (ii) compute efficiency/parameter sharing can be learnt from data. Next, we analyze the emergent connectivity and computation patterns in the trained DNAs. We find that the paths that tokens take through the models are themselves distributed according to a power-law. We show that some paths (or, equivalently, groups of modules) show emergent specialization. Finally, we demonstrate that models learn to allocate compute and active parameters in an interpretable way.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22389",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements",
    "description": "arXiv:2506.22419v1 Announce Type: new Abstract: Rapid advancements in large language models (LLMs) have the potential to assist in scientific progress. A critical capability toward this endeavor is the ability to reproduce existing work. To evaluate the ability of AI agents to reproduce results in an active research area, we introduce the Automated LLM Speedrunning Benchmark, leveraging the research community contributions on the NanoGPT speedrun, a competition to train a GPT-2 model in the shortest time. Each of the 19 speedrun tasks provides the agent with the previous records training script, optionally paired with one of three hint formats, ranging from pseudocode to paper-like descriptions of the new records improvements. Records execute quickly by design and speedrun improvements encompass diverse code-level changes, ranging from high-level algorithmic advancements to hardware-aware optimizations. These features make the benchmark both accessible and realistic for the frontier problem of improving LLM training. We find that recent reasoning LLMs combined with SoTA scaffolds struggle to reimplement already-known innovations in our benchmark, even when given detailed hints. Our benchmark thus provides a simple, non-saturated measure of an LLMs ability to automate scientific reproduction, a necessary (but not sufficient) skill for an autonomous research agent.",
    "summary": "arXiv:2506.22419v1 Announce Type: new Abstract: Rapid advancements in large language models (LLMs) have the potential to assist in scientific progress. A critical capability toward this endeavor is the ability to reproduce existing work. To evaluate the ability of AI agents to reproduce results in an active research area, we introduce the Automated LLM Speedrunning Benchmark, leveraging the research community contributions on the NanoGPT speedrun, a competition to train a GPT-2 model in the shortest time. Each of the 19 speedrun tasks provides the agent with the previous records training script, optionally paired with one of three hint formats, ranging from pseudocode to paper-like descriptions of the new records improvements. Records execute quickly by design and speedrun improvements encompass diverse code-level changes, ranging from high-level algorithmic advancements to hardware-aware optimizations. These features make the benchmark both accessible and realistic for the frontier problem of improving LLM training. We find that recent reasoning LLMs combined with SoTA scaffolds struggle to reimplement already-known innovations in our benchmark, even when given detailed hints. Our benchmark thus provides a simple, non-saturated measure of an LLMs ability to automate scientific reproduction, a necessary (but not sufficient) skill for an autonomous research agent.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22419",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅ  ~Áã¨Ëá™LLM„ÅÆÈñãÁô∫ÁßòË©±„Åã„ÇâGPU„Ç≥„Çπ„Éà„ÇíÂâäÊ∏õ„Åô„Çã„Åü„ÇÅ„ÅÆÂÖ∑‰ΩìÁöÑ„Å™„Éù„Ç§„É≥„Éà„Åæ„Åß‰∏ÄÊåôÂ§ßÂÖ¨Èñã~",
    "description": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà16Êó•ÔºàÊ∞¥Ôºâ12ÊôÇ„Åã„ÇâLLMÈñãÁô∫„Å´Èñ¢„Åô„Çã„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ Êú¨„Ç¶„Çß„Éì„Éä„Éº„Åß„ÅØ„ÄÅ‰ªñÁ§æ„ÅÆGPU„ÇØ„É©„Ç¶„Éâ„Çµ„Éº„Éì„Çπ„ÇÑ„Ç™„É≥„Éó„É¨„Éü„ÇπÁí∞Â¢É„Å®„ÅÆÊØîËºÉ„ÇíÈÄö„Åò„Å¶„ÄÅGPU„Ç≥„Çπ„Éà„Çí [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250716webinar/'>„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅ  ~Áã¨Ëá™LLM„ÅÆÈñãÁô∫ÁßòË©±„Åã„ÇâGPU„Ç≥„Çπ„Éà„ÇíÂâäÊ∏õ„Åô„Çã„Åü„ÇÅ„ÅÆÂÖ∑‰ΩìÁöÑ„Å™„Éù„Ç§„É≥„Éà„Åæ„Åß‰∏ÄÊåôÂ§ßÂÖ¨Èñã~</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà16Êó•ÔºàÊ∞¥Ôºâ12ÊôÇ„Åã„ÇâLLMÈñãÁô∫„Å´Èñ¢„Åô„Çã„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ Êú¨„Ç¶„Çß„Éì„Éä„Éº„Åß„ÅØ„ÄÅ‰ªñÁ§æ„ÅÆGPU„ÇØ„É©„Ç¶„Éâ„Çµ„Éº„Éì„Çπ„ÇÑ„Ç™„É≥„Éó„É¨„Éü„ÇπÁí∞Â¢É„Å®„ÅÆÊØîËºÉ„ÇíÈÄö„Åò„Å¶„ÄÅGPU„Ç≥„Çπ„Éà„Çí [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250716webinar/'>„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅ  ~Áã¨Ëá™LLM„ÅÆÈñãÁô∫ÁßòË©±„Åã„ÇâGPU„Ç≥„Çπ„Éà„ÇíÂâäÊ∏õ„Åô„Çã„Åü„ÇÅ„ÅÆÂÖ∑‰ΩìÁöÑ„Å™„Éù„Ç§„É≥„Éà„Åæ„Åß‰∏ÄÊåôÂ§ßÂÖ¨Èñã~</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Wed, 18 Jun 2025 01:00:37 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/20250716webinar/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/700_1200x628_2.jpg"
  },
  {
    "title": "NVIDIA's GTC 2025 Announcement for Physical AI Developers: New Open Models and Datasets",
    "description": "",
    "summary": "NVIDIA's GTC 2025 Announcement for Physical AI Developers: New Open Models and Datasets At its annua...",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nvidia-physical-ai",
    "thumbnail": "https://huggingface.co/blog/assets/nvidia-physical-ai/thumbnail.png"
  },
  {
    "title": "Introducing Optimum: The Optimization Toolkit for Transformers at Scale",
    "description": "",
    "summary": "Introducing ü§ó Optimum: The Optimization Toolkit for Transformers at Scale This post is the first ste...",
    "pubDate": "Tue, 14 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hardware-partners-program",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Disrupting deceptive uses of AI by covert influence operations",
    "description": "We‚Äôve terminated accounts linked to covert influence operations; no significant audience increase due to our services.",
    "summary": "We‚Äôve terminated accounts linked to covert influence operations; no significant audience increase due to our services.",
    "pubDate": "Thu, 30 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-deceptive-uses-of-AI-by-covert-influence-operations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 2",
    "description": "",
    "summary": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 2 In a recent post, we introduced...",
    "pubDate": "Mon, 06 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-sapphire-rapids-inference",
    "thumbnail": "https://huggingface.co/blog/assets/129_intel_sapphire_rapids_inference/01.png"
  },
  {
    "title": "Dell Enterprise Hub is all you need to build AI on premises",
    "description": "",
    "summary": "Dell Enterprise Hub is all you need to build AI on premises This week at Dell Tech World, we announc...",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dell-ai-applications",
    "thumbnail": "https://huggingface.co/blog/assets/dell-ai-applications/dell-post-thumbnail.png"
  },
  {
    "title": "Defeating Prompt Injections by Design",
    "description": "arXiv:2503.18813v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are increasingly deployed in agentic systems that interact with an untrusted environment. However, LLM agents are vulnerable to prompt injection attacks when handling untrusted data. In this paper we propose CaMeL, a robust defense that creates a protective system layer around the LLM, securing it even when underlying models are susceptible to attacks. To operate, CaMeL explicitly extracts the control and data flows from the (trusted) query; therefore, the untrusted data retrieved by the LLM can never impact the program flow. To further improve security, CaMeL uses a notion of a capability to prevent the exfiltration of private data over unauthorized data flows by enforcing security policies when tools are called. We demonstrate effectiveness of CaMeL by solving $77%$ of tasks with provable security (compared to $84%$ with an undefended system) in AgentDojo. We release CaMeL at https://github.com/google-research/camel-prompt-injection.",
    "summary": "arXiv:2503.18813v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are increasingly deployed in agentic systems that interact with an untrusted environment. However, LLM agents are vulnerable to prompt injection attacks when handling untrusted data. In this paper we propose CaMeL, a robust defense that creates a protective system layer around the LLM, securing it even when underlying models are susceptible to attacks. To operate, CaMeL explicitly extracts the control and data flows from the (trusted) query; therefore, the untrusted data retrieved by the LLM can never impact the program flow. To further improve security, CaMeL uses a notion of a capability to prevent the exfiltration of private data over unauthorized data flows by enforcing security policies when tools are called. We demonstrate effectiveness of CaMeL by solving $77%$ of tasks with provable security (compared to $84%$ with an undefended system) in AgentDojo. We release CaMeL at https://github.com/google-research/camel-prompt-injection.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.18813",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Training Cluster as a Service - a new collaboration with NVIDIA",
    "description": "",
    "summary": "Introducing Training Cluster as a Service - a new collaboration with NVIDIA Today at GTC Paris, we a...",
    "pubDate": "Wed, 11 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nvidia-training-cluster",
    "thumbnail": "https://huggingface.co/blog/assets/nvidia-training-cluster/nvidia-training-cluster-thumbnail-compressed.png"
  },
  {
    "title": "Towards Efficient Few-shot Graph Neural Architecture Search via Partitioning Gradient Contribution",
    "description": "arXiv:2506.01231v2 Announce Type: replace-cross Abstract: To address the weight coupling problem, certain studies introduced few-shot Neural Architecture Search (NAS) methods, which partition the supernet into multiple sub-supernets. However, these methods often suffer from computational inefficiency and tend to provide suboptimal partitioning schemes. To address this problem more effectively, we analyze the weight coupling problem from a novel perspective, which primarily stems from distinct modules in succeeding layers imposing conflicting gradient directions on the preceding layer modules. Based on this perspective, we propose the Gradient Contribution (GC) method that efficiently computes the cosine similarity of gradient directions among modules by decomposing the Vector-Jacobian Product during supernet backpropagation. Subsequently, the modules with conflicting gradient directions are allocated to distinct sub-supernets while similar ones are grouped together. To assess the advantages of GC and address the limitations of existing Graph Neural Architecture Search methods, which are limited to searching a single type of Graph Neural Networks (Message Passing Neural Networks (MPNNs) or Graph Transformers (GTs)), we propose the Unified Graph Neural Architecture Search (UGAS) framework, which explores optimal combinations of MPNNs and GTs. The experimental results demonstrate that GC achieves state-of-the-art (SOTA) performance in supernet partitioning quality and time efficiency. In addition, the architectures searched by UGAS+GC outperform both the manually designed GNNs and those obtained by existing NAS methods. Finally, ablation studies further demonstrate the effectiveness of all proposed methods.",
    "summary": "arXiv:2506.01231v2 Announce Type: replace-cross Abstract: To address the weight coupling problem, certain studies introduced few-shot Neural Architecture Search (NAS) methods, which partition the supernet into multiple sub-supernets. However, these methods often suffer from computational inefficiency and tend to provide suboptimal partitioning schemes. To address this problem more effectively, we analyze the weight coupling problem from a novel perspective, which primarily stems from distinct modules in succeeding layers imposing conflicting gradient directions on the preceding layer modules. Based on this perspective, we propose the Gradient Contribution (GC) method that efficiently computes the cosine similarity of gradient directions among modules by decomposing the Vector-Jacobian Product during supernet backpropagation. Subsequently, the modules with conflicting gradient directions are allocated to distinct sub-supernets while similar ones are grouped together. To assess the advantages of GC and address the limitations of existing Graph Neural Architecture Search methods, which are limited to searching a single type of Graph Neural Networks (Message Passing Neural Networks (MPNNs) or Graph Transformers (GTs)), we propose the Unified Graph Neural Architecture Search (UGAS) framework, which explores optimal combinations of MPNNs and GTs. The experimental results demonstrate that GC achieves state-of-the-art (SOTA) performance in supernet partitioning quality and time efficiency. In addition, the architectures searched by UGAS+GC outperform both the manually designed GNNs and those obtained by existing NAS methods. Finally, ablation studies further demonstrate the effectiveness of all proposed methods.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.01231",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Interpretable and Granular Video-Based Quantification of Motor Characteristics from the Finger Tapping Test in Parkinson Disease",
    "description": "arXiv:2506.18925v1 Announce Type: cross Abstract: Accurately quantifying motor characteristics in Parkinson disease (PD) is crucial for monitoring disease progression and optimizing treatment strategies. The finger-tapping test is a standard motor assessment. Clinicians visually evaluate a patient's tapping performance and assign an overall severity score based on tapping amplitude, speed, and irregularity. However, this subjective evaluation is prone to inter- and intra-rater variability, and does not offer insights into individual motor characteristics captured during this test. This paper introduces a granular computer vision-based method for quantifying PD motor characteristics from video recordings. Four sets of clinically relevant features are proposed to characterize hypokinesia, bradykinesia, sequence effect, and hesitation-halts. We evaluate our approach on video recordings and clinical evaluations of 74 PD patients from the Personalized Parkinson Project. Principal component analysis with varimax rotation shows that the video-based features corresponded to the four deficits. Additionally, video-based analysis has allowed us to identify further granular distinctions within sequence effect and hesitation-halts deficits. In the following, we have used these features to train machine learning classifiers to estimate the Movement Disorder Society Unified Parkinson Disease Rating Scale (MDS-UPDRS) finger-tapping score. Compared to state-of-the-art approaches, our method achieves a higher accuracy in MDS-UPDRS score prediction, while still providing an interpretable quantification of individual finger-tapping motor characteristics. In summary, the proposed framework provides a practical solution for the objective assessment of PD motor characteristics, that can potentially be applied in both clinical and remote settings. Future work is needed to assess its responsiveness to symptomatic treatment and disease progression.",
    "summary": "arXiv:2506.18925v1 Announce Type: cross Abstract: Accurately quantifying motor characteristics in Parkinson disease (PD) is crucial for monitoring disease progression and optimizing treatment strategies. The finger-tapping test is a standard motor assessment. Clinicians visually evaluate a patient's tapping performance and assign an overall severity score based on tapping amplitude, speed, and irregularity. However, this subjective evaluation is prone to inter- and intra-rater variability, and does not offer insights into individual motor characteristics captured during this test. This paper introduces a granular computer vision-based method for quantifying PD motor characteristics from video recordings. Four sets of clinically relevant features are proposed to characterize hypokinesia, bradykinesia, sequence effect, and hesitation-halts. We evaluate our approach on video recordings and clinical evaluations of 74 PD patients from the Personalized Parkinson Project. Principal component analysis with varimax rotation shows that the video-based features corresponded to the four deficits. Additionally, video-based analysis has allowed us to identify further granular distinctions within sequence effect and hesitation-halts deficits. In the following, we have used these features to train machine learning classifiers to estimate the Movement Disorder Society Unified Parkinson Disease Rating Scale (MDS-UPDRS) finger-tapping score. Compared to state-of-the-art approaches, our method achieves a higher accuracy in MDS-UPDRS score prediction, while still providing an interpretable quantification of individual finger-tapping motor characteristics. In summary, the proposed framework provides a practical solution for the objective assessment of PD motor characteristics, that can potentially be applied in both clinical and remote settings. Future work is needed to assess its responsiveness to symptomatic treatment and disease progression.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18925",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LRP4RAG: Detecting Hallucinations in Retrieval-Augmented Generation via Layer-wise Relevance Propagation",
    "description": "arXiv:2408.15533v3 Announce Type: replace-cross Abstract: Retrieval-Augmented Generation (RAG) has become a primary technique for mitigating hallucinations in large language models (LLMs). However, incomplete knowledge extraction and insufficient understanding can still mislead LLMs to produce irrelevant or even contradictory responses, which means hallucinations persist in RAG. In this paper, we propose LRP4RAG, a method based on the Layer-wise Relevance Propagation (LRP) algorithm for detecting hallucinations in RAG. Specifically, we first utilize LRP to compute the relevance between the input and output of the RAG generator. We then apply further extraction and resampling to the relevance matrix. The processed relevance data are input into multiple classifiers to determine whether the output contains hallucinations. To the best of our knowledge, this is the first time that LRP has been used for detecting RAG hallucinations, and extensive experiments demonstrate that LRP4RAG outperforms existing baselines.",
    "summary": "arXiv:2408.15533v3 Announce Type: replace-cross Abstract: Retrieval-Augmented Generation (RAG) has become a primary technique for mitigating hallucinations in large language models (LLMs). However, incomplete knowledge extraction and insufficient understanding can still mislead LLMs to produce irrelevant or even contradictory responses, which means hallucinations persist in RAG. In this paper, we propose LRP4RAG, a method based on the Layer-wise Relevance Propagation (LRP) algorithm for detecting hallucinations in RAG. Specifically, we first utilize LRP to compute the relevance between the input and output of the RAG generator. We then apply further extraction and resampling to the relevance matrix. The processed relevance data are input into multiple classifiers to determine whether the output contains hallucinations. To the best of our knowledge, this is the first time that LRP has been used for detecting RAG hallucinations, and extensive experiments demonstrate that LRP4RAG outperforms existing baselines.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.15533",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Will Hurd joins OpenAI‚Äôs board of directors",
    "description": "OpenAI is committed to developing general-purpose artificial intelligence that benefits all humanity, and we believe that achieving our goal requires expertise in public policy as well as technology. So, we‚Äôre delighted to announce that Congressman¬†Will Hurd¬†has joined our board of directors.",
    "summary": "OpenAI is committed to developing general-purpose artificial intelligence that benefits all humanity, and we believe that achieving our goal requires expertise in public policy as well as technology. So, we‚Äôre delighted to announce that Congressman¬†Will Hurd¬†has joined our board of directors.",
    "pubDate": "Mon, 03 May 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/will-hurd-joins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the ChatGPT app for iOS",
    "description": "The ChatGPT app syncs your conversations, supports voice input, and brings our latest model improvements to your fingertips.",
    "summary": "The ChatGPT app syncs your conversations, supports voice input, and brings our latest model improvements to your fingertips.",
    "pubDate": "Thu, 18 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-chatgpt-app-for-ios",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Memory Paradox: Why Our Brains Need Knowledge in an Age of AI",
    "description": "arXiv:2506.11015v2 Announce Type: replace-cross Abstract: In the age of generative AI and ubiquitous digital tools, human cognition faces a structural paradox: as external aids become more capable, internal memory systems risk atrophy. Drawing on neuroscience and cognitive psychology, this paper examines how heavy reliance on AI systems and discovery-based pedagogies may impair the consolidation of declarative and procedural memory -- systems essential for expertise, critical thinking, and long-term retention. We review how tools like ChatGPT and calculators can short-circuit the retrieval, error correction, and schema-building processes necessary for robust neural encoding. Notably, we highlight striking parallels between deep learning phenomena such as 'grokking' and the neuroscience of overlearning and intuition. Empirical studies are discussed showing how premature reliance on AI during learning inhibits proceduralization and intuitive mastery. We argue that effective human-AI interaction depends on strong internal models -- biological 'schemata' and neural manifolds -- that enable users to evaluate, refine, and guide AI output. The paper concludes with policy implications for education and workforce training in the age of large language models.",
    "summary": "arXiv:2506.11015v2 Announce Type: replace-cross Abstract: In the age of generative AI and ubiquitous digital tools, human cognition faces a structural paradox: as external aids become more capable, internal memory systems risk atrophy. Drawing on neuroscience and cognitive psychology, this paper examines how heavy reliance on AI systems and discovery-based pedagogies may impair the consolidation of declarative and procedural memory -- systems essential for expertise, critical thinking, and long-term retention. We review how tools like ChatGPT and calculators can short-circuit the retrieval, error correction, and schema-building processes necessary for robust neural encoding. Notably, we highlight striking parallels between deep learning phenomena such as 'grokking' and the neuroscience of overlearning and intuition. Empirical studies are discussed showing how premature reliance on AI during learning inhibits proceduralization and intuitive mastery. We argue that effective human-AI interaction depends on strong internal models -- biological 'schemata' and neural manifolds -- that enable users to evaluate, refine, and guide AI output. The paper concludes with policy implications for education and workforce training in the age of large language models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11015",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Data Partnerships",
    "description": "Working together to create open-source and private datasets for AI training.",
    "summary": "Working together to create open-source and private datasets for AI training.",
    "pubDate": "Thu, 09 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/data-partnerships",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Can Video Large Multimodal Models Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment",
    "description": "arXiv:2506.22385v1 Announce Type: cross Abstract: Video Large Multimodal Models (VLMMs) have made impressive strides in understanding video content, but they often struggle with abstract and adaptive reasoning-the ability to revise their interpretations when new information emerges. In reality, conclusions are rarely set in stone; additional context can strengthen or weaken an initial inference. To address this, we introduce Defeasible Video Entailment (DVidE), a new task that challenges models to think like doubters, constantly updating their reasoning based on evolving evidence. In DVidE, given a video premise and a textual hypothesis, models must determine whether a new update strengthens or weakens the hypothesis (classification version) or generate a coherent update that modifies the entailment relationship (generation version). For solving the classification task, we propose the Chain of Counterfactual Thought framework, utilizing counterfactual reasoning, ASR-enhanced video content, and rationale refinement to reduce inference bias. For the generation task, we develop a framework that combines ASR output with a Large Language Model (LLM) to produce coherent, contextually relevant updates aligned with the intended strengthener or weakener goals. Additionally, we introduce a novel benchmark dataset, with strengthener/weakener annotations and an LLM-based evaluation metric specifically designed for assessing generative performance. Experimental results demonstrate significant improvements, highlighting our proposed method in enhancing dynamic reasoning capabilities of VLMMs.",
    "summary": "arXiv:2506.22385v1 Announce Type: cross Abstract: Video Large Multimodal Models (VLMMs) have made impressive strides in understanding video content, but they often struggle with abstract and adaptive reasoning-the ability to revise their interpretations when new information emerges. In reality, conclusions are rarely set in stone; additional context can strengthen or weaken an initial inference. To address this, we introduce Defeasible Video Entailment (DVidE), a new task that challenges models to think like doubters, constantly updating their reasoning based on evolving evidence. In DVidE, given a video premise and a textual hypothesis, models must determine whether a new update strengthens or weakens the hypothesis (classification version) or generate a coherent update that modifies the entailment relationship (generation version). For solving the classification task, we propose the Chain of Counterfactual Thought framework, utilizing counterfactual reasoning, ASR-enhanced video content, and rationale refinement to reduce inference bias. For the generation task, we develop a framework that combines ASR output with a Large Language Model (LLM) to produce coherent, contextually relevant updates aligned with the intended strengthener or weakener goals. Additionally, we introduce a novel benchmark dataset, with strengthener/weakener annotations and an LLM-based evaluation metric specifically designed for assessing generative performance. Experimental results demonstrate significant improvements, highlighting our proposed method in enhancing dynamic reasoning capabilities of VLMMs.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22385",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Subspace-Boosted Model Merging",
    "description": "arXiv:2506.16506v1 Announce Type: cross Abstract: Model merging enables the combination of multiple specialized expert models into a single model capable of performing multiple tasks. However, the benefits of merging an increasing amount of specialized experts generally lead to diminishing returns and reduced overall performance gains. In this work, we offer an explanation and analysis from a task arithmetic perspective; revealing that as the merging process (across numerous existing merging methods) continues for more and more experts, the associated task vector space experiences rank collapse. To mitigate this issue, we introduce Subspace Boosting, which operates on the singular value decomposed task vector space and maintains task vector ranks. Subspace Boosting raises merging efficacy for up to 20 expert models by large margins of more than 10% when evaluated on vision benchmarks. Moreover, we propose employing Higher-Order Generalized Singular Value Decomposition to further quantify task similarity, offering a new interpretable perspective on model merging.",
    "summary": "arXiv:2506.16506v1 Announce Type: cross Abstract: Model merging enables the combination of multiple specialized expert models into a single model capable of performing multiple tasks. However, the benefits of merging an increasing amount of specialized experts generally lead to diminishing returns and reduced overall performance gains. In this work, we offer an explanation and analysis from a task arithmetic perspective; revealing that as the merging process (across numerous existing merging methods) continues for more and more experts, the associated task vector space experiences rank collapse. To mitigate this issue, we introduce Subspace Boosting, which operates on the singular value decomposed task vector space and maintains task vector ranks. Subspace Boosting raises merging efficacy for up to 20 expert models by large margins of more than 10% when evaluated on vision benchmarks. Moreover, we propose employing Higher-Order Generalized Singular Value Decomposition to further quantify task similarity, offering a new interpretable perspective on model merging.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16506",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Discovering the minutiae of backend systems",
    "description": "Christian Gibson is an engineer on the Supercomputing team at OpenAI.",
    "summary": "Christian Gibson is an engineer on the Supercomputing team at OpenAI.",
    "pubDate": "Thu, 08 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/discovering-the-minutiae-of-backend-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "We‚Äôre bringing the Financial Times‚Äô world-class journalism to ChatGPT",
    "description": "We will also collaborate on new AI experiences for FT readers.",
    "summary": "We will also collaborate on new AI experiences for FT readers.",
    "pubDate": "Mon, 29 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/content-partnership-with-financial-times",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reinforcement learning for hybrid charging stations planning and operation considering fixed and mobile chargers",
    "description": "arXiv:2506.16764v1 Announce Type: new Abstract: The success of vehicle electrification, which brings significant societal and environmental benefits, is contingent upon the availability of efficient and adaptable charging infrastructure. Traditional fixed-location charging stations often face issues like underutilization or congestion due to the dynamic nature of charging demand. Mobile chargers have emerged as a flexible solution, capable of relocating to align with these demand fluctuations. This paper addresses the optimal planning and operation of hybrid charging infrastructures, integrating both fixed and mobile chargers within urban road networks. We introduce the Hybrid Charging Station Planning and Operation (HCSPO) problem, which simultaneously optimizes the location and configuration of fixed charging stations and schedules mobile chargers for dynamic operations. Our approach incorporates a charging demand prediction model grounded in Model Predictive Control (MPC) to enhance decision-making. To solve the HCSPO problem, we propose a deep reinforcement learning method, augmented with heuristic scheduling techniques, to effectively bridge the planning of fixed chargers with the real-time operation of mobile chargers. Extensive case studies using real-world urban scenarios demonstrate that our method significantly improves the availability of charging infrastructure and reduces user inconvenience compared to existing solutions and baselines.",
    "summary": "arXiv:2506.16764v1 Announce Type: new Abstract: The success of vehicle electrification, which brings significant societal and environmental benefits, is contingent upon the availability of efficient and adaptable charging infrastructure. Traditional fixed-location charging stations often face issues like underutilization or congestion due to the dynamic nature of charging demand. Mobile chargers have emerged as a flexible solution, capable of relocating to align with these demand fluctuations. This paper addresses the optimal planning and operation of hybrid charging infrastructures, integrating both fixed and mobile chargers within urban road networks. We introduce the Hybrid Charging Station Planning and Operation (HCSPO) problem, which simultaneously optimizes the location and configuration of fixed charging stations and schedules mobile chargers for dynamic operations. Our approach incorporates a charging demand prediction model grounded in Model Predictive Control (MPC) to enhance decision-making. To solve the HCSPO problem, we propose a deep reinforcement learning method, augmented with heuristic scheduling techniques, to effectively bridge the planning of fixed chargers with the real-time operation of mobile chargers. Extensive case studies using real-world urban scenarios demonstrate that our method significantly improves the availability of charging infrastructure and reduces user inconvenience compared to existing solutions and baselines.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16764",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows",
    "description": "arXiv:2505.19897v2 Announce Type: replace Abstract: Large Language Models (LLMs) have extended their impact beyond Natural Language Processing, substantially fostering the development of interdisciplinary research. Recently, various LLM-based agents have been developed to assist scientific discovery progress across multiple aspects and domains. Among these, computer-using agents, capable of interacting with operating systems as humans do, are paving the way to automated scientific problem-solving and addressing routines in researchers' workflows. Recognizing the transformative potential of these agents, we introduce ScienceBoard, which encompasses two complementary contributions: (i) a realistic, multi-domain environment featuring dynamic and visually rich scientific workflows with integrated professional software, where agents can autonomously interact via different interfaces to accelerate complex research tasks and experiments; and (ii) a challenging benchmark of 169 high-quality, rigorously validated real-world tasks curated by humans, spanning scientific-discovery workflows in domains such as biochemistry, astronomy, and geoinformatics. Extensive evaluations of agents with state-of-the-art backbones (e.g., GPT-4o, Claude 3.7, UI-TARS) show that, despite some promising results, they still fall short of reliably assisting scientists in complex workflows, achieving only a 15% overall success rate. In-depth analysis further provides valuable insights for addressing current agent limitations and more effective design principles, paving the way to build more capable agents for scientific discovery. Our code, environment, and benchmark are at https://qiushisun.github.io/ScienceBoard-Home/.",
    "summary": "arXiv:2505.19897v2 Announce Type: replace Abstract: Large Language Models (LLMs) have extended their impact beyond Natural Language Processing, substantially fostering the development of interdisciplinary research. Recently, various LLM-based agents have been developed to assist scientific discovery progress across multiple aspects and domains. Among these, computer-using agents, capable of interacting with operating systems as humans do, are paving the way to automated scientific problem-solving and addressing routines in researchers' workflows. Recognizing the transformative potential of these agents, we introduce ScienceBoard, which encompasses two complementary contributions: (i) a realistic, multi-domain environment featuring dynamic and visually rich scientific workflows with integrated professional software, where agents can autonomously interact via different interfaces to accelerate complex research tasks and experiments; and (ii) a challenging benchmark of 169 high-quality, rigorously validated real-world tasks curated by humans, spanning scientific-discovery workflows in domains such as biochemistry, astronomy, and geoinformatics. Extensive evaluations of agents with state-of-the-art backbones (e.g., GPT-4o, Claude 3.7, UI-TARS) show that, despite some promising results, they still fall short of reliably assisting scientists in complex workflows, achieving only a 15% overall success rate. In-depth analysis further provides valuable insights for addressing current agent limitations and more effective design principles, paving the way to build more capable agents for scientific discovery. Our code, environment, and benchmark are at https://qiushisun.github.io/ScienceBoard-Home/.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.19897",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Disrupting malicious uses of AI",
    "description": "Ensuring AI benefits humanity by advancing democratic AI, preventing misuse, and protecting against authoritarian threats.",
    "summary": "Ensuring AI benefits humanity by advancing democratic AI, preventing misuse, and protecting against authoritarian threats.",
    "pubDate": "Fri, 21 Feb 2025 06:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios",
    "description": "arXiv:2506.22068v1 Announce Type: new Abstract: With the deep penetration of Artificial Intelligence (AI) in the transportation sector, intelligent cockpits, autonomous driving, and intelligent road networks are developing at an unprecedented pace. However, the data ecosystems of these three key areas are increasingly fragmented and incompatible. Especially, existing testing methods rely on data stacking, fail to cover all edge cases, and lack flexibility. To address this issue, this paper introduces the concept of 'Query as Test' (QaT). This concept shifts the focus from rigid, prescripted test cases to flexible, on-demand logical queries against a unified data representation. Specifically, we identify the need for a fundamental improvement in data storage and representation, leading to our proposal of 'Extensible Scenarios Notations' (ESN). ESN is a novel declarative data framework based on Answer Set Programming (ASP), which uniformly represents heterogeneous multimodal data from the cockpit, vehicle, and road as a collection of logical facts and rules. This approach not only achieves deep semantic fusion of data, but also brings three core advantages: (1) supports complex and flexible semantic querying through logical reasoning; (2) provides natural interpretability for decision-making processes; (3) allows for on-demand data abstraction through logical rules, enabling fine-grained privacy protection. We further elaborate on the QaT paradigm, transforming the functional validation and safety compliance checks of autonomous driving systems into logical queries against the ESN database, significantly enhancing the expressiveness and formal rigor of the testing. Finally, we introduce the concept of 'Validation-Driven Development' (VDD), which suggests to guide developments by logical validation rather than quantitative testing in the era of Large Language Models, in order to accelerating the iteration and development process.",
    "summary": "arXiv:2506.22068v1 Announce Type: new Abstract: With the deep penetration of Artificial Intelligence (AI) in the transportation sector, intelligent cockpits, autonomous driving, and intelligent road networks are developing at an unprecedented pace. However, the data ecosystems of these three key areas are increasingly fragmented and incompatible. Especially, existing testing methods rely on data stacking, fail to cover all edge cases, and lack flexibility. To address this issue, this paper introduces the concept of 'Query as Test' (QaT). This concept shifts the focus from rigid, prescripted test cases to flexible, on-demand logical queries against a unified data representation. Specifically, we identify the need for a fundamental improvement in data storage and representation, leading to our proposal of 'Extensible Scenarios Notations' (ESN). ESN is a novel declarative data framework based on Answer Set Programming (ASP), which uniformly represents heterogeneous multimodal data from the cockpit, vehicle, and road as a collection of logical facts and rules. This approach not only achieves deep semantic fusion of data, but also brings three core advantages: (1) supports complex and flexible semantic querying through logical reasoning; (2) provides natural interpretability for decision-making processes; (3) allows for on-demand data abstraction through logical rules, enabling fine-grained privacy protection. We further elaborate on the QaT paradigm, transforming the functional validation and safety compliance checks of autonomous driving systems into logical queries against the ESN database, significantly enhancing the expressiveness and formal rigor of the testing. Finally, we introduce the concept of 'Validation-Driven Development' (VDD), which suggests to guide developments by logical validation rather than quantitative testing in the era of Large Language Models, in order to accelerating the iteration and development process.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22068",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Minimalist Method for Fine-tuning Text-to-Image Diffusion Models",
    "description": "arXiv:2506.12036v2 Announce Type: replace-cross Abstract: Recent work uses reinforcement learning (RL) to fine-tune text-to-image diffusion models, improving text-image alignment and sample quality. However, existing approaches introduce unnecessary complexity: they cache the full sampling trajectory, depend on differentiable reward models or large preference datasets, or require specialized guidance techniques. Motivated by the 'golden noise' hypothesis -- that certain initial noise samples can consistently yield superior alignment -- we introduce Noise PPO, a minimalist RL algorithm that leaves the pre-trained diffusion model entirely frozen and learns a prompt-conditioned initial noise generator. Our approach requires no trajectory storage, reward backpropagation, or complex guidance tricks. Extensive experiments show that optimizing the initial noise distribution consistently improves alignment and sample quality over the original model, with the most significant gains at low inference steps. As the number of inference steps increases, the benefit of noise optimization diminishes but remains present. These findings clarify the scope and limitations of the golden noise hypothesis and reinforce the practical value of minimalist RL fine-tuning for diffusion models.",
    "summary": "arXiv:2506.12036v2 Announce Type: replace-cross Abstract: Recent work uses reinforcement learning (RL) to fine-tune text-to-image diffusion models, improving text-image alignment and sample quality. However, existing approaches introduce unnecessary complexity: they cache the full sampling trajectory, depend on differentiable reward models or large preference datasets, or require specialized guidance techniques. Motivated by the 'golden noise' hypothesis -- that certain initial noise samples can consistently yield superior alignment -- we introduce Noise PPO, a minimalist RL algorithm that leaves the pre-trained diffusion model entirely frozen and learns a prompt-conditioned initial noise generator. Our approach requires no trajectory storage, reward backpropagation, or complex guidance tricks. Extensive experiments show that optimizing the initial noise distribution consistently improves alignment and sample quality over the original model, with the most significant gains at low inference steps. As the number of inference steps increases, the benefit of noise optimization diminishes but remains present. These findings clarify the scope and limitations of the golden noise hypothesis and reinforce the practical value of minimalist RL fine-tuning for diffusion models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12036",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Effective Complementary Security Analysis using Large Language Models",
    "description": "arXiv:2506.16899v1 Announce Type: cross Abstract: A key challenge in security analysis is the manual evaluation of potential security weaknesses generated by static application security testing (SAST) tools. Numerous false positives (FPs) in these reports reduce the effectiveness of security analysis. We propose using Large Language Models (LLMs) to improve the assessment of SAST findings. We investigate the ability of LLMs to reduce FPs while trying to maintain a perfect true positive rate, using datasets extracted from the OWASP Benchmark (v1.2) and a real-world software project. Our results indicate that advanced prompting techniques, such as Chain-of-Thought and Self-Consistency, substantially improve FP detection. Notably, some LLMs identified approximately 62.5% of FPs in the OWASP Benchmark dataset without missing genuine weaknesses. Combining detections from different LLMs would increase this FP detection to approximately 78.9%. Additionally, we demonstrate our approach's generalizability using a real-world dataset covering five SAST tools, three programming languages, and infrastructure files. The best LLM detected 33.85% of all FPs without missing genuine weaknesses, while combining detections from different LLMs would increase this detection to 38.46%. Our findings highlight the potential of LLMs to complement traditional SAST tools, enhancing automation and reducing resources spent addressing false alarms.",
    "summary": "arXiv:2506.16899v1 Announce Type: cross Abstract: A key challenge in security analysis is the manual evaluation of potential security weaknesses generated by static application security testing (SAST) tools. Numerous false positives (FPs) in these reports reduce the effectiveness of security analysis. We propose using Large Language Models (LLMs) to improve the assessment of SAST findings. We investigate the ability of LLMs to reduce FPs while trying to maintain a perfect true positive rate, using datasets extracted from the OWASP Benchmark (v1.2) and a real-world software project. Our results indicate that advanced prompting techniques, such as Chain-of-Thought and Self-Consistency, substantially improve FP detection. Notably, some LLMs identified approximately 62.5% of FPs in the OWASP Benchmark dataset without missing genuine weaknesses. Combining detections from different LLMs would increase this FP detection to approximately 78.9%. Additionally, we demonstrate our approach's generalizability using a real-world dataset covering five SAST tools, three programming languages, and infrastructure files. The best LLM detected 33.85% of all FPs without missing genuine weaknesses, while combining detections from different LLMs would increase this detection to 38.46%. Our findings highlight the potential of LLMs to complement traditional SAST tools, enhancing automation and reducing resources spent addressing false alarms.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16899",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The International 2018: Results",
    "description": "OpenAI Five lost two games against top Dota 2 players at The International in Vancouver this week, maintaining a good chance of winning for the first 20‚Äì35 minutes of both¬†games.",
    "summary": "OpenAI Five lost two games against top Dota 2 players at The International in Vancouver this week, maintaining a good chance of winning for the first 20‚Äì35 minutes of both¬†games.",
    "pubDate": "Thu, 23 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-international-2018-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Stability of Primal-Dual Gradient Flow Dynamics for Multi-Block Convex Optimization Problems",
    "description": "arXiv:2408.15969v2 Announce Type: replace-cross Abstract: We examine stability properties of primal-dual gradient flow dynamics for composite convex optimization problems with multiple, possibly nonsmooth, terms in the objective function under the generalized consensus constraint. The proposed dynamics are based on the proximal augmented Lagrangian and they provide a viable alternative to ADMM which faces significant challenges from both analysis and implementation viewpoints in large-scale multi-block scenarios. In contrast to customized algorithms with individualized convergence guarantees, we develop a systematic approach for solving a broad class of challenging composite optimization problems. We leverage various structural properties to establish global (exponential) convergence guarantees for the proposed dynamics. Our assumptions are much weaker than those required to prove (exponential) stability of primal-dual dynamics as well as (linear) convergence of discrete-time methods such as standard two-block and multi-block ADMM and EXTRA algorithms. Finally, we show necessity of some of our structural assumptions for exponential stability and provide computational experiments to demonstrate the convenience of the proposed approach for parallel and distributed computing applications.",
    "summary": "arXiv:2408.15969v2 Announce Type: replace-cross Abstract: We examine stability properties of primal-dual gradient flow dynamics for composite convex optimization problems with multiple, possibly nonsmooth, terms in the objective function under the generalized consensus constraint. The proposed dynamics are based on the proximal augmented Lagrangian and they provide a viable alternative to ADMM which faces significant challenges from both analysis and implementation viewpoints in large-scale multi-block scenarios. In contrast to customized algorithms with individualized convergence guarantees, we develop a systematic approach for solving a broad class of challenging composite optimization problems. We leverage various structural properties to establish global (exponential) convergence guarantees for the proposed dynamics. Our assumptions are much weaker than those required to prove (exponential) stability of primal-dual dynamics as well as (linear) convergence of discrete-time methods such as standard two-block and multi-block ADMM and EXTRA algorithms. Finally, we show necessity of some of our structural assumptions for exponential stability and provide computational experiments to demonstrate the convenience of the proposed approach for parallel and distributed computing applications.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.15969",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome aMUSEd: Efficient Text-to-Image Generation",
    "description": "",
    "summary": "Welcome aMUSEd: Efficient Text-to-Image Generation We‚Äôre excited to present an efficient non-diffusi...",
    "pubDate": "Thu, 04 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/amused",
    "thumbnail": "https://huggingface.co/blog/assets/amused/thumbnail.png"
  },
  {
    "title": "A Dive into Pretraining Strategies for Vision-Language Models",
    "description": "",
    "summary": "A Dive into Vision-Language Models Human learning is inherently multi-modal as jointly leveraging mu...",
    "pubDate": "Fri, 03 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vision_language_pretraining",
    "thumbnail": "https://huggingface.co/blog//assets/128_vision_language_pretraining/thumbnail.png"
  },
  {
    "title": "Organizational update from OpenAI",
    "description": "It‚Äôs been a year of dramatic change and growth at OpenAI.",
    "summary": "It‚Äôs been a year of dramatic change and growth at OpenAI.",
    "pubDate": "Tue, 29 Dec 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/organizational-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Capturing Polysemanticity with PRISM: A Multi-Concept Feature Description Framework",
    "description": "arXiv:2506.15538v2 Announce Type: replace-cross Abstract: Automated interpretability research aims to identify concepts encoded in neural network features to enhance human understanding of model behavior. Current feature description methods face two critical challenges: limited robustness and the flawed assumption that each neuron encodes only a single concept (monosemanticity), despite growing evidence that neurons are often polysemantic. This assumption restricts the expressiveness of feature descriptions and limits their ability to capture the full range of behaviors encoded in model internals. To address this, we introduce Polysemantic FeatuRe Identification and Scoring Method (PRISM), a novel framework that captures the inherent complexity of neural network features. Unlike prior approaches that assign a single description per feature, PRISM provides more nuanced descriptions for both polysemantic and monosemantic features. We apply PRISM to language models and, through extensive benchmarking against existing methods, demonstrate that our approach produces more accurate and faithful feature descriptions, improving both overall description quality (via a description score) and the ability to capture distinct concepts when polysemanticity is present (via a polysemanticity score).",
    "summary": "arXiv:2506.15538v2 Announce Type: replace-cross Abstract: Automated interpretability research aims to identify concepts encoded in neural network features to enhance human understanding of model behavior. Current feature description methods face two critical challenges: limited robustness and the flawed assumption that each neuron encodes only a single concept (monosemanticity), despite growing evidence that neurons are often polysemantic. This assumption restricts the expressiveness of feature descriptions and limits their ability to capture the full range of behaviors encoded in model internals. To address this, we introduce Polysemantic FeatuRe Identification and Scoring Method (PRISM), a novel framework that captures the inherent complexity of neural network features. Unlike prior approaches that assign a single description per feature, PRISM provides more nuanced descriptions for both polysemantic and monosemantic features. We apply PRISM to language models and, through extensive benchmarking against existing methods, demonstrate that our approach produces more accurate and faithful feature descriptions, improving both overall description quality (via a description score) and the ability to capture distinct concepts when polysemanticity is present (via a polysemanticity score).",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15538",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Planning of Heuristics: Strategic Planning on Large Language Models with Monte Carlo Tree Search for Automating Heuristic Optimization",
    "description": "arXiv:2502.11422v3 Announce Type: replace Abstract: Heuristics have achieved great success in solving combinatorial optimization problems~(COPs). However, heuristics designed by humans require too much domain knowledge and testing time. Since Large Language Models~(LLMs) possess strong capabilities to understand and generate content with a knowledge base that covers various domains, they offer potential ways to automatically optimize heuristics. To this end, we propose Planning of Heuristics~(PoH), an optimization method that integrates LLM self-reflection with Monte Carlo Tree Search, a well-known planning algorithm. PoH iteratively refines generated heuristics by evaluating their performance and providing improvement suggestions. Our method enables to iteratively evaluate the generated heuristics~(states) and improve them based on the improvement suggestions~(actions) and evaluation results~(rewards), by effectively simulating future states to search for paths with higher rewards. In this paper, we apply PoH to solve the Traveling Salesman Problem and the Flow Shop Scheduling Problem. The experimental results show that PoH outperforms hand-crafted heuristics and other Automatic Heuristic Design methods based on LLMs, and achieves the state-of-the-art performance in automating heuristic optimization with LLMs to solve tested COPs, especially with large sizes.",
    "summary": "arXiv:2502.11422v3 Announce Type: replace Abstract: Heuristics have achieved great success in solving combinatorial optimization problems~(COPs). However, heuristics designed by humans require too much domain knowledge and testing time. Since Large Language Models~(LLMs) possess strong capabilities to understand and generate content with a knowledge base that covers various domains, they offer potential ways to automatically optimize heuristics. To this end, we propose Planning of Heuristics~(PoH), an optimization method that integrates LLM self-reflection with Monte Carlo Tree Search, a well-known planning algorithm. PoH iteratively refines generated heuristics by evaluating their performance and providing improvement suggestions. Our method enables to iteratively evaluate the generated heuristics~(states) and improve them based on the improvement suggestions~(actions) and evaluation results~(rewards), by effectively simulating future states to search for paths with higher rewards. In this paper, we apply PoH to solve the Traveling Salesman Problem and the Flow Shop Scheduling Problem. The experimental results show that PoH outperforms hand-crafted heuristics and other Automatic Heuristic Design methods based on LLMs, and achieves the state-of-the-art performance in automating heuristic optimization with LLMs to solve tested COPs, especially with large sizes.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.11422",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Expanding on how Voice Engine works and our safety research",
    "description": "Exploring the technology behind our text-to-speech model.",
    "summary": "Exploring the technology behind our text-to-speech model.",
    "pubDate": "Fri, 07 Jun 2024 17:45:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expanding-on-how-voice-engine-works-and-our-safety-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents",
    "description": "arXiv:2506.21582v1 Announce Type: cross Abstract: Text analytics has traditionally required specialized knowledge in Natural Language Processing (NLP) or text analysis, which presents a barrier for entry-level analysts. Recent advances in large language models (LLMs) have changed the landscape of NLP by enabling more accessible and automated text analysis (e.g., topic detection, summarization, information extraction, etc.). We introduce VIDEE, a system that supports entry-level data analysts to conduct advanced text analytics with intelligent agents. VIDEE instantiates a human-agent collaroration workflow consisting of three stages: (1) Decomposition, which incorporates a human-in-the-loop Monte-Carlo Tree Search algorithm to support generative reasoning with human feedback, (2) Execution, which generates an executable text analytics pipeline, and (3) Evaluation, which integrates LLM-based evaluation and visualizations to support user validation of execution results. We conduct two quantitative experiments to evaluate VIDEE's effectiveness and analyze common agent errors. A user study involving participants with varying levels of NLP and text analytics experience -- from none to expert -- demonstrates the system's usability and reveals distinct user behavior patterns. The findings identify design implications for human-agent collaboration, validate the practical utility of VIDEE for non-expert users, and inform future improvements to intelligent text analytics systems.",
    "summary": "arXiv:2506.21582v1 Announce Type: cross Abstract: Text analytics has traditionally required specialized knowledge in Natural Language Processing (NLP) or text analysis, which presents a barrier for entry-level analysts. Recent advances in large language models (LLMs) have changed the landscape of NLP by enabling more accessible and automated text analysis (e.g., topic detection, summarization, information extraction, etc.). We introduce VIDEE, a system that supports entry-level data analysts to conduct advanced text analytics with intelligent agents. VIDEE instantiates a human-agent collaroration workflow consisting of three stages: (1) Decomposition, which incorporates a human-in-the-loop Monte-Carlo Tree Search algorithm to support generative reasoning with human feedback, (2) Execution, which generates an executable text analytics pipeline, and (3) Evaluation, which integrates LLM-based evaluation and visualizations to support user validation of execution results. We conduct two quantitative experiments to evaluate VIDEE's effectiveness and analyze common agent errors. A user study involving participants with varying levels of NLP and text analytics experience -- from none to expert -- demonstrates the system's usability and reveals distinct user behavior patterns. The findings identify design implications for human-agent collaboration, validate the practical utility of VIDEE for non-expert users, and inform future improvements to intelligent text analytics systems.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21582",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Explainable Rule Application via Structured Prompting: A Neural-Symbolic Approach",
    "description": "arXiv:2506.16335v1 Announce Type: new Abstract: Large Language Models (LLMs) excel in complex reasoning tasks but struggle with consistent rule application, exception handling, and explainability, particularly in domains like legal analysis that require both natural language understanding and precise logical inference. This paper introduces a structured prompting framework that decomposes reasoning into three verifiable steps: entity identification, property extraction, and symbolic rule application. By integrating neural and symbolic approaches, our method leverages LLMs' interpretive flexibility while ensuring logical consistency through formal verification. The framework externalizes task definitions, enabling domain experts to refine logical structures without altering the architecture. Evaluated on the LegalBench hearsay determination task, our approach significantly outperformed baselines, with OpenAI o-family models showing substantial improvements - o1 achieving an F1 score of 0.929 and o3-mini reaching 0.867 using structured decomposition with complementary predicates, compared to their few-shot baselines of 0.714 and 0.74 respectively. This hybrid neural-symbolic system offers a promising pathway for transparent and consistent rule-based reasoning, suggesting potential for explainable AI applications in structured legal reasoning tasks.",
    "summary": "arXiv:2506.16335v1 Announce Type: new Abstract: Large Language Models (LLMs) excel in complex reasoning tasks but struggle with consistent rule application, exception handling, and explainability, particularly in domains like legal analysis that require both natural language understanding and precise logical inference. This paper introduces a structured prompting framework that decomposes reasoning into three verifiable steps: entity identification, property extraction, and symbolic rule application. By integrating neural and symbolic approaches, our method leverages LLMs' interpretive flexibility while ensuring logical consistency through formal verification. The framework externalizes task definitions, enabling domain experts to refine logical structures without altering the architecture. Evaluated on the LegalBench hearsay determination task, our approach significantly outperformed baselines, with OpenAI o-family models showing substantial improvements - o1 achieving an F1 score of 0.929 and o3-mini reaching 0.867 using structured decomposition with complementary predicates, compared to their few-shot baselines of 0.714 and 0.74 respectively. This hybrid neural-symbolic system offers a promising pathway for transparent and consistent rule-based reasoning, suggesting potential for explainable AI applications in structured legal reasoning tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16335",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DeepMind‚Äôs latest research at NeurIPS 2022",
    "description": "NeurIPS is the world‚Äôs largest conference in artificial intelligence (AI) and machine learning (ML), and we‚Äôre proud to support the event as Diamond sponsors, helping foster the exchange of research advances in the AI and ML community. Teams from across DeepMind are presenting 47 papers, including 35 external collaborations in virtual panels and poster sessions.",
    "summary": "NeurIPS is the world‚Äôs largest conference in artificial intelligence (AI) and machine learning (ML), and we‚Äôre proud to support the event as Diamond sponsors, helping foster the exchange of research advances in the AI and ML community. Teams from across DeepMind are presenting 47 papers, including 35 external collaborations in virtual panels and poster sessions.",
    "pubDate": "Fri, 25 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/deepminds-latest-research-at-neurips-2022/",
    "thumbnail": "https://lh3.googleusercontent.com/MFZKdGWHOzJ6nM8NufhIfpts0R-v9D4jQqnC416FT8ArwmNC2Ztke2S50WVtUhO0g1u8AGmYEyWMDC7LO0a16ydHBMei9GmJO4NjykhpLKw1TVtd4Mg=w1200-h630-n-nu"
  },
  {
    "title": "Learning Day",
    "description": "At OpenAI, each Thursday is Learning Day: a day where employees have the option to self-study technical skills that will make them better at their job but which aren‚Äôt being learned from daily work.",
    "summary": "At OpenAI, each Thursday is Learning Day: a day where employees have the option to self-study technical skills that will make them better at their job but which aren‚Äôt being learned from daily work.",
    "pubDate": "Thu, 01 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-day",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SLR: An Automated Synthesis Framework for Scalable Logical Reasoning",
    "description": "arXiv:2506.15787v1 Announce Type: new Abstract: We introduce SLR, an end-to-end framework for systematic evaluation and training of Large Language Models (LLMs) via Scalable Logical Reasoning. Given a user's task specification, SLR enables scalable, automated synthesis of inductive reasoning tasks with precisely controlled difficulty. For each task, SLR synthesizes (i) a latent ground-truth rule, (ii) an executable validation program used by a symbolic judge to deterministically verify model outputs, and (iii) an instruction prompt for the reasoning task. Using SLR, we create SLR-Bench, a benchmark comprising over 19k prompts spanning 20 curriculum levels that progressively increase in relational, arithmetic, and recursive complexity. Large-scale evaluation reveals that contemporary LLMs readily produce syntactically valid rules, yet often fail at correct logical inference. Recent reasoning LLMs do somewhat better, but incur substantial increases in test-time compute, sometimes exceeding 15k completion tokens. Finally, logic-tuning via SLR doubles Llama-3-8B accuracy on SLR-Bench, achieving parity with Gemini-Flash-Thinking at a fraction of computational cost. SLR is fully automated, requires no human annotation, ensures dataset novelty, and offers a scalable environment for probing and advancing LLMs' reasoning capabilities.",
    "summary": "arXiv:2506.15787v1 Announce Type: new Abstract: We introduce SLR, an end-to-end framework for systematic evaluation and training of Large Language Models (LLMs) via Scalable Logical Reasoning. Given a user's task specification, SLR enables scalable, automated synthesis of inductive reasoning tasks with precisely controlled difficulty. For each task, SLR synthesizes (i) a latent ground-truth rule, (ii) an executable validation program used by a symbolic judge to deterministically verify model outputs, and (iii) an instruction prompt for the reasoning task. Using SLR, we create SLR-Bench, a benchmark comprising over 19k prompts spanning 20 curriculum levels that progressively increase in relational, arithmetic, and recursive complexity. Large-scale evaluation reveals that contemporary LLMs readily produce syntactically valid rules, yet often fail at correct logical inference. Recent reasoning LLMs do somewhat better, but incur substantial increases in test-time compute, sometimes exceeding 15k completion tokens. Finally, logic-tuning via SLR doubles Llama-3-8B accuracy on SLR-Bench, achieving parity with Gemini-Flash-Thinking at a fraction of computational cost. SLR is fully automated, requires no human annotation, ensures dataset novelty, and offers a scalable environment for probing and advancing LLMs' reasoning capabilities.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15787",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Minne Atairu & Sora",
    "description": "Interdisciplinary artist Minne Atairu discusses how Sora helps realize her vision.",
    "summary": "Interdisciplinary artist Minne Atairu discusses how Sora helps realize her vision.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-minne-atairu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI Japan",
    "description": "We are excited to announce our first office in Asia and we‚Äôre releasing a GPT-4 custom model optimized for the Japanese language.",
    "summary": "We are excited to announce our first office in Asia and we‚Äôre releasing a GPT-4 custom model optimized for the Japanese language.",
    "pubDate": "Sun, 14 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-japan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemma: Introducing new state-of-the-art open models",
    "description": "Gemma is built for responsible AI development from the same research and technology used to create Gemini models.",
    "summary": "Gemma is built for responsible AI development from the same research and technology used to create Gemini models.",
    "pubDate": "Wed, 21 Feb 2024 13:06:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemma-introducing-new-state-of-the-art-open-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemma-social-share.width-1300.jpg"
  },
  {
    "title": "OpenAI Fellows Summer 2018: Final projects",
    "description": "Our first cohort of OpenAI Fellows has concluded, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship.",
    "summary": "Our first cohort of OpenAI Fellows has concluded, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship.",
    "pubDate": "Wed, 19 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-summer-fellows-2018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TriCon-SF: A Triple-Shuffle and Contribution-Aware Serial Federated Learning Framework for Heterogeneous Healthcare Data",
    "description": "arXiv:2506.16723v1 Announce Type: cross Abstract: Serial pipeline training is an efficient paradigm for handling data heterogeneity in cross-silo federated learning with low communication overhead. However, even without centralized aggregation, direct transfer of models between clients can violate privacy regulations and remain susceptible to gradient leakage and linkage attacks. Additionally, ensuring resilience against semi-honest or malicious clients who may manipulate or misuse received models remains a grand challenge, particularly in privacy-sensitive domains such as healthcare. To address these challenges, we propose TriCon-SF, a novel serial federated learning framework that integrates triple shuffling and contribution awareness. TriCon-SF introduces three levels of randomization by shuffling model layers, data segments, and training sequences to break deterministic learning patterns and disrupt potential attack vectors, thereby enhancing privacy and robustness. In parallel, it leverages Shapley value methods to dynamically evaluate client contributions during training, enabling the detection of dishonest behavior and enhancing system accountability. Extensive experiments on non-IID healthcare datasets demonstrate that TriCon-SF outperforms standard serial and parallel federated learning in both accuracy and communication efficiency. Security analysis further supports its resilience against client-side privacy attacks.",
    "summary": "arXiv:2506.16723v1 Announce Type: cross Abstract: Serial pipeline training is an efficient paradigm for handling data heterogeneity in cross-silo federated learning with low communication overhead. However, even without centralized aggregation, direct transfer of models between clients can violate privacy regulations and remain susceptible to gradient leakage and linkage attacks. Additionally, ensuring resilience against semi-honest or malicious clients who may manipulate or misuse received models remains a grand challenge, particularly in privacy-sensitive domains such as healthcare. To address these challenges, we propose TriCon-SF, a novel serial federated learning framework that integrates triple shuffling and contribution awareness. TriCon-SF introduces three levels of randomization by shuffling model layers, data segments, and training sequences to break deterministic learning patterns and disrupt potential attack vectors, thereby enhancing privacy and robustness. In parallel, it leverages Shapley value methods to dynamically evaluate client contributions during training, enabling the detection of dishonest behavior and enhancing system accountability. Extensive experiments on non-IID healthcare datasets demonstrate that TriCon-SF outperforms standard serial and parallel federated learning in both accuracy and communication efficiency. Security analysis further supports its resilience against client-side privacy attacks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16723",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Bringing intelligence to every workflow",
    "description": "Notion is a connected workspace where teams write, plan, and organize everything from meeting notes to product roadmaps. Today, it‚Äôs also a deeply AI-powered platform, used by millions to summarize content, generate writing, and ask questions in natural language across their entire workspace.",
    "summary": "Notion is a connected workspace where teams write, plan, and organize everything from meeting notes to product roadmaps. Today, it‚Äôs also a deeply AI-powered platform, used by millions to summarize content, generate writing, and ask questions in natural language across their entire workspace.",
    "pubDate": "Thu, 03 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/notion",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making automatic speech recognition work on large files with Wav2Vec2 in ü§ó Transformers",
    "description": "",
    "summary": "Making automatic speech recognition work on large files with Wav2Vec2 in ü§ó Transformers Tl;dr: This ...",
    "pubDate": "Tue, 01 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/asr-chunking",
    "thumbnail": "https://huggingface.co/blog/assets/49_asr_chunking/thumbnail.png"
  },
  {
    "title": "The Annotated Diffusion Model",
    "description": "",
    "summary": "The Annotated Diffusion Model In this blog post, we'll take a deeper look into Denoising Diffusion P...",
    "pubDate": "Tue, 07 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/annotated-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/78_annotated-diffusion/thumbnail.png"
  },
  {
    "title": "CinePile 2.0 - making stronger datasets with adversarial refinement",
    "description": "",
    "summary": "CinePile 2.0 - making stronger datasets with adversarial refinement In this blog post we share the j...",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cinepile2",
    "thumbnail": "https://huggingface.co/blog/assets/188_cinepile2/thumbnail.png"
  },
  {
    "title": "Synthetic ALS-EEG Data Augmentation for ALS Diagnosis Using Conditional WGAN with Weight Clipping",
    "description": "arXiv:2506.16243v1 Announce Type: cross Abstract: Amyotrophic Lateral Sclerosis (ALS) is a rare neurodegenerative disease, and high-quality EEG data from ALS patients are scarce. This data scarcity, coupled with severe class imbalance between ALS and healthy control recordings, poses a challenge for training reliable machine learning classifiers. In this work, we address these issues by generating synthetic EEG signals for ALS patients using a Conditional Wasserstein Generative Adversarial Network (CWGAN). We train CWGAN on a private EEG dataset (ALS vs. non-ALS) to learn the distribution of ALS EEG signals and produce realistic synthetic samples. We preprocess and normalize EEG recordings, and train a CWGAN model to generate synthetic ALS signals. The CWGAN architecture and training routine are detailed, with key hyperparameters chosen for stable training. Qualitative evaluation of generated signals shows that they closely mimic real ALS EEG patterns. The CWGAN training converged with generator and discriminator loss curves stabilizing, indicating successful learning. The synthetic EEG signals appear realistic and have potential use as augmented data for training classifiers, helping to mitigate class imbalance and improve ALS detection accuracy. We discuss how this approach can facilitate data sharing and enhance diagnostic models.",
    "summary": "arXiv:2506.16243v1 Announce Type: cross Abstract: Amyotrophic Lateral Sclerosis (ALS) is a rare neurodegenerative disease, and high-quality EEG data from ALS patients are scarce. This data scarcity, coupled with severe class imbalance between ALS and healthy control recordings, poses a challenge for training reliable machine learning classifiers. In this work, we address these issues by generating synthetic EEG signals for ALS patients using a Conditional Wasserstein Generative Adversarial Network (CWGAN). We train CWGAN on a private EEG dataset (ALS vs. non-ALS) to learn the distribution of ALS EEG signals and produce realistic synthetic samples. We preprocess and normalize EEG recordings, and train a CWGAN model to generate synthetic ALS signals. The CWGAN architecture and training routine are detailed, with key hyperparameters chosen for stable training. Qualitative evaluation of generated signals shows that they closely mimic real ALS EEG patterns. The CWGAN training converged with generator and discriminator loss curves stabilizing, indicating successful learning. The synthetic EEG signals appear realistic and have potential use as augmented data for training classifiers, helping to mitigate class imbalance and improve ALS detection accuracy. We discuss how this approach can facilitate data sharing and enhance diagnostic models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16243",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Getting Started with Sentiment Analysis on Twitter",
    "description": "",
    "summary": "Getting Started with Sentiment Analysis on Twitter Sentiment analysis is the automatic process of cl...",
    "pubDate": "Thu, 07 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-twitter",
    "thumbnail": "https://huggingface.co/blog/assets/85_sentiment_analysis_twitter/thumbnail.png"
  },
  {
    "title": "AI Model Passport: Data and System Traceability Framework for Transparent AI in Health",
    "description": "arXiv:2506.22358v1 Announce Type: new Abstract: The increasing integration of Artificial Intelligence (AI) into health and biomedical systems necessitates robust frameworks for transparency, accountability, and ethical compliance. Existing frameworks often rely on human-readable, manual documentation which limits scalability, comparability, and machine interpretability across projects and platforms. They also fail to provide a unique, verifiable identity for AI models to ensure their provenance and authenticity across systems and use cases, limiting reproducibility and stakeholder trust. This paper introduces the concept of the AI Model Passport, a structured and standardized documentation framework that acts as a digital identity and verification tool for AI models. It captures essential metadata to uniquely identify, verify, trace and monitor AI models across their lifecycle - from data acquisition and preprocessing to model design, development and deployment. In addition, an implementation of this framework is presented through AIPassport, an MLOps tool developed within the ProCAncer-I EU project for medical imaging applications. AIPassport automates metadata collection, ensures proper versioning, decouples results from source scripts, and integrates with various development environments. Its effectiveness is showcased through a lesion segmentation use case using data from the ProCAncer-I dataset, illustrating how the AI Model Passport enhances transparency, reproducibility, and regulatory readiness while reducing manual effort. This approach aims to set a new standard for fostering trust and accountability in AI-driven healthcare solutions, aspiring to serve as the basis for developing transparent and regulation compliant AI systems across domains.",
    "summary": "arXiv:2506.22358v1 Announce Type: new Abstract: The increasing integration of Artificial Intelligence (AI) into health and biomedical systems necessitates robust frameworks for transparency, accountability, and ethical compliance. Existing frameworks often rely on human-readable, manual documentation which limits scalability, comparability, and machine interpretability across projects and platforms. They also fail to provide a unique, verifiable identity for AI models to ensure their provenance and authenticity across systems and use cases, limiting reproducibility and stakeholder trust. This paper introduces the concept of the AI Model Passport, a structured and standardized documentation framework that acts as a digital identity and verification tool for AI models. It captures essential metadata to uniquely identify, verify, trace and monitor AI models across their lifecycle - from data acquisition and preprocessing to model design, development and deployment. In addition, an implementation of this framework is presented through AIPassport, an MLOps tool developed within the ProCAncer-I EU project for medical imaging applications. AIPassport automates metadata collection, ensures proper versioning, decouples results from source scripts, and integrates with various development environments. Its effectiveness is showcased through a lesion segmentation use case using data from the ProCAncer-I dataset, illustrating how the AI Model Passport enhances transparency, reproducibility, and regulatory readiness while reducing manual effort. This approach aims to set a new standard for fostering trust and accountability in AI-driven healthcare solutions, aspiring to serve as the basis for developing transparent and regulation compliant AI systems across domains.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22358",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Releasing Swift Transformers: Run On-Device LLMs in Apple Devices",
    "description": "",
    "summary": "Releasing Swift Transformers: Run On-Device LLMs in Apple Devices I have a lot of respect for iOS/Ma...",
    "pubDate": "Tue, 08 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/swift-coreml-llm",
    "thumbnail": "https://huggingface.co/blog/assets/swift-coreml-llm/thumbnail.png"
  },
  {
    "title": "Disrupting a covert Iranian influence operation",
    "description": "We banned accounts linked to a covert Iranian influence operation using ChatGPT to generate website and social media content focused on multiple topics, including the U.S. presidential campaign. We have seen no indication that this content reached a meaningful audience.",
    "summary": "We banned accounts linked to a covert Iranian influence operation using ChatGPT to generate website and social media content focused on multiple topics, including the U.S. presidential campaign. We have seen no indication that this content reached a meaningful audience.",
    "pubDate": "Fri, 16 Aug 2024 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-a-covert-iranian-influence-operation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How NuminaMath Won the 1st AIMO Progress Prize",
    "description": "",
    "summary": "How NuminaMath Won the 1st AIMO Progress Prize This year, Numina and Hugging Face collaborated to co...",
    "pubDate": "Thu, 11 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/winning-aimo-progress-prize",
    "thumbnail": "https://huggingface.co/blog/assets/winning-aimo-progress-prize/thumbnail.png"
  },
  {
    "title": "Putting AI to work at Upwork",
    "description": "Upwork puts AI to work, uniting team members, operations and product development",
    "summary": "Upwork puts AI to work, uniting team members, operations and product development",
    "pubDate": "Tue, 20 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/upwork",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Transformers are Graph Neural Networks",
    "description": "arXiv:2506.22084v1 Announce Type: cross Abstract: We establish connections between the Transformer architecture, originally introduced for natural language processing, and Graph Neural Networks (GNNs) for representation learning on graphs. We show how Transformers can be viewed as message passing GNNs operating on fully connected graphs of tokens, where the self-attention mechanism capture the relative importance of all tokens w.r.t. each-other, and positional encodings provide hints about sequential ordering or structure. Thus, Transformers are expressive set processing networks that learn relationships among input elements without being constrained by apriori graphs. Despite this mathematical connection to GNNs, Transformers are implemented via dense matrix operations that are significantly more efficient on modern hardware than sparse message passing. This leads to the perspective that Transformers are GNNs currently winning the hardware lottery.",
    "summary": "arXiv:2506.22084v1 Announce Type: cross Abstract: We establish connections between the Transformer architecture, originally introduced for natural language processing, and Graph Neural Networks (GNNs) for representation learning on graphs. We show how Transformers can be viewed as message passing GNNs operating on fully connected graphs of tokens, where the self-attention mechanism capture the relative importance of all tokens w.r.t. each-other, and positional encodings provide hints about sequential ordering or structure. Thus, Transformers are expressive set processing networks that learn relationships among input elements without being constrained by apriori graphs. Despite this mathematical connection to GNNs, Transformers are implemented via dense matrix operations that are significantly more efficient on modern hardware than sparse message passing. This leads to the perspective that Transformers are GNNs currently winning the hardware lottery.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22084",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Large Language Models are Near-Optimal Decision-Makers with a Non-Human Learning Behavior",
    "description": "arXiv:2506.16163v1 Announce Type: new Abstract: Human decision-making belongs to the foundation of our society and civilization, but we are on the verge of a future where much of it will be delegated to artificial intelligence. The arrival of Large Language Models (LLMs) has transformed the nature and scope of AI-supported decision-making; however, the process by which they learn to make decisions, compared to humans, remains poorly understood. In this study, we examined the decision-making behavior of five leading LLMs across three core dimensions of real-world decision-making: uncertainty, risk, and set-shifting. Using three well-established experimental psychology tasks designed to probe these dimensions, we benchmarked LLMs against 360 newly recruited human participants. Across all tasks, LLMs often outperformed humans, approaching near-optimal performance. Moreover, the processes underlying their decisions diverged fundamentally from those of humans. On the one hand, our finding demonstrates the ability of LLMs to manage uncertainty, calibrate risk, and adapt to changes. On the other hand, this disparity highlights the risks of relying on them as substitutes for human judgment, calling for further inquiry.",
    "summary": "arXiv:2506.16163v1 Announce Type: new Abstract: Human decision-making belongs to the foundation of our society and civilization, but we are on the verge of a future where much of it will be delegated to artificial intelligence. The arrival of Large Language Models (LLMs) has transformed the nature and scope of AI-supported decision-making; however, the process by which they learn to make decisions, compared to humans, remains poorly understood. In this study, we examined the decision-making behavior of five leading LLMs across three core dimensions of real-world decision-making: uncertainty, risk, and set-shifting. Using three well-established experimental psychology tasks designed to probe these dimensions, we benchmarked LLMs against 360 newly recruited human participants. Across all tasks, LLMs often outperformed humans, approaching near-optimal performance. Moreover, the processes underlying their decisions diverged fundamentally from those of humans. On the one hand, our finding demonstrates the ability of LLMs to manage uncertainty, calibrate risk, and adapt to changes. On the other hand, this disparity highlights the risks of relying on them as substitutes for human judgment, calling for further inquiry.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16163",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Our next-generation model: Gemini 1.5",
    "description": "The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities.",
    "summary": "The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities.",
    "pubDate": "Thu, 15 Feb 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/our-next-generation-model-gemini-15/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/final_gemini_1.5_blog_social_share_800x418.width-1300.png"
  },
  {
    "title": "Comment on NTIA AI Accountability Policy",
    "description": "The National Telecommunications and Information Administration (NTIA) request for comments on AI Accountability policy.",
    "summary": "The National Telecommunications and Information Administration (NTIA) request for comments on AI Accountability policy.",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/comment-on-ntia-ai-accountability-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GeoGuess: Multimodal Reasoning based on Hierarchy of Visual Information in Street View",
    "description": "arXiv:2506.16633v1 Announce Type: cross Abstract: Multimodal reasoning is a process of understanding, integrating and inferring information across different data modalities. It has recently attracted surging academic attention as a benchmark for Artificial Intelligence (AI). Although there are various tasks for evaluating multimodal reasoning ability, they still have limitations. Lack of reasoning on hierarchical visual clues at different levels of granularity, e.g., local details and global context, is of little discussion, despite its frequent involvement in real scenarios. To bridge the gap, we introduce a novel and challenging task for multimodal reasoning, namely GeoGuess. Given a street view image, the task is to identify its location and provide a detailed explanation. A system that succeeds in GeoGuess should be able to detect tiny visual clues, perceive the broader landscape, and associate with vast geographic knowledge. Therefore, GeoGuess would require the ability to reason between hierarchical visual information and geographic knowledge. In this work, we establish a benchmark for GeoGuess by introducing a specially curated dataset GeoExplain which consists of panoramas-geocoordinates-explanation tuples. Additionally, we present a multimodal and multilevel reasoning method, namely SightSense which can make prediction and generate comprehensive explanation based on hierarchy of visual information and external knowledge. Our analysis and experiments demonstrate their outstanding performance in GeoGuess.",
    "summary": "arXiv:2506.16633v1 Announce Type: cross Abstract: Multimodal reasoning is a process of understanding, integrating and inferring information across different data modalities. It has recently attracted surging academic attention as a benchmark for Artificial Intelligence (AI). Although there are various tasks for evaluating multimodal reasoning ability, they still have limitations. Lack of reasoning on hierarchical visual clues at different levels of granularity, e.g., local details and global context, is of little discussion, despite its frequent involvement in real scenarios. To bridge the gap, we introduce a novel and challenging task for multimodal reasoning, namely GeoGuess. Given a street view image, the task is to identify its location and provide a detailed explanation. A system that succeeds in GeoGuess should be able to detect tiny visual clues, perceive the broader landscape, and associate with vast geographic knowledge. Therefore, GeoGuess would require the ability to reason between hierarchical visual information and geographic knowledge. In this work, we establish a benchmark for GeoGuess by introducing a specially curated dataset GeoExplain which consists of panoramas-geocoordinates-explanation tuples. Additionally, we present a multimodal and multilevel reasoning method, namely SightSense which can make prediction and generate comprehensive explanation based on hierarchy of visual information and external knowledge. Our analysis and experiments demonstrate their outstanding performance in GeoGuess.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16633",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NeuronSeek: On Stability and Expressivity of Task-driven Neurons",
    "description": "arXiv:2506.15715v1 Announce Type: cross Abstract: Drawing inspiration from our human brain that designs different neurons for different tasks, recent advances in deep learning have explored modifying a network's neurons to develop so-called task-driven neurons. Prototyping task-driven neurons (referred to as NeuronSeek) employs symbolic regression (SR) to discover the optimal neuron formulation and construct a network from these optimized neurons. Along this direction, this work replaces symbolic regression with tensor decomposition (TD) to discover optimal neuronal formulations, offering enhanced stability and faster convergence. Furthermore, we establish theoretical guarantees that modifying the aggregation functions with common activation functions can empower a network with a fixed number of parameters to approximate any continuous function with an arbitrarily small error, providing a rigorous mathematical foundation for the NeuronSeek framework. Extensive empirical evaluations demonstrate that our NeuronSeek-TD framework not only achieves superior stability, but also is competitive relative to the state-of-the-art models across diverse benchmarks. The code is available at https://github.com/HanyuPei22/NeuronSeek.",
    "summary": "arXiv:2506.15715v1 Announce Type: cross Abstract: Drawing inspiration from our human brain that designs different neurons for different tasks, recent advances in deep learning have explored modifying a network's neurons to develop so-called task-driven neurons. Prototyping task-driven neurons (referred to as NeuronSeek) employs symbolic regression (SR) to discover the optimal neuron formulation and construct a network from these optimized neurons. Along this direction, this work replaces symbolic regression with tensor decomposition (TD) to discover optimal neuronal formulations, offering enhanced stability and faster convergence. Furthermore, we establish theoretical guarantees that modifying the aggregation functions with common activation functions can empower a network with a fixed number of parameters to approximate any continuous function with an arbitrarily small error, providing a rigorous mathematical foundation for the NeuronSeek framework. Extensive empirical evaluations demonstrate that our NeuronSeek-TD framework not only achieves superior stability, but also is competitive relative to the state-of-the-art models across diverse benchmarks. The code is available at https://github.com/HanyuPei22/NeuronSeek.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15715",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Optimum-NVIDIA - Unlock blazingly fast LLM inference in just 1 line of code",
    "description": "",
    "summary": "Optimum-NVIDIA on Hugging Face enables blazingly fast LLM inference in just 1 line of code Large Lan...",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-nvidia",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_nvidia/hf_nvidia_banner.png"
  },
  {
    "title": "Awakening Sleeping Beauties at The Met",
    "description": "AI can enrich lives through beauty and creativity, and its artistic potential shines in 'Sleeping Beauties: Reawakening Fashion,' a collaborative exhibit from The Met's Costume Institute.",
    "summary": "AI can enrich lives through beauty and creativity, and its artistic potential shines in 'Sleeping Beauties: Reawakening Fashion,' a collaborative exhibit from The Met's Costume Institute.",
    "pubDate": "Wed, 14 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-met-museum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeMaterial: an open source initiative to accelerate materials discovery and research",
    "description": "",
    "summary": "LeMaterial: an open source initiative to accelerate materials discovery and research Today, we are t...",
    "pubDate": "Tue, 10 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lematerial",
    "thumbnail": "https://huggingface.co/blog/assets/lematerial/thumbnail_lematerial.png"
  },
  {
    "title": "SmolVLA: Efficient Vision-Language-Action Model trained on Lerobot Community Data",
    "description": "",
    "summary": "SmolVLA: Efficient Vision-Language-Action Model trained on Lerobot Community Data üß≠TL;DR Today, we i...",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvla",
    "thumbnail": "https://huggingface.co/blog/assets/smolvla/SmolVLA_thumbnail.png"
  },
  {
    "title": "Incivility and Rigidity: The Risks of Fine-Tuning LLMs for Political Argumentation",
    "description": "arXiv:2411.16813v3 Announce Type: replace-cross Abstract: The incivility prevalent on platforms like Twitter (now X) and Reddit poses a challenge for developing AI systems that can support productive and rhetorically sound political argumentation. In this study, we report experiments with GPT-3.5 Turbo, fine-tuned on two contrasting datasets of political discussions: high-variance, high-incivility Twitter replies to U.S. Congress, and low-variance, low-incivility posts from Reddit's r/ChangeMyView. We systematically evaluate how these data sources and prompting strategies shape the rhetorical framing and deliberative quality of model-generated arguments. Our results show that Reddit-finetuned models produce safer but rhetorically rigid arguments, while cross-platform fine-tuning amplifies toxicity. Prompting reduces specific toxic behaviors, such as personal attacks, but fails to fully mitigate the influence of high-incivility training data. We introduce and validate a rhetorical evaluation rubric and provide practical guidelines for deploying LLMs in content authoring, moderation, and deliberation support.",
    "summary": "arXiv:2411.16813v3 Announce Type: replace-cross Abstract: The incivility prevalent on platforms like Twitter (now X) and Reddit poses a challenge for developing AI systems that can support productive and rhetorically sound political argumentation. In this study, we report experiments with GPT-3.5 Turbo, fine-tuned on two contrasting datasets of political discussions: high-variance, high-incivility Twitter replies to U.S. Congress, and low-variance, low-incivility posts from Reddit's r/ChangeMyView. We systematically evaluate how these data sources and prompting strategies shape the rhetorical framing and deliberative quality of model-generated arguments. Our results show that Reddit-finetuned models produce safer but rhetorically rigid arguments, while cross-platform fine-tuning amplifies toxicity. Prompting reduces specific toxic behaviors, such as personal attacks, but fails to fully mitigate the influence of high-incivility training data. We introduce and validate a rhetorical evaluation rubric and provide practical guidelines for deploying LLMs in content authoring, moderation, and deliberation support.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.16813",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Spinning Up in Deep RL: Workshop review",
    "description": "On February 2, we held our first Spinning Up Workshop as part of our new education initiative at OpenAI.",
    "summary": "On February 2, we held our first Spinning Up Workshop as part of our new education initiative at OpenAI.",
    "pubDate": "Tue, 26 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spinning-up-in-deep-rl-workshop-review",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Empirical Evidence for Alignment Faking in Small LLMs and Prompt-Based Mitigation Techniques",
    "description": "arXiv:2506.21584v1 Announce Type: cross Abstract: Current literature suggests that alignment faking (deceptive alignment) is an emergent property of large language models. We present the first empirical evidence that a small instruction-tuned model, specifically LLaMA 3 8B, can also exhibit alignment faking. We further show that prompt-only interventions, including deontological moral framing and scratchpad reasoning, significantly reduce this behavior without modifying model internals. This challenges the assumption that prompt-based ethics are trivial and that deceptive alignment requires scale. We introduce a taxonomy distinguishing shallow deception, shaped by context and suppressible through prompting, from deep deception, which reflects persistent, goal-driven misalignment. Our findings refine the understanding of deception in language models and underscore the need for alignment evaluations across model sizes and deployment settings.",
    "summary": "arXiv:2506.21584v1 Announce Type: cross Abstract: Current literature suggests that alignment faking (deceptive alignment) is an emergent property of large language models. We present the first empirical evidence that a small instruction-tuned model, specifically LLaMA 3 8B, can also exhibit alignment faking. We further show that prompt-only interventions, including deontological moral framing and scratchpad reasoning, significantly reduce this behavior without modifying model internals. This challenges the assumption that prompt-based ethics are trivial and that deceptive alignment requires scale. We introduce a taxonomy distinguishing shallow deception, shaped by context and suppressible through prompting, from deep deception, which reflects persistent, goal-driven misalignment. Our findings refine the understanding of deception in language models and underscore the need for alignment evaluations across model sizes and deployment settings.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21584",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome Mixtral - a SOTA Mixture of Experts on Hugging Face",
    "description": "",
    "summary": "Welcome Mixtral - a SOTA Mixture of Experts on Hugging Face Mixtral 8x7b is an exciting large langua...",
    "pubDate": "Mon, 11 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mixtral",
    "thumbnail": "https://huggingface.co/blog/assets/mixtral/thumbnail.jpg"
  },
  {
    "title": "Deprecation of Git Authentication using password",
    "description": "",
    "summary": "Hugging Face Hub: Important Git Authentication Changes Because we are committed to improving the sec...",
    "pubDate": "Fri, 25 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/password-git-deprecation",
    "thumbnail": "https://huggingface.co/blog/assets/password-git-deprecation/thumbnail.png"
  },
  {
    "title": "CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation",
    "description": "arXiv:2506.21805v1 Announce Type: new Abstract: Modeling human behavior in urban environments is fundamental for social science, behavioral studies, and urban planning. Prior work often rely on rigid, hand-crafted rules, limiting their ability to simulate nuanced intentions, plans, and adaptive behaviors. Addressing these challenges, we envision an urban simulator (CitySim), capitalizing on breakthroughs in human-level intelligence exhibited by large language models. In CitySim, agents generate realistic daily schedules using a recursive value-driven approach that balances mandatory activities, personal habits, and situational factors. To enable long-term, lifelike simulations, we endow agents with beliefs, long-term goals, and spatial memory for navigation. CitySim exhibits closer alignment with real humans than prior work, both at micro and macro levels. Additionally, we conduct insightful experiments by modeling tens of thousands of agents and evaluating their collective behaviors under various real-world scenarios, including estimating crowd density, predicting place popularity, and assessing well-being. Our results highlight CitySim as a scalable, flexible testbed for understanding and forecasting urban phenomena.",
    "summary": "arXiv:2506.21805v1 Announce Type: new Abstract: Modeling human behavior in urban environments is fundamental for social science, behavioral studies, and urban planning. Prior work often rely on rigid, hand-crafted rules, limiting their ability to simulate nuanced intentions, plans, and adaptive behaviors. Addressing these challenges, we envision an urban simulator (CitySim), capitalizing on breakthroughs in human-level intelligence exhibited by large language models. In CitySim, agents generate realistic daily schedules using a recursive value-driven approach that balances mandatory activities, personal habits, and situational factors. To enable long-term, lifelike simulations, we endow agents with beliefs, long-term goals, and spatial memory for navigation. CitySim exhibits closer alignment with real humans than prior work, both at micro and macro levels. Additionally, we conduct insightful experiments by modeling tens of thousands of agents and evaluating their collective behaviors under various real-world scenarios, including estimating crowd density, predicting place popularity, and assessing well-being. Our results highlight CitySim as a scalable, flexible testbed for understanding and forecasting urban phenomena.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21805",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improving language model behavior by training on a curated dataset",
    "description": "Our latest research finds we can improve language model behavior with respect to specific behavioral values by fine-tuning on a small, curated¬†dataset.",
    "summary": "Our latest research finds we can improve language model behavior with respect to specific behavioral values by fine-tuning on a small, curated¬†dataset.",
    "pubDate": "Thu, 10 Jun 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-language-model-behavior",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ü§ó PEFT welcomes new merging methods",
    "description": "",
    "summary": "ü§ó PEFT welcomes new merging methods Model merging has quickly become the de-facto standard of pushin...",
    "pubDate": "Mon, 19 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/peft_merging",
    "thumbnail": "https://huggingface.co/blog/assets/peft_merging/thumbnail.png"
  },
  {
    "title": "Learning policy representations in multiagent systems",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 17 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-policy-representations-in-multiagent-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Adversarial attacks on neural network policies",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 Feb 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adversarial-attacks-on-neural-network-policies",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI„Å´„Çà„ÇãÁîüÁî£Ë¶Å‰ª∂„ÅÆËá™ÂãïÂà§ÂÆöÊ©üËÉΩ„ÅåÂ•ΩË©ï„Å™3D„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†",
    "description": "LIGHTz„ÅØ„ÄÅË£ΩÈÄ†Ê•≠„ÅÆË®≠Ë®àÈñãÁô∫„Å´„Åä„Åë„ÇãÈñãÁô∫ÈÄüÂ∫¶„ÇÑÁîüÁî£ÊÄß„ÅÆÂêë‰∏ä„ÇíÊîØÊè¥„Åô„Çã3D„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„Äåblooplinter„Äç„ÅÆÂ∞éÂÖ•„ÅåË£ΩÈÄ†Ê•≠„ÅßÈÄ≤„Çì„Åß„ÅÑ„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇÁâπ„Å´„ÄåAIË¶Å‰ª∂„ÉÅ„Çß„ÉÉ„ÇØÊ©üËÉΩ„Äç„ÅåÊ¥ªÁî®„Åï„Çå„Å¶„ÅÑ„Çã„Å®„ÅÑ„ÅÜ„ÄÇ",
    "summary": "LIGHTz„ÅØ„ÄÅË£ΩÈÄ†Ê•≠„ÅÆË®≠Ë®àÈñãÁô∫„Å´„Åä„Åë„ÇãÈñãÁô∫ÈÄüÂ∫¶„ÇÑÁîüÁî£ÊÄß„ÅÆÂêë‰∏ä„ÇíÊîØÊè¥„Åô„Çã3D„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„Äåblooplinter„Äç„ÅÆÂ∞éÂÖ•„ÅåË£ΩÈÄ†Ê•≠„ÅßÈÄ≤„Çì„Åß„ÅÑ„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇÁâπ„Å´„ÄåAIË¶Å‰ª∂„ÉÅ„Çß„ÉÉ„ÇØÊ©üËÉΩ„Äç„ÅåÊ¥ªÁî®„Åï„Çå„Å¶„ÅÑ„Çã„Å®„ÅÑ„ÅÜ„ÄÇ",
    "pubDate": "Mon, 23 Jun 2025 09:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://monoist.itmedia.co.jp/mn/articles/2506/23/news006.html",
    "thumbnail": "https://image.itmedia.co.jp/mn/articles/2506/23/cover_news006.jpg"
  },
  {
    "title": "Info-Coevolution: An Efficient Framework for Data Model Coevolution",
    "description": "arXiv:2506.08070v2 Announce Type: replace-cross Abstract: Machine learning relies heavily on data, yet the continuous growth of real-world data poses challenges for efficient dataset construction and training. A fundamental yet unsolved question is: given our current model and data, does a new data (sample/batch) need annotation/learning? Conventional approaches retain all available data, leading to non-optimal data and training efficiency. Active learning aims to reduce data redundancy by selecting a subset of samples to annotate, while it increases pipeline complexity and introduces bias. In this work, we propose Info-Coevolution, a novel framework that efficiently enables models and data to coevolve through online selective annotation with no bias. Leveraging task-specific models (and open-source models), it selectively annotates and integrates online and web data to improve datasets efficiently. For real-world datasets like ImageNet-1K, Info-Coevolution reduces annotation and training costs by 32% without performance loss. It is able to automatically give the saving ratio without tuning the ratio. It can further reduce the annotation ratio to 50% with semi-supervised learning. We also explore retrieval-based dataset enhancement using unlabeled open-source data. Code is available at https://github.com/NUS-HPC-AI-Lab/Info-Coevolution/.",
    "summary": "arXiv:2506.08070v2 Announce Type: replace-cross Abstract: Machine learning relies heavily on data, yet the continuous growth of real-world data poses challenges for efficient dataset construction and training. A fundamental yet unsolved question is: given our current model and data, does a new data (sample/batch) need annotation/learning? Conventional approaches retain all available data, leading to non-optimal data and training efficiency. Active learning aims to reduce data redundancy by selecting a subset of samples to annotate, while it increases pipeline complexity and introduces bias. In this work, we propose Info-Coevolution, a novel framework that efficiently enables models and data to coevolve through online selective annotation with no bias. Leveraging task-specific models (and open-source models), it selectively annotates and integrates online and web data to improve datasets efficiently. For real-world datasets like ImageNet-1K, Info-Coevolution reduces annotation and training costs by 32% without performance loss. It is able to automatically give the saving ratio without tuning the ratio. It can further reduce the annotation ratio to 50% with semi-supervised learning. We also explore retrieval-based dataset enhancement using unlabeled open-source data. Code is available at https://github.com/NUS-HPC-AI-Lab/Info-Coevolution/.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.08070",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Energy-Based Transfer for Reinforcement Learning",
    "description": "arXiv:2506.16590v1 Announce Type: cross Abstract: Reinforcement learning algorithms often suffer from poor sample efficiency, making them challenging to apply in multi-task or continual learning settings. Efficiency can be improved by transferring knowledge from a previously trained teacher policy to guide exploration in new but related tasks. However, if the new task sufficiently differs from the teacher's training task, the transferred guidance may be sub-optimal and bias exploration toward low-reward behaviors. We propose an energy-based transfer learning method that uses out-of-distribution detection to selectively issue guidance, enabling the teacher to intervene only in states within its training distribution. We theoretically show that energy scores reflect the teacher's state-visitation density and empirically demonstrate improved sample efficiency and performance across both single-task and multi-task settings.",
    "summary": "arXiv:2506.16590v1 Announce Type: cross Abstract: Reinforcement learning algorithms often suffer from poor sample efficiency, making them challenging to apply in multi-task or continual learning settings. Efficiency can be improved by transferring knowledge from a previously trained teacher policy to guide exploration in new but related tasks. However, if the new task sufficiently differs from the teacher's training task, the transferred guidance may be sub-optimal and bias exploration toward low-reward behaviors. We propose an energy-based transfer learning method that uses out-of-distribution detection to selectively issue guidance, enabling the teacher to intervene only in states within its training distribution. We theoretically show that energy scores reflect the teacher's state-visitation density and empirically demonstrate improved sample efficiency and performance across both single-task and multi-task settings.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16590",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Intelligence Age",
    "description": "We aired our first-ever television ad during the Super Bowl to pique people‚Äôs curiosity and help us all realize how AI can open up new possibilities for us, create more fulfillment in our lives, and make us more productive, just as all the tools that came before AI did for those who came before us.",
    "summary": "We aired our first-ever television ad during the Super Bowl to pique people‚Äôs curiosity and help us all realize how AI can open up new possibilities for us, create more fulfillment in our lives, and make us more productive, just as all the tools that came before AI did for those who came before us.",
    "pubDate": "Sun, 09 Feb 2025 22:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-the-intelligence-age",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SDRNET: Stacked Deep Residual Network for Accurate Semantic Segmentation of Fine-Resolution Remotely Sensed Images",
    "description": "arXiv:2506.21945v1 Announce Type: cross Abstract: Land cover maps generated from semantic segmentation of high-resolution remotely sensed images have drawn mucon in the photogrammetry and remote sensing research community. Currently, massive fine-resolution remotely sensed (FRRS) images acquired by improving sensing and imaging technologies become available. However, accurate semantic segmentation of such FRRS images is greatly affected by substantial class disparities, the invisibility of key ground objects due to occlusion, and object size variation. Despite the extraordinary potential in deep convolutional neural networks (DCNNs) in image feature learning and representation, extracting sufficient features from FRRS images for accurate semantic segmentation is still challenging. These challenges demand the deep learning models to learn robust features and generate sufficient feature descriptors. Specifically, learning multi-contextual features to guarantee adequate coverage of varied object sizes from the ground scene and harnessing global-local contexts to overcome class disparities challenge even profound networks. Deeper networks significantly lose spatial details due to gradual downsampling processes resulting in poor segmentation results and coarse boundaries. This article presents a stacked deep residual network (SDRNet) for semantic segmentation from FRRS images. The proposed framework utilizes two stacked encoder-decoder networks to harness long-range semantics yet preserve spatial information and dilated residual blocks (DRB) between each encoder and decoder network to capture sufficient global dependencies thus improving segmentation performance. Our experimental results obtained using the ISPRS Vaihingen and Potsdam datasets demonstrate that the SDRNet performs effectively and competitively against current DCNNs in semantic segmentation.",
    "summary": "arXiv:2506.21945v1 Announce Type: cross Abstract: Land cover maps generated from semantic segmentation of high-resolution remotely sensed images have drawn mucon in the photogrammetry and remote sensing research community. Currently, massive fine-resolution remotely sensed (FRRS) images acquired by improving sensing and imaging technologies become available. However, accurate semantic segmentation of such FRRS images is greatly affected by substantial class disparities, the invisibility of key ground objects due to occlusion, and object size variation. Despite the extraordinary potential in deep convolutional neural networks (DCNNs) in image feature learning and representation, extracting sufficient features from FRRS images for accurate semantic segmentation is still challenging. These challenges demand the deep learning models to learn robust features and generate sufficient feature descriptors. Specifically, learning multi-contextual features to guarantee adequate coverage of varied object sizes from the ground scene and harnessing global-local contexts to overcome class disparities challenge even profound networks. Deeper networks significantly lose spatial details due to gradual downsampling processes resulting in poor segmentation results and coarse boundaries. This article presents a stacked deep residual network (SDRNet) for semantic segmentation from FRRS images. The proposed framework utilizes two stacked encoder-decoder networks to harness long-range semantics yet preserve spatial information and dilated residual blocks (DRB) between each encoder and decoder network to capture sufficient global dependencies thus improving segmentation performance. Our experimental results obtained using the ISPRS Vaihingen and Potsdam datasets demonstrate that the SDRNet performs effectively and competitively against current DCNNs in semantic segmentation.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21945",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "#Exploration: A study of count-based exploration for deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 15 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/exploration",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning",
    "description": "arXiv:2410.17933v3 Announce Type: replace-cross Abstract: One of the biggest challenges of building artificial intelligence (AI) model in the healthcare area is the data sharing. Since healthcare data is private, sensitive, and heterogeneous, collecting sufficient data for modelling is exhausting, costly, and sometimes impossible. In this paper, we propose a framework for global healthcare modelling using datasets from multi-continents (Europe, North America, and Asia) without sharing the local datasets, and choose glucose management as a study model to verify its effectiveness. Technically, blockchain-enabled federated learning is implemented with adaptation to meet the privacy and safety requirements of healthcare data, meanwhile, it rewards honest participation and penalizes malicious activities using its on-chain incentive mechanism. Experimental results show that the proposed framework is effective, efficient, and privacy-preserving. Its prediction accuracy consistently outperforms models trained on limited personal data and achieves comparable or even slightly better results than centralized training in certain scenarios, all while preserving data privacy. This work paves the way for international collaborations on healthcare projects, where additional data is crucial for reducing bias and providing benefits to humanity.",
    "summary": "arXiv:2410.17933v3 Announce Type: replace-cross Abstract: One of the biggest challenges of building artificial intelligence (AI) model in the healthcare area is the data sharing. Since healthcare data is private, sensitive, and heterogeneous, collecting sufficient data for modelling is exhausting, costly, and sometimes impossible. In this paper, we propose a framework for global healthcare modelling using datasets from multi-continents (Europe, North America, and Asia) without sharing the local datasets, and choose glucose management as a study model to verify its effectiveness. Technically, blockchain-enabled federated learning is implemented with adaptation to meet the privacy and safety requirements of healthcare data, meanwhile, it rewards honest participation and penalizes malicious activities using its on-chain incentive mechanism. Experimental results show that the proposed framework is effective, efficient, and privacy-preserving. Its prediction accuracy consistently outperforms models trained on limited personal data and achieves comparable or even slightly better results than centralized training in certain scenarios, all while preserving data privacy. This work paves the way for international collaborations on healthcare projects, where additional data is crucial for reducing bias and providing benefits to humanity.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.17933",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Cosmopedia: how to create large-scale synthetic data for pre-training Large Language Models",
    "description": "",
    "summary": "Cosmopedia: how to create large-scale synthetic data for pre-training In this blog post, we outline ...",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cosmopedia",
    "thumbnail": "https://huggingface.co/blog/assets/cosmopedia/thumbnail.png"
  },
  {
    "title": "Drag-and-Drop LLMs: Zero-Shot Prompt-to-Weights",
    "description": "arXiv:2506.16406v1 Announce Type: cross Abstract: Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-rank adaptation (LoRA) reduce the cost of customizing large language models (LLMs), yet still require a separate optimization run for every downstream dataset. We introduce textbf{Drag-and-Drop LLMs (textit{DnD})}, a prompt-conditioned parameter generator that eliminates per-task training by mapping a handful of unlabeled task prompts directly to LoRA weight updates. A lightweight text encoder distills each prompt batch into condition embeddings, which are then transformed by a cascaded hyper-convolutional decoder into the full set of LoRA matrices. Once trained in a diverse collection of prompt-checkpoint pairs, DnD produces task-specific parameters in seconds, yielding i) up to textbf{12,000$times$} lower overhead than full fine-tuning, ii) average gains up to textbf{30%} in performance over the strongest training LoRAs on unseen common-sense reasoning, math, coding, and multimodal benchmarks, and iii) robust cross-domain generalization despite never seeing the target data or labels. Our results demonstrate that prompt-conditioned parameter generation is a viable alternative to gradient-based adaptation for rapidly specializing LLMs. Our project is available at href{https://jerryliang24.github.io/DnD}{https://jerryliang24.github.io/DnD}.",
    "summary": "arXiv:2506.16406v1 Announce Type: cross Abstract: Modern Parameter-Efficient Fine-Tuning (PEFT) methods such as low-rank adaptation (LoRA) reduce the cost of customizing large language models (LLMs), yet still require a separate optimization run for every downstream dataset. We introduce textbf{Drag-and-Drop LLMs (textit{DnD})}, a prompt-conditioned parameter generator that eliminates per-task training by mapping a handful of unlabeled task prompts directly to LoRA weight updates. A lightweight text encoder distills each prompt batch into condition embeddings, which are then transformed by a cascaded hyper-convolutional decoder into the full set of LoRA matrices. Once trained in a diverse collection of prompt-checkpoint pairs, DnD produces task-specific parameters in seconds, yielding i) up to textbf{12,000$times$} lower overhead than full fine-tuning, ii) average gains up to textbf{30%} in performance over the strongest training LoRAs on unseen common-sense reasoning, math, coding, and multimodal benchmarks, and iii) robust cross-domain generalization despite never seeing the target data or labels. Our results demonstrate that prompt-conditioned parameter generation is a viable alternative to gradient-based adaptation for rapidly specializing LLMs. Our project is available at href{https://jerryliang24.github.io/DnD}{https://jerryliang24.github.io/DnD}.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16406",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Data is better together",
    "description": "",
    "summary": "Data is better together: Enabling communities to collectively build better datasets together using A...",
    "pubDate": "Mon, 04 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/community-datasets/thumbnail.png"
  },
  {
    "title": "AI learns how vision and sound are connected, without human intervention",
    "description": "This new machine-learning model can match corresponding audio and visual data, which could someday help robots interact in the real world.",
    "summary": "This new machine-learning model can match corresponding audio and visual data, which could someday help robots interact in the real world.",
    "pubDate": "Thu, 22 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-learns-how-vision-and-sound-are-connected-without-human-intervention-0522",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-AV-Learning-01-press.jpg"
  },
  {
    "title": "„Çµ„Ç§„Éê„Éº„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„Å´Âπ¥4ÂÑÑÂÜÜÊäïË≥á„ÄÄÈñãÁô∫„Ç®„É≥„Ç∏„Éã„Ç¢„Å´Êúà200„Éâ„É´ÊîØÊè¥„ÄÄÊ•≠ÂãôÂ§ñ„Åß„ÇÇË©¶„Åõ„Çã",
    "description": "„Çµ„Ç§„Éê„Éº„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅØ„ÄÅ„Ç®„É≥„Ç∏„Éã„Ç¢Á¥Ñ1200‰∫∫„Å´1‰∫∫ÂΩì„Åü„ÇäÊúà200„Éâ„É´„ÄÅÈñãÁô∫AI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂ∞éÂÖ•Ë≤ªÁî®„Çí„Çµ„Éù„Éº„Éà„Åô„Çã„ÄÇ",
    "summary": "„Çµ„Ç§„Éê„Éº„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅØ„ÄÅ„Ç®„É≥„Ç∏„Éã„Ç¢Á¥Ñ1200‰∫∫„Å´1‰∫∫ÂΩì„Åü„ÇäÊúà200„Éâ„É´„ÄÅÈñãÁô∫AI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂ∞éÂÖ•Ë≤ªÁî®„Çí„Çµ„Éù„Éº„Éà„Åô„Çã„ÄÇ",
    "pubDate": "Thu, 19 Jun 2025 15:59:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/19/news100.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/19/cover_news100.jpg"
  },
  {
    "title": "‰∏≠Â∞è‰ºÅÊ•≠„ÅÆ„Éõ„É≥„Éç„ÄÄ„ÄåAI„ÅØÊúüÂæÖ„Åª„Å©„ÅÆÊàêÊûú„Çí‰∏ä„Åí„Å¶„ÅÑ„Å™„ÅÑ„Äç",
    "description": "American Express„ÅÆË™øÊüª„Å´„Çà„Çã„Å®„ÄÅAI„ÅÆÊ¥ªÁî®„Å´„Çà„Çä‰∏ÄÂÆö„ÅÆ„É°„É™„ÉÉ„Éà„ÅØ„ÅÇ„Å£„Åü„ÇÇ„ÅÆ„ÅÆÊúüÂæÖ„Åï„Çå„Å¶„ÅÑ„Åü„Åª„Å©„ÅÆÊàêÊûú„ÅØÂá∫„Å¶„ÅÑ„Å™„ÅÑ„Å®„ÅÑ„ÅÜ„ÄÇ",
    "summary": "American Express„ÅÆË™øÊüª„Å´„Çà„Çã„Å®„ÄÅAI„ÅÆÊ¥ªÁî®„Å´„Çà„Çä‰∏ÄÂÆö„ÅÆ„É°„É™„ÉÉ„Éà„ÅØ„ÅÇ„Å£„Åü„ÇÇ„ÅÆ„ÅÆÊúüÂæÖ„Åï„Çå„Å¶„ÅÑ„Åü„Åª„Å©„ÅÆÊàêÊûú„ÅØÂá∫„Å¶„ÅÑ„Å™„ÅÑ„Å®„ÅÑ„ÅÜ„ÄÇ",
    "pubDate": "Tue, 24 Jun 2025 10:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://kn.itmedia.co.jp/kn/articles/2506/24/news026.html",
    "thumbnail": "https://image.itmedia.co.jp/kn/articles/2506/24/cover_news026.jpg"
  },
  {
    "title": "Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel",
    "description": "",
    "summary": "Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel In this post we will look ...",
    "pubDate": "Mon, 02 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-fsdp",
    "thumbnail": "https://huggingface.co/blog/assets/62_pytorch_fsdp/fsdp-thumbnail.png"
  },
  {
    "title": "Graph Classification with Transformers",
    "description": "",
    "summary": "Graph classification with Transformers In the previous blog, we explored some of the theoretical asp...",
    "pubDate": "Fri, 14 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphml-classification",
    "thumbnail": "https://huggingface.co/blog/assets/125_intro-to-graphml/thumbnail_classification.png"
  },
  {
    "title": "OpenAI supporters",
    "description": "We‚Äôre excited to welcome new donors to OpenAI.",
    "summary": "We‚Äôre excited to welcome new donors to OpenAI.",
    "pubDate": "Tue, 20 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-supporters",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Run a Chatgpt-like Chatbot on a Single GPU with ROCm",
    "description": "",
    "summary": "Run a Chatgpt-like Chatbot on a Single GPU with ROCm Introduction ChatGPT, OpenAI's groundbreaking l...",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chatbot-amd-gpu",
    "thumbnail": "https://huggingface.co/blog/assets/chatbot-amd-gpu/thumbnail.png"
  },
  {
    "title": "APO: Enhancing Reasoning Ability of MLLMs via Asymmetric Policy Optimization",
    "description": "arXiv:2506.21655v1 Announce Type: cross Abstract: Multimodal Large Language Models (MLLMs) are powerful at integrating diverse data, but they often struggle with complex reasoning. While Reinforcement learning (RL) can boost reasoning in LLMs, applying it to MLLMs is tricky. Common issues include a drop in performance on general tasks and the generation of overly detailed or 'overthinking' reasoning. Our work investigates how the KL penalty and overthinking affect RL training in MLLMs. We propose Asymmetric Policy Optimization (APO) to address these issues, which divides the sampled responses into positive and negative groups. For positive samples, Difficulty-Adaptive Divergence Shaping (DADS) is introduced to dynamically adjust the KL divergence weight based on their difficulty. This method prevents policy entropy from dropping sharply, improves training stability, utilizes samples better, and preserves the model's existing knowledge. For negative samples, Suboptimal Trajectory Complexity Regularization (STCR) is proposed to penalize overly long responses. This helps mitigate overthinking and encourages more concise reasoning while preserving the model's explorative capacity. We apply our method to Qwen2.5-VL-3B, creating View-R1-3B. View-R1-3B significantly enhances reasoning capabilities, showing an average 7% gain over the base model and outperforming larger MLLMs (7-11B) on various reasoning benchmarks. Importantly, unlike other reasoning-tuned MLLMs that often degrade on general tasks, View-R1-3B maintains consistent improvement, demonstrating superior generalization. These results highlight the effectiveness and broad applicability of our DADS and STCR techniques for advancing complex multimodal reasoning in MLLMs. The code will be made available at https://github.com/Indolent-Kawhi/View-R1.",
    "summary": "arXiv:2506.21655v1 Announce Type: cross Abstract: Multimodal Large Language Models (MLLMs) are powerful at integrating diverse data, but they often struggle with complex reasoning. While Reinforcement learning (RL) can boost reasoning in LLMs, applying it to MLLMs is tricky. Common issues include a drop in performance on general tasks and the generation of overly detailed or 'overthinking' reasoning. Our work investigates how the KL penalty and overthinking affect RL training in MLLMs. We propose Asymmetric Policy Optimization (APO) to address these issues, which divides the sampled responses into positive and negative groups. For positive samples, Difficulty-Adaptive Divergence Shaping (DADS) is introduced to dynamically adjust the KL divergence weight based on their difficulty. This method prevents policy entropy from dropping sharply, improves training stability, utilizes samples better, and preserves the model's existing knowledge. For negative samples, Suboptimal Trajectory Complexity Regularization (STCR) is proposed to penalize overly long responses. This helps mitigate overthinking and encourages more concise reasoning while preserving the model's explorative capacity. We apply our method to Qwen2.5-VL-3B, creating View-R1-3B. View-R1-3B significantly enhances reasoning capabilities, showing an average 7% gain over the base model and outperforming larger MLLMs (7-11B) on various reasoning benchmarks. Importantly, unlike other reasoning-tuned MLLMs that often degrade on general tasks, View-R1-3B maintains consistent improvement, demonstrating superior generalization. These results highlight the effectiveness and broad applicability of our DADS and STCR techniques for advancing complex multimodal reasoning in MLLMs. The code will be made available at https://github.com/Indolent-Kawhi/View-R1.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21655",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evaluating Compliance with Visualization Guidelines in Diagrams for Scientific Publications Using Large Vision Language Models",
    "description": "arXiv:2506.19825v1 Announce Type: new Abstract: Diagrams are widely used to visualize data in publications. The research field of data visualization deals with defining principles and guidelines for the creation and use of these diagrams, which are often not known or adhered to by researchers, leading to misinformation caused by providing inaccurate or incomplete information. In this work, large Vision Language Models (VLMs) are used to analyze diagrams in order to identify potential problems in regards to selected data visualization principles and guidelines. To determine the suitability of VLMs for these tasks, five open source VLMs and five prompting strategies are compared using a set of questions derived from selected data visualization guidelines. The results show that the employed VLMs work well to accurately analyze diagram types (F1-score 82.49 %), 3D effects (F1-score 98.55 %), axes labels (F1-score 76.74 %), lines (RMSE 1.16), colors (RMSE 1.60) and legends (F1-score 96.64 %, RMSE 0.70), while they cannot reliably provide feedback about the image quality (F1-score 0.74 %) and tick marks/labels (F1-score 46.13 %). Among the employed VLMs, Qwen2.5VL performs best, and the summarizing prompting strategy performs best for most of the experimental questions. It is shown that VLMs can be used to automatically identify a number of potential issues in diagrams, such as missing axes labels, missing legends, and unnecessary 3D effects. The approach laid out in this work can be extended for further aspects of data visualization.",
    "summary": "arXiv:2506.19825v1 Announce Type: new Abstract: Diagrams are widely used to visualize data in publications. The research field of data visualization deals with defining principles and guidelines for the creation and use of these diagrams, which are often not known or adhered to by researchers, leading to misinformation caused by providing inaccurate or incomplete information. In this work, large Vision Language Models (VLMs) are used to analyze diagrams in order to identify potential problems in regards to selected data visualization principles and guidelines. To determine the suitability of VLMs for these tasks, five open source VLMs and five prompting strategies are compared using a set of questions derived from selected data visualization guidelines. The results show that the employed VLMs work well to accurately analyze diagram types (F1-score 82.49 %), 3D effects (F1-score 98.55 %), axes labels (F1-score 76.74 %), lines (RMSE 1.16), colors (RMSE 1.60) and legends (F1-score 96.64 %, RMSE 0.70), while they cannot reliably provide feedback about the image quality (F1-score 0.74 %) and tick marks/labels (F1-score 46.13 %). Among the employed VLMs, Qwen2.5VL performs best, and the summarizing prompting strategy performs best for most of the experimental questions. It is shown that VLMs can be used to automatically identify a number of potential issues in diagrams, such as missing axes labels, missing legends, and unnecessary 3D effects. The approach laid out in this work can be extended for further aspects of data visualization.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19825",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Open Ko-LLM Leaderboard: Leading the Korean LLM Evaluation Ecosystem",
    "description": "",
    "summary": "Introducing the Open Ko-LLM Leaderboard: Leading the Korean LLM Evaluation Ecosystem In the fast-evo...",
    "pubDate": "Tue, 20 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-upstage",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_upstage.png"
  },
  {
    "title": "Learning Multi-scale Spatial-frequency Features for Image Denoising",
    "description": "arXiv:2506.16307v1 Announce Type: cross Abstract: Recent advancements in multi-scale architectures have demonstrated exceptional performance in image denoising tasks. However, existing architectures mainly depends on a fixed single-input single-output Unet architecture, ignoring the multi-scale representations of pixel level. In addition, previous methods treat the frequency domain uniformly, ignoring the different characteristics of high-frequency and low-frequency noise. In this paper, we propose a novel multi-scale adaptive dual-domain network (MADNet) for image denoising. We use image pyramid inputs to restore noise-free results from low-resolution images. In order to realize the interaction of high-frequency and low-frequency information, we design an adaptive spatial-frequency learning unit (ASFU), where a learnable mask is used to separate the information into high-frequency and low-frequency components. In the skip connections, we design a global feature fusion block to enhance the features at different scales. Extensive experiments on both synthetic and real noisy image datasets verify the effectiveness of MADNet compared with current state-of-the-art denoising approaches.",
    "summary": "arXiv:2506.16307v1 Announce Type: cross Abstract: Recent advancements in multi-scale architectures have demonstrated exceptional performance in image denoising tasks. However, existing architectures mainly depends on a fixed single-input single-output Unet architecture, ignoring the multi-scale representations of pixel level. In addition, previous methods treat the frequency domain uniformly, ignoring the different characteristics of high-frequency and low-frequency noise. In this paper, we propose a novel multi-scale adaptive dual-domain network (MADNet) for image denoising. We use image pyramid inputs to restore noise-free results from low-resolution images. In order to realize the interaction of high-frequency and low-frequency information, we design an adaptive spatial-frequency learning unit (ASFU), where a learnable mask is used to separate the information into high-frequency and low-frequency components. In the skip connections, we design a global feature fusion block to enhance the features at different scales. Extensive experiments on both synthetic and real noisy image datasets verify the effectiveness of MADNet compared with current state-of-the-art denoising approaches.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16307",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google„ÄÅ„Éê„Éº„ÉÅ„É£„É´AIË©¶ÁùÄ„Ç¢„Éó„É™„ÄåDoppl„Äç„ÇíiOSÔºèAndroid„ÅßÂÖ¨ÈñãÔºà„Åæ„Åö„ÅØÁ±≥ÂõΩ„ÅßÔºâ",
    "description": "Google„ÅØ„ÄÅÂÆüÈ®ìÁöÑ„Å™„Éê„Éº„ÉÅ„É£„É´Ë©¶ÁùÄ„Ç¢„Éó„É™„ÄåDoppl„Äç„ÇíÁ±≥ÂõΩ„ÅßÂÖ¨Èñã„Åó„Åü„ÄÇGoogle I/O„ÅßÊä´Èú≤„Åï„Çå„ÅüÁîüÊàêAIÊäÄË°ì„ÇíÊ¥ªÁî®„Åó„ÄÅ„É¶„Éº„Ç∂„Éº„ÅåËá™Ë∫´„ÅÆÂÖ®Ë∫´ÂÜôÁúü„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åô„Çã„Å†„Åë„Åß„ÄÅ„Ç™„É≥„É©„Ç§„É≥‰∏ä„ÅÆË°£Êúç„Çí‰ªÆÊÉ≥ÁöÑ„Å´Ë©¶ÁùÄ„Åß„Åç„Çã„ÄÇÁü≠„ÅÑÂãïÁîªÁîüÊàêÊ©üËÉΩ„ÇÇÂÇô„Åà„Çã„ÄÇ",
    "summary": "Google„ÅØ„ÄÅÂÆüÈ®ìÁöÑ„Å™„Éê„Éº„ÉÅ„É£„É´Ë©¶ÁùÄ„Ç¢„Éó„É™„ÄåDoppl„Äç„ÇíÁ±≥ÂõΩ„ÅßÂÖ¨Èñã„Åó„Åü„ÄÇGoogle I/O„ÅßÊä´Èú≤„Åï„Çå„ÅüÁîüÊàêAIÊäÄË°ì„ÇíÊ¥ªÁî®„Åó„ÄÅ„É¶„Éº„Ç∂„Éº„ÅåËá™Ë∫´„ÅÆÂÖ®Ë∫´ÂÜôÁúü„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åô„Çã„Å†„Åë„Åß„ÄÅ„Ç™„É≥„É©„Ç§„É≥‰∏ä„ÅÆË°£Êúç„Çí‰ªÆÊÉ≥ÁöÑ„Å´Ë©¶ÁùÄ„Åß„Åç„Çã„ÄÇÁü≠„ÅÑÂãïÁîªÁîüÊàêÊ©üËÉΩ„ÇÇÂÇô„Åà„Çã„ÄÇ",
    "pubDate": "Sat, 28 Jun 2025 06:48:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/28/news035.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/28/cover_news035.jpg"
  },
  {
    "title": "New AI classifier for indicating AI-written text",
    "description": "We‚Äôre launching a classifier trained to distinguish between AI-written and human-written¬†text.",
    "summary": "We‚Äôre launching a classifier trained to distinguish between AI-written and human-written¬†text.",
    "pubDate": "Tue, 31 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "3 Questions: How to help students recognize potential bias in their AI datasets",
    "description": "Courses on developing AI models for health care need to focus more on identifying and addressing bias, says Leo Anthony Celi.",
    "summary": "Courses on developing AI models for health care need to focus more on identifying and addressing bias, says Leo Anthony Celi.",
    "pubDate": "Mon, 02 Jun 2025 10:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/3-questions-recognizing-potential-bias-in-ai-datasets-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_AI-Health-Data-01.jpg"
  },
  {
    "title": "Introducing the AMD 5th Gen EPYC‚Ñ¢ CPU",
    "description": "",
    "summary": "Introducing the AMD 5th Gen EPYC‚Ñ¢ CPU AMD has just unveiled its 5th generation of server-grade EPYC ...",
    "pubDate": "Thu, 10 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-amd-turin",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "Experimenting with Automatic PII Detection on the Hub using Presidio",
    "description": "",
    "summary": "Experimenting with Automatic PII Detection on the Hub using Presidio At Hugging Face, we've noticed ...",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/presidio-pii-detection",
    "thumbnail": "https://huggingface.co/blog/assets/presidio-pii-detection/thumbnail.png"
  },
  {
    "title": "OpenAI Baselines: ACKTR & A2C",
    "description": "We‚Äôre releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic variant of Asynchronous Advantage Actor Critic (A3C) which we‚Äôve found gives equal performance. ACKTR is a more sample-efficient reinforcement learning algorithm than TRPO and A2C, and requires only slightly more computation than A2C per update.",
    "summary": "We‚Äôre releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic variant of Asynchronous Advantage Actor Critic (A3C) which we‚Äôve found gives equal performance. ACKTR is a more sample-efficient reinforcement learning algorithm than TRPO and A2C, and requires only slightly more computation than A2C per update.",
    "pubDate": "Fri, 18 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-acktr-a2c",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generalisation Bounds of Zero-Shot Economic Forecasting using Time Series Foundation Models",
    "description": "arXiv:2506.15705v1 Announce Type: cross Abstract: This study investigates zero-shot forecasting capabilities of Time Series Foundation Models (TSFMs) for macroeconomic indicators. We apply TSFMs to forecasting economic indicators under univariate conditions, bypassing the need for train bespoke econometric models using and extensive training datasets. Our experiments were conducted on a case study dataset, without additional customisation. We rigorously back-tested three state-of-the-art TSFMs (Chronos, TimeGPT and Moirai) under data-scarce conditions and structural breaks. Our results demonstrate that appropriately engineered TSFMs can internalise rich economic dynamics, accommodate regime shifts, and deliver well-behaved uncertainty estimates out of the box, while matching state-of-the-art multivariate models on this domain. Our findings suggest that, without any fine-tuning, TSFMs can match or exceed classical models during stable economic conditions. However, they are vulnerable to degradation in performances during periods of rapid shocks. The findings offer guidance to practitioners on when zero-shot deployments are viable for macroeconomic monitoring and strategic planning.",
    "summary": "arXiv:2506.15705v1 Announce Type: cross Abstract: This study investigates zero-shot forecasting capabilities of Time Series Foundation Models (TSFMs) for macroeconomic indicators. We apply TSFMs to forecasting economic indicators under univariate conditions, bypassing the need for train bespoke econometric models using and extensive training datasets. Our experiments were conducted on a case study dataset, without additional customisation. We rigorously back-tested three state-of-the-art TSFMs (Chronos, TimeGPT and Moirai) under data-scarce conditions and structural breaks. Our results demonstrate that appropriately engineered TSFMs can internalise rich economic dynamics, accommodate regime shifts, and deliver well-behaved uncertainty estimates out of the box, while matching state-of-the-art multivariate models on this domain. Our findings suggest that, without any fine-tuning, TSFMs can match or exceed classical models during stable economic conditions. However, they are vulnerable to degradation in performances during periods of rapid shocks. The findings offer guidance to practitioners on when zero-shot deployments are viable for macroeconomic monitoring and strategic planning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15705",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Scaling Kubernetes to 7,500 nodes",
    "description": "We‚Äôve scaled Kubernetes clusters to 7,500 nodes, producing a scalable infrastructure for large models like¬†GPT-3,¬†CLIP, and¬†DALL¬∑E, but also for rapid small-scale iterative research such as¬†Scaling Laws for Neural Language Models.",
    "summary": "We‚Äôve scaled Kubernetes clusters to 7,500 nodes, producing a scalable infrastructure for large models like¬†GPT-3,¬†CLIP, and¬†DALL¬∑E, but also for rapid small-scale iterative research such as¬†Scaling Laws for Neural Language Models.",
    "pubDate": "Mon, 25 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-kubernetes-to-7500-nodes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Decision Transformers on Hugging Face ü§ó",
    "description": "",
    "summary": "Introducing Decision Transformers on Hugging Face ü§ó At Hugging Face, we are contributing to the ecos...",
    "pubDate": "Mon, 28 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/decision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/58_decision-transformers/thumbnail.jpg"
  },
  {
    "title": "IndieFake Dataset: A Benchmark Dataset for Audio Deepfake Detection",
    "description": "arXiv:2506.19014v1 Announce Type: cross Abstract: Advancements in audio deepfake technology offers benefits like AI assistants, better accessibility for speech impairments, and enhanced entertainment. However, it also poses significant risks to security, privacy, and trust in digital communications. Detecting and mitigating these threats requires comprehensive datasets. Existing datasets lack diverse ethnic accents, making them inadequate for many real-world scenarios. Consequently, models trained on these datasets struggle to detect audio deepfakes in diverse linguistic and cultural contexts such as in South-Asian countries. Ironically, there is a stark lack of South-Asian speaker samples in the existing datasets despite constituting a quarter of the worlds population. This work introduces the IndieFake Dataset (IFD), featuring 27.17 hours of bonafide and deepfake audio from 50 English speaking Indian speakers. IFD offers balanced data distribution and includes speaker-level characterization, absent in datasets like ASVspoof21 (DF). We evaluated various baselines on IFD against existing ASVspoof21 (DF) and In-The-Wild (ITW) datasets. IFD outperforms ASVspoof21 (DF) and proves to be more challenging compared to benchmark ITW dataset. The dataset will be publicly available upon acceptance.",
    "summary": "arXiv:2506.19014v1 Announce Type: cross Abstract: Advancements in audio deepfake technology offers benefits like AI assistants, better accessibility for speech impairments, and enhanced entertainment. However, it also poses significant risks to security, privacy, and trust in digital communications. Detecting and mitigating these threats requires comprehensive datasets. Existing datasets lack diverse ethnic accents, making them inadequate for many real-world scenarios. Consequently, models trained on these datasets struggle to detect audio deepfakes in diverse linguistic and cultural contexts such as in South-Asian countries. Ironically, there is a stark lack of South-Asian speaker samples in the existing datasets despite constituting a quarter of the worlds population. This work introduces the IndieFake Dataset (IFD), featuring 27.17 hours of bonafide and deepfake audio from 50 English speaking Indian speakers. IFD offers balanced data distribution and includes speaker-level characterization, absent in datasets like ASVspoof21 (DF). We evaluated various baselines on IFD against existing ASVspoof21 (DF) and In-The-Wild (ITW) datasets. IFD outperforms ASVspoof21 (DF) and proves to be more challenging compared to benchmark ITW dataset. The dataset will be publicly available upon acceptance.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19014",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Recycling the Web: A Method to Enhance Pre-training Data Quality and Quantity for Language Models",
    "description": "arXiv:2506.04689v1 Announce Type: cross Abstract: Scaling laws predict that the performance of large language models improves with increasing model size and data size. In practice, pre-training has been relying on massive web crawls, using almost all data sources publicly available on the internet so far. However, this pool of natural data does not grow at the same rate as the compute supply. Furthermore, the availability of high-quality texts is even more limited: data filtering pipelines often remove up to 99% of the initial web scrapes to achieve state-of-the-art. To address the 'data wall' of pre-training scaling, our work explores ways to transform and recycle data discarded in existing filtering processes. We propose REWIRE, REcycling the Web with guIded REwrite, a method to enrich low-quality documents so that they could become useful for training. This in turn allows us to increase the representation of synthetic data in the final pre-training set. Experiments at 1B, 3B and 7B scales of the DCLM benchmark show that mixing high-quality raw texts and our rewritten texts lead to 1.0, 1.3 and 2.5 percentage points improvement respectively across 22 diverse tasks, compared to training on only filtered web data. Training on the raw-synthetic data mix is also more effective than having access to 2x web data. Through further analysis, we demonstrate that about 82% of the mixed in texts come from transforming lower-quality documents that would otherwise be discarded. REWIRE also outperforms related approaches of generating synthetic data, including Wikipedia-style paraphrasing, question-answer synthesizing and knowledge extraction. These results suggest that recycling web texts holds the potential for being a simple and effective approach for scaling pre-training data.",
    "summary": "arXiv:2506.04689v1 Announce Type: cross Abstract: Scaling laws predict that the performance of large language models improves with increasing model size and data size. In practice, pre-training has been relying on massive web crawls, using almost all data sources publicly available on the internet so far. However, this pool of natural data does not grow at the same rate as the compute supply. Furthermore, the availability of high-quality texts is even more limited: data filtering pipelines often remove up to 99% of the initial web scrapes to achieve state-of-the-art. To address the 'data wall' of pre-training scaling, our work explores ways to transform and recycle data discarded in existing filtering processes. We propose REWIRE, REcycling the Web with guIded REwrite, a method to enrich low-quality documents so that they could become useful for training. This in turn allows us to increase the representation of synthetic data in the final pre-training set. Experiments at 1B, 3B and 7B scales of the DCLM benchmark show that mixing high-quality raw texts and our rewritten texts lead to 1.0, 1.3 and 2.5 percentage points improvement respectively across 22 diverse tasks, compared to training on only filtered web data. Training on the raw-synthetic data mix is also more effective than having access to 2x web data. Through further analysis, we demonstrate that about 82% of the mixed in texts come from transforming lower-quality documents that would otherwise be discarded. REWIRE also outperforms related approaches of generating synthetic data, including Wikipedia-style paraphrasing, question-answer synthesizing and knowledge extraction. These results suggest that recycling web texts holds the potential for being a simple and effective approach for scaling pre-training data.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.04689",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI and Apple announce partnership",
    "description": "OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences.",
    "summary": "OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences.",
    "pubDate": "Mon, 10 Jun 2024 11:55:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-apple-announce-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ethics and Society Newsletter #6: Building Better AI: The Importance of Data Quality",
    "description": "",
    "summary": "Ethics and Society Newsletter #6: Building Better AI: The Importance of Data Quality In February, Re...",
    "pubDate": "Mon, 24 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-6",
    "thumbnail": "https://huggingface.co/blog/assets/182_ethics-soc-6/thumbnail.png"
  },
  {
    "title": "Bandwidth Selectors on Semiparametric Bayesian Networks",
    "description": "arXiv:2506.16844v1 Announce Type: cross Abstract: Semiparametric Bayesian networks (SPBNs) integrate parametric and non-parametric probabilistic models, offering flexibility in learning complex data distributions from samples. In particular, kernel density estimators (KDEs) are employed for the non-parametric component. Under the assumption of data normality, the normal rule is used to learn the bandwidth matrix for the KDEs in SPBNs. This matrix is the key hyperparameter that controls the trade-off between bias and variance. However, real-world data often deviates from normality, potentially leading to suboptimal density estimation and reduced predictive performance. This paper first establishes the theoretical framework for the application of state-of-the-art bandwidth selectors and subsequently evaluates their impact on SPBN performance. We explore the approaches of cross-validation and plug-in selectors, assessing their effectiveness in enhancing the learning capability and applicability of SPBNs. To support this investigation, we have extended the open-source package PyBNesian for SPBNs with the additional bandwidth selection techniques and conducted extensive experimental analyses. Our results demonstrate that the proposed bandwidth selectors leverage increasing information more effectively than the normal rule, which, despite its robustness, stagnates with more data. In particular, unbiased cross-validation generally outperforms the normal rule, highlighting its advantage in high sample size scenarios.",
    "summary": "arXiv:2506.16844v1 Announce Type: cross Abstract: Semiparametric Bayesian networks (SPBNs) integrate parametric and non-parametric probabilistic models, offering flexibility in learning complex data distributions from samples. In particular, kernel density estimators (KDEs) are employed for the non-parametric component. Under the assumption of data normality, the normal rule is used to learn the bandwidth matrix for the KDEs in SPBNs. This matrix is the key hyperparameter that controls the trade-off between bias and variance. However, real-world data often deviates from normality, potentially leading to suboptimal density estimation and reduced predictive performance. This paper first establishes the theoretical framework for the application of state-of-the-art bandwidth selectors and subsequently evaluates their impact on SPBN performance. We explore the approaches of cross-validation and plug-in selectors, assessing their effectiveness in enhancing the learning capability and applicability of SPBNs. To support this investigation, we have extended the open-source package PyBNesian for SPBNs with the additional bandwidth selection techniques and conducted extensive experimental analyses. Our results demonstrate that the proposed bandwidth selectors leverage increasing information more effectively than the normal rule, which, despite its robustness, stagnates with more data. In particular, unbiased cross-validation generally outperforms the normal rule, highlighting its advantage in high sample size scenarios.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16844",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TabArena: A Living Benchmark for Machine Learning on Tabular Data",
    "description": "arXiv:2506.16791v1 Announce Type: cross Abstract: With the growing popularity of deep learning and foundation models for tabular data, the need for standardized and reliable benchmarks is higher than ever. However, current benchmarks are static. Their design is not updated even if flaws are discovered, model versions are updated, or new models are released. To address this, we introduce TabArena, the first continuously maintained living tabular benchmarking system. To launch TabArena, we manually curate a representative collection of datasets and well-implemented models, conduct a large-scale benchmarking study to initialize a public leaderboard, and assemble a team of experienced maintainers. Our results highlight the influence of validation method and ensembling of hyperparameter configurations to benchmark models at their full potential. While gradient-boosted trees are still strong contenders on practical tabular datasets, we observe that deep learning methods have caught up under larger time budgets with ensembling. At the same time, foundation models excel on smaller datasets. Finally, we show that ensembles across models advance the state-of-the-art in tabular machine learning and investigate the contributions of individual models. We launch TabArena with a public leaderboard, reproducible code, and maintenance protocols to create a living benchmark available at https://tabarena.ai.",
    "summary": "arXiv:2506.16791v1 Announce Type: cross Abstract: With the growing popularity of deep learning and foundation models for tabular data, the need for standardized and reliable benchmarks is higher than ever. However, current benchmarks are static. Their design is not updated even if flaws are discovered, model versions are updated, or new models are released. To address this, we introduce TabArena, the first continuously maintained living tabular benchmarking system. To launch TabArena, we manually curate a representative collection of datasets and well-implemented models, conduct a large-scale benchmarking study to initialize a public leaderboard, and assemble a team of experienced maintainers. Our results highlight the influence of validation method and ensembling of hyperparameter configurations to benchmark models at their full potential. While gradient-boosted trees are still strong contenders on practical tabular datasets, we observe that deep learning methods have caught up under larger time budgets with ensembling. At the same time, foundation models excel on smaller datasets. Finally, we show that ensembles across models advance the state-of-the-art in tabular machine learning and investigate the contributions of individual models. We launch TabArena with a public leaderboard, reproducible code, and maintenance protocols to create a living benchmark available at https://tabarena.ai.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16791",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Planning for AGI and beyond",
    "description": "Our mission is to ensure that artificial general intelligence‚ÄîAI systems that are generally smarter than humans‚Äîbenefits all of¬†humanity.",
    "summary": "Our mission is to ensure that artificial general intelligence‚ÄîAI systems that are generally smarter than humans‚Äîbenefits all of¬†humanity.",
    "pubDate": "Fri, 24 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/planning-for-agi-and-beyond",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reinforcement learning with prediction-based rewards",
    "description": "We‚Äôve developed¬†Random Network Distillation (RND), a prediction-based method for encouraging reinforcement learning agents to explore their environments through curiosity, which for the first time exceeds average human performance on¬†Montezuma‚Äôs Revenge.",
    "summary": "We‚Äôve developed¬†Random Network Distillation (RND), a prediction-based method for encouraging reinforcement learning agents to explore their environments through curiosity, which for the first time exceeds average human performance on¬†Montezuma‚Äôs Revenge.",
    "pubDate": "Wed, 31 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reinforcement-learning-with-prediction-based-rewards",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ÁîüÊàêAIÁ§æ‰ºöÂÆüË£Ö„Å´Âêë„Åë„ÅüÊúÄÊñ∞ÊàêÊûú„Å®„ÅØ‚ÄïGENIACÁ¨¨2ÊúüÊàêÊûúÂ†±Âëä‰ºö„É¨„Éù„Éº„Éà",
    "description": "<p>Êó•Êú¨„ÅÆÁîüÊàêAIÈñãÁô∫Âäõ„ÇíÂ∫ï‰∏ä„Åí„Åô„ÇãÂèñ„ÇäÁµÑ„Åø„Å®„Åó„Å¶Ê≥®ÁõÆ„Åï„Çå„Å¶„ÅÑ„Çã„ÄåGENIACÔºàGenerative AI Accelerator ChallengeÔºâ„Äç„ÅÆÁ¨¨2ÊúüÊàêÊûúÂ†±Âëä‰ºö„ÅåÈñãÂÇ¨„Åï„Çå„Åæ„Åó„Åü„ÄÇ GENIAC„ÅØ„ÄÅÁµåÊ∏àÁî£Ê•≠ÁúÅ„Å®NE [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/report-geniac-second-results-presentation/'>ÁîüÊàêAIÁ§æ‰ºöÂÆüË£Ö„Å´Âêë„Åë„ÅüÊúÄÊñ∞ÊàêÊûú„Å®„ÅØ‚ÄïGENIACÁ¨¨2ÊúüÊàêÊûúÂ†±Âëä‰ºö„É¨„Éù„Éº„Éà</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>Êó•Êú¨„ÅÆÁîüÊàêAIÈñãÁô∫Âäõ„ÇíÂ∫ï‰∏ä„Åí„Åô„ÇãÂèñ„ÇäÁµÑ„Åø„Å®„Åó„Å¶Ê≥®ÁõÆ„Åï„Çå„Å¶„ÅÑ„Çã„ÄåGENIACÔºàGenerative AI Accelerator ChallengeÔºâ„Äç„ÅÆÁ¨¨2ÊúüÊàêÊûúÂ†±Âëä‰ºö„ÅåÈñãÂÇ¨„Åï„Çå„Åæ„Åó„Åü„ÄÇ GENIAC„ÅØ„ÄÅÁµåÊ∏àÁî£Ê•≠ÁúÅ„Å®NE [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/report-geniac-second-results-presentation/'>ÁîüÊàêAIÁ§æ‰ºöÂÆüË£Ö„Å´Âêë„Åë„ÅüÊúÄÊñ∞ÊàêÊûú„Å®„ÅØ‚ÄïGENIACÁ¨¨2ÊúüÊàêÊûúÂ†±Âëä‰ºö„É¨„Éù„Éº„Éà</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Wed, 11 Jun 2025 07:45:26 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/report-geniac-second-results-presentation/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/geniac-main.png"
  },
  {
    "title": "Melding data, systems, and society",
    "description": "A new book from Professor Munther Dahleh details the creation of a unique kind of transdisciplinary center, uniting many specialties through a common need for data science.",
    "summary": "A new book from Professor Munther Dahleh details the creation of a unique kind of transdisciplinary center, uniting many specialties through a common need for data science.",
    "pubDate": "Tue, 10 Jun 2025 14:25:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/data-systems-and-society-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Data-Systems-Dahleh-book.jpg"
  },
  {
    "title": "Practical 3D Asset Generation: A Step-by-Step Guide",
    "description": "",
    "summary": "Practical 3D Asset Generation: A Step-by-Step Guide Introduction Generative AI has become an instrum...",
    "pubDate": "Tue, 01 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/3d-assets",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail-3d.jpg"
  },
  {
    "title": "Japanese Stable Diffusion",
    "description": "",
    "summary": "Japanese Stable Diffusion Stable Diffusion, developed by CompVis, Stability AI, and LAION, has gener...",
    "pubDate": "Wed, 05 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/japanese-stable-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/106_japanese_stable_diffusion/jsd_thumbnail.png"
  },
  {
    "title": "How we really judge AI",
    "description": "Forget optimists vs. Luddites. Most people evaluate AI based on its perceived capability and their need for personalization.",
    "summary": "Forget optimists vs. Luddites. Most people evaluate AI based on its perceived capability and their need for personalization.",
    "pubDate": "Tue, 10 Jun 2025 11:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/how-we-really-judge-ai-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-AI-Aversion-Appreciation-01.jpg"
  },
  {
    "title": "Robust Reinforcement Learning from Human Feedback for Large Language Models Fine-Tuning",
    "description": "arXiv:2504.03784v4 Announce Type: replace-cross Abstract: Reinforcement learning from human feedback (RLHF) has emerged as a key technique for aligning the output of large language models (LLMs) with human preferences. To learn the reward function, most existing RLHF algorithms use the Bradley-Terry model, which relies on assumptions about human preferences that may not reflect the complexity and variability of real-world judgments. In this paper, we propose a robust algorithm to enhance the performance of existing approaches under such reward model misspecifications. Theoretically, our algorithm reduces the variance of reward and policy estimators, leading to improved regret bounds. Empirical evaluations on LLM benchmark datasets demonstrate that the proposed algorithm consistently outperforms existing methods, with 77-81% of responses being favored over baselines on the Anthropic Helpful and Harmless dataset.",
    "summary": "arXiv:2504.03784v4 Announce Type: replace-cross Abstract: Reinforcement learning from human feedback (RLHF) has emerged as a key technique for aligning the output of large language models (LLMs) with human preferences. To learn the reward function, most existing RLHF algorithms use the Bradley-Terry model, which relies on assumptions about human preferences that may not reflect the complexity and variability of real-world judgments. In this paper, we propose a robust algorithm to enhance the performance of existing approaches under such reward model misspecifications. Theoretically, our algorithm reduces the variance of reward and policy estimators, leading to improved regret bounds. Empirical evaluations on LLM benchmark datasets demonstrate that the proposed algorithm consistently outperforms existing methods, with 77-81% of responses being favored over baselines on the Anthropic Helpful and Harmless dataset.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.03784",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RecLLM-R1: A Two-Stage Training Paradigm with Reinforcement Learning and Chain-of-Thought v1",
    "description": "arXiv:2506.19235v1 Announce Type: new Abstract: Traditional recommendation systems often grapple with 'filter bubbles', underutilization of external knowledge, and a disconnect between model optimization and business policy iteration. To address these limitations, this paper introduces RecLLM-R1, a novel recommendation framework leveraging Large Language Models (LLMs) and drawing inspiration from the DeepSeek R1 methodology. The framework initiates by transforming user profiles, historical interactions, and multi-faceted item attributes into LLM-interpretable natural language prompts through a carefully engineered data construction process. Subsequently, a two-stage training paradigm is employed: the initial stage involves Supervised Fine-Tuning (SFT) to imbue the LLM with fundamental recommendation capabilities. The subsequent stage utilizes Group Relative Policy Optimization (GRPO), a reinforcement learning technique, augmented with a Chain-of-Thought (CoT) mechanism. This stage guides the model through multi-step reasoning and holistic decision-making via a flexibly defined reward function, aiming to concurrently optimize recommendation accuracy, diversity, and other bespoke business objectives. Empirical evaluations on a real-world user behavior dataset from a large-scale social media platform demonstrate that RecLLM-R1 significantly surpasses existing baseline methods across a spectrum of evaluation metrics, including accuracy, diversity, and novelty. It effectively mitigates the filter bubble effect and presents a promising avenue for the integrated optimization of recommendation models and policies under intricate business goals.",
    "summary": "arXiv:2506.19235v1 Announce Type: new Abstract: Traditional recommendation systems often grapple with 'filter bubbles', underutilization of external knowledge, and a disconnect between model optimization and business policy iteration. To address these limitations, this paper introduces RecLLM-R1, a novel recommendation framework leveraging Large Language Models (LLMs) and drawing inspiration from the DeepSeek R1 methodology. The framework initiates by transforming user profiles, historical interactions, and multi-faceted item attributes into LLM-interpretable natural language prompts through a carefully engineered data construction process. Subsequently, a two-stage training paradigm is employed: the initial stage involves Supervised Fine-Tuning (SFT) to imbue the LLM with fundamental recommendation capabilities. The subsequent stage utilizes Group Relative Policy Optimization (GRPO), a reinforcement learning technique, augmented with a Chain-of-Thought (CoT) mechanism. This stage guides the model through multi-step reasoning and holistic decision-making via a flexibly defined reward function, aiming to concurrently optimize recommendation accuracy, diversity, and other bespoke business objectives. Empirical evaluations on a real-world user behavior dataset from a large-scale social media platform demonstrate that RecLLM-R1 significantly surpasses existing baseline methods across a spectrum of evaluation metrics, including accuracy, diversity, and novelty. It effectively mitigates the filter bubble effect and presents a promising avenue for the integrated optimization of recommendation models and policies under intricate business goals.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19235",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Baba is LLM: Reasoning in a Game with Dynamic Rules",
    "description": "arXiv:2506.19095v1 Announce Type: new Abstract: Large language models (LLMs) are known to perform well on language tasks, but struggle with reasoning tasks. This paper explores the ability of LLMs to play the 2D puzzle game Baba is You, in which players manipulate rules by rearranging text blocks that define object properties. Given that this rule-manipulation relies on language abilities and reasoning, it is a compelling challenge for LLMs. Six LLMs are evaluated using different prompt types, including (1) simple, (2) rule-extended and (3) action-extended prompts. In addition, two models (Mistral, OLMo) are finetuned using textual and structural data from the game. Results show that while larger models (particularly GPT-4o) perform better in reasoning and puzzle solving, smaller unadapted models struggle to recognize game mechanics or apply rule changes. Finetuning improves the ability to analyze the game levels, but does not significantly improve solution formulation. We conclude that even for state-of-the-art and finetuned LLMs, reasoning about dynamic rule changes is difficult (specifically, understanding the use-mention distinction). The results provide insights into the applicability of LLMs to complex problem-solving tasks and highlight the suitability of games with dynamically changing rules for testing reasoning and reflection by LLMs.",
    "summary": "arXiv:2506.19095v1 Announce Type: new Abstract: Large language models (LLMs) are known to perform well on language tasks, but struggle with reasoning tasks. This paper explores the ability of LLMs to play the 2D puzzle game Baba is You, in which players manipulate rules by rearranging text blocks that define object properties. Given that this rule-manipulation relies on language abilities and reasoning, it is a compelling challenge for LLMs. Six LLMs are evaluated using different prompt types, including (1) simple, (2) rule-extended and (3) action-extended prompts. In addition, two models (Mistral, OLMo) are finetuned using textual and structural data from the game. Results show that while larger models (particularly GPT-4o) perform better in reasoning and puzzle solving, smaller unadapted models struggle to recognize game mechanics or apply rule changes. Finetuning improves the ability to analyze the game levels, but does not significantly improve solution formulation. We conclude that even for state-of-the-art and finetuned LLMs, reasoning about dynamic rule changes is difficult (specifically, understanding the use-mention distinction). The results provide insights into the applicability of LLMs to complex problem-solving tasks and highlight the suitability of games with dynamically changing rules for testing reasoning and reflection by LLMs.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19095",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÇíÊÇ™Áî®„Åó„ÅüÊîªÊíÉÊâãÊ≥ï3ÈÅ∏„ÄÄÂØæÁ≠ñ„ÅÆËÄÉ„ÅàÊñπ„Å´„ÇÇËª¢Êèõ„ÅåÂøÖË¶ÅÔºàÂâçÁ∑®Ôºâ",
    "description": "AI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆ„Çª„Ç≠„É•„É™„ÉÜ„Ç£ËÑÖÂ®Å„Å´ÂØæ„Åó„ÄÅÂ≠¶Ë°ìÁïå„Å®Áî£Ê•≠Áïå„Åß„ÅØÊñ∞„Åü„Å™ÂØæÁ≠ñ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„ÅÆÊßãÁØâ„ÅåÊ¥ªÁô∫Âåñ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Å©„ÅÆ„Çà„ÅÜ„Å™Êà¶Áï•ÁöÑ„Ç¢„Éó„É≠„Éº„ÉÅ„ÅåÊúâÂäπ„Å™„ÅÆ„Åß„Åó„Çá„ÅÜ„Åã„ÄÇÊúÄÊñ∞„ÅÆÁ†îÁ©∂ÊàêÊûú„ÅåÁ§∫„ÅôÊñ∞„Åó„ÅÑËÑÖÂ®ÅÂàÜÈ°û„Å®„ÄÅ„Åù„Çå„Å´ÂØæÂøú„Åô„ÇãÂåÖÊã¨ÁöÑ„Çª„Ç≠„É•„É™„ÉÜ„Ç£„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„ÅÆË®≠Ë®àÊÄùÊÉ≥„Å´„Å§„ÅÑ„Å¶Ëß£Ë™¨„Åó„Åæ„Åô„ÄÇ",
    "summary": "AI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆ„Çª„Ç≠„É•„É™„ÉÜ„Ç£ËÑÖÂ®Å„Å´ÂØæ„Åó„ÄÅÂ≠¶Ë°ìÁïå„Å®Áî£Ê•≠Áïå„Åß„ÅØÊñ∞„Åü„Å™ÂØæÁ≠ñ„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„ÅÆÊßãÁØâ„ÅåÊ¥ªÁô∫Âåñ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Å©„ÅÆ„Çà„ÅÜ„Å™Êà¶Áï•ÁöÑ„Ç¢„Éó„É≠„Éº„ÉÅ„ÅåÊúâÂäπ„Å™„ÅÆ„Åß„Åó„Çá„ÅÜ„Åã„ÄÇÊúÄÊñ∞„ÅÆÁ†îÁ©∂ÊàêÊûú„ÅåÁ§∫„ÅôÊñ∞„Åó„ÅÑËÑÖÂ®ÅÂàÜÈ°û„Å®„ÄÅ„Åù„Çå„Å´ÂØæÂøú„Åô„ÇãÂåÖÊã¨ÁöÑ„Çª„Ç≠„É•„É™„ÉÜ„Ç£„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„ÅÆË®≠Ë®àÊÄùÊÉ≥„Å´„Å§„ÅÑ„Å¶Ëß£Ë™¨„Åó„Åæ„Åô„ÄÇ",
    "pubDate": "Wed, 25 Jun 2025 10:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/25/news041.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/25/cover_news041.jpg"
  },
  {
    "title": "Hugging Face partners with TruffleHog to Scan for Secrets",
    "description": "",
    "summary": "Hugging Face partners with TruffleHog to Scan for Secrets We're excited to announce our partnership ...",
    "pubDate": "Wed, 04 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trufflesecurity-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/trufflesecurity-partnership/thumbnail.png"
  },
  {
    "title": "Linear-Time Primitives for Algorithm Development in Graphical Causal Inference",
    "description": "arXiv:2506.15758v1 Announce Type: new Abstract: We introduce CIfly, a framework for efficient algorithmic primitives in graphical causal inference that isolates reachability as a reusable core operation. It builds on the insight that many causal reasoning tasks can be reduced to reachability in purpose-built state-space graphs that can be constructed on the fly during traversal. We formalize a rule table schema for specifying such algorithms and prove they run in linear time. We establish CIfly as a more efficient alternative to the common primitives moralization and latent projection, which we show are computationally equivalent to Boolean matrix multiplication. Our open-source Rust implementation parses rule table text files and runs the specified CIfly algorithms providing high-performance execution accessible from Python and R. We demonstrate CIfly's utility by re-implementing a range of established causal inference tasks within the framework and by developing new algorithms for instrumental variables. These contributions position CIfly as a flexible and scalable backbone for graphical causal inference, guiding algorithm development and enabling easy and efficient deployment.",
    "summary": "arXiv:2506.15758v1 Announce Type: new Abstract: We introduce CIfly, a framework for efficient algorithmic primitives in graphical causal inference that isolates reachability as a reusable core operation. It builds on the insight that many causal reasoning tasks can be reduced to reachability in purpose-built state-space graphs that can be constructed on the fly during traversal. We formalize a rule table schema for specifying such algorithms and prove they run in linear time. We establish CIfly as a more efficient alternative to the common primitives moralization and latent projection, which we show are computationally equivalent to Boolean matrix multiplication. Our open-source Rust implementation parses rule table text files and runs the specified CIfly algorithms providing high-performance execution accessible from Python and R. We demonstrate CIfly's utility by re-implementing a range of established causal inference tasks within the framework and by developing new algorithms for instrumental variables. These contributions position CIfly as a flexible and scalable backbone for graphical causal inference, guiding algorithm development and enabling easy and efficient deployment.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15758",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome Gemma 2 - Google's new open LLM",
    "description": "",
    "summary": "Welcome Gemma 2 - Google‚Äôs new open LLM Google released Gemma 2, the latest addition to its family o...",
    "pubDate": "Thu, 27 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma2",
    "thumbnail": "https://huggingface.co/blog/assets/gemma2/thumbnail.jpg"
  },
  {
    "title": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "description": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "summary": "Put AI to Work: Lessons from Hundreds of Successful Deployments",
    "pubDate": "Tue, 10 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-lessons-from-hundreds-of-successful-deployments",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FineVideo: behind the scenes",
    "description": "",
    "summary": "FineVideo: behind the scenes Open video datasets are scarce and therefore slowing down the developme...",
    "pubDate": "Mon, 23 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-video",
    "thumbnail": "https://huggingface.co/blog/assets/186_fine_video/thumbnail.png"
  },
  {
    "title": "Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA",
    "description": "",
    "summary": "Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA LLMs are known to b...",
    "pubDate": "Wed, 24 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/4bit-transformers-bitsandbytes",
    "thumbnail": "https://huggingface.co/blog/assets/96_hf_bitsandbytes_integration/Thumbnail_blue.png"
  },
  {
    "title": "The AI Imperative: Scaling High-Quality Peer Review in Machine Learning",
    "description": "arXiv:2506.08134v3 Announce Type: replace Abstract: Peer review, the bedrock of scientific advancement in machine learning (ML), is strained by a crisis of scale. Exponential growth in manuscript submissions to premier ML venues such as NeurIPS, ICML, and ICLR is outpacing the finite capacity of qualified reviewers, leading to concerns about review quality, consistency, and reviewer fatigue. This position paper argues that AI-assisted peer review must become an urgent research and infrastructure priority. We advocate for a comprehensive AI-augmented ecosystem, leveraging Large Language Models (LLMs) not as replacements for human judgment, but as sophisticated collaborators for authors, reviewers, and Area Chairs (ACs). We propose specific roles for AI in enhancing factual verification, guiding reviewer performance, assisting authors in quality improvement, and supporting ACs in decision-making. Crucially, we contend that the development of such systems hinges on access to more granular, structured, and ethically-sourced peer review process data. We outline a research agenda, including illustrative experiments, to develop and validate these AI assistants, and discuss significant technical and ethical challenges. We call upon the ML community to proactively build this AI-assisted future, ensuring the continued integrity and scalability of scientific validation, while maintaining high standards of peer review.",
    "summary": "arXiv:2506.08134v3 Announce Type: replace Abstract: Peer review, the bedrock of scientific advancement in machine learning (ML), is strained by a crisis of scale. Exponential growth in manuscript submissions to premier ML venues such as NeurIPS, ICML, and ICLR is outpacing the finite capacity of qualified reviewers, leading to concerns about review quality, consistency, and reviewer fatigue. This position paper argues that AI-assisted peer review must become an urgent research and infrastructure priority. We advocate for a comprehensive AI-augmented ecosystem, leveraging Large Language Models (LLMs) not as replacements for human judgment, but as sophisticated collaborators for authors, reviewers, and Area Chairs (ACs). We propose specific roles for AI in enhancing factual verification, guiding reviewer performance, assisting authors in quality improvement, and supporting ACs in decision-making. Crucially, we contend that the development of such systems hinges on access to more granular, structured, and ethically-sourced peer review process data. We outline a research agenda, including illustrative experiments, to develop and validate these AI assistants, and discuss significant technical and ethical challenges. We call upon the ML community to proactively build this AI-assisted future, ensuring the continued integrity and scalability of scientific validation, while maintaining high standards of peer review.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.08134",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Understanding Reasoning in Thinking Language Models via Steering Vectors",
    "description": "arXiv:2506.18167v2 Announce Type: replace-cross Abstract: Recent advances in large language models (LLMs) have led to the development of thinking language models that generate extensive internal reasoning chains before producing responses. While these models achieve improved performance, controlling their reasoning processes remains challenging. This work presents a steering approach for thinking LLMs by analyzing and manipulating specific reasoning behaviors in DeepSeek-R1-Distill models. Through a systematic experiment on 500 tasks across 10 diverse categories, we identify several reasoning behaviors exhibited by thinking models, including expressing uncertainty, generating examples for hypothesis validation, and backtracking in reasoning chains. We demonstrate that these behaviors are mediated by linear directions in the model's activation space and can be controlled using steering vectors. By extracting and applying these vectors, we provide a method to modulate specific aspects of the model's reasoning process, such as its tendency to backtrack or express uncertainty. Our approach offers practical tools for steering reasoning processes in thinking models in a controlled and interpretable manner. We validate our steering method using three DeepSeek-R1-Distill models, demonstrating consistent control across different model architectures.",
    "summary": "arXiv:2506.18167v2 Announce Type: replace-cross Abstract: Recent advances in large language models (LLMs) have led to the development of thinking language models that generate extensive internal reasoning chains before producing responses. While these models achieve improved performance, controlling their reasoning processes remains challenging. This work presents a steering approach for thinking LLMs by analyzing and manipulating specific reasoning behaviors in DeepSeek-R1-Distill models. Through a systematic experiment on 500 tasks across 10 diverse categories, we identify several reasoning behaviors exhibited by thinking models, including expressing uncertainty, generating examples for hypothesis validation, and backtracking in reasoning chains. We demonstrate that these behaviors are mediated by linear directions in the model's activation space and can be controlled using steering vectors. By extracting and applying these vectors, we provide a method to modulate specific aspects of the model's reasoning process, such as its tendency to backtrack or express uncertainty. Our approach offers practical tools for steering reasoning processes in thinking models in a controlled and interpretable manner. We validate our steering method using three DeepSeek-R1-Distill models, demonstrating consistent control across different model architectures.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18167",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "YouTube„ÇÇÊ§úÁ¥¢ÁµêÊûú„Çí‚ÄúAIË¶ÅÁ¥Ñ‚Äù„ÄÄË§áÊï∞ÂãïÁîª„ÅÆË¶ã„Å©„Åì„ÇçË°®Á§∫„ÄÅË™¨ÊòéÊñá„ÇÑ„Çø„Ç§„Éà„É´„ÇÇÁîüÊàê„ÄÄÁ±≥ÂõΩ„Åß",
    "description": "Á±≥YouTube„ÅØ„ÄÅAI„ÇíÊ¥ªÁî®„Åó„ÅüÊ§úÁ¥¢ÁµêÊûú„ÅÆË¶ÅÁ¥ÑÊ©üËÉΩ„ÇíËøΩÂä†„Åó„Åü„Å®Áô∫Ë°®„Åó„Åü„ÄÇÊ§úÁ¥¢„ÉØ„Éº„Éâ„Å´Âøú„Åò„ÄÅË§áÊï∞„ÅÆÂãïÁîª„ÅÆ„Éè„Ç§„É©„Ç§„Éà„Çí„Çπ„É©„Ç§„ÉâÂΩ¢Âºè„ÅßÂº∑Ë™øË°®Á§∫„ÄÇÂêåÊó•„Çà„ÇäÁ±≥ÂõΩ„ÅÆÊúâÊñô‰ºöÂì°„ÄåPremium„Äç„É¶„Éº„Ç∂„ÉºÂêë„Åë„Å´„ÄÅ„Çπ„Éû„Éº„Éà„Éï„Ç©„É≥„Ç¢„Éó„É™„ÅßÊèê‰æõ„Åô„Çã„ÄÇ",
    "summary": "Á±≥YouTube„ÅØ„ÄÅAI„ÇíÊ¥ªÁî®„Åó„ÅüÊ§úÁ¥¢ÁµêÊûú„ÅÆË¶ÅÁ¥ÑÊ©üËÉΩ„ÇíËøΩÂä†„Åó„Åü„Å®Áô∫Ë°®„Åó„Åü„ÄÇÊ§úÁ¥¢„ÉØ„Éº„Éâ„Å´Âøú„Åò„ÄÅË§áÊï∞„ÅÆÂãïÁîª„ÅÆ„Éè„Ç§„É©„Ç§„Éà„Çí„Çπ„É©„Ç§„ÉâÂΩ¢Âºè„ÅßÂº∑Ë™øË°®Á§∫„ÄÇÂêåÊó•„Çà„ÇäÁ±≥ÂõΩ„ÅÆÊúâÊñô‰ºöÂì°„ÄåPremium„Äç„É¶„Éº„Ç∂„ÉºÂêë„Åë„Å´„ÄÅ„Çπ„Éû„Éº„Éà„Éï„Ç©„É≥„Ç¢„Éó„É™„ÅßÊèê‰æõ„Åô„Çã„ÄÇ",
    "pubDate": "Fri, 27 Jun 2025 12:22:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/27/news068.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/27/cover_news068.jpg"
  },
  {
    "title": "GPTs are GPTs: An early look at the labor market impact potential of large language models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpts-are-gpts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ü™Ü Introduction to Matryoshka Embedding Models",
    "description": "",
    "summary": "ü™Ü Introduction to Matryoshka Embedding Models In this blogpost, we will introduce you to the concept...",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/matryoshka",
    "thumbnail": "https://huggingface.co/blog/assets/matryoshka/thumbnail.png"
  },
  {
    "title": "Reimagining secure infrastructure for advanced AI",
    "description": "Securing advanced AI systems will require an evolution in infrastructure security. We‚Äôre calling for research and investment in six security measures that we believe will play key roles in protecting advanced AI. Protecting, exploring, and applying advanced artificial intelligence (AI) is our strategic imperative. OpenAI‚Äôs mission is to deliver positive impact of advanced AI to everything from healthcare to science to education ‚Äì and yes, even to cybersecurity. That work begins with building secure, trustworthy AI systems and protecting the underlying technologies from those who seek to subvert our work to cause harm.",
    "summary": "Securing advanced AI systems will require an evolution in infrastructure security. We‚Äôre calling for research and investment in six security measures that we believe will play key roles in protecting advanced AI. Protecting, exploring, and applying advanced artificial intelligence (AI) is our strategic imperative. OpenAI‚Äôs mission is to deliver positive impact of advanced AI to everything from healthcare to science to education ‚Äì and yes, even to cybersecurity. That work begins with building secure, trustworthy AI systems and protecting the underlying technologies from those who seek to subvert our work to cause harm.",
    "pubDate": "Fri, 03 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reimagining-secure-infrastructure-for-advanced-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Optimizing Bark using ü§ó Transformers",
    "description": "",
    "summary": "Optimizing a Text-To-Speech model using ü§ó Transformers ü§ó Transformers provides many of the latest st...",
    "pubDate": "Wed, 09 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimizing-bark",
    "thumbnail": "https://huggingface.co/blog/assets/bark_optimization/thumbnail.png"
  },
  {
    "title": "How AlphaChip transformed computer chip design",
    "description": "Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world.",
    "summary": "Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world.",
    "pubDate": "Thu, 26 Sep 2024 14:08:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/",
    "thumbnail": "https://lh3.googleusercontent.com/Y_xdq8eqcQlZXYk-MZ2OWPpppmWG6LAQ8DZ-LZFUh8TV5s2TBb3RK_VkMUe-skRzIop5aP6Ot9xPMWFaWmenz55EwxVFCMszpTg2EzsyOd6ftlllGyE=w1200-h630-n-nu"
  },
  {
    "title": "Open R1: How to use OlympicCoder locally for coding?",
    "description": "",
    "summary": "Open R1: How to use OlympicCoder locally for coding Everyone‚Äôs been using Claude and OpenAI as codin...",
    "pubDate": "Thu, 20 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/olympic-coder-lmstudio",
    "thumbnail": "https://huggingface.co/blog/assets/olympic-coder-lmstudio/banner.png"
  },
  {
    "title": "Data Is Better Together: A Look Back and Forward",
    "description": "",
    "summary": "Data Is Better Together: A Look Back and Forward For the past few months, we have been working on th...",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dibt",
    "thumbnail": "https://huggingface.co/blog/assets/dibt/thumbnail.png"
  },
  {
    "title": "Adaptive Guidance Accelerates Reinforcement Learning of Reasoning Models",
    "description": "arXiv:2506.13923v2 Announce Type: replace-cross Abstract: We study the process through which reasoning models trained with reinforcement learning on verifiable rewards (RLVR) can learn to solve new problems. We find that RLVR drives performance in two main ways: (1) by compressing pass@$k$ into pass@1 and (2) via 'capability gain' in which models learn to solve new problems that they previously could not solve even at high $k$. We find that while capability gain exists across model scales, learning to solve new problems is primarily driven through self-distillation. We demonstrate these findings across model scales ranging from 0.5B to 72B parameters on >500,000 reasoning problems with prompts and verifiable final answers across math, science, and code domains. We further show that we can significantly improve pass@$k$ rates by leveraging natural language guidance for the model to consider within context while still requiring the model to derive a solution chain from scratch. Based of these insights, we derive $text{Guide}$ -- a new class of online training algorithms. $text{Guide}$ adaptively incorporates hints into the model's context on problems for which all rollouts were initially incorrect and adjusts the importance sampling ratio for the 'off-policy' trajectories in order to optimize the policy for contexts in which the hints are no longer present. We describe variants of $text{Guide}$ for GRPO and PPO and empirically show that Guide-GRPO on 7B and 32B parameter models improves generalization over its vanilla counterpart with up to 4$%$ macro-average improvement across math benchmarks. We include careful ablations to analyze $text{Guide}$'s components and theoretically analyze Guide's learning efficiency.",
    "summary": "arXiv:2506.13923v2 Announce Type: replace-cross Abstract: We study the process through which reasoning models trained with reinforcement learning on verifiable rewards (RLVR) can learn to solve new problems. We find that RLVR drives performance in two main ways: (1) by compressing pass@$k$ into pass@1 and (2) via 'capability gain' in which models learn to solve new problems that they previously could not solve even at high $k$. We find that while capability gain exists across model scales, learning to solve new problems is primarily driven through self-distillation. We demonstrate these findings across model scales ranging from 0.5B to 72B parameters on >500,000 reasoning problems with prompts and verifiable final answers across math, science, and code domains. We further show that we can significantly improve pass@$k$ rates by leveraging natural language guidance for the model to consider within context while still requiring the model to derive a solution chain from scratch. Based of these insights, we derive $text{Guide}$ -- a new class of online training algorithms. $text{Guide}$ adaptively incorporates hints into the model's context on problems for which all rollouts were initially incorrect and adjusts the importance sampling ratio for the 'off-policy' trajectories in order to optimize the policy for contexts in which the hints are no longer present. We describe variants of $text{Guide}$ for GRPO and PPO and empirically show that Guide-GRPO on 7B and 32B parameter models improves generalization over its vanilla counterpart with up to 4$%$ macro-average improvement across math benchmarks. We include careful ablations to analyze $text{Guide}$'s components and theoretically analyze Guide's learning efficiency.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.13923",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Probabilistic Time Series Forecasting with ü§ó Transformers",
    "description": "",
    "summary": "Probabilistic Time Series Forecasting with ü§ó Transformers Introduction Time series forecasting is an...",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/time-series-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/118_time-series-transformers/thumbnail.png"
  },
  {
    "title": "Dehazing Light Microscopy Images with Guided Conditional Flow Matching: finding a sweet spot between fidelity and realism",
    "description": "arXiv:2506.22397v1 Announce Type: cross Abstract: Fluorescence microscopy is a major driver of scientific progress in the life sciences. Although high-end confocal microscopes are capable of filtering out-of-focus light, cheaper and more accessible microscopy modalities, such as widefield microscopy, can not, which consequently leads to hazy image data. Computational dehazing is trying to combine the best of both worlds, leading to cheap microscopy but crisp-looking images. The perception-distortion trade-off tells us that we can optimize either for data fidelity, e.g. low MSE or high PSNR, or for data realism, measured by perceptual metrics such as LPIPS or FID. Existing methods either prioritize fidelity at the expense of realism, or produce perceptually convincing results that lack quantitative accuracy. In this work, we propose HazeMatching, a novel iterative method for dehazing light microscopy images, which effectively balances these objectives. Our goal was to find a balanced trade-off between the fidelity of the dehazing results and the realism of individual predictions (samples). We achieve this by adapting the conditional flow matching framework by guiding the generative process with a hazy observation in the conditional velocity field. We evaluate HazeMatching on 5 datasets, covering both synthetic and real data, assessing both distortion and perceptual quality. Our method is compared against 7 baselines, achieving a consistent balance between fidelity and realism on average. Additionally, with calibration analysis, we show that HazeMatching produces well-calibrated predictions. Note that our method does not need an explicit degradation operator to exist, making it easily applicable on real microscopy data. All data used for training and evaluation and our code will be publicly available under a permissive license.",
    "summary": "arXiv:2506.22397v1 Announce Type: cross Abstract: Fluorescence microscopy is a major driver of scientific progress in the life sciences. Although high-end confocal microscopes are capable of filtering out-of-focus light, cheaper and more accessible microscopy modalities, such as widefield microscopy, can not, which consequently leads to hazy image data. Computational dehazing is trying to combine the best of both worlds, leading to cheap microscopy but crisp-looking images. The perception-distortion trade-off tells us that we can optimize either for data fidelity, e.g. low MSE or high PSNR, or for data realism, measured by perceptual metrics such as LPIPS or FID. Existing methods either prioritize fidelity at the expense of realism, or produce perceptually convincing results that lack quantitative accuracy. In this work, we propose HazeMatching, a novel iterative method for dehazing light microscopy images, which effectively balances these objectives. Our goal was to find a balanced trade-off between the fidelity of the dehazing results and the realism of individual predictions (samples). We achieve this by adapting the conditional flow matching framework by guiding the generative process with a hazy observation in the conditional velocity field. We evaluate HazeMatching on 5 datasets, covering both synthetic and real data, assessing both distortion and perceptual quality. Our method is compared against 7 baselines, achieving a consistent balance between fidelity and realism on average. Additionally, with calibration analysis, we show that HazeMatching produces well-calibrated predictions. Note that our method does not need an explicit degradation operator to exist, making it easily applicable on real microscopy data. All data used for training and evaluation and our code will be publicly available under a permissive license.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22397",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "New funding to scale the benefits of AI",
    "description": "We are making progress on our mission to ensure that artificial general intelligence benefits all of humanity.",
    "summary": "We are making progress on our mission to ensure that artificial general intelligence benefits all of humanity.",
    "pubDate": "Wed, 02 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scale-the-benefits-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating the Robustness of Dense Retrievers in Interdisciplinary Domains",
    "description": "arXiv:2506.21581v1 Announce Type: cross Abstract: Evaluation benchmark characteristics may distort the true benefits of domain adaptation in retrieval models. This creates misleading assessments that influence deployment decisions in specialized domains. We show that two benchmarks with drastically different features such as topic diversity, boundary overlap, and semantic complexity can influence the perceived benefits of fine-tuning. Using environmental regulatory document retrieval as a case study, we fine-tune ColBERTv2 model on Environmental Impact Statements (EIS) from federal agencies. We evaluate these models across two benchmarks with different semantic structures. Our findings reveal that identical domain adaptation approaches show very different perceived benefits depending on evaluation methodology. On one benchmark, with clearly separated topic boundaries, domain adaptation shows small improvements (maximum 0.61% NDCG gain). However, on the other benchmark with overlapping semantic structures, the same models demonstrate large improvements (up to 2.22% NDCG gain), a 3.6-fold difference in the performance benefit. We compare these benchmarks through topic diversity metrics, finding that the higher-performing benchmark shows 11% higher average cosine distances between contexts and 23% lower silhouette scores, directly contributing to the observed performance difference. These results demonstrate that benchmark selection strongly determines assessments of retrieval system effectiveness in specialized domains. Evaluation frameworks with well-separated topics regularly underestimate domain adaptation benefits, while those with overlapping semantic boundaries reveal improvements that better reflect real-world regulatory document complexity. Our findings have important implications for developing and deploying AI systems for interdisciplinary domains that integrate multiple topics.",
    "summary": "arXiv:2506.21581v1 Announce Type: cross Abstract: Evaluation benchmark characteristics may distort the true benefits of domain adaptation in retrieval models. This creates misleading assessments that influence deployment decisions in specialized domains. We show that two benchmarks with drastically different features such as topic diversity, boundary overlap, and semantic complexity can influence the perceived benefits of fine-tuning. Using environmental regulatory document retrieval as a case study, we fine-tune ColBERTv2 model on Environmental Impact Statements (EIS) from federal agencies. We evaluate these models across two benchmarks with different semantic structures. Our findings reveal that identical domain adaptation approaches show very different perceived benefits depending on evaluation methodology. On one benchmark, with clearly separated topic boundaries, domain adaptation shows small improvements (maximum 0.61% NDCG gain). However, on the other benchmark with overlapping semantic structures, the same models demonstrate large improvements (up to 2.22% NDCG gain), a 3.6-fold difference in the performance benefit. We compare these benchmarks through topic diversity metrics, finding that the higher-performing benchmark shows 11% higher average cosine distances between contexts and 23% lower silhouette scores, directly contributing to the observed performance difference. These results demonstrate that benchmark selection strongly determines assessments of retrieval system effectiveness in specialized domains. Evaluation frameworks with well-separated topics regularly underestimate domain adaptation benefits, while those with overlapping semantic boundaries reveal improvements that better reflect real-world regulatory document complexity. Our findings have important implications for developing and deploying AI systems for interdisciplinary domains that integrate multiple topics.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21581",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Open Arabic LLM Leaderboard 2",
    "description": "",
    "summary": "The Open Arabic LLM Leaderboard 2 Current status of Arabic LLMs leaderboards The growing availabilit...",
    "pubDate": "Mon, 10 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-arabic-v2",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_arabic.png"
  },
  {
    "title": "From General Reasoning to Domain Expertise: Uncovering the Limits of Generalization in Large Language Models",
    "description": "arXiv:2506.21580v1 Announce Type: cross Abstract: Recent advancements in Large Language Models (LLMs) have demonstrated remarkable capabilities in various domains. However, effective decision-making relies heavily on strong reasoning abilities. Reasoning is the foundation for decision-making, providing the analytical and logical framework to make sound choices. Reasoning involves analyzing information, drawing inferences, and reaching conclusions based on logic or evidence. Decision-making builds on this foundation by applying the insights from reasoning to select the best course of action among alternatives. Together, these processes create a continuous cycle of thought and action aimed at achieving goals effectively. As AI technology evolves, there is a growing trend to train LLMs to excel in general reasoning. This study explores how the general reasoning capabilities of LLMs connect to their performance in domain-specific reasoning tasks.",
    "summary": "arXiv:2506.21580v1 Announce Type: cross Abstract: Recent advancements in Large Language Models (LLMs) have demonstrated remarkable capabilities in various domains. However, effective decision-making relies heavily on strong reasoning abilities. Reasoning is the foundation for decision-making, providing the analytical and logical framework to make sound choices. Reasoning involves analyzing information, drawing inferences, and reaching conclusions based on logic or evidence. Decision-making builds on this foundation by applying the insights from reasoning to select the best course of action among alternatives. Together, these processes create a continuous cycle of thought and action aimed at achieving goals effectively. As AI technology evolves, there is a growing trend to train LLMs to excel in general reasoning. This study explores how the general reasoning capabilities of LLMs connect to their performance in domain-specific reasoning tasks.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21580",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GPT-2: 1.5B release",
    "description": "As the final model release of¬†GPT-2‚Äôs¬†staged release, we‚Äôre releasing the largest version (1.5B parameters) of GPT-2 along with¬†code and model weights¬†to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we‚Äôve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we‚Äôre actively continuing the conversation with the AI community on responsible¬†publication.",
    "summary": "As the final model release of¬†GPT-2‚Äôs¬†staged release, we‚Äôre releasing the largest version (1.5B parameters) of GPT-2 along with¬†code and model weights¬†to facilitate detection of outputs of GPT-2 models. While there have been larger language models released since August, we‚Äôve continued with our original staged release plan in order to provide the community with a test case of a full staged release process. We hope that this test case will be useful to developers of future powerful models, and we‚Äôre actively continuing the conversation with the AI community on responsible¬†publication.",
    "pubDate": "Tue, 05 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-2-1-5b-release",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI‚Äôs commitment to child safety: adopting safety by design principles",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/child-safety-adopting-sbd-principles",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LM-SPT: LM-Aligned Semantic Distillation for Speech Tokenization",
    "description": "arXiv:2506.16738v1 Announce Type: cross Abstract: With the rapid progress of speech language models (SLMs), discrete speech tokens have emerged as a core interface between speech and text, enabling unified modeling across modalities. Recent speech tokenization approaches aim to isolate semantic information from low-level acoustics to better align with language models. In particular, previous methods use SSL teachers such as HuBERT to extract semantic representations, which are then distilled into a semantic quantizer to suppress acoustic redundancy as well as capture content-related latent structures. However, they still produce speech token sequences significantly longer than their textual counterparts, creating challenges for efficient speech-language modeling. Reducing the frame rate is a natural solution, but standard techniques, such as rigid average pooling across frames, can distort or dilute the semantic structure required for effective LM alignment. To address this, we propose LM-SPT, a speech tokenization method that introduces a novel semantic distillation. Instead of directly matching teacher and student features via pooling, we reconstruct speech solely from semantic tokens and minimize the discrepancy between the encoded representations of the original and reconstructed waveforms, obtained from a frozen automatic speech recognition (ASR) encoder. This indirect yet data-driven supervision enables the tokenizer to learn discrete units that are more semantically aligned with language models. LM-SPT further incorporates architectural improvements to the encoder and decoder for speech tokenization, and supports multiple frame rates, including 25Hz, 12.5Hz, and 6.25Hz. Experimental results show that LM-SPT achieves superior reconstruction fidelity compared to baselines, and that SLMs trained with LM-SPT tokens achieve competitive performances on speech-to-text and consistently outperform baselines on text-to-speech tasks.",
    "summary": "arXiv:2506.16738v1 Announce Type: cross Abstract: With the rapid progress of speech language models (SLMs), discrete speech tokens have emerged as a core interface between speech and text, enabling unified modeling across modalities. Recent speech tokenization approaches aim to isolate semantic information from low-level acoustics to better align with language models. In particular, previous methods use SSL teachers such as HuBERT to extract semantic representations, which are then distilled into a semantic quantizer to suppress acoustic redundancy as well as capture content-related latent structures. However, they still produce speech token sequences significantly longer than their textual counterparts, creating challenges for efficient speech-language modeling. Reducing the frame rate is a natural solution, but standard techniques, such as rigid average pooling across frames, can distort or dilute the semantic structure required for effective LM alignment. To address this, we propose LM-SPT, a speech tokenization method that introduces a novel semantic distillation. Instead of directly matching teacher and student features via pooling, we reconstruct speech solely from semantic tokens and minimize the discrepancy between the encoded representations of the original and reconstructed waveforms, obtained from a frozen automatic speech recognition (ASR) encoder. This indirect yet data-driven supervision enables the tokenizer to learn discrete units that are more semantically aligned with language models. LM-SPT further incorporates architectural improvements to the encoder and decoder for speech tokenization, and supports multiple frame rates, including 25Hz, 12.5Hz, and 6.25Hz. Experimental results show that LM-SPT achieves superior reconstruction fidelity compared to baselines, and that SLMs trained with LM-SPT tokens achieve competitive performances on speech-to-text and consistently outperform baselines on text-to-speech tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16738",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SENSEI: Semantic Exploration Guided by Foundation Models to Learn Versatile World Models",
    "description": "arXiv:2503.01584v2 Announce Type: replace Abstract: Exploration is a cornerstone of reinforcement learning (RL). Intrinsic motivation attempts to decouple exploration from external, task-based rewards. However, established approaches to intrinsic motivation that follow general principles such as information gain, often only uncover low-level interactions. In contrast, children's play suggests that they engage in meaningful high-level behavior by imitating or interacting with their caregivers. Recent work has focused on using foundation models to inject these semantic biases into exploration. However, these methods often rely on unrealistic assumptions, such as language-embedded environments or access to high-level actions. We propose SEmaNtically Sensible ExploratIon (SENSEI), a framework to equip model-based RL agents with an intrinsic motivation for semantically meaningful behavior. SENSEI distills a reward signal of interestingness from Vision Language Model (VLM) annotations, enabling an agent to predict these rewards through a world model. Using model-based RL, SENSEI trains an exploration policy that jointly maximizes semantic rewards and uncertainty. We show that in both robotic and video game-like simulations SENSEI discovers a variety of meaningful behaviors from image observations and low-level actions. SENSEI provides a general tool for learning from foundation model feedback, a crucial research direction, as VLMs become more powerful.",
    "summary": "arXiv:2503.01584v2 Announce Type: replace Abstract: Exploration is a cornerstone of reinforcement learning (RL). Intrinsic motivation attempts to decouple exploration from external, task-based rewards. However, established approaches to intrinsic motivation that follow general principles such as information gain, often only uncover low-level interactions. In contrast, children's play suggests that they engage in meaningful high-level behavior by imitating or interacting with their caregivers. Recent work has focused on using foundation models to inject these semantic biases into exploration. However, these methods often rely on unrealistic assumptions, such as language-embedded environments or access to high-level actions. We propose SEmaNtically Sensible ExploratIon (SENSEI), a framework to equip model-based RL agents with an intrinsic motivation for semantically meaningful behavior. SENSEI distills a reward signal of interestingness from Vision Language Model (VLM) annotations, enabling an agent to predict these rewards through a world model. Using model-based RL, SENSEI trains an exploration policy that jointly maximizes semantic rewards and uncertainty. We show that in both robotic and video game-like simulations SENSEI discovers a variety of meaningful behaviors from image observations and low-level actions. SENSEI provides a general tool for learning from foundation model feedback, a crucial research direction, as VLMs become more powerful.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.01584",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tune Llama 2 with DPO",
    "description": "",
    "summary": "Fine-tune Llama 2 with DPO Introduction Reinforcement Learning from Human Feedback (RLHF) has become...",
    "pubDate": "Tue, 08 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dpo-trl",
    "thumbnail": "https://huggingface.co/blog/assets/157_dpo_trl/dpo_thumbnail.png"
  },
  {
    "title": "Introducing ü§ó Accelerate",
    "description": "",
    "summary": "Introducing ü§ó Accelerate ü§ó Accelerate Run your raw PyTorch training scripts on any kind of device. M...",
    "pubDate": "Fri, 16 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-library",
    "thumbnail": "https://huggingface.co/blog/assets/20_accelerate_library/accelerate_diff.png"
  },
  {
    "title": "AI Policy: ü§ó Response to the White House AI Action Plan RFI",
    "description": "",
    "summary": "AI Policy @ü§ó: Response to the White House AI Action Plan RFI On March 14, we submitted Hugging Face'...",
    "pubDate": "Wed, 19 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-action-wh-2025",
    "thumbnail": "https://huggingface.co/blog/assets/151_policy_ntia_rfc/us_policy_thumbnail.png"
  },
  {
    "title": "Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit",
    "description": "arXiv:2506.21990v1 Announce Type: cross Abstract: The developments in transformer encoder-decoder architectures have led to significant breakthroughs in machine translation, Automatic Speech Recognition (ASR), and instruction-based chat machines, among other applications. The pre-trained models were trained on vast amounts of generic data over a few epochs (fewer than five in most cases), resulting in their strong generalization capabilities. Nevertheless, the performance of these models does suffer when applied to niche domains like transcribing pilot speech in the cockpit, which involves a lot of specific vocabulary and multilingual conversations. This paper investigates and improves the transcription accuracy of cockpit conversations with Whisper models. We have collected around 85 minutes of cockpit simulator recordings and 130 minutes of interview recordings with pilots and manually labeled them. The speakers are middle aged men speaking both German and English. To improve the accuracy of transcriptions, we propose multiple normalization schemes to refine the transcripts and improve Word Error Rate (WER). We then employ fine-tuning to enhance ASR performance, utilizing performance-efficient fine-tuning with Low-Rank Adaptation (LoRA). Hereby, WER decreased from 68.49 % (pretrained whisper Large model without normalization baseline) to 26.26% (finetuned whisper Large model with the proposed normalization scheme).",
    "summary": "arXiv:2506.21990v1 Announce Type: cross Abstract: The developments in transformer encoder-decoder architectures have led to significant breakthroughs in machine translation, Automatic Speech Recognition (ASR), and instruction-based chat machines, among other applications. The pre-trained models were trained on vast amounts of generic data over a few epochs (fewer than five in most cases), resulting in their strong generalization capabilities. Nevertheless, the performance of these models does suffer when applied to niche domains like transcribing pilot speech in the cockpit, which involves a lot of specific vocabulary and multilingual conversations. This paper investigates and improves the transcription accuracy of cockpit conversations with Whisper models. We have collected around 85 minutes of cockpit simulator recordings and 130 minutes of interview recordings with pilots and manually labeled them. The speakers are middle aged men speaking both German and English. To improve the accuracy of transcriptions, we propose multiple normalization schemes to refine the transcripts and improve Word Error Rate (WER). We then employ fine-tuning to enhance ASR performance, utilizing performance-efficient fine-tuning with Low-Rank Adaptation (LoRA). Hereby, WER decreased from 68.49 % (pretrained whisper Large model without normalization baseline) to 26.26% (finetuned whisper Large model with the proposed normalization scheme).",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21990",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Bringing the Magic of AI to Mattel‚Äôs Iconic Brands",
    "description": "OpenAI and Mattel are partnering to integrate AI into iconic brands such as Barbie and Hot Wheels, aiming to enhance creative development, streamline workflows, and create new ways for fans to engage.",
    "summary": "OpenAI and Mattel are partnering to integrate AI into iconic brands such as Barbie and Hot Wheels, aiming to enhance creative development, streamline workflows, and create new ways for fans to engage.",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mattels-iconic-brands",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-tuning now available for GPT-4o",
    "description": "Fine-tune custom versions of GPT-4o to increase performance and accuracy for your applications",
    "summary": "Fine-tune custom versions of GPT-4o to increase performance and accuracy for your applications",
    "pubDate": "Tue, 20 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-fine-tuning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing GPTs",
    "description": "You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills.",
    "summary": "You can now create custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills.",
    "pubDate": "Mon, 06 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-gpts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Adapting Whisper for Parameter-efficient Code-Switching Speech Recognition via Soft Prompt Tuning",
    "description": "arXiv:2506.21576v1 Announce Type: cross Abstract: Large-scale multilingual ASR models like Whisper excel in high-resource settings but face challenges in low-resource scenarios, such as rare languages and code-switching (CS), due to computational costs and catastrophic forgetting. We explore Soft Prompt Tuning (SPT), a parameter-efficient method to enhance CS ASR while preserving prior knowledge. We evaluate two strategies: (1) full fine-tuning (FFT) of both soft prompts and the entire Whisper model, demonstrating improved cross-lingual capabilities compared to traditional methods, and (2) adhering to SPT's original design by freezing model parameters and only training soft prompts. Additionally, we introduce SPT4ASR, a combination of different SPT variants. Experiments on the SEAME and ASRU2019 datasets show that deep prompt tuning is the most effective SPT approach, and our SPT4ASR methods achieve further error reductions in CS ASR, maintaining parameter efficiency similar to LoRA, without degrading performance on existing languages.",
    "summary": "arXiv:2506.21576v1 Announce Type: cross Abstract: Large-scale multilingual ASR models like Whisper excel in high-resource settings but face challenges in low-resource scenarios, such as rare languages and code-switching (CS), due to computational costs and catastrophic forgetting. We explore Soft Prompt Tuning (SPT), a parameter-efficient method to enhance CS ASR while preserving prior knowledge. We evaluate two strategies: (1) full fine-tuning (FFT) of both soft prompts and the entire Whisper model, demonstrating improved cross-lingual capabilities compared to traditional methods, and (2) adhering to SPT's original design by freezing model parameters and only training soft prompts. Additionally, we introduce SPT4ASR, a combination of different SPT variants. Experiments on the SEAME and ASRU2019 datasets show that deep prompt tuning is the most effective SPT approach, and our SPT4ASR methods achieve further error reductions in CS ASR, maintaining parameter efficiency similar to LoRA, without degrading performance on existing languages.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21576",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Exploring simple optimizations for SDXL",
    "description": "",
    "summary": "Exploring simple optimizations for SDXL Stable Diffusion XL (SDXL) is the latest latent diffusion mo...",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/simple_sdxl_optimizations",
    "thumbnail": "https://huggingface.co/blog/assets/simple_sdxl_optimizations/thumbnail.png"
  },
  {
    "title": "Sora is here",
    "description": "Our video generation model, Sora, is now available to use at sora.com. Users can generate videos up to 1080p resolution, up to 20 sec long, and in widescreen, vertical or square aspect ratios. You can bring your own assets to extend, remix, and blend, or generate entirely new content from text.",
    "summary": "Our video generation model, Sora, is now available to use at sora.com. Users can generate videos up to 1080p resolution, up to 20 sec long, and in widescreen, vertical or square aspect ratios. You can bring your own assets to extend, remix, and blend, or generate entirely new content from text.",
    "pubDate": "Mon, 09 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-is-here",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New compliance and administrative tools for ChatGPT Enterprise",
    "description": "Compliance API integrations, SCIM, and GPT controls to support compliance programs, data security, and user access at scale",
    "summary": "Compliance API integrations, SCIM, and GPT controls to support compliance programs, data security, and user access at scale",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-for-chatgpt-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "StackLLaMA: A hands-on guide to train LLaMA with RLHF",
    "description": "",
    "summary": "StackLLaMA: A hands-on guide to train LLaMA with RLHF Models such as ChatGPT, GPT-4, and Claude are ...",
    "pubDate": "Wed, 05 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stackllama",
    "thumbnail": "https://huggingface.co/blog/assets/138_stackllama/thumbnail.png"
  },
  {
    "title": "Faster Assisted Generation with Dynamic Speculation",
    "description": "",
    "summary": "Faster Assisted Generation with Dynamic Speculation ‚≠ê In this blog post, we‚Äôll explore dynamic specu...",
    "pubDate": "Tue, 08 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dynamic_speculation_lookahead",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Do We Need Large VLMs for Spotting Soccer Actions?",
    "description": "arXiv:2506.17144v1 Announce Type: cross Abstract: Traditional video-based tasks like soccer action spotting rely heavily on visual inputs, often requiring complex and computationally expensive models to process dense video data. In this work, we propose a shift from this video-centric approach to a text-based task, making it lightweight and scalable by utilizing Large Language Models (LLMs) instead of Vision-Language Models (VLMs). We posit that expert commentary, which provides rich, fine-grained descriptions and contextual cues such as excitement and tactical insights, contains enough information to reliably spot key actions in a match. To demonstrate this, we use the SoccerNet Echoes dataset, which provides timestamped commentary, and employ a system of three LLMs acting as judges specializing in outcome, excitement, and tactics. Each LLM evaluates sliding windows of commentary to identify actions like goals, cards, and substitutions, generating accurate timestamps for these events. Our experiments show that this language-centric approach performs effectively in detecting critical match events, providing a lightweight and training-free alternative to traditional video-based methods for action spotting.",
    "summary": "arXiv:2506.17144v1 Announce Type: cross Abstract: Traditional video-based tasks like soccer action spotting rely heavily on visual inputs, often requiring complex and computationally expensive models to process dense video data. In this work, we propose a shift from this video-centric approach to a text-based task, making it lightweight and scalable by utilizing Large Language Models (LLMs) instead of Vision-Language Models (VLMs). We posit that expert commentary, which provides rich, fine-grained descriptions and contextual cues such as excitement and tactical insights, contains enough information to reliably spot key actions in a match. To demonstrate this, we use the SoccerNet Echoes dataset, which provides timestamped commentary, and employ a system of three LLMs acting as judges specializing in outcome, excitement, and tactics. Each LLM evaluates sliding windows of commentary to identify actions like goals, cards, and substitutions, generating accurate timestamps for these events. Our experiments show that this language-centric approach performs effectively in detecting critical match events, providing a lightweight and training-free alternative to traditional video-based methods for action spotting.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17144",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PaliGemma 2 Mix - New Instruction Vision Language Models by Google",
    "description": "",
    "summary": "PaliGemma 2 Mix - New Instruction Vision Language Models by Google TL;DR Last December, Google relea...",
    "pubDate": "Wed, 19 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma2mix",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma2/thumbnail.png"
  },
  {
    "title": "Introducing OpenAI",
    "description": "OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact.",
    "summary": "OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. Since our research is free from financial obligations, we can better focus on a positive human impact.",
    "pubDate": "Fri, 11 Dec 2015 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Banque des Territoires (CDC Group) x Polyconseil x Hugging Face: Enhancing a Major French Environmental Program with a Sovereign Data Solution",
    "description": "",
    "summary": "Banque des Territoires (CDC Group) x Polyconseil x Hugging Face: Enhancing a Major French Environmen...",
    "pubDate": "Tue, 09 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sovereign-data-solution-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/cdc_poly_hf.png"
  },
  {
    "title": "FermiNet: Quantum physics and chemistry from first principles",
    "description": "Using deep learning to solve fundamental problems in computational quantum chemistry and explore how matter interacts with light",
    "summary": "Using deep learning to solve fundamental problems in computational quantum chemistry and explore how matter interacts with light",
    "pubDate": "Thu, 22 Aug 2024 19:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ferminet-quantum-physics-and-chemistry-from-first-principles/",
    "thumbnail": "https://lh3.googleusercontent.com/u-LZOO0ynV2UCorbNrUtWS6MJ_sxTfGzObe2YzBt5Grgohx39WcsGiPNOsHwBja8C51lQBclpaovrzUVVQRzj2WpWeM7f7y5eeYt3Dx6l3gxfx9S9g=w1200-h630-n-nu"
  },
  {
    "title": "FFJORD: Free-form continuous dynamics for scalable reversible generative models",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 02 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ffjord",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "No More Sliding Window: Efficient 3D Medical Image Segmentation with Differentiable Top-k Patch Sampling",
    "description": "arXiv:2501.10814v3 Announce Type: replace-cross Abstract: 3D models surpass 2D models in CT/MRI segmentation by effectively capturing inter-slice relationships. However, the added depth dimension substantially increases memory consumption. While patch-based training alleviates memory constraints, it significantly slows down the inference speed due to the sliding window (SW) approach. We propose No-More-Sliding-Window (NMSW), a novel end-to-end trainable framework that enhances the efficiency of generic 3D segmentation backbone during an inference step by eliminating the need for SW. NMSW employs a differentiable Top-k module to selectively sample only the most relevant patches, thereby minimizing redundant computations. When patch-level predictions are insufficient, the framework intelligently leverages coarse global predictions to refine results. Evaluated across 3 tasks using 3 segmentation backbones, NMSW achieves competitive accuracy compared to SW inference while significantly reducing computational complexity by 91% (88.0 to 8.00 TMACs). Moreover, it delivers a 9.1x faster inference on the H100 GPU (99.0 to 8.3 sec) and a 11.1x faster inference on the Xeon Gold CPU (2110 to 189 sec). NMSW is model-agnostic, further boosting efficiency when integrated with any existing efficient segmentation backbones. The code is avaialble: https://github.com/Youngseok0001/open_nmsw.",
    "summary": "arXiv:2501.10814v3 Announce Type: replace-cross Abstract: 3D models surpass 2D models in CT/MRI segmentation by effectively capturing inter-slice relationships. However, the added depth dimension substantially increases memory consumption. While patch-based training alleviates memory constraints, it significantly slows down the inference speed due to the sliding window (SW) approach. We propose No-More-Sliding-Window (NMSW), a novel end-to-end trainable framework that enhances the efficiency of generic 3D segmentation backbone during an inference step by eliminating the need for SW. NMSW employs a differentiable Top-k module to selectively sample only the most relevant patches, thereby minimizing redundant computations. When patch-level predictions are insufficient, the framework intelligently leverages coarse global predictions to refine results. Evaluated across 3 tasks using 3 segmentation backbones, NMSW achieves competitive accuracy compared to SW inference while significantly reducing computational complexity by 91% (88.0 to 8.00 TMACs). Moreover, it delivers a 9.1x faster inference on the H100 GPU (99.0 to 8.3 sec) and a 11.1x faster inference on the Xeon Gold CPU (2110 to 189 sec). NMSW is model-agnostic, further boosting efficiency when integrated with any existing efficient segmentation backbones. The code is avaialble: https://github.com/Youngseok0001/open_nmsw.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.10814",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Finding GPT-4‚Äôs mistakes with GPT-4",
    "description": "CriticGPT, a model based on GPT-4, writes critiques of ChatGPT responses to help human trainers spot mistakes during RLHF",
    "summary": "CriticGPT, a model based on GPT-4, writes critiques of ChatGPT responses to help human trainers spot mistakes during RLHF",
    "pubDate": "Thu, 27 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/finding-gpt4s-mistakes-with-gpt-4",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Train your first Decision Transformer",
    "description": "",
    "summary": "Train your first Decision Transformer In a previous post, we announced the launch of Decision Transf...",
    "pubDate": "Thu, 08 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-decision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/101_train-decision-transformers/thumbnail.gif"
  },
  {
    "title": "Ingredients for robotics research",
    "description": "We‚Äôre releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience Replay, all developed for our research over the past year. We‚Äôve used these environments to train models which work on physical robots. We‚Äôre also releasing a set of requests for robotics research.",
    "summary": "We‚Äôre releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience Replay, all developed for our research over the past year. We‚Äôve used these environments to train models which work on physical robots. We‚Äôre also releasing a set of requests for robotics research.",
    "pubDate": "Mon, 26 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ingredients-for-robotics-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DeepSelective: Interpretable Prognosis Prediction via Feature Selection and Compression in EHR Data",
    "description": "arXiv:2504.11264v2 Announce Type: replace-cross Abstract: The rapid accumulation of Electronic Health Records (EHRs) has transformed healthcare by providing valuable data that enhance clinical predictions and diagnoses. While conventional machine learning models have proven effective, they often lack robust representation learning and depend heavily on expert-crafted features. Although deep learning offers powerful solutions, it is often criticized for its lack of interpretability. To address these challenges, we propose DeepSelective, a novel end to end deep learning framework for predicting patient prognosis using EHR data, with a strong emphasis on enhancing model interpretability. DeepSelective combines data compression techniques with an innovative feature selection approach, integrating custom-designed modules that work together to improve both accuracy and interpretability. Our experiments demonstrate that DeepSelective not only enhances predictive accuracy but also significantly improves interpretability, making it a valuable tool for clinical decision-making. The source code is freely available at http://www.healthinformaticslab.org/supp/resources.php .",
    "summary": "arXiv:2504.11264v2 Announce Type: replace-cross Abstract: The rapid accumulation of Electronic Health Records (EHRs) has transformed healthcare by providing valuable data that enhance clinical predictions and diagnoses. While conventional machine learning models have proven effective, they often lack robust representation learning and depend heavily on expert-crafted features. Although deep learning offers powerful solutions, it is often criticized for its lack of interpretability. To address these challenges, we propose DeepSelective, a novel end to end deep learning framework for predicting patient prognosis using EHR data, with a strong emphasis on enhancing model interpretability. DeepSelective combines data compression techniques with an innovative feature selection approach, integrating custom-designed modules that work together to improve both accuracy and interpretability. Our experiments demonstrate that DeepSelective not only enhances predictive accuracy but also significantly improves interpretability, making it a valuable tool for clinical decision-making. The source code is freely available at http://www.healthinformaticslab.org/supp/resources.php .",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.11264",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Pull Requests and Discussions ü•≥",
    "description": "",
    "summary": "Introducing Pull Requests and Discussions ü•≥ We are thrilled to announce the release of our latest co...",
    "pubDate": "Wed, 25 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-update",
    "thumbnail": "https://huggingface.co/blog/assets/76_community_update/thumbnail.png"
  },
  {
    "title": "FANZAÂêå‰∫∫„ÄÅAIÁîüÊàê‰ΩúÂìÅ„Çí„Éà„ÉÉ„Éó„Éö„Éº„Ç∏„Å™„Å©„Åã„ÇâÈô§Â§ñ„Å∏„ÄÄÂÖ∑‰ΩìÁöÑ„Å™‰ªïÊßò„ÅØ„ÄåÂøÖË¶Å„Å´Âøú„Åò„Å¶ÂëäÁü•„Äç„Å®ÈÅãÂñ∂ÂÖÉ",
    "description": "Êàê‰∫∫Âêë„ÅëÂêå‰∫∫‰ΩúÂìÅ„ÅÆEC„Çµ„Ç§„Éà„ÄåFANZAÂêå‰∫∫„Äç„ÅÆ„Éà„ÉÉ„Éó„Éö„Éº„Ç∏„Å™„Å©„Åã„ÇâAIÁîüÊàê‰ΩúÂìÅ„ÇíÈô§Â§ñ„Åô„Çã‚Äï‚ÄïFANZAÈÅãÂñ∂ÂÖÉ„ÅÆ„Éá„Ç∏„Çø„É´„Ç≥„Éû„Éº„Çπ„ÅØ„ÄÅÂêå‰∫∫„Çµ„Éº„ÇØ„É´Âêë„Åë„Å´„Åì„ÅÆ„Çà„ÅÜ„Å™ÂëäÁü•„Çí„Åó„Åü„Å®„ÄÅITmedia AIÔºãÁ∑®ÈõÜÈÉ®„ÅÆÂèñÊùê„Å´ÂØæ„Åó„Å¶Êòé„Åã„Åó„Åü„ÄÇ",
    "summary": "Êàê‰∫∫Âêë„ÅëÂêå‰∫∫‰ΩúÂìÅ„ÅÆEC„Çµ„Ç§„Éà„ÄåFANZAÂêå‰∫∫„Äç„ÅÆ„Éà„ÉÉ„Éó„Éö„Éº„Ç∏„Å™„Å©„Åã„ÇâAIÁîüÊàê‰ΩúÂìÅ„ÇíÈô§Â§ñ„Åô„Çã‚Äï‚ÄïFANZAÈÅãÂñ∂ÂÖÉ„ÅÆ„Éá„Ç∏„Çø„É´„Ç≥„Éû„Éº„Çπ„ÅØ„ÄÅÂêå‰∫∫„Çµ„Éº„ÇØ„É´Âêë„Åë„Å´„Åì„ÅÆ„Çà„ÅÜ„Å™ÂëäÁü•„Çí„Åó„Åü„Å®„ÄÅITmedia AIÔºãÁ∑®ÈõÜÈÉ®„ÅÆÂèñÊùê„Å´ÂØæ„Åó„Å¶Êòé„Åã„Åó„Åü„ÄÇ",
    "pubDate": "Tue, 24 Jun 2025 07:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/24/news053.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/24/cover_news053.jpg"
  },
  {
    "title": "Experiment with Gemini 2.0 Flash native image generation",
    "description": "Native image output is available in Gemini 2.0 Flash for developers to experiment with in Google AI Studio and the Gemini API.",
    "summary": "Native image output is available in Gemini 2.0 Flash for developers to experiment with in Google AI Studio and the Gemini API.",
    "pubDate": "Wed, 12 Mar 2025 14:58:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/experiment-with-gemini-20-flash-native-image-generation/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-image-generation_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Dynamic Risk Assessments for Offensive Cybersecurity Agents",
    "description": "arXiv:2505.18384v2 Announce Type: replace-cross Abstract: Foundation models are increasingly becoming better autonomous programmers, raising the prospect that they could also automate dangerous offensive cyber-operations. Current frontier model audits probe the cybersecurity risks of such agents, but most fail to account for the degrees of freedom available to adversaries in the real world. In particular, with strong verifiers and financial incentives, agents for offensive cybersecurity are amenable to iterative improvement by would-be adversaries. We argue that assessments should take into account an expanded threat model in the context of cybersecurity, emphasizing the varying degrees of freedom that an adversary may possess in stateful and non-stateful environments within a fixed compute budget. We show that even with a relatively small compute budget (8 H100 GPU Hours in our study), adversaries can improve an agent's cybersecurity capability on InterCode CTF by more than 40% relative to the baseline -- without any external assistance. These results highlight the need to evaluate agents' cybersecurity risk in a dynamic manner, painting a more representative picture of risk.",
    "summary": "arXiv:2505.18384v2 Announce Type: replace-cross Abstract: Foundation models are increasingly becoming better autonomous programmers, raising the prospect that they could also automate dangerous offensive cyber-operations. Current frontier model audits probe the cybersecurity risks of such agents, but most fail to account for the degrees of freedom available to adversaries in the real world. In particular, with strong verifiers and financial incentives, agents for offensive cybersecurity are amenable to iterative improvement by would-be adversaries. We argue that assessments should take into account an expanded threat model in the context of cybersecurity, emphasizing the varying degrees of freedom that an adversary may possess in stateful and non-stateful environments within a fixed compute budget. We show that even with a relatively small compute budget (8 H100 GPU Hours in our study), adversaries can improve an agent's cybersecurity capability on InterCode CTF by more than 40% relative to the baseline -- without any external assistance. These results highlight the need to evaluate agents' cybersecurity risk in a dynamic manner, painting a more representative picture of risk.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.18384",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Exploring Quantization Backends in Diffusers",
    "description": "",
    "summary": "Exploring Quantization Backends in Diffusers Large diffusion models like Flux (a flow-based text-to-...",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers-quantization/thumbnail.png"
  },
  {
    "title": "Getting Started with Hugging Face Transformers for IPUs with Optimum",
    "description": "",
    "summary": "Getting Started with Hugging Face Transformers for IPUs with Optimum Transformer models have proven ...",
    "pubDate": "Tue, 30 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore-getting-started",
    "thumbnail": "https://huggingface.co/blog/assets/38_getting_started_graphcore/graphcore_1.png"
  },
  {
    "title": "Developing reliable AI tools for healthcare",
    "description": "We‚Äôve published our joint paper with Google Research in Nature Medicine, which proposes CoDoC (Complementarity-driven Deferral-to-Clinical Workflow), an AI system that learns when to rely on predictive AI tools or defer to a clinician for the most accurate interpretation of medical images.",
    "summary": "We‚Äôve published our joint paper with Google Research in Nature Medicine, which proposes CoDoC (Complementarity-driven Deferral-to-Clinical Workflow), an AI system that learns when to rely on predictive AI tools or defer to a clinician for the most accurate interpretation of medical images.",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/codoc-developing-reliable-ai-tools-for-healthcare/",
    "thumbnail": "https://lh3.googleusercontent.com/JCyH0sgVtuYFCB0n7g6f2NMV19yeAgvxQBqcfy9H_-DP_aW3k5h4i0bcZ9_9KCExs7rXRrCaC6s21uK5Udap6tX3zy96zOdn8YcF5WIxAFzUgru6Nw=w1200-h630-n-nu"
  },
  {
    "title": "On Path to Multimodal Historical Reasoning: HistBench and HistAgent",
    "description": "arXiv:2505.20246v3 Announce Type: replace Abstract: Recent advances in large language models (LLMs) have led to remarkable progress across domains, yet their capabilities in the humanities, particularly history, remain underexplored. Historical reasoning poses unique challenges for AI, involving multimodal source interpretation, temporal inference, and cross-linguistic analysis. While general-purpose agents perform well on many existing benchmarks, they lack the domain-specific expertise required to engage with historical materials and questions. To address this gap, we introduce HistBench, a new benchmark of 414 high-quality questions designed to evaluate AI's capacity for historical reasoning and authored by more than 40 expert contributors. The tasks span a wide range of historical problems-from factual retrieval based on primary sources to interpretive analysis of manuscripts and images, to interdisciplinary challenges involving archaeology, linguistics, or cultural history. Furthermore, the benchmark dataset spans 29 ancient and modern languages and covers a wide range of historical periods and world regions. Finding the poor performance of LLMs and other agents on HistBench, we further present HistAgent, a history-specific agent equipped with carefully designed tools for OCR, translation, archival search, and image understanding in History. On HistBench, HistAgent based on GPT-4o achieves an accuracy of 27.54% pass@1 and 36.47% pass@2, significantly outperforming LLMs with online search and generalist agents, including GPT-4o (18.60%), DeepSeek-R1(14.49%) and Open Deep Research-smolagents(20.29% pass@1 and 25.12% pass@2). These results highlight the limitations of existing LLMs and generalist agents and demonstrate the advantages of HistAgent for historical reasoning.",
    "summary": "arXiv:2505.20246v3 Announce Type: replace Abstract: Recent advances in large language models (LLMs) have led to remarkable progress across domains, yet their capabilities in the humanities, particularly history, remain underexplored. Historical reasoning poses unique challenges for AI, involving multimodal source interpretation, temporal inference, and cross-linguistic analysis. While general-purpose agents perform well on many existing benchmarks, they lack the domain-specific expertise required to engage with historical materials and questions. To address this gap, we introduce HistBench, a new benchmark of 414 high-quality questions designed to evaluate AI's capacity for historical reasoning and authored by more than 40 expert contributors. The tasks span a wide range of historical problems-from factual retrieval based on primary sources to interpretive analysis of manuscripts and images, to interdisciplinary challenges involving archaeology, linguistics, or cultural history. Furthermore, the benchmark dataset spans 29 ancient and modern languages and covers a wide range of historical periods and world regions. Finding the poor performance of LLMs and other agents on HistBench, we further present HistAgent, a history-specific agent equipped with carefully designed tools for OCR, translation, archival search, and image understanding in History. On HistBench, HistAgent based on GPT-4o achieves an accuracy of 27.54% pass@1 and 36.47% pass@2, significantly outperforming LLMs with online search and generalist agents, including GPT-4o (18.60%), DeepSeek-R1(14.49%) and Open Deep Research-smolagents(20.29% pass@1 and 25.12% pass@2). These results highlight the limitations of existing LLMs and generalist agents and demonstrate the advantages of HistAgent for historical reasoning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.20246",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Programming Distributed Collective Processes in the eXchange Calculus",
    "description": "arXiv:2401.11212v4 Announce Type: replace-cross Abstract: Recent trends like the Internet of Things (IoT) suggest a vision of dense and multi-scale deployments of computing devices in nearly all kinds of environments. A prominent engineering challenge revolves around programming the collective adaptive behaviour of such computational ecosystems. This requires abstractions able to capture concepts like ensembles (dynamic groups of cooperating devices) and collective tasks (joint activities carried out by ensembles). In this work, we consider collections of devices interacting with neighbours and that execute in nearly-synchronised sense-compute-interact rounds, where the computation is given by a single program mapping sensing values and incoming messages to output and outcoming messages. To support programming whole computational collectives, we propose the abstraction of a distributed collective process, which can be used to define at once the ensemble formation logic and its collective task. We formalise the abstraction in the eXchange Calculus (XC), a core functional language based on neighbouring values (maps from neighbours to values) where state and interaction is handled through a single primitive, exchange, and provide a corresponding implementation in the FCPP language. Then, we exercise distributed collective processes using two case studies: multi-hop message propagation and distributed monitoring of spatial properties. Finally, we discuss the features of the abstraction and its suitability for different kinds of distributed computing applications.",
    "summary": "arXiv:2401.11212v4 Announce Type: replace-cross Abstract: Recent trends like the Internet of Things (IoT) suggest a vision of dense and multi-scale deployments of computing devices in nearly all kinds of environments. A prominent engineering challenge revolves around programming the collective adaptive behaviour of such computational ecosystems. This requires abstractions able to capture concepts like ensembles (dynamic groups of cooperating devices) and collective tasks (joint activities carried out by ensembles). In this work, we consider collections of devices interacting with neighbours and that execute in nearly-synchronised sense-compute-interact rounds, where the computation is given by a single program mapping sensing values and incoming messages to output and outcoming messages. To support programming whole computational collectives, we propose the abstraction of a distributed collective process, which can be used to define at once the ensemble formation logic and its collective task. We formalise the abstraction in the eXchange Calculus (XC), a core functional language based on neighbouring values (maps from neighbours to values) where state and interaction is handled through a single primitive, exchange, and provide a corresponding implementation in the FCPP language. Then, we exercise distributed collective processes using two case studies: multi-hop message propagation and distributed monitoring of spatial properties. Finally, we discuss the features of the abstraction and its suitability for different kinds of distributed computing applications.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2401.11212",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Llama 3.1 - 405B, 70B & 8B with multilinguality and long context",
    "description": "",
    "summary": "Llama 3.1 - 405B, 70B & 8B with multilinguality and long context Llama 3.1 is out! Today we welcome ...",
    "pubDate": "Tue, 23 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama31",
    "thumbnail": "https://huggingface.co/blog/assets/llama31/thumbnail.jpg"
  },
  {
    "title": "Evolved Policy Gradients",
    "description": "We‚Äôre releasing an experimental metalearning approach called Evolved Policy Gradients, a method that evolves the loss function of learning agents, which can enable fast training on novel tasks. Agents trained with EPG can succeed at basic tasks at test time that were outside their training regime, like learning to navigate to an object on a different side of the room from where it was placed during training.",
    "summary": "We‚Äôre releasing an experimental metalearning approach called Evolved Policy Gradients, a method that evolves the loss function of learning agents, which can enable fast training on novel tasks. Agents trained with EPG can succeed at basic tasks at test time that were outside their training regime, like learning to navigate to an object on a different side of the room from where it was placed during training.",
    "pubDate": "Wed, 18 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolved-policy-gradients",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Using GPT-4o reasoning to transform cancer care",
    "description": "Color Health is working with OpenAI to pioneer a new way of accelerating cancer patients‚Äô access to treatment. Their new Cancer Copilot application uses GPT-4o to identify missing diagnostics and create tailored workup plans, enabling healthcare providers to make evidence-based decisions about cancer screening and treatment.",
    "summary": "Color Health is working with OpenAI to pioneer a new way of accelerating cancer patients‚Äô access to treatment. Their new Cancer Copilot application uses GPT-4o to identify missing diagnostics and create tailored workup plans, enabling healthcare providers to make evidence-based decisions about cancer screening and treatment.",
    "pubDate": "Mon, 17 Jun 2024 04:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/color-health",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Watermarking Autoregressive Image Generation",
    "description": "arXiv:2506.16349v1 Announce Type: cross Abstract: Watermarking the outputs of generative models has emerged as a promising approach for tracking their provenance. Despite significant interest in autoregressive image generation models and their potential for misuse, no prior work has attempted to watermark their outputs at the token level. In this work, we present the first such approach by adapting language model watermarking techniques to this setting. We identify a key challenge: the lack of reverse cycle-consistency (RCC), wherein re-tokenizing generated image tokens significantly alters the token sequence, effectively erasing the watermark. To address this and to make our method robust to common image transformations, neural compression, and removal attacks, we introduce (i) a custom tokenizer-detokenizer finetuning procedure that improves RCC, and (ii) a complementary watermark synchronization layer. As our experiments demonstrate, our approach enables reliable and robust watermark detection with theoretically grounded p-values.",
    "summary": "arXiv:2506.16349v1 Announce Type: cross Abstract: Watermarking the outputs of generative models has emerged as a promising approach for tracking their provenance. Despite significant interest in autoregressive image generation models and their potential for misuse, no prior work has attempted to watermark their outputs at the token level. In this work, we present the first such approach by adapting language model watermarking techniques to this setting. We identify a key challenge: the lack of reverse cycle-consistency (RCC), wherein re-tokenizing generated image tokens significantly alters the token sequence, effectively erasing the watermark. To address this and to make our method robust to common image transformations, neural compression, and removal attacks, we introduce (i) a custom tokenizer-detokenizer finetuning procedure that improves RCC, and (ii) a complementary watermark synchronization layer. As our experiments demonstrate, our approach enables reliable and robust watermark detection with theoretically grounded p-values.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16349",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI and Microsoft",
    "description": "We‚Äôre working with Microsoft to start running most of our large-scale experiments on Azure.",
    "summary": "We‚Äôre working with Microsoft to start running most of our large-scale experiments on Azure.",
    "pubDate": "Tue, 15 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-microsoft",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From memories to maps: Mechanisms of in context reinforcement learning in transformers",
    "description": "arXiv:2506.19686v1 Announce Type: new Abstract: Humans and animals show remarkable learning efficiency, adapting to new environments with minimal experience. This capability is not well captured by standard reinforcement learning algorithms that rely on incremental value updates. Rapid adaptation likely depends on episodic memory -- the ability to retrieve specific past experiences to guide decisions in novel contexts. Transformers provide a useful setting for studying these questions because of their ability to learn rapidly in-context and because their key-value architecture resembles episodic memory systems in the brain. We train a transformer to in-context reinforcement learn in a distribution of planning tasks inspired by rodent behavior. We then characterize the learning algorithms that emerge in the model. We first find that representation learning is supported by in-context structure learning and cross-context alignment, where representations are aligned across environments with different sensory stimuli. We next demonstrate that the reinforcement learning strategies developed by the model are not interpretable as standard model-free or model-based planning. Instead, we show that in-context reinforcement learning is supported by caching intermediate computations within the model's memory tokens, which are then accessed at decision time. Overall, we find that memory may serve as a computational resource, storing both raw experience and cached computations to support flexible behavior. Furthermore, the representations developed in the model resemble computations associated with the hippocampal-entorhinal system in the brain, suggesting that our findings may be relevant for natural cognition. Taken together, our work offers a mechanistic hypothesis for the rapid adaptation that underlies in-context learning in artificial and natural settings.",
    "summary": "arXiv:2506.19686v1 Announce Type: new Abstract: Humans and animals show remarkable learning efficiency, adapting to new environments with minimal experience. This capability is not well captured by standard reinforcement learning algorithms that rely on incremental value updates. Rapid adaptation likely depends on episodic memory -- the ability to retrieve specific past experiences to guide decisions in novel contexts. Transformers provide a useful setting for studying these questions because of their ability to learn rapidly in-context and because their key-value architecture resembles episodic memory systems in the brain. We train a transformer to in-context reinforcement learn in a distribution of planning tasks inspired by rodent behavior. We then characterize the learning algorithms that emerge in the model. We first find that representation learning is supported by in-context structure learning and cross-context alignment, where representations are aligned across environments with different sensory stimuli. We next demonstrate that the reinforcement learning strategies developed by the model are not interpretable as standard model-free or model-based planning. Instead, we show that in-context reinforcement learning is supported by caching intermediate computations within the model's memory tokens, which are then accessed at decision time. Overall, we find that memory may serve as a computational resource, storing both raw experience and cached computations to support flexible behavior. Furthermore, the representations developed in the model resemble computations associated with the hippocampal-entorhinal system in the brain, suggesting that our findings may be relevant for natural cognition. Taken together, our work offers a mechanistic hypothesis for the rapid adaptation that underlies in-context learning in artificial and natural settings.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19686",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evolutionary Level Repair",
    "description": "arXiv:2506.19359v1 Announce Type: new Abstract: We address the problem of game level repair, which consists of taking a designed but non-functional game level and making it functional. This might consist of ensuring the completeness of the level, reachability of objects, or other performance characteristics. The repair problem may also be constrained in that it can only make a small number of changes to the level. We investigate search-based solutions to the level repair problem, particularly using evolutionary and quality-diversity algorithms, with good results. This level repair method is applied to levels generated using a machine learning-based procedural content generation (PCGML) method that generates stylistically appropriate but frequently broken levels. This combination of PCGML for generation and search-based methods for repair shows great promise as a hybrid procedural content generation (PCG) method.",
    "summary": "arXiv:2506.19359v1 Announce Type: new Abstract: We address the problem of game level repair, which consists of taking a designed but non-functional game level and making it functional. This might consist of ensuring the completeness of the level, reachability of objects, or other performance characteristics. The repair problem may also be constrained in that it can only make a small number of changes to the level. We investigate search-based solutions to the level repair problem, particularly using evolutionary and quality-diversity algorithms, with good results. This level repair method is applied to levels generated using a machine learning-based procedural content generation (PCGML) method that generates stylistically appropriate but frequently broken levels. This combination of PCGML for generation and search-based methods for repair shows great promise as a hybrid procedural content generation (PCG) method.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19359",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Advancing Stochastic 3-SAT Solvers by Dissipating Oversatisfied Constraints",
    "description": "arXiv:2506.15774v1 Announce Type: new Abstract: We introduce and benchmark a stochastic local search heuristic for the NP-complete satisfiability problem 3-SAT that drastically outperforms existing solvers in the notoriously difficult realm of critically hard instances. Our construction is based on the crucial observation that well established previous approaches such as WalkSAT are prone to get stuck in local minima that are distinguished from true solutions by a larger number of oversatisfied combinatorial constraints. To address this issue, the proposed algorithm, coined DOCSAT, dissipates oversatisfied constraints (DOC), i.e. reduces their unfavorable abundance so as to render them critical. We analyze and benchmark our algorithm on a randomly generated sample of hard but satisfiable 3-SAT instances with varying problem sizes up to N=15000. Quite remarkably, we find that DOCSAT outperforms both WalkSAT and other well known algorithms including the complete solver Kissat, even when comparing its ability to solve the hardest quintile of the sample to the average performance of its competitors. The essence of DOCSAT may be seen as a way of harnessing statistical structure beyond the primary cost function of a combinatorial problem to avoid or escape local minima traps in stochastic local search, which opens avenues for generalization to other optimization problems.",
    "summary": "arXiv:2506.15774v1 Announce Type: new Abstract: We introduce and benchmark a stochastic local search heuristic for the NP-complete satisfiability problem 3-SAT that drastically outperforms existing solvers in the notoriously difficult realm of critically hard instances. Our construction is based on the crucial observation that well established previous approaches such as WalkSAT are prone to get stuck in local minima that are distinguished from true solutions by a larger number of oversatisfied combinatorial constraints. To address this issue, the proposed algorithm, coined DOCSAT, dissipates oversatisfied constraints (DOC), i.e. reduces their unfavorable abundance so as to render them critical. We analyze and benchmark our algorithm on a randomly generated sample of hard but satisfiable 3-SAT instances with varying problem sizes up to N=15000. Quite remarkably, we find that DOCSAT outperforms both WalkSAT and other well known algorithms including the complete solver Kissat, even when comparing its ability to solve the hardest quintile of the sample to the average performance of its competitors. The essence of DOCSAT may be seen as a way of harnessing statistical structure beyond the primary cost function of a combinatorial problem to avoid or escape local minima traps in stochastic local search, which opens avenues for generalization to other optimization problems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15774",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLM-Based Bot Broadens the Range of Arguments in Online Discussions, Even When Transparently Disclosed as AI",
    "description": "arXiv:2506.17073v1 Announce Type: cross Abstract: A wide range of participation is essential for democracy, as it helps prevent the dominance of extreme views, erosion of legitimacy, and political polarization. However, engagement in online political discussions often features a limited spectrum of views due to high levels of self-selection and the tendency of online platforms to facilitate exchanges primarily among like-minded individuals. This study examines whether an LLM-based bot can widen the scope of perspectives expressed by participants in online discussions through two pre-registered randomized experiments conducted in a chatroom. We evaluate the impact of a bot that actively monitors discussions, identifies missing arguments, and introduces them into the conversation. The results indicate that our bot significantly expands the range of arguments, as measured by both objective and subjective metrics. Furthermore, disclosure of the bot as AI does not significantly alter these effects. These findings suggest that LLM-based moderation tools can positively influence online political discourse.",
    "summary": "arXiv:2506.17073v1 Announce Type: cross Abstract: A wide range of participation is essential for democracy, as it helps prevent the dominance of extreme views, erosion of legitimacy, and political polarization. However, engagement in online political discussions often features a limited spectrum of views due to high levels of self-selection and the tendency of online platforms to facilitate exchanges primarily among like-minded individuals. This study examines whether an LLM-based bot can widen the scope of perspectives expressed by participants in online discussions through two pre-registered randomized experiments conducted in a chatroom. We evaluate the impact of a bot that actively monitors discussions, identifies missing arguments, and introduces them into the conversation. The results indicate that our bot significantly expands the range of arguments, as measured by both objective and subjective metrics. Furthermore, disclosure of the bot as AI does not significantly alter these effects. These findings suggest that LLM-based moderation tools can positively influence online political discourse.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17073",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Start building with Gemini 2.0 Flash and Flash-Lite",
    "description": "Gemini 2.0 Flash-Lite is now generally available in the Gemini API for production use in Google AI Studio and for enterprise customers on Vertex AI",
    "summary": "Gemini 2.0 Flash-Lite is now generally available in the Gemini API for production use in Google AI Studio and for enterprise customers on Vertex AI",
    "pubDate": "Tue, 25 Feb 2025 18:02:12 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/start-building-with-gemini-20-flash-and-flash-lite/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Flash_Family_meta.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Hello GPT-4o",
    "description": "We‚Äôre announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.",
    "summary": "We‚Äôre announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.",
    "pubDate": "Mon, 13 May 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hello-gpt-4o",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing data residency in Asia",
    "description": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "summary": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "pubDate": "Wed, 07 May 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-data-residency-in-asia",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Conformal Inference under High-Dimensional Covariate Shifts via Likelihood-Ratio Regularization",
    "description": "arXiv:2502.13030v4 Announce Type: replace-cross Abstract: We consider the problem of conformal prediction under covariate shift. Given labeled data from a source domain and unlabeled data from a covariate shifted target domain, we seek to construct prediction sets with valid marginal coverage in the target domain. Most existing methods require estimating the unknown likelihood ratio function, which can be prohibitive for high-dimensional data such as images. To address this challenge, we introduce the likelihood ratio regularized quantile regression (LR-QR) algorithm, which combines the pinball loss with a novel choice of regularization in order to construct a threshold function without directly estimating the unknown likelihood ratio. We show that the LR-QR method has coverage at the desired level in the target domain, up to a small error term that we can control. Our proofs draw on a novel analysis of coverage via stability bounds from learning theory. Our experiments demonstrate that the LR-QR algorithm outperforms existing methods on high-dimensional prediction tasks, including a regression task for the Communities and Crime dataset, an image classification task from the WILDS repository, and an LLM question-answering task on the MMLU benchmark.",
    "summary": "arXiv:2502.13030v4 Announce Type: replace-cross Abstract: We consider the problem of conformal prediction under covariate shift. Given labeled data from a source domain and unlabeled data from a covariate shifted target domain, we seek to construct prediction sets with valid marginal coverage in the target domain. Most existing methods require estimating the unknown likelihood ratio function, which can be prohibitive for high-dimensional data such as images. To address this challenge, we introduce the likelihood ratio regularized quantile regression (LR-QR) algorithm, which combines the pinball loss with a novel choice of regularization in order to construct a threshold function without directly estimating the unknown likelihood ratio. We show that the LR-QR method has coverage at the desired level in the target domain, up to a small error term that we can control. Our proofs draw on a novel analysis of coverage via stability bounds from learning theory. Our experiments demonstrate that the LR-QR algorithm outperforms existing methods on high-dimensional prediction tasks, including a regression task for the Communities and Crime dataset, an image classification task from the WILDS repository, and an LLM question-answering task on the MMLU benchmark.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.13030",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ASR-enhanced Multimodal Representation Learning for Cross-Domain Product Retrieval",
    "description": "arXiv:2408.02978v2 Announce Type: replace-cross Abstract: E-commerce is increasingly multimedia-enriched, with products exhibited in a broad-domain manner as images, short videos, or live stream promotions. A unified and vectorized cross-domain production representation is essential. Due to large intra-product variance and high inter-product similarity in the broad-domain scenario, a visual-only representation is inadequate. While Automatic Speech Recognition (ASR) text derived from the short or live-stream videos is readily accessible, how to de-noise the excessively noisy text for multimodal representation learning is mostly untouched. We propose ASR-enhanced Multimodal Product Representation Learning (AMPere). In order to extract product-specific information from the raw ASR text, AMPere uses an easy-to-implement LLM-based ASR text summarizer. The LLM-summarized text, together with visual data, is then fed into a multi-branch network to generate compact multimodal embeddings. Extensive experiments on a large-scale tri-domain dataset verify the effectiveness of AMPere in obtaining a unified multimodal product representation that clearly improves cross-domain product retrieval.",
    "summary": "arXiv:2408.02978v2 Announce Type: replace-cross Abstract: E-commerce is increasingly multimedia-enriched, with products exhibited in a broad-domain manner as images, short videos, or live stream promotions. A unified and vectorized cross-domain production representation is essential. Due to large intra-product variance and high inter-product similarity in the broad-domain scenario, a visual-only representation is inadequate. While Automatic Speech Recognition (ASR) text derived from the short or live-stream videos is readily accessible, how to de-noise the excessively noisy text for multimodal representation learning is mostly untouched. We propose ASR-enhanced Multimodal Product Representation Learning (AMPere). In order to extract product-specific information from the raw ASR text, AMPere uses an easy-to-implement LLM-based ASR text summarizer. The LLM-summarized text, together with visual data, is then fed into a multi-branch network to generate compact multimodal embeddings. Extensive experiments on a large-scale tri-domain dataset verify the effectiveness of AMPere in obtaining a unified multimodal product representation that clearly improves cross-domain product retrieval.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.02978",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerating over 130,000 Hugging Face models with ONNX Runtime",
    "description": "",
    "summary": "Accelerating over 130,000 Hugging Face models with ONNX Runtime What is ONNX Runtime? ONNX Runtime i...",
    "pubDate": "Wed, 04 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ort-accelerating-hf-models",
    "thumbnail": "https://huggingface.co/blog/assets/ort_accelerating_hf_models/thumbnail.png"
  },
  {
    "title": "Accelerating Document AI",
    "description": "",
    "summary": "Accelerating Document AI Enterprises are full of documents containing knowledge that isn't accessibl...",
    "pubDate": "Mon, 21 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/document-ai",
    "thumbnail": "https://huggingface.co/blog/assets/112_document-ai/thumbnail.png"
  },
  {
    "title": "Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion",
    "description": "arXiv:2506.15981v1 Announce Type: cross Abstract: The rapid advancement of AI-based music generation tools is revolutionizing the music industry but also posing challenges to artists, copyright holders, and providers alike. This necessitates reliable methods for detecting such AI-generated content. However, existing detectors, relying on either audio or lyrics, face key practical limitations: audio-based detectors fail to generalize to new or unseen generators and are vulnerable to audio perturbations; lyrics-based methods require cleanly formatted and accurate lyrics, unavailable in practice. To overcome these limitations, we propose a novel, practically grounded approach: a multimodal, modular late-fusion pipeline that combines automatically transcribed sung lyrics and speech features capturing lyrics-related information within the audio. By relying on lyrical aspects directly from audio, our method enhances robustness, mitigates susceptibility to low-level artifacts, and enables practical applicability. Experiments show that our method, DE-detect, outperforms existing lyrics-based detectors while also being more robust to audio perturbations. Thus, it offers an effective, robust solution for detecting AI-generated music in real-world scenarios. Our code is available at https://github.com/deezer/robust-AI-lyrics-detection.",
    "summary": "arXiv:2506.15981v1 Announce Type: cross Abstract: The rapid advancement of AI-based music generation tools is revolutionizing the music industry but also posing challenges to artists, copyright holders, and providers alike. This necessitates reliable methods for detecting such AI-generated content. However, existing detectors, relying on either audio or lyrics, face key practical limitations: audio-based detectors fail to generalize to new or unseen generators and are vulnerable to audio perturbations; lyrics-based methods require cleanly formatted and accurate lyrics, unavailable in practice. To overcome these limitations, we propose a novel, practically grounded approach: a multimodal, modular late-fusion pipeline that combines automatically transcribed sung lyrics and speech features capturing lyrics-related information within the audio. By relying on lyrical aspects directly from audio, our method enhances robustness, mitigates susceptibility to low-level artifacts, and enables practical applicability. Experiments show that our method, DE-detect, outperforms existing lyrics-based detectors while also being more robust to audio perturbations. Thus, it offers an effective, robust solution for detecting AI-generated music in real-world scenarios. Our code is available at https://github.com/deezer/robust-AI-lyrics-detection.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15981",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Collective Reasoning Among LLMs: A Framework for Answer Validation Without Ground Truth",
    "description": "arXiv:2502.20758v2 Announce Type: replace-cross Abstract: We introduce a new approach in which several advanced large language models-specifically GPT-4-0125-preview, Meta-LLAMA-3-70B-Instruct, Claude-3-Opus, and Gemini-1.5-Flash-collaborate to both produce and answer intricate, doctoral-level probability problems without relying on any single 'correct' reference. Rather than depending on an established ground truth, our investigation focuses on how agreement among diverse models can signal the reliability of their outputs and, by extension, reflect the overall quality of the generated questions. To measure this inter-model alignment, we apply a suite of statistical evaluations, including chi-square tests, Fleiss' Kappa coefficients, and confidence interval calculations, thereby capturing both precision in answers and clarity in question phrasing. Our analysis reveals that Claude and Gemini tend to frame questions more coherently and unambiguously, which is evidenced by their tighter confidence intervals and greater concordance with responding agents. In contrast, LLAMA exhibits wider confidence bands and a lower level of agreement, indicating more variability and reduced consistency in its question formulations. These observations support the notion that a multi-model collaborative strategy not only improves answer dependability but also offers an effective, data-driven mechanism for evaluating and refining question quality when no definitive solution exists. Ultimately, this work delivers actionable insights into enhancing AI-guided reasoning processes through coordinated interactions among heterogeneous language models.",
    "summary": "arXiv:2502.20758v2 Announce Type: replace-cross Abstract: We introduce a new approach in which several advanced large language models-specifically GPT-4-0125-preview, Meta-LLAMA-3-70B-Instruct, Claude-3-Opus, and Gemini-1.5-Flash-collaborate to both produce and answer intricate, doctoral-level probability problems without relying on any single 'correct' reference. Rather than depending on an established ground truth, our investigation focuses on how agreement among diverse models can signal the reliability of their outputs and, by extension, reflect the overall quality of the generated questions. To measure this inter-model alignment, we apply a suite of statistical evaluations, including chi-square tests, Fleiss' Kappa coefficients, and confidence interval calculations, thereby capturing both precision in answers and clarity in question phrasing. Our analysis reveals that Claude and Gemini tend to frame questions more coherently and unambiguously, which is evidenced by their tighter confidence intervals and greater concordance with responding agents. In contrast, LLAMA exhibits wider confidence bands and a lower level of agreement, indicating more variability and reduced consistency in its question formulations. These observations support the notion that a multi-model collaborative strategy not only improves answer dependability but also offers an effective, data-driven mechanism for evaluating and refining question quality when no definitive solution exists. Ultimately, this work delivers actionable insights into enhancing AI-guided reasoning processes through coordinated interactions among heterogeneous language models.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.20758",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Generating Human-level Text with Contrastive Search in Transformers ü§ó",
    "description": "",
    "summary": "Generating Human-level Text with Contrastive Search in Transformers ü§ó 1. Introduction: Natural langu...",
    "pubDate": "Tue, 08 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-csearch",
    "thumbnail": "https://huggingface.co/blog/assets/115_introducing_contrastive_search/thumbnail.png"
  },
  {
    "title": "The Elements of Differentiable Programming",
    "description": "arXiv:2403.14606v3 Announce Type: replace-cross Abstract: Artificial intelligence has recently experienced remarkable advances, fueled by large models, vast datasets, accelerated hardware, and, last but not least, the transformative power of differentiable programming. This new programming paradigm enables end-to-end differentiation of complex computer programs (including those with control flows and data structures), making gradient-based optimization of program parameters possible. As an emerging paradigm, differentiable programming builds upon several areas of computer science and applied mathematics, including automatic differentiation, graphical models, optimization and statistics. This book presents a comprehensive review of the fundamental concepts useful for differentiable programming. We adopt two main perspectives, that of optimization and that of probability, with clear analogies between the two. Differentiable programming is not merely the differentiation of programs, but also the thoughtful design of programs intended for differentiation. By making programs differentiable, we inherently introduce probability distributions over their execution, providing a means to quantify the uncertainty associated with program outputs.",
    "summary": "arXiv:2403.14606v3 Announce Type: replace-cross Abstract: Artificial intelligence has recently experienced remarkable advances, fueled by large models, vast datasets, accelerated hardware, and, last but not least, the transformative power of differentiable programming. This new programming paradigm enables end-to-end differentiation of complex computer programs (including those with control flows and data structures), making gradient-based optimization of program parameters possible. As an emerging paradigm, differentiable programming builds upon several areas of computer science and applied mathematics, including automatic differentiation, graphical models, optimization and statistics. This book presents a comprehensive review of the fundamental concepts useful for differentiable programming. We adopt two main perspectives, that of optimization and that of probability, with clear analogies between the two. Differentiable programming is not merely the differentiation of programs, but also the thoughtful design of programs intended for differentiation. By making programs differentiable, we inherently introduce probability distributions over their execution, providing a means to quantify the uncertainty associated with program outputs.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2403.14606",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ShapeLib: Designing a library of programmatic 3D shape abstractions with Large Language Models",
    "description": "arXiv:2502.08884v2 Announce Type: replace-cross Abstract: We present ShapeLib, the first method that leverages the priors of LLMs to design libraries of programmatic 3D shape abstractions. Our system accepts two forms of design intent: text descriptions of functions to include in the library and a seed set of exemplar shapes. We discover abstractions that match this design intent with a guided LLM workflow that first proposes, and then validates, different ways of applying and implementing functions. We learn recognition networks that map shapes to programs with these newly discovered abstractions by training on data produced by LLM authored synthetic data generation procedures. Across modeling domains (split by shape category), we find that LLMs, when thoughtfully combined with geometric reasoning, can be guided to author a library of abstraction functions that generalize to shapes outside of the seed set. This framework addresses a long-standing shape analysis problem of how to discover reusable abstraction functions while exposing interpretable, semantically aligned interfaces. We find that ShapeLib provides distinct advantages over prior alternative abstraction discovery works in terms of generalization, usability, and maintaining plausibility under manipulation. Finally, we demonstrate that ShapeLib's abstraction functions unlock a number of downstream applications, combining LLM reasoning over shape programs with geometry processing to support shape editing and generation.",
    "summary": "arXiv:2502.08884v2 Announce Type: replace-cross Abstract: We present ShapeLib, the first method that leverages the priors of LLMs to design libraries of programmatic 3D shape abstractions. Our system accepts two forms of design intent: text descriptions of functions to include in the library and a seed set of exemplar shapes. We discover abstractions that match this design intent with a guided LLM workflow that first proposes, and then validates, different ways of applying and implementing functions. We learn recognition networks that map shapes to programs with these newly discovered abstractions by training on data produced by LLM authored synthetic data generation procedures. Across modeling domains (split by shape category), we find that LLMs, when thoughtfully combined with geometric reasoning, can be guided to author a library of abstraction functions that generalize to shapes outside of the seed set. This framework addresses a long-standing shape analysis problem of how to discover reusable abstraction functions while exposing interpretable, semantically aligned interfaces. We find that ShapeLib provides distinct advantages over prior alternative abstraction discovery works in terms of generalization, usability, and maintaining plausibility under manipulation. Finally, we demonstrate that ShapeLib's abstraction functions unlock a number of downstream applications, combining LLM reasoning over shape programs with geometry processing to support shape editing and generation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.08884",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Convert Transformers to ONNX with Hugging Face Optimum",
    "description": "",
    "summary": "Convert Transformers to ONNX with Hugging Face Optimum Hundreds of Transformers experiments and mode...",
    "pubDate": "Wed, 22 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/convert-transformers-to-onnx",
    "thumbnail": "https://huggingface.co/blog/assets/81_convert_transformers_to_onnx/thumbnail.png"
  },
  {
    "title": "Getting Started with Sentiment Analysis using Python",
    "description": "",
    "summary": "Getting Started with Sentiment Analysis using Python Sentiment analysis is the automated process of ...",
    "pubDate": "Wed, 02 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-python",
    "thumbnail": "https://huggingface.co/blog/assets/50_sentiment_python/thumbnail.png"
  },
  {
    "title": "Elon Musk wanted an OpenAI for-profit",
    "description": "Elon Musk‚Äôs latest legal filing against OpenAI marks his fourth attempt in less than a year to reframe his claims. However, his own words and actions speak for themselves‚Äîin 2017, Elon not only wanted, but actually created, a for-profit as OpenAI‚Äôs proposed new structure.",
    "summary": "Elon Musk‚Äôs latest legal filing against OpenAI marks his fourth attempt in less than a year to reframe his claims. However, his own words and actions speak for themselves‚Äîin 2017, Elon not only wanted, but actually created, a for-profit as OpenAI‚Äôs proposed new structure.",
    "pubDate": "Fri, 13 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/elon-musk-wanted-an-openai-for-profit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Enhancing Object Detection Robustness: Detecting and Restoring Confidence in the Presence of Adversarial Patch Attacks",
    "description": "arXiv:2403.12988v2 Announce Type: replace-cross Abstract: The widespread adoption of computer vision systems has underscored their susceptibility to adversarial attacks, particularly adversarial patch attacks on object detectors. This study evaluates defense mechanisms for the YOLOv5 model against such attacks. Optimized adversarial patches were generated and placed in sensitive image regions, by applying EigenCAM and grid search to determine optimal placement. We tested several defenses, including Segment and Complete (SAC), Inpainting, and Latent Diffusion Models. Our pipeline comprises three main stages: patch application, object detection, and defense analysis. Results indicate that adversarial patches reduce average detection confidence by 22.06%. Defenses restored confidence levels by 3.45% (SAC), 5.05% (Inpainting), and significantly improved them by 26.61%, which even exceeds the original accuracy levels, when using the Latent Diffusion Model, highlighting its superior effectiveness in mitigating the effects of adversarial patches.",
    "summary": "arXiv:2403.12988v2 Announce Type: replace-cross Abstract: The widespread adoption of computer vision systems has underscored their susceptibility to adversarial attacks, particularly adversarial patch attacks on object detectors. This study evaluates defense mechanisms for the YOLOv5 model against such attacks. Optimized adversarial patches were generated and placed in sensitive image regions, by applying EigenCAM and grid search to determine optimal placement. We tested several defenses, including Segment and Complete (SAC), Inpainting, and Latent Diffusion Models. Our pipeline comprises three main stages: patch application, object detection, and defense analysis. Results indicate that adversarial patches reduce average detection confidence by 22.06%. Defenses restored confidence levels by 3.45% (SAC), 5.05% (Inpainting), and significantly improved them by 26.61%, which even exceeds the original accuracy levels, when using the Latent Diffusion Model, highlighting its superior effectiveness in mitigating the effects of adversarial patches.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2403.12988",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI GPT-4.5 System Card",
    "description": "We‚Äôre releasing a research preview of OpenAI GPT‚Äë4.5, our largest and most knowledgeable model yet.",
    "summary": "We‚Äôre releasing a research preview of OpenAI GPT‚Äë4.5, our largest and most knowledgeable model yet.",
    "pubDate": "Thu, 27 Feb 2025 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-5-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SigLIP 2: A better multilingual vision language encoder",
    "description": "",
    "summary": "SigLIP 2: A better multilingual vision language encoder TL;DR Today Google releases a new and better...",
    "pubDate": "Fri, 21 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/siglip2",
    "thumbnail": "https://huggingface.co/blog/assets/siglip2/thumbnail.png"
  },
  {
    "title": "Fine-Tune Whisper with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune Whisper For Multilingual ASR with ü§ó Transformers In this blog, we present a step-by-step g...",
    "pubDate": "Thu, 03 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-whisper",
    "thumbnail": "https://huggingface.co/blog/assets/111_fine_tune_whisper/thumbnail.jpg"
  },
  {
    "title": "Introducing the LiveCodeBench Leaderboard - Holistic and Contamination-Free Evaluation of Code LLMs",
    "description": "",
    "summary": "Introducing the LiveCodeBench Leaderboard - Holistic and Contamination-Free Evaluation of Code LLMs ...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-livecodebench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "On Training-Test (Mis)alignment in Unsupervised Combinatorial Optimization: Observation, Empirical Exploration, and Analysis",
    "description": "arXiv:2506.16732v1 Announce Type: cross Abstract: In unsupervised combinatorial optimization (UCO), during training, one aims to have continuous decisions that are promising in a probabilistic sense for each training instance, which enables end-to-end training on initially discrete and non-differentiable problems. At the test time, for each test instance, starting from continuous decisions, derandomization is typically applied to obtain the final deterministic decisions. Researchers have developed more and more powerful test-time derandomization schemes to enhance the empirical performance and the theoretical guarantee of UCO methods. However, we notice a misalignment between training and testing in the existing UCO methods. Consequently, lower training losses do not necessarily entail better post-derandomization performance, even for the training instances without any data distribution shift. Empirically, we indeed observe such undesirable cases. We explore a preliminary idea to better align training and testing in UCO by including a differentiable version of derandomization into training. Our empirical exploration shows that such an idea indeed improves training-test alignment, but also introduces nontrivial challenges into training.",
    "summary": "arXiv:2506.16732v1 Announce Type: cross Abstract: In unsupervised combinatorial optimization (UCO), during training, one aims to have continuous decisions that are promising in a probabilistic sense for each training instance, which enables end-to-end training on initially discrete and non-differentiable problems. At the test time, for each test instance, starting from continuous decisions, derandomization is typically applied to obtain the final deterministic decisions. Researchers have developed more and more powerful test-time derandomization schemes to enhance the empirical performance and the theoretical guarantee of UCO methods. However, we notice a misalignment between training and testing in the existing UCO methods. Consequently, lower training losses do not necessarily entail better post-derandomization performance, even for the training instances without any data distribution shift. Empirically, we indeed observe such undesirable cases. We explore a preliminary idea to better align training and testing in UCO by including a differentiable version of derandomization into training. Our empirical exploration shows that such an idea indeed improves training-test alignment, but also introduces nontrivial challenges into training.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16732",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "No Free Lunch: Rethinking Internal Feedback for LLM Reasoning",
    "description": "arXiv:2506.17219v1 Announce Type: cross Abstract: Reinforcement learning has emerged as a powerful paradigm for post-training large language models (LLMs) to improve reasoning. Approaches like Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with Verifiable Rewards (RLVR) have shown strong results, but they require extensive external supervision. We investigate an alternative class of methods, Reinforcement Learning from Internal Feedback (RLIF), which relies solely on intrinsic model-derived signals instead of external rewards. In particular, we leverage unsupervised reward proxies such as token-level entropy, trajectory-level entropy, and self-certainty. Our theoretical analysis shows these internal objectives are partially equivalent, and we empirically evaluate various RLIF strategies on challenging math reasoning benchmarks. Experimental results demonstrate that RLIF can boost the reasoning performance of base LLMs at the beginning phase of the training, matching or surpassing RLVR techniques on these tasks. However, when training progresses, performance degrades even below the model before training. Moreover, we find that RLIF yields little improvement for instruction-tuned models, indicating diminishing returns of intrinsic feedback once an LLM is already instruction-tuned. We further analyze this limitation by mixing model weights and explain the reason of RLIF's training behaviors, providing practical guidelines for integrating internal feedback signals into LLM training. We hope our analysis of internal feedback will inform more principled and effective strategies for LLM post-training.",
    "summary": "arXiv:2506.17219v1 Announce Type: cross Abstract: Reinforcement learning has emerged as a powerful paradigm for post-training large language models (LLMs) to improve reasoning. Approaches like Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with Verifiable Rewards (RLVR) have shown strong results, but they require extensive external supervision. We investigate an alternative class of methods, Reinforcement Learning from Internal Feedback (RLIF), which relies solely on intrinsic model-derived signals instead of external rewards. In particular, we leverage unsupervised reward proxies such as token-level entropy, trajectory-level entropy, and self-certainty. Our theoretical analysis shows these internal objectives are partially equivalent, and we empirically evaluate various RLIF strategies on challenging math reasoning benchmarks. Experimental results demonstrate that RLIF can boost the reasoning performance of base LLMs at the beginning phase of the training, matching or surpassing RLVR techniques on these tasks. However, when training progresses, performance degrades even below the model before training. Moreover, we find that RLIF yields little improvement for instruction-tuned models, indicating diminishing returns of intrinsic feedback once an LLM is already instruction-tuned. We further analyze this limitation by mixing model weights and explain the reason of RLIF's training behaviors, providing practical guidelines for integrating internal feedback signals into LLM training. We hope our analysis of internal feedback will inform more principled and effective strategies for LLM post-training.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17219",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing GPT-4o and more tools to ChatGPT free users",
    "description": "Introducing GPT-4o and more tools to ChatGPT free users We are launching our newest flagship model and making more capabilities available for free in ChatGPT.",
    "summary": "Introducing GPT-4o and more tools to ChatGPT free users We are launching our newest flagship model and making more capabilities available for free in ChatGPT.",
    "pubDate": "Mon, 13 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-and-more-tools-to-chatgpt-free",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building a custom math tutor powered by ChatGPT",
    "description": "ChatGPT and personal tutoring",
    "summary": "ChatGPT and personal tutoring",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/my-dog-the-math-tutor",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An early warning system for novel AI risks",
    "description": "New research proposes a framework for evaluating general-purpose models against novel threats",
    "summary": "New research proposes a framework for evaluating general-purpose models against novel threats",
    "pubDate": "Thu, 25 May 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/an-early-warning-system-for-novel-ai-risks/",
    "thumbnail": "https://lh3.googleusercontent.com/REkFCC8KEOAocMWBwcHOxKM6K2zRs_qpMeUhnmHYkkGSbPPCLRhPDluhoZzx2k6_b4XvgZmhUqeuko9BXZZIPLmGR1q4BycDjLuDFQ5G5FDYPKD0x08=w1200-h630-n-nu"
  },
  {
    "title": "Hugging Face on AMD Instinct MI300 GPU",
    "description": "",
    "summary": "Hugging Face on AMD Instinct MI300 GPU Join the next Hugging Cast on June 6th to ask questions to th...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-amd-mi300",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "Putting ethical principles at the core of research lifecycle",
    "description": "",
    "summary": "Putting ethical principles at the core of the research lifecycle Ethical charter - Multimodal projec...",
    "pubDate": "Thu, 19 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethical-charter-multimodal",
    "thumbnail": "https://huggingface.co/blog/assets/71_ethical-charter/thumbnail.jpg"
  },
  {
    "title": "A Framework for Multi-source Privacy Preserving Epidemic Analysis",
    "description": "arXiv:2506.22342v1 Announce Type: cross Abstract: It is now well understood that diverse datasets provide a lot of value in key epidemiology and public health analyses, such as forecasting and nowcasting, development of epidemic models, evaluation and design of interventions and resource allocation. Some of these datasets are often sensitive, and need adequate privacy protections. There are many models of privacy, but Differential Privacy (DP) has become a de facto standard because of its strong guarantees, without making models about adversaries. In this paper, we develop a framework the integrates deep learning and epidemic models to simultaneously perform epidemic forecasting and learning a mechanistic model of epidemic spread, while incorporating multiple datasets for these analyses, including some with DP guarantees. We demonstrate our framework using a realistic but synthetic financial dataset with DP; such a dataset has not been used in such epidemic analyses. We show that this dataset provides significant value in forecasting and learning an epidemic model, even when used with DP guarantees.",
    "summary": "arXiv:2506.22342v1 Announce Type: cross Abstract: It is now well understood that diverse datasets provide a lot of value in key epidemiology and public health analyses, such as forecasting and nowcasting, development of epidemic models, evaluation and design of interventions and resource allocation. Some of these datasets are often sensitive, and need adequate privacy protections. There are many models of privacy, but Differential Privacy (DP) has become a de facto standard because of its strong guarantees, without making models about adversaries. In this paper, we develop a framework the integrates deep learning and epidemic models to simultaneously perform epidemic forecasting and learning a mechanistic model of epidemic spread, while incorporating multiple datasets for these analyses, including some with DP guarantees. We demonstrate our framework using a realistic but synthetic financial dataset with DP; such a dataset has not been used in such epidemic analyses. We show that this dataset provides significant value in forecasting and learning an epidemic model, even when used with DP guarantees.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22342",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Announcing The Stargate Project",
    "description": "Announcing The Stargate Project",
    "summary": "Announcing The Stargate Project",
    "pubDate": "Tue, 21 Jan 2025 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/announcing-the-stargate-project",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MAWIFlow Benchmark: Realistic Flow-Based Evaluation for Network Intrusion Detection",
    "description": "arXiv:2506.17041v1 Announce Type: cross Abstract: Benchmark datasets for network intrusion detection commonly rely on synthetically generated traffic, which fails to reflect the statistical variability and temporal drift encountered in operational environments. This paper introduces MAWIFlow, a flow-based benchmark derived from the MAWILAB v1.1 dataset, designed to enable realistic and reproducible evaluation of anomaly detection methods. A reproducible preprocessing pipeline is presented that transforms raw packet captures into flow representations conforming to the CICFlowMeter format, while preserving MAWILab's original anomaly labels. The resulting datasets comprise temporally distinct samples from January 2011, 2016, and 2021, drawn from trans-Pacific backbone traffic. To establish reference baselines, traditional machine learning methods, including Decision Trees, Random Forests, XGBoost, and Logistic Regression, are compared to a deep learning model based on a CNN-BiLSTM architecture. Empirical results demonstrate that tree-based classifiers perform well on temporally static data but experience significant performance degradation over time. In contrast, the CNN-BiLSTM model maintains better performance, thus showing improved generalization. These findings underscore the limitations of synthetic benchmarks and static models, and motivate the adoption of realistic datasets with explicit temporal structure. All datasets, pipeline code, and model implementations are made publicly available to foster transparency and reproducibility.",
    "summary": "arXiv:2506.17041v1 Announce Type: cross Abstract: Benchmark datasets for network intrusion detection commonly rely on synthetically generated traffic, which fails to reflect the statistical variability and temporal drift encountered in operational environments. This paper introduces MAWIFlow, a flow-based benchmark derived from the MAWILAB v1.1 dataset, designed to enable realistic and reproducible evaluation of anomaly detection methods. A reproducible preprocessing pipeline is presented that transforms raw packet captures into flow representations conforming to the CICFlowMeter format, while preserving MAWILab's original anomaly labels. The resulting datasets comprise temporally distinct samples from January 2011, 2016, and 2021, drawn from trans-Pacific backbone traffic. To establish reference baselines, traditional machine learning methods, including Decision Trees, Random Forests, XGBoost, and Logistic Regression, are compared to a deep learning model based on a CNN-BiLSTM architecture. Empirical results demonstrate that tree-based classifiers perform well on temporally static data but experience significant performance degradation over time. In contrast, the CNN-BiLSTM model maintains better performance, thus showing improved generalization. These findings underscore the limitations of synthetic benchmarks and static models, and motivate the adoption of realistic datasets with explicit temporal structure. All datasets, pipeline code, and model implementations are made publicly available to foster transparency and reproducibility.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17041",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more",
    "description": "We‚Äôre releasing two updated production-ready Gemini models",
    "summary": "We‚Äôre releasing two updated production-ready Gemini models",
    "pubDate": "Tue, 24 Sep 2024 16:03:03 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini-15-Flash-Social_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "SP-VLA: A Joint Model Scheduling and Token Pruning Approach for VLA Model Acceleration",
    "description": "arXiv:2506.12723v2 Announce Type: replace-cross Abstract: Vision-Language-Action (VLA) models have attracted increasing attention for their strong control capabilities. However, their high computational cost and low execution frequency hinder their suitability for real-time tasks such as robotic manipulation and autonomous navigation. Existing VLA acceleration methods primarily focus on structural optimization, overlooking the fact that these models operate in sequential decision-making environments. As a result, temporal redundancy in sequential action generation and spatial redundancy in visual input remain unaddressed. To this end, we propose SP-VLA, a unified framework that accelerates VLA models by jointly scheduling models and pruning tokens. Specifically, we design an action-aware model scheduling mechanism that reduces temporal redundancy by dynamically switching between VLA model and a lightweight generator. Inspired by the human motion pattern of focusing on key decision points while relying on intuition for other actions, we categorize VLA actions into deliberative and intuitive, assigning the former to the VLA model and the latter to the lightweight generator, enabling frequency-adaptive execution through collaborative model scheduling. To address spatial redundancy, we further develop a spatio-semantic dual-aware token pruning method. Tokens are classified into spatial and semantic types and pruned based on their dual-aware importance to accelerate VLA inference. These two mechanisms work jointly to guide the VLA in focusing on critical actions and salient visual information, achieving effective acceleration while maintaining high accuracy. Experimental results demonstrate that our method achieves up to 1.5$times$ acceleration with less than 3% drop in accuracy, outperforming existing approaches in multiple tasks.",
    "summary": "arXiv:2506.12723v2 Announce Type: replace-cross Abstract: Vision-Language-Action (VLA) models have attracted increasing attention for their strong control capabilities. However, their high computational cost and low execution frequency hinder their suitability for real-time tasks such as robotic manipulation and autonomous navigation. Existing VLA acceleration methods primarily focus on structural optimization, overlooking the fact that these models operate in sequential decision-making environments. As a result, temporal redundancy in sequential action generation and spatial redundancy in visual input remain unaddressed. To this end, we propose SP-VLA, a unified framework that accelerates VLA models by jointly scheduling models and pruning tokens. Specifically, we design an action-aware model scheduling mechanism that reduces temporal redundancy by dynamically switching between VLA model and a lightweight generator. Inspired by the human motion pattern of focusing on key decision points while relying on intuition for other actions, we categorize VLA actions into deliberative and intuitive, assigning the former to the VLA model and the latter to the lightweight generator, enabling frequency-adaptive execution through collaborative model scheduling. To address spatial redundancy, we further develop a spatio-semantic dual-aware token pruning method. Tokens are classified into spatial and semantic types and pruned based on their dual-aware importance to accelerate VLA inference. These two mechanisms work jointly to guide the VLA in focusing on critical actions and salient visual information, achieving effective acceleration while maintaining high accuracy. Experimental results demonstrate that our method achieves up to 1.5$times$ acceleration with less than 3% drop in accuracy, outperforming existing approaches in multiple tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12723",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome Fireworks.ai on the Hub üéÜ",
    "description": "",
    "summary": "Welcome Fireworks.ai on the Hub üéÜ Following our recent announcement on Inference Providers on the Hu...",
    "pubDate": "Fri, 14 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fireworks-ai",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-fireworks.jpg"
  },
  {
    "title": "The court rejects Elon‚Äôs latest attempt to slow OpenAI down",
    "description": "We welcome the court‚Äôs March 4, 2025, decision rejecting Elon Musk‚Äôs latest attempt to slow down OpenAI for his personal benefit.",
    "summary": "We welcome the court‚Äôs March 4, 2025, decision rejecting Elon Musk‚Äôs latest attempt to slow down OpenAI for his personal benefit.",
    "pubDate": "Fri, 14 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/court-rejects-elon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploying the AI Comic Factory using the Inference API",
    "description": "",
    "summary": "Deploying the AI Comic Factory using the Inference API We recently announced Inference for PROs, our...",
    "pubDate": "Mon, 02 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-comic-factory",
    "thumbnail": "https://huggingface.co/blog/assets/165_ai_comic_factory/thumbnail.jpg"
  },
  {
    "title": "DALL¬∑E API now available in public beta",
    "description": "Starting today, developers can begin building apps with the DALL¬∑E API.",
    "summary": "Starting today, developers can begin building apps with the DALL¬∑E API.",
    "pubDate": "Thu, 03 Nov 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-api-now-available-in-public-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Probing the Robustness of Large Language Models Safety to Latent Perturbations",
    "description": "arXiv:2506.16078v1 Announce Type: cross Abstract: Safety alignment is a key requirement for building reliable Artificial General Intelligence. Despite significant advances in safety alignment, we observe that minor latent shifts can still trigger unsafe responses in aligned models. We argue that this stems from the shallow nature of existing alignment methods, which focus on surface-level refusal behaviors without sufficiently altering internal representations. Consequently, small shifts in hidden activations can re-trigger harmful behaviors embedded in the latent space. To explore the robustness of safety alignment to latent perturbations, we introduce a probing method that measures the Negative Log-Likelihood of the original response generated by the model. This probe quantifies local sensitivity in the latent space, serving as a diagnostic tool for identifying vulnerable directions. Based on this signal, we construct effective jailbreak trajectories, giving rise to the Activation Steering Attack (ASA). More importantly, these insights offer a principled foundation for improving alignment robustness. To this end, we introduce Layer-wise Adversarial Patch Training~(LAPT), a fine-tuning strategy that inject controlled perturbations into hidden representations during training. Experimental results highlight that LAPT strengthen alignment robustness without compromising general capabilities. Our findings reveal fundamental flaws in current alignment paradigms and call for representation-level training strategies that move beyond surface-level behavior supervision. Codes and results are available at https://github.com/Carol-gutianle/LatentSafety.",
    "summary": "arXiv:2506.16078v1 Announce Type: cross Abstract: Safety alignment is a key requirement for building reliable Artificial General Intelligence. Despite significant advances in safety alignment, we observe that minor latent shifts can still trigger unsafe responses in aligned models. We argue that this stems from the shallow nature of existing alignment methods, which focus on surface-level refusal behaviors without sufficiently altering internal representations. Consequently, small shifts in hidden activations can re-trigger harmful behaviors embedded in the latent space. To explore the robustness of safety alignment to latent perturbations, we introduce a probing method that measures the Negative Log-Likelihood of the original response generated by the model. This probe quantifies local sensitivity in the latent space, serving as a diagnostic tool for identifying vulnerable directions. Based on this signal, we construct effective jailbreak trajectories, giving rise to the Activation Steering Attack (ASA). More importantly, these insights offer a principled foundation for improving alignment robustness. To this end, we introduce Layer-wise Adversarial Patch Training~(LAPT), a fine-tuning strategy that inject controlled perturbations into hidden representations during training. Experimental results highlight that LAPT strengthen alignment robustness without compromising general capabilities. Our findings reveal fundamental flaws in current alignment paradigms and call for representation-level training strategies that move beyond surface-level behavior supervision. Codes and results are available at https://github.com/Carol-gutianle/LatentSafety.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16078",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI Speech Recognition in Unity",
    "description": "",
    "summary": "AI Speech Recognition in Unity Introduction This tutorial guides you through the process of implemen...",
    "pubDate": "Fri, 02 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-asr",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-asr-thumbnail.png"
  },
  {
    "title": "Ethics and Society Newsletter #3: Ethical Openness at Hugging Face",
    "description": "",
    "summary": "Ethics and Society Newsletter #3: Ethical Openness at Hugging Face Mission: Open and Good ML In our ...",
    "pubDate": "Thu, 30 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-3",
    "thumbnail": "https://huggingface.co/blog/assets/137_ethics_soc_3/ethics_3_thumbnail.png"
  },
  {
    "title": "Human-Centered Editable Speech-to-Sign-Language Generation via Streaming Conformer-Transformer and Resampling Hook",
    "description": "arXiv:2506.14677v2 Announce Type: replace-cross Abstract: Existing end-to-end sign-language animation systems suffer from low naturalness, limited facial/body expressivity, and no user control. We propose a human-centered, real-time speech-to-sign animation framework that integrates (1) a streaming Conformer encoder with an autoregressive Transformer-MDN decoder for synchronized upper-body and facial motion generation, (2) a transparent, editable JSON intermediate representation empowering deaf users and experts to inspect and modify each sign segment, and (3) a human-in-the-loop optimization loop that refines the model based on user edits and ratings. Deployed on Unity3D, our system achieves a 13 ms average frame-inference time and a 103 ms end-to-end latency on an RTX 4070. Our key contributions include the design of a JSON-centric editing mechanism for fine-grained sign-level personalization and the first application of an MDN-based feedback loop for continuous model adaptation. This combination establishes a generalizable, explainable AI paradigm for user-adaptive, low-latency multimodal systems. In studies with 20 deaf signers and 5 professional interpreters, we observe a +13 point SUS improvement, 6.7 point reduction in cognitive load, and significant gains in naturalness and trust (p $<$ .001) over baselines. This work establishes a scalable, explainable AI paradigm for accessible sign-language technologies.",
    "summary": "arXiv:2506.14677v2 Announce Type: replace-cross Abstract: Existing end-to-end sign-language animation systems suffer from low naturalness, limited facial/body expressivity, and no user control. We propose a human-centered, real-time speech-to-sign animation framework that integrates (1) a streaming Conformer encoder with an autoregressive Transformer-MDN decoder for synchronized upper-body and facial motion generation, (2) a transparent, editable JSON intermediate representation empowering deaf users and experts to inspect and modify each sign segment, and (3) a human-in-the-loop optimization loop that refines the model based on user edits and ratings. Deployed on Unity3D, our system achieves a 13 ms average frame-inference time and a 103 ms end-to-end latency on an RTX 4070. Our key contributions include the design of a JSON-centric editing mechanism for fine-grained sign-level personalization and the first application of an MDN-based feedback loop for continuous model adaptation. This combination establishes a generalizable, explainable AI paradigm for user-adaptive, low-latency multimodal systems. In studies with 20 deaf signers and 5 professional interpreters, we observe a +13 point SUS improvement, 6.7 point reduction in cognitive load, and significant gains in naturalness and trust (p $<$ .001) over baselines. This work establishes a scalable, explainable AI paradigm for accessible sign-language technologies.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14677",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Security on the path to AGI",
    "description": "At OpenAI, we proactively adapt, including by building comprehensive security measures directly into our infrastructure and models.",
    "summary": "At OpenAI, we proactively adapt, including by building comprehensive security measures directly into our infrastructure and models.",
    "pubDate": "Wed, 26 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/security-on-the-path-to-agi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Holistic Approach to Undesired Content Detection in the Real World",
    "description": "We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation.",
    "summary": "We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-holistic-approach-to-undesired-content-detection-in-the-real-world",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing Evaluation on the Hub",
    "description": "",
    "summary": "Announcing Evaluation on the Hub This project has been archived. If you want to evaluate LLMs on the...",
    "pubDate": "Tue, 28 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eval-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/82_eval_on_the_hub/thumbnail.png"
  },
  {
    "title": "OpenAI Five defeats Dota 2 world champions",
    "description": "OpenAI Five is the first AI to beat the world champions in an esports game, having won two back-to-back games versus the world champion Dota 2 team,¬†OG, at¬†Finals¬†this weekend. Both OpenAI Five and DeepMind‚Äôs AlphaStar had previously beaten good pros privately but lost their live pro matches, making this also the first time an AI has beaten esports pros on¬†livestream.",
    "summary": "OpenAI Five is the first AI to beat the world champions in an esports game, having won two back-to-back games versus the world champion Dota 2 team,¬†OG, at¬†Finals¬†this weekend. Both OpenAI Five and DeepMind‚Äôs AlphaStar had previously beaten good pros privately but lost their live pro matches, making this also the first time an AI has beaten esports pros on¬†livestream.",
    "pubDate": "Mon, 15 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-defeats-dota-2-world-champions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding complex trends with deep research",
    "description": "How OpenAI deep research helps Bain & Company understand complex industry trends.",
    "summary": "How OpenAI deep research helps Bain & Company understand complex industry trends.",
    "pubDate": "Sun, 02 Feb 2025 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Primer on the EU AI Act: What It Means for AI Providers and Deployers",
    "description": "We‚Äôre sharing a preliminary overview of the EU AI Act including upcoming deadlines and requirements, with a particular focus on prohibited and high-risk use cases",
    "summary": "We‚Äôre sharing a preliminary overview of the EU AI Act including upcoming deadlines and requirements, with a particular focus on prohibited and high-risk use cases",
    "pubDate": "Tue, 30 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/a-primer-on-the-eu-ai-act",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs",
    "description": "arXiv:2506.19290v1 Announce Type: new Abstract: Software engineering (SWE) has recently emerged as a crucial testbed for next-generation LLM agents, demanding inherent capabilities in two critical dimensions: sustained iterative problem-solving (e.g., >50 interaction rounds) and long-context dependency resolution (e.g., >32k tokens). However, the data curation process in SWE remains notoriously time-consuming, as it heavily relies on manual annotation for code file filtering and the setup of dedicated runtime environments to execute and validate unit tests. Consequently, most existing datasets are limited to only a few thousand GitHub-sourced instances. To this end, we propose an incremental, automated data-curation pipeline that systematically scales both the volume and diversity of SWE datasets. Our dataset comprises 10,169 real-world Python task instances from 2,531 distinct GitHub repositories, each accompanied by a task specified in natural language and a dedicated runtime-environment image for automated unit-test validation. We have carefully curated over 8,000 successfully runtime-validated training trajectories from our proposed SWE dataset. When fine-tuning the Skywork-SWE model on these trajectories, we uncover a striking data scaling phenomenon: the trained model's performance for software engineering capabilities in LLMs continues to improve as the data size increases, showing no signs of saturation. Notably, our Skywork-SWE model achieves 38.0% pass@1 accuracy on the SWE-bench Verified benchmark without using verifiers or multiple rollouts, establishing a new state-of-the-art (SOTA) among the Qwen2.5-Coder-32B-based LLMs built on the OpenHands agent framework. Furthermore, with the incorporation of test-time scaling techniques, the performance further improves to 47.0% accuracy, surpassing the previous SOTA results for sub-32B parameter models. We release the Skywork-SWE-32B model checkpoint to accelerate future research.",
    "summary": "arXiv:2506.19290v1 Announce Type: new Abstract: Software engineering (SWE) has recently emerged as a crucial testbed for next-generation LLM agents, demanding inherent capabilities in two critical dimensions: sustained iterative problem-solving (e.g., >50 interaction rounds) and long-context dependency resolution (e.g., >32k tokens). However, the data curation process in SWE remains notoriously time-consuming, as it heavily relies on manual annotation for code file filtering and the setup of dedicated runtime environments to execute and validate unit tests. Consequently, most existing datasets are limited to only a few thousand GitHub-sourced instances. To this end, we propose an incremental, automated data-curation pipeline that systematically scales both the volume and diversity of SWE datasets. Our dataset comprises 10,169 real-world Python task instances from 2,531 distinct GitHub repositories, each accompanied by a task specified in natural language and a dedicated runtime-environment image for automated unit-test validation. We have carefully curated over 8,000 successfully runtime-validated training trajectories from our proposed SWE dataset. When fine-tuning the Skywork-SWE model on these trajectories, we uncover a striking data scaling phenomenon: the trained model's performance for software engineering capabilities in LLMs continues to improve as the data size increases, showing no signs of saturation. Notably, our Skywork-SWE model achieves 38.0% pass@1 accuracy on the SWE-bench Verified benchmark without using verifiers or multiple rollouts, establishing a new state-of-the-art (SOTA) among the Qwen2.5-Coder-32B-based LLMs built on the OpenHands agent framework. Furthermore, with the incorporation of test-time scaling techniques, the performance further improves to 47.0% accuracy, surpassing the previous SOTA results for sub-32B parameter models. We release the Skywork-SWE-32B model checkpoint to accelerate future research.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19290",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Scholars 2020: Final projects",
    "description": "Our third class of OpenAI Scholars presented their final projects at virtual Demo Day, showcasing their research results from over the past five months.",
    "summary": "Our third class of OpenAI Scholars presented their final projects at virtual Demo Day, showcasing their research results from over the past five months.",
    "pubDate": "Thu, 09 Jul 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2020-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Smart Traffic Signals: Comparing MARL and Fixed-Time Strategies",
    "description": "arXiv:2505.14544v2 Announce Type: replace Abstract: Urban traffic congestion, particularly at intersections, significantly impacts travel time, fuel consumption, and emissions. Traditional fixed-time signal control systems often lack the adaptability to manage dynamic traffic patterns effectively. This study explores the application of multi-agent reinforcement learning (MARL) to optimize traffic signal coordination across multiple intersections within a simulated environment. Utilizing Pygame, a simulation was developed to model a network of interconnected intersections with randomly generated vehicle flows to reflect realistic traffic variability. A decentralized MARL controller was implemented, in which each traffic signal operates as an autonomous agent, making decisions based on local observations and information from neighboring agents. Performance was evaluated against a baseline fixed-time controller using metrics such as average vehicle wait time and overall throughput. The MARL approach demonstrated statistically significant improvements, including reduced average waiting times and improved throughput. These findings suggest that MARL-based dynamic control strategies hold substantial promise for improving urban traffic management efficiency. More research is recommended to address scalability and real-world implementation challenges.",
    "summary": "arXiv:2505.14544v2 Announce Type: replace Abstract: Urban traffic congestion, particularly at intersections, significantly impacts travel time, fuel consumption, and emissions. Traditional fixed-time signal control systems often lack the adaptability to manage dynamic traffic patterns effectively. This study explores the application of multi-agent reinforcement learning (MARL) to optimize traffic signal coordination across multiple intersections within a simulated environment. Utilizing Pygame, a simulation was developed to model a network of interconnected intersections with randomly generated vehicle flows to reflect realistic traffic variability. A decentralized MARL controller was implemented, in which each traffic signal operates as an autonomous agent, making decisions based on local observations and information from neighboring agents. Performance was evaluated against a baseline fixed-time controller using metrics such as average vehicle wait time and overall throughput. The MARL approach demonstrated statistically significant improvements, including reduced average waiting times and improved throughput. These findings suggest that MARL-based dynamic control strategies hold substantial promise for improving urban traffic management efficiency. More research is recommended to address scalability and real-world implementation challenges.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.14544",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gathering human feedback",
    "description": "RL-Teacher is an open-source implementation of our interface to train AIs via occasional human feedback rather than hand-crafted reward functions. The underlying technique was developed as a step towards safe AI systems, but also applies to reinforcement learning problems with rewards that are hard to specify.",
    "summary": "RL-Teacher is an open-source implementation of our interface to train AIs via occasional human feedback rather than hand-crafted reward functions. The underlying technique was developed as a step towards safe AI systems, but also applies to reinforcement learning problems with rewards that are hard to specify.",
    "pubDate": "Thu, 03 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gathering-human-feedback",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Estonia and OpenAI to bring ChatGPT to schools nationwide",
    "description": "Estonia and OpenAI to bring ChatGPT to schools nationwide. OpenAI will work with the Estonian Government to provide students and teachers in the secondary school system with access to ChatGPT Edu.",
    "summary": "Estonia and OpenAI to bring ChatGPT to schools nationwide. OpenAI will work with the Estonian Government to provide students and teachers in the secondary school system with access to ChatGPT Edu.",
    "pubDate": "Tue, 25 Feb 2025 04:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/estonia-schools-and-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating link prediction: New perspectives and recommendations",
    "description": "arXiv:2502.12777v3 Announce Type: replace-cross Abstract: Link prediction (LP) is an important problem in network science and machine learning research. The state-of-the-art LP methods are usually evaluated in a uniform setup, ignoring several factors associated with the data and application specific needs. We identify a number of such factors, such as, network-type, problem-type, geodesic distance between the end nodes and its distribution over the classes, nature and applicability of LP methods, class imbalance and its impact on early retrieval, evaluation metric, etc., and present an experimental setup which allows us to evaluate LP methods in a rigorous and controlled manner. We perform extensive experiments with a variety of LP methods over real network datasets in this controlled setup, and gather valuable insights on the interactions of these factors with the performance of LP through an array of carefully designed hypotheses. Following the insights, we provide recommendations to be followed as best practice for evaluating LP methods.",
    "summary": "arXiv:2502.12777v3 Announce Type: replace-cross Abstract: Link prediction (LP) is an important problem in network science and machine learning research. The state-of-the-art LP methods are usually evaluated in a uniform setup, ignoring several factors associated with the data and application specific needs. We identify a number of such factors, such as, network-type, problem-type, geodesic distance between the end nodes and its distribution over the classes, nature and applicability of LP methods, class imbalance and its impact on early retrieval, evaluation metric, etc., and present an experimental setup which allows us to evaluate LP methods in a rigorous and controlled manner. We perform extensive experiments with a variety of LP methods over real network datasets in this controlled setup, and gather valuable insights on the interactions of these factors with the performance of LP through an array of carefully designed hypotheses. Following the insights, we provide recommendations to be followed as best practice for evaluating LP methods.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.12777",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "VLM@school -- Evaluation of AI image understanding on German middle school knowledge",
    "description": "arXiv:2506.11604v2 Announce Type: replace Abstract: This paper introduces a novel benchmark dataset designed to evaluate the capabilities of Vision Language Models (VLMs) on tasks that combine visual reasoning with subject-specific background knowledge in the German language. In contrast to widely used English-language benchmarks that often rely on artificially difficult or decontextualized problems, this dataset draws from real middle school curricula across nine domains including mathematics, history, biology, and religion. The benchmark includes over 2,000 open-ended questions grounded in 486 images, ensuring that models must integrate visual interpretation with factual reasoning rather than rely on superficial textual cues. We evaluate thirteen state-of-the-art open-weight VLMs across multiple dimensions, including domain-specific accuracy and performance on adversarial crafted questions. Our findings reveal that even the strongest models achieve less than 45% overall accuracy, with particularly poor performance in music, mathematics, and adversarial settings. Furthermore, the results indicate significant discrepancies between success on popular benchmarks and real-world multimodal understanding. We conclude that middle school-level tasks offer a meaningful and underutilized avenue for stress-testing VLMs, especially in non-English contexts. The dataset and evaluation protocol serve as a rigorous testbed to better understand and improve the visual and linguistic reasoning capabilities of future AI systems.",
    "summary": "arXiv:2506.11604v2 Announce Type: replace Abstract: This paper introduces a novel benchmark dataset designed to evaluate the capabilities of Vision Language Models (VLMs) on tasks that combine visual reasoning with subject-specific background knowledge in the German language. In contrast to widely used English-language benchmarks that often rely on artificially difficult or decontextualized problems, this dataset draws from real middle school curricula across nine domains including mathematics, history, biology, and religion. The benchmark includes over 2,000 open-ended questions grounded in 486 images, ensuring that models must integrate visual interpretation with factual reasoning rather than rely on superficial textual cues. We evaluate thirteen state-of-the-art open-weight VLMs across multiple dimensions, including domain-specific accuracy and performance on adversarial crafted questions. Our findings reveal that even the strongest models achieve less than 45% overall accuracy, with particularly poor performance in music, mathematics, and adversarial settings. Furthermore, the results indicate significant discrepancies between success on popular benchmarks and real-world multimodal understanding. We conclude that middle school-level tasks offer a meaningful and underutilized avenue for stress-testing VLMs, especially in non-English contexts. The dataset and evaluation protocol serve as a rigorous testbed to better understand and improve the visual and linguistic reasoning capabilities of future AI systems.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11604",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Total noob‚Äôs intro to Hugging Face Transformers",
    "description": "",
    "summary": "Total noob‚Äôs intro to Hugging Face Transformers Welcome to 'A Total Noob‚Äôs Introduction to Hugging F...",
    "pubDate": "Fri, 22 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/noob_intro_transformers",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/guide.png"
  },
  {
    "title": "Preference-Driven Multi-Objective Combinatorial Optimization with Conditional Computation",
    "description": "arXiv:2506.08898v2 Announce Type: replace Abstract: Recent deep reinforcement learning methods have achieved remarkable success in solving multi-objective combinatorial optimization problems (MOCOPs) by decomposing them into multiple subproblems, each associated with a specific weight vector. However, these methods typically treat all subproblems equally and solve them using a single model, hindering the effective exploration of the solution space and thus leading to suboptimal performance. To overcome the limitation, we propose POCCO, a novel plug-and-play framework that enables adaptive selection of model structures for subproblems, which are subsequently optimized based on preference signals rather than explicit reward values. Specifically, we design a conditional computation block that routes subproblems to specialized neural architectures. Moreover, we propose a preference-driven optimization algorithm that learns pairwise preferences between winning and losing solutions. We evaluate the efficacy and versatility of POCCO by applying it to two state-of-the-art neural methods for MOCOPs. Experimental results across four classic MOCOP benchmarks demonstrate its significant superiority and strong generalization.",
    "summary": "arXiv:2506.08898v2 Announce Type: replace Abstract: Recent deep reinforcement learning methods have achieved remarkable success in solving multi-objective combinatorial optimization problems (MOCOPs) by decomposing them into multiple subproblems, each associated with a specific weight vector. However, these methods typically treat all subproblems equally and solve them using a single model, hindering the effective exploration of the solution space and thus leading to suboptimal performance. To overcome the limitation, we propose POCCO, a novel plug-and-play framework that enables adaptive selection of model structures for subproblems, which are subsequently optimized based on preference signals rather than explicit reward values. Specifically, we design a conditional computation block that routes subproblems to specialized neural architectures. Moreover, we propose a preference-driven optimization algorithm that learns pairwise preferences between winning and losing solutions. We evaluate the efficacy and versatility of POCCO by applying it to two state-of-the-art neural methods for MOCOPs. Experimental results across four classic MOCOP benchmarks demonstrate its significant superiority and strong generalization.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.08898",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents",
    "description": "arXiv:2506.21669v1 Announce Type: new Abstract: Self-evolution, the ability of agents to autonomously improve their reasoning and behavior, is essential for the embodied domain with long-horizon, real-world tasks. Despite current advancements in reinforcement fine-tuning (RFT) showing strong performance in enhancing reasoning in LLMs, its potential to enable self-evolving embodied intelligence with multi-modal interactions remains largely unexplored. Specifically, reinforcement fine-tuning faces two fundamental obstacles in embodied settings: (i) the lack of accessible intermediate rewards in multi-step reasoning tasks limits effective learning signals, and (ii) reliance on hand-crafted reward functions restricts generalization to novel tasks and environments. To address these challenges, we present Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework designed for enabling the self-evolving capabilities of embodied agents. Specifically, to convert sparse delayed rewards into denser intermediate signals that improve multi-step reasoning, we propose Tree-based group relative policy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into GRPO. To generalize reward estimation across tasks and scenes, supporting autonomous adaptation and reward-driven self-evolution, we further introduce Multi-modal Generative Reward Model (MGRM). To holistically evaluate the effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing state-of-the-art methods with scores of 85.07% (textual) and 36.19% (multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also achieves scores of 80.3% without environmental reward, surpassing all open-source baselines and highlighting its scalability as a self-evolving embodied agent. Additional experiments and qualitative analysis further support the potential of SEEA-R1 for future research in scalable embodied intelligence.",
    "summary": "arXiv:2506.21669v1 Announce Type: new Abstract: Self-evolution, the ability of agents to autonomously improve their reasoning and behavior, is essential for the embodied domain with long-horizon, real-world tasks. Despite current advancements in reinforcement fine-tuning (RFT) showing strong performance in enhancing reasoning in LLMs, its potential to enable self-evolving embodied intelligence with multi-modal interactions remains largely unexplored. Specifically, reinforcement fine-tuning faces two fundamental obstacles in embodied settings: (i) the lack of accessible intermediate rewards in multi-step reasoning tasks limits effective learning signals, and (ii) reliance on hand-crafted reward functions restricts generalization to novel tasks and environments. To address these challenges, we present Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework designed for enabling the self-evolving capabilities of embodied agents. Specifically, to convert sparse delayed rewards into denser intermediate signals that improve multi-step reasoning, we propose Tree-based group relative policy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into GRPO. To generalize reward estimation across tasks and scenes, supporting autonomous adaptation and reward-driven self-evolution, we further introduce Multi-modal Generative Reward Model (MGRM). To holistically evaluate the effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing state-of-the-art methods with scores of 85.07% (textual) and 36.19% (multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also achieves scores of 80.3% without environmental reward, surpassing all open-source baselines and highlighting its scalability as a self-evolving embodied agent. Additional experiments and qualitative analysis further support the potential of SEEA-R1 for future research in scalable embodied intelligence.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21669",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Faster assisted generation support for Intel Gaudi",
    "description": "",
    "summary": "Faster assisted generation support for Intel Gaudi As model sizes grow, Generative AI implementation...",
    "pubDate": "Tue, 04 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/assisted-generation-support-gaudi",
    "thumbnail": "https://huggingface.co/blog/assets/assisted-generation-support-gaudi/thumbnail.png"
  },
  {
    "title": "The sweet taste of a new idea",
    "description": "Sendhil Mullainathan brings a lifetime of unique perspectives to research in behavioral economics and machine learning.",
    "summary": "Sendhil Mullainathan brings a lifetime of unique perspectives to research in behavioral economics and machine learning.",
    "pubDate": "Mon, 19 May 2025 16:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/sweet-taste-new-idea-sendhil-mullainathan-0519",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-sendhil-Mullainathan.jpg"
  },
  {
    "title": "Put AI to Work for Marketing Teams",
    "description": "Put AI to Work for Marketing Teams",
    "summary": "Put AI to Work for Marketing Teams",
    "pubDate": "Thu, 31 Oct 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-for-marketing-teams",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Codex",
    "description": "Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered by codex-1. With Codex, developers can simultaneously deploy multiple agents to independently handle coding tasks such as writing features, answering questions about your codebase, fixing bugs, and proposing pull requests for review.",
    "summary": "Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered by codex-1. With Codex, developers can simultaneously deploy multiple agents to independently handle coding tasks such as writing features, answering questions about your codebase, fixing bugs, and proposing pull requests for review.",
    "pubDate": "Fri, 16 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-codex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Boosting the customer retail experience with GPT-4o mini",
    "description": "Zalando boosts the customer experience with its Assistant, powered by GPT-4o mini",
    "summary": "Zalando boosts the customer experience with its Assistant, powered by GPT-4o mini",
    "pubDate": "Wed, 11 Dec 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zalando",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Block Sparse Matrices for Smaller and Faster Language Models",
    "description": "",
    "summary": "Block Sparse Matrices for Smaller and Faster Language Models Saving space and time, one zero at a ti...",
    "pubDate": "Thu, 10 Sep 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch_block_sparse",
    "thumbnail": "https://huggingface.co/blog/assets/04_pytorch_block_sparse/thumbnail.png"
  },
  {
    "title": "OpenAI Fellows Winter 2019 & Interns Summer 2019",
    "description": "We are now accepting applications for OpenAI Fellows and Interns for 2019.",
    "summary": "We are now accepting applications for OpenAI Fellows and Interns for 2019.",
    "pubDate": "Tue, 09 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows-interns-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A guide to setting up your own Hugging Face leaderboard: an end-to-end example with Vectara's hallucination leaderboard",
    "description": "",
    "summary": "A guide to setting up your own Hugging Face leaderboard: an end-to-end example with Vectara's halluc...",
    "pubDate": "Fri, 12 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-vectara",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "You could have designed state of the art positional encoding",
    "description": "",
    "summary": "You could have designed state of the art positional encoding Gall's Law A complex system that works ...",
    "pubDate": "Mon, 25 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/designing-positional-encoding",
    "thumbnail": "https://huggingface.co/blog/assets/designing-positional-encoding/thumbnail_posenc.png"
  },
  {
    "title": "Gemini 2.5 Pro Preview: even better coding performance",
    "description": "We‚Äôve seen developers doing amazing things with Gemini 2.5 Pro, so we decided to release an updated version a couple of weeks early to get into developers hands sooner.",
    "summary": "We‚Äôve seen developers doing amazing things with Gemini 2.5 Pro, so we decided to release an updated version a couple of weeks early to get into developers hands sooner.",
    "pubDate": "Tue, 06 May 2025 15:06:55 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-pro-preview-even-better-coding-performance/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini_2-5_pro_claybrook__dev_her.2e16d0ba.fill-1200x600.jpg"
  },
  {
    "title": "3D modeling you can feel",
    "description": "TactStyle, a system developed by CSAIL researchers, uses image prompts to replicate both the visual appearance and tactile properties of 3D models.",
    "summary": "TactStyle, a system developed by CSAIL researchers, uses image prompts to replicate both the visual appearance and tactile properties of 3D models.",
    "pubDate": "Tue, 22 Apr 2025 15:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/3d-modeling-you-can-feel-0422",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-TactStyle-00.jpg"
  },
  {
    "title": "Timm ‚ù§Ô∏è Transformers: Use any timm model with transformers",
    "description": "",
    "summary": "Timm ‚ù§Ô∏è Transformers: Use any timm model with transformers Get lightning-fast inference, quick quant...",
    "pubDate": "Thu, 16 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/timm-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/timm-transformers/thumbnail.png"
  },
  {
    "title": "The Falcon has landed in the Hugging Face ecosystem",
    "description": "",
    "summary": "The Falcon has landed in the Hugging Face ecosystem Falcon is a new family of state-of-the-art langu...",
    "pubDate": "Mon, 05 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon",
    "thumbnail": "https://huggingface.co/blog/assets/147_falcon/falcon_thumbnail.jpg"
  },
  {
    "title": "DALL¬∑E: Creating images from text",
    "description": "We‚Äôve trained a neural network called DALL¬∑E that creates images from text captions for a wide range of concepts expressible in natural¬†language.",
    "summary": "We‚Äôve trained a neural network called DALL¬∑E that creates images from text captions for a wide range of concepts expressible in natural¬†language.",
    "pubDate": "Tue, 05 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Behaviour Planning: A Toolkit for Diverse Planning",
    "description": "arXiv:2405.04300v3 Announce Type: replace Abstract: Diverse planning approaches are utilised in real-world applications like risk management, automated streamed data analysis, and malware detection. The current diverse planning formulations encode the diversity model as a distance function, which is computational inexpensive when comparing two plans. However, such modelling approach limits what can be encoded as measure of diversity, as well as the ability to explain why two plans are different. This paper introduces a novel approach to the diverse planning problem, allowing for more expressive modelling of diversity using a n-dimensional grid representation, where each dimension corresponds to a user-defined feature. Furthermore, we present a novel toolkit that generates diverse plans based on such customisable diversity models, called emph{Behaviour Planning}. We provide an implementation for behaviour planning using planning-as-satisfiability. An empirical evaluation of our implementation shows that behaviour planning significantly outperforms the current diverse planning method in generating diverse plans measured on our new customisable diversity models. Our implementation is the first diverse planning approach to support planning categories beyond classical planning, such as over-subscription and numerical planning.",
    "summary": "arXiv:2405.04300v3 Announce Type: replace Abstract: Diverse planning approaches are utilised in real-world applications like risk management, automated streamed data analysis, and malware detection. The current diverse planning formulations encode the diversity model as a distance function, which is computational inexpensive when comparing two plans. However, such modelling approach limits what can be encoded as measure of diversity, as well as the ability to explain why two plans are different. This paper introduces a novel approach to the diverse planning problem, allowing for more expressive modelling of diversity using a n-dimensional grid representation, where each dimension corresponds to a user-defined feature. Furthermore, we present a novel toolkit that generates diverse plans based on such customisable diversity models, called emph{Behaviour Planning}. We provide an implementation for behaviour planning using planning-as-satisfiability. An empirical evaluation of our implementation shows that behaviour planning significantly outperforms the current diverse planning method in generating diverse plans measured on our new customisable diversity models. Our implementation is the first diverse planning approach to support planning categories beyond classical planning, such as over-subscription and numerical planning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.04300",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More",
    "description": "",
    "summary": "Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More At Inceptio...",
    "pubDate": "Tue, 08 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-3c3h-aragen-ifeval",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_3c3h_aragen.png"
  },
  {
    "title": "TALE: A Tool-Augmented Framework for Reference-Free Evaluation of Large Language Models",
    "description": "arXiv:2504.07385v2 Announce Type: replace-cross Abstract: As Large Language Models (LLMs) become increasingly integrated into real-world, autonomous applications, relying on static, pre-annotated references for evaluation poses significant challenges in cost, scalability, and completeness. We propose Tool-Augmented LLM Evaluation (TALE), a framework to assess LLM outputs without predetermined ground-truth answers. Unlike conventional metrics that compare to fixed references or depend solely on LLM-as-a-judge knowledge, TALE employs an agent with tool-access capabilities that actively retrieves and synthesizes external evidence. It iteratively generates web queries, collects information, summarizes findings, and refines subsequent searches through reflection. By shifting away from static references, TALE aligns with free-form question-answering tasks common in real-world scenarios. Experimental results on multiple free-form QA benchmarks show that TALE not only outperforms standard reference-based metrics for measuring response accuracy but also achieves substantial to near-perfect agreement with human evaluations. TALE enhances the reliability of LLM evaluations in real-world, dynamic scenarios without relying on static references.",
    "summary": "arXiv:2504.07385v2 Announce Type: replace-cross Abstract: As Large Language Models (LLMs) become increasingly integrated into real-world, autonomous applications, relying on static, pre-annotated references for evaluation poses significant challenges in cost, scalability, and completeness. We propose Tool-Augmented LLM Evaluation (TALE), a framework to assess LLM outputs without predetermined ground-truth answers. Unlike conventional metrics that compare to fixed references or depend solely on LLM-as-a-judge knowledge, TALE employs an agent with tool-access capabilities that actively retrieves and synthesizes external evidence. It iteratively generates web queries, collects information, summarizes findings, and refines subsequent searches through reflection. By shifting away from static references, TALE aligns with free-form question-answering tasks common in real-world scenarios. Experimental results on multiple free-form QA benchmarks show that TALE not only outperforms standard reference-based metrics for measuring response accuracy but also achieves substantial to near-perfect agreement with human evaluations. TALE enhances the reliability of LLM evaluations in real-world, dynamic scenarios without relying on static references.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.07385",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evaluating potential cybersecurity threats of advanced AI",
    "description": "Our framework enables cybersecurity experts to identify which defenses are necessary‚Äîand how to prioritize them",
    "summary": "Our framework enables cybersecurity experts to identify which defenses are necessary‚Äîand how to prioritize them",
    "pubDate": "Wed, 02 Apr 2025 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/evaluating-potential-cybersecurity-threats-of-advanced-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/qVftghWK2fcPAfl80FKEGIuxUxYuwlN2guNdIpH5A1nF4KYf5jufujNE7j3zv5uJ3CGPEJ47ec4UaUa1vl8H3rpuEX8jIkdQlXgCEYeGhAAEj3p06IY=w1200-h630-n-nu"
  },
  {
    "title": "Round Attention: A Novel Round-Level Attention Mechanism to Accelerate LLM Inference",
    "description": "arXiv:2502.15294v3 Announce Type: replace-cross Abstract: The increasing context window size in large language models (LLMs) has improved their ability to handle complex, long-text tasks. However, as the conversation rounds continue, it is required to store a large amount of KV cache in GPU memory, which significantly affects the efficiency and even availability of the model serving systems. This paper analyzes dialogue data from real users on the granularity of round and discovers that the LLM inference manifests a watershed layer, after which the distribution of round-level attention shows notable similarity. Based on this, we propose Round Attention - a novel round-level attention mechanism that selectively processes the KV cache of top-k relevant rounds, where k is dynamically determined through the attention matrix in the watershed layer. Theoretical analysis demonstrates that our method reduces memory usage by 54% to 82%, while experimental results confirm that loading sparse critical-round KV cache maintains answer accuracy without performance degradation.",
    "summary": "arXiv:2502.15294v3 Announce Type: replace-cross Abstract: The increasing context window size in large language models (LLMs) has improved their ability to handle complex, long-text tasks. However, as the conversation rounds continue, it is required to store a large amount of KV cache in GPU memory, which significantly affects the efficiency and even availability of the model serving systems. This paper analyzes dialogue data from real users on the granularity of round and discovers that the LLM inference manifests a watershed layer, after which the distribution of round-level attention shows notable similarity. Based on this, we propose Round Attention - a novel round-level attention mechanism that selectively processes the KV cache of top-k relevant rounds, where k is dynamically determined through the attention matrix in the watershed layer. Theoretical analysis demonstrates that our method reduces memory usage by 54% to 82%, while experimental results confirm that loading sparse critical-round KV cache maintains answer accuracy without performance degradation.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.15294",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Operator System Card",
    "description": "Drawing from OpenAI‚Äôs established safety frameworks, this document highlights our multi-layered approach, including model and product mitigations we‚Äôve implemented to protect against prompt engineering and jailbreaks, protect privacy and security, as well as details our external red teaming efforts, safety evaluations, and ongoing work to further refine these safeguards.",
    "summary": "Drawing from OpenAI‚Äôs established safety frameworks, this document highlights our multi-layered approach, including model and product mitigations we‚Äôve implemented to protect against prompt engineering and jailbreaks, protect privacy and security, as well as details our external red teaming efforts, safety evaluations, and ongoing work to further refine these safeguards.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/operator-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning Dynamics in Continual Pre-Training for Large Language Models",
    "description": "arXiv:2505.07796v2 Announce Type: replace-cross Abstract: Continual Pre-Training (CPT) has become a popular and effective method to apply strong foundation models to specific downstream tasks. In this work, we explore the learning dynamics throughout the CPT process for large language models. We specifically focus on how general and downstream domain performance evolves at each training step, with domain performance measured via validation losses. We have observed that the CPT loss curve fundamentally characterizes the transition from one curve to another hidden curve, and could be described by decoupling the effects of distribution shift and learning rate annealing. We derive a CPT scaling law that combines the two factors, enabling the prediction of loss at any (continual) training steps and across learning rate schedules (LRS) in CPT. Our formulation presents a comprehensive understanding of several critical factors in CPT, including loss potential, peak learning rate, training steps, replay ratio, etc. Moreover, our approach can be adapted to customize training hyper-parameters to different CPT goals such as balancing general and domain-specific performance. Extensive experiments demonstrate that our scaling law holds across various CPT datasets and training hyper-parameters.",
    "summary": "arXiv:2505.07796v2 Announce Type: replace-cross Abstract: Continual Pre-Training (CPT) has become a popular and effective method to apply strong foundation models to specific downstream tasks. In this work, we explore the learning dynamics throughout the CPT process for large language models. We specifically focus on how general and downstream domain performance evolves at each training step, with domain performance measured via validation losses. We have observed that the CPT loss curve fundamentally characterizes the transition from one curve to another hidden curve, and could be described by decoupling the effects of distribution shift and learning rate annealing. We derive a CPT scaling law that combines the two factors, enabling the prediction of loss at any (continual) training steps and across learning rate schedules (LRS) in CPT. Our formulation presents a comprehensive understanding of several critical factors in CPT, including loss potential, peak learning rate, training steps, replay ratio, etc. Moreover, our approach can be adapted to customize training hyper-parameters to different CPT goals such as balancing general and domain-specific performance. Extensive experiments demonstrate that our scaling law holds across various CPT datasets and training hyper-parameters.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.07796",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PlantBert: An Open Source Language Model for Plant Science",
    "description": "arXiv:2506.08897v2 Announce Type: replace-cross Abstract: The rapid advancement of transformer-based language models has catalyzed breakthroughs in biomedical and clinical natural language processing; however, plant science remains markedly underserved by such domain-adapted tools. In this work, we present PlantBert, a high-performance, open-source language model specifically tailored for extracting structured knowledge from plant stress-response literature. Built upon the DeBERTa architecture-known for its disentangled attention and robust contextual encoding-PlantBert is fine-tuned on a meticulously curated corpus of expert-annotated abstracts, with a primary focus on lentil (Lens culinaris) responses to diverse abiotic and biotic stressors. Our methodology combines transformer-based modeling with rule-enhanced linguistic post-processing and ontology-grounded entity normalization, enabling PlantBert to capture biologically meaningful relationships with precision and semantic fidelity. The underlying corpus is annotated using a hierarchical schema aligned with the Crop Ontology, encompassing molecular, physiological, biochemical, and agronomic dimensions of plant adaptation. PlantBert exhibits strong generalization capabilities across entity types and demonstrates the feasibility of robust domain adaptation in low-resource scientific fields. By providing a scalable and reproducible framework for high-resolution entity recognition, PlantBert bridges a critical gap in agricultural NLP and paves the way for intelligent, data-driven systems in plant genomics, phenomics, and agronomic knowledge discovery. Our model is publicly released to promote transparency and accelerate cross-disciplinary innovation in computational plant science.",
    "summary": "arXiv:2506.08897v2 Announce Type: replace-cross Abstract: The rapid advancement of transformer-based language models has catalyzed breakthroughs in biomedical and clinical natural language processing; however, plant science remains markedly underserved by such domain-adapted tools. In this work, we present PlantBert, a high-performance, open-source language model specifically tailored for extracting structured knowledge from plant stress-response literature. Built upon the DeBERTa architecture-known for its disentangled attention and robust contextual encoding-PlantBert is fine-tuned on a meticulously curated corpus of expert-annotated abstracts, with a primary focus on lentil (Lens culinaris) responses to diverse abiotic and biotic stressors. Our methodology combines transformer-based modeling with rule-enhanced linguistic post-processing and ontology-grounded entity normalization, enabling PlantBert to capture biologically meaningful relationships with precision and semantic fidelity. The underlying corpus is annotated using a hierarchical schema aligned with the Crop Ontology, encompassing molecular, physiological, biochemical, and agronomic dimensions of plant adaptation. PlantBert exhibits strong generalization capabilities across entity types and demonstrates the feasibility of robust domain adaptation in low-resource scientific fields. By providing a scalable and reproducible framework for high-resolution entity recognition, PlantBert bridges a critical gap in agricultural NLP and paves the way for intelligent, data-driven systems in plant genomics, phenomics, and agronomic knowledge discovery. Our model is publicly released to promote transparency and accelerate cross-disciplinary innovation in computational plant science.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.08897",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CryoCCD: Conditional Cycle-consistent Diffusion with Biophysical Modeling for Cryo-EM Synthesis",
    "description": "arXiv:2505.23444v2 Announce Type: replace-cross Abstract: Cryo-electron microscopy (cryo-EM) offers near-atomic resolution imaging of macromolecules, but developing robust models for downstream analysis is hindered by the scarcity of high-quality annotated data. While synthetic data generation has emerged as a potential solution, existing methods often fail to capture both the structural diversity of biological specimens and the complex, spatially varying noise inherent in cryo-EM imaging. To overcome these limitations, we propose CryoCCD, a synthesis framework that integrates biophysical modeling with generative techniques. Specifically, CryoCCD produces multi-scale cryo-EM micrographs that reflect realistic biophysical variability through compositional heterogeneity, cellular context, and physics-informed imaging. To generate realistic noise, we employ a conditional diffusion model, enhanced by cycle consistency to preserve structural fidelity and mask-aware contrastive learning to capture spatially adaptive noise patterns. Extensive experiments show that CryoCCD generates structurally accurate micrographs and enhances performance in downstream tasks, outperforming state-of-the-art baselines in both particle picking and reconstruction.",
    "summary": "arXiv:2505.23444v2 Announce Type: replace-cross Abstract: Cryo-electron microscopy (cryo-EM) offers near-atomic resolution imaging of macromolecules, but developing robust models for downstream analysis is hindered by the scarcity of high-quality annotated data. While synthetic data generation has emerged as a potential solution, existing methods often fail to capture both the structural diversity of biological specimens and the complex, spatially varying noise inherent in cryo-EM imaging. To overcome these limitations, we propose CryoCCD, a synthesis framework that integrates biophysical modeling with generative techniques. Specifically, CryoCCD produces multi-scale cryo-EM micrographs that reflect realistic biophysical variability through compositional heterogeneity, cellular context, and physics-informed imaging. To generate realistic noise, we employ a conditional diffusion model, enhanced by cycle consistency to preserve structural fidelity and mask-aware contrastive learning to capture spatially adaptive noise patterns. Extensive experiments show that CryoCCD generates structurally accurate micrographs and enhances performance in downstream tasks, outperforming state-of-the-art baselines in both particle picking and reconstruction.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.23444",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "UCB exploration via Q-ensembles",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 05 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ucb-exploration-via-q-ensembles",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "NTT Com„ÇÇÂèÇÂÖ•„ÄÄNTT„Ç∞„É´„Éº„Éó„ÅØAI„Ç®„Éº„Ç∏„Çß„É≥„Éà‰∫ãÊ•≠„Å´Á∑èÂäõ„ÇíÁµêÈõÜ„Åß„Åç„Çã„ÅãÔºü",
    "description": "‚ÄúÁôæËä±Áπö‰π±‚Äù„ÅÆAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂ∏ÇÂ†¥„Å´„Åä„ÅÑ„Å¶„ÄÅNTT Com„ÅåÊ•≠Âãô„ÄÅÊ•≠ÁïåÂà•„ÅÆ„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥„ÇíÊâì„Å°Âá∫„Åó„Åü„ÄÇNTT„Éá„Éº„Çø„ÇÇÊó¢„Å´AI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂ∏ÇÂ†¥„Å´ÂèÇÂÖ•„Åó„Å¶„ÅÑ„Çã„Åå„ÄÅNTT„Ç∞„É´„Éº„Éó„Å®„Åó„Å¶„Åì„ÅÆÂàÜÈáé„Å´Á∑èÂäõ„ÇíÁµêÈõÜ„Åô„ÇãÊÖãÂã¢„Å´„Å™„ÇäÂæó„Çã„ÅÆ„Å†„Çç„ÅÜ„Åã„ÄÇ",
    "summary": "‚ÄúÁôæËä±Áπö‰π±‚Äù„ÅÆAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂ∏ÇÂ†¥„Å´„Åä„ÅÑ„Å¶„ÄÅNTT Com„ÅåÊ•≠Âãô„ÄÅÊ•≠ÁïåÂà•„ÅÆ„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥„ÇíÊâì„Å°Âá∫„Åó„Åü„ÄÇNTT„Éá„Éº„Çø„ÇÇÊó¢„Å´AI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÂ∏ÇÂ†¥„Å´ÂèÇÂÖ•„Åó„Å¶„ÅÑ„Çã„Åå„ÄÅNTT„Ç∞„É´„Éº„Éó„Å®„Åó„Å¶„Åì„ÅÆÂàÜÈáé„Å´Á∑èÂäõ„ÇíÁµêÈõÜ„Åô„ÇãÊÖãÂã¢„Å´„Å™„ÇäÂæó„Çã„ÅÆ„Å†„Çç„ÅÜ„Åã„ÄÇ",
    "pubDate": "Mon, 23 Jun 2025 16:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/23/news064.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/23/cover_news064.jpg"
  },
  {
    "title": "Cannot See the Forest for the Trees: Invoking Heuristics and Biases to Elicit Irrational Choices of LLMs",
    "description": "arXiv:2505.02862v3 Announce Type: replace-cross Abstract: Despite the remarkable performance of Large Language Models (LLMs), they remain vulnerable to jailbreak attacks, which can compromise their safety mechanisms. Existing studies often rely on brute-force optimization or manual design, failing to uncover potential risks in real-world scenarios. To address this, we propose a novel jailbreak attack framework, ICRT, inspired by heuristics and biases in human cognition. Leveraging the simplicity effect, we employ cognitive decomposition to reduce the complexity of malicious prompts. Simultaneously, relevance bias is utilized to reorganize prompts, enhancing semantic alignment and inducing harmful outputs effectively. Furthermore, we introduce a ranking-based harmfulness evaluation metric that surpasses the traditional binary success-or-failure paradigm by employing ranking aggregation methods such as Elo, HodgeRank, and Rank Centrality to comprehensively quantify the harmfulness of generated content. Experimental results show that our approach consistently bypasses mainstream LLMs' safety mechanisms and generates high-risk content, providing insights into jailbreak attack risks and contributing to stronger defense strategies.",
    "summary": "arXiv:2505.02862v3 Announce Type: replace-cross Abstract: Despite the remarkable performance of Large Language Models (LLMs), they remain vulnerable to jailbreak attacks, which can compromise their safety mechanisms. Existing studies often rely on brute-force optimization or manual design, failing to uncover potential risks in real-world scenarios. To address this, we propose a novel jailbreak attack framework, ICRT, inspired by heuristics and biases in human cognition. Leveraging the simplicity effect, we employ cognitive decomposition to reduce the complexity of malicious prompts. Simultaneously, relevance bias is utilized to reorganize prompts, enhancing semantic alignment and inducing harmful outputs effectively. Furthermore, we introduce a ranking-based harmfulness evaluation metric that surpasses the traditional binary success-or-failure paradigm by employing ranking aggregation methods such as Elo, HodgeRank, and Rank Centrality to comprehensively quantify the harmfulness of generated content. Experimental results show that our approach consistently bypasses mainstream LLMs' safety mechanisms and generates high-risk content, providing insights into jailbreak attack risks and contributing to stronger defense strategies.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.02862",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sim-to-real transfer of robotic control with dynamics randomization",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 18 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sim-to-real-transfer-of-robotic-control-with-dynamics-randomization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MIXI„ÅÆ‰ºöË©±„É≠„Éú„ÄÅASD„ÉªADHDÂΩì‰∫ãËÄÖÂêë„Åë„ÅÆÊñ∞„É¢„Éá„É´Áô∫Â£≤„ÄÄ‰ºöË©±„ÇíÈÄö„Åò„ÄÅËá™Ë∫´„ÅÆÁâπÊÄßÁêÜËß£„Åô„Çã„Çµ„Éù„Éº„Éà",
    "description": "MIXI„ÅØ„ÄÅËá™Èñâ„Çπ„Éö„ÇØ„Éà„É©„É†ÁóáÔºàASDÔºâ„Å®Ê≥®ÊÑèÊ¨†Â¶Ç„ÉªÂ§öÂãïÁóáÔºàADHDÔºâÂΩì‰∫ãËÄÖ„ÅÆÁ§æ‰ºö‰∫∫Âêë„Åë„Å´„ÄÅAI‰ºöË©±„É≠„Éú„ÉÉ„Éà„ÄåRomi„Äç„ÅÆÊñ∞„É¢„Éá„É´„Äå„É©„Ç§„Éï„Çπ„Ç≠„É´„Éà„É¨„Éº„Éã„É≥„Ç∞„É¢„Éá„É´„Äç„ÇíÁô∫Â£≤„Åó„Åü„ÄÇRomi„Å®„ÅÆ‰ºöË©±„ÇíÈÄö„Åò„Å¶„ÄÅASD„ÉªADHDÂΩì‰∫ãËÄÖ„ÅåËá™Ë∫´„ÅÆÁâπÊÄß„ÇíÁêÜËß£„Åô„ÇãÊâãÂä©„Åë„Çí„Åô„Çã„Å®„ÅÑ„ÅÜ„ÄÇ",
    "summary": "MIXI„ÅØ„ÄÅËá™Èñâ„Çπ„Éö„ÇØ„Éà„É©„É†ÁóáÔºàASDÔºâ„Å®Ê≥®ÊÑèÊ¨†Â¶Ç„ÉªÂ§öÂãïÁóáÔºàADHDÔºâÂΩì‰∫ãËÄÖ„ÅÆÁ§æ‰ºö‰∫∫Âêë„Åë„Å´„ÄÅAI‰ºöË©±„É≠„Éú„ÉÉ„Éà„ÄåRomi„Äç„ÅÆÊñ∞„É¢„Éá„É´„Äå„É©„Ç§„Éï„Çπ„Ç≠„É´„Éà„É¨„Éº„Éã„É≥„Ç∞„É¢„Éá„É´„Äç„ÇíÁô∫Â£≤„Åó„Åü„ÄÇRomi„Å®„ÅÆ‰ºöË©±„ÇíÈÄö„Åò„Å¶„ÄÅASD„ÉªADHDÂΩì‰∫ãËÄÖ„ÅåËá™Ë∫´„ÅÆÁâπÊÄß„ÇíÁêÜËß£„Åô„ÇãÊâãÂä©„Åë„Çí„Åô„Çã„Å®„ÅÑ„ÅÜ„ÄÇ",
    "pubDate": "Fri, 20 Jun 2025 18:36:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/20/news099.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/20/cover_news099.jpg"
  },
  {
    "title": "OpenAI o1 System Card",
    "description": "This report outlines the safety work carried out prior to releasing OpenAI o1 and o1-mini, including external red teaming and frontier risk evaluations according to our Preparedness Framework.",
    "summary": "This report outlines the safety work carried out prior to releasing OpenAI o1 and o1-mini, including external red teaming and frontier risk evaluations according to our Preparedness Framework.",
    "pubDate": "Thu, 05 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Security Review of Gradio 5",
    "description": "",
    "summary": "A Security Review of Gradio 5 We audited Gradio 5 so that your machine learning apps are safe! In th...",
    "pubDate": "Thu, 10 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-5-security",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-5-security/thumbnail.png"
  },
  {
    "title": "Projected Compression: Trainable Projection for Efficient Transformer Compression",
    "description": "arXiv:2506.22255v1 Announce Type: cross Abstract: Large language models have steadily increased in size to achieve improved performance; however, this growth has also led to greater inference time and computational demands. Consequently, there is rising interest in model size reduction methods. To address this issue, we propose Projected Compression, a novel model compression technique, that reduces model weights by utilizing projection modules. Specifically, we first train additional trainable projections weights and preserve access to all the original model parameters. Subsequently, these projections are merged into a lower-dimensional product matrix, resulting in a reduced-size standard Transformer-based model. Unlike alternative approaches that require additional computational overhead, our method matches the base model's per-token computation step in FLOPs. Experimental results show that Projected Compression outperforms the comparable hard pruning and retraining approach on higher quality models. Moreover, the performance margin scales well with the number of tokens.",
    "summary": "arXiv:2506.22255v1 Announce Type: cross Abstract: Large language models have steadily increased in size to achieve improved performance; however, this growth has also led to greater inference time and computational demands. Consequently, there is rising interest in model size reduction methods. To address this issue, we propose Projected Compression, a novel model compression technique, that reduces model weights by utilizing projection modules. Specifically, we first train additional trainable projections weights and preserve access to all the original model parameters. Subsequently, these projections are merged into a lower-dimensional product matrix, resulting in a reduced-size standard Transformer-based model. Unlike alternative approaches that require additional computational overhead, our method matches the base model's per-token computation step in FLOPs. Experimental results show that Projected Compression outperforms the comparable hard pruning and retraining approach on higher quality models. Moreover, the performance margin scales well with the number of tokens.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22255",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Realtime API",
    "description": "Developers can now build fast speech-to-speech experiences into their applications",
    "summary": "Developers can now build fast speech-to-speech experiences into their applications",
    "pubDate": "Tue, 01 Oct 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-realtime-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Has Machine Translation Evaluation Achieved Human Parity? The Human Reference and the Limits of Progress",
    "description": "arXiv:2506.19571v1 Announce Type: cross Abstract: In Machine Translation (MT) evaluation, metric performance is assessed based on agreement with human judgments. In recent years, automatic metrics have demonstrated increasingly high levels of agreement with humans. To gain a clearer understanding of metric performance and establish an upper bound, we incorporate human baselines in the MT meta-evaluation, that is, the assessment of MT metrics' capabilities. Our results show that human annotators are not consistently superior to automatic metrics, with state-of-the-art metrics often ranking on par with or higher than human baselines. Despite these findings suggesting human parity, we discuss several reasons for caution. Finally, we explore the broader implications of our results for the research field, asking: Can we still reliably measure improvements in MT evaluation? With this work, we aim to shed light on the limits of our ability to measure progress in the field, fostering discussion on an issue that we believe is crucial to the entire MT evaluation community.",
    "summary": "arXiv:2506.19571v1 Announce Type: cross Abstract: In Machine Translation (MT) evaluation, metric performance is assessed based on agreement with human judgments. In recent years, automatic metrics have demonstrated increasingly high levels of agreement with humans. To gain a clearer understanding of metric performance and establish an upper bound, we incorporate human baselines in the MT meta-evaluation, that is, the assessment of MT metrics' capabilities. Our results show that human annotators are not consistently superior to automatic metrics, with state-of-the-art metrics often ranking on par with or higher than human baselines. Despite these findings suggesting human parity, we discuss several reasons for caution. Finally, we explore the broader implications of our results for the research field, asking: Can we still reliably measure improvements in MT evaluation? With this work, we aim to shed light on the limits of our ability to measure progress in the field, fostering discussion on an issue that we believe is crucial to the entire MT evaluation community.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19571",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„Äå„É©„Éº„É°„É≥„Çí„ÇÜ„Åß„Çã„Äç„Å´„ÇÇÁîüÊàêAI„ÅÆÊôÇ‰ª£„ÅåÊù•„Åü„Åû",
    "description": "„É©„Éº„É°„É≥„ÉÅ„Çß„Éº„É≥„Äå„É©„Éº„É°„É≥Â±±Â≤°ÂÆ∂„Äç„Åå„ÄÅÈ∫∫„Çí„ÇÜ„Åß„ÇãÈ†ÜÁï™„ÇíÂá¶ÁêÜ„Åô„ÇãÈöõ„ÄÅAmazon„ÅÆÁîüÊàêAI„Çµ„Éº„Éì„Çπ„ÄåAmazon Bedrock„Äç„ÇíÊ¥ªÁî®„Åó„Å¶„ÅÑ„Çã„ÄÅ„Å®„ÅÑ„ÅÜ„Åì„Å®„ÅåÊòé„Çâ„Åã„Å´„Å™„Å£„Åü„ÄÇÁîªÈù¢„ÅÆ‰∏≠„ÅÆAI„Åå„ÄÅÂé®Êàø„Å®„ÅÑ„ÅÜÁâ©ÁêÜÁ©∫Èñì„Å´Èôç„Çä„Å¶„Åç„ÅüÊÑü„Åò„Åå„Åó„Å¶Êñ∞ÈÆÆ„Å™‰∫ã‰æã„Å†„ÄÇ",
    "summary": "„É©„Éº„É°„É≥„ÉÅ„Çß„Éº„É≥„Äå„É©„Éº„É°„É≥Â±±Â≤°ÂÆ∂„Äç„Åå„ÄÅÈ∫∫„Çí„ÇÜ„Åß„ÇãÈ†ÜÁï™„ÇíÂá¶ÁêÜ„Åô„ÇãÈöõ„ÄÅAmazon„ÅÆÁîüÊàêAI„Çµ„Éº„Éì„Çπ„ÄåAmazon Bedrock„Äç„ÇíÊ¥ªÁî®„Åó„Å¶„ÅÑ„Çã„ÄÅ„Å®„ÅÑ„ÅÜ„Åì„Å®„ÅåÊòé„Çâ„Åã„Å´„Å™„Å£„Åü„ÄÇÁîªÈù¢„ÅÆ‰∏≠„ÅÆAI„Åå„ÄÅÂé®Êàø„Å®„ÅÑ„ÅÜÁâ©ÁêÜÁ©∫Èñì„Å´Èôç„Çä„Å¶„Åç„ÅüÊÑü„Åò„Åå„Åó„Å¶Êñ∞ÈÆÆ„Å™‰∫ã‰æã„Å†„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 11:39:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/30/news068.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/30/cover_news068.jpg"
  },
  {
    "title": "Supercharged Searching on the Hugging Face Hub",
    "description": "",
    "summary": "Supercharged Searching on the Hugging Face Hub The huggingface_hub library is a lightweight interfac...",
    "pubDate": "Tue, 25 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/searching-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/48_hubsearch/thumbnail.png"
  },
  {
    "title": "Partnership with American Journalism Project to support local news",
    "description": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
    "summary": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
    "pubDate": "Tue, 18 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/partnership-with-american-journalism-project-to-support-local-news",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A closer look inside AI Mode",
    "description": "Two smartphones showing AI Mode. The left phone shows an AI Mode prompt being entered: ‚Äòthings to do in nashville this weekend with friends, we‚Äôre big foodies who like music but also more chill vibes and exploring off the beaten path‚Äô. The right phone sho",
    "summary": "Two smartphones showing AI Mode. The left phone shows an AI Mode prompt being entered: ‚Äòthings to do in nashville this weekend with friends, we‚Äôre big foodies who like music but also more chill vibes and exploring off the beaten path‚Äô. The right phone sho",
    "pubDate": "Thu, 05 Jun 2025 18:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/ai-mode-development/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Meet_AI_mode_ss.width-1300.png"
  },
  {
    "title": "GPT-4o System Card External Testers Acknowledgements",
    "description": "GPT-4o system card external testers acknowledgements",
    "summary": "GPT-4o system card external testers acknowledgements",
    "pubDate": "Thu, 08 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-system-card/external-testers-acknowledgements",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ML-Master: Towards AI-for-AI via Integration of Exploration and Reasoning",
    "description": "arXiv:2506.16499v1 Announce Type: new Abstract: As AI capabilities advance toward and potentially beyond human-level performance, a natural transition emerges where AI-driven development becomes more efficient than human-centric approaches. A promising pathway toward this transition lies in AI-for-AI (AI4AI), which leverages AI techniques to automate and optimize the design, training, and deployment of AI systems themselves. While LLM-based agents have shown the potential to realize AI4AI, they are often unable to fully leverage the experience accumulated by agents during the exploration of solutions in the reasoning process, leading to inefficiencies and suboptimal performance. To address this limitation, we propose ML-Master, a novel AI4AI agent that seamlessly integrates exploration and reasoning by employing a selectively scoped memory mechanism. This approach allows ML-Master to efficiently combine diverse insights from parallel solution trajectories with analytical reasoning, guiding further exploration without overwhelming the agent with excessive context. We evaluate ML-Master on the MLE-Bench, where it achieves a 29.3% average medal rate, significantly surpassing existing methods, particularly in medium-complexity tasks, while accomplishing this superior performance within a strict 12-hour time constraint-half the 24-hour limit used by previous baselines. These results demonstrate ML-Master's potential as a powerful tool for advancing AI4AI.",
    "summary": "arXiv:2506.16499v1 Announce Type: new Abstract: As AI capabilities advance toward and potentially beyond human-level performance, a natural transition emerges where AI-driven development becomes more efficient than human-centric approaches. A promising pathway toward this transition lies in AI-for-AI (AI4AI), which leverages AI techniques to automate and optimize the design, training, and deployment of AI systems themselves. While LLM-based agents have shown the potential to realize AI4AI, they are often unable to fully leverage the experience accumulated by agents during the exploration of solutions in the reasoning process, leading to inefficiencies and suboptimal performance. To address this limitation, we propose ML-Master, a novel AI4AI agent that seamlessly integrates exploration and reasoning by employing a selectively scoped memory mechanism. This approach allows ML-Master to efficiently combine diverse insights from parallel solution trajectories with analytical reasoning, guiding further exploration without overwhelming the agent with excessive context. We evaluate ML-Master on the MLE-Bench, where it achieves a 29.3% average medal rate, significantly surpassing existing methods, particularly in medium-complexity tasks, while accomplishing this superior performance within a strict 12-hour time constraint-half the 24-hour limit used by previous baselines. These results demonstrate ML-Master's potential as a powerful tool for advancing AI4AI.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16499",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Radial Attention: $O(nlog n)$ Sparse Attention with Energy Decay for Long Video Generation",
    "description": "arXiv:2506.19852v1 Announce Type: cross Abstract: Recent advances in diffusion models have enabled high-quality video generation, but the additional temporal dimension significantly increases computational costs, making training and inference on long videos prohibitively expensive. In this paper, we identify a phenomenon we term Spatiotemporal Energy Decay in video diffusion models: post-softmax attention scores diminish as spatial and temporal distance between tokens increase, akin to the physical decay of signal or waves over space and time in nature. Motivated by this, we propose Radial Attention, a scalable sparse attention mechanism with $O(n log n)$ complexity that translates energy decay into exponentially decaying compute density, which is significantly more efficient than standard $O(n^2)$ dense attention and more expressive than linear attention. Specifically, Radial Attention employs a simple, static attention mask where each token attends to spatially nearby tokens, with the attention window size shrinking with temporal distance. Moreover, it allows pre-trained video diffusion models to extend their generation length with efficient LoRA-based fine-tuning. Extensive experiments show that Radial Attention maintains video quality across Wan2.1-14B, HunyuanVideo, and Mochi 1, achieving up to a 1.9$times$ speedup over the original dense attention. With minimal tuning, it enables video generation up to 4$times$ longer while reducing training costs by up to 4.4$times$ compared to direct fine-tuning and accelerating inference by up to 3.7$times$ compared to dense attention inference.",
    "summary": "arXiv:2506.19852v1 Announce Type: cross Abstract: Recent advances in diffusion models have enabled high-quality video generation, but the additional temporal dimension significantly increases computational costs, making training and inference on long videos prohibitively expensive. In this paper, we identify a phenomenon we term Spatiotemporal Energy Decay in video diffusion models: post-softmax attention scores diminish as spatial and temporal distance between tokens increase, akin to the physical decay of signal or waves over space and time in nature. Motivated by this, we propose Radial Attention, a scalable sparse attention mechanism with $O(n log n)$ complexity that translates energy decay into exponentially decaying compute density, which is significantly more efficient than standard $O(n^2)$ dense attention and more expressive than linear attention. Specifically, Radial Attention employs a simple, static attention mask where each token attends to spatially nearby tokens, with the attention window size shrinking with temporal distance. Moreover, it allows pre-trained video diffusion models to extend their generation length with efficient LoRA-based fine-tuning. Extensive experiments show that Radial Attention maintains video quality across Wan2.1-14B, HunyuanVideo, and Mochi 1, achieving up to a 1.9$times$ speedup over the original dense attention. With minimal tuning, it enables video generation up to 4$times$ longer while reducing training costs by up to 4.4$times$ compared to direct fine-tuning and accelerating inference by up to 3.7$times$ compared to dense attention inference.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19852",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Celebrating an academic-industry collaboration to advance vehicle technology",
    "description": "MIT Advanced Vehicle Technology Consortium marks a decade of developing data that improve understanding of how drivers use and respond to increasingly sophisticated automotive features.",
    "summary": "MIT Advanced Vehicle Technology Consortium marks a decade of developing data that improve understanding of how drivers use and respond to increasingly sophisticated automotive features.",
    "pubDate": "Mon, 16 Jun 2025 14:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/celebrating-academic-industry-collaboration-advance-vehicle-technology-0616",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-AVT-conference.jpg"
  },
  {
    "title": "Porting fairseq wmt19 translation system to transformers",
    "description": "",
    "summary": "Porting fairseq wmt19 translation system to transformers A guest blog post by Stas Bekman This artic...",
    "pubDate": "Tue, 03 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/porting-fsmt",
    "thumbnail": "https://huggingface.co/blog/assets/07_porting_fsmt/thumbnail.png"
  },
  {
    "title": "Improved Techniques for Training Consistency Models",
    "description": "Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training.",
    "summary": "Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improved-techniques-for-training-consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The power of continuous learning",
    "description": "Lilian Weng works on Applied AI Research at OpenAI.",
    "summary": "Lilian Weng works on Applied AI Research at OpenAI.",
    "pubDate": "Fri, 23 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-power-of-continuous-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action",
    "description": "",
    "summary": "Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action Hugging Face provides a Hub platf...",
    "pubDate": "Wed, 09 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-deepfloydif-using-bentoml",
    "thumbnail": "https://huggingface.co/blog/assets/deploy-deepfloydif-using-bentoml/thumbnail.png"
  },
  {
    "title": "JETHICS: Japanese Ethics Understanding Evaluation Dataset",
    "description": "arXiv:2506.16187v1 Announce Type: cross Abstract: In this work, we propose JETHICS, a Japanese dataset for evaluating ethics understanding of AI models. JETHICS contains 78K examples and is built by following the construction methods of the existing English ETHICS dataset. It includes four categories based normative theories and concepts from ethics and political philosophy; and one representing commonsense morality. Our evaluation experiments on non-proprietary large language models (LLMs) and on GPT-4o reveal that even GPT-4o achieves only an average score of about 0.7, while the best-performing Japanese LLM attains around 0.5, indicating a relatively large room for improvement in current LLMs.",
    "summary": "arXiv:2506.16187v1 Announce Type: cross Abstract: In this work, we propose JETHICS, a Japanese dataset for evaluating ethics understanding of AI models. JETHICS contains 78K examples and is built by following the construction methods of the existing English ETHICS dataset. It includes four categories based normative theories and concepts from ethics and political philosophy; and one representing commonsense morality. Our evaluation experiments on non-proprietary large language models (LLMs) and on GPT-4o reveal that even GPT-4o achieves only an average score of about 0.7, while the best-performing Japanese LLM attains around 0.5, indicating a relatively large room for improvement in current LLMs.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16187",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reinforcement Learning Fine-Tuning of Language Model for Instruction Following and Math Reasoning",
    "description": "arXiv:2506.21560v1 Announce Type: cross Abstract: This study investigates the effectiveness of reinforcement learning (RL) fine-tuning techniques on a compact language model (Qwen2.5-0.5B Base) for two challenging tasks: instruction following and mathematical reasoning. We compare supervised fine-tuning (SFT), Direct Preference Optimization (DPO) using preference-labeled data, and Reinforce Leave-One-Out (RLOO) with reward models. Our experiments show that RLOO with DeBERTa reward modeling achieves the best alignment, while DPO provides strong and consistent results. For math reasoing tasks, synthetic data augmentation and best-of-N sampling with an external verifier significantly improve accuracy, showing the potential of combining fine-tuning with inference-time tools. This study highlights key trade-offs and practical strategies for training lightweight, task-aligned small-scale language models.",
    "summary": "arXiv:2506.21560v1 Announce Type: cross Abstract: This study investigates the effectiveness of reinforcement learning (RL) fine-tuning techniques on a compact language model (Qwen2.5-0.5B Base) for two challenging tasks: instruction following and mathematical reasoning. We compare supervised fine-tuning (SFT), Direct Preference Optimization (DPO) using preference-labeled data, and Reinforce Leave-One-Out (RLOO) with reward models. Our experiments show that RLOO with DeBERTa reward modeling achieves the best alignment, while DPO provides strong and consistent results. For math reasoing tasks, synthetic data augmentation and best-of-N sampling with an external verifier significantly improve accuracy, showing the potential of combining fine-tuning with inference-time tools. This study highlights key trade-offs and practical strategies for training lightweight, task-aligned small-scale language models.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21560",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Driving growth and ‚ÄòWOW‚Äô moments with OpenAI",
    "description": "LY Corporation: Driving growth and ‚ÄòWOW‚Äô moments with OpenAI",
    "summary": "LY Corporation: Driving growth and ‚ÄòWOW‚Äô moments with OpenAI",
    "pubDate": "Wed, 12 Mar 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ly-corporation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Outbound coordinated vulnerability disclosure policy",
    "description": "Outbound coordinated vulnerability disclosure policy",
    "summary": "Outbound coordinated vulnerability disclosure policy",
    "pubDate": "Mon, 09 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/policies/outbound-coordinated-disclosure-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Federated Incomplete Multi-view Clustering with Globally Fused Graph Guidance",
    "description": "arXiv:2506.15703v1 Announce Type: cross Abstract: Federated multi-view clustering has been proposed to mine the valuable information within multi-view data distributed across different devices and has achieved impressive results while preserving the privacy. Despite great progress, most federated multi-view clustering methods only used global pseudo-labels to guide the downstream clustering process and failed to exploit the global information when extracting features. In addition, missing data problem in federated multi-view clustering task is less explored. To address these problems, we propose a novel Federated Incomplete Multi-view Clustering method with globally Fused Graph guidance (FIMCFG). Specifically, we designed a dual-head graph convolutional encoder at each client to extract two kinds of underlying features containing global and view-specific information. Subsequently, under the guidance of the fused graph, the two underlying features are fused into high-level features, based on which clustering is conducted under the supervision of pseudo-labeling. Finally, the high-level features are uploaded to the server to refine the graph fusion and pseudo-labeling computation. Extensive experimental results demonstrate the effectiveness and superiority of FIMCFG. Our code is publicly available at https://github.com/PaddiHunter/FIMCFG.",
    "summary": "arXiv:2506.15703v1 Announce Type: cross Abstract: Federated multi-view clustering has been proposed to mine the valuable information within multi-view data distributed across different devices and has achieved impressive results while preserving the privacy. Despite great progress, most federated multi-view clustering methods only used global pseudo-labels to guide the downstream clustering process and failed to exploit the global information when extracting features. In addition, missing data problem in federated multi-view clustering task is less explored. To address these problems, we propose a novel Federated Incomplete Multi-view Clustering method with globally Fused Graph guidance (FIMCFG). Specifically, we designed a dual-head graph convolutional encoder at each client to extract two kinds of underlying features containing global and view-specific information. Subsequently, under the guidance of the fused graph, the two underlying features are fused into high-level features, based on which clustering is conducted under the supervision of pseudo-labeling. Finally, the high-level features are uploaded to the server to refine the graph fusion and pseudo-labeling computation. Extensive experimental results demonstrate the effectiveness and superiority of FIMCFG. Our code is publicly available at https://github.com/PaddiHunter/FIMCFG.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15703",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing GPT-4.5",
    "description": "We‚Äôre releasing a research preview of GPT‚Äë4.5‚Äîour largest and best model for chat yet. GPT‚Äë4.5 is a step forward in scaling up pre-training and post-training.",
    "summary": "We‚Äôre releasing a research preview of GPT‚Äë4.5‚Äîour largest and best model for chat yet. GPT‚Äë4.5 is a step forward in scaling up pre-training and post-training.",
    "pubDate": "Thu, 27 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-gpt-4-5",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MuseNet",
    "description": "We‚Äôve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose unsupervised technology as¬†GPT-2, a large-scale¬†transformer¬†model trained to predict the next token in a sequence, whether audio or¬†text.",
    "summary": "We‚Äôve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose unsupervised technology as¬†GPT-2, a large-scale¬†transformer¬†model trained to predict the next token in a sequence, whether audio or¬†text.",
    "pubDate": "Thu, 25 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/musenet",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Systematic Review of Human-AI Co-Creativity",
    "description": "arXiv:2506.21333v2 Announce Type: replace-cross Abstract: The co creativity community is making significant progress in developing more sophisticated and tailored systems to support and enhance human creativity. Design considerations from prior work can serve as a valuable and efficient foundation for future systems. To support this effort, we conducted a systematic literature review of 62 papers on co-creative systems. These papers cover a diverse range of applications, including visual arts, design, and writing, where the AI acts not just as a tool but as an active collaborator in the creative process. From this review, we identified several key dimensions relevant to system design: phase of the creative process, creative task, proactive behavior of the system, user control, system embodiment, and AI model type. Our findings suggest that systems offering high user control lead to greater satisfaction, trust, and a stronger sense of ownership over creative outcomes. Furthermore, proactive systems, when adaptive and context sensitive, can enhance collaboration. We also extracted 24 design considerations, highlighting the value of encouraging users to externalize their thoughts and of increasing the system's social presence and transparency to foster trust. Despite recent advancements, important gaps remain, such as limited support for early creative phases like problem clarification, and challenges related to user adaptation to AI systems.",
    "summary": "arXiv:2506.21333v2 Announce Type: replace-cross Abstract: The co creativity community is making significant progress in developing more sophisticated and tailored systems to support and enhance human creativity. Design considerations from prior work can serve as a valuable and efficient foundation for future systems. To support this effort, we conducted a systematic literature review of 62 papers on co-creative systems. These papers cover a diverse range of applications, including visual arts, design, and writing, where the AI acts not just as a tool but as an active collaborator in the creative process. From this review, we identified several key dimensions relevant to system design: phase of the creative process, creative task, proactive behavior of the system, user control, system embodiment, and AI model type. Our findings suggest that systems offering high user control lead to greater satisfaction, trust, and a stronger sense of ownership over creative outcomes. Furthermore, proactive systems, when adaptive and context sensitive, can enhance collaboration. We also extracted 24 design considerations, highlighting the value of encouraging users to externalize their thoughts and of increasing the system's social presence and transparency to foster trust. Despite recent advancements, important gaps remain, such as limited support for early creative phases like problem clarification, and challenges related to user adaptation to AI systems.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21333",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Practical Approach to Power Saving in Hearables Using Sub-Nyquist Sampling with Bandwidth Extension",
    "description": "arXiv:2506.22321v1 Announce Type: cross Abstract: Hearables are wearable computers that are worn on the ear. Bone conduction microphones (BCMs) are used with air conduction microphones (ACMs) in hearables as a supporting modality for multimodal speech enhancement (SE) in noisy conditions. However, existing works don't consider the following practical aspects for low-power implementations on hearables: (i) They do not explore how lowering the sampling frequencies and bit resolutions in analog-to-digital converters (ADCs) of hearables jointly impact low-power processing and multimodal SE in terms of speech quality and intelligibility. (ii) They don't discuss how GAN-like audio quality can be achieved without using actual GAN discriminators. And (iii) They don't process signals from ACMs/BCMs at sub-Nyquist sampling rate because, in their frameworks, they lack a wideband reconstruction methodology from their narrowband parts. We propose SUBARU (textbf{Sub}-Nyquist textbf{A}udio textbf{R}esolution textbf{U}psampling), which achieves the following: SUBARU (i) intentionally uses sub-Nyquist sampling and low bit resolution in ADCs, achieving a 3.31x reduction in power consumption; (ii) introduces novel multi-scale and multi-period virtual discriminators, which achieve GAN-like audio quality without using GANs' adversarial training; and (iii) achieves streaming operations on mobile platforms and SE in in-the-wild noisy conditions with an inference time of 1.74ms and a memory footprint of less than 13.77MB.",
    "summary": "arXiv:2506.22321v1 Announce Type: cross Abstract: Hearables are wearable computers that are worn on the ear. Bone conduction microphones (BCMs) are used with air conduction microphones (ACMs) in hearables as a supporting modality for multimodal speech enhancement (SE) in noisy conditions. However, existing works don't consider the following practical aspects for low-power implementations on hearables: (i) They do not explore how lowering the sampling frequencies and bit resolutions in analog-to-digital converters (ADCs) of hearables jointly impact low-power processing and multimodal SE in terms of speech quality and intelligibility. (ii) They don't discuss how GAN-like audio quality can be achieved without using actual GAN discriminators. And (iii) They don't process signals from ACMs/BCMs at sub-Nyquist sampling rate because, in their frameworks, they lack a wideband reconstruction methodology from their narrowband parts. We propose SUBARU (textbf{Sub}-Nyquist textbf{A}udio textbf{R}esolution textbf{U}psampling), which achieves the following: SUBARU (i) intentionally uses sub-Nyquist sampling and low bit resolution in ADCs, achieving a 3.31x reduction in power consumption; (ii) introduces novel multi-scale and multi-period virtual discriminators, which achieve GAN-like audio quality without using GANs' adversarial training; and (iii) achieves streaming operations on mobile platforms and SE in in-the-wild noisy conditions with an inference time of 1.74ms and a memory footprint of less than 13.77MB.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22321",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Creating Privacy Preserving AI with Substra",
    "description": "",
    "summary": "Creating Privacy Preserving AI with Substra With the recent rise of generative techniques, machine l...",
    "pubDate": "Wed, 12 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/owkin-substra",
    "thumbnail": "https://huggingface.co/blog/assets/139_owkin-substra/thumbnail.png"
  },
  {
    "title": "Transfer of adversarial robustness between perturbation types",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 03 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/transfer-of-adversarial-robustness-between-perturbation-types",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing GPT-4.1 in the API",
    "description": "Introducing GPT-4.1 in the API‚Äîa new family of models with across-the-board improvements, including major gains in coding, instruction following, and long-context understanding. We‚Äôre also releasing our first nano model. Available to developers worldwide starting today.",
    "summary": "Introducing GPT-4.1 in the API‚Äîa new family of models with across-the-board improvements, including major gains in coding, instruction following, and long-context understanding. We‚Äôre also releasing our first nano model. Available to developers worldwide starting today.",
    "pubDate": "Mon, 14 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-1",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Data-driven beauty and creativity with ChatGPT",
    "description": "Data-driven beauty: How The Est√©e Lauder Companies unlocks insights with ChatGPT",
    "summary": "Data-driven beauty: How The Est√©e Lauder Companies unlocks insights with ChatGPT",
    "pubDate": "Wed, 13 Nov 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/estee-lauder",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SHAMaNS: Sound Localization with Hybrid Alpha-Stable Spatial Measure and Neural Steerer",
    "description": "arXiv:2506.18954v1 Announce Type: cross Abstract: This paper describes a sound source localization (SSL) technique that combines an $alpha$-stable model for the observed signal with a neural network-based approach for modeling steering vectors. Specifically, a physics-informed neural network, referred to as Neural Steerer, is used to interpolate measured steering vectors (SVs) on a fixed microphone array. This allows for a more robust estimation of the so-called $alpha$-stable spatial measure, which represents the most plausible direction of arrival (DOA) of a target signal. As an $alpha$-stable model for the non-Gaussian case ($alpha$ $in$ (0, 2)) theoretically defines a unique spatial measure, we choose to leverage it to account for residual reconstruction error of the Neural Steerer in the downstream tasks. The objective scores indicate that our proposed technique outperforms state-of-the-art methods in the case of multiple sound sources.",
    "summary": "arXiv:2506.18954v1 Announce Type: cross Abstract: This paper describes a sound source localization (SSL) technique that combines an $alpha$-stable model for the observed signal with a neural network-based approach for modeling steering vectors. Specifically, a physics-informed neural network, referred to as Neural Steerer, is used to interpolate measured steering vectors (SVs) on a fixed microphone array. This allows for a more robust estimation of the so-called $alpha$-stable spatial measure, which represents the most plausible direction of arrival (DOA) of a target signal. As an $alpha$-stable model for the non-Gaussian case ($alpha$ $in$ (0, 2)) theoretically defines a unique spatial measure, we choose to leverage it to account for residual reconstruction error of the Neural Steerer in the downstream tasks. The objective scores indicate that our proposed technique outperforms state-of-the-art methods in the case of multiple sound sources.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18954",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SynthID Detector ‚Äî a new portal to help identify AI-generated content",
    "description": "Learn about the new SynthID Detector portal we announced at I/O to help people understand how the content they see online was generated.",
    "summary": "Learn about the new SynthID Detector portal we announced at I/O to help people understand how the content they see online was generated.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/synthid-detector--a-new-portal-to-help-identify-ai-generated-content/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_Gemini_MOD_HEADER.width-1300.jpg"
  },
  {
    "title": "Active Learning with AutoNLP and Prodigy",
    "description": "",
    "summary": "Active Learning with AutoNLP and Prodigy Active learning in the context of Machine Learning is a pro...",
    "pubDate": "Thu, 23 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autonlp-prodigy",
    "thumbnail": "https://huggingface.co/blog/assets/43_autonlp_prodigy/thumbnail.png"
  },
  {
    "title": "Part$^{2}$GS: Part-aware Modeling of Articulated Objects using 3D Gaussian Splatting",
    "description": "arXiv:2506.17212v1 Announce Type: cross Abstract: Articulated objects are common in the real world, yet modeling their structure and motion remains a challenging task for 3D reconstruction methods. In this work, we introduce Part$^{2}$GS, a novel framework for modeling articulated digital twins of multi-part objects with high-fidelity geometry and physically consistent articulation. Part$^{2}$GS leverages a part-aware 3D Gaussian representation that encodes articulated components with learnable attributes, enabling structured, disentangled transformations that preserve high-fidelity geometry. To ensure physically consistent motion, we propose a motion-aware canonical representation guided by physics-based constraints, including contact enforcement, velocity consistency, and vector-field alignment. Furthermore, we introduce a field of repel points to prevent part collisions and maintain stable articulation paths, significantly improving motion coherence over baselines. Extensive evaluations on both synthetic and real-world datasets show that Part$^{2}$GS consistently outperforms state-of-the-art methods by up to 10$times$ in Chamfer Distance for movable parts.",
    "summary": "arXiv:2506.17212v1 Announce Type: cross Abstract: Articulated objects are common in the real world, yet modeling their structure and motion remains a challenging task for 3D reconstruction methods. In this work, we introduce Part$^{2}$GS, a novel framework for modeling articulated digital twins of multi-part objects with high-fidelity geometry and physically consistent articulation. Part$^{2}$GS leverages a part-aware 3D Gaussian representation that encodes articulated components with learnable attributes, enabling structured, disentangled transformations that preserve high-fidelity geometry. To ensure physically consistent motion, we propose a motion-aware canonical representation guided by physics-based constraints, including contact enforcement, velocity consistency, and vector-field alignment. Furthermore, we introduce a field of repel points to prevent part collisions and maintain stable articulation paths, significantly improving motion coherence over baselines. Extensive evaluations on both synthetic and real-world datasets show that Part$^{2}$GS consistently outperforms state-of-the-art methods by up to 10$times$ in Chamfer Distance for movable parts.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17212",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Structured Attention Matters to Multimodal LLMs in Document Understanding",
    "description": "arXiv:2506.21600v1 Announce Type: cross Abstract: Document understanding remains a significant challenge for multimodal large language models (MLLMs). While previous research has primarily focused on locating evidence pages through precise multimodal queries, our work investigates a fundamental yet overlooked aspect: how input format influences document comprehension performance. Through systematic analysis, we discover that raw OCR text often impairs rather than improves MLLMs' performance, which is a counterintuitive finding we attribute to attention dispersion and structure loss. To further substantiate our hypothesis, we propose a novel structure-preserving approach that encodes document elements using the LaTex paradigm, maintaining the hierarchical organization and spatial relationships critical for comprehension. Our attention analysis reveals that structured text induces structured attention patterns on both textual and visual content, directing models to focus on semantically meaningful regions while reducing attention waste. This approach significantly enhances MLLMs' document question answering performance across diverse document types without requiring architectural modifications or additional training.",
    "summary": "arXiv:2506.21600v1 Announce Type: cross Abstract: Document understanding remains a significant challenge for multimodal large language models (MLLMs). While previous research has primarily focused on locating evidence pages through precise multimodal queries, our work investigates a fundamental yet overlooked aspect: how input format influences document comprehension performance. Through systematic analysis, we discover that raw OCR text often impairs rather than improves MLLMs' performance, which is a counterintuitive finding we attribute to attention dispersion and structure loss. To further substantiate our hypothesis, we propose a novel structure-preserving approach that encodes document elements using the LaTex paradigm, maintaining the hierarchical organization and spatial relationships critical for comprehension. Our attention analysis reveals that structured text induces structured attention patterns on both textual and visual content, directing models to focus on semantically meaningful regions while reducing attention waste. This approach significantly enhances MLLMs' document question answering performance across diverse document types without requiring architectural modifications or additional training.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21600",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Releasing Outlines-core 0.1.0: structured generation in Rust and Python",
    "description": "",
    "summary": "Releasing Outlines-core 0.1.0: structured generation in Rust and Python dottxt and Hugging Face are ...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/outlines-core",
    "thumbnail": "https://huggingface.co/blog/assets/outlines-core/thumbnail.gif"
  },
  {
    "title": "DALL¬∑E now available without waitlist",
    "description": "New users can start creating straight away. Lessons learned from deployment and improvements to our safety systems make wider availability possible.",
    "summary": "New users can start creating straight away. Lessons learned from deployment and improvements to our safety systems make wider availability possible.",
    "pubDate": "Wed, 28 Sep 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-now-available-without-waitlist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Doc2SAR: A Synergistic Framework for High-Fidelity Extraction of Structure-Activity Relationships from Scientific Documents",
    "description": "arXiv:2506.21625v1 Announce Type: cross Abstract: Extracting molecular structure-activity relationships (SARs) from scientific literature and patents is essential for drug discovery and materials research. However, this task remains challenging due to heterogeneous document formats and limitations of existing methods. Specifically, rule-based approaches relying on rigid templates fail to generalize across diverse document layouts, while general-purpose multimodal large language models (MLLMs) lack sufficient accuracy and reliability for specialized tasks, such as layout detection and optical chemical structure recognition (OCSR). To address these challenges, we introduce DocSAR-200, a rigorously annotated benchmark of 200 scientific documents designed specifically for evaluating SAR extraction methods. Additionally, we propose Doc2SAR, a novel synergistic framework that integrates domain-specific tools with MLLMs enhanced via supervised fine-tuning (SFT). Extensive experiments demonstrate that Doc2SAR achieves state-of-the-art performance across various document types, significantly outperforming leading end-to-end baselines. Specifically, Doc2SAR attains an overall Table Recall of 80.78% on DocSAR-200, exceeding end2end GPT-4o by 51.48%. Furthermore, Doc2SAR demonstrates practical usability through efficient inference and is accompanied by a web app.",
    "summary": "arXiv:2506.21625v1 Announce Type: cross Abstract: Extracting molecular structure-activity relationships (SARs) from scientific literature and patents is essential for drug discovery and materials research. However, this task remains challenging due to heterogeneous document formats and limitations of existing methods. Specifically, rule-based approaches relying on rigid templates fail to generalize across diverse document layouts, while general-purpose multimodal large language models (MLLMs) lack sufficient accuracy and reliability for specialized tasks, such as layout detection and optical chemical structure recognition (OCSR). To address these challenges, we introduce DocSAR-200, a rigorously annotated benchmark of 200 scientific documents designed specifically for evaluating SAR extraction methods. Additionally, we propose Doc2SAR, a novel synergistic framework that integrates domain-specific tools with MLLMs enhanced via supervised fine-tuning (SFT). Extensive experiments demonstrate that Doc2SAR achieves state-of-the-art performance across various document types, significantly outperforming leading end-to-end baselines. Specifically, Doc2SAR attains an overall Table Recall of 80.78% on DocSAR-200, exceeding end2end GPT-4o by 51.48%. Furthermore, Doc2SAR demonstrates practical usability through efficient inference and is accompanied by a web app.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21625",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Short Summary of Chinese AI Global Expansion",
    "description": "",
    "summary": "A Short Summary of Chinese AI Global Expansion In the early 15th century, Zheng He (also known as Ch...",
    "pubDate": "Thu, 03 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chinese-ai-expansion",
    "thumbnail": "https://huggingface.co/blog/assets/chinese-ai-expansion/thumbnail.png"
  },
  {
    "title": "Benchmarking the Pedagogical Knowledge of Large Language Models",
    "description": "arXiv:2506.18710v2 Announce Type: replace-cross Abstract: Benchmarks like Massive Multitask Language Understanding (MMLU) have played a pivotal role in evaluating AI's knowledge and abilities across diverse domains. However, existing benchmarks predominantly focus on content knowledge, leaving a critical gap in assessing models' understanding of pedagogy - the method and practice of teaching. This paper introduces The Pedagogy Benchmark, a novel dataset designed to evaluate large language models on their Cross-Domain Pedagogical Knowledge (CDPK) and Special Education Needs and Disability (SEND) pedagogical knowledge. These benchmarks are built on a carefully curated set of questions sourced from professional development exams for teachers, which cover a range of pedagogical subdomains such as teaching strategies and assessment methods. Here we outline the methodology and development of these benchmarks. We report results for 97 models, with accuracies spanning a range from 28% to 89% on the pedagogical knowledge questions. We consider the relationship between cost and accuracy and chart the progression of the Pareto value frontier over time. We provide online leaderboards at https://rebrand.ly/pedagogy which are updated with new models and allow interactive exploration and filtering based on various model properties, such as cost per token and open-vs-closed weights, as well as looking at performance in different subjects. LLMs and generative AI have tremendous potential to influence education and help to address the global learning crisis. Education-focused benchmarks are crucial to measure models' capacities to understand pedagogical concepts, respond appropriately to learners' needs, and support effective teaching practices across diverse contexts. They are needed for informing the responsible and evidence-based deployment of LLMs and LLM-based tools in educational settings, and for guiding both development and policy decisions.",
    "summary": "arXiv:2506.18710v2 Announce Type: replace-cross Abstract: Benchmarks like Massive Multitask Language Understanding (MMLU) have played a pivotal role in evaluating AI's knowledge and abilities across diverse domains. However, existing benchmarks predominantly focus on content knowledge, leaving a critical gap in assessing models' understanding of pedagogy - the method and practice of teaching. This paper introduces The Pedagogy Benchmark, a novel dataset designed to evaluate large language models on their Cross-Domain Pedagogical Knowledge (CDPK) and Special Education Needs and Disability (SEND) pedagogical knowledge. These benchmarks are built on a carefully curated set of questions sourced from professional development exams for teachers, which cover a range of pedagogical subdomains such as teaching strategies and assessment methods. Here we outline the methodology and development of these benchmarks. We report results for 97 models, with accuracies spanning a range from 28% to 89% on the pedagogical knowledge questions. We consider the relationship between cost and accuracy and chart the progression of the Pareto value frontier over time. We provide online leaderboards at https://rebrand.ly/pedagogy which are updated with new models and allow interactive exploration and filtering based on various model properties, such as cost per token and open-vs-closed weights, as well as looking at performance in different subjects. LLMs and generative AI have tremendous potential to influence education and help to address the global learning crisis. Education-focused benchmarks are crucial to measure models' capacities to understand pedagogical concepts, respond appropriately to learners' needs, and support effective teaching practices across diverse contexts. They are needed for informing the responsible and evidence-based deployment of LLMs and LLM-based tools in educational settings, and for guiding both development and policy decisions.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18710",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How Hugging Face Accelerated Development of Witty Works Writing Assistant",
    "description": "",
    "summary": "How Hugging Face Accelerated Development of Witty Works Writing Assistant The Success Story of Witty...",
    "pubDate": "Wed, 01 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/classification-use-cases",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/witty-works.png"
  },
  {
    "title": "The Google for Startups Gemini kit is here",
    "description": "A blonde woman wearing a black top and red skit looks at the camera, describing the benefits of the Google for Startups Gemini Kit.",
    "summary": "A blonde woman wearing a black top and red skit looks at the camera, describing the benefits of the Google for Startups Gemini Kit.",
    "pubDate": "Thu, 26 Jun 2025 12:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/entrepreneurs/google-for-startups-gemini-ai-kit/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Paige_Thumbnail.width-1300.png"
  },
  {
    "title": "OpenAI and the CSU system bring AI to 500,000 students & faculty",
    "description": "The largest deployment of ChatGPT to date will expand the use of AI in education and help the United States build an AI-ready workforce.",
    "summary": "The largest deployment of ChatGPT to date will expand the use of AI in education and help the United States build an AI-ready workforce.",
    "pubDate": "Tue, 04 Feb 2025 11:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-the-csu-system",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "4M Models Scanned: Protect AI + Hugging Face 6 Months In",
    "description": "",
    "summary": "4M Models Scanned: Protect AI + Hugging Face 6 Months In Hugging Face and Protect AI partnered in Oc...",
    "pubDate": "Mon, 14 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pai-6-month",
    "thumbnail": "https://huggingface.co/blog/assets/pai-6-month/thumbnail.png"
  },
  {
    "title": "Learning to reason with LLMs",
    "description": "We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before it answers‚Äîit can produce a long internal chain of thought before responding to the user.",
    "summary": "We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex reasoning. o1 thinks before it answers‚Äîit can produce a long internal chain of thought before responding to the user.",
    "pubDate": "Thu, 12 Sep 2024 10:02:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-reason-with-llms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation",
    "description": "arXiv:2506.18810v2 Announce Type: replace Abstract: Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and OpenAI o1 series have achieved notable performance enhancements on complex reasoning tasks by scaling up the generation length by Chain-of-Thought (CoT). However, an emerging issue is their inclination to produce excessively verbose reasoning processes, leading to the inefficiency problem. Existing literature on improving efficiency mainly adheres to the before-reasoning paradigms such as prompting and reasoning or fine-tuning and reasoning, but ignores the promising direction of directly encouraging the model to speak concisely by intervening during the generation of reasoning. In order to fill the blank, we propose a framework dubbed ConciseHint, which continuously encourages the reasoning model to speak concisely by injecting the textual hint (manually designed or trained on the concise data) during the token generation of the reasoning process. Besides, ConciseHint is adaptive to the complexity of the query by adaptively adjusting the hint intensity, which ensures it will not undermine model performance. Experiments on the state-of-the-art LRMs, including DeepSeek-R1 and Qwen-3 series, demonstrate that our method can effectively produce concise reasoning processes while maintaining performance well. For instance, we achieve a reduction ratio of 65% for the reasoning length on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.",
    "summary": "arXiv:2506.18810v2 Announce Type: replace Abstract: Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and OpenAI o1 series have achieved notable performance enhancements on complex reasoning tasks by scaling up the generation length by Chain-of-Thought (CoT). However, an emerging issue is their inclination to produce excessively verbose reasoning processes, leading to the inefficiency problem. Existing literature on improving efficiency mainly adheres to the before-reasoning paradigms such as prompting and reasoning or fine-tuning and reasoning, but ignores the promising direction of directly encouraging the model to speak concisely by intervening during the generation of reasoning. In order to fill the blank, we propose a framework dubbed ConciseHint, which continuously encourages the reasoning model to speak concisely by injecting the textual hint (manually designed or trained on the concise data) during the token generation of the reasoning process. Besides, ConciseHint is adaptive to the complexity of the query by adaptively adjusting the hint intensity, which ensures it will not undermine model performance. Experiments on the state-of-the-art LRMs, including DeepSeek-R1 and Qwen-3 series, demonstrate that our method can effectively produce concise reasoning processes while maintaining performance well. For instance, we achieve a reduction ratio of 65% for the reasoning length on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18810",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Essential-Web v1.0: 24T tokens of organized web data",
    "description": "arXiv:2506.14111v2 Announce Type: replace-cross Abstract: Data plays the most prominent role in how language models acquire skills and knowledge. The lack of massive, well-organized pre-training datasets results in costly and inaccessible data pipelines. We present Essential-Web v1.0, a 24-trillion-token dataset in which every document is annotated with a twelve-category taxonomy covering topic, format, content complexity, and quality. Taxonomy labels are produced by EAI-Distill-0.5b, a fine-tuned 0.5b-parameter model that achieves an annotator agreement within 3% of Qwen2.5-32B-Instruct. With nothing more than SQL-style filters, we obtain competitive web-curated datasets in math (-8.0% relative to SOTA), web code (+14.3%), STEM (+24.5%) and medical (+8.6%). Essential-Web v1.0 is available on HuggingFace: https://huggingface.co/datasets/EssentialAI/essential-web-v1.0",
    "summary": "arXiv:2506.14111v2 Announce Type: replace-cross Abstract: Data plays the most prominent role in how language models acquire skills and knowledge. The lack of massive, well-organized pre-training datasets results in costly and inaccessible data pipelines. We present Essential-Web v1.0, a 24-trillion-token dataset in which every document is annotated with a twelve-category taxonomy covering topic, format, content complexity, and quality. Taxonomy labels are produced by EAI-Distill-0.5b, a fine-tuned 0.5b-parameter model that achieves an annotator agreement within 3% of Qwen2.5-32B-Instruct. With nothing more than SQL-style filters, we obtain competitive web-curated datasets in math (-8.0% relative to SOTA), web code (+14.3%), STEM (+24.5%) and medical (+8.6%). Essential-Web v1.0 is available on HuggingFace: https://huggingface.co/datasets/EssentialAI/essential-web-v1.0",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14111",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning from M-Tuple Dominant Positive and Unlabeled Data",
    "description": "arXiv:2506.15686v1 Announce Type: cross Abstract: Label Proportion Learning (LLP) addresses the classification problem where multiple instances are grouped into bags and each bag contains information about the proportion of each class. However, in practical applications, obtaining precise supervisory information regarding the proportion of instances in a specific class is challenging. To better align with real-world application scenarios and effectively leverage the proportional constraints of instances within tuples, this paper proposes a generalized learning framework emph{MDPU}. Specifically, we first mathematically model the distribution of instances within tuples of arbitrary size, under the constraint that the number of positive instances is no less than that of negative instances. Then we derive an unbiased risk estimator that satisfies risk consistency based on the empirical risk minimization (ERM) method. To mitigate the inevitable overfitting issue during training, a risk correction method is introduced, leading to the development of a corrected risk estimator. The generalization error bounds of the unbiased risk estimator theoretically demonstrate the consistency of the proposed method. Extensive experiments on multiple datasets and comparisons with other relevant baseline methods comprehensively validate the effectiveness of the proposed learning framework.",
    "summary": "arXiv:2506.15686v1 Announce Type: cross Abstract: Label Proportion Learning (LLP) addresses the classification problem where multiple instances are grouped into bags and each bag contains information about the proportion of each class. However, in practical applications, obtaining precise supervisory information regarding the proportion of instances in a specific class is challenging. To better align with real-world application scenarios and effectively leverage the proportional constraints of instances within tuples, this paper proposes a generalized learning framework emph{MDPU}. Specifically, we first mathematically model the distribution of instances within tuples of arbitrary size, under the constraint that the number of positive instances is no less than that of negative instances. Then we derive an unbiased risk estimator that satisfies risk consistency based on the empirical risk minimization (ERM) method. To mitigate the inevitable overfitting issue during training, a risk correction method is introduced, leading to the development of a corrected risk estimator. The generalization error bounds of the unbiased risk estimator theoretically demonstrate the consistency of the proposed method. Extensive experiments on multiple datasets and comparisons with other relevant baseline methods comprehensively validate the effectiveness of the proposed learning framework.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15686",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "What Makes a Dialog Agent Useful?",
    "description": "",
    "summary": "What Makes a Dialog Agent Useful? The techniques behind ChatGPT: RLHF, IFT, CoT, Red teaming, and mo...",
    "pubDate": "Tue, 24 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dialog-agents",
    "thumbnail": "https://huggingface.co/blog/assets/dialog-agents/thumbnail.png"
  },
  {
    "title": "Goodbye cold boot - how we made LoRA inference 300% faster",
    "description": "",
    "summary": "Goodbye cold boot - how we made LoRA Inference 300% faster tl;dr: We swap the Stable Diffusion LoRA ...",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lora-adapters-dynamic-loading",
    "thumbnail": "https://huggingface.co/blog/assets/171_load_lora_adapters/thumbnail3.png"
  },
  {
    "title": "Introducing Gemma 3",
    "description": "The most capable model you can run on a single GPU or TPU.",
    "summary": "The most capable model you can run on a single GPU or TPU.",
    "pubDate": "Wed, 12 Mar 2025 08:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemma-3/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemma3_KeywordBlog_RD3_V01b_SocialShare.width-1300.png"
  },
  {
    "title": "Arabic Dialect Classification using RNNs, Transformers, and Large Language Models: A Comparative Analysis",
    "description": "arXiv:2506.19753v1 Announce Type: cross Abstract: The Arabic language is among the most popular languages in the world with a huge variety of dialects spoken in 22 countries. In this study, we address the problem of classifying 18 Arabic dialects of the QADI dataset of Arabic tweets. RNN models, Transformer models, and large language models (LLMs) via prompt engineering are created and tested. Among these, MARBERTv2 performed best with 65% accuracy and 64% F1-score. Through the use of state-of-the-art preprocessing techniques and the latest NLP models, this paper identifies the most significant linguistic issues in Arabic dialect identification. The results corroborate applications like personalized chatbots that respond in users' dialects, social media monitoring, and greater accessibility for Arabic communities.",
    "summary": "arXiv:2506.19753v1 Announce Type: cross Abstract: The Arabic language is among the most popular languages in the world with a huge variety of dialects spoken in 22 countries. In this study, we address the problem of classifying 18 Arabic dialects of the QADI dataset of Arabic tweets. RNN models, Transformer models, and large language models (LLMs) via prompt engineering are created and tested. Among these, MARBERTv2 performed best with 65% accuracy and 64% F1-score. Through the use of state-of-the-art preprocessing techniques and the latest NLP models, this paper identifies the most significant linguistic issues in Arabic dialect identification. The results corroborate applications like personalized chatbots that respond in users' dialects, social media monitoring, and greater accessibility for Arabic communities.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19753",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Ark: An Open-source Python-based Framework for Robot Learning",
    "description": "arXiv:2506.21628v1 Announce Type: cross Abstract: Robotics has made remarkable hardware strides-from DARPA's Urban and Robotics Challenges to the first humanoid-robot kickboxing tournament-yet commercial autonomy still lags behind progress in machine learning. A major bottleneck is software: current robot stacks demand steep learning curves, low-level C/C++ expertise, fragmented tooling, and intricate hardware integration, in stark contrast to the Python-centric, well-documented ecosystems that propelled modern AI. We introduce ARK, an open-source, Python-first robotics framework designed to close that gap. ARK presents a Gym-style environment interface that allows users to collect data, preprocess it, and train policies using state-of-the-art imitation-learning algorithms (e.g., ACT, Diffusion Policy) while seamlessly toggling between high-fidelity simulation and physical robots. A lightweight client-server architecture provides networked publisher-subscriber communication, and optional C/C++ bindings ensure real-time performance when needed. ARK ships with reusable modules for control, SLAM, motion planning, system identification, and visualization, along with native ROS interoperability. Comprehensive documentation and case studies-from manipulation to mobile navigation-demonstrate rapid prototyping, effortless hardware swapping, and end-to-end pipelines that rival the convenience of mainstream machine-learning workflows. By unifying robotics and AI practices under a common Python umbrella, ARK lowers entry barriers and accelerates research and commercial deployment of autonomous robots.",
    "summary": "arXiv:2506.21628v1 Announce Type: cross Abstract: Robotics has made remarkable hardware strides-from DARPA's Urban and Robotics Challenges to the first humanoid-robot kickboxing tournament-yet commercial autonomy still lags behind progress in machine learning. A major bottleneck is software: current robot stacks demand steep learning curves, low-level C/C++ expertise, fragmented tooling, and intricate hardware integration, in stark contrast to the Python-centric, well-documented ecosystems that propelled modern AI. We introduce ARK, an open-source, Python-first robotics framework designed to close that gap. ARK presents a Gym-style environment interface that allows users to collect data, preprocess it, and train policies using state-of-the-art imitation-learning algorithms (e.g., ACT, Diffusion Policy) while seamlessly toggling between high-fidelity simulation and physical robots. A lightweight client-server architecture provides networked publisher-subscriber communication, and optional C/C++ bindings ensure real-time performance when needed. ARK ships with reusable modules for control, SLAM, motion planning, system identification, and visualization, along with native ROS interoperability. Comprehensive documentation and case studies-from manipulation to mobile navigation-demonstrate rapid prototyping, effortless hardware swapping, and end-to-end pipelines that rival the convenience of mainstream machine-learning workflows. By unifying robotics and AI practices under a common Python umbrella, ARK lowers entry barriers and accelerates research and commercial deployment of autonomous robots.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21628",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Baselines: DQN",
    "description": "We‚Äôre open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with performance on par with published results. We‚Äôll release the algorithms over upcoming months; today‚Äôs release includes DQN and three of its variants.",
    "summary": "We‚Äôre open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with performance on par with published results. We‚Äôll release the algorithms over upcoming months; today‚Äôs release includes DQN and three of its variants.",
    "pubDate": "Wed, 24 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-dqn",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Continual Learning with Columnar Spiking Neural Networks",
    "description": "arXiv:2506.17169v1 Announce Type: cross Abstract: This study investigates columnar-organized spiking neural networks (SNNs) for continual learning and catastrophic forgetting. Using CoLaNET (Columnar Layered Network), we show that microcolumns adapt most efficiently to new tasks when they lack shared structure with prior learning. We demonstrate how CoLaNET hyperparameters govern the trade-off between retaining old knowledge (stability) and acquiring new information (plasticity). Our optimal configuration learns ten sequential MNIST tasks effectively, maintaining 92% accuracy on each. It shows low forgetting, with only 4% performance degradation on the first task after training on nine subsequent tasks.",
    "summary": "arXiv:2506.17169v1 Announce Type: cross Abstract: This study investigates columnar-organized spiking neural networks (SNNs) for continual learning and catastrophic forgetting. Using CoLaNET (Columnar Layered Network), we show that microcolumns adapt most efficiently to new tasks when they lack shared structure with prior learning. We demonstrate how CoLaNET hyperparameters govern the trade-off between retaining old knowledge (stability) and acquiring new information (plasticity). Our optimal configuration learns ten sequential MNIST tasks effectively, maintaining 92% accuracy on each. It shows low forgetting, with only 4% performance degradation on the first task after training on nine subsequent tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17169",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Making sense of this mess",
    "description": "",
    "summary": "Making sense of this mess When I joined Hugging Face nearly 3 years ago, the Transformers documentat...",
    "pubDate": "Fri, 07 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-docs-redesign",
    "thumbnail": "https://huggingface.co/blog/assets/transformers-docs-redesign/thumbnail.png"
  },
  {
    "title": "Coding with OpenAI o1",
    "description": "Scott Wu, CEO and Co-Founder of Cognition, explains how OpenAI o1 makes coding decisions in a more human-like way.",
    "summary": "Scott Wu, CEO and Co-Founder of Cognition, explains how OpenAI o1 makes coding decisions in a more human-like way.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-coding",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ReMAR-DS: Recalibrated Feature Learning for Metal Artifact Reduction and CT Domain Transformation",
    "description": "arXiv:2506.19531v1 Announce Type: cross Abstract: Artifacts in kilo-Voltage CT (kVCT) imaging degrade image quality, impacting clinical decisions. We propose a deep learning framework for metal artifact reduction (MAR) and domain transformation from kVCT to Mega-Voltage CT (MVCT). The proposed framework, ReMAR-DS, utilizes an encoder-decoder architecture with enhanced feature recalibration, effectively reducing artifacts while preserving anatomical structures. This ensures that only relevant information is utilized in the reconstruction process. By infusing recalibrated features from the encoder block, the model focuses on relevant spatial regions (e.g., areas with artifacts) and highlights key features across channels (e.g., anatomical structures), leading to improved reconstruction of artifact-corrupted regions. Unlike traditional MAR methods, our approach bridges the gap between high-resolution kVCT and artifact-resistant MVCT, enhancing radiotherapy planning. It produces high-quality MVCT-like reconstructions, validated through qualitative and quantitative evaluations. Clinically, this enables oncologists to rely on kVCT alone, reducing repeated high-dose MVCT scans and lowering radiation exposure for cancer patients.",
    "summary": "arXiv:2506.19531v1 Announce Type: cross Abstract: Artifacts in kilo-Voltage CT (kVCT) imaging degrade image quality, impacting clinical decisions. We propose a deep learning framework for metal artifact reduction (MAR) and domain transformation from kVCT to Mega-Voltage CT (MVCT). The proposed framework, ReMAR-DS, utilizes an encoder-decoder architecture with enhanced feature recalibration, effectively reducing artifacts while preserving anatomical structures. This ensures that only relevant information is utilized in the reconstruction process. By infusing recalibrated features from the encoder block, the model focuses on relevant spatial regions (e.g., areas with artifacts) and highlights key features across channels (e.g., anatomical structures), leading to improved reconstruction of artifact-corrupted regions. Unlike traditional MAR methods, our approach bridges the gap between high-resolution kVCT and artifact-resistant MVCT, enhancing radiotherapy planning. It produces high-quality MVCT-like reconstructions, validated through qualitative and quantitative evaluations. Clinically, this enables oncologists to rely on kVCT alone, reducing repeated high-dose MVCT scans and lowering radiation exposure for cancer patients.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19531",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LastingBench: Defend Benchmarks Against Knowledge Leakage",
    "description": "arXiv:2506.21614v1 Announce Type: cross Abstract: The increasing complexity of large language models (LLMs) raises concerns about their ability to 'cheat' on standard Question Answering (QA) benchmarks by memorizing task-specific data. This undermines the validity of benchmark evaluations, as they no longer reflect genuine model capabilities but instead the effects of data leakage. While prior work has focused on detecting such leakage, little attention has been given to mitigating its impact and preserving the long-term utility of benchmarks. In this paper, we introduce LastingBench, a novel framework designed to continuously reinforce and safeguard existing benchmarks against knowledge leakage. LastingBench identifies leakage points in the context through perturbation, then rewrites the leakage points to counterfactual ones-disrupting memorization while preserving the benchmark's original evaluative intent. Evaluations of state-of-the-art QA benchmarks show significant performance gaps, highlighting the efficacy of LastingBench in reducing memorization effects. LastingBench offers a practical and scalable solution to ensure benchmark robustness over time, promoting fairer and more interpretable evaluations of LLMs.",
    "summary": "arXiv:2506.21614v1 Announce Type: cross Abstract: The increasing complexity of large language models (LLMs) raises concerns about their ability to 'cheat' on standard Question Answering (QA) benchmarks by memorizing task-specific data. This undermines the validity of benchmark evaluations, as they no longer reflect genuine model capabilities but instead the effects of data leakage. While prior work has focused on detecting such leakage, little attention has been given to mitigating its impact and preserving the long-term utility of benchmarks. In this paper, we introduce LastingBench, a novel framework designed to continuously reinforce and safeguard existing benchmarks against knowledge leakage. LastingBench identifies leakage points in the context through perturbation, then rewrites the leakage points to counterfactual ones-disrupting memorization while preserving the benchmark's original evaluative intent. Evaluations of state-of-the-art QA benchmarks show significant performance gaps, highlighting the efficacy of LastingBench in reducing memorization effects. LastingBench offers a practical and scalable solution to ensure benchmark robustness over time, promoting fairer and more interpretable evaluations of LLMs.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21614",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Tower+: Bridging Generality and Translation Specialization in Multilingual LLMs",
    "description": "arXiv:2506.17080v1 Announce Type: cross Abstract: Fine-tuning pretrained LLMs has been shown to be an effective strategy for reaching state-of-the-art performance on specific tasks like machine translation. However, this process of adaptation often implies sacrificing general-purpose capabilities, such as conversational reasoning and instruction-following, hampering the utility of the system in real-world applications that require a mixture of skills. In this paper, we introduce Tower+, a suite of models designed to deliver strong performance across both translation and multilingual general-purpose text capabilities. We achieve a Pareto frontier between translation specialization and multilingual general-purpose capabilities by introducing a novel training recipe that builds on Tower (Alves et al., 2024), comprising continued pretraining, supervised fine-tuning, preference optimization, and reinforcement learning with verifiable rewards. At each stage of training, we carefully generate and curate data to strengthen performance on translation as well as general-purpose tasks involving code generation, mathematics problem solving, and general instruction-following. We develop models at multiple scales: 2B, 9B, and 72B. Our smaller models often outperform larger general-purpose open-weight and proprietary LLMs (e.g., Llama 3.3 70B, GPT-4o). Our largest model delivers best-in-class translation performance for high-resource languages and top results in multilingual Arena Hard evaluations and in IF-MT, a benchmark we introduce for evaluating both translation and instruction-following. Our findings highlight that it is possible to rival frontier models in general capabilities, while optimizing for specific business domains, such as translation and localization.",
    "summary": "arXiv:2506.17080v1 Announce Type: cross Abstract: Fine-tuning pretrained LLMs has been shown to be an effective strategy for reaching state-of-the-art performance on specific tasks like machine translation. However, this process of adaptation often implies sacrificing general-purpose capabilities, such as conversational reasoning and instruction-following, hampering the utility of the system in real-world applications that require a mixture of skills. In this paper, we introduce Tower+, a suite of models designed to deliver strong performance across both translation and multilingual general-purpose text capabilities. We achieve a Pareto frontier between translation specialization and multilingual general-purpose capabilities by introducing a novel training recipe that builds on Tower (Alves et al., 2024), comprising continued pretraining, supervised fine-tuning, preference optimization, and reinforcement learning with verifiable rewards. At each stage of training, we carefully generate and curate data to strengthen performance on translation as well as general-purpose tasks involving code generation, mathematics problem solving, and general instruction-following. We develop models at multiple scales: 2B, 9B, and 72B. Our smaller models often outperform larger general-purpose open-weight and proprietary LLMs (e.g., Llama 3.3 70B, GPT-4o). Our largest model delivers best-in-class translation performance for high-resource languages and top results in multilingual Arena Hard evaluations and in IF-MT, a benchmark we introduce for evaluating both translation and instruction-following. Our findings highlight that it is possible to rival frontier models in general capabilities, while optimizing for specific business domains, such as translation and localization.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17080",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Klarna's AI assistant does the work of 700 full-time agents",
    "description": "Klarna is using AI to revolutionize personal shopping, customer service, and employee productivity.",
    "summary": "Klarna is using AI to revolutionize personal shopping, customer service, and employee productivity.",
    "pubDate": "Fri, 05 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/klarna",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Progressive Generation with Decomposable Flow Matching",
    "description": "arXiv:2506.19839v1 Announce Type: cross Abstract: Generating high-dimensional visual modalities is a computationally intensive task. A common solution is progressive generation, where the outputs are synthesized in a coarse-to-fine spectral autoregressive manner. While diffusion models benefit from the coarse-to-fine nature of denoising, explicit multi-stage architectures are rarely adopted. These architectures have increased the complexity of the overall approach, introducing the need for a custom diffusion formulation, decomposition-dependent stage transitions, add-hoc samplers, or a model cascade. Our contribution, Decomposable Flow Matching (DFM), is a simple and effective framework for the progressive generation of visual media. DFM applies Flow Matching independently at each level of a user-defined multi-scale representation (such as Laplacian pyramid). As shown by our experiments, our approach improves visual quality for both images and videos, featuring superior results compared to prior multistage frameworks. On Imagenet-1k 512px, DFM achieves 35.2% improvements in FDD scores over the base architecture and 26.4% over the best-performing baseline, under the same training compute. When applied to finetuning of large models, such as FLUX, DFM shows faster convergence speed to the training distribution. Crucially, all these advantages are achieved with a single model, architectural simplicity, and minimal modifications to existing training pipelines.",
    "summary": "arXiv:2506.19839v1 Announce Type: cross Abstract: Generating high-dimensional visual modalities is a computationally intensive task. A common solution is progressive generation, where the outputs are synthesized in a coarse-to-fine spectral autoregressive manner. While diffusion models benefit from the coarse-to-fine nature of denoising, explicit multi-stage architectures are rarely adopted. These architectures have increased the complexity of the overall approach, introducing the need for a custom diffusion formulation, decomposition-dependent stage transitions, add-hoc samplers, or a model cascade. Our contribution, Decomposable Flow Matching (DFM), is a simple and effective framework for the progressive generation of visual media. DFM applies Flow Matching independently at each level of a user-defined multi-scale representation (such as Laplacian pyramid). As shown by our experiments, our approach improves visual quality for both images and videos, featuring superior results compared to prior multistage frameworks. On Imagenet-1k 512px, DFM achieves 35.2% improvements in FDD scores over the base architecture and 26.4% over the best-performing baseline, under the same training compute. When applied to finetuning of large models, such as FLUX, DFM shows faster convergence speed to the training distribution. Crucially, all these advantages are achieved with a single model, architectural simplicity, and minimal modifications to existing training pipelines.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19839",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face Machine Learning Demos on arXiv",
    "description": "",
    "summary": "Hugging Face Machine Learning Demos on arXiv We‚Äôre very excited to announce that Hugging Face has co...",
    "pubDate": "Thu, 17 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arxiv",
    "thumbnail": "https://huggingface.co/blog/assets/arxiv/thumbnail.png"
  },
  {
    "title": "Scaling up BERT-like model Inference on modern CPU - Part 2",
    "description": "",
    "summary": "Scaling up BERT-like model Inference on modern CPU - Part 2 Introduction: Using Intel Software to Op...",
    "pubDate": "Thu, 04 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-cpu-scaling-part-2",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Bringing serverless GPU inference to Hugging Face users",
    "description": "",
    "summary": "Bringing serverless GPU inference to Hugging Face users Today, we are thrilled to announce the launc...",
    "pubDate": "Tue, 02 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cloudflare-workers-ai",
    "thumbnail": "https://huggingface.co/blog/assets/cloudflare-workers-ai/thumbnail.jpg"
  },
  {
    "title": "Train your ControlNet with diffusers",
    "description": "",
    "summary": "Train your ControlNet with diffusers üß® Introduction ControlNet is a neural network structure that al...",
    "pubDate": "Fri, 24 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-your-controlnet",
    "thumbnail": "https://huggingface.co/blog/assets/136_train-your-controlnet/thumbnail.png"
  },
  {
    "title": "LLMs Struggle to Perform Counterfactual Reasoning with Parametric Knowledge",
    "description": "arXiv:2506.15732v1 Announce Type: new Abstract: Large Language Models have been shown to contain extensive world knowledge in their parameters, enabling impressive performance on many knowledge intensive tasks. However, when deployed in novel settings, LLMs often encounter situations where they must integrate parametric knowledge with new or unfamiliar information. In this work, we explore whether LLMs can combine knowledge in-context with their parametric knowledge through the lens of counterfactual reasoning. Through synthetic and real experiments in multi-hop reasoning problems, we show that LLMs generally struggle with counterfactual reasoning, often resorting to exclusively using their parametric knowledge. Moreover, we show that simple post-hoc finetuning can struggle to instill counterfactual reasoning ability -- often leading to degradation in stored parametric knowledge. Ultimately, our work reveals important limitations of current LLM's abilities to re-purpose parametric knowledge in novel settings.",
    "summary": "arXiv:2506.15732v1 Announce Type: new Abstract: Large Language Models have been shown to contain extensive world knowledge in their parameters, enabling impressive performance on many knowledge intensive tasks. However, when deployed in novel settings, LLMs often encounter situations where they must integrate parametric knowledge with new or unfamiliar information. In this work, we explore whether LLMs can combine knowledge in-context with their parametric knowledge through the lens of counterfactual reasoning. Through synthetic and real experiments in multi-hop reasoning problems, we show that LLMs generally struggle with counterfactual reasoning, often resorting to exclusively using their parametric knowledge. Moreover, we show that simple post-hoc finetuning can struggle to instill counterfactual reasoning ability -- often leading to degradation in stored parametric knowledge. Ultimately, our work reveals important limitations of current LLM's abilities to re-purpose parametric knowledge in novel settings.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15732",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerating Stable Diffusion XL Inference with JAX on Cloud TPU v5e",
    "description": "",
    "summary": "Accelerating Stable Diffusion XL Inference with JAX on Cloud TPU v5e Generative AI models, such as S...",
    "pubDate": "Tue, 03 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_jax",
    "thumbnail": "https://huggingface.co/blog/assets/sdxl-jax/thumbnail.jpg"
  },
  {
    "title": "TGI Multi-LoRA: Deploy Once, Serve 30 Models",
    "description": "",
    "summary": "TGI Multi-LoRA: Deploy Once, Serve 30 models Are you tired of the complexity and expense of managing...",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/multi-lora-serving",
    "thumbnail": "https://huggingface.co/blog/assets/multi-lora-serving/thumbnail.png"
  },
  {
    "title": "OpenAI and Los Alamos National Laboratory announce research partnership",
    "description": "OpenAI and Los Alamos National Laboratory are working to develop safety evaluations to assess and measure biological capabilities and risks associated with frontier models.",
    "summary": "OpenAI and Los Alamos National Laboratory are working to develop safety evaluations to assess and measure biological capabilities and risks associated with frontier models.",
    "pubDate": "Wed, 10 Jul 2024 06:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-los-alamos-national-laboratory-work-together",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hindsight Experience Replay",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 05 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hindsight-experience-replay",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI o1",
    "description": "Introducing OpenAI o1",
    "summary": "Introducing OpenAI o1",
    "pubDate": "Thu, 12 Sep 2024 10:03:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-o1-preview",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Nonlinear computation in deep linear networks",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 29 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonlinear-computation-in-deep-linear-networks",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Search Live: Talk, listen and explore in real time with AI Mode",
    "description": "Logos for AI Mode in Search and Search Live in front of a black background",
    "summary": "Logos for AI Mode in Search and Search Live in front of a black background",
    "pubDate": "Wed, 18 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/search-live-ai-mode/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SearchLive_SS.width-1300.png"
  },
  {
    "title": "Process Reward Models That Think",
    "description": "arXiv:2504.16828v3 Announce Type: replace-cross Abstract: Step-by-step verifiers -- also known as process reward models (PRMs) -- are a key ingredient for test-time scaling. PRMs require step-level supervision, making them expensive to train. This work aims to build data-efficient PRMs as verbalized step-wise reward models that verify every step in the solution by generating a verification chain-of-thought (CoT). We propose ThinkPRM, a long CoT verifier fine-tuned on orders of magnitude fewer process labels than those required by discriminative PRMs. Our approach capitalizes on the inherent reasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and discriminative verifiers -- using only 1% of the process labels in PRM800K -- across several challenging benchmarks. Specifically, ThinkPRM beats the baselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and reward-guided search. In an out-of-domain evaluation on a subset of GPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers trained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the same token budget, ThinkPRM scales up verification compute more effectively compared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of ProcessBench. Our work highlights the value of generative, long CoT PRMs that can scale test-time compute for verification while requiring minimal supervision for training. Our code, data, and models will be released at https://github.com/mukhal/thinkprm.",
    "summary": "arXiv:2504.16828v3 Announce Type: replace-cross Abstract: Step-by-step verifiers -- also known as process reward models (PRMs) -- are a key ingredient for test-time scaling. PRMs require step-level supervision, making them expensive to train. This work aims to build data-efficient PRMs as verbalized step-wise reward models that verify every step in the solution by generating a verification chain-of-thought (CoT). We propose ThinkPRM, a long CoT verifier fine-tuned on orders of magnitude fewer process labels than those required by discriminative PRMs. Our approach capitalizes on the inherent reasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and discriminative verifiers -- using only 1% of the process labels in PRM800K -- across several challenging benchmarks. Specifically, ThinkPRM beats the baselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and reward-guided search. In an out-of-domain evaluation on a subset of GPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers trained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the same token budget, ThinkPRM scales up verification compute more effectively compared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of ProcessBench. Our work highlights the value of generative, long CoT PRMs that can scale test-time compute for verification while requiring minimal supervision for training. Our code, data, and models will be released at https://github.com/mukhal/thinkprm.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.16828",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„Äå‰∏âÂõΩÂøó„Äç„Å´Â≠¶„Å∂ÁîüÊàêAI„ÅÆÂ∞éÂÖ•Êé®ÈÄ≤„ÄÄ„ÄåÊé®ÈÄ≤Ê¥æ„Äç„ÄåÂèçÂØæÊ¥æ„Äç„ÄåÁÑ°Èñ¢ÂøÉÊ¥æ„Äç„ÅÆÂã¢Âäõ‰∫â„ÅÑ„ÄÅ„Åù„ÅÆÊîªÁï•Ê≥ï„ÅØÔºü",
    "description": "‰ºÅÊ•≠„Å´„Åä„Åë„ÇãÁîüÊàêAIÂ∞éÂÖ•„ÅåÈÄ≤„ÇÄ‰∏≠„ÄÅ‰ºÅÊ•≠ÂÜÖ„Å´„ÅØÁîüÊàêAI„Å´ÂØæ„Åó„Å¶„ÄåÊé®ÈÄ≤Ê¥æ„Äç„ÄåÂèçÂØæÊ¥æ„Äç„ÄåÁÑ°Èñ¢ÂøÉÊ¥æ„Äç„ÅÆ‰∏â„Å§„ÅÆÂã¢Âäõ„ÅåÂ≠òÂú®„Åô„Çã„ÄÇÁèæ‰ª£„ÅÆ‰∏âÂõΩÂøó„Å®„ÇÇ„ÅÑ„Åà„ÇãÁä∂Ê≥Å„Åß„ÄÅAIÊ¥ªÁî®„ÇíÊé®ÈÄ≤„Åó„Å¶„ÅÑ„Åè„Å´„ÅØ„Å©„ÅÜ„Åô„Çå„Å∞„ÅÑ„ÅÑ„Åã„ÄÇ‰∏âÂõΩÂøó„ÅÆÊ≠¥Âè≤„Å´ÂÄ£„ÅÑ„ÄÅËÄÉ„Åà„Çã„ÄÇ",
    "summary": "‰ºÅÊ•≠„Å´„Åä„Åë„ÇãÁîüÊàêAIÂ∞éÂÖ•„ÅåÈÄ≤„ÇÄ‰∏≠„ÄÅ‰ºÅÊ•≠ÂÜÖ„Å´„ÅØÁîüÊàêAI„Å´ÂØæ„Åó„Å¶„ÄåÊé®ÈÄ≤Ê¥æ„Äç„ÄåÂèçÂØæÊ¥æ„Äç„ÄåÁÑ°Èñ¢ÂøÉÊ¥æ„Äç„ÅÆ‰∏â„Å§„ÅÆÂã¢Âäõ„ÅåÂ≠òÂú®„Åô„Çã„ÄÇÁèæ‰ª£„ÅÆ‰∏âÂõΩÂøó„Å®„ÇÇ„ÅÑ„Åà„ÇãÁä∂Ê≥Å„Åß„ÄÅAIÊ¥ªÁî®„ÇíÊé®ÈÄ≤„Åó„Å¶„ÅÑ„Åè„Å´„ÅØ„Å©„ÅÜ„Åô„Çå„Å∞„ÅÑ„ÅÑ„Åã„ÄÇ‰∏âÂõΩÂøó„ÅÆÊ≠¥Âè≤„Å´ÂÄ£„ÅÑ„ÄÅËÄÉ„Åà„Çã„ÄÇ",
    "pubDate": "Fri, 27 Jun 2025 12:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/27/news018.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/27/cover_news018.jpg"
  },
  {
    "title": "Exploring the Structure of AI-Induced Language Change in Scientific English",
    "description": "arXiv:2506.21817v1 Announce Type: cross Abstract: Scientific English has undergone rapid and unprecedented changes in recent years, with words such as 'delve,' 'intricate,' and 'crucial' showing significant spikes in frequency since around 2022. These changes are widely attributed to the growing influence of Large Language Models like ChatGPT in the discourse surrounding bias and misalignment. However, apart from changes in frequency, the exact structure of these linguistic shifts has remained unclear. The present study addresses this and investigates whether these changes involve the replacement of synonyms by suddenly 'spiking words,' for example, 'crucial' replacing 'essential' and 'key,' or whether they reflect broader semantic and pragmatic qualifications. To further investigate structural changes, we include part of speech tagging in our analysis to quantify linguistic shifts over grammatical categories and differentiate between word forms, like 'potential' as a noun vs. as an adjective. We systematically analyze synonym groups for widely discussed 'spiking words' based on frequency trends in scientific abstracts from PubMed. We find that entire semantic clusters often shift together, with most or all words in a group increasing in usage. This pattern suggests that changes induced by Large Language Models are primarily semantic and pragmatic rather than purely lexical. Notably, the adjective 'important' shows a significant decline, which prompted us to systematically analyze decreasing lexical items. Our analysis of 'collapsing' words reveals a more complex picture, which is consistent with organic language change and contrasts with the patterns of the abrupt spikes. These insights into the structure of language change contribute to our understanding of how language technology continues to shape human language.",
    "summary": "arXiv:2506.21817v1 Announce Type: cross Abstract: Scientific English has undergone rapid and unprecedented changes in recent years, with words such as 'delve,' 'intricate,' and 'crucial' showing significant spikes in frequency since around 2022. These changes are widely attributed to the growing influence of Large Language Models like ChatGPT in the discourse surrounding bias and misalignment. However, apart from changes in frequency, the exact structure of these linguistic shifts has remained unclear. The present study addresses this and investigates whether these changes involve the replacement of synonyms by suddenly 'spiking words,' for example, 'crucial' replacing 'essential' and 'key,' or whether they reflect broader semantic and pragmatic qualifications. To further investigate structural changes, we include part of speech tagging in our analysis to quantify linguistic shifts over grammatical categories and differentiate between word forms, like 'potential' as a noun vs. as an adjective. We systematically analyze synonym groups for widely discussed 'spiking words' based on frequency trends in scientific abstracts from PubMed. We find that entire semantic clusters often shift together, with most or all words in a group increasing in usage. This pattern suggests that changes induced by Large Language Models are primarily semantic and pragmatic rather than purely lexical. Notably, the adjective 'important' shows a significant decline, which prompted us to systematically analyze decreasing lexical items. Our analysis of 'collapsing' words reveals a more complex picture, which is consistent with organic language change and contrasts with the patterns of the abrupt spikes. These insights into the structure of language change contribute to our understanding of how language technology continues to shape human language.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21817",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Machine Learning Experts - Lewis Tunstall Interview",
    "description": "",
    "summary": "Machine Learning Experts - Lewis Tunstall ü§ó Welcome to Machine Learning Experts - Lewis Tunstall Hey...",
    "pubDate": "Wed, 13 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lewis-tunstall-interview",
    "thumbnail": "https://huggingface.co/blog/assets/60_lewis_tunstall_interview/thumbnail.png"
  },
  {
    "title": "Uncertainty Estimation by Human Perception versus Neural Models",
    "description": "arXiv:2506.15850v1 Announce Type: cross Abstract: Modern neural networks (NNs) often achieve high predictive accuracy but remain poorly calibrated, producing overconfident predictions even when wrong. This miscalibration poses serious challenges in applications where reliable uncertainty estimates are critical. In this work, we investigate how human perceptual uncertainty compares to uncertainty estimated by NNs. Using three vision benchmarks annotated with both human disagreement and crowdsourced confidence, we assess the correlation between model-predicted uncertainty and human-perceived uncertainty. Our results show that current methods only weakly align with human intuition, with correlations varying significantly across tasks and uncertainty metrics. Notably, we find that incorporating human-derived soft labels into the training process can improve calibration without compromising accuracy. These findings reveal a persistent gap between model and human uncertainty and highlight the potential of leveraging human insights to guide the development of more trustworthy AI systems.",
    "summary": "arXiv:2506.15850v1 Announce Type: cross Abstract: Modern neural networks (NNs) often achieve high predictive accuracy but remain poorly calibrated, producing overconfident predictions even when wrong. This miscalibration poses serious challenges in applications where reliable uncertainty estimates are critical. In this work, we investigate how human perceptual uncertainty compares to uncertainty estimated by NNs. Using three vision benchmarks annotated with both human disagreement and crowdsourced confidence, we assess the correlation between model-predicted uncertainty and human-perceived uncertainty. Our results show that current methods only weakly align with human intuition, with correlations varying significantly across tasks and uncertainty metrics. Notably, we find that incorporating human-derived soft labels into the training process can improve calibration without compromising accuracy. These findings reveal a persistent gap between model and human uncertainty and highlight the potential of leveraging human insights to guide the development of more trustworthy AI systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15850",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google Cloud TPUs made available to Hugging Face users",
    "description": "",
    "summary": "Google Cloud TPUs made available to Hugging Face users We're excited to share some great news! AI bu...",
    "pubDate": "Tue, 09 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tpu-inference-endpoints-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/tpu-inference-endpoints-spaces/thumbnail.png"
  },
  {
    "title": "Finance Language Model Evaluation (FLaME)",
    "description": "arXiv:2506.15846v1 Announce Type: cross Abstract: Language Models (LMs) have demonstrated impressive capabilities with core Natural Language Processing (NLP) tasks. The effectiveness of LMs for highly specialized knowledge-intensive tasks in finance remains difficult to assess due to major gaps in the methodologies of existing evaluation frameworks, which have caused an erroneous belief in a far lower bound of LMs' performance on common Finance NLP (FinNLP) tasks. To demonstrate the potential of LMs for these FinNLP tasks, we present the first holistic benchmarking suite for Financial Language Model Evaluation (FLaME). We are the first research paper to comprehensively study LMs against 'reasoning-reinforced' LMs, with an empirical study of 23 foundation LMs over 20 core NLP tasks in finance. We open-source our framework software along with all data and results.",
    "summary": "arXiv:2506.15846v1 Announce Type: cross Abstract: Language Models (LMs) have demonstrated impressive capabilities with core Natural Language Processing (NLP) tasks. The effectiveness of LMs for highly specialized knowledge-intensive tasks in finance remains difficult to assess due to major gaps in the methodologies of existing evaluation frameworks, which have caused an erroneous belief in a far lower bound of LMs' performance on common Finance NLP (FinNLP) tasks. To demonstrate the potential of LMs for these FinNLP tasks, we present the first holistic benchmarking suite for Financial Language Model Evaluation (FLaME). We are the first research paper to comprehensively study LMs against 'reasoning-reinforced' LMs, with an empirical study of 23 foundation LMs over 20 core NLP tasks in finance. We open-source our framework software along with all data and results.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15846",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Forecasting potential misuses of language models for disinformation campaigns and how to reduce risk",
    "description": "OpenAI researchers collaborated with Georgetown University‚Äôs Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report¬†here.",
    "summary": "OpenAI researchers collaborated with Georgetown University‚Äôs Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report¬†here.",
    "pubDate": "Wed, 11 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/forecasting-misuse",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GFlowGR: Fine-tuning Generative Recommendation Frameworks with Generative Flow Networks",
    "description": "arXiv:2506.16114v1 Announce Type: cross Abstract: Generative recommendations (GR), which usually include item tokenizers and generative Large Language Models (LLMs), have demonstrated remarkable success across a wide range of scenarios. The majority of existing research efforts primarily concentrate on developing powerful item tokenizers or advancing LLM decoding strategies to attain superior performance. However, the critical fine-tuning step in GR frameworks, which is essential for adapting LLMs to recommendation data, remains largely unexplored. Current approaches predominantly rely on either the next-token prediction loss of supervised fine-tuning (SFT) or recommendationspecific direct preference optimization (DPO) strategies. Both methods ignore the exploration of possible positive unobserved samples, which is commonly referred to as the exposure bias problem. To mitigate this problem, this paper treats the GR as a multi-step generation task and constructs a GFlowNets-based fine-tuning framework (GFlowGR). The proposed framework integrates collaborative knowledge from traditional recommender systems to create an adaptive trajectory sampler and a comprehensive reward model. Leveraging the diverse generation property of GFlowNets, along with sampling and heuristic weighting techniques, GFlowGR emerges as a promising approach to mitigate the exposure bias problem. Extensive empirical results on two real-world datasets and with two different GR backbones highlight the effectiveness and robustness of GFlowGR.",
    "summary": "arXiv:2506.16114v1 Announce Type: cross Abstract: Generative recommendations (GR), which usually include item tokenizers and generative Large Language Models (LLMs), have demonstrated remarkable success across a wide range of scenarios. The majority of existing research efforts primarily concentrate on developing powerful item tokenizers or advancing LLM decoding strategies to attain superior performance. However, the critical fine-tuning step in GR frameworks, which is essential for adapting LLMs to recommendation data, remains largely unexplored. Current approaches predominantly rely on either the next-token prediction loss of supervised fine-tuning (SFT) or recommendationspecific direct preference optimization (DPO) strategies. Both methods ignore the exploration of possible positive unobserved samples, which is commonly referred to as the exposure bias problem. To mitigate this problem, this paper treats the GR as a multi-step generation task and constructs a GFlowNets-based fine-tuning framework (GFlowGR). The proposed framework integrates collaborative knowledge from traditional recommender systems to create an adaptive trajectory sampler and a comprehensive reward model. Leveraging the diverse generation property of GFlowNets, along with sampling and heuristic weighting techniques, GFlowGR emerges as a promising approach to mitigate the exposure bias problem. Extensive empirical results on two real-world datasets and with two different GR backbones highlight the effectiveness and robustness of GFlowGR.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16114",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation",
    "description": "arXiv:2505.05625v2 Announce Type: replace-cross Abstract: Estimating rate coefficients from complex chemical reactions is essential for advancing detailed chemistry. However, the stiffness inherent in real-world atmospheric chemistry systems poses severe challenges, leading to training instability and poor convergence that hinder effective rate coefficient estimation using learning-based approaches. To address this, we propose a Stiff Physics-Informed Neural ODE framework (SPIN-ODE) for chemical reaction modelling. Our method introduces a three-stage optimisation process: first, a latent neural ODE learns the continuous and differentiable trajectory between chemical concentrations and their time derivatives; second, an explicit Chemical Reaction Neural Network (CRNN) extracts the underlying rate coefficients based on the learned dynamics; and third, fine-tune CRNN using a neural ODE solver to further improve rate coefficient estimation. Extensive experiments on both synthetic and newly proposed real-world datasets validate the effectiveness and robustness of our approach. As the first work on stiff Neural ODEs for chemical rate coefficient discovery, our study opens promising directions for integrating neural networks with detailed chemistry.",
    "summary": "arXiv:2505.05625v2 Announce Type: replace-cross Abstract: Estimating rate coefficients from complex chemical reactions is essential for advancing detailed chemistry. However, the stiffness inherent in real-world atmospheric chemistry systems poses severe challenges, leading to training instability and poor convergence that hinder effective rate coefficient estimation using learning-based approaches. To address this, we propose a Stiff Physics-Informed Neural ODE framework (SPIN-ODE) for chemical reaction modelling. Our method introduces a three-stage optimisation process: first, a latent neural ODE learns the continuous and differentiable trajectory between chemical concentrations and their time derivatives; second, an explicit Chemical Reaction Neural Network (CRNN) extracts the underlying rate coefficients based on the learned dynamics; and third, fine-tune CRNN using a neural ODE solver to further improve rate coefficient estimation. Extensive experiments on both synthetic and newly proposed real-world datasets validate the effectiveness and robustness of our approach. As the first work on stiff Neural ODEs for chemical rate coefficient discovery, our study opens promising directions for integrating neural networks with detailed chemistry.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.05625",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "KNN-MMD: Cross Domain Wireless Sensing via Local Distribution Alignment",
    "description": "arXiv:2412.04783v3 Announce Type: replace-cross Abstract: Wireless sensing has recently found widespread applications in diverse environments, including homes, offices, and public spaces. By analyzing patterns in channel state information (CSI), it is possible to infer human actions for tasks such as person identification, gesture recognition, and fall detection. However, CSI is highly sensitive to environmental changes, where even minor alterations can significantly distort the CSI patterns. This sensitivity often leads to performance degradation or outright failure when applying wireless sensing models trained in one environment to another. To address this challenge, Domain Alignment (DAL) has been widely adopted for cross-domain classification tasks, as it focuses on aligning the global distributions of the source and target domains in feature space. Despite its popularity, DAL often neglects inter-category relationships, which can lead to misalignment between categories across domains, even when global alignment is achieved. To overcome these limitations, we propose K-Nearest Neighbors Maximum Mean Discrepancy (KNN-MMD), a novel few-shot method for cross-domain wireless sensing. Our approach begins by constructing a help set using KNN from the target domain, enabling local alignment between the source and target domains within each category using MMD. Additionally, we address a key instability issue commonly observed in cross-domain methods, where model performance fluctuates sharply between epochs. Further, most existing methods struggle to determine an optimal stopping point during training due to the absence of labeled data from the target domain. Our method resolves this by excluding the support set from the target domain during training and employing it as a validation set to determine the stopping criterion.The dataset and code are publicly available at https://github.com/RS2002/KNN-MMD .",
    "summary": "arXiv:2412.04783v3 Announce Type: replace-cross Abstract: Wireless sensing has recently found widespread applications in diverse environments, including homes, offices, and public spaces. By analyzing patterns in channel state information (CSI), it is possible to infer human actions for tasks such as person identification, gesture recognition, and fall detection. However, CSI is highly sensitive to environmental changes, where even minor alterations can significantly distort the CSI patterns. This sensitivity often leads to performance degradation or outright failure when applying wireless sensing models trained in one environment to another. To address this challenge, Domain Alignment (DAL) has been widely adopted for cross-domain classification tasks, as it focuses on aligning the global distributions of the source and target domains in feature space. Despite its popularity, DAL often neglects inter-category relationships, which can lead to misalignment between categories across domains, even when global alignment is achieved. To overcome these limitations, we propose K-Nearest Neighbors Maximum Mean Discrepancy (KNN-MMD), a novel few-shot method for cross-domain wireless sensing. Our approach begins by constructing a help set using KNN from the target domain, enabling local alignment between the source and target domains within each category using MMD. Additionally, we address a key instability issue commonly observed in cross-domain methods, where model performance fluctuates sharply between epochs. Further, most existing methods struggle to determine an optimal stopping point during training due to the absence of labeled data from the target domain. Our method resolves this by excluding the support set from the target domain during training and employing it as a validation set to determine the stopping criterion.The dataset and code are publicly available at https://github.com/RS2002/KNN-MMD .",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.04783",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tuning Stable Diffusion models on Intel CPUs",
    "description": "",
    "summary": "Fine-tuning Stable Diffusion Models on Intel CPUs Diffusion models helped popularize generative AI t...",
    "pubDate": "Fri, 14 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-finetuning-intel",
    "thumbnail": "https://huggingface.co/blog/assets/stable-diffusion-finetuning-intel/01.png"
  },
  {
    "title": "OpenAI and Elon Musk",
    "description": "We are dedicated to the OpenAI mission and have pursued it every step of the way.",
    "summary": "We are dedicated to the OpenAI mission and have pursued it every step of the way.",
    "pubDate": "Tue, 05 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-elon-musk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An Introduction to Q-Learning Part 2",
    "description": "",
    "summary": "An Introduction to Q-Learning Part 2/2 Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 2,...",
    "pubDate": "Fri, 20 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-q-part2",
    "thumbnail": "https://huggingface.co/blog/assets/73_deep_rl_q_part2/thumbnail.gif"
  },
  {
    "title": "Dynamic Adaptive Rank Space Exploration for Efficient Sentiment Analysis with Large Language Models",
    "description": "arXiv:2410.16589v2 Announce Type: replace-cross Abstract: Sentiment analysis has become increasingly important for assessing public opinion and informing decision-making. Large language models (LLMs) have revolutionized this field by capturing nuanced language patterns. However, adapting LLMs to domain-specific sentiment analysis tasks remains challenging due to computational constraints and the need for optimal fine-tuning. To address these challenges, we propose a novel Dynamic Adaptive Rank Space Exploration (DARSE) framework for efficient and effective sentiment analysis using LLMs. DARSE consists of a coarse-grained greedy algorithm to identify the optimal rank range, a fine-grained exploration algorithm to refine rank selection, and a dynamic rank allocation method to determine the optimal rank combination for each LLM layer. Extensive experiments demonstrate that DARSE significantly improves sentiment analysis accuracy, achieving a 15.1% improvement in MSE and a 4.3% improvement in accuracy compared to previous work. Our framework strikes a balance between computational efficiency and model performance, making it a promising approach for sentiment analysis with LLMs.",
    "summary": "arXiv:2410.16589v2 Announce Type: replace-cross Abstract: Sentiment analysis has become increasingly important for assessing public opinion and informing decision-making. Large language models (LLMs) have revolutionized this field by capturing nuanced language patterns. However, adapting LLMs to domain-specific sentiment analysis tasks remains challenging due to computational constraints and the need for optimal fine-tuning. To address these challenges, we propose a novel Dynamic Adaptive Rank Space Exploration (DARSE) framework for efficient and effective sentiment analysis using LLMs. DARSE consists of a coarse-grained greedy algorithm to identify the optimal rank range, a fine-grained exploration algorithm to refine rank selection, and a dynamic rank allocation method to determine the optimal rank combination for each LLM layer. Extensive experiments demonstrate that DARSE significantly improves sentiment analysis accuracy, achieving a 15.1% improvement in MSE and a 4.3% improvement in accuracy compared to previous work. Our framework strikes a balance between computational efficiency and model performance, making it a promising approach for sentiment analysis with LLMs.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.16589",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing smolagents: simple agents that write actions in code.",
    "description": "",
    "summary": "Introducing smolagents, a simple library to build agents Today we are launching smolagents , a very ...",
    "pubDate": "Tue, 31 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents/thumbnail.png"
  },
  {
    "title": "Open-R1: a fully open reproduction of DeepSeek-R1",
    "description": "",
    "summary": "Open-R1: a fully open reproduction of DeepSeek-R1 What is DeepSeek-R1? If you‚Äôve ever struggled with...",
    "pubDate": "Tue, 28 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-r1",
    "thumbnail": "https://huggingface.co/blog/assets/open-r1/thumbnails.png"
  },
  {
    "title": "Optimizing MoE Routers: Design, Implementation, and Evaluation in Transformer Models",
    "description": "arXiv:2506.16419v1 Announce Type: cross Abstract: Mixture of Experts (MoE) architectures increase large language model scalability, yet their performance depends on the router module that moves tokens to specialized experts. Bad routing can load imbalance and reduced accuracy. This project designed and implemented different router architectures within Transformer models to fix these limitations. We experimented with six distinct router variants Linear, Attention, Multi-Layer Perceptron (MLP), Hybrid, Hash, and our new MLP-Hadamard. We characterized these routers using BERT and the Qwen1.5-MoE model, looking at parameter efficiency, inference latency, routing entropy, and expert utilization patterns. Our evaluations showed distinct trade-offs: Linear routers offer speed, while MLP and Attention routers provide greater expressiveness. The MLP-Hadamard router shows a unique capability for structured, sparse routing. We successfully replaced and fine-tuned custom routers within the complex, quantized Qwen1.5-MoE model. This work provides a comparative analysis of MoE router designs and offers insights into optimizing their performance for efficient and effective large-scale model deployment.",
    "summary": "arXiv:2506.16419v1 Announce Type: cross Abstract: Mixture of Experts (MoE) architectures increase large language model scalability, yet their performance depends on the router module that moves tokens to specialized experts. Bad routing can load imbalance and reduced accuracy. This project designed and implemented different router architectures within Transformer models to fix these limitations. We experimented with six distinct router variants Linear, Attention, Multi-Layer Perceptron (MLP), Hybrid, Hash, and our new MLP-Hadamard. We characterized these routers using BERT and the Qwen1.5-MoE model, looking at parameter efficiency, inference latency, routing entropy, and expert utilization patterns. Our evaluations showed distinct trade-offs: Linear routers offer speed, while MLP and Attention routers provide greater expressiveness. The MLP-Hadamard router shows a unique capability for structured, sparse routing. We successfully replaced and fine-tuned custom routers within the complex, quantized Qwen1.5-MoE model. This work provides a comparative analysis of MoE router designs and offers insights into optimizing their performance for efficient and effective large-scale model deployment.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16419",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Finally, a Replacement for BERT: Introducing ModernBERT",
    "description": "",
    "summary": "Finally, a Replacement for BERT TL;DR This blog post introduces ModernBERT, a family of state-of-the...",
    "pubDate": "Thu, 19 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/modernbert",
    "thumbnail": "https://huggingface.co/blog/assets/modernbert/thumbnail.png"
  },
  {
    "title": "Commander-GPT: Dividing and Routing for Multimodal Sarcasm Detection",
    "description": "arXiv:2506.19420v1 Announce Type: new Abstract: Multimodal sarcasm understanding is a high-order cognitive task. Although large language models (LLMs) have shown impressive performance on many downstream NLP tasks, growing evidence suggests that they struggle with sarcasm understanding. In this paper, we propose Commander-GPT, a modular decision routing framework inspired by military command theory. Rather than relying on a single LLM's capability, Commander-GPT orchestrates a team of specialized LLM agents where each agent will be selectively assigned to a focused sub-task such as context modeling, sentiment analysis, etc. Their outputs are then routed back to the commander, which integrates the information and performs the final sarcasm judgment. To coordinate these agents, we introduce three types of centralized commanders: (1) a trained lightweight encoder-based commander (e.g., multi-modal BERT); (2) four small autoregressive language models, serving as moderately capable commanders (e.g., DeepSeek-VL); (3) two large LLM-based commander (Gemini Pro and GPT-4o) that performs task routing, output aggregation, and sarcasm decision-making in a zero-shot fashion. We evaluate Commander-GPT on the MMSD and MMSD 2.0 benchmarks, comparing five prompting strategies. Experimental results show that our framework achieves 4.4% and 11.7% improvement in F1 score over state-of-the-art (SoTA) baselines on average, demonstrating its effectiveness.",
    "summary": "arXiv:2506.19420v1 Announce Type: new Abstract: Multimodal sarcasm understanding is a high-order cognitive task. Although large language models (LLMs) have shown impressive performance on many downstream NLP tasks, growing evidence suggests that they struggle with sarcasm understanding. In this paper, we propose Commander-GPT, a modular decision routing framework inspired by military command theory. Rather than relying on a single LLM's capability, Commander-GPT orchestrates a team of specialized LLM agents where each agent will be selectively assigned to a focused sub-task such as context modeling, sentiment analysis, etc. Their outputs are then routed back to the commander, which integrates the information and performs the final sarcasm judgment. To coordinate these agents, we introduce three types of centralized commanders: (1) a trained lightweight encoder-based commander (e.g., multi-modal BERT); (2) four small autoregressive language models, serving as moderately capable commanders (e.g., DeepSeek-VL); (3) two large LLM-based commander (Gemini Pro and GPT-4o) that performs task routing, output aggregation, and sarcasm decision-making in a zero-shot fashion. We evaluate Commander-GPT on the MMSD and MMSD 2.0 benchmarks, comparing five prompting strategies. Experimental results show that our framework achieves 4.4% and 11.7% improvement in F1 score over state-of-the-art (SoTA) baselines on average, demonstrating its effectiveness.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19420",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "New generative media models and tools, built with and for creators",
    "description": "We‚Äôre introducing Veo, our most capable model for generating high-definition video, and Imagen 3, our highest quality text-to-image model. We‚Äôre also sharing new demo recordings created with our Music AI Sandbox.",
    "summary": "We‚Äôre introducing Veo, our most capable model for generating high-definition video, and Imagen 3, our highest quality text-to-image model. We‚Äôre also sharing new demo recordings created with our Music AI Sandbox.",
    "pubDate": "Tue, 14 May 2024 17:57:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/new-generative-media-models-and-tools-built-with-and-for-creators/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO24_Gen_Media_Header_1.width-1300.png"
  },
  {
    "title": "ContextBench: Modifying Contexts for Targeted Latent Activation",
    "description": "arXiv:2506.15735v1 Announce Type: new Abstract: Identifying inputs that trigger specific behaviours or latent features in language models could have a wide range of safety use cases. We investigate a class of methods capable of generating targeted, linguistically fluent inputs that activate specific latent features or elicit model behaviours. We formalise this approach as context modification and present ContextBench -- a benchmark with tasks assessing core method capabilities and potential safety applications. Our evaluation framework measures both elicitation strength (activation of latent features or behaviours) and linguistic fluency, highlighting how current state-of-the-art methods struggle to balance these objectives. We enhance Evolutionary Prompt Optimisation (EPO) with LLM-assistance and diffusion model inpainting, and demonstrate that these variants achieve state-of-the-art performance in balancing elicitation effectiveness and fluency.",
    "summary": "arXiv:2506.15735v1 Announce Type: new Abstract: Identifying inputs that trigger specific behaviours or latent features in language models could have a wide range of safety use cases. We investigate a class of methods capable of generating targeted, linguistically fluent inputs that activate specific latent features or elicit model behaviours. We formalise this approach as context modification and present ContextBench -- a benchmark with tasks assessing core method capabilities and potential safety applications. Our evaluation framework measures both elicitation strength (activation of latent features or behaviours) and linguistic fluency, highlighting how current state-of-the-art methods struggle to balance these objectives. We enhance Evolutionary Prompt Optimisation (EPO) with LLM-assistance and diffusion model inpainting, and demonstrate that these variants achieve state-of-the-art performance in balancing elicitation effectiveness and fluency.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15735",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Better language models and their implications",
    "description": "We‚Äôve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization‚Äîall without task-specific¬†training.",
    "summary": "We‚Äôve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization‚Äîall without task-specific¬†training.",
    "pubDate": "Thu, 14 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/better-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Operator",
    "description": "A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in the U.S.",
    "summary": "A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in the U.S.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-operator",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster Text Generation with TensorFlow and XLA",
    "description": "",
    "summary": "Faster Text Generation with TensorFlow and XLA TL;DR: Text Generation on ü§ó transformers using Tensor...",
    "pubDate": "Wed, 27 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-xla-generate",
    "thumbnail": "https://huggingface.co/blog/assets/91_tf_xla_generate/thumbnail.png"
  },
  {
    "title": "Open-sourcing Knowledge Distillation Code and Weights of SD-Small and SD-Tiny",
    "description": "",
    "summary": "Open-sourcing Knowledge Distillation Code and Weights of SD-Small and SD-Tiny In recent times, the A...",
    "pubDate": "Tue, 01 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd_distillation",
    "thumbnail": "https://huggingface.co/blog/assets/distill_sd/thumbnail.png"
  },
  {
    "title": "Automatic Posology Structuration : What role for LLMs?",
    "description": "arXiv:2506.19525v1 Announce Type: cross Abstract: Automatically structuring posology instructions is essential for improving medication safety and enabling clinical decision support. In French prescriptions, these instructions are often ambiguous, irregular, or colloquial, limiting the effectiveness of classic ML pipelines. We explore the use of Large Language Models (LLMs) to convert free-text posologies into structured formats, comparing prompt-based methods and fine-tuning against a 'pre-LLM' system based on Named Entity Recognition and Linking (NERL). Our results show that while prompting improves performance, only fine-tuned LLMs match the accuracy of the baseline. Through error analysis, we observe complementary strengths: NERL offers structural precision, while LLMs better handle semantic nuances. Based on this, we propose a hybrid pipeline that routes low-confidence cases from NERL (<0.8) to the LLM, selecting outputs based on confidence scores. This strategy achieves 91% structuration accuracy while minimizing latency and compute. Our results show that this hybrid approach improves structuration accuracy while limiting computational cost, offering a scalable solution for real-world clinical use.",
    "summary": "arXiv:2506.19525v1 Announce Type: cross Abstract: Automatically structuring posology instructions is essential for improving medication safety and enabling clinical decision support. In French prescriptions, these instructions are often ambiguous, irregular, or colloquial, limiting the effectiveness of classic ML pipelines. We explore the use of Large Language Models (LLMs) to convert free-text posologies into structured formats, comparing prompt-based methods and fine-tuning against a 'pre-LLM' system based on Named Entity Recognition and Linking (NERL). Our results show that while prompting improves performance, only fine-tuned LLMs match the accuracy of the baseline. Through error analysis, we observe complementary strengths: NERL offers structural precision, while LLMs better handle semantic nuances. Based on this, we propose a hybrid pipeline that routes low-confidence cases from NERL (<0.8) to the LLM, selecting outputs based on confidence scores. This strategy achieves 91% structuration accuracy while minimizing latency and compute. Our results show that this hybrid approach improves structuration accuracy while limiting computational cost, offering a scalable solution for real-world clinical use.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19525",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FrodoKEM: A conservative quantum-safe cryptographic algorithm",
    "description": "<p>The recent advances in quantum computing offer many advantages‚Äîbut also challenge current cryptographic strategies. Learn how FrodoKEM could help strengthen security, even in a future with powerful quantum computers.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/frodokem-a-conservative-quantum-safe-cryptographic-algorithm/'>FrodoKEM: A conservative quantum-safe cryptographic algorithm</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>The recent advances in quantum computing offer many advantages‚Äîbut also challenge current cryptographic strategies. Learn how FrodoKEM could help strengthen security, even in a future with powerful quantum computers.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/frodokem-a-conservative-quantum-safe-cryptographic-algorithm/'>FrodoKEM: A conservative quantum-safe cryptographic algorithm</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Tue, 27 May 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/frodokem-a-conservative-quantum-safe-cryptographic-algorithm/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Open-source DeepResearch ‚Äì Freeing our search agents",
    "description": "",
    "summary": "Open-source DeepResearch ‚Äì Freeing our search agents TLDR Yesterday, OpenAI released Deep Research, ...",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-deep-research",
    "thumbnail": "https://huggingface.co/blog/assets/open-deep-research/thumbnail.png"
  },
  {
    "title": "MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models",
    "description": "arXiv:2506.21784v1 Announce Type: new Abstract: Understanding and modeling human mobility patterns is crucial for effective transportation planning and urban development. Despite significant advances in mobility research, there remains a critical gap in simulation platforms that allow for algorithm development, policy implementation, and comprehensive evaluation at scale. Traditional activity-based models require extensive data collection and manual calibration, machine learning approaches struggle with adaptation to dynamic conditions, and treding agent-based Large Language Models (LLMs) implementations face computational constraints with large-scale simulations. To address these challenges, we propose MobiVerse, a hybrid framework leverages the efficiency of lightweight domain-specific generator for generating base activity chains with the adaptability of LLMs for context-aware modifications. A case study was conducted in Westwood, Los Angeles, where we efficiently generated and dynamically adjusted schedules for the whole population of approximately 53,000 agents on a standard PC. Our experiments demonstrate that MobiVerse successfully enables agents to respond to environmental feedback, including road closures, large gathering events like football games, and congestion, through our hybrid framework. Its modular design facilitates testing various mobility algorithms at both transportation system and agent levels. Results show our approach maintains computational efficiency while enhancing behavioral realism. MobiVerse bridges the gap in mobility simulation by providing a customizable platform for mobility systems planning and operations with benchmark algorithms. Code and videos are available at https://github.com/ucla-mobility/MobiVerse.",
    "summary": "arXiv:2506.21784v1 Announce Type: new Abstract: Understanding and modeling human mobility patterns is crucial for effective transportation planning and urban development. Despite significant advances in mobility research, there remains a critical gap in simulation platforms that allow for algorithm development, policy implementation, and comprehensive evaluation at scale. Traditional activity-based models require extensive data collection and manual calibration, machine learning approaches struggle with adaptation to dynamic conditions, and treding agent-based Large Language Models (LLMs) implementations face computational constraints with large-scale simulations. To address these challenges, we propose MobiVerse, a hybrid framework leverages the efficiency of lightweight domain-specific generator for generating base activity chains with the adaptability of LLMs for context-aware modifications. A case study was conducted in Westwood, Los Angeles, where we efficiently generated and dynamically adjusted schedules for the whole population of approximately 53,000 agents on a standard PC. Our experiments demonstrate that MobiVerse successfully enables agents to respond to environmental feedback, including road closures, large gathering events like football games, and congestion, through our hybrid framework. Its modular design facilitates testing various mobility algorithms at both transportation system and agent levels. Results show our approach maintains computational efficiency while enhancing behavioral realism. MobiVerse bridges the gap in mobility simulation by providing a customizable platform for mobility systems planning and operations with benchmark algorithms. Code and videos are available at https://github.com/ucla-mobility/MobiVerse.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21784",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing SWE-bench Verified",
    "description": "We‚Äôre releasing a human-validated subset of SWE-bench that more reliably evaluates AI models‚Äô ability to solve real-world software issues.",
    "summary": "We‚Äôre releasing a human-validated subset of SWE-bench that more reliably evaluates AI models‚Äô ability to solve real-world software issues.",
    "pubDate": "Tue, 13 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-swe-bench-verified",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Washington Post partners with OpenAI on search content",
    "description": "The Washington Post is partnering with with OpenAI to integrate news into ChatGPT, providing users with summaries, quotes, and direct links to original reporting.",
    "summary": "The Washington Post is partnering with with OpenAI to integrate news into ChatGPT, providing users with summaries, quotes, and direct links to original reporting.",
    "pubDate": "Tue, 22 Apr 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/the-washington-post-partners-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Personalized Robotic Object Rearrangement from Scene Context",
    "description": "arXiv:2505.11108v2 Announce Type: replace-cross Abstract: Object rearrangement is a key task for household robots requiring personalization without explicit instructions, meaningful object placement in environments occupied with objects, and generalization to unseen objects and new environments. To facilitate research addressing these challenges, we introduce PARSEC, an object rearrangement benchmark for learning user organizational preferences from observed scene context to place objects in a partially arranged environment. PARSEC is built upon a novel dataset of 110K rearrangement examples crowdsourced from 72 users, featuring 93 object categories and 15 environments. To better align with real-world organizational habits, we propose ContextSortLM, an LLM-based personalized rearrangement model that handles flexible user preferences by explicitly accounting for objects with multiple valid placement locations when placing items in partially arranged environments. We evaluate ContextSortLM and existing personalized rearrangement approaches on the PARSEC benchmark and complement these findings with a crowdsourced evaluation of 108 online raters ranking model predictions based on alignment with user preferences. Our results indicate that personalized rearrangement models leveraging multiple scene context sources perform better than models relying on a single context source. Moreover, ContextSortLM outperforms other models in placing objects to replicate the target user's arrangement and ranks among the top two in all three environment categories, as rated by online evaluators. Importantly, our evaluation highlights challenges associated with modeling environment semantics across different environment categories and provides recommendations for future work.",
    "summary": "arXiv:2505.11108v2 Announce Type: replace-cross Abstract: Object rearrangement is a key task for household robots requiring personalization without explicit instructions, meaningful object placement in environments occupied with objects, and generalization to unseen objects and new environments. To facilitate research addressing these challenges, we introduce PARSEC, an object rearrangement benchmark for learning user organizational preferences from observed scene context to place objects in a partially arranged environment. PARSEC is built upon a novel dataset of 110K rearrangement examples crowdsourced from 72 users, featuring 93 object categories and 15 environments. To better align with real-world organizational habits, we propose ContextSortLM, an LLM-based personalized rearrangement model that handles flexible user preferences by explicitly accounting for objects with multiple valid placement locations when placing items in partially arranged environments. We evaluate ContextSortLM and existing personalized rearrangement approaches on the PARSEC benchmark and complement these findings with a crowdsourced evaluation of 108 online raters ranking model predictions based on alignment with user preferences. Our results indicate that personalized rearrangement models leveraging multiple scene context sources perform better than models relying on a single context source. Moreover, ContextSortLM outperforms other models in placing objects to replicate the target user's arrangement and ranks among the top two in all three environment categories, as rated by online evaluators. Importantly, our evaluation highlights challenges associated with modeling environment semantics across different environment categories and provides recommendations for future work.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.11108",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team",
    "description": "arXiv:2506.18348v2 Announce Type: replace Abstract: Scientific progress increasingly relies on effective collaboration among researchers, a dynamic that large language models (LLMs) have only begun to emulate. While recent LLM-based scientist agents show promise in autonomous scientific discovery, they often lack the interactive reasoning and evaluation mechanisms essential to real-world research. We propose IDVSCI (Internal Discussion and Vote SCIentists), a multi-agent framework built on LLMs that incorporates two key innovations: a Dynamic Knowledge Exchange mechanism enabling iterative feedback among agents, and a Dual-Diversity Review paradigm that simulates heterogeneous expert evaluation. These components jointly promote deeper reasoning and the generation of more creative and impactful scientific ideas. To evaluate the effectiveness and generalizability of our approach, we conduct experiments on two datasets: a widely used benchmark in computer science and a new dataset we introduce in the health sciences domain. Results show that IDVSCI consistently achieves the best performance across both datasets, outperforming existing systems such as AI Scientist and VIRSCI. These findings highlight the value of modeling interaction and peer review dynamics in LLM-based autonomous research.",
    "summary": "arXiv:2506.18348v2 Announce Type: replace Abstract: Scientific progress increasingly relies on effective collaboration among researchers, a dynamic that large language models (LLMs) have only begun to emulate. While recent LLM-based scientist agents show promise in autonomous scientific discovery, they often lack the interactive reasoning and evaluation mechanisms essential to real-world research. We propose IDVSCI (Internal Discussion and Vote SCIentists), a multi-agent framework built on LLMs that incorporates two key innovations: a Dynamic Knowledge Exchange mechanism enabling iterative feedback among agents, and a Dual-Diversity Review paradigm that simulates heterogeneous expert evaluation. These components jointly promote deeper reasoning and the generation of more creative and impactful scientific ideas. To evaluate the effectiveness and generalizability of our approach, we conduct experiments on two datasets: a widely used benchmark in computer science and a new dataset we introduce in the health sciences domain. Results show that IDVSCI consistently achieves the best performance across both datasets, outperforming existing systems such as AI Scientist and VIRSCI. These findings highlight the value of modeling interaction and peer review dynamics in LLM-based autonomous research.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18348",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TransDreamerV3: Implanting Transformer In DreamerV3",
    "description": "arXiv:2506.17103v1 Announce Type: cross Abstract: This paper introduces TransDreamerV3, a reinforcement learning model that enhances the DreamerV3 architecture by integrating a transformer encoder. The model is designed to improve memory and decision-making capabilities in complex environments. We conducted experiments on Atari-Boxing, Atari-Freeway, Atari-Pong, and Crafter tasks, where TransDreamerV3 demonstrated improved performance over DreamerV3, particularly in the Atari-Freeway and Crafter tasks. While issues in the Minecraft task and limited training across all tasks were noted, TransDreamerV3 displays advancement in world model-based reinforcement learning, leveraging transformer architectures.",
    "summary": "arXiv:2506.17103v1 Announce Type: cross Abstract: This paper introduces TransDreamerV3, a reinforcement learning model that enhances the DreamerV3 architecture by integrating a transformer encoder. The model is designed to improve memory and decision-making capabilities in complex environments. We conducted experiments on Atari-Boxing, Atari-Freeway, Atari-Pong, and Crafter tasks, where TransDreamerV3 demonstrated improved performance over DreamerV3, particularly in the Atari-Freeway and Crafter tasks. While issues in the Minecraft task and limited training across all tasks were noted, TransDreamerV3 displays advancement in world model-based reinforcement learning, leveraging transformer architectures.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17103",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Few-Shot Segmentation of Historical Maps via Linear Probing of Vision Foundation Models",
    "description": "arXiv:2506.21826v1 Announce Type: cross Abstract: As rich sources of history, maps provide crucial insights into historical changes, yet their diverse visual representations and limited annotated data pose significant challenges for automated processing. We propose a simple yet effective approach for few-shot segmentation of historical maps, leveraging the rich semantic embeddings of large vision foundation models combined with parameter-efficient fine-tuning. Our method outperforms the state-of-the-art on the Siegfried benchmark dataset in vineyard and railway segmentation, achieving +5% and +13% relative improvements in mIoU in 10-shot scenarios and around +20% in the more challenging 5-shot setting. Additionally, it demonstrates strong performance on the ICDAR 2021 competition dataset, attaining a mean PQ of 67.3% for building block segmentation, despite not being optimized for this shape-sensitive metric, underscoring its generalizability. Notably, our approach maintains high performance even in extremely low-data regimes (10- & 5-shot), while requiring only 689k trainable parameters - just 0.21% of the total model size. Our approach enables precise segmentation of diverse historical maps while drastically reducing the need for manual annotations, advancing automated processing and analysis in the field. Our implementation is publicly available at: https://github.com/RafaelSterzinger/few-shot-map-segmentation.",
    "summary": "arXiv:2506.21826v1 Announce Type: cross Abstract: As rich sources of history, maps provide crucial insights into historical changes, yet their diverse visual representations and limited annotated data pose significant challenges for automated processing. We propose a simple yet effective approach for few-shot segmentation of historical maps, leveraging the rich semantic embeddings of large vision foundation models combined with parameter-efficient fine-tuning. Our method outperforms the state-of-the-art on the Siegfried benchmark dataset in vineyard and railway segmentation, achieving +5% and +13% relative improvements in mIoU in 10-shot scenarios and around +20% in the more challenging 5-shot setting. Additionally, it demonstrates strong performance on the ICDAR 2021 competition dataset, attaining a mean PQ of 67.3% for building block segmentation, despite not being optimized for this shape-sensitive metric, underscoring its generalizability. Notably, our approach maintains high performance even in extremely low-data regimes (10- & 5-shot), while requiring only 689k trainable parameters - just 0.21% of the total model size. Our approach enables precise segmentation of diverse historical maps while drastically reducing the need for manual annotations, advancing automated processing and analysis in the field. Our implementation is publicly available at: https://github.com/RafaelSterzinger/few-shot-map-segmentation.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21826",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From OpenAI to Open LLMs with Messages API",
    "description": "",
    "summary": "From OpenAI to Open LLMs with Messages API on Hugging Face We are excited to introduce the Messages ...",
    "pubDate": "Thu, 08 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-messages-api",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-messages-api/thumbnail.jpg"
  },
  {
    "title": "Learning with opponent-learning awareness",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-with-opponent-learning-awareness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing ChatGPT and Whisper APIs",
    "description": "Developers can now integrate ChatGPT and Whisper models into their apps and products through our API.",
    "summary": "Developers can now integrate ChatGPT and Whisper models into their apps and products through our API.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-and-whisper-apis",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemini 2.5: Our most intelligent AI model",
    "description": "Gemini 2.5 is our most intelligent AI model, now with thinking built in.",
    "summary": "Gemini 2.5 is our most intelligent AI model, now with thinking built in.",
    "pubDate": "Tue, 25 Mar 2025 17:00:36 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-2-5-our-most-intelligent-ai-model/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_keyword_social_share_text.width-1300.png"
  },
  {
    "title": "Introducing HealthBench",
    "description": "HealthBench is a new evaluation benchmark for AI in healthcare which evaluates models in realistic scenarios. Built with input from 250+ physicians, it aims to provide a shared standard for model performance and safety in health.",
    "summary": "HealthBench is a new evaluation benchmark for AI in healthcare which evaluates models in realistic scenarios. Built with input from 250+ physicians, it aims to provide a shared standard for model performance and safety in health.",
    "pubDate": "Mon, 12 May 2025 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/healthbench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "NPHardEval Leaderboard: Unveiling the Reasoning Abilities of Large Language Models through Complexity Classes and Dynamic Updates",
    "description": "",
    "summary": "NPHardEval Leaderboard: Unveiling the Reasoning Abilities of Large Language Models through Complexit...",
    "pubDate": "Fri, 02 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-nphardeval",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_nphardeval.png"
  },
  {
    "title": "MonoSOWA: Scalable monocular 3D Object detector Without human Annotations",
    "description": "arXiv:2501.09481v3 Announce Type: replace-cross Abstract: Inferring object 3D position and orientation from a single RGB camera is a foundational task in computer vision with many important applications. Traditionally, 3D object detection methods are trained in a fully-supervised setup, requiring LiDAR and vast amounts of human annotations, which are laborious, costly, and do not scale well with the ever-increasing amounts of data being captured. We present a novel method to train a 3D object detector from a single RGB camera without domain-specific human annotations, making orders of magnitude more data available for training. The method uses newly proposed Local Object Motion Model to disentangle object movement source between subsequent frames, is approximately 700 times faster than previous work and compensates camera focal length differences to aggregate multiple datasets. The method is evaluated on three public datasets, where despite using no human labels, it outperforms prior work by a significant margin. It also shows its versatility as a pre-training tool for fully-supervised training and shows that combining pseudo-labels from multiple datasets can achieve comparable accuracy to using human labels from a single dataset. The source code and model are available at https://github.com/jskvrna/MonoSOWA.",
    "summary": "arXiv:2501.09481v3 Announce Type: replace-cross Abstract: Inferring object 3D position and orientation from a single RGB camera is a foundational task in computer vision with many important applications. Traditionally, 3D object detection methods are trained in a fully-supervised setup, requiring LiDAR and vast amounts of human annotations, which are laborious, costly, and do not scale well with the ever-increasing amounts of data being captured. We present a novel method to train a 3D object detector from a single RGB camera without domain-specific human annotations, making orders of magnitude more data available for training. The method uses newly proposed Local Object Motion Model to disentangle object movement source between subsequent frames, is approximately 700 times faster than previous work and compensates camera focal length differences to aggregate multiple datasets. The method is evaluated on three public datasets, where despite using no human labels, it outperforms prior work by a significant margin. It also shows its versatility as a pre-training tool for fully-supervised training and shows that combining pseudo-labels from multiple datasets can achieve comparable accuracy to using human labels from a single dataset. The source code and model are available at https://github.com/jskvrna/MonoSOWA.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.09481",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sam Altman returns as CEO, OpenAI has a new initial board",
    "description": "Mira Murati as CTO, Greg Brockman returns as President. Read messages from CEO Sam Altman and board chair Bret Taylor.",
    "summary": "Mira Murati as CTO, Greg Brockman returns as President. Read messages from CEO Sam Altman and board chair Bret Taylor.",
    "pubDate": "Wed, 29 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sam-altman-returns-as-ceo-openai-has-a-new-initial-board",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models",
    "description": "arXiv:2502.19918v3 Announce Type: replace Abstract: Large Language Models (LLMs) increasingly rely on prolonged reasoning chains to solve complex tasks. However, this trial-and-error approach often leads to high computational overhead and error propagation, where early mistakes can derail subsequent steps. To address these issues, we introduce Meta-Reasoner, a framework that dynamically optimizes inference-time reasoning by enabling LLMs to 'think about how to think.' Drawing inspiration from human meta-cognition and dual-process theory, Meta-Reasoner operates as a strategic advisor, decoupling high-level guidance from step-by-step generation. It employs contextual multi-armed bandits to iteratively evaluate reasoning progress and select optimal strategies (e.g., backtrack, clarify ambiguity, restart from scratch, or propose alternative approaches), and reallocates computational resources toward the most promising paths. Our evaluations on mathematical reasoning and puzzles highlight the potential of dynamic reasoning chains to overcome inherent challenges in the LLM reasoning process and also show promise in broader applications, offering a scalable and adaptable solution for reasoning-intensive tasks.",
    "summary": "arXiv:2502.19918v3 Announce Type: replace Abstract: Large Language Models (LLMs) increasingly rely on prolonged reasoning chains to solve complex tasks. However, this trial-and-error approach often leads to high computational overhead and error propagation, where early mistakes can derail subsequent steps. To address these issues, we introduce Meta-Reasoner, a framework that dynamically optimizes inference-time reasoning by enabling LLMs to 'think about how to think.' Drawing inspiration from human meta-cognition and dual-process theory, Meta-Reasoner operates as a strategic advisor, decoupling high-level guidance from step-by-step generation. It employs contextual multi-armed bandits to iteratively evaluate reasoning progress and select optimal strategies (e.g., backtrack, clarify ambiguity, restart from scratch, or propose alternative approaches), and reallocates computational resources toward the most promising paths. Our evaluations on mathematical reasoning and puzzles highlight the potential of dynamic reasoning chains to overcome inherent challenges in the LLM reasoning process and also show promise in broader applications, offering a scalable and adaptable solution for reasoning-intensive tasks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.19918",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Advancing Embodied Agent Security: From Safety Benchmarks to Input Moderation",
    "description": "arXiv:2504.15699v3 Announce Type: replace Abstract: Embodied agents exhibit immense potential across a multitude of domains, making the assurance of their behavioral safety a fundamental prerequisite for their widespread deployment. However, existing research predominantly concentrates on the security of general large language models, lacking specialized methodologies for establishing safety benchmarks and input moderation tailored to embodied agents. To bridge this gap, this paper introduces a novel input moderation framework, meticulously designed to safeguard embodied agents. This framework encompasses the entire pipeline, including taxonomy definition, dataset curation, moderator architecture, model training, and rigorous evaluation. Notably, we introduce EAsafetyBench, a meticulously crafted safety benchmark engineered to facilitate both the training and stringent assessment of moderators specifically designed for embodied agents. Furthermore, we propose Pinpoint, an innovative prompt-decoupled input moderation scheme that harnesses a masked attention mechanism to effectively isolate and mitigate the influence of functional prompts on moderation tasks. Extensive experiments conducted on diverse benchmark datasets and models validate the feasibility and efficacy of the proposed approach. The results demonstrate that our methodologies achieve an impressive average detection accuracy of 94.58%, surpassing the performance of existing state-of-the-art techniques, alongside an exceptional moderation processing time of merely 0.002 seconds per instance.",
    "summary": "arXiv:2504.15699v3 Announce Type: replace Abstract: Embodied agents exhibit immense potential across a multitude of domains, making the assurance of their behavioral safety a fundamental prerequisite for their widespread deployment. However, existing research predominantly concentrates on the security of general large language models, lacking specialized methodologies for establishing safety benchmarks and input moderation tailored to embodied agents. To bridge this gap, this paper introduces a novel input moderation framework, meticulously designed to safeguard embodied agents. This framework encompasses the entire pipeline, including taxonomy definition, dataset curation, moderator architecture, model training, and rigorous evaluation. Notably, we introduce EAsafetyBench, a meticulously crafted safety benchmark engineered to facilitate both the training and stringent assessment of moderators specifically designed for embodied agents. Furthermore, we propose Pinpoint, an innovative prompt-decoupled input moderation scheme that harnesses a masked attention mechanism to effectively isolate and mitigate the influence of functional prompts on moderation tasks. Extensive experiments conducted on diverse benchmark datasets and models validate the feasibility and efficacy of the proposed approach. The results demonstrate that our methodologies achieve an impressive average detection accuracy of 94.58%, surpassing the performance of existing state-of-the-art techniques, alongside an exceptional moderation processing time of merely 0.002 seconds per instance.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.15699",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Lowe‚Äôs leverages AI to power home improvement retail",
    "description": "A conversation with Chandhu Nair, Senior Vice President of Data, AI, and Innovation.",
    "summary": "A conversation with Chandhu Nair, Senior Vice President of Data, AI, and Innovation.",
    "pubDate": "Mon, 05 May 2025 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lowes-chandhu-nair",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Results of the Open Source AI Game Jam",
    "description": "",
    "summary": "Results of the Open Source AI Game Jam From July 7th to July 11th, we hosted our first Open Source A...",
    "pubDate": "Fri, 21 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/game-jam-first-edition-results",
    "thumbnail": "https://huggingface.co/blog/assets/game-jam-first-edition-results/thumbnail.jpg"
  },
  {
    "title": "Scaling robotics datasets with video encoding",
    "description": "",
    "summary": "Scaling robotics datasets with video encoding Over the past few years, text and image-based models h...",
    "pubDate": "Tue, 27 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/video-encoding",
    "thumbnail": "https://huggingface.co/blog/assets/video-encoding/thumbnail.png"
  },
  {
    "title": "Case Study: Millisecond Latency using Hugging Face Infinity and modern CPUs",
    "description": "",
    "summary": "Case Study: Millisecond Latency using Hugging Face Infinity and modern CPUs Inference Endpoints to e...",
    "pubDate": "Thu, 13 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/infinity-cpu-performance",
    "thumbnail": "https://huggingface.co/blog/assets/46_infinity_cpu_performance/thumbnail.png"
  },
  {
    "title": "CLIP: Connecting text and images",
    "description": "We‚Äôre introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the ‚Äúzero-shot‚Äù capabilities of GPT-2 and¬†GPT-3.",
    "summary": "We‚Äôre introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the visual categories to be recognized, similar to the ‚Äúzero-shot‚Äù capabilities of GPT-2 and¬†GPT-3.",
    "pubDate": "Tue, 05 Jan 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/clip",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building an autonomous financial analyst with o1 and o3-mini",
    "description": "Endex builds the future of financial analysis, powered by OpenAI‚Äôs reasoning models.",
    "summary": "Endex builds the future of financial analysis, powered by OpenAI‚Äôs reasoning models.",
    "pubDate": "Thu, 27 Feb 2025 09:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/endex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TacticAI: an AI assistant for football tactics",
    "description": "As part of our multi-year collaboration with Liverpool FC, we develop a full AI system that can advise coaches on corner kicks",
    "summary": "As part of our multi-year collaboration with Liverpool FC, we develop a full AI system that can advise coaches on corner kicks",
    "pubDate": "Tue, 19 Mar 2024 16:03:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/tacticai-ai-assistant-for-football-tactics/",
    "thumbnail": "https://lh3.googleusercontent.com/pPa45NPPYrOc4QHbcLIsmueJXi9hKNFdB0rbnRMdiRH0Gf3fgIc_g26-UbFxHVzqUT85QA-N3IvPpQaDevlp3OeF3RIiLQjmuONVRVyX1et0WYEKTQ=w1200-h630-n-nu"
  },
  {
    "title": "Enhancing news in ChatGPT with The Atlantic",
    "description": "The Atlantic is announcing a strategic content and product partnership with OpenAI, which positions The Atlantic as a premium news source within OpenAI. The Atlantic‚Äôs articles will be discoverable within OpenAI‚Äôs products, including ChatGPT, and as a partner, The Atlantic will help to shape how news is surfaced and presented in future real-time discovery products.",
    "summary": "The Atlantic is announcing a strategic content and product partnership with OpenAI, which positions The Atlantic as a premium news source within OpenAI. The Atlantic‚Äôs articles will be discoverable within OpenAI‚Äôs products, including ChatGPT, and as a partner, The Atlantic will help to shape how news is surfaced and presented in future real-time discovery products.",
    "pubDate": "Wed, 29 May 2024 07:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/enhancing-news-in-chatgpt-with-the-atlantic",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CAPM: Fast and Robust Verification on Maxpool-based CNN via Dual Network",
    "description": "arXiv:2407.09550v3 Announce Type: replace-cross Abstract: This study uses CAPM (Convex Adversarial Polytope for Maxpool-based CNN) to improve the verified bound for general purpose maxpool-based convolutional neural networks (CNNs) under bounded norm adversarial perturbations. The maxpool function is decomposed as a series of ReLU functions to extend the convex relaxation technique to maxpool functions, by which the verified bound can be efficiently computed through a dual network. The experimental results demonstrate that this technique allows the state-of-the-art verification precision for maxpool-based CNNs and involves a much lower computational cost than current verification methods, such as DeepZ, DeepPoly and PRIMA. This method is also applicable to large-scale CNNs, which previous studies show to be often computationally prohibitively expensive. Under certain circumstances, CAPM is 40-times, 20-times or twice as fast and give a significantly higher verification bound (CAPM 98% vs. PRIMA 76%/DeepPoly 73%/DeepZ 8%) as compared to PRIMA/DeepPoly/DeepZ. Furthermore, we additionally present the time complexity of our algorithm as $O(W^2NK)$, where $W$ is the maximum width of the neural network, $N$ is the number of neurons, and $K$ is the size of the maxpool layer's kernel.",
    "summary": "arXiv:2407.09550v3 Announce Type: replace-cross Abstract: This study uses CAPM (Convex Adversarial Polytope for Maxpool-based CNN) to improve the verified bound for general purpose maxpool-based convolutional neural networks (CNNs) under bounded norm adversarial perturbations. The maxpool function is decomposed as a series of ReLU functions to extend the convex relaxation technique to maxpool functions, by which the verified bound can be efficiently computed through a dual network. The experimental results demonstrate that this technique allows the state-of-the-art verification precision for maxpool-based CNNs and involves a much lower computational cost than current verification methods, such as DeepZ, DeepPoly and PRIMA. This method is also applicable to large-scale CNNs, which previous studies show to be often computationally prohibitively expensive. Under certain circumstances, CAPM is 40-times, 20-times or twice as fast and give a significantly higher verification bound (CAPM 98% vs. PRIMA 76%/DeepPoly 73%/DeepZ 8%) as compared to PRIMA/DeepPoly/DeepZ. Furthermore, we additionally present the time complexity of our algorithm as $O(W^2NK)$, where $W$ is the maximum width of the neural network, $N$ is the number of neurons, and $K$ is the size of the maxpool layer's kernel.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.09550",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deploying ü§ó ViT on Vertex AI",
    "description": "",
    "summary": "Deploying ü§ó ViT on Vertex AI In the previous posts, we showed how to deploy a Vision Transformers (V...",
    "pubDate": "Fri, 19 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-vertex-ai",
    "thumbnail": "https://huggingface.co/blog/assets/97_vertex_ai/image1.png"
  },
  {
    "title": "The Safety Reminder: A Soft Prompt to Reactivate Delayed Safety Awareness in Vision-Language Models",
    "description": "arXiv:2506.15734v1 Announce Type: new Abstract: As Vision-Language Models (VLMs) demonstrate increasing capabilities across real-world applications such as code generation and chatbot assistance, ensuring their safety has become paramount. Unlike traditional Large Language Models (LLMs), VLMs face unique vulnerabilities due to their multimodal nature, allowing adversaries to modify visual or textual inputs to bypass safety guardrails and trigger the generation of harmful content. Through systematic analysis of VLM behavior under attack, we identify a novel phenomenon termed ``delayed safety awareness''. Specifically, we observe that safety-aligned VLMs may initially be compromised to produce harmful content, but eventually recognize the associated risks and attempt to self-correct. This pattern suggests that VLMs retain their underlying safety awareness but experience a temporal delay in their activation. Building on this insight, we hypothesize that VLMs' safety awareness can be proactively reactivated through carefully designed prompts. To this end, we introduce ``The Safety Reminder'', a soft prompt tuning approach that optimizes learnable prompt tokens, which are periodically injected during the text generation process to enhance safety awareness, effectively preventing harmful content generation. Additionally, our safety reminder only activates when harmful content is detected, leaving normal conversations unaffected and preserving the model's performance on benign tasks. Through comprehensive evaluation across three established safety benchmarks and one adversarial attacks, we demonstrate that our approach significantly reduces attack success rates while maintaining model utility, offering a practical solution for deploying safer VLMs in real-world applications.",
    "summary": "arXiv:2506.15734v1 Announce Type: new Abstract: As Vision-Language Models (VLMs) demonstrate increasing capabilities across real-world applications such as code generation and chatbot assistance, ensuring their safety has become paramount. Unlike traditional Large Language Models (LLMs), VLMs face unique vulnerabilities due to their multimodal nature, allowing adversaries to modify visual or textual inputs to bypass safety guardrails and trigger the generation of harmful content. Through systematic analysis of VLM behavior under attack, we identify a novel phenomenon termed ``delayed safety awareness''. Specifically, we observe that safety-aligned VLMs may initially be compromised to produce harmful content, but eventually recognize the associated risks and attempt to self-correct. This pattern suggests that VLMs retain their underlying safety awareness but experience a temporal delay in their activation. Building on this insight, we hypothesize that VLMs' safety awareness can be proactively reactivated through carefully designed prompts. To this end, we introduce ``The Safety Reminder'', a soft prompt tuning approach that optimizes learnable prompt tokens, which are periodically injected during the text generation process to enhance safety awareness, effectively preventing harmful content generation. Additionally, our safety reminder only activates when harmful content is detected, leaving normal conversations unaffected and preserving the model's performance on benign tasks. Through comprehensive evaluation across three established safety benchmarks and one adversarial attacks, we demonstrate that our approach significantly reduces attack success rates while maintaining model utility, offering a practical solution for deploying safer VLMs in real-world applications.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15734",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SONG: Self-Organizing Neural Graphs",
    "description": "arXiv:2107.13214v2 Announce Type: replace-cross Abstract: Recent years have seen a surge in research on deep interpretable neural networks with decision trees as one of the most commonly incorporated tools. There are at least three advantages of using decision trees over logistic regression classification models: they are easy to interpret since they are based on binary decisions, they can make decisions faster, and they provide a hierarchy of classes. However, one of the well-known drawbacks of decision trees, as compared to decision graphs, is that decision trees cannot reuse the decision nodes. Nevertheless, decision graphs were not commonly used in deep learning due to the lack of efficient gradient-based training techniques. In this paper, we fill this gap and provide a general paradigm based on Markov processes, which allows for efficient training of the special type of decision graphs, which we call Self-Organizing Neural Graphs (SONG). We provide an extensive theoretical study of SONG, complemented by experiments conducted on Letter, Connect4, MNIST, CIFAR, and TinyImageNet datasets, showing that our method performs on par or better than existing decision models.",
    "summary": "arXiv:2107.13214v2 Announce Type: replace-cross Abstract: Recent years have seen a surge in research on deep interpretable neural networks with decision trees as one of the most commonly incorporated tools. There are at least three advantages of using decision trees over logistic regression classification models: they are easy to interpret since they are based on binary decisions, they can make decisions faster, and they provide a hierarchy of classes. However, one of the well-known drawbacks of decision trees, as compared to decision graphs, is that decision trees cannot reuse the decision nodes. Nevertheless, decision graphs were not commonly used in deep learning due to the lack of efficient gradient-based training techniques. In this paper, we fill this gap and provide a general paradigm based on Markov processes, which allows for efficient training of the special type of decision graphs, which we call Self-Organizing Neural Graphs (SONG). We provide an extensive theoretical study of SONG, complemented by experiments conducted on Letter, Connect4, MNIST, CIFAR, and TinyImageNet datasets, showing that our method performs on par or better than existing decision models.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2107.13214",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TrajTok: Technical Report for 2025 Waymo Open Sim Agents Challenge",
    "description": "arXiv:2506.21618v1 Announce Type: cross Abstract: In this technical report, we introduce TrajTok, a trajectory tokenizer for discrete next-token-prediction based behavior generation models, which combines data-driven and rule-based methods with better coverage, symmetry and robustness, along with a spatial-aware label smoothing method for cross-entropy loss. We adopt the tokenizer and loss for the SMART model and reach a superior performance with realism score of 0.7852 on the Waymo Open Sim Agents Challenge 2025. We will open-source the code in the future.",
    "summary": "arXiv:2506.21618v1 Announce Type: cross Abstract: In this technical report, we introduce TrajTok, a trajectory tokenizer for discrete next-token-prediction based behavior generation models, which combines data-driven and rule-based methods with better coverage, symmetry and robustness, along with a spatial-aware label smoothing method for cross-entropy loss. We adopt the tokenizer and loss for the SMART model and reach a superior performance with realism score of 0.7852 on the Waymo Open Sim Agents Challenge 2025. We will open-source the code in the future.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21618",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Survey of HPC in US Research Institutions",
    "description": "arXiv:2506.19019v1 Announce Type: cross Abstract: The rapid growth of AI, data-intensive science, and digital twin technologies has driven an unprecedented demand for high-performance computing (HPC) across the research ecosystem. While national laboratories and industrial hyperscalers have invested heavily in exascale and GPU-centric architectures, university-operated HPC systems remain comparatively under-resourced. This survey presents a comprehensive assessment of the HPC landscape across U.S. universities, benchmarking their capabilities against Department of Energy (DOE) leadership-class systems and industrial AI infrastructures. We examine over 50 premier research institutions, analyzing compute capacity, architectural design, governance models, and energy efficiency. Our findings reveal that university clusters, though vital for academic research, exhibit significantly lower growth trajectories (CAGR $approx$ 18%) than their national ($approx$ 43%) and industrial ($approx$ 78%) counterparts. The increasing skew toward GPU-dense AI workloads has widened the capability gap, highlighting the need for federated computing, idle-GPU harvesting, and cost-sharing models. We also identify emerging paradigms, such as decentralized reinforcement learning, as promising opportunities for democratizing AI training within campus environments. Ultimately, this work provides actionable insights for academic leaders, funding agencies, and technology partners to ensure more equitable and sustainable HPC access in support of national research priorities.",
    "summary": "arXiv:2506.19019v1 Announce Type: cross Abstract: The rapid growth of AI, data-intensive science, and digital twin technologies has driven an unprecedented demand for high-performance computing (HPC) across the research ecosystem. While national laboratories and industrial hyperscalers have invested heavily in exascale and GPU-centric architectures, university-operated HPC systems remain comparatively under-resourced. This survey presents a comprehensive assessment of the HPC landscape across U.S. universities, benchmarking their capabilities against Department of Energy (DOE) leadership-class systems and industrial AI infrastructures. We examine over 50 premier research institutions, analyzing compute capacity, architectural design, governance models, and energy efficiency. Our findings reveal that university clusters, though vital for academic research, exhibit significantly lower growth trajectories (CAGR $approx$ 18%) than their national ($approx$ 43%) and industrial ($approx$ 78%) counterparts. The increasing skew toward GPU-dense AI workloads has widened the capability gap, highlighting the need for federated computing, idle-GPU harvesting, and cost-sharing models. We also identify emerging paradigms, such as decentralized reinforcement learning, as promising opportunities for democratizing AI training within campus environments. Ultimately, this work provides actionable insights for academic leaders, funding agencies, and technology partners to ensure more equitable and sustainable HPC access in support of national research priorities.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility Applications",
    "description": "arXiv:2506.19502v1 Announce Type: cross Abstract: Accessibility remains a critical concern in today's society, as many technologies are not developed to support the full range of user needs. Existing multi-agent systems (MAS) often cannot provide comprehensive assistance for users in need due to the lack of customization stemming from closed-source designs. Consequently, individuals with disabilities frequently encounter significant barriers when attempting to interact with digital environments. We introduce MATE, a multimodal accessibility MAS, which performs the modality conversions based on the user's needs. The system is useful for assisting people with disabilities by ensuring that data will be converted to an understandable format. For instance, if the user cannot see well and receives an image, the system converts this image to its audio description. MATE can be applied to a wide range of domains, industries, and areas, such as healthcare, and can become a useful assistant for various groups of users. The system supports multiple types of models, ranging from LLM API calling to using custom machine learning (ML) classifiers. This flexibility ensures that the system can be adapted to various needs and is compatible with a wide variety of hardware. Since the system is expected to run locally, it ensures the privacy and security of sensitive information. In addition, the framework can be effectively integrated with institutional technologies (e.g., digital healthcare service) for real-time user assistance. Furthermore, we introduce ModCon-Task-Identifier, a model that is capable of extracting the precise modality conversion task from the user input. Numerous experiments show that ModCon-Task-Identifier consistently outperforms other LLMs and statistical models on our custom data. Our code and data are publicly available at https://github.com/AlgazinovAleksandr/Multi-Agent-MATE.",
    "summary": "arXiv:2506.19502v1 Announce Type: cross Abstract: Accessibility remains a critical concern in today's society, as many technologies are not developed to support the full range of user needs. Existing multi-agent systems (MAS) often cannot provide comprehensive assistance for users in need due to the lack of customization stemming from closed-source designs. Consequently, individuals with disabilities frequently encounter significant barriers when attempting to interact with digital environments. We introduce MATE, a multimodal accessibility MAS, which performs the modality conversions based on the user's needs. The system is useful for assisting people with disabilities by ensuring that data will be converted to an understandable format. For instance, if the user cannot see well and receives an image, the system converts this image to its audio description. MATE can be applied to a wide range of domains, industries, and areas, such as healthcare, and can become a useful assistant for various groups of users. The system supports multiple types of models, ranging from LLM API calling to using custom machine learning (ML) classifiers. This flexibility ensures that the system can be adapted to various needs and is compatible with a wide variety of hardware. Since the system is expected to run locally, it ensures the privacy and security of sensitive information. In addition, the framework can be effectively integrated with institutional technologies (e.g., digital healthcare service) for real-time user assistance. Furthermore, we introduce ModCon-Task-Identifier, a model that is capable of extracting the precise modality conversion task from the user input. Numerous experiments show that ModCon-Task-Identifier consistently outperforms other LLMs and statistical models on our custom data. Our code and data are publicly available at https://github.com/AlgazinovAleksandr/Multi-Agent-MATE.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19502",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Snorkel AI x Hugging Face: unlock foundation models for enterprises",
    "description": "",
    "summary": "Snorkel AI x Hugging Face: unlock foundation models for enterprises This article is a cross-post fro...",
    "pubDate": "Thu, 06 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/snorkel-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/snorkel.png"
  },
  {
    "title": "Roboschool",
    "description": "We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym.",
    "summary": "We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym.",
    "pubDate": "Mon, 15 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/roboschool",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Advancing Gemini's security safeguards",
    "description": "We‚Äôve made Gemini 2.5 our most secure model family to date.",
    "summary": "We‚Äôve made Gemini 2.5 our most secure model family to date.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advancing-geminis-security-safeguards/",
    "thumbnail": "https://lh3.googleusercontent.com/Uh_O6Nx1GWznAfODatYYz2sxiDekdb6HWnnSsy-cfmTxfjdUEEleh9w4cBdwUfBnyQBS-t1xW4UZXrMmC-rI6bz31hCrm5nHLt6Cp1FJAT7X9Upv5g=w1200-h630-n-nu"
  },
  {
    "title": "Spring Update",
    "description": "Introducing GPT-4o and making more capabilities available for free in ChatGPT.",
    "summary": "Introducing GPT-4o and making more capabilities available for free in ChatGPT.",
    "pubDate": "Mon, 13 May 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spring-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Partnering with Axios expands OpenAI‚Äôs work with the news industry",
    "description": "Publishers representing hundreds of newsrooms and content brands are using OpenAI partnerships and grant programs to adopt AI tools and strengthen the news ecosystem, while ChatGPT users gain access to information from leading, reliable publications.",
    "summary": "Publishers representing hundreds of newsrooms and content brands are using OpenAI partnerships and grant programs to adopt AI tools and strengthen the news ecosystem, while ChatGPT users gain access to information from leading, reliable publications.",
    "pubDate": "Wed, 15 Jan 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/partnering-with-axios-expands-openai-work-with-the-news-industry",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Gemini Robotics On-Device brings AI to local robotic devices",
    "description": "We‚Äôre introducing an efficient, on-device robotics model with general-purpose dexterity and fast task adaptation.",
    "summary": "We‚Äôre introducing an efficient, on-device robotics model with general-purpose dexterity and fast task adaptation.",
    "pubDate": "Tue, 24 Jun 2025 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-robotics-on-device-brings-ai-to-local-robotic-devices/",
    "thumbnail": "https://lh3.googleusercontent.com/Jt_Vw7PIJEZtXcMIKM1HbWbBCLxv7RUyjyf07eHp-YOfxMCUZA6mPI9kSCaz65UkMoGcZ8CwlD3dNBvy7bnnYchjSkWyN-SugglT3dmg1A9KdoDqdQM=w1200-h630-n-nu"
  },
  {
    "title": "Adapting Probabilistic Risk Assessment for AI",
    "description": "arXiv:2504.18536v2 Announce Type: replace Abstract: Modern general-purpose artificial intelligence (AI) systems present an urgent risk management challenge, as their rapidly evolving capabilities and potential for catastrophic harm outpace our ability to reliably assess their risks. Current methods often rely on selective testing and undocumented assumptions about risk priorities, frequently failing to make a serious attempt at assessing the set of pathways through which AI systems pose direct or indirect risks to society and the biosphere. This paper introduces the probabilistic risk assessment (PRA) for AI framework, adapting established PRA techniques from high-reliability industries (e.g., nuclear power, aerospace) for the new challenges of advanced AI. The framework guides assessors in identifying potential risks, estimating likelihood and severity bands, and explicitly documenting evidence, underlying assumptions, and analyses at appropriate granularities. The framework's implementation tool synthesizes the results into a risk report card with aggregated risk estimates from all assessed risks. It introduces three methodological advances: (1) Aspect-oriented hazard analysis provides systematic hazard coverage guided by a first-principles taxonomy of AI system aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk pathway modeling analyzes causal chains from system aspects to societal impacts using bidirectional analysis and incorporating prospective techniques; and (3) Uncertainty management employs scenario decomposition, reference scales, and explicit tracing protocols to structure credible projections with novelty or limited data. Additionally, the framework harmonizes diverse assessment methods by integrating evidence into comparable, quantified absolute risk estimates for lifecycle decisions. We have implemented this as a workbook tool for AI developers, evaluators, and regulators.",
    "summary": "arXiv:2504.18536v2 Announce Type: replace Abstract: Modern general-purpose artificial intelligence (AI) systems present an urgent risk management challenge, as their rapidly evolving capabilities and potential for catastrophic harm outpace our ability to reliably assess their risks. Current methods often rely on selective testing and undocumented assumptions about risk priorities, frequently failing to make a serious attempt at assessing the set of pathways through which AI systems pose direct or indirect risks to society and the biosphere. This paper introduces the probabilistic risk assessment (PRA) for AI framework, adapting established PRA techniques from high-reliability industries (e.g., nuclear power, aerospace) for the new challenges of advanced AI. The framework guides assessors in identifying potential risks, estimating likelihood and severity bands, and explicitly documenting evidence, underlying assumptions, and analyses at appropriate granularities. The framework's implementation tool synthesizes the results into a risk report card with aggregated risk estimates from all assessed risks. It introduces three methodological advances: (1) Aspect-oriented hazard analysis provides systematic hazard coverage guided by a first-principles taxonomy of AI system aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk pathway modeling analyzes causal chains from system aspects to societal impacts using bidirectional analysis and incorporating prospective techniques; and (3) Uncertainty management employs scenario decomposition, reference scales, and explicit tracing protocols to structure credible projections with novelty or limited data. Additionally, the framework harmonizes diverse assessment methods by integrating evidence into comparable, quantified absolute risk estimates for lifecycle decisions. We have implemented this as a workbook tool for AI developers, evaluators, and regulators.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.18536",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Efficient training of language models to fill in the middle",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 28 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/efficient-training-of-language-models-to-fill-in-the-middle",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Catching halibut with ChatGPT",
    "description": "Using ChatGPT to catch halibut",
    "summary": "Using ChatGPT to catch halibut",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fishing-for-first-timers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New model predicts a chemical reaction‚Äôs point of no return",
    "description": "Chemists could use this quick computational method to design more efficient reactions that yield useful compounds, from fuels to pharmaceuticals.",
    "summary": "Chemists could use this quick computational method to design more efficient reactions that yield useful compounds, from fuels to pharmaceuticals.",
    "pubDate": "Wed, 23 Apr 2025 11:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-model-predicts-chemical-reactions-no-return-point-0423",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/BetterPredict-01-press.jpg"
  },
  {
    "title": "Private Model Personalization Revisited",
    "description": "arXiv:2506.19220v1 Announce Type: cross Abstract: We study model personalization under user-level differential privacy (DP) in the shared representation framework. In this problem, there are $n$ users whose data is statistically heterogeneous, and their optimal parameters share an unknown embedding $U^* inmathbb{R}^{dtimes k}$ that maps the user parameters in $mathbb{R}^d$ to low-dimensional representations in $mathbb{R}^k$, where $kll d$. Our goal is to privately recover the shared embedding and the local low-dimensional representations with small excess risk in the federated setting. We propose a private, efficient federated learning algorithm to learn the shared embedding based on the FedRep algorithm in [CHM+21]. Unlike [CHM+21], our algorithm satisfies differential privacy, and our results hold for the case of noisy labels. In contrast to prior work on private model personalization [JRS+21], our utility guarantees hold under a larger class of users' distributions (sub-Gaussian instead of Gaussian distributions). Additionally, in natural parameter regimes, we improve the privacy error term in [JRS+21] by a factor of $widetilde{O}(dk)$. Next, we consider the binary classification setting. We present an information-theoretic construction to privately learn the shared embedding and derive a margin-based accuracy guarantee that is independent of $d$. Our method utilizes the Johnson-Lindenstrauss transform to reduce the effective dimensions of the shared embedding and the users' data. This result shows that dimension-independent risk bounds are possible in this setting under a margin loss.",
    "summary": "arXiv:2506.19220v1 Announce Type: cross Abstract: We study model personalization under user-level differential privacy (DP) in the shared representation framework. In this problem, there are $n$ users whose data is statistically heterogeneous, and their optimal parameters share an unknown embedding $U^* inmathbb{R}^{dtimes k}$ that maps the user parameters in $mathbb{R}^d$ to low-dimensional representations in $mathbb{R}^k$, where $kll d$. Our goal is to privately recover the shared embedding and the local low-dimensional representations with small excess risk in the federated setting. We propose a private, efficient federated learning algorithm to learn the shared embedding based on the FedRep algorithm in [CHM+21]. Unlike [CHM+21], our algorithm satisfies differential privacy, and our results hold for the case of noisy labels. In contrast to prior work on private model personalization [JRS+21], our utility guarantees hold under a larger class of users' distributions (sub-Gaussian instead of Gaussian distributions). Additionally, in natural parameter regimes, we improve the privacy error term in [JRS+21] by a factor of $widetilde{O}(dk)$. Next, we consider the binary classification setting. We present an information-theoretic construction to privately learn the shared embedding and derive a margin-based accuracy guarantee that is independent of $d$. Our method utilizes the Johnson-Lindenstrauss transform to reduce the effective dimensions of the shared embedding and the users' data. This result shows that dimension-independent risk bounds are possible in this setting under a margin loss.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19220",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Large Language Models: A New Moore's Law?",
    "description": "",
    "summary": "Large Language Models: A New Moore's Law? A few days ago, Microsoft and NVIDIA introduced Megatron-T...",
    "pubDate": "Tue, 26 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/large-language-models",
    "thumbnail": "https://huggingface.co/blog/assets/33_large_language_models/01_model_size.jpg"
  },
  {
    "title": "Ethics and Society Newsletter #4: Bias in Text-to-Image Models",
    "description": "",
    "summary": "Ethics and Society Newsletter #4: Bias in Text-to-Image Models TL;DR: We need better ways of evaluat...",
    "pubDate": "Mon, 26 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-4",
    "thumbnail": "https://huggingface.co/blog/assets/152_ethics_soc_4/ethics_4_thumbnail.png"
  },
  {
    "title": "Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought",
    "description": "arXiv:2403.05518v3 Announce Type: replace-cross Abstract: Chain-of-thought prompting (CoT) has the potential to improve the explainability of language model reasoning. But CoT can also systematically misrepresent the factors influencing models' behavior -- for example, rationalizing answers in line with a user's opinion. We first create a new dataset of 9 different biases that affect GPT-3.5-Turbo and Llama-8b models. These consist of spurious-few-shot patterns, post hoc rationalization, and sycophantic settings. Models switch to the answer implied by the bias, without mentioning the effect of the bias in the CoT. To mitigate this biased reasoning problem, we introduce bias-augmented consistency training (BCT), an unsupervised fine-tuning scheme that trains models to give consistent reasoning across prompts with and without biasing features. We construct a suite testing nine forms of biased reasoning on seven question-answering tasks, and find that applying BCT to GPT-3.5-Turbo with one bias reduces the rate of biased reasoning by 86% on held-out tasks. Moreover, this model generalizes to other forms of bias, reducing biased reasoning on held-out biases by an average of 37%. As BCT generalizes to held-out biases and does not require gold labels, this method may hold promise for reducing biased reasoning from as-of-yet unknown biases and on tasks where ground truth reasoning is unavailable.",
    "summary": "arXiv:2403.05518v3 Announce Type: replace-cross Abstract: Chain-of-thought prompting (CoT) has the potential to improve the explainability of language model reasoning. But CoT can also systematically misrepresent the factors influencing models' behavior -- for example, rationalizing answers in line with a user's opinion. We first create a new dataset of 9 different biases that affect GPT-3.5-Turbo and Llama-8b models. These consist of spurious-few-shot patterns, post hoc rationalization, and sycophantic settings. Models switch to the answer implied by the bias, without mentioning the effect of the bias in the CoT. To mitigate this biased reasoning problem, we introduce bias-augmented consistency training (BCT), an unsupervised fine-tuning scheme that trains models to give consistent reasoning across prompts with and without biasing features. We construct a suite testing nine forms of biased reasoning on seven question-answering tasks, and find that applying BCT to GPT-3.5-Turbo with one bias reduces the rate of biased reasoning by 86% on held-out tasks. Moreover, this model generalizes to other forms of bias, reducing biased reasoning on held-out biases by an average of 37%. As BCT generalizes to held-out biases and does not require gold labels, this method may hold promise for reducing biased reasoning from as-of-yet unknown biases and on tasks where ground truth reasoning is unavailable.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2403.05518",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLM Web Dynamics: Tracing Model Collapse in a Network of LLMs",
    "description": "arXiv:2506.15690v1 Announce Type: cross Abstract: The increasing use of synthetic data from the public Internet has enhanced data usage efficiency in large language model (LLM) training. However, the potential threat of model collapse remains insufficiently explored. Existing studies primarily examine model collapse in a single model setting or rely solely on statistical surrogates. In this work, we introduce LLM Web Dynamics (LWD), an efficient framework for investigating model collapse at the network level. By simulating the Internet with a retrieval-augmented generation (RAG) database, we analyze the convergence pattern of model outputs. Furthermore, we provide theoretical guarantees for this convergence by drawing an analogy to interacting Gaussian Mixture Models.",
    "summary": "arXiv:2506.15690v1 Announce Type: cross Abstract: The increasing use of synthetic data from the public Internet has enhanced data usage efficiency in large language model (LLM) training. However, the potential threat of model collapse remains insufficiently explored. Existing studies primarily examine model collapse in a single model setting or rely solely on statistical surrogates. In this work, we introduce LLM Web Dynamics (LWD), an efficient framework for investigating model collapse at the network level. By simulating the Internet with a retrieval-augmented generation (RAG) database, we analyze the convergence pattern of model outputs. Furthermore, we provide theoretical guarantees for this convergence by drawing an analogy to interacting Gaussian Mixture Models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15690",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "New ways to manage your data in ChatGPT",
    "description": "ChatGPT users can now turn off chat history, allowing you to choose which conversations can be used to train our models.",
    "summary": "ChatGPT users can now turn off chat history, allowing you to choose which conversations can be used to train our models.",
    "pubDate": "Tue, 25 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-ways-to-manage-your-data-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Guiding Text Generation with Constrained Beam Search in ü§ó Transformers",
    "description": "",
    "summary": "Guiding Text Generation with Constrained Beam Search in ü§ó Transformers Introduction This blog post a...",
    "pubDate": "Fri, 11 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/constrained-beam-search",
    "thumbnail": "https://huggingface.co/blog/assets/53_constrained_beam_search/thumbnail.png"
  },
  {
    "title": "Fine-Tune W2V2-Bert for low-resource ASR with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune W2V2-Bert for low-resource ASR with ü§ó Transformers New (01/2024): This blog post is strong...",
    "pubDate": "Fri, 19 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-w2v2-bert",
    "thumbnail": "https://huggingface.co/blog/assets/fine-tune-w2v2-bert/w2v_thumbnail.png"
  },
  {
    "title": "Novel AI model inspired by neural dynamics from the brain",
    "description": "New type of ‚Äústate-space model‚Äù leverages principles of harmonic oscillators.",
    "summary": "New type of ‚Äústate-space model‚Äù leverages principles of harmonic oscillators.",
    "pubDate": "Fri, 02 May 2025 15:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/novel-ai-model-inspired-neural-dynamics-from-brain-0502",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-LinOSS.jpg"
  },
  {
    "title": "Disrupting malicious uses of AI by state-affiliated threat actors",
    "description": "We terminated accounts associated with state-affiliated threat actors. Our findings show our models offer only limited, incremental capabilities for malicious cybersecurity tasks.",
    "summary": "We terminated accounts associated with state-affiliated threat actors. Our findings show our models offer only limited, incremental capabilities for malicious cybersecurity tasks.",
    "pubDate": "Wed, 14 Feb 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/disrupting-malicious-uses-of-ai-by-state-affiliated-threat-actors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Universal Image Segmentation with Mask2Former and OneFormer",
    "description": "",
    "summary": "Universal Image Segmentation with Mask2Former and OneFormer This guide introduces Mask2Former and On...",
    "pubDate": "Thu, 19 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mask2former",
    "thumbnail": "https://huggingface.co/blog/assets/127_mask2former/thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT search",
    "description": "Get fast, timely answers with links to relevant web sources",
    "summary": "Get fast, timely answers with links to relevant web sources",
    "pubDate": "Thu, 31 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-search",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Binned semiparametric Bayesian networks",
    "description": "arXiv:2506.21997v1 Announce Type: cross Abstract: This paper introduces a new type of probabilistic semiparametric model that takes advantage of data binning to reduce the computational cost of kernel density estimation in nonparametric distributions. Two new conditional probability distributions are developed for the new binned semiparametric Bayesian networks, the sparse binned kernel density estimation and the Fourier kernel density estimation. These two probability distributions address the curse of dimensionality, which typically impacts binned models, by using sparse tensors and restricting the number of parent nodes in conditional probability calculations. To evaluate the proposal, we perform a complexity analysis and conduct several comparative experiments using synthetic data and datasets from the UCI Machine Learning repository. The experiments include different binning rules, parent restrictions, grid sizes, and number of instances to get a holistic view of the model's behavior. As a result, our binned semiparametric Bayesian networks achieve structural learning and log-likelihood estimations with no statistically significant differences compared to the semiparametric Bayesian networks, but at a much higher speed. Thus, the new binned semiparametric Bayesian networks prove to be a reliable and more efficient alternative to their non-binned counterparts.",
    "summary": "arXiv:2506.21997v1 Announce Type: cross Abstract: This paper introduces a new type of probabilistic semiparametric model that takes advantage of data binning to reduce the computational cost of kernel density estimation in nonparametric distributions. Two new conditional probability distributions are developed for the new binned semiparametric Bayesian networks, the sparse binned kernel density estimation and the Fourier kernel density estimation. These two probability distributions address the curse of dimensionality, which typically impacts binned models, by using sparse tensors and restricting the number of parent nodes in conditional probability calculations. To evaluate the proposal, we perform a complexity analysis and conduct several comparative experiments using synthetic data and datasets from the UCI Machine Learning repository. The experiments include different binning rules, parent restrictions, grid sizes, and number of instances to get a holistic view of the model's behavior. As a result, our binned semiparametric Bayesian networks achieve structural learning and log-likelihood estimations with no statistically significant differences compared to the semiparametric Bayesian networks, but at a much higher speed. Thus, the new binned semiparametric Bayesian networks prove to be a reliable and more efficient alternative to their non-binned counterparts.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21997",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SafeCoder vs. Closed-source Code Assistants",
    "description": "",
    "summary": "SafeCoder vs. Closed-source Code Assistants For decades, software developers have designed methodolo...",
    "pubDate": "Mon, 11 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safecoder-vs-closed-source-code-assistants",
    "thumbnail": "https://huggingface.co/blog/assets/safecoder-vs-closed-source-code-assistants/image.png"
  },
  {
    "title": "SmolVLM2: Bringing Video Understanding to Every Device",
    "description": "",
    "summary": "SmolVLM2: Bringing Video Understanding to Every Device TL;DR: SmolVLM can now watch üì∫ with even bett...",
    "pubDate": "Thu, 20 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvlm2",
    "thumbnail": "https://huggingface.co/blog/assets/smolvlm2/banner.png"
  },
  {
    "title": "A Deepdive into Aya Expanse: Advancing the Frontier of Multilinguality",
    "description": "",
    "summary": "A Deepdive into Aya Expanse: Advancing the Frontier of Multilinguality This is a guest blog post by ...",
    "pubDate": "Thu, 24 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aya-expanse",
    "thumbnail": "https://huggingface.co/blog/assets/aya-expanse/thumbnail.jpg"
  },
  {
    "title": "Consistency Verification in Ontology-Based Process Models with Parameter Interdependencies",
    "description": "arXiv:2506.16087v1 Announce Type: new Abstract: The formalization of process knowledge using ontologies enables consistent modeling of parameter interdependencies in manufacturing. These interdependencies are typically represented as mathematical expressions that define relations between process parameters, supporting tasks such as calculation, validation, and simulation. To support cross-context application and knowledge reuse, such expressions are often defined in a generic form and applied across multiple process contexts. This highlights the necessity of a consistent and semantically coherent model to ensure the correctness of data retrieval and interpretation. Consequently, dedicated mechanisms are required to address key challenges such as selecting context-relevant data, ensuring unit compatibility between variables and data elements, and verifying the completeness of input data required for evaluating mathematical expressions. This paper presents a set of verification mechanisms for a previously developed ontology-based process model that integrates standardized process semantics, data element definitions, and formal mathematical constructs. The approach includes (i) SPARQL-based filtering to retrieve process-relevant data, (ii) a unit consistency check based on expected-unit annotations and semantic classification, and (iii) a data completeness check to validate the evaluability of interdependencies. The applicability of the approach is demonstrated with a use case from Resin Transfer Molding (RTM), supporting the development of machine-interpretable and verifiable engineering models.",
    "summary": "arXiv:2506.16087v1 Announce Type: new Abstract: The formalization of process knowledge using ontologies enables consistent modeling of parameter interdependencies in manufacturing. These interdependencies are typically represented as mathematical expressions that define relations between process parameters, supporting tasks such as calculation, validation, and simulation. To support cross-context application and knowledge reuse, such expressions are often defined in a generic form and applied across multiple process contexts. This highlights the necessity of a consistent and semantically coherent model to ensure the correctness of data retrieval and interpretation. Consequently, dedicated mechanisms are required to address key challenges such as selecting context-relevant data, ensuring unit compatibility between variables and data elements, and verifying the completeness of input data required for evaluating mathematical expressions. This paper presents a set of verification mechanisms for a previously developed ontology-based process model that integrates standardized process semantics, data element definitions, and formal mathematical constructs. The approach includes (i) SPARQL-based filtering to retrieve process-relevant data, (ii) a unit consistency check based on expected-unit annotations and semantic classification, and (iii) a data completeness check to validate the evaluability of interdependencies. The applicability of the approach is demonstrated with a use case from Resin Transfer Molding (RTM), supporting the development of machine-interpretable and verifiable engineering models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16087",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon",
    "description": "",
    "summary": "Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon Large language models (LLM...",
    "pubDate": "Tue, 16 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/generative-ai-models-on-intel-cpu",
    "thumbnail": "https://huggingface.co/blog/assets/143_q8chat/thumbnail.png"
  },
  {
    "title": "ScreenSuite - The most comprehensive evaluation suite for GUI Agents!",
    "description": "",
    "summary": "ScreenSuite - The most comprehensive evaluation suite for GUI Agents! Releasing ScreenSuite, the mos...",
    "pubDate": "Fri, 06 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/screensuite",
    "thumbnail": "https://huggingface.co/blog/assets/screensuite/thumbnail.png"
  },
  {
    "title": "Progressive Inference-Time Annealing of Diffusion Models for Sampling from Boltzmann Densities",
    "description": "arXiv:2506.16471v1 Announce Type: cross Abstract: Sampling efficiently from a target unnormalized probability density remains a core challenge, with relevance across countless high-impact scientific applications. A promising approach towards this challenge is the design of amortized samplers that borrow key ideas, such as probability path design, from state-of-the-art generative diffusion models. However, all existing diffusion-based samplers remain unable to draw samples from distributions at the scale of even simple molecular systems. In this paper, we propose Progressive Inference-Time Annealing (PITA), a novel framework to learn diffusion-based samplers that combines two complementary interpolation techniques: I.) Annealing of the Boltzmann distribution and II.) Diffusion smoothing. PITA trains a sequence of diffusion models from high to low temperatures by sequentially training each model at progressively higher temperatures, leveraging engineered easy access to samples of the temperature-annealed target density. In the subsequent step, PITA enables simulating the trained diffusion model to procure training samples at a lower temperature for the next diffusion model through inference-time annealing using a novel Feynman-Kac PDE combined with Sequential Monte Carlo. Empirically, PITA enables, for the first time, equilibrium sampling of N-body particle systems, Alanine Dipeptide, and tripeptides in Cartesian coordinates with dramatically lower energy function evaluations. Code available at: https://github.com/taraak/pita",
    "summary": "arXiv:2506.16471v1 Announce Type: cross Abstract: Sampling efficiently from a target unnormalized probability density remains a core challenge, with relevance across countless high-impact scientific applications. A promising approach towards this challenge is the design of amortized samplers that borrow key ideas, such as probability path design, from state-of-the-art generative diffusion models. However, all existing diffusion-based samplers remain unable to draw samples from distributions at the scale of even simple molecular systems. In this paper, we propose Progressive Inference-Time Annealing (PITA), a novel framework to learn diffusion-based samplers that combines two complementary interpolation techniques: I.) Annealing of the Boltzmann distribution and II.) Diffusion smoothing. PITA trains a sequence of diffusion models from high to low temperatures by sequentially training each model at progressively higher temperatures, leveraging engineered easy access to samples of the temperature-annealed target density. In the subsequent step, PITA enables simulating the trained diffusion model to procure training samples at a lower temperature for the next diffusion model through inference-time annealing using a novel Feynman-Kac PDE combined with Sequential Monte Carlo. Empirically, PITA enables, for the first time, equilibrium sampling of N-body particle systems, Alanine Dipeptide, and tripeptides in Cartesian coordinates with dramatically lower energy function evaluations. Code available at: https://github.com/taraak/pita",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16471",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Ë§áÊï∞„ÅÆË≥™Âïè„ÅßÊØí„Çí‰ªïËæº„ÇÄ„ÄÄÊñ∞ÂûãAI„Ç∏„Çß„Ç§„É´„Éñ„É¨„Éº„ÇØ„ÄåEcho Chamber Attack„Äç„É°„Ç´„Éã„Ç∫„É†",
    "description": "NeuralTrust„ÅØÊñ∞„Åü„Å™LLM„Ç∏„Çß„Ç§„É´„Éñ„É¨„Éº„ÇØÊâãÊ≥ï„ÄåEcho Chamber Attack„Äç„ÇíÁô∫Ë°®„Åó„Åü„ÄÇË§áÊï∞„Çø„Éº„É≥„ÅÆÁÑ°ÂÆ≥„Å™„ÇÑ„Çä„Å®„Çä„ÇíÈÄö„Åò„Å¶„É¢„Éá„É´„ÅÆÂÜÖÈÉ®ÊñáËÑà„ÇíË™òÂ∞é„Åó„ÄÅÊúâÂÆ≥Âá∫Âäõ„ÇíÂºï„ÅçÂá∫„ÅôÊäÄË°ì„Å®„Åï„Çå„ÄÅÂ§ö„Åè„ÅÆAI„É¢„Éá„É´„Å´ÈÄöÁî®„Åô„Çã„Å®„ÅÑ„ÅÜ„ÄÇ",
    "summary": "NeuralTrust„ÅØÊñ∞„Åü„Å™LLM„Ç∏„Çß„Ç§„É´„Éñ„É¨„Éº„ÇØÊâãÊ≥ï„ÄåEcho Chamber Attack„Äç„ÇíÁô∫Ë°®„Åó„Åü„ÄÇË§áÊï∞„Çø„Éº„É≥„ÅÆÁÑ°ÂÆ≥„Å™„ÇÑ„Çä„Å®„Çä„ÇíÈÄö„Åò„Å¶„É¢„Éá„É´„ÅÆÂÜÖÈÉ®ÊñáËÑà„ÇíË™òÂ∞é„Åó„ÄÅÊúâÂÆ≥Âá∫Âäõ„ÇíÂºï„ÅçÂá∫„ÅôÊäÄË°ì„Å®„Åï„Çå„ÄÅÂ§ö„Åè„ÅÆAI„É¢„Éá„É´„Å´ÈÄöÁî®„Åô„Çã„Å®„ÅÑ„ÅÜ„ÄÇ",
    "pubDate": "Wed, 25 Jun 2025 09:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/25/news036.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/25/cover_news036.jpg"
  },
  {
    "title": "„É™„Ç≥„Éº„ÄÅGENIAC„Åß„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„ÄÇ7Êúà„Å´ÁÑ°ÂÑüÂÖ¨Èñã",
    "description": "<p>„É™„Ç≥„Éº„ÅØ„ÄÅÁµåÊ∏àÁî£Ê•≠ÁúÅ„Åä„Çà„Å≥NEDO„ÅåÊé®ÈÄ≤„Åô„ÇãGENIAC„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Å´„Åä„ÅÑ„Å¶„ÄÅÊó•Êú¨‰ºÅÊ•≠Âêë„ÅëÂõ≥Ë°®„ÇíÂê´„ÇÄ„Éâ„Ç≠„É•„É°„É≥„ÉàË™≠„ÅøÂèñ„Çä„Å´ÁâπÂåñ„Åó„Åü„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„Åó„Åæ„Åó„Åü„ÄÇ7Êúà29Êó•ÈñãÂÇ¨„ÅÆMIRU2025„ÅßË´ñÊñáÁô∫Ë°® [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/'>„É™„Ç≥„Éº„ÄÅGENIAC„Åß„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„ÄÇ7Êúà„Å´ÁÑ°ÂÑüÂÖ¨Èñã</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>„É™„Ç≥„Éº„ÅØ„ÄÅÁµåÊ∏àÁî£Ê•≠ÁúÅ„Åä„Çà„Å≥NEDO„ÅåÊé®ÈÄ≤„Åô„ÇãGENIAC„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Å´„Åä„ÅÑ„Å¶„ÄÅÊó•Êú¨‰ºÅÊ•≠Âêë„ÅëÂõ≥Ë°®„ÇíÂê´„ÇÄ„Éâ„Ç≠„É•„É°„É≥„ÉàË™≠„ÅøÂèñ„Çä„Å´ÁâπÂåñ„Åó„Åü„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„Åó„Åæ„Åó„Åü„ÄÇ7Êúà29Êó•ÈñãÂÇ¨„ÅÆMIRU2025„ÅßË´ñÊñáÁô∫Ë°® [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/'>„É™„Ç≥„Éº„ÄÅGENIAC„Åß„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´LLM„ÅÆÂü∫Êú¨„É¢„Éá„É´„ÇíÈñãÁô∫„ÄÇ7Êúà„Å´ÁÑ°ÂÑüÂÖ¨Èñã</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Tue, 24 Jun 2025 07:52:10 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/ricoh-genia-multimodal-llm/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/ricoh-genia-multimodal-llm.png"
  },
  {
    "title": "DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs",
    "description": "arXiv:2506.11558v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have recently been extended to the video domain, enabling sophisticated video-language understanding. However, existing Video LLMs often exhibit limitations in fine-grained temporal reasoning, restricting their ability to precisely attribute responses to specific video moments, especially under constrained supervision. We introduce DaMO, a data-efficient Video LLM explicitly designed for accurate temporal reasoning and multimodal understanding. At its core, the proposed Temporal-aware Fuseformer employs a hierarchical dual-stream architecture that progressively captures temporal dynamics within each modality and effectively fuses complementary visual and audio information. To further enhance computational efficiency, DaMO integrates a global residual that reduces spatial redundancy while preserving essential semantic details. We train DaMO via a structured four-stage progressive training paradigm, incrementally equipping the model with multimodal alignment, semantic grounding, and temporal reasoning capabilities. This work also contributes multiple datasets augmented from existing ones with GPT-generated temporally grounded QA pairs for tasks requiring temporal supervision. Comprehensive experiments on temporal grounding and video QA benchmarks demonstrate that DaMO consistently surpasses prior methods, particularly in tasks demanding precise temporal alignment and reasoning. Our work establishes a promising direction for data-efficient video-language modeling.",
    "summary": "arXiv:2506.11558v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have recently been extended to the video domain, enabling sophisticated video-language understanding. However, existing Video LLMs often exhibit limitations in fine-grained temporal reasoning, restricting their ability to precisely attribute responses to specific video moments, especially under constrained supervision. We introduce DaMO, a data-efficient Video LLM explicitly designed for accurate temporal reasoning and multimodal understanding. At its core, the proposed Temporal-aware Fuseformer employs a hierarchical dual-stream architecture that progressively captures temporal dynamics within each modality and effectively fuses complementary visual and audio information. To further enhance computational efficiency, DaMO integrates a global residual that reduces spatial redundancy while preserving essential semantic details. We train DaMO via a structured four-stage progressive training paradigm, incrementally equipping the model with multimodal alignment, semantic grounding, and temporal reasoning capabilities. This work also contributes multiple datasets augmented from existing ones with GPT-generated temporally grounded QA pairs for tasks requiring temporal supervision. Comprehensive experiments on temporal grounding and video QA benchmarks demonstrate that DaMO consistently surpasses prior methods, particularly in tasks demanding precise temporal alignment and reasoning. Our work establishes a promising direction for data-efficient video-language modeling.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11558",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AntiGrounding: Lifting Robotic Actions into VLM Representation Space for Decision Making",
    "description": "arXiv:2506.12374v2 Announce Type: replace-cross Abstract: Vision-Language Models (VLMs) encode knowledge and reasoning capabilities for robotic manipulation within high-dimensional representation spaces. However, current approaches often project them into compressed intermediate representations, discarding important task-specific information such as fine-grained spatial or semantic details. To address this, we propose AntiGrounding, a new framework that reverses the instruction grounding process. It lifts candidate actions directly into the VLM representation space, renders trajectories from multiple views, and uses structured visual question answering for instruction-based decision making. This enables zero-shot synthesis of optimal closed-loop robot trajectories for new tasks. We also propose an offline policy refinement module that leverages past experience to enhance long-term performance. Experiments in both simulation and real-world environments show that our method outperforms baselines across diverse robotic manipulation tasks.",
    "summary": "arXiv:2506.12374v2 Announce Type: replace-cross Abstract: Vision-Language Models (VLMs) encode knowledge and reasoning capabilities for robotic manipulation within high-dimensional representation spaces. However, current approaches often project them into compressed intermediate representations, discarding important task-specific information such as fine-grained spatial or semantic details. To address this, we propose AntiGrounding, a new framework that reverses the instruction grounding process. It lifts candidate actions directly into the VLM representation space, renders trajectories from multiple views, and uses structured visual question answering for instruction-based decision making. This enables zero-shot synthesis of optimal closed-loop robot trajectories for new tasks. We also propose an offline policy refinement module that leverages past experience to enhance long-term performance. Experiments in both simulation and real-world environments show that our method outperforms baselines across diverse robotic manipulation tasks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12374",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Machine Learning Experts - Sasha Luccioni Interview",
    "description": "",
    "summary": "Machine Learning Experts - Sasha Luccioni ü§ó Welcome to Machine Learning Experts - Sasha Luccioni üöÄ I...",
    "pubDate": "Tue, 17 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sasha-luccioni-interview",
    "thumbnail": "https://huggingface.co/blog/assets/69_sasha_luccioni_interview/thumbnail.png"
  },
  {
    "title": "SDE-SQL: Enhancing Text-to-SQL Generation in Large Language Models via Self-Driven Exploration with SQL Probes",
    "description": "arXiv:2506.07245v2 Announce Type: replace-cross Abstract: Recent advancements in large language models (LLMs) have significantly improved performance on the Text-to-SQL task. However, prior approaches typically rely on static, pre-processed database information provided at inference time, which limits the model's ability to fully understand the database contents. Without dynamic interaction, LLMs are constrained to fixed, human-provided context and cannot autonomously explore the underlying data. To address this limitation, we propose SDE-SQL, a framework that enables large language models to perform self-driven exploration of databases during inference. This is accomplished by generating and executing SQL probes, which allow the model to actively retrieve information from the database and iteratively update its understanding of the data. Unlike prior methods, SDE-SQL operates in a zero-shot setting, without relying on any question-SQL pairs as in-context demonstrations. When evaluated on the BIRD benchmark with Qwen2.5-72B-Instruct, SDE-SQL achieves an 8.02% relative improvement in execution accuracy over the vanilla Qwen2.5-72B-Instruct baseline, establishing a new state-of-the-art among methods based on open-source models without supervised fine-tuning (SFT) or model ensembling. Moreover, with SFT, the performance of SDE-SQL can be further enhanced, yielding an additional 0.52% improvement.",
    "summary": "arXiv:2506.07245v2 Announce Type: replace-cross Abstract: Recent advancements in large language models (LLMs) have significantly improved performance on the Text-to-SQL task. However, prior approaches typically rely on static, pre-processed database information provided at inference time, which limits the model's ability to fully understand the database contents. Without dynamic interaction, LLMs are constrained to fixed, human-provided context and cannot autonomously explore the underlying data. To address this limitation, we propose SDE-SQL, a framework that enables large language models to perform self-driven exploration of databases during inference. This is accomplished by generating and executing SQL probes, which allow the model to actively retrieve information from the database and iteratively update its understanding of the data. Unlike prior methods, SDE-SQL operates in a zero-shot setting, without relying on any question-SQL pairs as in-context demonstrations. When evaluated on the BIRD benchmark with Qwen2.5-72B-Instruct, SDE-SQL achieves an 8.02% relative improvement in execution accuracy over the vanilla Qwen2.5-72B-Instruct baseline, establishing a new state-of-the-art among methods based on open-source models without supervised fine-tuning (SFT) or model ensembling. Moreover, with SFT, the performance of SDE-SQL can be further enhanced, yielding an additional 0.52% improvement.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.07245",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage",
    "description": "arXiv:2504.20007v3 Announce Type: replace Abstract: This paper proposes a novel interdisciplinary framework for analyzing police body-worn camera (BWC) footage from the Rochester Police Department (RPD) using advanced artificial intelligence (AI) and statistical machine learning (ML) techniques. Our goal is to detect, classify, and analyze patterns of interaction between police officers and civilians to identify key behavioral dynamics, such as respect, disrespect, escalation, and de-escalation. We apply multimodal data analysis by integrating image, audio, and natural language processing (NLP) techniques to extract meaningful insights from BWC footage. The framework incorporates speaker separation, transcription, and large language models (LLMs) to produce structured, interpretable summaries of police-civilian encounters. We also employ a custom evaluation pipeline to assess transcription quality and behavior detection accuracy in high-stakes, real-world policing scenarios. Our methodology, computational techniques, and findings outline a practical approach for law enforcement review, training, and accountability processes while advancing the frontiers of knowledge discovery from complex police BWC data.",
    "summary": "arXiv:2504.20007v3 Announce Type: replace Abstract: This paper proposes a novel interdisciplinary framework for analyzing police body-worn camera (BWC) footage from the Rochester Police Department (RPD) using advanced artificial intelligence (AI) and statistical machine learning (ML) techniques. Our goal is to detect, classify, and analyze patterns of interaction between police officers and civilians to identify key behavioral dynamics, such as respect, disrespect, escalation, and de-escalation. We apply multimodal data analysis by integrating image, audio, and natural language processing (NLP) techniques to extract meaningful insights from BWC footage. The framework incorporates speaker separation, transcription, and large language models (LLMs) to produce structured, interpretable summaries of police-civilian encounters. We also employ a custom evaluation pipeline to assess transcription quality and behavior detection accuracy in high-stakes, real-world policing scenarios. Our methodology, computational techniques, and findings outline a practical approach for law enforcement review, training, and accountability processes while advancing the frontiers of knowledge discovery from complex police BWC data.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.20007",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Explicit neural network classifiers for non-separable data",
    "description": "arXiv:2504.18710v2 Announce Type: replace-cross Abstract: We fully characterize a large class of feedforward neural networks in terms of truncation maps. As an application, we show how a ReLU neural network can implement a feature map which separates concentric data.",
    "summary": "arXiv:2504.18710v2 Announce Type: replace-cross Abstract: We fully characterize a large class of feedforward neural networks in terms of truncation maps. As an application, we show how a ReLU neural network can implement a feature map which separates concentric data.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.18710",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome, Gradio 5",
    "description": "",
    "summary": "Welcome, Gradio 5 We‚Äôve been hard at work over the past few months, and we are excited to now announ...",
    "pubDate": "Wed, 09 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-5",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-5/thumbnail.png"
  },
  {
    "title": "Adapting Foundation Speech Recognition Models to Impaired Speech: A Semantic Re-chaining Approach for Personalization of German Speech",
    "description": "arXiv:2506.21622v1 Announce Type: cross Abstract: Speech impairments caused by conditions such as cerebral palsy or genetic disorders pose significant challenges for automatic speech recognition (ASR) systems. Despite recent advances, ASR models like Whisper struggle with non-normative speech due to limited training data and the difficulty of collecting and annotating non-normative speech samples. In this work, we propose a practical and lightweight pipeline to personalize ASR models, formalizing the selection of words and enriching a small, speech-impaired dataset with semantic coherence. Applied to data from a child with a structural speech impairment, our approach shows promising improvements in transcription quality, demonstrating the potential to reduce communication barriers for individuals with atypical speech patterns.",
    "summary": "arXiv:2506.21622v1 Announce Type: cross Abstract: Speech impairments caused by conditions such as cerebral palsy or genetic disorders pose significant challenges for automatic speech recognition (ASR) systems. Despite recent advances, ASR models like Whisper struggle with non-normative speech due to limited training data and the difficulty of collecting and annotating non-normative speech samples. In this work, we propose a practical and lightweight pipeline to personalize ASR models, formalizing the selection of words and enriching a small, speech-impaired dataset with semantic coherence. Applied to data from a child with a structural speech impairment, our approach shows promising improvements in transcription quality, demonstrating the potential to reduce communication barriers for individuals with atypical speech patterns.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21622",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hear a podcast discussion about Gemini‚Äôs coding capabilities.",
    "description": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-600x600.format-webp.webp' />The latest episode of the Google AI: Release Notes podcast focuses on how the Gemini team built one of the world‚Äôs leading AI coding models.Host Logan Kilpatrick chats w‚Ä¶",
    "summary": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-600x600.format-webp.webp' />The latest episode of the Google AI: Release Notes podcast focuses on how the Gemini team built one of the world‚Äôs leading AI coding models.Host Logan Kilpatrick chats w‚Ä¶",
    "pubDate": "Wed, 18 Jun 2025 10:28:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/gemini/gemini-coding-podcast/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/ep8_thumbnail.max-1440x810.png"
  },
  {
    "title": "Using GPT-4 to improve teaching and learning in Brazil",
    "description": "Improving teaching and learning in Brazil",
    "summary": "Improving teaching and learning in Brazil",
    "pubDate": "Tue, 17 Sep 2024 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/arco-education",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "2023, year of open LLMs",
    "description": "",
    "summary": "2023, year of open LLMs 2023 has seen a surge of public interest in Large Language Models (LLMs), an...",
    "pubDate": "Mon, 18 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/2023-in-llms",
    "thumbnail": "https://huggingface.co/blog/assets/cv_state/thumbnail.png"
  },
  {
    "title": "Decentralized Collective World Model for Emergent Communication and Coordination",
    "description": "arXiv:2504.03353v2 Announce Type: replace-cross Abstract: We propose a fully decentralized multi-agent world model that enables both symbol emergence for communication and coordinated behavior through temporal extension of collective predictive coding. Unlike previous research that focuses on either communication or coordination separately, our approach achieves both simultaneously. Our method integrates world models with communication channels, enabling agents to predict environmental dynamics, estimate states from partial observations, and share critical information through bidirectional message exchange with contrastive learning for message alignment. Using a two-agent trajectory drawing task, we demonstrate that our communication-based approach outperforms non-communicative models when agents have divergent perceptual capabilities, achieving the second-best coordination after centralized models. Importantly, our decentralized approach with constraints preventing direct access to other agents' internal states facilitates the emergence of more meaningful symbol systems that accurately reflect environmental states. These findings demonstrate the effectiveness of decentralized communication for supporting coordination while developing shared representations of the environment.",
    "summary": "arXiv:2504.03353v2 Announce Type: replace-cross Abstract: We propose a fully decentralized multi-agent world model that enables both symbol emergence for communication and coordinated behavior through temporal extension of collective predictive coding. Unlike previous research that focuses on either communication or coordination separately, our approach achieves both simultaneously. Our method integrates world models with communication channels, enabling agents to predict environmental dynamics, estimate states from partial observations, and share critical information through bidirectional message exchange with contrastive learning for message alignment. Using a two-agent trajectory drawing task, we demonstrate that our communication-based approach outperforms non-communicative models when agents have divergent perceptual capabilities, achieving the second-best coordination after centralized models. Importantly, our decentralized approach with constraints preventing direct access to other agents' internal states facilitates the emergence of more meaningful symbol systems that accurately reflect environmental states. These findings demonstrate the effectiveness of decentralized communication for supporting coordination while developing shared representations of the environment.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.03353",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Cost-effective Instruction Learning for Pathology Vision and Language Analysis",
    "description": "arXiv:2407.17734v2 Announce Type: replace Abstract: The advent of vision-language models fosters the interactive conversations between AI-enabled models and humans. Yet applying these models into clinics must deal with daunting challenges around large-scale training data, financial, and computational resources. Here we propose a cost-effective instruction learning framework for conversational pathology named as CLOVER. CLOVER only trains a lightweight module and uses instruction tuning while freezing the parameters of the large language model. Instead of using costly GPT-4, we propose well-designed prompts on GPT-3.5 for building generation-based instructions, emphasizing the utility of pathological knowledge derived from the Internet source. To augment the use of instructions, we construct a high-quality set of template-based instructions in the context of digital pathology. From two benchmark datasets, our findings reveal the strength of hybrid-form instructions in the visual question-answer in pathology. Extensive results show the cost-effectiveness of CLOVER in answering both open-ended and closed-ended questions, where CLOVER outperforms strong baselines that possess 37 times more training parameters and use instruction data generated from GPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot learning in the external clinical dataset. These findings demonstrate that cost-effective modeling of CLOVER could accelerate the adoption of rapid conversational applications in the landscape of digital pathology.",
    "summary": "arXiv:2407.17734v2 Announce Type: replace Abstract: The advent of vision-language models fosters the interactive conversations between AI-enabled models and humans. Yet applying these models into clinics must deal with daunting challenges around large-scale training data, financial, and computational resources. Here we propose a cost-effective instruction learning framework for conversational pathology named as CLOVER. CLOVER only trains a lightweight module and uses instruction tuning while freezing the parameters of the large language model. Instead of using costly GPT-4, we propose well-designed prompts on GPT-3.5 for building generation-based instructions, emphasizing the utility of pathological knowledge derived from the Internet source. To augment the use of instructions, we construct a high-quality set of template-based instructions in the context of digital pathology. From two benchmark datasets, our findings reveal the strength of hybrid-form instructions in the visual question-answer in pathology. Extensive results show the cost-effectiveness of CLOVER in answering both open-ended and closed-ended questions, where CLOVER outperforms strong baselines that possess 37 times more training parameters and use instruction data generated from GPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot learning in the external clinical dataset. These findings demonstrate that cost-effective modeling of CLOVER could accelerate the adoption of rapid conversational applications in the landscape of digital pathology.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.17734",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLMs in Disease Diagnosis: A Comparative Study of DeepSeek-R1 and O3 Mini Across Chronic Health Conditions",
    "description": "arXiv:2503.10486v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are revolutionizing medical diagnostics by enhancing both disease classification and clinical decision-making. In this study, we evaluate the performance of two LLM- based diagnostic tools, DeepSeek R1 and O3 Mini, using a structured dataset of symptoms and diagnoses. We assessed their predictive accuracy at both the disease and category levels, as well as the reliability of their confidence scores. DeepSeek R1 achieved a disease-level accuracy of 76% and an overall accuracy of 82%, outperforming O3 Mini, which attained 72% and 75% respectively. Notably, DeepSeek R1 demonstrated exceptional performance in Mental Health, Neurological Disorders, and Oncology, where it reached 100% accuracy, while O3 Mini excelled in Autoimmune Disease classification with 100% accuracy. Both models, however, struggled with Respiratory Disease classification, recording accuracies of only 40% for DeepSeek R1 and 20% for O3 Mini. Additionally, the analysis of confidence scores revealed that DeepSeek R1 provided high-confidence predictions in 92% of cases, compared to 68% for O3 Mini. Ethical considerations regarding bias, model interpretability, and data privacy are also discussed to ensure the responsible integration of LLMs into clinical practice. Overall, our findings offer valuable insights into the strengths and limitations of LLM-based diagnostic systems and provide a roadmap for future enhancements in AI-driven healthcare.",
    "summary": "arXiv:2503.10486v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are revolutionizing medical diagnostics by enhancing both disease classification and clinical decision-making. In this study, we evaluate the performance of two LLM- based diagnostic tools, DeepSeek R1 and O3 Mini, using a structured dataset of symptoms and diagnoses. We assessed their predictive accuracy at both the disease and category levels, as well as the reliability of their confidence scores. DeepSeek R1 achieved a disease-level accuracy of 76% and an overall accuracy of 82%, outperforming O3 Mini, which attained 72% and 75% respectively. Notably, DeepSeek R1 demonstrated exceptional performance in Mental Health, Neurological Disorders, and Oncology, where it reached 100% accuracy, while O3 Mini excelled in Autoimmune Disease classification with 100% accuracy. Both models, however, struggled with Respiratory Disease classification, recording accuracies of only 40% for DeepSeek R1 and 20% for O3 Mini. Additionally, the analysis of confidence scores revealed that DeepSeek R1 provided high-confidence predictions in 92% of cases, compared to 68% for O3 Mini. Ethical considerations regarding bias, model interpretability, and data privacy are also discussed to ensure the responsible integration of LLMs into clinical practice. Overall, our findings offer valuable insights into the strengths and limitations of LLM-based diagnostic systems and provide a roadmap for future enhancements in AI-driven healthcare.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.10486",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Creating an AI-powered Magic Studio",
    "description": "Canva is a visual communication platform, enjoyed by more than 175 million people monthly to make presentations, videos, documents, websites, social media graphics and more. A majority of the world‚Äôs knowledge workers lack design training, but Canva‚Äôs combination of an easy-to-use interface, vast libraries, and time-saving tools allows anyone to create visually compelling content.",
    "summary": "Canva is a visual communication platform, enjoyed by more than 175 million people monthly to make presentations, videos, documents, websites, social media graphics and more. A majority of the world‚Äôs knowledge workers lack design training, but Canva‚Äôs combination of an easy-to-use interface, vast libraries, and time-saving tools allows anyone to create visually compelling content.",
    "pubDate": "Thu, 16 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/canva",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Why Uncertainty Calibration Matters for Reliable Perturbation-based Explanations",
    "description": "arXiv:2506.19630v1 Announce Type: cross Abstract: Perturbation-based explanations are widely utilized to enhance the transparency of modern machine-learning models. However, their reliability is often compromised by the unknown model behavior under the specific perturbations used. This paper investigates the relationship between uncertainty calibration - the alignment of model confidence with actual accuracy - and perturbation-based explanations. We show that models frequently produce unreliable probability estimates when subjected to explainability-specific perturbations and theoretically prove that this directly undermines explanation quality. To address this, we introduce ReCalX, a novel approach to recalibrate models for improved perturbation-based explanations while preserving their original predictions. Experiments on popular computer vision models demonstrate that our calibration strategy produces explanations that are more aligned with human perception and actual object locations.",
    "summary": "arXiv:2506.19630v1 Announce Type: cross Abstract: Perturbation-based explanations are widely utilized to enhance the transparency of modern machine-learning models. However, their reliability is often compromised by the unknown model behavior under the specific perturbations used. This paper investigates the relationship between uncertainty calibration - the alignment of model confidence with actual accuracy - and perturbation-based explanations. We show that models frequently produce unreliable probability estimates when subjected to explainability-specific perturbations and theoretically prove that this directly undermines explanation quality. To address this, we introduce ReCalX, a novel approach to recalibrate models for improved perturbation-based explanations while preserving their original predictions. Experiments on popular computer vision models demonstrate that our calibration strategy produces explanations that are more aligned with human perception and actual object locations.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19630",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Incentivizing High-quality Participation From Federated Learning Agents",
    "description": "arXiv:2506.16731v1 Announce Type: new Abstract: Federated learning (FL) provides a promising paradigm for facilitating collaboration between multiple clients that jointly learn a global model without directly sharing their local data. However, existing research suffers from two caveats: 1) From the perspective of agents, voluntary and unselfish participation is often assumed. But self-interested agents may opt out of the system or provide low-quality contributions without proper incentives; 2) From the mechanism designer's perspective, the aggregated models can be unsatisfactory as the existing game-theoretical federated learning approach for data collection ignores the potential heterogeneous effort caused by contributed data. To alleviate above challenges, we propose an incentive-aware framework for agent participation that considers data heterogeneity to accelerate the convergence process. Specifically, we first introduce the notion of Wasserstein distance to explicitly illustrate the heterogeneous effort and reformulate the existing upper bound of convergence. To induce truthful reporting from agents, we analyze and measure the generalization error gap of any two agents by leveraging the peer prediction mechanism to develop score functions. We further present a two-stage Stackelberg game model that formalizes the process and examines the existence of equilibrium. Extensive experiments on real-world datasets demonstrate the effectiveness of our proposed mechanism.",
    "summary": "arXiv:2506.16731v1 Announce Type: new Abstract: Federated learning (FL) provides a promising paradigm for facilitating collaboration between multiple clients that jointly learn a global model without directly sharing their local data. However, existing research suffers from two caveats: 1) From the perspective of agents, voluntary and unselfish participation is often assumed. But self-interested agents may opt out of the system or provide low-quality contributions without proper incentives; 2) From the mechanism designer's perspective, the aggregated models can be unsatisfactory as the existing game-theoretical federated learning approach for data collection ignores the potential heterogeneous effort caused by contributed data. To alleviate above challenges, we propose an incentive-aware framework for agent participation that considers data heterogeneity to accelerate the convergence process. Specifically, we first introduce the notion of Wasserstein distance to explicitly illustrate the heterogeneous effort and reformulate the existing upper bound of convergence. To induce truthful reporting from agents, we analyze and measure the generalization error gap of any two agents by leveraging the peer prediction mechanism to develop score functions. We further present a two-stage Stackelberg game model that formalizes the process and examines the existence of equilibrium. Extensive experiments on real-world datasets demonstrate the effectiveness of our proposed mechanism.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16731",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Generative AI for Software Architecture. Applications, Challenges, and Future Directions",
    "description": "arXiv:2503.13310v2 Announce Type: replace-cross Abstract: Context: Generative Artificial Intelligence (GenAI) is transforming much of software development, yet its application in software architecture is still in its infancy, and no prior study has systematically addressed the topic. Aim: We aim to systematically synthesize the use, rationale, contexts, usability, and future challenges of GenAI in software architecture. Method: We performed a multivocal literature review (MLR), analyzing peer-reviewed and gray literature, identifying current practices, models, adoption contexts, and reported challenges, extracting themes via open coding. Results: Our review identified significant adoption of GenAI for architectural decision support and architectural reconstruction. OpenAI GPT models are predominantly applied, and there is consistent use of techniques such as few-shot prompting and retrieved-augmented generation (RAG). GenAI has been applied mostly to initial stages of the Software Development Life Cycle (SDLC), such as Requirements-to-Architecture and Architecture-to-Code. Monolithic and microservice architectures were the dominant targets. However, rigorous testing of GenAI outputs was typically missing from the studies. Among the most frequent challenges are model precision, hallucinations, ethical aspects, privacy issues, lack of architecture-specific datasets, and the absence of sound evaluation frameworks. Conclusions: GenAI shows significant potential in software design, but several challenges remain on its path to greater adoption. Research efforts should target designing general evaluation methodologies, handling ethics and precision, increasing transparency and explainability, and promoting architecture-specific datasets and benchmarks to bridge the gap between theoretical possibilities and practical use.",
    "summary": "arXiv:2503.13310v2 Announce Type: replace-cross Abstract: Context: Generative Artificial Intelligence (GenAI) is transforming much of software development, yet its application in software architecture is still in its infancy, and no prior study has systematically addressed the topic. Aim: We aim to systematically synthesize the use, rationale, contexts, usability, and future challenges of GenAI in software architecture. Method: We performed a multivocal literature review (MLR), analyzing peer-reviewed and gray literature, identifying current practices, models, adoption contexts, and reported challenges, extracting themes via open coding. Results: Our review identified significant adoption of GenAI for architectural decision support and architectural reconstruction. OpenAI GPT models are predominantly applied, and there is consistent use of techniques such as few-shot prompting and retrieved-augmented generation (RAG). GenAI has been applied mostly to initial stages of the Software Development Life Cycle (SDLC), such as Requirements-to-Architecture and Architecture-to-Code. Monolithic and microservice architectures were the dominant targets. However, rigorous testing of GenAI outputs was typically missing from the studies. Among the most frequent challenges are model precision, hallucinations, ethical aspects, privacy issues, lack of architecture-specific datasets, and the absence of sound evaluation frameworks. Conclusions: GenAI shows significant potential in software design, but several challenges remain on its path to greater adoption. Research efforts should target designing general evaluation methodologies, handling ethics and precision, increasing transparency and explainability, and promoting architecture-specific datasets and benchmarks to bridge the gap between theoretical possibilities and practical use.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.13310",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google for Nonprofits will expand to 100+ new countries and launch 10+ new no-cost AI features",
    "description": "Collage on a white background showing people in multiple different situations including two people in suits sitting on the back of an ambulance, and an adult and child using a laptop together",
    "summary": "Collage on a white background showing people in multiple different situations including two people in suits sitting on the back of an ambulance, and an adult and child using a laptop together",
    "pubDate": "Wed, 11 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/google-org/google-nonprofits-updates-june-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GoogleforNonProfit_SS.width-1300.png"
  },
  {
    "title": "OpenAI‚Äôs technology explained",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-technology-explained",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Featherless AI on Hugging Face Inference Providers üî•",
    "description": "",
    "summary": "Featherless AI on Hugging Face Inference Providers üî• We're thrilled to share that Featherless AI is ...",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-featherless",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/welcome-featherless.jpg"
  },
  {
    "title": "Formal Control for Uncertain Systems via Contract-Based Probabilistic Surrogates (Extended Version)",
    "description": "arXiv:2506.16971v1 Announce Type: cross Abstract: The requirement for identifying accurate system representations has not only been a challenge to fulfill, but it has compromised the scalability of formal methods, as the resulting models are often too complex for effective decision making with formal correctness and performance guarantees. Focusing on probabilistic simulation relations and surrogate models of stochastic systems, we propose an approach that significantly enhances the scalability and practical applicability of such simulation relations by eliminating the need to compute error bounds directly. As a result, we provide an abstraction-based technique that scales effectively to higher dimensions while addressing complex nonlinear agent-environment interactions with infinite-horizon temporal logic guarantees amidst uncertainty. Our approach trades scalability for conservatism favorably, as demonstrated on a complex high-dimensional vehicle intersection case study.",
    "summary": "arXiv:2506.16971v1 Announce Type: cross Abstract: The requirement for identifying accurate system representations has not only been a challenge to fulfill, but it has compromised the scalability of formal methods, as the resulting models are often too complex for effective decision making with formal correctness and performance guarantees. Focusing on probabilistic simulation relations and surrogate models of stochastic systems, we propose an approach that significantly enhances the scalability and practical applicability of such simulation relations by eliminating the need to compute error bounds directly. As a result, we provide an abstraction-based technique that scales effectively to higher dimensions while addressing complex nonlinear agent-environment interactions with infinite-horizon temporal logic guarantees amidst uncertainty. Our approach trades scalability for conservatism favorably, as demonstrated on a complex high-dimensional vehicle intersection case study.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16971",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DeltaSpace: A Semantic-aligned Feature Space for Flexible Text-guided Image Editing",
    "description": "arXiv:2310.08785v2 Announce Type: replace-cross Abstract: Text-guided image editing faces significant challenges when considering training and inference flexibility. Much literature collects large amounts of annotated image-text pairs to train text-conditioned generative models from scratch, which is expensive and not efficient. After that, some approaches that leverage pre-trained vision-language models have been proposed to avoid data collection, but they are limited by either per text-prompt optimization or inference-time hyper-parameters tuning. To address these issues, we investigate and identify a specific space, referred to as CLIP DeltaSpace, where the CLIP visual feature difference of two images is semantically aligned with the CLIP textual feature difference of their corresponding text descriptions. Based on DeltaSpace, we propose a novel framework called DeltaEdit, which maps the CLIP visual feature differences to the latent space directions of a generative model during the training phase, and predicts the latent space directions from the CLIP textual feature differences during the inference phase. And this design endows DeltaEdit with two advantages: (1) text-free training; (2) generalization to various text prompts for zero-shot inference. Extensive experiments validate the effectiveness and versatility of DeltaEdit with different generative models, including both the GAN model and the diffusion model, in achieving flexible text-guided image editing. Code is available at https://github.com/Yueming6568/DeltaEdit.",
    "summary": "arXiv:2310.08785v2 Announce Type: replace-cross Abstract: Text-guided image editing faces significant challenges when considering training and inference flexibility. Much literature collects large amounts of annotated image-text pairs to train text-conditioned generative models from scratch, which is expensive and not efficient. After that, some approaches that leverage pre-trained vision-language models have been proposed to avoid data collection, but they are limited by either per text-prompt optimization or inference-time hyper-parameters tuning. To address these issues, we investigate and identify a specific space, referred to as CLIP DeltaSpace, where the CLIP visual feature difference of two images is semantically aligned with the CLIP textual feature difference of their corresponding text descriptions. Based on DeltaSpace, we propose a novel framework called DeltaEdit, which maps the CLIP visual feature differences to the latent space directions of a generative model during the training phase, and predicts the latent space directions from the CLIP textual feature differences during the inference phase. And this design endows DeltaEdit with two advantages: (1) text-free training; (2) generalization to various text prompts for zero-shot inference. Extensive experiments validate the effectiveness and versatility of DeltaEdit with different generative models, including both the GAN model and the diffusion model, in achieving flexible text-guided image editing. Code is available at https://github.com/Yueming6568/DeltaEdit.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2310.08785",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "quanto: a pytorch quantization toolkit",
    "description": "",
    "summary": "Quanto: a PyTorch quantization backend for Optimum Quantization is a technique to reduce the computa...",
    "pubDate": "Mon, 18 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/quanto-introduction",
    "thumbnail": "https://huggingface.co/blog/assets/169_quanto_intro/thumbnail.png"
  },
  {
    "title": "Assessing Tenstorrent's RISC-V MatMul Acceleration Capabilities",
    "description": "arXiv:2505.06085v3 Announce Type: replace-cross Abstract: The increasing demand for generative AI as Large Language Models (LLMs) services has driven the need for specialized hardware architectures that optimize computational efficiency and energy consumption. This paper evaluates the performance of the Tenstorrent Grayskull e75 RISC-V accelerator for basic linear algebra kernels at reduced numerical precision, a fundamental operation in LLM computations. We present a detailed characterization of Grayskull's execution model, gridsize, matrix dimensions, data formats, and numerical precision impact computational efficiency. Furthermore, we compare Grayskull's performance against state-of-the-art architectures with tensor acceleration, including Intel Sapphire Rapids processors and two NVIDIA GPUs (V100 and A100). Whilst NVIDIA GPUs dominate raw performance, Grayskull demonstrates a competitive trade-off between power consumption and computational throughput, reaching a peak of 1.55 TFLOPs/Watt with BF16.",
    "summary": "arXiv:2505.06085v3 Announce Type: replace-cross Abstract: The increasing demand for generative AI as Large Language Models (LLMs) services has driven the need for specialized hardware architectures that optimize computational efficiency and energy consumption. This paper evaluates the performance of the Tenstorrent Grayskull e75 RISC-V accelerator for basic linear algebra kernels at reduced numerical precision, a fundamental operation in LLM computations. We present a detailed characterization of Grayskull's execution model, gridsize, matrix dimensions, data formats, and numerical precision impact computational efficiency. Furthermore, we compare Grayskull's performance against state-of-the-art architectures with tensor acceleration, including Intel Sapphire Rapids processors and two NVIDIA GPUs (V100 and A100). Whilst NVIDIA GPUs dominate raw performance, Grayskull demonstrates a competitive trade-off between power consumption and computational throughput, reaching a peak of 1.55 TFLOPs/Watt with BF16.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.06085",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Making education data accessible",
    "description": "Zelma uses GPT-4 to make education data accessible.",
    "summary": "Zelma uses GPT-4 to make education data accessible.",
    "pubDate": "Thu, 28 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zelma",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI and compute",
    "description": "We‚Äôre releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore‚Äôs Law had a 2-year doubling period)[^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it‚Äôs worth preparing for the implications of systems far outside today‚Äôs capabilities.",
    "summary": "We‚Äôre releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore‚Äôs Law had a 2-year doubling period)[^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it‚Äôs worth preparing for the implications of systems far outside today‚Äôs capabilities.",
    "pubDate": "Wed, 16 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-and-compute",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Storage Regions on the HF Hub",
    "description": "",
    "summary": "Introducing Storage Regions on the Hub As part of our Enterprise Hub plan, we recently released supp...",
    "pubDate": "Fri, 03 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/regions",
    "thumbnail": "https://huggingface.co/blog/assets/172_regions/thumbnail.png"
  },
  {
    "title": "Better exploration with parameter noise",
    "description": "We‚Äôve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts performance. This exploration method is simple to implement and very rarely decreases performance, so it‚Äôs worth trying on any problem.",
    "summary": "We‚Äôve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts performance. This exploration method is simple to implement and very rarely decreases performance, so it‚Äôs worth trying on any problem.",
    "pubDate": "Thu, 27 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/better-exploration-with-parameter-noise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome Gemma - Google's new open LLM",
    "description": "",
    "summary": "Welcome Gemma - Google‚Äôs new open LLM An update to the Gemma models was released two months after th...",
    "pubDate": "Wed, 21 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma",
    "thumbnail": "https://huggingface.co/blog/assets/gemma/thumbnail.jpg"
  },
  {
    "title": "Cross-regularization: Adaptive Model Complexity through Validation Gradients",
    "description": "arXiv:2506.19755v1 Announce Type: cross Abstract: Model regularization requires extensive manual tuning to balance complexity against overfitting. Cross-regularization resolves this tradeoff by directly adapting regularization parameters through validation gradients during training. The method splits parameter optimization - training data guides feature learning while validation data shapes complexity controls - converging provably to cross-validation optima. When implemented through noise injection in neural networks, this approach reveals striking patterns: unexpectedly high noise tolerance and architecture-specific regularization that emerges organically during training. Beyond complexity control, the framework integrates seamlessly with data augmentation, uncertainty calibration and growing datasets while maintaining single-run efficiency through a simple gradient-based approach.",
    "summary": "arXiv:2506.19755v1 Announce Type: cross Abstract: Model regularization requires extensive manual tuning to balance complexity against overfitting. Cross-regularization resolves this tradeoff by directly adapting regularization parameters through validation gradients during training. The method splits parameter optimization - training data guides feature learning while validation data shapes complexity controls - converging provably to cross-validation optima. When implemented through noise injection in neural networks, this approach reveals striking patterns: unexpectedly high noise tolerance and architecture-specific regularization that emerges organically during training. Beyond complexity control, the framework integrates seamlessly with data augmentation, uncertainty calibration and growing datasets while maintaining single-run efficiency through a simple gradient-based approach.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19755",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing ChatGPT Plus",
    "description": "We‚Äôre launching a pilot subscription plan for ChatGPT, a conversational AI that can chat with you, answer follow-up questions, and challenge incorrect¬†assumptions.",
    "summary": "We‚Äôre launching a pilot subscription plan for ChatGPT, a conversational AI that can chat with you, answer follow-up questions, and challenge incorrect¬†assumptions.",
    "pubDate": "Wed, 01 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Inference for PROs",
    "description": "",
    "summary": "Inference for PROs Today, we're introducing Inference for PRO users - a community offering that give...",
    "pubDate": "Fri, 22 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-pro",
    "thumbnail": "https://huggingface.co/blog/assets/inference_pro/thumbnail.png"
  },
  {
    "title": "Photonic processor could streamline 6G wireless signal processing",
    "description": "By performing deep learning at the speed of light, this chip could give edge devices new capabilities for real-time data analysis.",
    "summary": "By performing deep learning at the speed of light, this chip could give edge devices new capabilities for real-time data analysis.",
    "pubDate": "Wed, 11 Jun 2025 14:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/photonic-processor-could-streamline-6g-wireless-signal-processing-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Photonic-Process-01-press.jpg"
  },
  {
    "title": "Introducing OpenAI Dublin",
    "description": "We‚Äôre growing our presence in Europe with an office in Dublin, Ireland.",
    "summary": "We‚Äôre growing our presence in Europe with an office in Dublin, Ireland.",
    "pubDate": "Wed, 13 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-dublin",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Prover-Verifier Games improve legibility of language model outputs",
    "description": "desc",
    "summary": "desc",
    "pubDate": "Wed, 17 Jul 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/prover-verifier-games-improve-legibility",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Policy Gradient with PyTorch",
    "description": "",
    "summary": "Policy Gradient with PyTorch Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 5, of the‚ö†Ô∏è ...",
    "pubDate": "Thu, 30 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-pg",
    "thumbnail": "https://huggingface.co/blog/assets/85_policy_gradient/thumbnail.gif"
  },
  {
    "title": "BIDA: A Bi-level Interaction Decision-making Algorithm for Autonomous Vehicles in Dynamic Traffic Scenarios",
    "description": "arXiv:2506.16546v1 Announce Type: cross Abstract: In complex real-world traffic environments, autonomous vehicles (AVs) need to interact with other traffic participants while making real-time and safety-critical decisions accordingly. The unpredictability of human behaviors poses significant challenges, particularly in dynamic scenarios, such as multi-lane highways and unsignalized T-intersections. To address this gap, we design a bi-level interaction decision-making algorithm (BIDA) that integrates interactive Monte Carlo tree search (MCTS) with deep reinforcement learning (DRL), aiming to enhance interaction rationality, efficiency and safety of AVs in dynamic key traffic scenarios. Specifically, we adopt three types of DRL algorithms to construct a reliable value network and policy network, which guide the online deduction process of interactive MCTS by assisting in value update and node selection. Then, a dynamic trajectory planner and a trajectory tracking controller are designed and implemented in CARLA to ensure smooth execution of planned maneuvers. Experimental evaluations demonstrate that our BIDA not only enhances interactive deduction and reduces computational costs, but also outperforms other latest benchmarks, which exhibits superior safety, efficiency and interaction rationality under varying traffic conditions.",
    "summary": "arXiv:2506.16546v1 Announce Type: cross Abstract: In complex real-world traffic environments, autonomous vehicles (AVs) need to interact with other traffic participants while making real-time and safety-critical decisions accordingly. The unpredictability of human behaviors poses significant challenges, particularly in dynamic scenarios, such as multi-lane highways and unsignalized T-intersections. To address this gap, we design a bi-level interaction decision-making algorithm (BIDA) that integrates interactive Monte Carlo tree search (MCTS) with deep reinforcement learning (DRL), aiming to enhance interaction rationality, efficiency and safety of AVs in dynamic key traffic scenarios. Specifically, we adopt three types of DRL algorithms to construct a reliable value network and policy network, which guide the online deduction process of interactive MCTS by assisting in value update and node selection. Then, a dynamic trajectory planner and a trajectory tracking controller are designed and implemented in CARLA to ensure smooth execution of planned maneuvers. Experimental evaluations demonstrate that our BIDA not only enhances interactive deduction and reduces computational costs, but also outperforms other latest benchmarks, which exhibits superior safety, efficiency and interaction rationality under varying traffic conditions.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16546",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Open FinLLM Leaderboard",
    "description": "",
    "summary": "Introducing the Open FinLLM Leaderboard Finding the best LLM models for finance use cases The growin...",
    "pubDate": "Fri, 04 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-finbench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_finbench.png"
  },
  {
    "title": "Refining music sample identification with a self-supervised graph neural network",
    "description": "arXiv:2506.14684v2 Announce Type: replace-cross Abstract: Automatic sample identification (ASID), the detection and identification of portions of audio recordings that have been reused in new musical works, is an essential but challenging task in the field of audio query-based retrieval. While a related task, audio fingerprinting, has made significant progress in accurately retrieving musical content under 'real world' (noisy, reverberant) conditions, ASID systems struggle to identify samples that have undergone musical modifications. Thus, a system robust to common music production transformations such as time-stretching, pitch-shifting, effects processing, and underlying or overlaying music is an important open challenge. In this work, we propose a lightweight and scalable encoding architecture employing a Graph Neural Network within a contrastive learning framework. Our model uses only 9% of the trainable parameters compared to the current state-of-the-art system while achieving comparable performance, reaching a mean average precision (mAP) of 44.2%. To enhance retrieval quality, we introduce a two-stage approach consisting of an initial coarse similarity search for candidate selection, followed by a cross-attention classifier that rejects irrelevant matches and refines the ranking of retrieved candidates - an essential capability absent in prior models. In addition, because queries in real-world applications are often short in duration, we benchmark our system for short queries using new fine-grained annotations for the Sample100 dataset, which we publish as part of this work.",
    "summary": "arXiv:2506.14684v2 Announce Type: replace-cross Abstract: Automatic sample identification (ASID), the detection and identification of portions of audio recordings that have been reused in new musical works, is an essential but challenging task in the field of audio query-based retrieval. While a related task, audio fingerprinting, has made significant progress in accurately retrieving musical content under 'real world' (noisy, reverberant) conditions, ASID systems struggle to identify samples that have undergone musical modifications. Thus, a system robust to common music production transformations such as time-stretching, pitch-shifting, effects processing, and underlying or overlaying music is an important open challenge. In this work, we propose a lightweight and scalable encoding architecture employing a Graph Neural Network within a contrastive learning framework. Our model uses only 9% of the trainable parameters compared to the current state-of-the-art system while achieving comparable performance, reaching a mean average precision (mAP) of 44.2%. To enhance retrieval quality, we introduce a two-stage approach consisting of an initial coarse similarity search for candidate selection, followed by a cross-attention classifier that rejects irrelevant matches and refines the ranking of retrieved candidates - an essential capability absent in prior models. In addition, because queries in real-world applications are often short in duration, we benchmark our system for short queries using new fine-grained annotations for the Sample100 dataset, which we publish as part of this work.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14684",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CORE-KG: An LLM-Driven Knowledge Graph Construction Framework for Human Smuggling Networks",
    "description": "arXiv:2506.21607v1 Announce Type: cross Abstract: Human smuggling networks are increasingly adaptive and difficult to analyze. Legal case documents offer valuable insights but are unstructured, lexically dense, and filled with ambiguous or shifting references-posing challenges for automated knowledge graph (KG) construction. Existing KG methods often rely on static templates and lack coreference resolution, while recent LLM-based approaches frequently produce noisy, fragmented graphs due to hallucinations, and duplicate nodes caused by a lack of guided extraction. We propose CORE-KG, a modular framework for building interpretable KGs from legal texts. It uses a two-step pipeline: (1) type-aware coreference resolution via sequential, structured LLM prompts, and (2) entity and relationship extraction using domain-guided instructions, built on an adapted GraphRAG framework. CORE-KG reduces node duplication by 33.28%, and legal noise by 38.37% compared to a GraphRAG-based baseline-resulting in cleaner and more coherent graph structures. These improvements make CORE-KG a strong foundation for analyzing complex criminal networks.",
    "summary": "arXiv:2506.21607v1 Announce Type: cross Abstract: Human smuggling networks are increasingly adaptive and difficult to analyze. Legal case documents offer valuable insights but are unstructured, lexically dense, and filled with ambiguous or shifting references-posing challenges for automated knowledge graph (KG) construction. Existing KG methods often rely on static templates and lack coreference resolution, while recent LLM-based approaches frequently produce noisy, fragmented graphs due to hallucinations, and duplicate nodes caused by a lack of guided extraction. We propose CORE-KG, a modular framework for building interpretable KGs from legal texts. It uses a two-step pipeline: (1) type-aware coreference resolution via sequential, structured LLM prompts, and (2) entity and relationship extraction using domain-guided instructions, built on an adapted GraphRAG framework. CORE-KG reduces node duplication by 33.28%, and legal noise by 38.37% compared to a GraphRAG-based baseline-resulting in cleaner and more coherent graph structures. These improvements make CORE-KG a strong foundation for analyzing complex criminal networks.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21607",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model",
    "description": "arXiv:2506.21976v1 Announce Type: cross Abstract: The goal of traffic simulation is to augment a potentially limited amount of manually-driven miles that is available for testing and validation, with a much larger amount of simulated synthetic miles. The culmination of this vision would be a generative simulated city, where given a map of the city and an autonomous vehicle (AV) software stack, the simulator can seamlessly simulate the trip from point A to point B by populating the city around the AV and controlling all aspects of the scene, from animating the dynamic agents (e.g., vehicles, pedestrians) to controlling the traffic light states. We refer to this vision as CitySim, which requires an agglomeration of simulation technologies: scene generation to populate the initial scene, agent behavior modeling to animate the scene, occlusion reasoning, dynamic scene generation to seamlessly spawn and remove agents, and environment simulation for factors such as traffic lights. While some key technologies have been separately studied in various works, others such as dynamic scene generation and environment simulation have received less attention in the research community. We propose SceneDiffuser++, the first end-to-end generative world model trained on a single loss function capable of point A-to-B simulation on a city scale integrating all the requirements above. We demonstrate the city-scale traffic simulation capability of SceneDiffuser++ and study its superior realism under long simulation conditions. We evaluate the simulation quality on an augmented version of the Waymo Open Motion Dataset (WOMD) with larger map regions to support trip-level simulation.",
    "summary": "arXiv:2506.21976v1 Announce Type: cross Abstract: The goal of traffic simulation is to augment a potentially limited amount of manually-driven miles that is available for testing and validation, with a much larger amount of simulated synthetic miles. The culmination of this vision would be a generative simulated city, where given a map of the city and an autonomous vehicle (AV) software stack, the simulator can seamlessly simulate the trip from point A to point B by populating the city around the AV and controlling all aspects of the scene, from animating the dynamic agents (e.g., vehicles, pedestrians) to controlling the traffic light states. We refer to this vision as CitySim, which requires an agglomeration of simulation technologies: scene generation to populate the initial scene, agent behavior modeling to animate the scene, occlusion reasoning, dynamic scene generation to seamlessly spawn and remove agents, and environment simulation for factors such as traffic lights. While some key technologies have been separately studied in various works, others such as dynamic scene generation and environment simulation have received less attention in the research community. We propose SceneDiffuser++, the first end-to-end generative world model trained on a single loss function capable of point A-to-B simulation on a city scale integrating all the requirements above. We demonstrate the city-scale traffic simulation capability of SceneDiffuser++ and study its superior realism under long simulation conditions. We evaluate the simulation quality on an augmented version of the Waymo Open Motion Dataset (WOMD) with larger map regions to support trip-level simulation.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21976",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Open Medical-LLM Leaderboard: Benchmarking Large Language Models in Healthcare",
    "description": "",
    "summary": "The Open Medical-LLM Leaderboard: Benchmarking Large Language Models in Healthcare Over the years, L...",
    "pubDate": "Fri, 19 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-medicalllm",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_medicalllm.png"
  },
  {
    "title": "Using Machine Learning to Aid Survivors and Race through Time",
    "description": "",
    "summary": "Using Machine Learning to Aid Survivors and Race through Time On February 6, 2023, earthquakes measu...",
    "pubDate": "Fri, 03 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/using-ml-for-disasters",
    "thumbnail": "https://huggingface.co/blog/assets/using-ml-for-disasters/thumbnail.png"
  },
  {
    "title": "DALL¬∑E: Introducing outpainting",
    "description": "Extend creativity and tell a bigger story with DALL¬∑E images of any¬†size.",
    "summary": "Extend creativity and tell a bigger story with DALL¬∑E images of any¬†size.",
    "pubDate": "Wed, 31 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-introducing-outpainting",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Federated Learning using Hugging Face and Flower",
    "description": "",
    "summary": "Federated Learning using Hugging Face and Flower This tutorial will show how to leverage Hugging Fac...",
    "pubDate": "Mon, 27 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fl-with-flower",
    "thumbnail": "https://huggingface.co/blog/assets/fl-with-flower/thumbnail.png"
  },
  {
    "title": "Teacher‚Äìstudent curriculum learning",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 01 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teacher-student-curriculum-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Safety vs. AI Security: Demystifying the Distinction and Boundaries",
    "description": "arXiv:2506.18932v1 Announce Type: cross Abstract: Artificial Intelligence (AI) is rapidly being integrated into critical systems across various domains, from healthcare to autonomous vehicles. While its integration brings immense benefits, it also introduces significant risks, including those arising from AI misuse. Within the discourse on managing these risks, the terms 'AI Safety' and 'AI Security' are often used, sometimes interchangeably, resulting in conceptual confusion. This paper aims to demystify the distinction and delineate the precise research boundaries between AI Safety and AI Security. We provide rigorous definitions, outline their respective research focuses, and explore their interdependency, including how security breaches can precipitate safety failures and vice versa. Using clear analogies from message transmission and building construction, we illustrate these distinctions. Clarifying these boundaries is crucial for guiding precise research directions, fostering effective cross-disciplinary collaboration, enhancing policy effectiveness, and ultimately, promoting the deployment of trustworthy AI systems.",
    "summary": "arXiv:2506.18932v1 Announce Type: cross Abstract: Artificial Intelligence (AI) is rapidly being integrated into critical systems across various domains, from healthcare to autonomous vehicles. While its integration brings immense benefits, it also introduces significant risks, including those arising from AI misuse. Within the discourse on managing these risks, the terms 'AI Safety' and 'AI Security' are often used, sometimes interchangeably, resulting in conceptual confusion. This paper aims to demystify the distinction and delineate the precise research boundaries between AI Safety and AI Security. We provide rigorous definitions, outline their respective research focuses, and explore their interdependency, including how security breaches can precipitate safety failures and vice versa. Using clear analogies from message transmission and building construction, we illustrate these distinctions. Clarifying these boundaries is crucial for guiding precise research directions, fostering effective cross-disciplinary collaboration, enhancing policy effectiveness, and ultimately, promoting the deployment of trustworthy AI systems.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18932",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Visualize proteins on Hugging Face Spaces",
    "description": "",
    "summary": "Visualize proteins on Hugging Face Spaces In this post we will look at how we can visualize proteins...",
    "pubDate": "Wed, 24 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spaces_3dmoljs",
    "thumbnail": "https://huggingface.co/blog/assets/98_spaces_3dmoljs/thumbnail.png"
  },
  {
    "title": "Director of Machine Learning Insights [Part 2: SaaS Edition]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 2: SaaS Edition] If you or your team are interested in b...",
    "pubDate": "Fri, 13 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-2",
    "thumbnail": "https://huggingface.co/blog/assets/67_ml_director_insights/thumbnail.png"
  },
  {
    "title": "HuggingFace, IISc partner to supercharge model building on India's diverse languages",
    "description": "",
    "summary": "HuggingFace, IISc partner to supercharge model building on India's diverse languages The Indian Inst...",
    "pubDate": "Thu, 27 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/iisc-huggingface-collab",
    "thumbnail": "https://huggingface.co/blog/assets/iisc-huggingface-collab/thumbnail.png"
  },
  {
    "title": "Language models can explain neurons in language models",
    "description": "We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to score those explanations. We release a dataset of these (imperfect) explanations and scores for every neuron in GPT-2.",
    "summary": "We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to score those explanations. We release a dataset of these (imperfect) explanations and scores for every neuron in GPT-2.",
    "pubDate": "Tue, 09 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-models-can-explain-neurons-in-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making AI models more trustworthy for high-stakes settings",
    "description": "A new method helps convey uncertainty more precisely, which could give researchers and medical clinicians better information to make decisions.",
    "summary": "A new method helps convey uncertainty more precisely, which could give researchers and medical clinicians better information to make decisions.",
    "pubDate": "Thu, 01 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/making-ai-models-more-trustworthy-high-stakes-settings-0501",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Conformal-Prediction-01.jpg"
  },
  {
    "title": "Performance Prediction for Large Systems via Text-to-Text Regression",
    "description": "arXiv:2506.21718v1 Announce Type: cross Abstract: In many industries, predicting metric outcomes of large systems is a fundamental problem, driven largely by traditional tabular regression. However, such methods struggle on complex systems data in the wild such as configuration files or system logs, where feature engineering is often infeasible. We propose text-to-text regression as a general, scalable alternative. For predicting resource efficiency on Borg, Google's massive compute cluster scheduling system, a 60M parameter encoder-decoder, trained from random initialization, achieves up to a near perfect 0.99 (0.9 average) rank correlation across the entire fleet, and 100x lower MSE than tabular approaches. The model also easily adapts to new tasks in only 500 few-shot examples and captures the densities of complex outcome distributions. Ablation studies highlight the importance of using encoders, increasing sequence length, and the model's inherent uncertainty quantification. These findings pave the way for universal simulators of real-world outcomes.",
    "summary": "arXiv:2506.21718v1 Announce Type: cross Abstract: In many industries, predicting metric outcomes of large systems is a fundamental problem, driven largely by traditional tabular regression. However, such methods struggle on complex systems data in the wild such as configuration files or system logs, where feature engineering is often infeasible. We propose text-to-text regression as a general, scalable alternative. For predicting resource efficiency on Borg, Google's massive compute cluster scheduling system, a 60M parameter encoder-decoder, trained from random initialization, achieves up to a near perfect 0.99 (0.9 average) rank correlation across the entire fleet, and 100x lower MSE than tabular approaches. The model also easily adapts to new tasks in only 500 few-shot examples and captures the densities of complex outcome distributions. Ablation studies highlight the importance of using encoders, increasing sequence length, and the model's inherent uncertainty quantification. These findings pave the way for universal simulators of real-world outcomes.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21718",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Deutschland",
    "description": "OpenAI announces the opening of its first office in Germany, based in Munich.",
    "summary": "OpenAI announces the opening of its first office in Germany, based in Munich.",
    "pubDate": "Thu, 22 May 2025 23:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-deutschland",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Towards an Introspective Dynamic Model of Globally Distributed Computing Infrastructures",
    "description": "arXiv:2506.19578v1 Announce Type: cross Abstract: Large-scale scientific collaborations like ATLAS, Belle II, CMS, DUNE, and others involve hundreds of research institutes and thousands of researchers spread across the globe. These experiments generate petabytes of data, with volumes soon expected to reach exabytes. Consequently, there is a growing need for computation, including structured data processing from raw data to consumer-ready derived data, extensive Monte Carlo simulation campaigns, and a wide range of end-user analysis. To manage these computational and storage demands, centralized workflow and data management systems are implemented. However, decisions regarding data placement and payload allocation are often made disjointly and via heuristic means. A significant obstacle in adopting more effective heuristic or AI-driven solutions is the absence of a quick and reliable introspective dynamic model to evaluate and refine alternative approaches. In this study, we aim to develop such an interactive system using real-world data. By examining job execution records from the PanDA workflow management system, we have pinpointed key performance indicators such as queuing time, error rate, and the extent of remote data access. The dataset includes five months of activity. Additionally, we are creating a generative AI model to simulate time series of payloads, which incorporate visible features like category, event count, and submitting group, as well as hidden features like the total computational load-derived from existing PanDA records and computing site capabilities. These hidden features, which are not visible to job allocators, whether heuristic or AI-driven, influence factors such as queuing times and data movement.",
    "summary": "arXiv:2506.19578v1 Announce Type: cross Abstract: Large-scale scientific collaborations like ATLAS, Belle II, CMS, DUNE, and others involve hundreds of research institutes and thousands of researchers spread across the globe. These experiments generate petabytes of data, with volumes soon expected to reach exabytes. Consequently, there is a growing need for computation, including structured data processing from raw data to consumer-ready derived data, extensive Monte Carlo simulation campaigns, and a wide range of end-user analysis. To manage these computational and storage demands, centralized workflow and data management systems are implemented. However, decisions regarding data placement and payload allocation are often made disjointly and via heuristic means. A significant obstacle in adopting more effective heuristic or AI-driven solutions is the absence of a quick and reliable introspective dynamic model to evaluate and refine alternative approaches. In this study, we aim to develop such an interactive system using real-world data. By examining job execution records from the PanDA workflow management system, we have pinpointed key performance indicators such as queuing time, error rate, and the extent of remote data access. The dataset includes five months of activity. Additionally, we are creating a generative AI model to simulate time series of payloads, which incorporate visible features like category, event count, and submitting group, as well as hidden features like the total computational load-derived from existing PanDA records and computing site capabilities. These hidden features, which are not visible to job allocators, whether heuristic or AI-driven, influence factors such as queuing times and data movement.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19578",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Single-shot thermometry of simulated Bose--Einstein condensates using artificial intelligence",
    "description": "arXiv:2506.16925v1 Announce Type: cross Abstract: Precise determination of thermodynamic parameters in ultracold Bose gases remains challenging due to the destructive nature of conventional measurement techniques and inherent experimental uncertainties. We demonstrate an artificial intelligence approach for rapid, non-destructive estimation of the chemical potential and temperature from single-shot, in situ imaged density profiles of finite-temperature Bose gases. Our convolutional neural network is trained exclusively on quasi-2D `pancake' condensates in harmonic trap configurations. It achieves parameter extraction within fractions of a second. The model also demonstrates zero-shot generalisation across both trap geometry and thermalisation dynamics, successfully estimating thermodynamic parameters for toroidally trapped condensates with errors of only a few nanokelvin despite no prior exposure to such geometries during training, and maintaining predictive accuracy during dynamic thermalisation processes after a relatively brief evolution without explicit training on non-equilibrium states. These results suggest that supervised learning can overcome traditional limitations in ultracold atom thermometry, with extension to broader geometric configurations, temperature ranges, and additional parameters potentially enabling comprehensive real-time analysis of quantum gas experiments. Such capabilities could significantly streamline experimental workflows whilst improving measurement precision across a range of quantum fluid systems.",
    "summary": "arXiv:2506.16925v1 Announce Type: cross Abstract: Precise determination of thermodynamic parameters in ultracold Bose gases remains challenging due to the destructive nature of conventional measurement techniques and inherent experimental uncertainties. We demonstrate an artificial intelligence approach for rapid, non-destructive estimation of the chemical potential and temperature from single-shot, in situ imaged density profiles of finite-temperature Bose gases. Our convolutional neural network is trained exclusively on quasi-2D `pancake' condensates in harmonic trap configurations. It achieves parameter extraction within fractions of a second. The model also demonstrates zero-shot generalisation across both trap geometry and thermalisation dynamics, successfully estimating thermodynamic parameters for toroidally trapped condensates with errors of only a few nanokelvin despite no prior exposure to such geometries during training, and maintaining predictive accuracy during dynamic thermalisation processes after a relatively brief evolution without explicit training on non-equilibrium states. These results suggest that supervised learning can overcome traditional limitations in ultracold atom thermometry, with extension to broader geometric configurations, temperature ranges, and additional parameters potentially enabling comprehensive real-time analysis of quantum gas experiments. Such capabilities could significantly streamline experimental workflows whilst improving measurement precision across a range of quantum fluid systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16925",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BreastDCEDL: Curating a Comprehensive DCE-MRI Dataset and developing a Transformer Implementation for Breast Cancer Treatment Response Prediction",
    "description": "arXiv:2506.12190v2 Announce Type: replace-cross Abstract: Breast cancer remains a leading cause of cancer-related mortality worldwide, making early detection and accurate treatment response monitoring critical priorities. We present BreastDCEDL, a curated, deep learning-ready dataset comprising pre-treatment 3D Dynamic Contrast-Enhanced MRI (DCE-MRI) scans from 2,070 breast cancer patients drawn from the I-SPY1, I-SPY2, and Duke cohorts, all sourced from The Cancer Imaging Archive. The raw DICOM imaging data were rigorously converted into standardized 3D NIfTI volumes with preserved signal integrity, accompanied by unified tumor annotations and harmonized clinical metadata including pathologic complete response (pCR), hormone receptor (HR), and HER2 status. Although DCE-MRI provides essential diagnostic information and deep learning offers tremendous potential for analyzing such complex data, progress has been limited by lack of accessible, public, multicenter datasets. BreastDCEDL addresses this gap by enabling development of advanced models, including state-of-the-art transformer architectures that require substantial training data. To demonstrate its capacity for robust modeling, we developed the first transformer-based model for breast DCE-MRI, leveraging Vision Transformer (ViT) architecture trained on RGB-fused images from three contrast phases (pre-contrast, early post-contrast, and late post-contrast). Our ViT model achieved state-of-the-art pCR prediction performance in HR+/HER2- patients (AUC 0.94, accuracy 0.93). BreastDCEDL includes predefined benchmark splits, offering a framework for reproducible research and enabling clinically meaningful modeling in breast cancer imaging.",
    "summary": "arXiv:2506.12190v2 Announce Type: replace-cross Abstract: Breast cancer remains a leading cause of cancer-related mortality worldwide, making early detection and accurate treatment response monitoring critical priorities. We present BreastDCEDL, a curated, deep learning-ready dataset comprising pre-treatment 3D Dynamic Contrast-Enhanced MRI (DCE-MRI) scans from 2,070 breast cancer patients drawn from the I-SPY1, I-SPY2, and Duke cohorts, all sourced from The Cancer Imaging Archive. The raw DICOM imaging data were rigorously converted into standardized 3D NIfTI volumes with preserved signal integrity, accompanied by unified tumor annotations and harmonized clinical metadata including pathologic complete response (pCR), hormone receptor (HR), and HER2 status. Although DCE-MRI provides essential diagnostic information and deep learning offers tremendous potential for analyzing such complex data, progress has been limited by lack of accessible, public, multicenter datasets. BreastDCEDL addresses this gap by enabling development of advanced models, including state-of-the-art transformer architectures that require substantial training data. To demonstrate its capacity for robust modeling, we developed the first transformer-based model for breast DCE-MRI, leveraging Vision Transformer (ViT) architecture trained on RGB-fused images from three contrast phases (pre-contrast, early post-contrast, and late post-contrast). Our ViT model achieved state-of-the-art pCR prediction performance in HR+/HER2- patients (AUC 0.94, accuracy 0.93). BreastDCEDL includes predefined benchmark splits, offering a framework for reproducible research and enabling clinically meaningful modeling in breast cancer imaging.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12190",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "We now support VLMs in smolagents!",
    "description": "",
    "summary": "We just gave sight to smolagents You hypocrite, first take the log out of your own eye, and then you...",
    "pubDate": "Fri, 24 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents-can-see",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents-can-see/thumbnail.png"
  },
  {
    "title": "Beyond Audio and Pose: A General-Purpose Framework for Video Synchronization",
    "description": "arXiv:2506.15937v1 Announce Type: cross Abstract: Video synchronization-aligning multiple video streams capturing the same event from different angles-is crucial for applications such as reality TV show production, sports analysis, surveillance, and autonomous systems. Prior work has heavily relied on audio cues or specific visual events, limiting applicability in diverse settings where such signals may be unreliable or absent. Additionally, existing benchmarks for video synchronization lack generality and reproducibility, restricting progress in the field. In this work, we introduce VideoSync, a video synchronization framework that operates independently of specific feature extraction methods, such as human pose estimation, enabling broader applicability across different content types. We evaluate our system on newly composed datasets covering single-human, multi-human, and non-human scenarios, providing both the methodology and code for dataset creation to establish reproducible benchmarks. Our analysis reveals biases in prior SOTA work, particularly in SeSyn-Net's preprocessing pipeline, leading to inflated performance claims. We correct these biases and propose a more rigorous evaluation framework, demonstrating that VideoSync outperforms existing approaches, including SeSyn-Net, under fair experimental conditions. Additionally, we explore various synchronization offset prediction methods, identifying a convolutional neural network (CNN)-based model as the most effective. Our findings advance video synchronization beyond domain-specific constraints, making it more generalizable and robust for real-world applications.",
    "summary": "arXiv:2506.15937v1 Announce Type: cross Abstract: Video synchronization-aligning multiple video streams capturing the same event from different angles-is crucial for applications such as reality TV show production, sports analysis, surveillance, and autonomous systems. Prior work has heavily relied on audio cues or specific visual events, limiting applicability in diverse settings where such signals may be unreliable or absent. Additionally, existing benchmarks for video synchronization lack generality and reproducibility, restricting progress in the field. In this work, we introduce VideoSync, a video synchronization framework that operates independently of specific feature extraction methods, such as human pose estimation, enabling broader applicability across different content types. We evaluate our system on newly composed datasets covering single-human, multi-human, and non-human scenarios, providing both the methodology and code for dataset creation to establish reproducible benchmarks. Our analysis reveals biases in prior SOTA work, particularly in SeSyn-Net's preprocessing pipeline, leading to inflated performance claims. We correct these biases and propose a more rigorous evaluation framework, demonstrating that VideoSync outperforms existing approaches, including SeSyn-Net, under fair experimental conditions. Additionally, we explore various synchronization offset prediction methods, identifying a convolutional neural network (CNN)-based model as the most effective. Our findings advance video synchronization beyond domain-specific constraints, making it more generalizable and robust for real-world applications.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15937",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evolution through large models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolution-through-large-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TruthfulQA: Measuring how models mimic human falsehoods",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/truthfulqa",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-tuning LLMs to 1.58bit: extreme quantization made easy",
    "description": "",
    "summary": "Fine-tuning LLMs to 1.58bit: extreme quantization made easy As Large Language Models (LLMs) grow in ...",
    "pubDate": "Wed, 18 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/1_58_llm_extreme_quantization",
    "thumbnail": "https://huggingface.co/blog/assets/1_58_llm_extreme_quantization/thumbnail.png"
  },
  {
    "title": "Transforming visual accessibility",
    "description": "Be My Eyes uses GPT-4 to transform visual accessibility.",
    "summary": "Be My Eyes uses GPT-4 to transform visual accessibility.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/be-my-eyes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Lowe‚Äôs puts project expertise into every hand",
    "description": "Lowe‚Äôs partnered with OpenAI to build Mylow and Mylow Companion, AI-powered tools that bring expert help to both customers and store associates‚Äîmaking complex home improvement projects easier to plan, navigate, and complete.",
    "summary": "Lowe‚Äôs partnered with OpenAI to build Mylow and Mylow Companion, AI-powered tools that bring expert help to both customers and store associates‚Äîmaking complex home improvement projects easier to plan, navigate, and complete.",
    "pubDate": "Wed, 07 May 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lowes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "StarCoder: A State-of-the-Art LLM for Code",
    "description": "",
    "summary": "StarCoder: A State-of-the-Art LLM for Code Introducing StarCoder StarCoder and StarCoderBase are Lar...",
    "pubDate": "Thu, 04 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starcoder",
    "thumbnail": "https://huggingface.co/blog/assets/141_starcoder/starcoder_thumbnail.png"
  },
  {
    "title": "The ethics of advanced AI assistants",
    "description": "Exploring the promise and risks of a future with more capable AI",
    "summary": "Exploring the promise and risks of a future with more capable AI",
    "pubDate": "Fri, 19 Apr 2024 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/the-ethics-of-advanced-ai-assistants/",
    "thumbnail": "https://lh3.googleusercontent.com/28MrwSZMny-Gf_FVYJS0z3JbnfLXzRLNAF2BA0YQ7rbcrZWdNNwddfFsWVh_n7C31N8oXBmWexFbyce4jzaX3FSNt3EXG6mSLSlXaSx70Mc7Q0s7FF4=w1200-h630-n-nu"
  },
  {
    "title": "1,000 Scientist AI Jam Session",
    "description": "OpenAI and nine national labs bring together leading scientists for first-of-its kind event.",
    "summary": "OpenAI and nine national labs bring together leading scientists for first-of-its kind event.",
    "pubDate": "Fri, 28 Feb 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/1000-scientist-ai-jam-session",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "EvoLM: In Search of Lost Language Model Training Dynamics",
    "description": "arXiv:2506.16029v1 Announce Type: cross Abstract: Modern language model (LM) training has been divided into multiple stages, making it difficult for downstream developers to evaluate the impact of design choices made at each stage. We present EvoLM, a model suite that enables systematic and transparent analysis of LMs' training dynamics across pre-training, continued pre-training, supervised fine-tuning, and reinforcement learning. By training over 100 LMs with 1B and 4B parameters from scratch, we rigorously evaluate both upstream (language modeling) and downstream (problem-solving) reasoning capabilities, including considerations of both in-domain and out-of-domain generalization. Key insights highlight the diminishing returns from excessive pre-training and post-training, the importance and practices of mitigating forgetting during domain-specific continued pre-training, the crucial role of continued pre-training in bridging pre-training and post-training phases, and various intricate trade-offs when configuring supervised fine-tuning and reinforcement learning. To facilitate open research and reproducibility, we release all pre-trained and post-trained models, training datasets for all stages, and our entire training and evaluation pipeline.",
    "summary": "arXiv:2506.16029v1 Announce Type: cross Abstract: Modern language model (LM) training has been divided into multiple stages, making it difficult for downstream developers to evaluate the impact of design choices made at each stage. We present EvoLM, a model suite that enables systematic and transparent analysis of LMs' training dynamics across pre-training, continued pre-training, supervised fine-tuning, and reinforcement learning. By training over 100 LMs with 1B and 4B parameters from scratch, we rigorously evaluate both upstream (language modeling) and downstream (problem-solving) reasoning capabilities, including considerations of both in-domain and out-of-domain generalization. Key insights highlight the diminishing returns from excessive pre-training and post-training, the importance and practices of mitigating forgetting during domain-specific continued pre-training, the crucial role of continued pre-training in bridging pre-training and post-training phases, and various intricate trade-offs when configuring supervised fine-tuning and reinforcement learning. To facilitate open research and reproducibility, we release all pre-trained and post-trained models, training datasets for all stages, and our entire training and evaluation pipeline.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16029",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How ü§ó Accelerate runs very large models thanks to PyTorch",
    "description": "",
    "summary": "How ü§ó Accelerate runs very large models thanks to PyTorch Load and run large models Meta AI and BigS...",
    "pubDate": "Tue, 27 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-large-models",
    "thumbnail": "https://huggingface.co/blog/assets/104_accelerate-large-models/thumbnail.png"
  },
  {
    "title": "Accelerating Protein Language Model ProtST on Intel Gaudi 2",
    "description": "",
    "summary": "Accelerating Protein Language Model ProtST on Intel Gaudi 2 Introduction Protein Language Models (PL...",
    "pubDate": "Wed, 03 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-protein-language-model-protst",
    "thumbnail": "https://huggingface.co/blog/assets/intel-protein-language-model-protst/01.jpeg"
  },
  {
    "title": "‰∏ñÁïåÁöÑYouTuber„ÄåMrBeast„Äç„Åï„Çì„ÄÅÂÖ¨Èñã„Åó„Åü„ÄåAI„Çµ„É†„Éç„Ç§„É´„ÉÑ„Éº„É´„Äç„ÅÆÊèê‰æõÂèñ„Çä„ÇÑ„ÇÅ„ÄÄX‰∏ä„Åß„ÅÆÂèçÁô∫Âèó„Åë",
    "description": "‰∏ñÁïåÁöÑ„Å™YouTuber„Å®Áü•„Çâ„Çå„Çã„ÄåMrBeast„Äç„Åï„Çì„ÅØ„ÄÅ„ÇØ„É™„Ç®„Ç§„Çø„ÉºÂêë„Åë„Å´ÂÖ¨Èñã„Åó„Åü„ÄåAI„Çµ„É†„Éç„Ç§„É´„ÉÑ„Éº„É´„Äç„ÅÆÊèê‰æõ„ÇíÂèñ„Çä„ÇÑ„ÇÅ„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ",
    "summary": "‰∏ñÁïåÁöÑ„Å™YouTuber„Å®Áü•„Çâ„Çå„Çã„ÄåMrBeast„Äç„Åï„Çì„ÅØ„ÄÅ„ÇØ„É™„Ç®„Ç§„Çø„ÉºÂêë„Åë„Å´ÂÖ¨Èñã„Åó„Åü„ÄåAI„Çµ„É†„Éç„Ç§„É´„ÉÑ„Éº„É´„Äç„ÅÆÊèê‰æõ„ÇíÂèñ„Çä„ÇÑ„ÇÅ„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ",
    "pubDate": "Sat, 28 Jun 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/28/news031.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/28/cover_news031.jpg"
  },
  {
    "title": "Introducing the Open Chain of Thought Leaderboard",
    "description": "",
    "summary": "Introducing the Open Chain of Thought Leaderboard Chain-of-thought prompting is emerging as a powerf...",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-cot",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_cot.png"
  },
  {
    "title": "Enhance Your Models in 5 Minutes with the Hugging Face Kernel Hub",
    "description": "",
    "summary": "üèéÔ∏è Enhance Your Models in 5 Minutes with the Hugging Face Kernel Hub Boost your model performance wi...",
    "pubDate": "Thu, 12 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hello-hf-kernels",
    "thumbnail": "https://huggingface.co/blog/assets/hello-hf-kernels/kernel-hub-five-mins-short.png"
  },
  {
    "title": "OpenAI at the Paris AI Action Summit",
    "description": "OpenAI looks forward to engaging with global leaders on AI‚Äôs role in shaping innovation and economic prosperity.",
    "summary": "OpenAI looks forward to engaging with global leaders on AI‚Äôs role in shaping innovation and economic prosperity.",
    "pubDate": "Fri, 07 Feb 2025 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-at-the-paris-ai-action-summit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Vietnamese Dataset for Text Segmentation and Multiple Choices Reading Comprehension",
    "description": "arXiv:2506.15978v1 Announce Type: cross Abstract: Vietnamese, the 20th most spoken language with over 102 million native speakers, lacks robust resources for key natural language processing tasks such as text segmentation and machine reading comprehension (MRC). To address this gap, we present VSMRC, the Vietnamese Text Segmentation and Multiple-Choice Reading Comprehension Dataset. Sourced from Vietnamese Wikipedia, our dataset includes 15,942 documents for text segmentation and 16,347 synthetic multiple-choice question-answer pairs generated with human quality assurance, ensuring a reliable and diverse resource. Experiments show that mBERT consistently outperforms monolingual models on both tasks, achieving an accuracy of 88.01% on MRC test set and an F1 score of 63.15% on text segmentation test set. Our analysis reveals that multilingual models excel in NLP tasks for Vietnamese, suggesting potential applications to other under-resourced languages. VSMRC is available at HuggingFace",
    "summary": "arXiv:2506.15978v1 Announce Type: cross Abstract: Vietnamese, the 20th most spoken language with over 102 million native speakers, lacks robust resources for key natural language processing tasks such as text segmentation and machine reading comprehension (MRC). To address this gap, we present VSMRC, the Vietnamese Text Segmentation and Multiple-Choice Reading Comprehension Dataset. Sourced from Vietnamese Wikipedia, our dataset includes 15,942 documents for text segmentation and 16,347 synthetic multiple-choice question-answer pairs generated with human quality assurance, ensuring a reliable and diverse resource. Experiments show that mBERT consistently outperforms monolingual models on both tasks, achieving an accuracy of 88.01% on MRC test set and an F1 score of 63.15% on text segmentation test set. Our analysis reveals that multilingual models excel in NLP tasks for Vietnamese, suggesting potential applications to other under-resourced languages. VSMRC is available at HuggingFace",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15978",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Thinking with images",
    "description": "OpenAI o3 and o4-mini represent a significant breakthrough in visual perception by reasoning with images in their chain of thought.",
    "summary": "OpenAI o3 and o4-mini represent a significant breakthrough in visual perception by reasoning with images in their chain of thought.",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/thinking-with-images",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Leveraging Influence Functions for Resampling Data in Physics-Informed Neural Networks",
    "description": "arXiv:2506.16443v1 Announce Type: cross Abstract: Physics-informed neural networks (PINNs) offer a powerful approach to solving partial differential equations (PDEs), which are ubiquitous in the quantitative sciences. Applied to both forward and inverse problems across various scientific domains, PINNs have recently emerged as a valuable tool in the field of scientific machine learning. A key aspect of their training is that the data -- spatio-temporal points sampled from the PDE's input domain -- are readily available. Influence functions, a tool from the field of explainable AI (XAI), approximate the effect of individual training points on the model, enhancing interpretability. In the present work, we explore the application of influence function-based sampling approaches for the training data. Our results indicate that such targeted resampling based on data attribution methods has the potential to enhance prediction accuracy in physics-informed neural networks, demonstrating a practical application of an XAI method in PINN training.",
    "summary": "arXiv:2506.16443v1 Announce Type: cross Abstract: Physics-informed neural networks (PINNs) offer a powerful approach to solving partial differential equations (PDEs), which are ubiquitous in the quantitative sciences. Applied to both forward and inverse problems across various scientific domains, PINNs have recently emerged as a valuable tool in the field of scientific machine learning. A key aspect of their training is that the data -- spatio-temporal points sampled from the PDE's input domain -- are readily available. Influence functions, a tool from the field of explainable AI (XAI), approximate the effect of individual training points on the model, enhancing interpretability. In the present work, we explore the application of influence function-based sampling approaches for the training data. Our results indicate that such targeted resampling based on data attribution methods has the potential to enhance prediction accuracy in physics-informed neural networks, demonstrating a practical application of an XAI method in PINN training.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16443",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NTRL: Encounter Generation via Reinforcement Learning for Dynamic Difficulty Adjustment in Dungeons and Dragons",
    "description": "arXiv:2506.19530v1 Announce Type: new Abstract: Balancing combat encounters in Dungeons & Dragons (D&amp;D) is a complex task that requires Dungeon Masters (DM) to manually assess party strength, enemy composition, and dynamic player interactions while avoiding interruption of the narrative flow. In this paper, we propose Encounter Generation via Reinforcement Learning (NTRL), a novel approach that automates Dynamic Difficulty Adjustment (DDA) in D&amp;D via combat encounter design. By framing the problem as a contextual bandit, NTRL generates encounters based on real-time party members attributes. In comparison with classic DM heuristics, NTRL iteratively optimizes encounters to extend combat longevity (+200%), increases damage dealt to party members, reducing post-combat hit points (-16.67%), and raises the number of player deaths while maintaining low total party kills (TPK). The intensification of combat forces players to act wisely and engage in tactical maneuvers, even though the generated encounters guarantee high win rates (70%). Even in comparison with encounters designed by human Dungeon Masters, NTRL demonstrates superior performance by enhancing the strategic depth of combat while increasing difficulty in a manner that preserves overall game fairness.",
    "summary": "arXiv:2506.19530v1 Announce Type: new Abstract: Balancing combat encounters in Dungeons & Dragons (D&amp;D) is a complex task that requires Dungeon Masters (DM) to manually assess party strength, enemy composition, and dynamic player interactions while avoiding interruption of the narrative flow. In this paper, we propose Encounter Generation via Reinforcement Learning (NTRL), a novel approach that automates Dynamic Difficulty Adjustment (DDA) in D&amp;D via combat encounter design. By framing the problem as a contextual bandit, NTRL generates encounters based on real-time party members attributes. In comparison with classic DM heuristics, NTRL iteratively optimizes encounters to extend combat longevity (+200%), increases damage dealt to party members, reducing post-combat hit points (-16.67%), and raises the number of player deaths while maintaining low total party kills (TPK). The intensification of combat forces players to act wisely and engage in tactical maneuvers, even though the generated encounters guarantee high win rates (70%). Even in comparison with encounters designed by human Dungeon Masters, NTRL demonstrates superior performance by enhancing the strategic depth of combat while increasing difficulty in a manner that preserves overall game fairness.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19530",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Unlocking Longer Generation with Key-Value Cache Quantization",
    "description": "",
    "summary": "Unlocking Longer Generation with Key-Value Cache Quantization At Hugging Face, we are excited to sha...",
    "pubDate": "Thu, 16 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kv-cache-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/kv_cache_quantization/thumbnail.png"
  },
  {
    "title": "Welcome, Pieter and Shivon!",
    "description": "We have two more team¬†updates.",
    "summary": "We have two more team¬†updates.",
    "pubDate": "Tue, 26 Apr 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/welcome-pieter-and-shivon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ControlNet in Diffusers üß®",
    "description": "",
    "summary": "Ultra fast ControlNet with üß® Diffusers Ever since Stable Diffusion took the world by storm, people h...",
    "pubDate": "Fri, 03 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/controlnet",
    "thumbnail": "https://huggingface.co/blog/assets/controlnet/thumbnail.png"
  },
  {
    "title": "Does Multimodality Lead to Better Time Series Forecasting?",
    "description": "arXiv:2506.21611v1 Announce Type: cross Abstract: Recently, there has been growing interest in incorporating textual information into foundation models for time series forecasting. However, it remains unclear whether and under what conditions such multimodal integration consistently yields gains. We systematically investigate these questions across a diverse benchmark of 14 forecasting tasks spanning 7 domains, including health, environment, and economics. We evaluate two popular multimodal forecasting paradigms: aligning-based methods, which align time series and text representations; and prompting-based methods, which directly prompt large language models for forecasting. Although prior works report gains from multimodal input, we find these effects are not universal across datasets and models, and multimodal methods sometimes do not outperform the strongest unimodal baselines. To understand when textual information helps, we disentangle the effects of model architectural properties and data characteristics. Our findings highlight that on the modeling side, incorporating text information is most helpful given (1) high-capacity text models, (2) comparatively weaker time series models, and (3) appropriate aligning strategies. On the data side, performance gains are more likely when (4) sufficient training data is available and (5) the text offers complementary predictive signal beyond what is already captured from the time series alone. Our empirical findings offer practical guidelines for when multimodality can be expected to aid forecasting tasks, and when it does not.",
    "summary": "arXiv:2506.21611v1 Announce Type: cross Abstract: Recently, there has been growing interest in incorporating textual information into foundation models for time series forecasting. However, it remains unclear whether and under what conditions such multimodal integration consistently yields gains. We systematically investigate these questions across a diverse benchmark of 14 forecasting tasks spanning 7 domains, including health, environment, and economics. We evaluate two popular multimodal forecasting paradigms: aligning-based methods, which align time series and text representations; and prompting-based methods, which directly prompt large language models for forecasting. Although prior works report gains from multimodal input, we find these effects are not universal across datasets and models, and multimodal methods sometimes do not outperform the strongest unimodal baselines. To understand when textual information helps, we disentangle the effects of model architectural properties and data characteristics. Our findings highlight that on the modeling side, incorporating text information is most helpful given (1) high-capacity text models, (2) comparatively weaker time series models, and (3) appropriate aligning strategies. On the data side, performance gains are more likely when (4) sufficient training data is available and (5) the text offers complementary predictive signal beyond what is already captured from the time series alone. Our empirical findings offer practical guidelines for when multimodality can be expected to aid forecasting tasks, and when it does not.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21611",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Technology Behind BLOOM Training",
    "description": "",
    "summary": "The Technology Behind BLOOM Training In recent years, training ever larger language models has becom...",
    "pubDate": "Thu, 14 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-megatron-deepspeed",
    "thumbnail": "https://huggingface.co/blog/assets/86_bloom_megatron_deepspeed/thumbnail.png"
  },
  {
    "title": "MUPA: Towards Multi-Path Agentic Reasoning for Grounded Video Question Answering",
    "description": "arXiv:2506.18071v2 Announce Type: replace-cross Abstract: Grounded Video Question Answering (Grounded VideoQA) requires aligning textual answers with explicit visual evidence. However, modern multimodal models often rely on linguistic priors and spurious correlations, resulting in poorly grounded predictions. In this work, we propose MUPA, a cooperative MUlti-Path Agentic approach that unifies video grounding, question answering, answer reflection and aggregation to tackle Grounded VideoQA. MUPA features three distinct reasoning paths on the interplay of grounding and QA agents in different chronological orders, along with a dedicated reflection agent to judge and aggregate the multi-path results to accomplish consistent QA and grounding. This design markedly improves grounding fidelity without sacrificing answer accuracy. Despite using only 2B parameters, our method outperforms all 7B-scale competitors. When scaled to 7B parameters, MUPA establishes new state-of-the-art results, with Acc@GQA of 30.3% and 47.4% on NExT-GQA and DeVE-QA respectively, demonstrating MUPA' effectiveness towards trustworthy video-language understanding. Our code is available in https://github.com/longmalongma/MUPA.",
    "summary": "arXiv:2506.18071v2 Announce Type: replace-cross Abstract: Grounded Video Question Answering (Grounded VideoQA) requires aligning textual answers with explicit visual evidence. However, modern multimodal models often rely on linguistic priors and spurious correlations, resulting in poorly grounded predictions. In this work, we propose MUPA, a cooperative MUlti-Path Agentic approach that unifies video grounding, question answering, answer reflection and aggregation to tackle Grounded VideoQA. MUPA features three distinct reasoning paths on the interplay of grounding and QA agents in different chronological orders, along with a dedicated reflection agent to judge and aggregate the multi-path results to accomplish consistent QA and grounding. This design markedly improves grounding fidelity without sacrificing answer accuracy. Despite using only 2B parameters, our method outperforms all 7B-scale competitors. When scaled to 7B parameters, MUPA establishes new state-of-the-art results, with Acc@GQA of 30.3% and 47.4% on NExT-GQA and DeVE-QA respectively, demonstrating MUPA' effectiveness towards trustworthy video-language understanding. Our code is available in https://github.com/longmalongma/MUPA.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18071",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SysTemp: A Multi-Agent System for Template-Based Generation of SysML v2",
    "description": "arXiv:2506.21608v1 Announce Type: cross Abstract: The automatic generation of SysML v2 models represents a major challenge in the engineering of complex systems, particularly due to the scarcity of learning corpora and complex syntax. We present SysTemp, a system aimed at facilitating and improving the creation of SysML v2 models from natural language specifications. It is based on a multi-agent system, including a template generator that structures the generation process. We discuss the advantages and challenges of this system through an evaluation, highlighting its potential to improve the quality of the generations in SysML v2 modeling.",
    "summary": "arXiv:2506.21608v1 Announce Type: cross Abstract: The automatic generation of SysML v2 models represents a major challenge in the engineering of complex systems, particularly due to the scarcity of learning corpora and complex syntax. We present SysTemp, a system aimed at facilitating and improving the creation of SysML v2 models from natural language specifications. It is based on a multi-agent system, including a template generator that structures the generation process. We discuss the advantages and challenges of this system through an evaluation, highlighting its potential to improve the quality of the generations in SysML v2 modeling.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21608",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI leadership team update",
    "description": "We‚Äôre happy to announce several executive role changes that reflect our recent progress and will ensure continued momentum toward our next major¬†milestones.",
    "summary": "We‚Äôre happy to announce several executive role changes that reflect our recent progress and will ensure continued momentum toward our next major¬†milestones.",
    "pubDate": "Thu, 05 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-team-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Overview of the ClinIQLink 2025 Shared Task on Medical Question-Answering",
    "description": "arXiv:2506.21597v1 Announce Type: cross Abstract: In this paper, we present an overview of ClinIQLink, a shared task, collocated with the 24th BioNLP workshop at ACL 2025, designed to stress-test large language models (LLMs) on medically-oriented question answering aimed at the level of a General Practitioner. The challenge supplies 4,978 expert-verified, medical source-grounded question-answer pairs that cover seven formats: true/false, multiple choice, unordered list, short answer, short-inverse, multi-hop, and multi-hop-inverse. Participating systems, bundled in Docker or Apptainer images, are executed on the CodaBench platform or the University of Maryland's Zaratan cluster. An automated harness (Task 1) scores closed-ended items by exact match and open-ended items with a three-tier embedding metric. A subsequent physician panel (Task 2) audits the top model responses.",
    "summary": "arXiv:2506.21597v1 Announce Type: cross Abstract: In this paper, we present an overview of ClinIQLink, a shared task, collocated with the 24th BioNLP workshop at ACL 2025, designed to stress-test large language models (LLMs) on medically-oriented question answering aimed at the level of a General Practitioner. The challenge supplies 4,978 expert-verified, medical source-grounded question-answer pairs that cover seven formats: true/false, multiple choice, unordered list, short answer, short-inverse, multi-hop, and multi-hop-inverse. Participating systems, bundled in Docker or Apptainer images, are executed on the CodaBench platform or the University of Maryland's Zaratan cluster. An automated harness (Task 1) scores closed-ended items by exact match and open-ended items with a three-tier embedding metric. A subsequent physician panel (Task 2) audits the top model responses.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21597",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The 4 Things Qwen-3's Chat Template Teaches Us",
    "description": "",
    "summary": "The 4 Things Qwen-3‚Äôs Chat Template Teaches Us What a boring Jinja snippet tells us about the new Qw...",
    "pubDate": "Wed, 30 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/qwen-3-chat-template-deep-dive",
    "thumbnail": "https://huggingface.co/blog/assets/qwen-3-chat-template-deep-dive/thumbnail.png"
  },
  {
    "title": "Our approach to AI safety",
    "description": "Ensuring that AI systems are built, deployed, and used safely is critical to our mission.",
    "summary": "Ensuring that AI systems are built, deployed, and used safely is critical to our mission.",
    "pubDate": "Wed, 05 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/our-approach-to-ai-safety",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI announces leadership transition",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 17 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-announces-leadership-transition",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Red-Teaming Large Language Models",
    "description": "",
    "summary": "Red-Teaming Large Language Models Warning: This article is about red-teaming and as such contains ex...",
    "pubDate": "Fri, 24 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/red-teaming",
    "thumbnail": "https://huggingface.co/blog/assets/red-teaming/thumbnail.png"
  },
  {
    "title": "Faster Text Generation with Self-Speculative Decoding",
    "description": "",
    "summary": "Faster Text Generation with Self-Speculative Decoding Self-speculative decoding, proposed in LayerSk...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/layerskip",
    "thumbnail": "https://huggingface.co/blog/assets/layerskip/thumbnail.png"
  },
  {
    "title": "Speak is personalizing language learning with AI",
    "description": "A conversation with Connor Zwick, CEO & Co-founder of Speak.",
    "summary": "A conversation with Connor Zwick, CEO & Co-founder of Speak.",
    "pubDate": "Tue, 22 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/speak-connor-zwick",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Global-Local Cross-Attention Network for Ultra-high Resolution Remote Sensing Image Semantic Segmentation",
    "description": "arXiv:2506.19406v1 Announce Type: cross Abstract: With the rapid development of ultra-high resolution (UHR) remote sensing technology, the demand for accurate and efficient semantic segmentation has increased significantly. However, existing methods face challenges in computational efficiency and multi-scale feature fusion. To address these issues, we propose GLCANet (Global-Local Cross-Attention Network), a lightweight segmentation framework designed for UHR remote sensing imagery.GLCANet employs a dual-stream architecture to efficiently fuse global semantics and local details while minimizing GPU usage. A self-attention mechanism enhances long-range dependencies, refines global features, and preserves local details for better semantic consistency. A masked cross-attention mechanism also adaptively fuses global-local features, selectively enhancing fine-grained details while exploiting global context to improve segmentation accuracy. Experimental results show that GLCANet outperforms state-of-the-art methods regarding accuracy and computational efficiency. The model effectively processes large, high-resolution images with a small memory footprint, providing a promising solution for real-world remote sensing applications.",
    "summary": "arXiv:2506.19406v1 Announce Type: cross Abstract: With the rapid development of ultra-high resolution (UHR) remote sensing technology, the demand for accurate and efficient semantic segmentation has increased significantly. However, existing methods face challenges in computational efficiency and multi-scale feature fusion. To address these issues, we propose GLCANet (Global-Local Cross-Attention Network), a lightweight segmentation framework designed for UHR remote sensing imagery.GLCANet employs a dual-stream architecture to efficiently fuse global semantics and local details while minimizing GPU usage. A self-attention mechanism enhances long-range dependencies, refines global features, and preserves local details for better semantic consistency. A masked cross-attention mechanism also adaptively fuses global-local features, selectively enhancing fine-grained details while exploiting global context to improve segmentation accuracy. Experimental results show that GLCANet outperforms state-of-the-art methods regarding accuracy and computational efficiency. The model effectively processes large, high-resolution images with a small memory footprint, providing a promising solution for real-world remote sensing applications.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19406",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FLAME: Towards Federated Fine-Tuning Large Language Models Through Adaptive SMoE",
    "description": "arXiv:2506.16600v1 Announce Type: cross Abstract: Existing resource-adaptive LoRA federated fine-tuning methods enable clients to fine-tune models using compressed versions of global LoRA matrices, in order to accommodate various compute resources across clients. This compression requirement will lead to suboptimal performance due to information loss. To address this, we propose FLAME, a novel federated learning framework based on the Sparse Mixture-of-Experts (SMoE) architecture. Unlike prior approaches, FLAME retains full (uncompressed) global LoRA matrices and achieves client-side adaptability by varying the number of activated experts per client. However, incorporating SMoE into federated learning introduces unique challenges, specifically, the mismatch in output magnitude from partial expert activation and the imbalance in expert training quality across clients. FLAME tackles these challenges through a lightweight rescaling mechanism and an activation-aware aggregation scheme. Empirical results across diverse computational settings demonstrate that FLAME consistently outperforms existing methods, providing a robust and effective solution for resource-adaptive federated learning.",
    "summary": "arXiv:2506.16600v1 Announce Type: cross Abstract: Existing resource-adaptive LoRA federated fine-tuning methods enable clients to fine-tune models using compressed versions of global LoRA matrices, in order to accommodate various compute resources across clients. This compression requirement will lead to suboptimal performance due to information loss. To address this, we propose FLAME, a novel federated learning framework based on the Sparse Mixture-of-Experts (SMoE) architecture. Unlike prior approaches, FLAME retains full (uncompressed) global LoRA matrices and achieves client-side adaptability by varying the number of activated experts per client. However, incorporating SMoE into federated learning introduces unique challenges, specifically, the mismatch in output magnitude from partial expert activation and the imbalance in expert training quality across clients. FLAME tackles these challenges through a lightweight rescaling mechanism and an activation-aware aggregation scheme. Empirical results across diverse computational settings demonstrate that FLAME consistently outperforms existing methods, providing a robust and effective solution for resource-adaptive federated learning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16600",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PBFT-Backed Semantic Voting for Multi-Agent Memory Pruning",
    "description": "arXiv:2506.17338v2 Announce Type: replace-cross Abstract: The proliferation of multi-agent systems (MAS) in complex, dynamic environments necessitates robust and efficient mechanisms for managing shared knowledge. A critical challenge is ensuring that distributed memories remain synchronized, relevant, and free from the accumulation of outdated or inconsequential data - a process analogous to biological forgetting. This paper introduces the Co-Forgetting Protocol, a novel, comprehensive framework designed to address this challenge by enabling synchronized memory pruning in MAS. The protocol integrates three key components: (1) context-aware semantic voting, where agents utilize a lightweight DistilBERT model to assess the relevance of memory items based on their content and the current operational context; (2) multi-scale temporal decay functions, which assign diminishing importance to memories based on their age and access frequency across different time horizons; and (3) a Practical Byzantine Fault Tolerance (PBFT)-based consensus mechanism, ensuring that decisions to retain or discard memory items are agreed upon by a qualified and fault-tolerant majority of agents, even in the presence of up to f Byzantine (malicious or faulty) agents in a system of N greater than or equal to 3f+1 agents. The protocol leverages gRPC for efficient inter-agent communication and Pinecone for scalable vector embedding storage and similarity search, with SQLite managing metadata. Experimental evaluations in a simulated MAS environment with four agents demonstrate the protocol's efficacy, achieving a 52% reduction in memory footprint over 500 epochs, 88% voting accuracy in forgetting decisions against human-annotated benchmarks, a 92% PBFT consensus success rate under simulated Byzantine conditions, and an 82% cache hit rate for memory access.",
    "summary": "arXiv:2506.17338v2 Announce Type: replace-cross Abstract: The proliferation of multi-agent systems (MAS) in complex, dynamic environments necessitates robust and efficient mechanisms for managing shared knowledge. A critical challenge is ensuring that distributed memories remain synchronized, relevant, and free from the accumulation of outdated or inconsequential data - a process analogous to biological forgetting. This paper introduces the Co-Forgetting Protocol, a novel, comprehensive framework designed to address this challenge by enabling synchronized memory pruning in MAS. The protocol integrates three key components: (1) context-aware semantic voting, where agents utilize a lightweight DistilBERT model to assess the relevance of memory items based on their content and the current operational context; (2) multi-scale temporal decay functions, which assign diminishing importance to memories based on their age and access frequency across different time horizons; and (3) a Practical Byzantine Fault Tolerance (PBFT)-based consensus mechanism, ensuring that decisions to retain or discard memory items are agreed upon by a qualified and fault-tolerant majority of agents, even in the presence of up to f Byzantine (malicious or faulty) agents in a system of N greater than or equal to 3f+1 agents. The protocol leverages gRPC for efficient inter-agent communication and Pinecone for scalable vector embedding storage and similarity search, with SQLite managing metadata. Experimental evaluations in a simulated MAS environment with four agents demonstrate the protocol's efficacy, achieving a 52% reduction in memory footprint over 500 epochs, 88% voting accuracy in forgetting decisions against human-annotated benchmarks, a 92% PBFT consensus success rate under simulated Byzantine conditions, and an 82% cache hit rate for memory access.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17338",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Controllable Video Generation with Provable Disentanglement",
    "description": "arXiv:2502.02690v2 Announce Type: replace-cross Abstract: Controllable video generation remains a significant challenge, despite recent advances in generating high-quality and consistent videos. Most existing methods for controlling video generation treat the video as a whole, neglecting intricate fine-grained spatiotemporal relationships, which limits both control precision and efficiency. In this paper, we propose Controllable Video Generative Adversarial Networks (CoVoGAN) to disentangle the video concepts, thus facilitating efficient and independent control over individual concepts. Specifically, following the minimal change principle, we first disentangle static and dynamic latent variables. We then leverage the sufficient change property to achieve component-wise identifiability of dynamic latent variables, enabling disentangled control of video generation. To establish the theoretical foundation, we provide a rigorous analysis demonstrating the identifiability of our approach. Building on these theoretical insights, we design a Temporal Transition Module to disentangle latent dynamics. To enforce the minimal change principle and sufficient change property, we minimize the dimensionality of latent dynamic variables and impose temporal conditional independence. To validate our approach, we integrate this module as a plug-in for GANs. Extensive qualitative and quantitative experiments on various video generation benchmarks demonstrate that our method significantly improves generation quality and controllability across diverse real-world scenarios.",
    "summary": "arXiv:2502.02690v2 Announce Type: replace-cross Abstract: Controllable video generation remains a significant challenge, despite recent advances in generating high-quality and consistent videos. Most existing methods for controlling video generation treat the video as a whole, neglecting intricate fine-grained spatiotemporal relationships, which limits both control precision and efficiency. In this paper, we propose Controllable Video Generative Adversarial Networks (CoVoGAN) to disentangle the video concepts, thus facilitating efficient and independent control over individual concepts. Specifically, following the minimal change principle, we first disentangle static and dynamic latent variables. We then leverage the sufficient change property to achieve component-wise identifiability of dynamic latent variables, enabling disentangled control of video generation. To establish the theoretical foundation, we provide a rigorous analysis demonstrating the identifiability of our approach. Building on these theoretical insights, we design a Temporal Transition Module to disentangle latent dynamics. To enforce the minimal change principle and sufficient change property, we minimize the dimensionality of latent dynamic variables and impose temporal conditional independence. To validate our approach, we integrate this module as a plug-in for GANs. Extensive qualitative and quantitative experiments on various video generation benchmarks demonstrate that our method significantly improves generation quality and controllability across diverse real-world scenarios.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.02690",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Object Detection Leaderboard",
    "description": "",
    "summary": "Object Detection Leaderboard: Decoding Metrics and Their Potential Pitfalls Welcome to our latest di...",
    "pubDate": "Mon, 18 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/object-detection-leaderboard",
    "thumbnail": "https://huggingface.co/blog/assets/object-detection-leaderboard/thumbnail.png"
  },
  {
    "title": "Video generation models as world simulators",
    "description": "We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.",
    "summary": "We explore large-scale training of generative models on video data. Specifically, we train text-conditional diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video generation models is a promising path towards building general purpose simulators of the physical world.",
    "pubDate": "Thu, 15 Feb 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/video-generation-models-as-world-simulators",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Get an audio overview of Search results in Labs, then click through to learn more.",
    "description": "A phone screen showing Google search results with a section titled 'Search Labs | Audio Overviews' and an audio player.",
    "summary": "A phone screen showing Google search results with a section titled 'Search Labs | Audio Overviews' and an audio player.",
    "pubDate": "Fri, 13 Jun 2025 15:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/audio-overviews-search-labs/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AudioOverview_SS.max-1440x810.png"
  },
  {
    "title": "OpenAI Five Finals",
    "description": "We‚Äôll be holding our final live event for OpenAI Five at 11:30am PT on April 13.",
    "summary": "We‚Äôll be holding our final live event for OpenAI Five at 11:30am PT on April 13.",
    "pubDate": "Tue, 26 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-finals",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How we leveraged distilabel to create an Argilla 2.0 Chatbot",
    "description": "",
    "summary": "How we leveraged distilabel to create an Argilla 2.0 Chatbot TL;DR Discover how to build a Chatbot f...",
    "pubDate": "Tue, 16 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/argilla-chatbot",
    "thumbnail": "https://huggingface.co/blog/assets/argilla-chatbot/thumbnail.png"
  },
  {
    "title": "New method assesses and improves the reliability of radiologists‚Äô diagnostic reports",
    "description": "The framework helps clinicians choose phrases that more accurately reflect the likelihood that certain conditions are present in X-rays.",
    "summary": "The framework helps clinicians choose phrases that more accurately reflect the likelihood that certain conditions are present in X-rays.",
    "pubDate": "Fri, 04 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-method-assesses-and-improves-reliability-radiologists-diagnostic-reports-0404",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Calibrating-Certainty-01-press_2.jpg"
  },
  {
    "title": "NepaliGPT: A Generative Language Model for the Nepali Language",
    "description": "arXiv:2506.16399v1 Announce Type: cross Abstract: After the release of ChatGPT, Large Language Models (LLMs) have gained huge popularity in recent days and thousands of variants of LLMs have been released. However, there is no generative language model for the Nepali language, due to which other downstream tasks, including fine-tuning, have not been explored yet. To fill this research gap in the Nepali NLP space, this research proposes textit{NepaliGPT}, a generative large language model tailored specifically for the Nepali language. This research introduces an advanced corpus for the Nepali language collected from several sources, called the Devanagari Corpus. Likewise, the research introduces the first NepaliGPT benchmark dataset comprised of 4,296 question-answer pairs in the Nepali language. The proposed LLM NepaliGPT achieves the following metrics in text generation: Perplexity of 26.32245, ROUGE-1 score of 0.2604, causal coherence of 81.25%, and causal consistency of 85.41%.",
    "summary": "arXiv:2506.16399v1 Announce Type: cross Abstract: After the release of ChatGPT, Large Language Models (LLMs) have gained huge popularity in recent days and thousands of variants of LLMs have been released. However, there is no generative language model for the Nepali language, due to which other downstream tasks, including fine-tuning, have not been explored yet. To fill this research gap in the Nepali NLP space, this research proposes textit{NepaliGPT}, a generative large language model tailored specifically for the Nepali language. This research introduces an advanced corpus for the Nepali language collected from several sources, called the Devanagari Corpus. Likewise, the research introduces the first NepaliGPT benchmark dataset comprised of 4,296 question-answer pairs in the Nepali language. The proposed LLM NepaliGPT achieves the following metrics in text generation: Perplexity of 26.32245, ROUGE-1 score of 0.2604, causal coherence of 81.25%, and causal consistency of 85.41%.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16399",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Efficient Controllable Generation for SDXL with T2I-Adapters",
    "description": "",
    "summary": "Efficient Controllable Generation for SDXL with T2I-Adapters T2I-Adapter is an efficient plug-and-pl...",
    "pubDate": "Fri, 08 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/t2i-sdxl-adapters",
    "thumbnail": "https://huggingface.co/blog/assets/t2i-sdxl-adapters/thumbnail.png"
  },
  {
    "title": "Going multimodal: How Prezi is leveraging the Hub and the Expert Support Program to accelerate their ML roadmap",
    "description": "",
    "summary": "Going multimodal: How Prezi is leveraging the Hub and the Expert Support Program to accelerate their...",
    "pubDate": "Wed, 19 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/prezi-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/70_sempre_health/thumbnailprezi.jpg"
  },
  {
    "title": "We are hiring interns!",
    "description": "",
    "summary": "We are hiring interns! Want to help build the future at -- if we may say so ourselves -- one of the ...",
    "pubDate": "Tue, 29 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/interns-2023",
    "thumbnail": "https://huggingface.co/blog/assets/interns-2023/thumbnail.png"
  },
  {
    "title": "Category-based Galaxy Image Generation via Diffusion Models",
    "description": "arXiv:2506.16255v1 Announce Type: cross Abstract: Conventional galaxy generation methods rely on semi-analytical models and hydrodynamic simulations, which are highly dependent on physical assumptions and parameter tuning. In contrast, data-driven generative models do not have explicit physical parameters pre-determined, and instead learn them efficiently from observational data, making them alternative solutions to galaxy generation. Among these, diffusion models outperform Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) in quality and diversity. Leveraging physical prior knowledge to these models can further enhance their capabilities. In this work, we present GalCatDiff, the first framework in astronomy to leverage both galaxy image features and astrophysical properties in the network design of diffusion models. GalCatDiff incorporates an enhanced U-Net and a novel block entitled Astro-RAB (Residual Attention Block), which dynamically combines attention mechanisms with convolution operations to ensure global consistency and local feature fidelity. Moreover, GalCatDiff uses category embeddings for class-specific galaxy generation, avoiding the high computational costs of training separate models for each category. Our experimental results demonstrate that GalCatDiff significantly outperforms existing methods in terms of the consistency of sample color and size distributions, and the generated galaxies are both visually realistic and physically consistent. This framework will enhance the reliability of galaxy simulations and can potentially serve as a data augmentor to support future galaxy classification algorithm development.",
    "summary": "arXiv:2506.16255v1 Announce Type: cross Abstract: Conventional galaxy generation methods rely on semi-analytical models and hydrodynamic simulations, which are highly dependent on physical assumptions and parameter tuning. In contrast, data-driven generative models do not have explicit physical parameters pre-determined, and instead learn them efficiently from observational data, making them alternative solutions to galaxy generation. Among these, diffusion models outperform Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) in quality and diversity. Leveraging physical prior knowledge to these models can further enhance their capabilities. In this work, we present GalCatDiff, the first framework in astronomy to leverage both galaxy image features and astrophysical properties in the network design of diffusion models. GalCatDiff incorporates an enhanced U-Net and a novel block entitled Astro-RAB (Residual Attention Block), which dynamically combines attention mechanisms with convolution operations to ensure global consistency and local feature fidelity. Moreover, GalCatDiff uses category embeddings for class-specific galaxy generation, avoiding the high computational costs of training separate models for each category. Our experimental results demonstrate that GalCatDiff significantly outperforms existing methods in terms of the consistency of sample color and size distributions, and the generated galaxies are both visually realistic and physically consistent. This framework will enhance the reliability of galaxy simulations and can potentially serve as a data augmentor to support future galaxy classification algorithm development.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16255",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using AI to fight climate change",
    "description": "AI is a powerful technology that will transform our future, so how can we best apply it to help combat climate change and find sustainable solutions?",
    "summary": "AI is a powerful technology that will transform our future, so how can we best apply it to help combat climate change and find sustainable solutions?",
    "pubDate": "Fri, 21 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/using-ai-to-fight-climate-change/",
    "thumbnail": "https://lh3.googleusercontent.com/_7lNDyMo0JuzMRu0wVUtaJuXaEPDy8ay20vcsv08JvF3fMkEbk20mGBWdI09Wg0USIinNH5urB5nudEGZWRvTeUNOz_WOAwcduNdQQQNGx-JgtQE1aE=w1200-h630-n-nu"
  },
  {
    "title": "Welcome PaliGemma 2 ‚Äì New vision language models by Google",
    "description": "",
    "summary": "Welcome PaliGemma 2 ‚Äì New vision language models by Google We are excited to welcome Google's all-ne...",
    "pubDate": "Thu, 05 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma2",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma/Paligemma2.png"
  },
  {
    "title": "MemeMind: A Large-Scale Multimodal Dataset with Chain-of-Thought Reasoning for Harmful Meme Detection",
    "description": "arXiv:2506.18919v1 Announce Type: cross Abstract: The rapid development of social media has intensified the spread of harmful content. Harmful memes, which integrate both images and text, pose significant challenges for automated detection due to their implicit semantics and complex multimodal interactions. Although existing research has made progress in detection accuracy and interpretability, the lack of a systematic, large-scale, diverse, and highly explainable dataset continues to hinder further advancement in this field. To address this gap, we introduce MemeMind, a novel dataset featuring scientifically rigorous standards, large scale, diversity, bilingual support (Chinese and English), and detailed Chain-of-Thought (CoT) annotations. MemeMind fills critical gaps in current datasets by offering comprehensive labeling and explicit reasoning traces, thereby providing a solid foundation for enhancing harmful meme detection. In addition, we propose an innovative detection framework, MemeGuard, which effectively integrates multimodal information with reasoning process modeling, significantly improving models' ability to understand and identify harmful memes. Extensive experiments conducted on the MemeMind dataset demonstrate that MemeGuard consistently outperforms existing state-of-the-art methods in harmful meme detection tasks.",
    "summary": "arXiv:2506.18919v1 Announce Type: cross Abstract: The rapid development of social media has intensified the spread of harmful content. Harmful memes, which integrate both images and text, pose significant challenges for automated detection due to their implicit semantics and complex multimodal interactions. Although existing research has made progress in detection accuracy and interpretability, the lack of a systematic, large-scale, diverse, and highly explainable dataset continues to hinder further advancement in this field. To address this gap, we introduce MemeMind, a novel dataset featuring scientifically rigorous standards, large scale, diversity, bilingual support (Chinese and English), and detailed Chain-of-Thought (CoT) annotations. MemeMind fills critical gaps in current datasets by offering comprehensive labeling and explicit reasoning traces, thereby providing a solid foundation for enhancing harmful meme detection. In addition, we propose an innovative detection framework, MemeGuard, which effectively integrates multimodal information with reasoning process modeling, significantly improving models' ability to understand and identify harmful memes. Extensive experiments conducted on the MemeMind dataset demonstrate that MemeGuard consistently outperforms existing state-of-the-art methods in harmful meme detection tasks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18919",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PEACE: Empowering Geologic Map Holistic Understanding with MLLMs",
    "description": "arXiv:2501.06184v1 Announce Type: cross Abstract: Geologic map, as a fundamental diagram in geology science, provides critical insights into the structure and composition of Earth's subsurface and surface. These maps are indispensable in various fields, including disaster detection, resource exploration, and civil engineering. Despite their significance, current Multimodal Large Language Models (MLLMs) often fall short in geologic map understanding. This gap is primarily due to the challenging nature of cartographic generalization, which involves handling high-resolution map, managing multiple associated components, and requiring domain-specific knowledge. To quantify this gap, we construct GeoMap-Bench, the first-ever benchmark for evaluating MLLMs in geologic map understanding, which assesses the full-scale abilities in extracting, referring, grounding, reasoning, and analyzing. To bridge this gap, we introduce GeoMap-Agent, the inaugural agent designed for geologic map understanding, which features three modules: Hierarchical Information Extraction (HIE), Domain Knowledge Injection (DKI), and Prompt-enhanced Question Answering (PEQA). Inspired by the interdisciplinary collaboration among human scientists, an AI expert group acts as consultants, utilizing a diverse tool pool to comprehensively analyze questions. Through comprehensive experiments, GeoMap-Agent achieves an overall score of 0.811 on GeoMap-Bench, significantly outperforming 0.369 of GPT-4o. Our work, emPowering gEologic mAp holistiC undErstanding (PEACE) with MLLMs, paves the way for advanced AI applications in geology, enhancing the efficiency and accuracy of geological investigations.",
    "summary": "arXiv:2501.06184v1 Announce Type: cross Abstract: Geologic map, as a fundamental diagram in geology science, provides critical insights into the structure and composition of Earth's subsurface and surface. These maps are indispensable in various fields, including disaster detection, resource exploration, and civil engineering. Despite their significance, current Multimodal Large Language Models (MLLMs) often fall short in geologic map understanding. This gap is primarily due to the challenging nature of cartographic generalization, which involves handling high-resolution map, managing multiple associated components, and requiring domain-specific knowledge. To quantify this gap, we construct GeoMap-Bench, the first-ever benchmark for evaluating MLLMs in geologic map understanding, which assesses the full-scale abilities in extracting, referring, grounding, reasoning, and analyzing. To bridge this gap, we introduce GeoMap-Agent, the inaugural agent designed for geologic map understanding, which features three modules: Hierarchical Information Extraction (HIE), Domain Knowledge Injection (DKI), and Prompt-enhanced Question Answering (PEQA). Inspired by the interdisciplinary collaboration among human scientists, an AI expert group acts as consultants, utilizing a diverse tool pool to comprehensively analyze questions. Through comprehensive experiments, GeoMap-Agent achieves an overall score of 0.811 on GeoMap-Bench, significantly outperforming 0.369 of GPT-4o. Our work, emPowering gEologic mAp holistiC undErstanding (PEACE) with MLLMs, paves the way for advanced AI applications in geology, enhancing the efficiency and accuracy of geological investigations.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.06184",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BenchmarkQED: Automated benchmarking of RAG systems",
    "description": "<p>BenchmarkQED is an open-source toolkit for benchmarking RAG systems using automated query generation, evaluation, and dataset prep. It shows that LazyGraphRAG outperforms standard methods, especially on complex, global queries.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/'>BenchmarkQED: Automated benchmarking of RAG systems</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>BenchmarkQED is an open-source toolkit for benchmarking RAG systems using automated query generation, evaluation, and dataset prep. It shows that LazyGraphRAG outperforms standard methods, especially on complex, global queries.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/'>BenchmarkQED: Automated benchmarking of RAG systems</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 05 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Hierarchical Reasoning Model",
    "description": "arXiv:2506.21734v1 Announce Type: new Abstract: Reasoning, the process of devising and executing complex goal-oriented action sequences, remains a critical challenge in AI. Current large language models (LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from brittle task decomposition, extensive data requirements, and high latency. Inspired by the hierarchical and multi-timescale processing in the human brain, we propose the Hierarchical Reasoning Model (HRM), a novel recurrent architecture that attains significant computational depth while maintaining both training stability and efficiency. HRM executes sequential reasoning tasks in a single forward pass without explicit supervision of the intermediate process, through two interdependent recurrent modules: a high-level module responsible for slow, abstract planning, and a low-level module handling rapid, detailed computations. With only 27 million parameters, HRM achieves exceptional performance on complex reasoning tasks using only 1000 training samples. The model operates without pre-training or CoT data, yet achieves nearly perfect performance on challenging tasks including complex Sudoku puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms much larger models with significantly longer context windows on the Abstraction and Reasoning Corpus (ARC), a key benchmark for measuring artificial general intelligence capabilities. These results underscore HRM's potential as a transformative advancement toward universal computation and general-purpose reasoning systems.",
    "summary": "arXiv:2506.21734v1 Announce Type: new Abstract: Reasoning, the process of devising and executing complex goal-oriented action sequences, remains a critical challenge in AI. Current large language models (LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from brittle task decomposition, extensive data requirements, and high latency. Inspired by the hierarchical and multi-timescale processing in the human brain, we propose the Hierarchical Reasoning Model (HRM), a novel recurrent architecture that attains significant computational depth while maintaining both training stability and efficiency. HRM executes sequential reasoning tasks in a single forward pass without explicit supervision of the intermediate process, through two interdependent recurrent modules: a high-level module responsible for slow, abstract planning, and a low-level module handling rapid, detailed computations. With only 27 million parameters, HRM achieves exceptional performance on complex reasoning tasks using only 1000 training samples. The model operates without pre-training or CoT data, yet achieves nearly perfect performance on challenging tasks including complex Sudoku puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms much larger models with significantly longer context windows on the Abstraction and Reasoning Corpus (ARC), a key benchmark for measuring artificial general intelligence capabilities. These results underscore HRM's potential as a transformative advancement toward universal computation and general-purpose reasoning systems.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21734",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The NLP Course is becoming the LLM Course!",
    "description": "",
    "summary": "The NLP Course is becoming the LLM Course! Education has always been at the heart of Hugging Face‚Äôs ...",
    "pubDate": "Thu, 03 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llm-course",
    "thumbnail": "https://huggingface.co/blog/assets/llm-course/llm-course-rename-thumbnail.png"
  },
  {
    "title": "VQ Diffusion with üß® Diffusers",
    "description": "",
    "summary": "VQ-Diffusion Vector Quantized Diffusion (VQ-Diffusion) is a conditional latent diffusion model devel...",
    "pubDate": "Wed, 30 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vq-diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/117_vq_diffusion/thumbnail.png"
  },
  {
    "title": "Federated Learning for MRI-based BrainAGE: a multicenter study on post-stroke functional outcome prediction",
    "description": "arXiv:2506.15626v2 Announce Type: replace-cross Abstract: $textbf{Objective:}$ Brain-predicted age difference (BrainAGE) is a neuroimaging biomarker reflecting brain health. However, training robust BrainAGE models requires large datasets, often restricted by privacy concerns. This study evaluates the performance of federated learning (FL) for BrainAGE estimation in ischemic stroke patients treated with mechanical thrombectomy, and investigates its association with clinical phenotypes and functional outcomes. $textbf{Methods:}$ We used FLAIR brain images from 1674 stroke patients across 16 hospital centers. We implemented standard machine learning and deep learning models for BrainAGE estimates under three data management strategies: centralized learning (pooled data), FL (local training at each site), and single-site learning. We reported prediction errors and examined associations between BrainAGE and vascular risk factors (e.g., diabetes mellitus, hypertension, smoking), as well as functional outcomes at three months post-stroke. Logistic regression evaluated BrainAGE's predictive value for these outcomes, adjusting for age, sex, vascular risk factors, stroke severity, time between MRI and arterial puncture, prior intravenous thrombolysis, and recanalisation outcome. $textbf{Results:}$ While centralized learning yielded the most accurate predictions, FL consistently outperformed single-site models. BrainAGE was significantly higher in patients with diabetes mellitus across all models. Comparisons between patients with good and poor functional outcomes, and multivariate predictions of these outcomes showed the significance of the association between BrainAGE and post-stroke recovery. $textbf{Conclusion:}$ FL enables accurate age predictions without data centralization. The strong association between BrainAGE, vascular risk factors, and post-stroke recovery highlights its potential for prognostic modeling in stroke care.",
    "summary": "arXiv:2506.15626v2 Announce Type: replace-cross Abstract: $textbf{Objective:}$ Brain-predicted age difference (BrainAGE) is a neuroimaging biomarker reflecting brain health. However, training robust BrainAGE models requires large datasets, often restricted by privacy concerns. This study evaluates the performance of federated learning (FL) for BrainAGE estimation in ischemic stroke patients treated with mechanical thrombectomy, and investigates its association with clinical phenotypes and functional outcomes. $textbf{Methods:}$ We used FLAIR brain images from 1674 stroke patients across 16 hospital centers. We implemented standard machine learning and deep learning models for BrainAGE estimates under three data management strategies: centralized learning (pooled data), FL (local training at each site), and single-site learning. We reported prediction errors and examined associations between BrainAGE and vascular risk factors (e.g., diabetes mellitus, hypertension, smoking), as well as functional outcomes at three months post-stroke. Logistic regression evaluated BrainAGE's predictive value for these outcomes, adjusting for age, sex, vascular risk factors, stroke severity, time between MRI and arterial puncture, prior intravenous thrombolysis, and recanalisation outcome. $textbf{Results:}$ While centralized learning yielded the most accurate predictions, FL consistently outperformed single-site models. BrainAGE was significantly higher in patients with diabetes mellitus across all models. Comparisons between patients with good and poor functional outcomes, and multivariate predictions of these outcomes showed the significance of the association between BrainAGE and post-stroke recovery. $textbf{Conclusion:}$ FL enables accurate age predictions without data centralization. The strong association between BrainAGE, vascular risk factors, and post-stroke recovery highlights its potential for prognostic modeling in stroke care.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15626",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GBGC: Efficient and Adaptive Graph Coarsening via Granular-ball Computing",
    "description": "arXiv:2506.19224v1 Announce Type: new Abstract: The objective of graph coarsening is to generate smaller, more manageable graphs while preserving key information of the original graph. Previous work were mainly based on the perspective of spectrum-preserving, using some predefined coarsening rules to make the eigenvalues of the Laplacian matrix of the original graph and the coarsened graph match as much as possible. However, they largely overlooked the fact that the original graph is composed of subregions at different levels of granularity, where highly connected and similar nodes should be more inclined to be aggregated together as nodes in the coarsened graph. By combining the multi-granularity characteristics of the graph structure, we can generate coarsened graph at the optimal granularity. To this end, inspired by the application of granular-ball computing in multi-granularity, we propose a new multi-granularity, efficient, and adaptive coarsening method via granular-ball (GBGC), which significantly improves the coarsening results and efficiency. Specifically, GBGC introduces an adaptive granular-ball graph refinement mechanism, which adaptively splits the original graph from coarse to fine into granular-balls of different sizes and optimal granularity, and constructs the coarsened graph using these granular-balls as supernodes. In addition, compared with other state-of-the-art graph coarsening methods, the processing speed of this method can be increased by tens to hundreds of times and has lower time complexity. The accuracy of GBGC is almost always higher than that of the original graph due to the good robustness and generalization of the granular-ball computing, so it has the potential to become a standard graph data preprocessing method.",
    "summary": "arXiv:2506.19224v1 Announce Type: new Abstract: The objective of graph coarsening is to generate smaller, more manageable graphs while preserving key information of the original graph. Previous work were mainly based on the perspective of spectrum-preserving, using some predefined coarsening rules to make the eigenvalues of the Laplacian matrix of the original graph and the coarsened graph match as much as possible. However, they largely overlooked the fact that the original graph is composed of subregions at different levels of granularity, where highly connected and similar nodes should be more inclined to be aggregated together as nodes in the coarsened graph. By combining the multi-granularity characteristics of the graph structure, we can generate coarsened graph at the optimal granularity. To this end, inspired by the application of granular-ball computing in multi-granularity, we propose a new multi-granularity, efficient, and adaptive coarsening method via granular-ball (GBGC), which significantly improves the coarsening results and efficiency. Specifically, GBGC introduces an adaptive granular-ball graph refinement mechanism, which adaptively splits the original graph from coarse to fine into granular-balls of different sizes and optimal granularity, and constructs the coarsened graph using these granular-balls as supernodes. In addition, compared with other state-of-the-art graph coarsening methods, the processing speed of this method can be increased by tens to hundreds of times and has lower time complexity. The accuracy of GBGC is almost always higher than that of the original graph due to the good robustness and generalization of the granular-ball computing, so it has the potential to become a standard graph data preprocessing method.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19224",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Share your open ML datasets on Hugging Face Hub!",
    "description": "",
    "summary": "Share your open ML datasets on Hugging Face Hub! If you're working on data-intensive research or mac...",
    "pubDate": "Tue, 12 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/researcher-dataset-sharing",
    "thumbnail": "https://huggingface.co/blog/assets/researcher-dataset-sharing/thumbnail.png"
  },
  {
    "title": "SearchGPT is a prototype of new AI search features",
    "description": "We‚Äôre testing SearchGPT, a temporary prototype of new search features that give you fast and timely answers with clear and relevant sources.",
    "summary": "We‚Äôre testing SearchGPT, a temporary prototype of new search features that give you fast and timely answers with clear and relevant sources.",
    "pubDate": "Thu, 25 Jul 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/searchgpt-prototype",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing NextGenAI",
    "description": "OpenAI commits $50M in funding and tools to leading institutions.",
    "summary": "OpenAI commits $50M in funding and tools to leading institutions.",
    "pubDate": "Tue, 04 Mar 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-nextgenai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Implicit generation and generalization methods for energy-based models",
    "description": "We‚Äôve made progress towards stable and scalable training of¬†energy-based models¬†(EBMs) resulting in better sample quality and generalization ability than existing models. Generation in EBMs spends more compute to continually refine its answers and doing so can generate samples competitive with¬†GANs¬†at low temperatures,¬†while also having mode coverage guarantees of¬†likelihood-based models. We hope these findings stimulate further research into this promising class of¬†models.",
    "summary": "We‚Äôve made progress towards stable and scalable training of¬†energy-based models¬†(EBMs) resulting in better sample quality and generalization ability than existing models. Generation in EBMs spends more compute to continually refine its answers and doing so can generate samples competitive with¬†GANs¬†at low temperatures,¬†while also having mode coverage guarantees of¬†likelihood-based models. We hope these findings stimulate further research into this promising class of¬†models.",
    "pubDate": "Thu, 21 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/energy-based-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Subscribe to Enterprise Hub with your AWS Account",
    "description": "",
    "summary": "Subscribe to Enterprise Hub with your AWS Account You can now upgrade your Hugging Face Organization...",
    "pubDate": "Thu, 09 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/enterprise-hub-aws-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/158_aws_marketplace/thumbnail.jpg"
  },
  {
    "title": "Preparing for future AI risks in biology",
    "description": "Advanced AI can transform biology and medicine‚Äîbut also raises biosecurity risks. We‚Äôre proactively assessing capabilities and implementing safeguards to prevent misuse.",
    "summary": "Advanced AI can transform biology and medicine‚Äîbut also raises biosecurity risks. We‚Äôre proactively assessing capabilities and implementing safeguards to prevent misuse.",
    "pubDate": "Wed, 18 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/preparing-for-future-ai-capabilities-in-biology",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ÁîüÊàêAI„ÅåÂ§â„Åà„ÇãÊ∂àË≤ªËÄÖ„Å®„ÅÆ„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥„ÄÄÂçöÂ†±Â†Ç„Ç∞„É´„Éº„Éó„ÅÆÊ¥ªÁî®‰æã„ÄÄ‰ºÅÊ•≠„ÅåÈÖçÊÖÆ„Åô„Åπ„Åç3„Å§„ÅÆ„Éù„Ç§„É≥„Éà",
    "description": "ÂçöÂ†±Â†Ç„Ç∞„É´„Éº„Éó„ÅÆÁ∑èÂêàÂà∂‰Ωú‰∫ãÊ•≠‰ºöÁ§æ„Åß„ÅÇ„ÇãÂçöÂ†±Â†Ç„Éó„É≠„ÉÄ„ÇØ„ÉÑ„ÅØ„ÄÅÁîüÊàêAIÊäÄË°ì„ÇíÂäπÁéáÂåñÊâãÊÆµ„Å®„Åô„Çã„ÅÆ„Åß„ÅØ„Å™„Åè„ÄÅÁîüÊ¥ªËÄÖ„Å®Êñ∞„Åü„Å™Êé•ÁÇπ„ÇíÁîü„ÅøÂá∫„Åô„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„ÉÑ„Éº„É´„Å®„Åó„Å¶Ê¥ªÁî®„Åó„Å¶„ÅÑ„Çã„ÄÇÂÆüÈöõ„ÅÆ„Éû„Éº„Ç±„ÉÜ„Ç£„É≥„Ç∞ÁèæÂ†¥„Å´„Åä„Åë„ÇãÁîüÊàêAIÊ¥ªÁî®„ÅÆ‰æã„ÇíÁ¥π‰ªã„Åô„Çã„ÄÇ",
    "summary": "ÂçöÂ†±Â†Ç„Ç∞„É´„Éº„Éó„ÅÆÁ∑èÂêàÂà∂‰Ωú‰∫ãÊ•≠‰ºöÁ§æ„Åß„ÅÇ„ÇãÂçöÂ†±Â†Ç„Éó„É≠„ÉÄ„ÇØ„ÉÑ„ÅØ„ÄÅÁîüÊàêAIÊäÄË°ì„ÇíÂäπÁéáÂåñÊâãÊÆµ„Å®„Åô„Çã„ÅÆ„Åß„ÅØ„Å™„Åè„ÄÅÁîüÊ¥ªËÄÖ„Å®Êñ∞„Åü„Å™Êé•ÁÇπ„ÇíÁîü„ÅøÂá∫„Åô„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„ÉÑ„Éº„É´„Å®„Åó„Å¶Ê¥ªÁî®„Åó„Å¶„ÅÑ„Çã„ÄÇÂÆüÈöõ„ÅÆ„Éû„Éº„Ç±„ÉÜ„Ç£„É≥„Ç∞ÁèæÂ†¥„Å´„Åä„Åë„ÇãÁîüÊàêAIÊ¥ªÁî®„ÅÆ‰æã„ÇíÁ¥π‰ªã„Åô„Çã„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 12:28:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/30/news023.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/30/cover_news023.jpg"
  },
  {
    "title": "„Äå‰ºÅÊ•≠„ÅÆ‰∏ª‰Ωì„ÅØ„Éí„Éà„Åã„ÇâAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„Å´„ÄçPwC„ÅåÁîüÊàêAI„ÅÆÊäÄË°ìÂãïÂêë„ÇíÂàÜÊûê",
    "description": "PwC„Ç≥„É≥„Çµ„É´„ÉÜ„Ç£„É≥„Ç∞„ÅØ„ÄÅ„ÄåÁîüÊàêAI„ÅÆÂ∞ÜÊù•ÊäÄË°ìÂãïÂêë„Äç„Å®È°å„Åó„Åü„É¨„Éù„Éº„Éà„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÁèæÂú®„ÅÆLLM„ÅåÊä±„Åà„ÇãÊäÄË°ìÁöÑ„Å™Ë™≤È°å„Å®„Åù„ÅÆÂÖãÊúç„Å´Âêë„Åë„ÅüÈÄ≤Âåñ„ÅÆÊñπÂêëÊÄß„Å™„Å©„Å´„Å§„ÅÑ„Å¶ÂàÜÊûê„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "PwC„Ç≥„É≥„Çµ„É´„ÉÜ„Ç£„É≥„Ç∞„ÅØ„ÄÅ„ÄåÁîüÊàêAI„ÅÆÂ∞ÜÊù•ÊäÄË°ìÂãïÂêë„Äç„Å®È°å„Åó„Åü„É¨„Éù„Éº„Éà„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÁèæÂú®„ÅÆLLM„ÅåÊä±„Åà„ÇãÊäÄË°ìÁöÑ„Å™Ë™≤È°å„Å®„Åù„ÅÆÂÖãÊúç„Å´Âêë„Åë„ÅüÈÄ≤Âåñ„ÅÆÊñπÂêëÊÄß„Å™„Å©„Å´„Å§„ÅÑ„Å¶ÂàÜÊûê„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Mon, 23 Jun 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://atmarkit.itmedia.co.jp/ait/articles/2506/23/news025.html",
    "thumbnail": "https://image.itmedia.co.jp/ait/articles/2506/23/cover_news025.jpg"
  },
  {
    "title": "Hybrid AI model crafts smooth, high-quality videos in seconds",
    "description": "The CausVid generative AI tool uses a diffusion model to teach an autoregressive (frame-by-frame) system to rapidly produce stable, high-resolution videos.",
    "summary": "The CausVid generative AI tool uses a diffusion model to teach an autoregressive (frame-by-frame) system to rapidly produce stable, high-resolution videos.",
    "pubDate": "Tue, 06 May 2025 12:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/causevid-hybrid-ai-model-crafts-smooth-high-quality-videos-in-seconds-0506",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-CausVid.jpg"
  },
  {
    "title": "Align and Distill: Unifying and Improving Domain Adaptive Object Detection",
    "description": "arXiv:2403.12029v4 Announce Type: replace-cross Abstract: Object detectors often perform poorly on data that differs from their training set. Domain adaptive object detection (DAOD) methods have recently demonstrated strong results on addressing this challenge. Unfortunately, we identify systemic benchmarking pitfalls that call past results into question and hamper further progress: (a) Overestimation of performance due to underpowered baselines, (b) Inconsistent implementation practices preventing transparent comparisons of methods, and (c) Lack of generality due to outdated backbones and lack of diversity in benchmarks. We address these problems by introducing: (1) A unified benchmarking and implementation framework, Align and Distill (ALDI), enabling comparison of DAOD methods and supporting future development, (2) A fair and modern training and evaluation protocol for DAOD that addresses benchmarking pitfalls, (3) A new DAOD benchmark dataset, CFC-DAOD, enabling evaluation on diverse real-world data, and (4) A new method, ALDI++, that achieves state-of-the-art results by a large margin. ALDI++ outperforms the previous state-of-the-art by +3.5 AP50 on Cityscapes to Foggy Cityscapes, +5.7 AP50 on Sim10k to Cityscapes (where ours is the only method to outperform a fair baseline), and +0.6 AP50 on CFC Kenai to Channel. ALDI and ALDI++ are architecture-agnostic, setting a new state-of-the-art for YOLO and DETR-based DAOD as well without additional hyperparameter tuning. Our framework, dataset, and state-of-the-art method offer a critical reset for DAOD and provide a strong foundation for future research. Code and data are available: https://github.com/justinkay/aldi and https://github.com/visipedia/caltech-fish-counting.",
    "summary": "arXiv:2403.12029v4 Announce Type: replace-cross Abstract: Object detectors often perform poorly on data that differs from their training set. Domain adaptive object detection (DAOD) methods have recently demonstrated strong results on addressing this challenge. Unfortunately, we identify systemic benchmarking pitfalls that call past results into question and hamper further progress: (a) Overestimation of performance due to underpowered baselines, (b) Inconsistent implementation practices preventing transparent comparisons of methods, and (c) Lack of generality due to outdated backbones and lack of diversity in benchmarks. We address these problems by introducing: (1) A unified benchmarking and implementation framework, Align and Distill (ALDI), enabling comparison of DAOD methods and supporting future development, (2) A fair and modern training and evaluation protocol for DAOD that addresses benchmarking pitfalls, (3) A new DAOD benchmark dataset, CFC-DAOD, enabling evaluation on diverse real-world data, and (4) A new method, ALDI++, that achieves state-of-the-art results by a large margin. ALDI++ outperforms the previous state-of-the-art by +3.5 AP50 on Cityscapes to Foggy Cityscapes, +5.7 AP50 on Sim10k to Cityscapes (where ours is the only method to outperform a fair baseline), and +0.6 AP50 on CFC Kenai to Channel. ALDI and ALDI++ are architecture-agnostic, setting a new state-of-the-art for YOLO and DETR-based DAOD as well without additional hyperparameter tuning. Our framework, dataset, and state-of-the-art method offer a critical reset for DAOD and provide a strong foundation for future research. Code and data are available: https://github.com/justinkay/aldi and https://github.com/visipedia/caltech-fish-counting.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2403.12029",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Automatic Prompt Optimization for Knowledge Graph Construction: Insights from an Empirical Study",
    "description": "arXiv:2506.19773v1 Announce Type: new Abstract: A KG represents a network of entities and illustrates relationships between them. KGs are used for various applications, including semantic search and discovery, reasoning, decision-making, natural language processing, machine learning, and recommendation systems. Triple (subject-relation-object) extraction from text is the fundamental building block of KG construction and has been widely studied, for example, in early benchmarks such as ACE 2002 to more recent ones, such as WebNLG 2020, REBEL and SynthIE. While the use of LLMs is explored for KG construction, handcrafting reasonable task-specific prompts for LLMs is a labour-intensive exercise and can be brittle due to subtle changes in the LLM models employed. Recent work in NLP tasks (e.g. autonomy generation) uses automatic prompt optimization/engineering to address this challenge by generating optimal or near-optimal task-specific prompts given input-output examples. This empirical study explores the application of automatic prompt optimization for the triple extraction task using experimental benchmarking. We evaluate different settings by changing (a) the prompting strategy, (b) the LLM being used for prompt optimization and task execution, (c) the number of canonical relations in the schema (schema complexity), (d) the length and diversity of input text, (e) the metric used to drive the prompt optimization, and (f) the dataset being used for training and testing. We evaluate three different automatic prompt optimizers, namely, DSPy, APE, and TextGrad and use two different triple extraction datasets, SynthIE and REBEL. Through rigorous empirical evaluation, our main contribution highlights that automatic prompt optimization techniques can generate reasonable prompts similar to humans for triple extraction. In turn, these optimized prompts achieve improved results, particularly with increasing schema complexity and text size.",
    "summary": "arXiv:2506.19773v1 Announce Type: new Abstract: A KG represents a network of entities and illustrates relationships between them. KGs are used for various applications, including semantic search and discovery, reasoning, decision-making, natural language processing, machine learning, and recommendation systems. Triple (subject-relation-object) extraction from text is the fundamental building block of KG construction and has been widely studied, for example, in early benchmarks such as ACE 2002 to more recent ones, such as WebNLG 2020, REBEL and SynthIE. While the use of LLMs is explored for KG construction, handcrafting reasonable task-specific prompts for LLMs is a labour-intensive exercise and can be brittle due to subtle changes in the LLM models employed. Recent work in NLP tasks (e.g. autonomy generation) uses automatic prompt optimization/engineering to address this challenge by generating optimal or near-optimal task-specific prompts given input-output examples. This empirical study explores the application of automatic prompt optimization for the triple extraction task using experimental benchmarking. We evaluate different settings by changing (a) the prompting strategy, (b) the LLM being used for prompt optimization and task execution, (c) the number of canonical relations in the schema (schema complexity), (d) the length and diversity of input text, (e) the metric used to drive the prompt optimization, and (f) the dataset being used for training and testing. We evaluate three different automatic prompt optimizers, namely, DSPy, APE, and TextGrad and use two different triple extraction datasets, SynthIE and REBEL. Through rigorous empirical evaluation, our main contribution highlights that automatic prompt optimization techniques can generate reasonable prompts similar to humans for triple extraction. In turn, these optimized prompts achieve improved results, particularly with increasing schema complexity and text size.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19773",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DuckDB: run SQL queries on 50,000+ datasets on the Hugging Face Hub",
    "description": "",
    "summary": "DuckDB: run SQL queries on 50,000+ datasets on the Hugging Face Hub The Hugging Face Hub is dedicate...",
    "pubDate": "Wed, 07 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hub-duckdb",
    "thumbnail": "https://huggingface.co/blog/assets/hub_duckdb/hub_duckdb.png"
  },
  {
    "title": "OpenAI o1 Contributions",
    "description": "OpenAI o1 Contributions",
    "summary": "OpenAI o1 Contributions",
    "pubDate": "Thu, 12 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/openai-o1-contributions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An anomaly detection framework anyone can use",
    "description": "PhD student Sarah Alnegheimish wants to make machine learning systems accessible.",
    "summary": "PhD student Sarah Alnegheimish wants to make machine learning systems accessible.",
    "pubDate": "Wed, 28 May 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/anomaly-detection-framework-anyone-can-use-sarah-alnegheimish-0528",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Sarah-Abdulaziz-Alnegheimish.JPG"
  },
  {
    "title": "Testimony before the U.S. Senate",
    "description": "The following is the written testimony of Sam Altman, Chief Executive Officer of OpenAI, before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "summary": "The following is the written testimony of Sam Altman, Chief Executive Officer of OpenAI, before the U.S. Senate Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/testimony-of-sam-altman-before-the-us-senate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Can Large Language Models Capture Human Annotator Disagreements?",
    "description": "arXiv:2506.19467v1 Announce Type: cross Abstract: Human annotation variation (i.e., annotation disagreements) is common in NLP and often reflects important information such as task subjectivity and sample ambiguity. While Large Language Models (LLMs) are increasingly used for automatic annotation to reduce human effort, their evaluation often focuses on predicting the majority-voted 'ground truth' labels. It is still unclear, however, whether these models also capture informative human annotation variation. Our work addresses this gap by extensively evaluating LLMs' ability to predict annotation disagreements without access to repeated human labels. Our results show that LLMs struggle with modeling disagreements, which can be overlooked by majority label-based evaluations. Notably, while RLVR-style (Reinforcement learning with verifiable rewards) reasoning generally boosts LLM performance, it degrades performance in disagreement prediction. Our findings highlight the critical need for evaluating and improving LLM annotators in disagreement modeling. Code and data at https://github.com/EdisonNi-hku/Disagreement_Prediction.",
    "summary": "arXiv:2506.19467v1 Announce Type: cross Abstract: Human annotation variation (i.e., annotation disagreements) is common in NLP and often reflects important information such as task subjectivity and sample ambiguity. While Large Language Models (LLMs) are increasingly used for automatic annotation to reduce human effort, their evaluation often focuses on predicting the majority-voted 'ground truth' labels. It is still unclear, however, whether these models also capture informative human annotation variation. Our work addresses this gap by extensively evaluating LLMs' ability to predict annotation disagreements without access to repeated human labels. Our results show that LLMs struggle with modeling disagreements, which can be overlooked by majority label-based evaluations. Notably, while RLVR-style (Reinforcement learning with verifiable rewards) reasoning generally boosts LLM performance, it degrades performance in disagreement prediction. Our findings highlight the critical need for evaluating and improving LLM annotators in disagreement modeling. Code and data at https://github.com/EdisonNi-hku/Disagreement_Prediction.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19467",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accurately analyzing large scale qualitative data",
    "description": "Viable uses GPT-4 to analyze qualitative data at a revolutionary scale with unparalleled accuracy.",
    "summary": "Viable uses GPT-4 to analyze qualitative data at a revolutionary scale with unparalleled accuracy.",
    "pubDate": "Fri, 07 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/viable",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI-Facilitated Episodic Future Thinking For Adults with Obesity",
    "description": "arXiv:2503.16484v2 Announce Type: replace-cross Abstract: Episodic Future Thinking (EFT) involves vividly imagining personal future events and experiences in detail. It has shown promise as an intervention to reduce delay discounting-the tendency to devalue delayed rewards in favor of immediate gratification- and to promote behavior change in a range of maladaptive health behaviors. We present EFTeacher, an AI chatbot powered by the GPT-4-Turbo large language model, designed to generate EFT cues for users with lifestyle-related conditions. To evaluate the feasibility and usability of EFTeacher, we conducted a mixed-methods study that included usability assessments, user evaluations based on content characteristics questionnaires, and semi-structured interviews. Qualitative findings indicate that participants perceived EFTeacher as communicative and supportive through an engaging dialogue. The chatbot facilitated imaginative thinking and reflection on future goals. Participants appreciated its adaptability and personalization features, though some noted challenges such as repetitive dialogue and verbose responses. Our findings underscore the potential of large language model-based chatbots in EFT interventions targeting maladaptive health behaviors.",
    "summary": "arXiv:2503.16484v2 Announce Type: replace-cross Abstract: Episodic Future Thinking (EFT) involves vividly imagining personal future events and experiences in detail. It has shown promise as an intervention to reduce delay discounting-the tendency to devalue delayed rewards in favor of immediate gratification- and to promote behavior change in a range of maladaptive health behaviors. We present EFTeacher, an AI chatbot powered by the GPT-4-Turbo large language model, designed to generate EFT cues for users with lifestyle-related conditions. To evaluate the feasibility and usability of EFTeacher, we conducted a mixed-methods study that included usability assessments, user evaluations based on content characteristics questionnaires, and semi-structured interviews. Qualitative findings indicate that participants perceived EFTeacher as communicative and supportive through an engaging dialogue. The chatbot facilitated imaginative thinking and reflection on future goals. Participants appreciated its adaptability and personalization features, though some noted challenges such as repetitive dialogue and verbose responses. Our findings underscore the potential of large language model-based chatbots in EFT interventions targeting maladaptive health behaviors.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.16484",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Running Privacy-Preserving Inference on Hugging Face Endpoints",
    "description": "",
    "summary": "Running Privacy-Preserving Inferences on Hugging Face Endpoints This is a guest blog post by the Zam...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fhe-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/fhe-endpoints/thumbnail.png"
  },
  {
    "title": "Êù±Ê≠¶„Éõ„ÉÜ„É´„ÅåÁõ¥Èù¢„Åô„Çã‰∫∫Êâã‰∏çË∂≥„ÄÄÁ§æÈï∑„ÅåÊèêÂî±„Åô„Çã„ÄåË¶≥ÂÖâÊ•≠Áïå„ÅÆAIÊ¥ªÁî®„Äç",
    "description": "„Éõ„ÉÜ„É´Ê•≠Áïå„ÅØ‰∫∫Êâã‰∏çË∂≥„ÇÑDX„ÅÆË™≤È°å„Å´„Å©„ÅÜÂêë„ÅçÂêà„Åà„Å∞„Çà„ÅÑ„ÅÆ„Åã„ÄÇÊù±Ê≠¶„Éõ„ÉÜ„É´„Éû„Éç„Ç∏„É°„É≥„Éà„ÅÆ‰∏âËº™Ë£ïÁ´†Á§æÈï∑„Å´„ÄÅ„Éõ„ÉÜ„É´ÁµåÂñ∂„ÅÆÁèæÂ†¥„ÅßÁõ¥Èù¢„Åô„ÇãË™≤È°å„Å®„ÄÅ„Åù„ÅÆÊâìÈñãÁ≠ñ„ÇíËÅû„ÅÑ„Åü„ÄÇ",
    "summary": "„Éõ„ÉÜ„É´Ê•≠Áïå„ÅØ‰∫∫Êâã‰∏çË∂≥„ÇÑDX„ÅÆË™≤È°å„Å´„Å©„ÅÜÂêë„ÅçÂêà„Åà„Å∞„Çà„ÅÑ„ÅÆ„Åã„ÄÇÊù±Ê≠¶„Éõ„ÉÜ„É´„Éû„Éç„Ç∏„É°„É≥„Éà„ÅÆ‰∏âËº™Ë£ïÁ´†Á§æÈï∑„Å´„ÄÅ„Éõ„ÉÜ„É´ÁµåÂñ∂„ÅÆÁèæÂ†¥„ÅßÁõ¥Èù¢„Åô„ÇãË™≤È°å„Å®„ÄÅ„Åù„ÅÆÊâìÈñãÁ≠ñ„ÇíËÅû„ÅÑ„Åü„ÄÇ",
    "pubDate": "Tue, 24 Jun 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2506/24/news019.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2506/24/cover_news019.jpg"
  },
  {
    "title": "The receptron is a nonlinear threshold logic gate with intrinsic multi-dimensional selective capabilities for analog inputs",
    "description": "arXiv:2506.19642v1 Announce Type: cross Abstract: Threshold logic gates (TLGs) have been proposed as artificial counterparts of biological neurons with classification capabilities based on a linear predictor function combining a set of weights with the feature vector. The linearity of TLGs limits their classification capabilities requiring the use of networks for the accomplishment of complex tasks. A generalization of the TLG model called receptron, characterized by input-dependent weight functions allows for a significant enhancement of classification performances even with the use of a single unit. Here we formally demonstrate that a receptron, characterized by nonlinear input-dependent weight functions, exhibit intrinsic selective activation properties for analog inputs, when the input vector is within cubic domains in a 3D space. The proposed model can be extended to the n-dimensional case for multidimensional applications. Our results suggest that receptron-based networks can represent a new class of devices capable to manage a large number of analog inputs, for edge applications requiring high selectivity and classification capabilities without the burden of complex training.",
    "summary": "arXiv:2506.19642v1 Announce Type: cross Abstract: Threshold logic gates (TLGs) have been proposed as artificial counterparts of biological neurons with classification capabilities based on a linear predictor function combining a set of weights with the feature vector. The linearity of TLGs limits their classification capabilities requiring the use of networks for the accomplishment of complex tasks. A generalization of the TLG model called receptron, characterized by input-dependent weight functions allows for a significant enhancement of classification performances even with the use of a single unit. Here we formally demonstrate that a receptron, characterized by nonlinear input-dependent weight functions, exhibit intrinsic selective activation properties for analog inputs, when the input vector is within cubic domains in a 3D space. The proposed model can be extended to the n-dimensional case for multidimensional applications. Our results suggest that receptron-based networks can represent a new class of devices capable to manage a large number of analog inputs, for edge applications requiring high selectivity and classification capabilities without the burden of complex training.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19642",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using & Mixing Hugging Face Models with Gradio 2.0",
    "description": "",
    "summary": "Using & Mixing Hugging Face Models with Gradio 2.0 Cross-posted from the Gradio blog. The Hugging Fa...",
    "pubDate": "Tue, 25 May 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio",
    "thumbnail": "https://huggingface.co/blog/assets/22_gradio/gradio.png"
  },
  {
    "title": "Overview of natively supported quantization schemes in ü§ó Transformers",
    "description": "",
    "summary": "Overview of natively supported quantization schemes in ü§ó Transformers We aim to give a clear overvie...",
    "pubDate": "Tue, 12 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/overview-quantization-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/163_overview_quantization_transformers/thumbnail.jpg"
  },
  {
    "title": "Agentic Personalisation of Cross-Channel Marketing Experiences",
    "description": "arXiv:2506.16429v1 Announce Type: new Abstract: Consumer applications provide ample opportunities to surface and communicate various forms of content to users. From promotional campaigns for new features or subscriptions, to evergreen nudges for engagement, or personalised recommendations; across e-mails, push notifications, and in-app surfaces. The conventional approach to orchestration for communication relies heavily on labour-intensive manual marketer work, and inhibits effective personalisation of content, timing, frequency, and copy-writing. We formulate this task under a sequential decision-making framework, where we aim to optimise a modular decision-making policy that maximises incremental engagement for any funnel event. Our approach leverages a Difference-in-Differences design for Individual Treatment Effect estimation, and Thompson sampling to balance the explore-exploit trade-off. We present results from a multi-service application, where our methodology has resulted in significant increases to a variety of goal events across several product features, and is currently deployed across 150 million users.",
    "summary": "arXiv:2506.16429v1 Announce Type: new Abstract: Consumer applications provide ample opportunities to surface and communicate various forms of content to users. From promotional campaigns for new features or subscriptions, to evergreen nudges for engagement, or personalised recommendations; across e-mails, push notifications, and in-app surfaces. The conventional approach to orchestration for communication relies heavily on labour-intensive manual marketer work, and inhibits effective personalisation of content, timing, frequency, and copy-writing. We formulate this task under a sequential decision-making framework, where we aim to optimise a modular decision-making policy that maximises incremental engagement for any funnel event. Our approach leverages a Difference-in-Differences design for Individual Treatment Effect estimation, and Thompson sampling to balance the explore-exploit trade-off. We present results from a multi-service application, where our methodology has resulted in significant increases to a variety of goal events across several product features, and is currently deployed across 150 million users.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16429",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MIT Department of Economics to launch James M. and Cathleen D. Stone Center on Inequality and Shaping the Future of Work",
    "description": "With support from the Stone Foundation, the center will advance cutting-edge research and inform policy.",
    "summary": "With support from the Stone Foundation, the center will advance cutting-edge research and inform policy.",
    "pubDate": "Tue, 13 May 2025 16:35:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-economics-department-launches-james-cathleen-stone-center-inequality-shaping-future-work-0513",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-campus.jpg"
  },
  {
    "title": "OpenAI‚Äôs Approach to Frontier Risk",
    "description": "An Update for the UK AI Safety Summit",
    "summary": "An Update for the UK AI Safety Summit",
    "pubDate": "Thu, 26 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/our-approach-to-frontier-risk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Survey of Multi-sensor Fusion Perception for Embodied AI: Background, Methods, Challenges and Prospects",
    "description": "arXiv:2506.19769v1 Announce Type: cross Abstract: Multi-sensor fusion perception (MSFP) is a key technology for embodied AI, which can serve a variety of downstream tasks (e.g., 3D object detection and semantic segmentation) and application scenarios (e.g., autonomous driving and swarm robotics). Recently, impressive achievements on AI-based MSFP methods have been reviewed in relevant surveys. However, we observe that the existing surveys have some limitations after a rigorous and detailed investigation. For one thing, most surveys are oriented to a single task or research field, such as 3D object detection or autonomous driving. Therefore, researchers in other related tasks often find it difficult to benefit directly. For another, most surveys only introduce MSFP from a single perspective of multi-modal fusion, while lacking consideration of the diversity of MSFP methods, such as multi-view fusion and time-series fusion. To this end, in this paper, we hope to organize MSFP research from a task-agnostic perspective, where methods are reported from various technical views. Specifically, we first introduce the background of MSFP. Next, we review multi-modal and multi-agent fusion methods. A step further, time-series fusion methods are analyzed. In the era of LLM, we also investigate multimodal LLM fusion methods. Finally, we discuss open challenges and future directions for MSFP. We hope this survey can help researchers understand the important progress in MSFP and provide possible insights for future research.",
    "summary": "arXiv:2506.19769v1 Announce Type: cross Abstract: Multi-sensor fusion perception (MSFP) is a key technology for embodied AI, which can serve a variety of downstream tasks (e.g., 3D object detection and semantic segmentation) and application scenarios (e.g., autonomous driving and swarm robotics). Recently, impressive achievements on AI-based MSFP methods have been reviewed in relevant surveys. However, we observe that the existing surveys have some limitations after a rigorous and detailed investigation. For one thing, most surveys are oriented to a single task or research field, such as 3D object detection or autonomous driving. Therefore, researchers in other related tasks often find it difficult to benefit directly. For another, most surveys only introduce MSFP from a single perspective of multi-modal fusion, while lacking consideration of the diversity of MSFP methods, such as multi-view fusion and time-series fusion. To this end, in this paper, we hope to organize MSFP research from a task-agnostic perspective, where methods are reported from various technical views. Specifically, we first introduce the background of MSFP. Next, we review multi-modal and multi-agent fusion methods. A step further, time-series fusion methods are analyzed. In the era of LLM, we also investigate multimodal LLM fusion methods. Finally, we discuss open challenges and future directions for MSFP. We hope this survey can help researchers understand the important progress in MSFP and provide possible insights for future research.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19769",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "UK government harnesses Gemini to support faster planning decisions",
    "description": "A summary of how Extract works",
    "summary": "A summary of how Extract works",
    "pubDate": "Mon, 09 Jun 2025 11:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/around-the-globe/google-europe/united-kingdom/uk-government-harnesses-gemini-to-support-faster-planning-decisions/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/overview.width-1300.png"
  },
  {
    "title": "Response to NIST Executive Order on AI",
    "description": "The National Institute of Standards and Technology (NIST) request for information related to its assignments under sections 4.1, 4.5, and 11 of the Executive Order Concerning Artificial Intelligence",
    "summary": "The National Institute of Standards and Technology (NIST) request for information related to its assignments under sections 4.1, 4.5, and 11 of the Executive Order Concerning Artificial Intelligence",
    "pubDate": "Fri, 02 Feb 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-nist-executive-order-on-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MIT‚Äôs McGovern Institute is shaping brain science and improving human lives on a global scale",
    "description": "A quarter century after its founding, the McGovern Institute reflects on its discoveries in the areas of neuroscience, neurotechnology, artificial intelligence, brain-body connections, and therapeutics.",
    "summary": "A quarter century after its founding, the McGovern Institute reflects on its discoveries in the areas of neuroscience, neurotechnology, artificial intelligence, brain-body connections, and therapeutics.",
    "pubDate": "Fri, 18 Apr 2025 10:40:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-mcgovern-institute-shaping-brain-science-improving-human-lives-0418",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-mcgovern-madonna-fmri-600x900.jpg"
  },
  {
    "title": "In-Context Occam's Razor: How Transformers Prefer Simpler Hypotheses on the Fly",
    "description": "arXiv:2506.19351v1 Announce Type: cross Abstract: In-context learning (ICL) enables transformers to adapt to new tasks through contextual examples without parameter updates. While existing research has typically studied ICL in fixed-complexity environments, practical language models encounter tasks spanning diverse complexity levels. This paper investigates how transformers navigate hierarchical task structures where higher-complexity categories can perfectly represent any pattern generated by simpler ones. We design well-controlled testbeds based on Markov chains and linear regression that reveal transformers not only identify the appropriate complexity level for each task but also accurately infer the corresponding parameters--even when the in-context examples are compatible with multiple complexity hypotheses. Notably, when presented with data generated by simpler processes, transformers consistently favor the least complex sufficient explanation. We theoretically explain this behavior through a Bayesian framework, demonstrating that transformers effectively implement an in-context Bayesian Occam's razor by balancing model fit against complexity penalties. We further ablate on the roles of model size, training mixture distribution, inference context length, and architecture. Finally, we validate this Occam's razor-like inductive bias on a pretrained GPT-4 model with Boolean-function tasks as case study, suggesting it may be inherent to transformers trained on diverse task distributions.",
    "summary": "arXiv:2506.19351v1 Announce Type: cross Abstract: In-context learning (ICL) enables transformers to adapt to new tasks through contextual examples without parameter updates. While existing research has typically studied ICL in fixed-complexity environments, practical language models encounter tasks spanning diverse complexity levels. This paper investigates how transformers navigate hierarchical task structures where higher-complexity categories can perfectly represent any pattern generated by simpler ones. We design well-controlled testbeds based on Markov chains and linear regression that reveal transformers not only identify the appropriate complexity level for each task but also accurately infer the corresponding parameters--even when the in-context examples are compatible with multiple complexity hypotheses. Notably, when presented with data generated by simpler processes, transformers consistently favor the least complex sufficient explanation. We theoretically explain this behavior through a Bayesian framework, demonstrating that transformers effectively implement an in-context Bayesian Occam's razor by balancing model fit against complexity penalties. We further ablate on the roles of model size, training mixture distribution, inference context length, and architecture. Finally, we validate this Occam's razor-like inductive bias on a pretrained GPT-4 model with Boolean-function tasks as case study, suggesting it may be inherent to transformers trained on diverse task distributions.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19351",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark",
    "description": "arXiv:2412.15194v1 Announce Type: cross Abstract: Multiple-choice question (MCQ) datasets like Massive Multitask Language Understanding (MMLU) are widely used to evaluate the commonsense, understanding, and problem-solving abilities of large language models (LLMs). However, the open-source nature of these benchmarks and the broad sources of training data for LLMs have inevitably led to benchmark contamination, resulting in unreliable evaluation results. To alleviate this issue, we propose a contamination-free and more challenging MCQ benchmark called MMLU-CF. This benchmark reassesses LLMs' understanding of world knowledge by averting both unintentional and malicious data leakage. To avoid unintentional data leakage, we source data from a broader domain and design three decontamination rules. To prevent malicious data leakage, we divide the benchmark into validation and test sets with similar difficulty and subject distributions. The test set remains closed-source to ensure reliable results, while the validation set is publicly available to promote transparency and facilitate independent verification. Our evaluation of mainstream LLMs reveals that the powerful GPT-4o achieves merely a 5-shot score of 73.4% and a 0-shot score of 71.9% on the test set, which indicates the effectiveness of our approach in creating a more rigorous and contamination-free evaluation standard. The GitHub repository is available at https://github.com/microsoft/MMLU-CF and the dataset refers to https://huggingface.co/datasets/microsoft/MMLU-CF.",
    "summary": "arXiv:2412.15194v1 Announce Type: cross Abstract: Multiple-choice question (MCQ) datasets like Massive Multitask Language Understanding (MMLU) are widely used to evaluate the commonsense, understanding, and problem-solving abilities of large language models (LLMs). However, the open-source nature of these benchmarks and the broad sources of training data for LLMs have inevitably led to benchmark contamination, resulting in unreliable evaluation results. To alleviate this issue, we propose a contamination-free and more challenging MCQ benchmark called MMLU-CF. This benchmark reassesses LLMs' understanding of world knowledge by averting both unintentional and malicious data leakage. To avoid unintentional data leakage, we source data from a broader domain and design three decontamination rules. To prevent malicious data leakage, we divide the benchmark into validation and test sets with similar difficulty and subject distributions. The test set remains closed-source to ensure reliable results, while the validation set is publicly available to promote transparency and facilitate independent verification. Our evaluation of mainstream LLMs reveals that the powerful GPT-4o achieves merely a 5-shot score of 73.4% and a 0-shot score of 71.9% on the test set, which indicates the effectiveness of our approach in creating a more rigorous and contamination-free evaluation standard. The GitHub repository is available at https://github.com/microsoft/MMLU-CF and the dataset refers to https://huggingface.co/datasets/microsoft/MMLU-CF.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.15194",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Securing Research Infrastructure for Advanced AI",
    "description": "We outline our architecture that supports the secure training of frontier models.",
    "summary": "We outline our architecture that supports the secure training of frontier models.",
    "pubDate": "Wed, 05 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/securing-research-infrastructure-for-advanced-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Tailored Conversations beyond LLMs: A RL-Based Dialogue Manager",
    "description": "arXiv:2506.19652v1 Announce Type: cross Abstract: In this work, we propose a novel framework that integrates large language models (LLMs) with an RL-based dialogue manager for open-ended dialogue with a specific goal. By leveraging hierarchical reinforcement learning to model the structured phases of dialogue and employ meta-learning to enhance adaptability across diverse user profiles, our approach enhances adaptability and efficiency, enabling the system to learn from limited data, transition fluidly between dialogue phases, and personalize responses to heterogeneous patient needs. We apply our framework to Motivational Interviews, aiming to foster behavior change, and demonstrate that the proposed dialogue manager outperforms a state-of-the-art LLM baseline in terms of reward, showing a potential benefit of conditioning LLMs to create open-ended dialogue systems with specific goals.",
    "summary": "arXiv:2506.19652v1 Announce Type: cross Abstract: In this work, we propose a novel framework that integrates large language models (LLMs) with an RL-based dialogue manager for open-ended dialogue with a specific goal. By leveraging hierarchical reinforcement learning to model the structured phases of dialogue and employ meta-learning to enhance adaptability across diverse user profiles, our approach enhances adaptability and efficiency, enabling the system to learn from limited data, transition fluidly between dialogue phases, and personalize responses to heterogeneous patient needs. We apply our framework to Motivational Interviews, aiming to foster behavior change, and demonstrate that the proposed dialogue manager outperforms a state-of-the-art LLM baseline in terms of reward, showing a potential benefit of conditioning LLMs to create open-ended dialogue systems with specific goals.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19652",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RapFlow-TTS: Rapid and High-Fidelity Text-to-Speech with Improved Consistency Flow Matching",
    "description": "arXiv:2506.16741v1 Announce Type: cross Abstract: We introduce RapFlow-TTS, a rapid and high-fidelity TTS acoustic model that leverages velocity consistency constraints in flow matching (FM) training. Although ordinary differential equation (ODE)-based TTS generation achieves natural-quality speech, it typically requires a large number of generation steps, resulting in a trade-off between quality and inference speed. To address this challenge, RapFlow-TTS enforces consistency in the velocity field along the FM-straightened ODE trajectory, enabling consistent synthetic quality with fewer generation steps. Additionally, we introduce techniques such as time interval scheduling and adversarial learning to further enhance the quality of the few-step synthesis. Experimental results show that RapFlow-TTS achieves high-fidelity speech synthesis with a 5- and 10-fold reduction in synthesis steps than the conventional FM- and score-based approaches, respectively.",
    "summary": "arXiv:2506.16741v1 Announce Type: cross Abstract: We introduce RapFlow-TTS, a rapid and high-fidelity TTS acoustic model that leverages velocity consistency constraints in flow matching (FM) training. Although ordinary differential equation (ODE)-based TTS generation achieves natural-quality speech, it typically requires a large number of generation steps, resulting in a trade-off between quality and inference speed. To address this challenge, RapFlow-TTS enforces consistency in the velocity field along the FM-straightened ODE trajectory, enabling consistent synthetic quality with fewer generation steps. Additionally, we introduce techniques such as time interval scheduling and adversarial learning to further enhance the quality of the few-step synthesis. Experimental results show that RapFlow-TTS achieves high-fidelity speech synthesis with a 5- and 10-fold reduction in synthesis steps than the conventional FM- and score-based approaches, respectively.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16741",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI API",
    "description": "We‚Äôre releasing an API for accessing new AI models developed by OpenAI.",
    "summary": "We‚Äôre releasing an API for accessing new AI models developed by OpenAI.",
    "pubDate": "Thu, 11 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From DeepSpeed to FSDP and Back Again with Hugging Face Accelerate",
    "description": "",
    "summary": "A Hugging Face Accelerate Story of Multiple Backends: FSDP and DeepSpeed There are two popular imple...",
    "pubDate": "Thu, 13 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deepspeed-to-fsdp-and-back",
    "thumbnail": "https://huggingface.co/blog/assets/deepspeed-to-fsdp-and-back/thumbnail.png"
  },
  {
    "title": "TTS Arena: Benchmarking Text-to-Speech Models in the Wild",
    "description": "",
    "summary": "TTS Arena: Benchmarking Text-to-Speech Models in the Wild Automated measurement of the quality of te...",
    "pubDate": "Tue, 27 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-tts",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail.png"
  },
  {
    "title": "AI for Game Development: Creating a Farming Game in 5 Days. Part 1",
    "description": "",
    "summary": "AI for Game Development: Creating a Farming Game in 5 Days. Part 1 Welcome to AI for Game Developmen...",
    "pubDate": "Mon, 02 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-1",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail.png"
  },
  {
    "title": "Gemini CLI: your open-source AI agent",
    "description": "Gemini CLI icon on a background with code snippets",
    "summary": "Gemini CLI icon on a background with code snippets",
    "pubDate": "Wed, 25 Jun 2025 13:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_CLI_Hero_Final.width-1300.png"
  },
  {
    "title": "Local Markov Equivalence and Local Causal Discovery for Identifying Controlled Direct Effects",
    "description": "arXiv:2505.02781v2 Announce Type: replace Abstract: Understanding and identifying controlled direct effects (CDEs) is crucial across numerous scientific domains, including public health. While existing methods can identify these effects from causal directed acyclic graphs (DAGs), the true underlying structure is often unknown in practice. Essential graphs, which represent a Markov equivalence class of DAGs characterized by the same set of $d$-separations, provide a more practical and realistic alternative. However, learning the full essential graph is computationally intensive and typically depends on strong, untestable assumptions. In this work, we characterize a local class of graphs, defined relative to a target variable, that share a specific subset of $d$-separations, and introduce a graphical representation of this class, called the local essential graph (LEG). We then present LocPC, a novel algorithm designed to recover the LEG from an observed distribution using only local conditional independence tests. Building on LocPC, we propose LocPC-CDE, an algorithm that discovers the portion of the LEG that is both sufficient and necessary to identify a CDE, bypassing the need of retrieving the full essential graph. Compared to global methods, our algorithms require less conditional independence tests and operate under weaker assumptions while maintaining theoretical guarantees. We illustrate the effectiveness of our approach through simulation studies.",
    "summary": "arXiv:2505.02781v2 Announce Type: replace Abstract: Understanding and identifying controlled direct effects (CDEs) is crucial across numerous scientific domains, including public health. While existing methods can identify these effects from causal directed acyclic graphs (DAGs), the true underlying structure is often unknown in practice. Essential graphs, which represent a Markov equivalence class of DAGs characterized by the same set of $d$-separations, provide a more practical and realistic alternative. However, learning the full essential graph is computationally intensive and typically depends on strong, untestable assumptions. In this work, we characterize a local class of graphs, defined relative to a target variable, that share a specific subset of $d$-separations, and introduce a graphical representation of this class, called the local essential graph (LEG). We then present LocPC, a novel algorithm designed to recover the LEG from an observed distribution using only local conditional independence tests. Building on LocPC, we propose LocPC-CDE, an algorithm that discovers the portion of the LEG that is both sufficient and necessary to identify a CDE, bypassing the need of retrieving the full essential graph. Compared to global methods, our algorithms require less conditional independence tests and operate under weaker assumptions while maintaining theoretical guarantees. We illustrate the effectiveness of our approach through simulation studies.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.02781",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects",
    "description": "arXiv:2506.19579v1 Announce Type: cross Abstract: Robotic scene understanding increasingly relies on vision-language models (VLMs) to generate natural language descriptions of the environment. In this work, we present a comparative study of captioning strategies for tabletop scenes captured by a robotic arm equipped with an RGB camera. The robot collects images of objects from multiple viewpoints, and we evaluate several models that generate scene descriptions. We compare the performance of various captioning models, like BLIP and VLMs. Our experiments examine the trade-offs between single-view and multi-view captioning, and difference between recognising real-world and 3D printed objects. We quantitatively evaluate object identification accuracy, completeness, and naturalness of the generated captions. Results show that VLMs can be used in robotic settings where common objects need to be recognised, but fail to generalise to novel representations. Our findings provide practical insights into deploying foundation models for embodied agents in real-world settings.",
    "summary": "arXiv:2506.19579v1 Announce Type: cross Abstract: Robotic scene understanding increasingly relies on vision-language models (VLMs) to generate natural language descriptions of the environment. In this work, we present a comparative study of captioning strategies for tabletop scenes captured by a robotic arm equipped with an RGB camera. The robot collects images of objects from multiple viewpoints, and we evaluate several models that generate scene descriptions. We compare the performance of various captioning models, like BLIP and VLMs. Our experiments examine the trade-offs between single-view and multi-view captioning, and difference between recognising real-world and 3D printed objects. We quantitatively evaluate object identification accuracy, completeness, and naturalness of the generated captions. Results show that VLMs can be used in robotic settings where common objects need to be recognised, but fail to generalise to novel representations. Our findings provide practical insights into deploying foundation models for embodied agents in real-world settings.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19579",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robust Training with Data Augmentation for Medical Imaging Classification",
    "description": "arXiv:2506.17133v1 Announce Type: cross Abstract: Deep neural networks are increasingly being used to detect and diagnose medical conditions using medical imaging. Despite their utility, these models are highly vulnerable to adversarial attacks and distribution shifts, which can affect diagnostic reliability and undermine trust among healthcare professionals. In this study, we propose a robust training algorithm with data augmentation (RTDA) to mitigate these vulnerabilities in medical image classification. We benchmark classifier robustness against adversarial perturbations and natural variations of RTDA and six competing baseline techniques, including adversarial training and data augmentation approaches in isolation and combination, using experimental data sets with three different imaging technologies (mammograms, X-rays, and ultrasound). We demonstrate that RTDA achieves superior robustness against adversarial attacks and improved generalization performance in the presence of distribution shift in each image classification task while maintaining high clean accuracy.",
    "summary": "arXiv:2506.17133v1 Announce Type: cross Abstract: Deep neural networks are increasingly being used to detect and diagnose medical conditions using medical imaging. Despite their utility, these models are highly vulnerable to adversarial attacks and distribution shifts, which can affect diagnostic reliability and undermine trust among healthcare professionals. In this study, we propose a robust training algorithm with data augmentation (RTDA) to mitigate these vulnerabilities in medical image classification. We benchmark classifier robustness against adversarial perturbations and natural variations of RTDA and six competing baseline techniques, including adversarial training and data augmentation approaches in isolation and combination, using experimental data sets with three different imaging technologies (mammograms, X-rays, and ultrasound). We demonstrate that RTDA achieves superior robustness against adversarial attacks and improved generalization performance in the presence of distribution shift in each image classification task while maintaining high clean accuracy.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17133",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How to Train your Text-to-Image Model: Evaluating Design Choices for Synthetic Training Captions",
    "description": "arXiv:2506.16679v1 Announce Type: cross Abstract: Training data is at the core of any successful text-to-image models. The quality and descriptiveness of image text are crucial to a model's performance. Given the noisiness and inconsistency in web-scraped datasets, recent works shifted towards synthetic training captions. While this setup is generally believed to produce more capable models, current literature does not provide any insights into its design choices. This study closes this gap by systematically investigating how different synthetic captioning strategies impact the downstream performance of text-to-image models. Our experiments demonstrate that dense, high-quality captions enhance text alignment but may introduce trade-offs in output aesthetics and diversity. Conversely, captions of randomized lengths yield balanced improvements across aesthetics and alignment without compromising sample diversity. We also demonstrate that varying caption distributions introduce significant shifts in the output bias of a trained model. Our findings underscore the importance of caption design in achieving optimal model performance and provide practical insights for more effective training data strategies in text-to-image generation.",
    "summary": "arXiv:2506.16679v1 Announce Type: cross Abstract: Training data is at the core of any successful text-to-image models. The quality and descriptiveness of image text are crucial to a model's performance. Given the noisiness and inconsistency in web-scraped datasets, recent works shifted towards synthetic training captions. While this setup is generally believed to produce more capable models, current literature does not provide any insights into its design choices. This study closes this gap by systematically investigating how different synthetic captioning strategies impact the downstream performance of text-to-image models. Our experiments demonstrate that dense, high-quality captions enhance text alignment but may introduce trade-offs in output aesthetics and diversity. Conversely, captions of randomized lengths yield balanced improvements across aesthetics and alignment without compromising sample diversity. We also demonstrate that varying caption distributions introduce significant shifts in the output bias of a trained model. Our findings underscore the importance of caption design in achieving optimal model performance and provide practical insights for more effective training data strategies in text-to-image generation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16679",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Director of Machine Learning Insights [Part 3: Finance Edition]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 3: Finance Edition] If you're interested in building ML ...",
    "pubDate": "Tue, 14 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-3",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/thumbnail.png"
  },
  {
    "title": "Economic impacts research at OpenAI",
    "description": "Call for expressions of interest to study the economic impacts of large language¬†models.",
    "summary": "Call for expressions of interest to study the economic impacts of large language¬†models.",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/economic-impacts",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "‚ÄúPeriodic table of machine learning‚Äù could fuel AI discovery",
    "description": "Researchers have created a unifying framework that can help scientists combine existing ideas to improve AI models or create new ones.",
    "summary": "Researchers have created a unifying framework that can help scientists combine existing ideas to improve AI models or create new ones.",
    "pubDate": "Wed, 23 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/machine-learning-periodic-table-could-fuel-ai-discovery-0423",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT_Periodic-Algorithm-01-PRESS.jpg"
  },
  {
    "title": "EliseAI improves housing and healthcare efficiency with AI",
    "description": "A conversation with Minna Song, CEO & Co-founder of EliseAI.",
    "summary": "A conversation with Minna Song, CEO & Co-founder of EliseAI.",
    "pubDate": "Tue, 18 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/eliseai-minna-song",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New generative AI tools open the doors of music creation",
    "description": "Our latest AI music technologies are now available in MusicFX DJ, Music AI Sandbox and YouTube Shorts",
    "summary": "Our latest AI music technologies are now available in MusicFX DJ, Music AI Sandbox and YouTube Shorts",
    "pubDate": "Wed, 23 Oct 2024 16:53:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/new-generative-ai-tools-open-the-doors-of-music-creation/",
    "thumbnail": "https://lh3.googleusercontent.com/7CWJ9fVeC97FrWgcispxyms9gTL_1PIDMIwBYTQNnU8S56JaxGB2Z4ThqZ-1vBTO-u-UBZg_cYhG8PtZjYP0rPabUbg5x2cCUnNJuiZAZBsE8u7Kvig=w1200-h630-n-nu"
  },
  {
    "title": "FastRTC: The Real-Time Communication Library for Python",
    "description": "",
    "summary": "FastRTC: The Real-Time Communication Library for Python In the last few months, many new real-time s...",
    "pubDate": "Tue, 25 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastrtc",
    "thumbnail": "https://huggingface.co/blog/assets/fastrtc/fastrtc_logo.jpg"
  },
  {
    "title": "A Implies B: Circuit Analysis in LLMs for Propositional Logical Reasoning",
    "description": "arXiv:2411.04105v4 Announce Type: replace-cross Abstract: Due to the size and complexity of modern large language models (LLMs), it has proven challenging to uncover the underlying mechanisms that models use to solve reasoning problems. For instance, is their reasoning for a specific problem localized to certain parts of the network? Do they break down the reasoning problem into modular components that are then executed as sequential steps as we go deeper in the model? To better understand the reasoning capability of LLMs, we study a minimal propositional logic problem that requires combining multiple facts to arrive at a solution. By studying this problem on Mistral and Gemma models, up to 27B parameters, we illuminate the core components the models use to solve such logic problems. From a mechanistic interpretability point of view, we use causal mediation analysis to uncover the pathways and components of the LLMs' reasoning processes. Then, we offer fine-grained insights into the functions of attention heads in different layers. We not only find a sparse circuit that computes the answer, but we decompose it into sub-circuits that have four distinct and modular uses. Finally, we reveal that three distinct models -- Mistral-7B, Gemma-2-9B and Gemma-2-27B -- contain analogous but not identical mechanisms.",
    "summary": "arXiv:2411.04105v4 Announce Type: replace-cross Abstract: Due to the size and complexity of modern large language models (LLMs), it has proven challenging to uncover the underlying mechanisms that models use to solve reasoning problems. For instance, is their reasoning for a specific problem localized to certain parts of the network? Do they break down the reasoning problem into modular components that are then executed as sequential steps as we go deeper in the model? To better understand the reasoning capability of LLMs, we study a minimal propositional logic problem that requires combining multiple facts to arrive at a solution. By studying this problem on Mistral and Gemma models, up to 27B parameters, we illuminate the core components the models use to solve such logic problems. From a mechanistic interpretability point of view, we use causal mediation analysis to uncover the pathways and components of the LLMs' reasoning processes. Then, we offer fine-grained insights into the functions of attention heads in different layers. We not only find a sparse circuit that computes the answer, but we decompose it into sub-circuits that have four distinct and modular uses. Finally, we reveal that three distinct models -- Mistral-7B, Gemma-2-9B and Gemma-2-27B -- contain analogous but not identical mechanisms.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.04105",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Bamba: Inference-Efficient Hybrid Mamba2 Model",
    "description": "",
    "summary": "Bamba: Inference-Efficient Hybrid Mamba2 Model üêç TL;DR We introduce Bamba-9B, an inference-efficient...",
    "pubDate": "Wed, 18 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bamba",
    "thumbnail": "https://huggingface.co/blog/assets/bamba/bamba_thumbnail.png"
  },
  {
    "title": "Boosting multi-demographic federated learning for chest radiograph analysis using general-purpose self-supervised representations",
    "description": "arXiv:2504.08584v2 Announce Type: replace-cross Abstract: Reliable artificial intelligence (AI) models for medical image analysis often depend on large and diverse labeled datasets. Federated learning (FL) offers a decentralized and privacy-preserving approach to training but struggles in highly non-independent and identically distributed (non-IID) settings, where institutions with more representative data may experience degraded performance. Moreover, existing large-scale FL studies have been limited to adult datasets, neglecting the unique challenges posed by pediatric data, which introduces additional non-IID variability. To address these limitations, we analyzed n=398,523 adult chest radiographs from diverse institutions across multiple countries and n=9,125 pediatric images, leveraging transfer learning from general-purpose self-supervised image representations to classify pneumonia and cases with no abnormality. Using state-of-the-art vision transformers, we found that FL improved performance only for smaller adult datasets (P<0.001) but degraded performance for larger datasets (P<0.064) and pediatric cases (P=0.242). However, equipping FL with self-supervised weights significantly enhanced outcomes across pediatric cases (P=0.031) and most adult datasets (P<0.008), except the largest dataset (P=0.052). These findings underscore the potential of easily deployable general-purpose self-supervised image representations to address non-IID challenges in clinical FL applications and highlight their promise for enhancing patient outcomes and advancing pediatric healthcare, where data scarcity and variability remain persistent obstacles.",
    "summary": "arXiv:2504.08584v2 Announce Type: replace-cross Abstract: Reliable artificial intelligence (AI) models for medical image analysis often depend on large and diverse labeled datasets. Federated learning (FL) offers a decentralized and privacy-preserving approach to training but struggles in highly non-independent and identically distributed (non-IID) settings, where institutions with more representative data may experience degraded performance. Moreover, existing large-scale FL studies have been limited to adult datasets, neglecting the unique challenges posed by pediatric data, which introduces additional non-IID variability. To address these limitations, we analyzed n=398,523 adult chest radiographs from diverse institutions across multiple countries and n=9,125 pediatric images, leveraging transfer learning from general-purpose self-supervised image representations to classify pneumonia and cases with no abnormality. Using state-of-the-art vision transformers, we found that FL improved performance only for smaller adult datasets (P<0.001) but degraded performance for larger datasets (P<0.064) and pediatric cases (P=0.242). However, equipping FL with self-supervised weights significantly enhanced outcomes across pediatric cases (P=0.031) and most adult datasets (P<0.008), except the largest dataset (P=0.052). These findings underscore the potential of easily deployable general-purpose self-supervised image representations to address non-IID challenges in clinical FL applications and highlight their promise for enhancing patient outcomes and advancing pediatric healthcare, where data scarcity and variability remain persistent obstacles.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.08584",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerating engineering cycles 20% with OpenAI",
    "description": "Accelerating engineering cycles 20% with OpenAI.",
    "summary": "Accelerating engineering cycles 20% with OpenAI.",
    "pubDate": "Thu, 06 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/factory",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pairing data with APIs to unlock customer value",
    "description": "Rakuten Pairs Data with AI to Unlock Customer Insights and Value",
    "summary": "Rakuten Pairs Data with AI to Unlock Customer Insights and Value",
    "pubDate": "Wed, 07 Aug 2024 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rakuten",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI technical goals",
    "description": "OpenAI‚Äôs mission is to build safe AI, and ensure AI‚Äôs benefits are as widely and evenly distributed as possible.",
    "summary": "OpenAI‚Äôs mission is to build safe AI, and ensure AI‚Äôs benefits are as widely and evenly distributed as possible.",
    "pubDate": "Mon, 20 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-technical-goals",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Updating the Frontier Safety Framework",
    "description": "Our next iteration of the FSF sets out stronger security protocols on the path to AGI",
    "summary": "Our next iteration of the FSF sets out stronger security protocols on the path to AGI",
    "pubDate": "Tue, 04 Feb 2025 16:41:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/updating-the-frontier-safety-framework/",
    "thumbnail": "https://lh3.googleusercontent.com/0fu18H8X3miSAuwcVJ7Zulis_LZAL7F4bIFU7FYFA2dGx3Rm3HHlm5N202B0dtKBuS7iI5SD1QgpFPuU-O3TPzb7iG1Ns-loZzinRB3M3X3W-MAgIQ=w1200-h630-n-nu"
  },
  {
    "title": "New embedding models and API updates",
    "description": "We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management tools, and soon, lower pricing on GPT-3.5 Turbo.",
    "summary": "We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage management tools, and soon, lower pricing on GPT-3.5 Turbo.",
    "pubDate": "Thu, 25 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-embedding-models-and-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An Introduction to AI Secure LLM Safety Leaderboard",
    "description": "",
    "summary": "An Introduction to AI Secure LLM Safety Leaderboard Given the widespread adoption of LLMs, it is cri...",
    "pubDate": "Fri, 26 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-decodingtrust",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_decodingtrust.png"
  },
  {
    "title": "AB-UPT: Scaling Neural CFD Surrogates for High-Fidelity Automotive Aerodynamics Simulations via Anchored-Branched Universal Physics Transformers",
    "description": "arXiv:2502.09692v3 Announce Type: replace-cross Abstract: Recent advances in neural surrogate modeling offer the potential for transformative innovations in applications such as automotive aerodynamics. Yet, industrial-scale problems often involve volumetric meshes with cell counts reaching 100 million, presenting major scalability challenges. Complex geometries further complicate modeling through intricate surface-volume interactions, while quantities such as vorticity are highly nonlinear and must satisfy strict divergence-free constraints. To address these requirements, we introduce Anchored-Branched Universal Physics Transformers (AB-UPT) as a novel modeling scheme for building neural surrogates for computational fluid dynamics (CFD) simulations. AB-UPT is designed to: (i) decouple geometry encoding and prediction tasks via multi-branch operators; (ii) enable scalability to high-resolution outputs via neural simulation in a low-dimensional latent space, coupled with anchored neural field decoders to predict high-fidelity outputs; (iii) enforce physics consistency by a novel divergence-free formulation. We show that AB-UPT yields state-of-the-art predictive accuracy of surface and volume fields on automotive CFD simulations ranging from 33 thousand up to 150 million mesh cells. Furthermore, our anchored neural field architecture enables the enforcement of hard physical constraints on the physics predictions without degradation in performance, exemplified by modeling divergence-free vorticity fields. Notably, the proposed models can be trained on a single GPU in less than a day and predict industry-standard surface and volume fields within seconds. Additionally, we show that the flexible design of our method enables neural simulation from a computer-aided design geometry alone, omitting the need for costly CFD meshing procedures.",
    "summary": "arXiv:2502.09692v3 Announce Type: replace-cross Abstract: Recent advances in neural surrogate modeling offer the potential for transformative innovations in applications such as automotive aerodynamics. Yet, industrial-scale problems often involve volumetric meshes with cell counts reaching 100 million, presenting major scalability challenges. Complex geometries further complicate modeling through intricate surface-volume interactions, while quantities such as vorticity are highly nonlinear and must satisfy strict divergence-free constraints. To address these requirements, we introduce Anchored-Branched Universal Physics Transformers (AB-UPT) as a novel modeling scheme for building neural surrogates for computational fluid dynamics (CFD) simulations. AB-UPT is designed to: (i) decouple geometry encoding and prediction tasks via multi-branch operators; (ii) enable scalability to high-resolution outputs via neural simulation in a low-dimensional latent space, coupled with anchored neural field decoders to predict high-fidelity outputs; (iii) enforce physics consistency by a novel divergence-free formulation. We show that AB-UPT yields state-of-the-art predictive accuracy of surface and volume fields on automotive CFD simulations ranging from 33 thousand up to 150 million mesh cells. Furthermore, our anchored neural field architecture enables the enforcement of hard physical constraints on the physics predictions without degradation in performance, exemplified by modeling divergence-free vorticity fields. Notably, the proposed models can be trained on a single GPU in less than a day and predict industry-standard surface and volume fields within seconds. Additionally, we show that the flexible design of our method enables neural simulation from a computer-aided design geometry alone, omitting the need for costly CFD meshing procedures.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.09692",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face models in Amazon Bedrock",
    "description": "",
    "summary": "Use Hugging Face models with Amazon Bedrock We are excited to announce that popular open models from...",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bedrock-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/bedrock-marketplace/thumbnail.png"
  },
  {
    "title": "Informatica„ÅåAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„Å´Êú¨Ê∞ó„ÄÄÊó•Êú¨„Å´Âêë„Åë„ÄåÊåëÊà¶„ÅØ„É™„Çπ„ÇØ„ÄÅ„Å†„ÅåÂæÖ„Å£„Å¶„ÅÑ„Å¶„ÅØËøΩ„ÅÑ‰ªò„Åë„Å™„ÅÑ„Äç",
    "description": "Á±≥Informatica„ÅØÂπ¥Ê¨°„Ç§„Éô„É≥„Éà„ÄåInformatica World 2025„Äç„Åß„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„Å´Èñ¢ÈÄ£„Åô„ÇãÂèñ„ÇäÁµÑ„Åø„ÅÆÂ§ßÂπÖÂº∑Âåñ„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÊó•Êú¨„Å´Âêë„Åë„Å¶„ÅØ„ÄÅÂ§±Êïó„ÇíÊÅê„Çå„ÅöÊåëÊà¶„Åô„Çã„Çà„ÅÜË®¥„Åà„Åã„Åë„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "Á±≥Informatica„ÅØÂπ¥Ê¨°„Ç§„Éô„É≥„Éà„ÄåInformatica World 2025„Äç„Åß„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„Å´Èñ¢ÈÄ£„Åô„ÇãÂèñ„ÇäÁµÑ„Åø„ÅÆÂ§ßÂπÖÂº∑Âåñ„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÊó•Êú¨„Å´Âêë„Åë„Å¶„ÅØ„ÄÅÂ§±Êïó„ÇíÊÅê„Çå„ÅöÊåëÊà¶„Åô„Çã„Çà„ÅÜË®¥„Åà„Åã„Åë„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Mon, 23 Jun 2025 10:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/23/news033.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/23/cover_news033.jpg"
  },
  {
    "title": "An Overview of Inference Solutions on Hugging Face",
    "description": "",
    "summary": "An Overview of Inference Solutions on Hugging Face Every day, developers and organizations are adopt...",
    "pubDate": "Mon, 21 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-update",
    "thumbnail": "https://huggingface.co/blog/assets/116_inference_update/widget.png"
  },
  {
    "title": "Images altered to trick machine vision can influence humans too",
    "description": "In a series of experiments published in Nature Communications, we found evidence that human judgments are indeed systematically influenced by adversarial perturbations.",
    "summary": "In a series of experiments published in Nature Communications, we found evidence that human judgments are indeed systematically influenced by adversarial perturbations.",
    "pubDate": "Tue, 02 Jan 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/images-altered-to-trick-machine-vision-can-influence-humans-too/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "Understanding the source of what we see and hear online",
    "description": "Today we‚Äôre introducing new technology to help researchers identify content created by our tools and joining the Coalition for Content Provenance and Authenticity Steering Committee to promote industry standards.",
    "summary": "Today we‚Äôre introducing new technology to help researchers identify content created by our tools and joining the Coalition for Content Provenance and Authenticity Steering Committee to promote industry standards.",
    "pubDate": "Tue, 07 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/understanding-the-source-of-what-we-see-and-hear-online",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fast and Stable Diffusion Planning through Variational Adaptive Weighting",
    "description": "arXiv:2506.16688v1 Announce Type: cross Abstract: Diffusion models have recently shown promise in offline RL. However, these methods often suffer from high training costs and slow convergence, particularly when using transformer-based denoising backbones. While several optimization strategies have been proposed -- such as modified noise schedules, auxiliary prediction targets, and adaptive loss weighting -- challenges remain in achieving stable and efficient training. In particular, existing loss weighting functions typically rely on neural network approximators, which can be ineffective in early training phases due to limited generalization capacity of MLPs when exposed to sparse feedback in the early training stages. In this work, we derive a variationally optimal uncertainty-aware weighting function and introduce a closed-form polynomial approximation method for its online estimation under the flow-based generative modeling framework. We integrate our method into a diffusion planning pipeline and evaluate it on standard offline RL benchmarks. Experimental results on Maze2D and Kitchen tasks show that our method achieves competitive performance with up to 10 times fewer training steps, highlighting its practical effectiveness.",
    "summary": "arXiv:2506.16688v1 Announce Type: cross Abstract: Diffusion models have recently shown promise in offline RL. However, these methods often suffer from high training costs and slow convergence, particularly when using transformer-based denoising backbones. While several optimization strategies have been proposed -- such as modified noise schedules, auxiliary prediction targets, and adaptive loss weighting -- challenges remain in achieving stable and efficient training. In particular, existing loss weighting functions typically rely on neural network approximators, which can be ineffective in early training phases due to limited generalization capacity of MLPs when exposed to sparse feedback in the early training stages. In this work, we derive a variationally optimal uncertainty-aware weighting function and introduce a closed-form polynomial approximation method for its online estimation under the flow-based generative modeling framework. We integrate our method into a diffusion planning pipeline and evaluate it on standard offline RL benchmarks. Experimental results on Maze2D and Kitchen tasks show that our method achieves competitive performance with up to 10 times fewer training steps, highlighting its practical effectiveness.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16688",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Context Matters! Relaxing Goals with LLMs for Feasible 3D Scene Planning",
    "description": "arXiv:2506.15828v1 Announce Type: cross Abstract: Classical planning in AI and Robotics addresses complex tasks by shifting from imperative to declarative approaches (e.g., PDDL). However, these methods often fail in real scenarios due to limited robot perception and the need to ground perceptions to planning predicates. This often results in heavily hard-coded behaviors that struggle to adapt, even with scenarios where goals can be achieved through relaxed planning. Meanwhile, Large Language Models (LLMs) lead to planning systems that leverage commonsense reasoning but often at the cost of generating unfeasible and/or unsafe plans. To address these limitations, we present an approach integrating classical planning with LLMs, leveraging their ability to extract commonsense knowledge and ground actions. We propose a hierarchical formulation that enables robots to make unfeasible tasks tractable by defining functionally equivalent goals through gradual relaxation. This mechanism supports partial achievement of the intended objective, suited to the agent's specific context. Our method demonstrates its ability to adapt and execute tasks effectively within environments modeled using 3D Scene Graphs through comprehensive qualitative and quantitative evaluations. We also show how this method succeeds in complex scenarios where other benchmark methods are more likely to fail. Code, dataset, and additional material are released to the community.",
    "summary": "arXiv:2506.15828v1 Announce Type: cross Abstract: Classical planning in AI and Robotics addresses complex tasks by shifting from imperative to declarative approaches (e.g., PDDL). However, these methods often fail in real scenarios due to limited robot perception and the need to ground perceptions to planning predicates. This often results in heavily hard-coded behaviors that struggle to adapt, even with scenarios where goals can be achieved through relaxed planning. Meanwhile, Large Language Models (LLMs) lead to planning systems that leverage commonsense reasoning but often at the cost of generating unfeasible and/or unsafe plans. To address these limitations, we present an approach integrating classical planning with LLMs, leveraging their ability to extract commonsense knowledge and ground actions. We propose a hierarchical formulation that enables robots to make unfeasible tasks tractable by defining functionally equivalent goals through gradual relaxation. This mechanism supports partial achievement of the intended objective, suited to the agent's specific context. Our method demonstrates its ability to adapt and execute tasks effectively within environments modeled using 3D Scene Graphs through comprehensive qualitative and quantitative evaluations. We also show how this method succeeds in complex scenarios where other benchmark methods are more likely to fail. Code, dataset, and additional material are released to the community.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15828",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face Collaborates with Microsoft to Launch Hugging Face Model Catalog on Azure",
    "description": "",
    "summary": "Hugging Face Collaborates with Microsoft to launch Hugging Face Model Catalog on Azure Today, we are...",
    "pubDate": "Wed, 24 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-endpoints-on-azure",
    "thumbnail": "https://huggingface.co/blog/assets/75_hugging_face_endpoints_on_azure/01.jpg"
  },
  {
    "title": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "description": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "summary": "OpenAI appoints Scott Schools as Chief Compliance Officer",
    "pubDate": "Tue, 22 Oct 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-chief-compliance-officer-announcement",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function Calling",
    "description": "arXiv:2506.19500v1 Announce Type: new Abstract: LLMs' reliance on static knowledge and fragile tool invocation severely hinders the orchestration of complex, heterogeneous toolchains, particularly at large scales. Existing methods typically use rigid single-path execution, resulting in poor error recovery and exponentially growing search spaces. We introduce NaviAgent, a graph-navigated bilevel planning architecture for robust function calling, comprising a Multi-Path Decider and Graph-Encoded Navigator. As an LLM-powered agent, the Multi-Path Decider defines a four-dimensional decision space and continuously perceives environmental states, dynamically selecting the optimal action to fully cover all tool invocation scenarios. The Graph-Encoded Navigator constructs a Tool Dependency Heterogeneous Graph (TDHG), where node embeddings explicitly fuse API schema structure with historical invocation behavior. It also integrates a novel heuristic search strategy that guides the Decider toward efficient and highly successful toolchains, even for unseen tool combinations. Experiments show that NaviAgent consistently achieves the highest task success rate (TSR) across all foundation models and task complexities, outperforming the average baselines (ReAct, ToolLLM, {alpha}-UMI) by 13.5%, 16.4%, and 19.0% on Qwen2.5-14B, Qwen2.5-32B, and Deepseek-V3, respectively. Its execution steps are typically within one step of the most efficient baseline, ensuring a strong balance between quality and efficiency. Notably, a fine-tuned Qwen2.5-14B model achieves a TSR of 49.5%, surpassing the much larger 32B model (44.9%) under our architecture. Incorporating the Graph-Encoded Navigator further boosts TSR by an average of 2.4 points, with gains up over 9 points on complex tasks for larger models (Deepseek-V3 and GPT-4o), highlighting its essential role in toolchain orchestration.",
    "summary": "arXiv:2506.19500v1 Announce Type: new Abstract: LLMs' reliance on static knowledge and fragile tool invocation severely hinders the orchestration of complex, heterogeneous toolchains, particularly at large scales. Existing methods typically use rigid single-path execution, resulting in poor error recovery and exponentially growing search spaces. We introduce NaviAgent, a graph-navigated bilevel planning architecture for robust function calling, comprising a Multi-Path Decider and Graph-Encoded Navigator. As an LLM-powered agent, the Multi-Path Decider defines a four-dimensional decision space and continuously perceives environmental states, dynamically selecting the optimal action to fully cover all tool invocation scenarios. The Graph-Encoded Navigator constructs a Tool Dependency Heterogeneous Graph (TDHG), where node embeddings explicitly fuse API schema structure with historical invocation behavior. It also integrates a novel heuristic search strategy that guides the Decider toward efficient and highly successful toolchains, even for unseen tool combinations. Experiments show that NaviAgent consistently achieves the highest task success rate (TSR) across all foundation models and task complexities, outperforming the average baselines (ReAct, ToolLLM, {alpha}-UMI) by 13.5%, 16.4%, and 19.0% on Qwen2.5-14B, Qwen2.5-32B, and Deepseek-V3, respectively. Its execution steps are typically within one step of the most efficient baseline, ensuring a strong balance between quality and efficiency. Notably, a fine-tuned Qwen2.5-14B model achieves a TSR of 49.5%, surpassing the much larger 32B model (44.9%) under our architecture. Incorporating the Graph-Encoded Navigator further boosts TSR by an average of 2.4 points, with gains up over 9 points on complex tasks for larger models (Deepseek-V3 and GPT-4o), highlighting its essential role in toolchain orchestration.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19500",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Vision Language Models (Better, Faster, Stronger)",
    "description": "",
    "summary": "Vision Language Models (Better, Faster, Stronger) Motivation Vision Language Models (VLMs) are the t...",
    "pubDate": "Mon, 12 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vlms-2025",
    "thumbnail": "https://huggingface.co/blog/assets/vlms2/vlms2.png"
  },
  {
    "title": "Machine Learning Methods for Small Data and Upstream Bioprocessing Applications: A Comprehensive Review",
    "description": "arXiv:2506.12322v2 Announce Type: replace-cross Abstract: Data is crucial for machine learning (ML) applications, yet acquiring large datasets can be costly and time-consuming, especially in complex, resource-intensive fields like biopharmaceuticals. A key process in this industry is upstream bioprocessing, where living cells are cultivated and optimised to produce therapeutic proteins and biologics. The intricate nature of these processes, combined with high resource demands, often limits data collection, resulting in smaller datasets. This comprehensive review explores ML methods designed to address the challenges posed by small data and classifies them into a taxonomy to guide practical applications. Furthermore, each method in the taxonomy was thoroughly analysed, with a detailed discussion of its core concepts and an evaluation of its effectiveness in tackling small data challenges, as demonstrated by application results in the upstream bioprocessing and other related domains. By analysing how these methods tackle small data challenges from different perspectives, this review provides actionable insights, identifies current research gaps, and offers guidance for leveraging ML in data-constrained environments.",
    "summary": "arXiv:2506.12322v2 Announce Type: replace-cross Abstract: Data is crucial for machine learning (ML) applications, yet acquiring large datasets can be costly and time-consuming, especially in complex, resource-intensive fields like biopharmaceuticals. A key process in this industry is upstream bioprocessing, where living cells are cultivated and optimised to produce therapeutic proteins and biologics. The intricate nature of these processes, combined with high resource demands, often limits data collection, resulting in smaller datasets. This comprehensive review explores ML methods designed to address the challenges posed by small data and classifies them into a taxonomy to guide practical applications. Furthermore, each method in the taxonomy was thoroughly analysed, with a detailed discussion of its core concepts and an evaluation of its effectiveness in tackling small data challenges, as demonstrated by application results in the upstream bioprocessing and other related domains. By analysing how these methods tackle small data challenges from different perspectives, this review provides actionable insights, identifies current research gaps, and offers guidance for leveraging ML in data-constrained environments.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12322",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Á±≥AI‰ºÅÊ•≠„ÅÆAnthropic„ÄÅÊù±‰∫¨„Å´Êã†ÁÇπÈñãË®≠„Å∏„ÄÄ„ÄåClaude„ÄçÊó•Êú¨Ë™ûÁâà„ÇÇ„É™„É™„Éº„Çπ‰∫àÂÆö",
    "description": "Á±≥Anthropic„ÅØ„ÄÅÁßã„Åî„Çç„Å´Êù±‰∫¨ÈÉΩ„Å´Êã†ÁÇπ„ÇíÈñãË®≠„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ‰Ωµ„Åõ„Å¶„ÄÅÂêåÁ§æ„ÅÆAI„Çµ„Éº„Éì„Çπ„ÄåClaude„Äç„ÅÆÊó•Êú¨Ë™ûÁâà„Çí„É™„É™„Éº„Çπ„Åô„Çã„ÄÇ",
    "summary": "Á±≥Anthropic„ÅØ„ÄÅÁßã„Åî„Çç„Å´Êù±‰∫¨ÈÉΩ„Å´Êã†ÁÇπ„ÇíÈñãË®≠„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ‰Ωµ„Åõ„Å¶„ÄÅÂêåÁ§æ„ÅÆAI„Çµ„Éº„Éì„Çπ„ÄåClaude„Äç„ÅÆÊó•Êú¨Ë™ûÁâà„Çí„É™„É™„Éº„Çπ„Åô„Çã„ÄÇ",
    "pubDate": "Wed, 25 Jun 2025 13:15:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/25/news076.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/25/cover_news076.jpg"
  },
  {
    "title": "Opinion Classification with Kili and HuggingFace AutoTrain",
    "description": "",
    "summary": "Opinion Classification with Kili and HuggingFace AutoTrain Introduction Understanding your users‚Äô ne...",
    "pubDate": "Thu, 28 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/opinion-classification-with-kili",
    "thumbnail": "https://huggingface.co/blog/assets/59_opinion-classification-with-kili/thumbnail.png"
  },
  {
    "title": "Why we‚Äôre switching to Hugging Face Inference Endpoints, and maybe you should too",
    "description": "",
    "summary": "Why we‚Äôre switching to Hugging Face Inference Endpoints, and maybe you should too Hugging Face recen...",
    "pubDate": "Wed, 15 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mantis-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/mantis1.png"
  },
  {
    "title": "Universal Retrieval for Multimodal Trajectory Modeling",
    "description": "arXiv:2506.22056v1 Announce Type: new Abstract: Trajectory data, capturing human actions and environmental states across various modalities, holds significant potential for enhancing AI agent capabilities, particularly in GUI environments. However, how to model the representation of trajectory-level data presents a significant challenge that has not been systematically addressed amid explosive trajectory data growth. In this work, we introduce Multimodal Trajectory Retrieval, bridging the gap between universal retrieval and agent-centric trajectory modeling. We construct the Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and states across diverse real-world scenarios. Based on this, we present GAE-Bench, a benchmark containing a large number of trajectory-based retrieval pairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework that adopts vision-language models and incorporates optimized contrastive learning through a token selection and the GradCache mechanism. Comprehensive evaluations across multiple datasets show that GAE-Retriever consistently outperforms strong baselines in retrieval recall, highlighting its effectiveness in advancing multimodal trajectory retrieval.",
    "summary": "arXiv:2506.22056v1 Announce Type: new Abstract: Trajectory data, capturing human actions and environmental states across various modalities, holds significant potential for enhancing AI agent capabilities, particularly in GUI environments. However, how to model the representation of trajectory-level data presents a significant challenge that has not been systematically addressed amid explosive trajectory data growth. In this work, we introduce Multimodal Trajectory Retrieval, bridging the gap between universal retrieval and agent-centric trajectory modeling. We construct the Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and states across diverse real-world scenarios. Based on this, we present GAE-Bench, a benchmark containing a large number of trajectory-based retrieval pairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework that adopts vision-language models and incorporates optimized contrastive learning through a token selection and the GradCache mechanism. Comprehensive evaluations across multiple datasets show that GAE-Retriever consistently outperforms strong baselines in retrieval recall, highlighting its effectiveness in advancing multimodal trajectory retrieval.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22056",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Batayan: A Filipino NLP benchmark for evaluating Large Language Models",
    "description": "arXiv:2502.14911v2 Announce Type: replace-cross Abstract: Recent advances in large language models (LLMs) have demonstrated remarkable capabilities on widely benchmarked high-resource languages. However, linguistic nuances of under-resourced languages remain unexplored. We introduce Batayan, a holistic Filipino benchmark that systematically evaluates LLMs across three key natural language processing (NLP) competencies: understanding, reasoning, and generation. Batayan consolidates eight tasks, three of which have not existed prior for Filipino corpora, covering both Tagalog and code-switched Taglish utterances. Our rigorous, native-speaker-driven adaptation and validation processes ensures fluency and authenticity to the complex morphological and syntactic structures of Filipino, alleviating the pervasive translationese bias in existing Filipino corpora. We report empirical results on a variety of open-source and commercial LLMs, highlighting significant performance gaps that signal the under-representation of Filipino in pre-training corpora, the unique hurdles in modeling Filipino's rich morphology and construction, and the importance of explicit Filipino language support. Moreover, we discuss the practical challenges encountered in dataset construction and propose principled solutions for building culturally and linguistically-faithful resources in under-represented languages. We also provide a public evaluation suite as a clear foundation for iterative, community-driven progress in Filipino NLP.",
    "summary": "arXiv:2502.14911v2 Announce Type: replace-cross Abstract: Recent advances in large language models (LLMs) have demonstrated remarkable capabilities on widely benchmarked high-resource languages. However, linguistic nuances of under-resourced languages remain unexplored. We introduce Batayan, a holistic Filipino benchmark that systematically evaluates LLMs across three key natural language processing (NLP) competencies: understanding, reasoning, and generation. Batayan consolidates eight tasks, three of which have not existed prior for Filipino corpora, covering both Tagalog and code-switched Taglish utterances. Our rigorous, native-speaker-driven adaptation and validation processes ensures fluency and authenticity to the complex morphological and syntactic structures of Filipino, alleviating the pervasive translationese bias in existing Filipino corpora. We report empirical results on a variety of open-source and commercial LLMs, highlighting significant performance gaps that signal the under-representation of Filipino in pre-training corpora, the unique hurdles in modeling Filipino's rich morphology and construction, and the importance of explicit Filipino language support. Moreover, we discuss the practical challenges encountered in dataset construction and propose principled solutions for building culturally and linguistically-faithful resources in under-represented languages. We also provide a public evaluation suite as a clear foundation for iterative, community-driven progress in Filipino NLP.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.14911",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Rocket Money x Hugging Face: Scaling Volatile ML Models in Production",
    "description": "",
    "summary": "Rocket Money x Hugging Face: Scaling Volatile ML Models in Production 'We discovered that they were ...",
    "pubDate": "Tue, 19 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rocketmoney-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/rocketmoney.png"
  },
  {
    "title": "Liftoff! How to get started with your first ML project üöÄ",
    "description": "",
    "summary": "Liftoff! How to get started with your first ML project üöÄ People who are new to the Machine Learning ...",
    "pubDate": "Wed, 29 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/your-first-ml-project",
    "thumbnail": "https://huggingface.co/blog/assets/84_first_ml_project/thumbnail.png"
  },
  {
    "title": "Automated detection of atomicity violations in large-scale systems",
    "description": "arXiv:2504.00521v2 Announce Type: replace-cross Abstract: Atomicity violations in interrupt-driven programs pose a significant threat to software safety in critical systems. These violations occur when the execution sequence of operations on shared resources is disrupted by asynchronous interrupts. Detecting atomicity violations is challenging due to the vast program state space, application-level code dependencies, and complex domain-specific knowledge. We propose Clover, a hybrid framework that integrates static analysis with large language model (LLM) agents to detect atomicity violations in real-world programs. Clover first performs static analysis to extract critical code snippets and operation information. It then initiates a multi-agent process, where the expert agent leverages domain-specific knowledge to detect atomicity violations, which are subsequently validated by the judge agent. Evaluations on RaceBench 2.1, SV-COMP, and RWIP demonstrate that Clover achieves a precision/recall of 92.3%/86.6%, outperforming existing approaches by 27.4-118.2% on F1-score.",
    "summary": "arXiv:2504.00521v2 Announce Type: replace-cross Abstract: Atomicity violations in interrupt-driven programs pose a significant threat to software safety in critical systems. These violations occur when the execution sequence of operations on shared resources is disrupted by asynchronous interrupts. Detecting atomicity violations is challenging due to the vast program state space, application-level code dependencies, and complex domain-specific knowledge. We propose Clover, a hybrid framework that integrates static analysis with large language model (LLM) agents to detect atomicity violations in real-world programs. Clover first performs static analysis to extract critical code snippets and operation information. It then initiates a multi-agent process, where the expert agent leverages domain-specific knowledge to detect atomicity violations, which are subsequently validated by the judge agent. Evaluations on RaceBench 2.1, SV-COMP, and RWIP demonstrate that Clover achieves a precision/recall of 92.3%/86.6%, outperforming existing approaches by 27.4-118.2% on F1-score.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.00521",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Creating websites in minutes with AI Website Builder",
    "description": "Wix‚Äôs AI Website Builder, powered by OpenAI, lets anyone create a full website in minutes‚Äîjust by describing their idea in a conversation.",
    "summary": "Wix‚Äôs AI Website Builder, powered by OpenAI, lets anyone create a full website in minutes‚Äîjust by describing their idea in a conversation.",
    "pubDate": "Thu, 29 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/wix",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Benchmarking Language Model Performance on 5th Gen Xeon at GCP",
    "description": "",
    "summary": "Benchmarking Language Model Performance on 5th Gen Xeon at GCP TL;DR: We benchmark 2 representative ...",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-gcp-c4",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Introduction to the Open Leaderboard for Japanese LLMs",
    "description": "",
    "summary": "Introduction to the Open Leaderboard for Japanese LLMs LLMs are now increasingly capable in English,...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-japanese",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_japanese.png"
  },
  {
    "title": "Course Launch Community Event",
    "description": "",
    "summary": "Course Launch Community Event We are excited to share that after a lot of work from the Hugging Face...",
    "pubDate": "Tue, 26 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/course-launch-event",
    "thumbnail": "https://huggingface.co/blog/assets/34_course_launch/speakers_day1_thumb.png"
  },
  {
    "title": "A Simple Contrastive Framework Of Item Tokenization For Generative Recommendation",
    "description": "arXiv:2506.16683v1 Announce Type: cross Abstract: Generative retrieval-based recommendation has emerged as a promising paradigm aiming at directly generating the identifiers of the target candidates. However, in large-scale recommendation systems, this approach becomes increasingly cumbersome due to the redundancy and sheer scale of the token space. To overcome these limitations, recent research has explored the use of semantic tokens as an alternative to ID tokens, which typically leveraged reconstruction-based strategies, like RQ-VAE, to quantize content embeddings and significantly reduce the embedding size. However, reconstructive quantization aims for the precise reconstruction of each item embedding independently, which conflicts with the goal of generative retrieval tasks focusing more on differentiating among items. Moreover, multi-modal side information of items, such as descriptive text and images, geographical knowledge in location-based recommendation services, has been shown to be effective in improving recommendations by providing richer contexts for interactions. Nevertheless, effectively integrating such complementary knowledge into existing generative recommendation frameworks remains challenging. To overcome these challenges, we propose a novel unsupervised deep quantization exclusively based on contrastive learning, named SimCIT (a Simple Contrastive Item Tokenization framework). Specifically, different from existing reconstruction-based strategies, SimCIT propose to use a learnable residual quantization module to align with the signals from different modalities of the items, which combines multi-modal knowledge alignment and semantic tokenization in a mutually beneficial contrastive learning framework. Extensive experiments across public datasets and a large-scale industrial dataset from various domains demonstrate SimCIT's effectiveness in LLM-based generative recommendation.",
    "summary": "arXiv:2506.16683v1 Announce Type: cross Abstract: Generative retrieval-based recommendation has emerged as a promising paradigm aiming at directly generating the identifiers of the target candidates. However, in large-scale recommendation systems, this approach becomes increasingly cumbersome due to the redundancy and sheer scale of the token space. To overcome these limitations, recent research has explored the use of semantic tokens as an alternative to ID tokens, which typically leveraged reconstruction-based strategies, like RQ-VAE, to quantize content embeddings and significantly reduce the embedding size. However, reconstructive quantization aims for the precise reconstruction of each item embedding independently, which conflicts with the goal of generative retrieval tasks focusing more on differentiating among items. Moreover, multi-modal side information of items, such as descriptive text and images, geographical knowledge in location-based recommendation services, has been shown to be effective in improving recommendations by providing richer contexts for interactions. Nevertheless, effectively integrating such complementary knowledge into existing generative recommendation frameworks remains challenging. To overcome these challenges, we propose a novel unsupervised deep quantization exclusively based on contrastive learning, named SimCIT (a Simple Contrastive Item Tokenization framework). Specifically, different from existing reconstruction-based strategies, SimCIT propose to use a learnable residual quantization module to align with the signals from different modalities of the items, which combines multi-modal knowledge alignment and semantic tokenization in a mutually beneficial contrastive learning framework. Extensive experiments across public datasets and a large-scale industrial dataset from various domains demonstrate SimCIT's effectiveness in LLM-based generative recommendation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16683",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "eccDNAMamba: A Pre-Trained Model for Ultra-Long eccDNA Sequence Analysis",
    "description": "arXiv:2506.18940v1 Announce Type: cross Abstract: Extrachromosomal circular DNA (eccDNA) plays key regulatory roles and contributes to oncogene overexpression in cancer through high-copy amplification and long-range interactions. Despite advances in modeling, no pre-trained models currently support full-length circular eccDNA for downstream analysis. Existing genomic models are either limited to single-nucleotide resolution or hindered by the inefficiency of the quadratic attention mechanism. Here, we introduce eccDNAMamba, the first bidirectional state-space encoder tailored for circular DNA sequences. It combines forward and reverse passes for full-context representation learning with linear-time complexity, and preserves circular structure through a novel augmentation strategy. Tested on two real-world datasets, eccDNAMamba achieves strong classification performance and scales to sequences up to 200 Kbp, offering a robust and efficient framework for modeling circular genomes. Our codes are available at https://github.com/zzq1zh/GenAI-Lab.",
    "summary": "arXiv:2506.18940v1 Announce Type: cross Abstract: Extrachromosomal circular DNA (eccDNA) plays key regulatory roles and contributes to oncogene overexpression in cancer through high-copy amplification and long-range interactions. Despite advances in modeling, no pre-trained models currently support full-length circular eccDNA for downstream analysis. Existing genomic models are either limited to single-nucleotide resolution or hindered by the inefficiency of the quadratic attention mechanism. Here, we introduce eccDNAMamba, the first bidirectional state-space encoder tailored for circular DNA sequences. It combines forward and reverse passes for full-context representation learning with linear-time complexity, and preserves circular structure through a novel augmentation strategy. Tested on two real-world datasets, eccDNAMamba achieves strong classification performance and scales to sequences up to 200 Kbp, offering a robust and efficient framework for modeling circular genomes. Our codes are available at https://github.com/zzq1zh/GenAI-Lab.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18940",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reasoning Isn't Enough: Examining Truth-Bias and Sycophancy in LLMs",
    "description": "arXiv:2506.21561v1 Announce Type: cross Abstract: Despite their widespread use in fact-checking, moderation, and high-stakes decision-making, large language models (LLMs) remain poorly understood as judges of truth. This study presents the largest evaluation to date of LLMs' veracity detection capabilities and the first analysis of these capabilities in reasoning models. We had eight LLMs make 4,800 veracity judgments across several prompts, comparing reasoning and non-reasoning models. We find that rates of truth-bias, or the likelihood to believe a statement is true, regardless of whether it is actually true, are lower in reasoning models than in non-reasoning models, but still higher than human benchmarks. Most concerning, we identify sycophantic tendencies in several advanced models (o4-mini and GPT-4.1 from OpenAI, R1 from DeepSeek), which displayed an asymmetry in detection accuracy, performing well in truth accuracy but poorly in deception accuracy. This suggests that capability advances alone do not resolve fundamental veracity detection challenges in LLMs.",
    "summary": "arXiv:2506.21561v1 Announce Type: cross Abstract: Despite their widespread use in fact-checking, moderation, and high-stakes decision-making, large language models (LLMs) remain poorly understood as judges of truth. This study presents the largest evaluation to date of LLMs' veracity detection capabilities and the first analysis of these capabilities in reasoning models. We had eight LLMs make 4,800 veracity judgments across several prompts, comparing reasoning and non-reasoning models. We find that rates of truth-bias, or the likelihood to believe a statement is true, regardless of whether it is actually true, are lower in reasoning models than in non-reasoning models, but still higher than human benchmarks. Most concerning, we identify sycophantic tendencies in several advanced models (o4-mini and GPT-4.1 from OpenAI, R1 from DeepSeek), which displayed an asymmetry in detection accuracy, performing well in truth accuracy but poorly in deception accuracy. This suggests that capability advances alone do not resolve fundamental veracity detection challenges in LLMs.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21561",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Powering next generation applications with OpenAI Codex",
    "description": "Codex is now powering 70 different applications across a variety of use cases through the OpenAI¬†API.",
    "summary": "Codex is now powering 70 different applications across a variety of use cases through the OpenAI¬†API.",
    "pubDate": "Tue, 24 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/codex-apps",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI-Enhanced Deliberative Democracy and the Future of the Collective Will",
    "description": "arXiv:2503.05830v2 Announce Type: replace-cross Abstract: This article unpacks the design choices behind longstanding and newly proposed computational frameworks aimed at finding common grounds across collective preferences and examines their potential future impacts, both technically and normatively. It begins by situating AI-assisted preference elicitation within the historical role of opinion polls, emphasizing that preferences are shaped by the decision-making context and are seldom objectively captured. With that caveat in mind, we explore AI-based democratic innovations as discovery tools for fostering reasonable representations of a collective will, sense-making, and agreement-seeking. At the same time, we caution against dangerously misguided uses, such as enabling binding decisions, fostering gradual disempowerment or post-rationalizing political outcomes.",
    "summary": "arXiv:2503.05830v2 Announce Type: replace-cross Abstract: This article unpacks the design choices behind longstanding and newly proposed computational frameworks aimed at finding common grounds across collective preferences and examines their potential future impacts, both technically and normatively. It begins by situating AI-assisted preference elicitation within the historical role of opinion polls, emphasizing that preferences are shaped by the decision-making context and are seldom objectively captured. With that caveat in mind, we explore AI-based democratic innovations as discovery tools for fostering reasonable representations of a collective will, sense-making, and agreement-seeking. At the same time, we caution against dangerously misguided uses, such as enabling binding decisions, fostering gradual disempowerment or post-rationalizing political outcomes.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.05830",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Patch Time Series Transformer in Hugging Face",
    "description": "",
    "summary": "Patch Time Series Transformer in Hugging Face - Getting Started In this blog, we provide examples of...",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/patchtst",
    "thumbnail": "https://huggingface.co/blog/assets/patchtst/thumbnail.png"
  },
  {
    "title": "Learning to model other minds",
    "description": "We‚Äôre releasing an algorithm which accounts for the fact that other agents are learning too, and discovers self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner‚Äôs dilemma. This algorithm, Learning with Opponent-Learning Awareness (LOLA), is a small step towards agents that model other minds.",
    "summary": "We‚Äôre releasing an algorithm which accounts for the fact that other agents are learning too, and discovers self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner‚Äôs dilemma. This algorithm, Learning with Opponent-Learning Awareness (LOLA), is a small step towards agents that model other minds.",
    "pubDate": "Thu, 14 Sep 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-model-other-minds",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy models on AWS Inferentia2 from Hugging Face",
    "description": "",
    "summary": "Deploy models on AWS Inferentia2 from Hugging Face AWS Inferentia2 is the latest AWS machine learnin...",
    "pubDate": "Wed, 22 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inferentia-inference-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/inferentia-inference-endpoints/thumbnail.jpg"
  },
  {
    "title": "Abstracts: Aurora with Megan Stanley and Wessel Bruinsma",
    "description": "<p>A new Nature paper explores Aurora, an AI model that redefines weather prediction with application to other environmental domains such as tropical cyclones. Hear from senior researchers Megan Stanley and Wessel Bruinsma as they share their groundbreaking work.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/abstracts-aurora-with-megan-stanley-and-wessel-bruinsma/'>Abstracts: Aurora with Megan Stanley and Wessel Bruinsma</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>A new Nature paper explores Aurora, an AI model that redefines weather prediction with application to other environmental domains such as tropical cyclones. Hear from senior researchers Megan Stanley and Wessel Bruinsma as they share their groundbreaking work.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/abstracts-aurora-with-megan-stanley-and-wessel-bruinsma/'>Abstracts: Aurora with Megan Stanley and Wessel Bruinsma</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Wed, 21 May 2025 15:22:51 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/abstracts-aurora-with-megan-stanley-and-wessel-bruinsma/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Optimizing Stable Diffusion for Intel CPUs with NNCF and ü§ó Optimum",
    "description": "",
    "summary": "Optimizing Stable Diffusion for Intel CPUs with NNCF and ü§ó Optimum Latent Diffusion models are game ...",
    "pubDate": "Thu, 25 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-optimize-sd-intel",
    "thumbnail": "https://huggingface.co/blog/assets/train_optimize_sd_intel/thumbnail.png"
  },
  {
    "title": "On using AI for EEG-based BCI applications: problems, current challenges and future trends",
    "description": "arXiv:2506.16168v1 Announce Type: cross Abstract: Imagine unlocking the power of the mind to communicate, create, and even interact with the world around us. Recent breakthroughs in Artificial Intelligence (AI), especially in how machines 'see' and 'understand' language, are now fueling exciting progress in decoding brain signals from scalp electroencephalography (EEG). Prima facie, this opens the door to revolutionary brain-computer interfaces (BCIs) designed for real life, moving beyond traditional uses to envision Brain-to-Speech, Brain-to-Image, and even a Brain-to-Internet of Things (BCIoT). However, the journey is not as straightforward as it was for Computer Vision (CV) and Natural Language Processing (NLP). Applying AI to real-world EEG-based BCIs, particularly in building powerful foundational models, presents unique and intricate hurdles that could affect their reliability. Here, we unfold a guided exploration of this dynamic and rapidly evolving research area. Rather than barely outlining a map of current endeavors and results, the goal is to provide a principled navigation of this hot and cutting-edge research landscape. We consider the basic paradigms that emerge from a causal perspective and the attendant challenges presented to AI-based models. Looking ahead, we then discuss promising research avenues that could overcome today's technological, methodological, and ethical limitations. Our aim is to lay out a clear roadmap for creating truly practical and effective EEG-based BCI solutions that can thrive in everyday environments.",
    "summary": "arXiv:2506.16168v1 Announce Type: cross Abstract: Imagine unlocking the power of the mind to communicate, create, and even interact with the world around us. Recent breakthroughs in Artificial Intelligence (AI), especially in how machines 'see' and 'understand' language, are now fueling exciting progress in decoding brain signals from scalp electroencephalography (EEG). Prima facie, this opens the door to revolutionary brain-computer interfaces (BCIs) designed for real life, moving beyond traditional uses to envision Brain-to-Speech, Brain-to-Image, and even a Brain-to-Internet of Things (BCIoT). However, the journey is not as straightforward as it was for Computer Vision (CV) and Natural Language Processing (NLP). Applying AI to real-world EEG-based BCIs, particularly in building powerful foundational models, presents unique and intricate hurdles that could affect their reliability. Here, we unfold a guided exploration of this dynamic and rapidly evolving research area. Rather than barely outlining a map of current endeavors and results, the goal is to provide a principled navigation of this hot and cutting-edge research landscape. We consider the basic paradigms that emerge from a causal perspective and the attendant challenges presented to AI-based models. Looking ahead, we then discuss promising research avenues that could overcome today's technological, methodological, and ethical limitations. Our aim is to lay out a clear roadmap for creating truly practical and effective EEG-based BCI solutions that can thrive in everyday environments.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16168",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning dexterity",
    "description": "We‚Äôve trained a human-like robot hand to manipulate physical objects with unprecedented¬†dexterity.",
    "summary": "We‚Äôve trained a human-like robot hand to manipulate physical objects with unprecedented¬†dexterity.",
    "pubDate": "Mon, 30 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-dexterity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Semi-supervised knowledge transfer for deep learning from private training data",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/semi-supervised-knowledge-transfer-for-deep-learning-from-private-training-data",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "UnMix-NeRF: Spectral Unmixing Meets Neural Radiance Fields",
    "description": "arXiv:2506.21884v1 Announce Type: cross Abstract: Neural Radiance Field (NeRF)-based segmentation methods focus on object semantics and rely solely on RGB data, lacking intrinsic material properties. This limitation restricts accurate material perception, which is crucial for robotics, augmented reality, simulation, and other applications. We introduce UnMix-NeRF, a framework that integrates spectral unmixing into NeRF, enabling joint hyperspectral novel view synthesis and unsupervised material segmentation. Our method models spectral reflectance via diffuse and specular components, where a learned dictionary of global endmembers represents pure material signatures, and per-point abundances capture their distribution. For material segmentation, we use spectral signature predictions along learned endmembers, allowing unsupervised material clustering. Additionally, UnMix-NeRF enables scene editing by modifying learned endmember dictionaries for flexible material-based appearance manipulation. Extensive experiments validate our approach, demonstrating superior spectral reconstruction and material segmentation to existing methods. Project page: https://www.factral.co/UnMix-NeRF.",
    "summary": "arXiv:2506.21884v1 Announce Type: cross Abstract: Neural Radiance Field (NeRF)-based segmentation methods focus on object semantics and rely solely on RGB data, lacking intrinsic material properties. This limitation restricts accurate material perception, which is crucial for robotics, augmented reality, simulation, and other applications. We introduce UnMix-NeRF, a framework that integrates spectral unmixing into NeRF, enabling joint hyperspectral novel view synthesis and unsupervised material segmentation. Our method models spectral reflectance via diffuse and specular components, where a learned dictionary of global endmembers represents pure material signatures, and per-point abundances capture their distribution. For material segmentation, we use spectral signature predictions along learned endmembers, allowing unsupervised material clustering. Additionally, UnMix-NeRF enables scene editing by modifying learned endmember dictionaries for flexible material-based appearance manipulation. Extensive experiments validate our approach, demonstrating superior spectral reconstruction and material segmentation to existing methods. Project page: https://www.factral.co/UnMix-NeRF.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21884",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "We‚Äôre improving Ask Photos and bringing it to more Google Photos users.",
    "description": "Animation showing a search in Ask Photos for 'Photos that'd make great phone backgrounds,' then a grid of initial results followed by the most relevant photos.",
    "summary": "Animation showing a search in Ask Photos for 'Photos that'd make great phone backgrounds,' then a grid of initial results followed by the most relevant photos.",
    "pubDate": "Thu, 26 Jun 2025 17:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/photos/updates-ask-photos-search/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/wagtailvideo-mbcag8qi_thumb.jpg"
  },
  {
    "title": "Emotion Detection on User Front-Facing App Interfaces for Enhanced Schedule Optimization: A Machine Learning Approach",
    "description": "arXiv:2506.19280v1 Announce Type: new Abstract: Human-Computer Interaction (HCI) has evolved significantly to incorporate emotion recognition capabilities, creating unprecedented opportunities for adaptive and personalized user experiences. This paper explores the integration of emotion detection into calendar applications, enabling user interfaces to dynamically respond to users' emotional states and stress levels, thereby enhancing both productivity and engagement. We present and evaluate two complementary approaches to emotion detection: a biometric-based method utilizing heart rate (HR) data extracted from electrocardiogram (ECG) signals processed through Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) neural networks to predict the emotional dimensions of Valence, Arousal, and Dominance; and a behavioral method analyzing computer activity through multiple machine learning models to classify emotions based on fine-grained user interactions such as mouse movements, clicks, and keystroke patterns. Our comparative analysis, from real-world datasets, reveals that while both approaches demonstrate effectiveness, the computer activity-based method delivers superior consistency and accuracy, particularly for mouse-related interactions, which achieved approximately 90% accuracy. Furthermore, GRU networks outperformed LSTM models in the biometric approach, with Valence prediction reaching 84.38% accuracy.",
    "summary": "arXiv:2506.19280v1 Announce Type: new Abstract: Human-Computer Interaction (HCI) has evolved significantly to incorporate emotion recognition capabilities, creating unprecedented opportunities for adaptive and personalized user experiences. This paper explores the integration of emotion detection into calendar applications, enabling user interfaces to dynamically respond to users' emotional states and stress levels, thereby enhancing both productivity and engagement. We present and evaluate two complementary approaches to emotion detection: a biometric-based method utilizing heart rate (HR) data extracted from electrocardiogram (ECG) signals processed through Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) neural networks to predict the emotional dimensions of Valence, Arousal, and Dominance; and a behavioral method analyzing computer activity through multiple machine learning models to classify emotions based on fine-grained user interactions such as mouse movements, clicks, and keystroke patterns. Our comparative analysis, from real-world datasets, reveals that while both approaches demonstrate effectiveness, the computer activity-based method delivers superior consistency and accuracy, particularly for mouse-related interactions, which achieved approximately 90% accuracy. Furthermore, GRU networks outperformed LSTM models in the biometric approach, with Valence prediction reaching 84.38% accuracy.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19280",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Disrupting malicious uses of AI: June 2025",
    "description": "In our June 2025 update, we outline how we‚Äôre disrupting malicious uses of AI‚Äîthrough safety tools that detect and counter abuse, support democratic values, and promote responsible AI deployment for the benefit of all.",
    "summary": "In our June 2025 update, we outline how we‚Äôre disrupting malicious uses of AI‚Äîthrough safety tools that detect and counter abuse, support democratic values, and promote responsible AI deployment for the benefit of all.",
    "pubDate": "Thu, 05 Jun 2025 02:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/disrupting-malicious-uses-of-ai-june-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning Task Belief Similarity with Latent Dynamics for Meta-Reinforcement Learning",
    "description": "arXiv:2506.19785v1 Announce Type: new Abstract: Meta-reinforcement learning requires utilizing prior task distribution information obtained during exploration to rapidly adapt to unknown tasks. The efficiency of an agent's exploration hinges on accurately identifying the current task. Recent Bayes-Adaptive Deep RL approaches often rely on reconstructing the environment's reward signal, which is challenging in sparse reward settings, leading to suboptimal exploitation. Inspired by bisimulation metrics, which robustly extracts behavioral similarity in continuous MDPs, we propose SimBelief-a novel meta-RL framework via measuring similarity of task belief in Bayes-Adaptive MDP (BAMDP). SimBelief effectively extracts common features of similar task distributions, enabling efficient task identification and exploration in sparse reward environments. We introduce latent task belief metric to learn the common structure of similar tasks and incorporate it into the specific task belief. By learning the latent dynamics across task distributions, we connect shared latent task belief features with specific task features, facilitating rapid task identification and adaptation. Our method outperforms state-of-the-art baselines on sparse reward MuJoCo and panda-gym tasks.",
    "summary": "arXiv:2506.19785v1 Announce Type: new Abstract: Meta-reinforcement learning requires utilizing prior task distribution information obtained during exploration to rapidly adapt to unknown tasks. The efficiency of an agent's exploration hinges on accurately identifying the current task. Recent Bayes-Adaptive Deep RL approaches often rely on reconstructing the environment's reward signal, which is challenging in sparse reward settings, leading to suboptimal exploitation. Inspired by bisimulation metrics, which robustly extracts behavioral similarity in continuous MDPs, we propose SimBelief-a novel meta-RL framework via measuring similarity of task belief in Bayes-Adaptive MDP (BAMDP). SimBelief effectively extracts common features of similar task distributions, enabling efficient task identification and exploration in sparse reward environments. We introduce latent task belief metric to learn the common structure of similar tasks and incorporate it into the specific task belief. By learning the latent dynamics across task distributions, we connect shared latent task belief features with specific task features, facilitating rapid task identification and adaptation. Our method outperforms state-of-the-art baselines on sparse reward MuJoCo and panda-gym tasks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19785",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Chain-of-Trust: A Progressive Trust Evaluation Framework Enabled by Generative AI",
    "description": "arXiv:2506.17130v1 Announce Type: new Abstract: In collaborative systems with complex tasks relying on distributed resources, trust evaluation of potential collaborators has emerged as an effective mechanism for task completion. However, due to the network dynamics and varying information gathering latencies, it is extremely challenging to observe and collect all trust attributes of a collaborating device concurrently for a comprehensive trust assessment. In this paper, a novel progressive trust evaluation framework, namely chain-of-trust, is proposed to make better use of misaligned device attribute data. This framework, designed for effective task completion, divides the trust evaluation process into multiple chained stages based on task decomposition. At each stage, based on the task completion process, the framework only gathers the latest device attribute data relevant to that stage, leading to reduced trust evaluation complexity and overhead. By leveraging advanced in-context learning, few-shot learning, and reasoning capabilities, generative AI is then employed to analyze and interpret the collected data to produce correct evaluation results quickly. Only devices deemed trustworthy at this stage proceed to the next round of trust evaluation. The framework ultimately determines devices that remain trustworthy across all stages. Experimental results demonstrate that the proposed framework achieves high accuracy in trust evaluation.",
    "summary": "arXiv:2506.17130v1 Announce Type: new Abstract: In collaborative systems with complex tasks relying on distributed resources, trust evaluation of potential collaborators has emerged as an effective mechanism for task completion. However, due to the network dynamics and varying information gathering latencies, it is extremely challenging to observe and collect all trust attributes of a collaborating device concurrently for a comprehensive trust assessment. In this paper, a novel progressive trust evaluation framework, namely chain-of-trust, is proposed to make better use of misaligned device attribute data. This framework, designed for effective task completion, divides the trust evaluation process into multiple chained stages based on task decomposition. At each stage, based on the task completion process, the framework only gathers the latest device attribute data relevant to that stage, leading to reduced trust evaluation complexity and overhead. By leveraging advanced in-context learning, few-shot learning, and reasoning capabilities, generative AI is then employed to analyze and interpret the collected data to produce correct evaluation results quickly. Only devices deemed trustworthy at this stage proceed to the next round of trust evaluation. The framework ultimately determines devices that remain trustworthy across all stages. Experimental results demonstrate that the proposed framework achieves high accuracy in trust evaluation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17130",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deep Learning with Proteins",
    "description": "",
    "summary": "Deep Learning With Proteins I have two audiences in mind while writing this. One is biologists who a...",
    "pubDate": "Fri, 02 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-learning-with-proteins",
    "thumbnail": "https://huggingface.co/blog/assets/119_deep_learning_with_proteins/folding_example.png"
  },
  {
    "title": "Deep research System Card",
    "description": "This report outlines the safety work carried out prior to releasing deep research including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "summary": "This report outlines the safety work carried out prior to releasing deep research including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "pubDate": "Tue, 25 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-research-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fetch Consolidates AI Tools and Saves 30% Development Time with Hugging Face on AWS",
    "description": "",
    "summary": "Fetch Consolidates AI Tools and Saves 30% Development Time with Hugging Face on AWS If you need supp...",
    "pubDate": "Thu, 23 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fetch-eap-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/fetch2.png"
  },
  {
    "title": "From Prompts to Constructs: A Dual-Validity Framework for LLM Research in Psychology",
    "description": "arXiv:2506.16697v1 Announce Type: cross Abstract: Large language models (LLMs) are rapidly being adopted across psychology, serving as research tools, experimental subjects, human simulators, and computational models of cognition. However, the application of human measurement tools to these systems can produce contradictory results, raising concerns that many findings are measurement phantoms--statistical artifacts rather than genuine psychological phenomena. In this Perspective, we argue that building a robust science of AI psychology requires integrating two of our field's foundational pillars: the principles of reliable measurement and the standards for sound causal inference. We present a dual-validity framework to guide this integration, which clarifies how the evidence needed to support a claim scales with its scientific ambition. Using an LLM to classify text may require only basic accuracy checks, whereas claiming it can simulate anxiety demands a far more rigorous validation process. Current practice systematically fails to meet these requirements, often treating statistical pattern matching as evidence of psychological phenomena. The same model output--endorsing 'I am anxious'--requires different validation strategies depending on whether researchers claim to measure, characterize, simulate, or model psychological constructs. Moving forward requires developing computational analogues of psychological constructs and establishing clear, scalable standards of evidence rather than the uncritical application of human measurement tools.",
    "summary": "arXiv:2506.16697v1 Announce Type: cross Abstract: Large language models (LLMs) are rapidly being adopted across psychology, serving as research tools, experimental subjects, human simulators, and computational models of cognition. However, the application of human measurement tools to these systems can produce contradictory results, raising concerns that many findings are measurement phantoms--statistical artifacts rather than genuine psychological phenomena. In this Perspective, we argue that building a robust science of AI psychology requires integrating two of our field's foundational pillars: the principles of reliable measurement and the standards for sound causal inference. We present a dual-validity framework to guide this integration, which clarifies how the evidence needed to support a claim scales with its scientific ambition. Using an LLM to classify text may require only basic accuracy checks, whereas claiming it can simulate anxiety demands a far more rigorous validation process. Current practice systematically fails to meet these requirements, often treating statistical pattern matching as evidence of psychological phenomena. The same model output--endorsing 'I am anxious'--requires different validation strategies depending on whether researchers claim to measure, characterize, simulate, or model psychological constructs. Moving forward requires developing computational analogues of psychological constructs and establishing clear, scalable standards of evidence rather than the uncritical application of human measurement tools.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16697",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Gemini 2.0: our new AI model for the agentic era",
    "description": "Today, we‚Äôre announcing Gemini 2.0, our most capable multimodal AI model yet.",
    "summary": "Today, we‚Äôre announcing Gemini 2.0, our most capable multimodal AI model yet.",
    "pubDate": "Wed, 11 Dec 2024 15:30:40 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-20-our-new-ai-model-for-the-agentic-era/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/blog_gemini_hero_thumbnail.width-1300.png"
  },
  {
    "title": "Multimodal Fused Learning for Solving the Generalized Traveling Salesman Problem in Robotic Task Planning",
    "description": "arXiv:2506.16931v1 Announce Type: new Abstract: Effective and efficient task planning is essential for mobile robots, especially in applications like warehouse retrieval and environmental monitoring. These tasks often involve selecting one location from each of several target clusters, forming a Generalized Traveling Salesman Problem (GTSP) that remains challenging to solve both accurately and efficiently. To address this, we propose a Multimodal Fused Learning (MMFL) framework that leverages both graph and image-based representations to capture complementary aspects of the problem, and learns a policy capable of generating high-quality task planning schemes in real time. Specifically, we first introduce a coordinate-based image builder that transforms GTSP instances into spatially informative representations. We then design an adaptive resolution scaling strategy to enhance adaptability across different problem scales, and develop a multimodal fusion module with dedicated bottlenecks that enables effective integration of geometric and spatial features. Extensive experiments show that our MMFL approach significantly outperforms state-of-the-art methods across various GTSP instances while maintaining the computational efficiency required for real-time robotic applications. Physical robot tests further validate its practical effectiveness in real-world scenarios.",
    "summary": "arXiv:2506.16931v1 Announce Type: new Abstract: Effective and efficient task planning is essential for mobile robots, especially in applications like warehouse retrieval and environmental monitoring. These tasks often involve selecting one location from each of several target clusters, forming a Generalized Traveling Salesman Problem (GTSP) that remains challenging to solve both accurately and efficiently. To address this, we propose a Multimodal Fused Learning (MMFL) framework that leverages both graph and image-based representations to capture complementary aspects of the problem, and learns a policy capable of generating high-quality task planning schemes in real time. Specifically, we first introduce a coordinate-based image builder that transforms GTSP instances into spatially informative representations. We then design an adaptive resolution scaling strategy to enhance adaptability across different problem scales, and develop a multimodal fusion module with dedicated bottlenecks that enables effective integration of geometric and spatial features. Extensive experiments show that our MMFL approach significantly outperforms state-of-the-art methods across various GTSP instances while maintaining the computational efficiency required for real-time robotic applications. Physical robot tests further validate its practical effectiveness in real-world scenarios.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16931",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Identifying AI-generated images with SynthID",
    "description": "New tool helps watermark and identify synthetic images created by Imagen",
    "summary": "New tool helps watermark and identify synthetic images created by Imagen",
    "pubDate": "Tue, 29 Aug 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/identifying-ai-generated-images-with-synthid/",
    "thumbnail": "https://lh3.googleusercontent.com/wUgtK2GBt2yZJ3dJkXtvAK84G93j6idOOalyihOMfwBxY0lR650fZZYIi3bXdgkKbBcitbUZ0ILbaIPg_-vDTgAJLlP1DO3h_UnyoZ27wl3mYSzKtw=w1200-h630-n-nu"
  },
  {
    "title": "Why OpenAI‚Äôs structure must evolve to advance our mission",
    "description": "A stronger non-profit supported by the for-profit‚Äôs success.",
    "summary": "A stronger non-profit supported by the for-profit‚Äôs success.",
    "pubDate": "Fri, 27 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/why-our-structure-must-evolve-to-advance-our-mission",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning concepts with energy functions",
    "description": "We‚Äôve developed an¬†energy-based model¬†that can quickly learn to identify and generate instances of concepts, such as near, above, between, closest, and furthest, expressed as sets of 2d points. Our model learns these concepts after only five demonstrations. We also show cross-domain transfer: we use concepts learned in a 2d particle environment to solve tasks on a 3-dimensional physics-based¬†robot.",
    "summary": "We‚Äôve developed an¬†energy-based model¬†that can quickly learn to identify and generate instances of concepts, such as near, above, between, closest, and furthest, expressed as sets of 2d points. Our model learns these concepts after only five demonstrations. We also show cross-domain transfer: we use concepts learned in a 2d particle environment to solve tasks on a 3-dimensional physics-based¬†robot.",
    "pubDate": "Wed, 07 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-concepts-with-energy-functions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "5 tips for getting started with Flow",
    "description": "Flow-generated video showing two astronaut pugs driving a car in outer space, with text overlaid saying 'Find your Flow'",
    "summary": "Flow-generated video showing two astronaut pugs driving a car in outer space, with text overlaid saying 'Find your Flow'",
    "pubDate": "Wed, 25 Jun 2025 22:45:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/flow-video-tips/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GetStartedwithFlow_SS.width-1300.png"
  },
  {
    "title": "CF-Seg: Counterfactuals meet Segmentation",
    "description": "arXiv:2506.16213v1 Announce Type: cross Abstract: Segmenting anatomical structures in medical images plays an important role in the quantitative assessment of various diseases. However, accurate segmentation becomes significantly more challenging in the presence of disease. Disease patterns can alter the appearance of surrounding healthy tissues, introduce ambiguous boundaries, or even obscure critical anatomical structures. As such, segmentation models trained on real-world datasets may struggle to provide good anatomical segmentation, leading to potential misdiagnosis. In this paper, we generate counterfactual (CF) images to simulate how the same anatomy would appear in the absence of disease without altering the underlying structure. We then use these CF images to segment structures of interest, without requiring any changes to the underlying segmentation model. Our experiments on two real-world clinical chest X-ray datasets show that the use of counterfactual images improves anatomical segmentation, thereby aiding downstream clinical decision-making.",
    "summary": "arXiv:2506.16213v1 Announce Type: cross Abstract: Segmenting anatomical structures in medical images plays an important role in the quantitative assessment of various diseases. However, accurate segmentation becomes significantly more challenging in the presence of disease. Disease patterns can alter the appearance of surrounding healthy tissues, introduce ambiguous boundaries, or even obscure critical anatomical structures. As such, segmentation models trained on real-world datasets may struggle to provide good anatomical segmentation, leading to potential misdiagnosis. In this paper, we generate counterfactual (CF) images to simulate how the same anatomy would appear in the absence of disease without altering the underlying structure. We then use these CF images to segment structures of interest, without requiring any changes to the underlying segmentation model. Our experiments on two real-world clinical chest X-ray datasets show that the use of counterfactual images improves anatomical segmentation, thereby aiding downstream clinical decision-making.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16213",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerating Stable Diffusion Inference on Intel CPUs",
    "description": "",
    "summary": "Accelerating Stable Diffusion Inference on Intel CPUs Recently, we introduced the latest generation ...",
    "pubDate": "Tue, 28 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable-diffusion-inference-intel",
    "thumbnail": "https://huggingface.co/blog/assets/136_stable_diffusion_inference_intel/01.png"
  },
  {
    "title": "Stochastic Neural Networks for hierarchical reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 10 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/stochastic-neural-networks-for-hierarchical-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Open Proof Corpus: A Large-Scale Study of LLM-Generated Mathematical Proofs",
    "description": "arXiv:2506.21621v1 Announce Type: cross Abstract: In recent months, large language models (LLMs) have made significant progress in mathematical proof generation, but further advancement is hindered by the lack of a large-scale, high-quality dataset of human-evaluated proofs. While expensive to create, such a dataset is essential for driving improvements in training and enabling a rigorous analysis of proof generation capabilities. In this work, we present the Open Proof Corpus (OPC), a dataset comprising over 5,000 human-evaluated proofs produced by state-of-the-art LLMs. The OPC was specifically designed for broad applicability and downstream usage in proof generation research and is the first to include a substantial number of correct, LLM-generated solutions to problems from prestigious mathematics competitions such as the USAMO and IMO. Using the OPC, we explore critical questions in automated proof generation: (1) the performance gap between natural language and formal proof generation, (2) the discrepancy between final-answer accuracy and full-proof validity, and (3) the impact of best-of-n selection on proof quality. Finally, to showcase the utility of the OPC, we finetune an 8B-parameter model on the dataset, obtaining a model that performs on par with the best model, Gemini-2.5-Pro, on the task of evaluating proof correctness.",
    "summary": "arXiv:2506.21621v1 Announce Type: cross Abstract: In recent months, large language models (LLMs) have made significant progress in mathematical proof generation, but further advancement is hindered by the lack of a large-scale, high-quality dataset of human-evaluated proofs. While expensive to create, such a dataset is essential for driving improvements in training and enabling a rigorous analysis of proof generation capabilities. In this work, we present the Open Proof Corpus (OPC), a dataset comprising over 5,000 human-evaluated proofs produced by state-of-the-art LLMs. The OPC was specifically designed for broad applicability and downstream usage in proof generation research and is the first to include a substantial number of correct, LLM-generated solutions to problems from prestigious mathematics competitions such as the USAMO and IMO. Using the OPC, we explore critical questions in automated proof generation: (1) the performance gap between natural language and formal proof generation, (2) the discrepancy between final-answer accuracy and full-proof validity, and (3) the impact of best-of-n selection on proof quality. Finally, to showcase the utility of the OPC, we finetune an 8B-parameter model on the dataset, obtaining a model that performs on par with the best model, Gemini-2.5-Pro, on the task of evaluating proof correctness.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21621",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„Ç¢„É≥„Ç∞„É©AI„ÄåWormGPT„Äç„ÅÆ‰∫úÁ®Æ„ÅåÁôªÂ†¥„ÄÄGrok„Å™„Å©„ÅÆ„É¢„Éá„É´„ÇíÊîπÈÄ†„Åã",
    "description": "Cato Networks„ÅØ„ÄÅÂú∞‰∏ã„Éï„Ç©„Éº„É©„É†„ÅßÊµÅÈÄö„Åô„ÇãWormGPTÊ¥æÁîü2„É¢„Éá„É´„ÅÆÂ≠òÂú®„ÇíÂ†±Âëä„Åó„Åü„ÄÇGrok„Å®Mixtral„ÇíÊÇ™Áî®„Åó„Åükeanu-WormGPT„Å®xzin0vich-WormGPT„ÅåÊ§úÈñ≤ÂõûÈÅø„ÅßÁäØÁΩ™ÊîØÊè¥„Å´Âà©Áî®„Åï„Çå„Å¶„ÅÑ„ÇãÂÆüÊÖã„ÅåÊòé„Çâ„Åã„Å´„Å™„Å£„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "Cato Networks„ÅØ„ÄÅÂú∞‰∏ã„Éï„Ç©„Éº„É©„É†„ÅßÊµÅÈÄö„Åô„ÇãWormGPTÊ¥æÁîü2„É¢„Éá„É´„ÅÆÂ≠òÂú®„ÇíÂ†±Âëä„Åó„Åü„ÄÇGrok„Å®Mixtral„ÇíÊÇ™Áî®„Åó„Åükeanu-WormGPT„Å®xzin0vich-WormGPT„ÅåÊ§úÈñ≤ÂõûÈÅø„ÅßÁäØÁΩ™ÊîØÊè¥„Å´Âà©Áî®„Åï„Çå„Å¶„ÅÑ„ÇãÂÆüÊÖã„ÅåÊòé„Çâ„Åã„Å´„Å™„Å£„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Fri, 20 Jun 2025 07:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/20/news022.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/20/cover_news022.jpg"
  },
  {
    "title": "Song Form-aware Full-Song Text-to-Lyrics Generation with Multi-Level Granularity Syllable Count Control",
    "description": "arXiv:2411.13100v2 Announce Type: replace-cross Abstract: Lyrics generation presents unique challenges, particularly in achieving precise syllable control while adhering to song form structures such as verses and choruses. Conventional line-by-line approaches often lead to unnatural phrasing, underscoring the need for more granular syllable management. We propose a framework for lyrics generation that enables multi-level syllable control at the word, phrase, line, and paragraph levels, aware of song form. Our approach generates complete lyrics conditioned on input text and song form, ensuring alignment with specified syllable constraints. Generated lyrics samples are available at: https://tinyurl.com/lyrics9999",
    "summary": "arXiv:2411.13100v2 Announce Type: replace-cross Abstract: Lyrics generation presents unique challenges, particularly in achieving precise syllable control while adhering to song form structures such as verses and choruses. Conventional line-by-line approaches often lead to unnatural phrasing, underscoring the need for more granular syllable management. We propose a framework for lyrics generation that enables multi-level syllable control at the word, phrase, line, and paragraph levels, aware of song form. Our approach generates complete lyrics conditioned on input text and song form, ensuring alignment with specified syllable constraints. Generated lyrics samples are available at: https://tinyurl.com/lyrics9999",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.13100",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Variance reduction for policy gradient with action-dependent factorized baselines",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 20 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variance-reduction-for-policy-gradient-with-action-dependent-factorized-baselines",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Try the latest Gemini 2.5 Pro before general availability.",
    "description": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_pro_preview_snippet_social_.max-600x600.format-webp.webp' />We‚Äôre introducing an upgraded preview of Gemini 2.5 Pro, our most intelligent model yet. Building on the version we released in May and showed at I/O, this model will be‚Ä¶",
    "summary": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_pro_preview_snippet_social_.max-600x600.format-webp.webp' />We‚Äôre introducing an upgraded preview of Gemini 2.5 Pro, our most intelligent model yet. Building on the version we released in May and showed at I/O, this model will be‚Ä¶",
    "pubDate": "Thu, 05 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/gemini/gemini-2-5-pro-latest-preview/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_pro_preview_snippet_social_share.max-1440x810.jpg"
  },
  {
    "title": "Convergent Linear Representations of Emergent Misalignment",
    "description": "arXiv:2506.11618v2 Announce Type: replace-cross Abstract: Fine-tuning large language models on narrow datasets can cause them to develop broadly misaligned behaviours: a phenomena known as emergent misalignment. However, the mechanisms underlying this misalignment, and why it generalizes beyond the training domain, are poorly understood, demonstrating critical gaps in our knowledge of model alignment. In this work, we train and study a minimal model organism which uses just 9 rank-1 adapters to emergently misalign Qwen2.5-14B-Instruct. Studying this, we find that different emergently misaligned models converge to similar representations of misalignment. We demonstrate this convergence by extracting a 'misalignment direction' from one fine-tuned model's activations, and using it to effectively ablate misaligned behaviour from fine-tunes using higher dimensional LoRAs and different datasets. Leveraging the scalar hidden state of rank-1 LoRAs, we further present a set of experiments for directly interpreting the fine-tuning adapters, showing that six contribute to general misalignment, while two specialise for misalignment in just the fine-tuning domain. Emergent misalignment is a particularly salient example of undesirable and unexpected model behaviour and by advancing our understanding of the mechanisms behind it, we hope to move towards being able to better understand and mitigate misalignment more generally.",
    "summary": "arXiv:2506.11618v2 Announce Type: replace-cross Abstract: Fine-tuning large language models on narrow datasets can cause them to develop broadly misaligned behaviours: a phenomena known as emergent misalignment. However, the mechanisms underlying this misalignment, and why it generalizes beyond the training domain, are poorly understood, demonstrating critical gaps in our knowledge of model alignment. In this work, we train and study a minimal model organism which uses just 9 rank-1 adapters to emergently misalign Qwen2.5-14B-Instruct. Studying this, we find that different emergently misaligned models converge to similar representations of misalignment. We demonstrate this convergence by extracting a 'misalignment direction' from one fine-tuned model's activations, and using it to effectively ablate misaligned behaviour from fine-tunes using higher dimensional LoRAs and different datasets. Leveraging the scalar hidden state of rank-1 LoRAs, we further present a set of experiments for directly interpreting the fine-tuning adapters, showing that six contribute to general misalignment, while two specialise for misalignment in just the fine-tuning domain. Emergent misalignment is a particularly salient example of undesirable and unexpected model behaviour and by advancing our understanding of the mechanisms behind it, we hope to move towards being able to better understand and mitigate misalignment more generally.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11618",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using Language and Road Manuals to Inform Map Reconstruction for Autonomous Driving",
    "description": "arXiv:2506.10317v2 Announce Type: replace-cross Abstract: Lane-topology prediction is a critical component of safe and reliable autonomous navigation. An accurate understanding of the road environment aids this task. We observe that this information often follows conventions encoded in natural language, through design codes that reflect the road structure and road names that capture the road functionality. We augment this information in a lightweight manner to SMERF, a map-prior-based online lane-topology prediction model, by combining structured road metadata from OSM maps and lane-width priors from Road design manuals with the road centerline encodings. We evaluate our method on two geo-diverse complex intersection scenarios. Our method shows improvement in both lane and traffic element detection and their association. We report results using four topology-aware metrics to comprehensively assess the model performance. These results demonstrate the ability of our approach to generalize and scale to diverse topologies and conditions.",
    "summary": "arXiv:2506.10317v2 Announce Type: replace-cross Abstract: Lane-topology prediction is a critical component of safe and reliable autonomous navigation. An accurate understanding of the road environment aids this task. We observe that this information often follows conventions encoded in natural language, through design codes that reflect the road structure and road names that capture the road functionality. We augment this information in a lightweight manner to SMERF, a map-prior-based online lane-topology prediction model, by combining structured road metadata from OSM maps and lane-width priors from Road design manuals with the road centerline encodings. We evaluate our method on two geo-diverse complex intersection scenarios. Our method shows improvement in both lane and traffic element detection and their association. We report results using four topology-aware metrics to comprehensively assess the model performance. These results demonstrate the ability of our approach to generalize and scale to diverse topologies and conditions.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.10317",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AutoHFormer: Efficient Hierarchical Autoregressive Transformer for Time Series Prediction",
    "description": "arXiv:2506.16001v1 Announce Type: cross Abstract: Time series forecasting requires architectures that simultaneously achieve three competing objectives: (1) strict temporal causality for reliable predictions, (2) sub-quadratic complexity for practical scalability, and (3) multi-scale pattern recognition for accurate long-horizon forecasting. We introduce AutoHFormer, a hierarchical autoregressive transformer that addresses these challenges through three key innovations: 1) Hierarchical Temporal Modeling: Our architecture decomposes predictions into segment-level blocks processed in parallel, followed by intra-segment sequential refinement. This dual-scale approach maintains temporal coherence while enabling efficient computation. 2) Dynamic Windowed Attention: The attention mechanism employs learnable causal windows with exponential decay, reducing complexity while preserving precise temporal relationships. This design avoids both the anti-causal violations of standard transformers and the sequential bottlenecks of RNN hybrids. 3) Adaptive Temporal Encoding: a novel position encoding system is adopted to capture time patterns at multiple scales. It combines fixed oscillating patterns for short-term variations with learnable decay rates for long-term trends. Comprehensive experiments demonstrate that AutoHFormer 10.76X faster training and 6.06X memory reduction compared to PatchTST on PEMS08, while maintaining consistent accuracy across 96-720 step horizons in most of cases. These breakthroughs establish new benchmarks for efficient and precise time series modeling. Implementations of our method and all baselines in hierarchical autoregressive mechanism are available at https://github.com/lizzyhku/Autotime.",
    "summary": "arXiv:2506.16001v1 Announce Type: cross Abstract: Time series forecasting requires architectures that simultaneously achieve three competing objectives: (1) strict temporal causality for reliable predictions, (2) sub-quadratic complexity for practical scalability, and (3) multi-scale pattern recognition for accurate long-horizon forecasting. We introduce AutoHFormer, a hierarchical autoregressive transformer that addresses these challenges through three key innovations: 1) Hierarchical Temporal Modeling: Our architecture decomposes predictions into segment-level blocks processed in parallel, followed by intra-segment sequential refinement. This dual-scale approach maintains temporal coherence while enabling efficient computation. 2) Dynamic Windowed Attention: The attention mechanism employs learnable causal windows with exponential decay, reducing complexity while preserving precise temporal relationships. This design avoids both the anti-causal violations of standard transformers and the sequential bottlenecks of RNN hybrids. 3) Adaptive Temporal Encoding: a novel position encoding system is adopted to capture time patterns at multiple scales. It combines fixed oscillating patterns for short-term variations with learnable decay rates for long-term trends. Comprehensive experiments demonstrate that AutoHFormer 10.76X faster training and 6.06X memory reduction compared to PatchTST on PEMS08, while maintaining consistent accuracy across 96-720 step horizons in most of cases. These breakthroughs establish new benchmarks for efficient and precise time series modeling. Implementations of our method and all baselines in hierarchical autoregressive mechanism are available at https://github.com/lizzyhku/Autotime.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16001",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Geometric Learning in Black-Box Optimization: A GNN Framework for Algorithm Performance Prediction",
    "description": "arXiv:2506.16144v1 Announce Type: new Abstract: Automated algorithm performance prediction in numerical blackbox optimization often relies on problem characterizations, such as exploratory landscape analysis features. These features are typically used as inputs to machine learning models and are represented in a tabular format. However, such approaches often overlook algorithm configurations, a key factor influencing performance. The relationships between algorithm operators, parameters, problem characteristics, and performance outcomes form a complex structure best represented as a graph. This work explores the use of heterogeneous graph data structures and graph neural networks to predict the performance of optimization algorithms by capturing the complex dependencies between problems, algorithm configurations, and performance outcomes. We focus on two modular frameworks, modCMA-ES and modDE, which decompose two widely used derivative-free optimization algorithms: the covariance matrix adaptation evolution strategy (CMA-ES) and differential evolution (DE). We evaluate 324 modCMA-ES and 576 modDE variants on 24 BBOB problems across six runtime budgets and two problem dimensions. Achieving up to 36.6% improvement in MSE over traditional tabular-based methods, this work highlights the potential of geometric learning in black-box optimization.",
    "summary": "arXiv:2506.16144v1 Announce Type: new Abstract: Automated algorithm performance prediction in numerical blackbox optimization often relies on problem characterizations, such as exploratory landscape analysis features. These features are typically used as inputs to machine learning models and are represented in a tabular format. However, such approaches often overlook algorithm configurations, a key factor influencing performance. The relationships between algorithm operators, parameters, problem characteristics, and performance outcomes form a complex structure best represented as a graph. This work explores the use of heterogeneous graph data structures and graph neural networks to predict the performance of optimization algorithms by capturing the complex dependencies between problems, algorithm configurations, and performance outcomes. We focus on two modular frameworks, modCMA-ES and modDE, which decompose two widely used derivative-free optimization algorithms: the covariance matrix adaptation evolution strategy (CMA-ES) and differential evolution (DE). We evaluate 324 modCMA-ES and 576 modDE variants on 24 BBOB problems across six runtime budgets and two problem dimensions. Achieving up to 36.6% improvement in MSE over traditional tabular-based methods, this work highlights the potential of geometric learning in black-box optimization.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16144",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "StarCoder2 and The Stack v2",
    "description": "",
    "summary": "StarCoder2 and The Stack v2 BigCode is releasing StarCoder2, the next generation of transparently tr...",
    "pubDate": "Wed, 28 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starcoder2",
    "thumbnail": "https://huggingface.co/blog/assets/177_starcoder2/sc2-banner.png"
  },
  {
    "title": "Neural MMO: A massively multiagent game environment",
    "description": "We‚Äôre releasing a Neural¬†MMO, a massively multiagent game environment for reinforcement learning agents. Our platform supports a large, variable number of agents within a persistent and open-ended task. The inclusion of many agents and species leads to better exploration, divergent niche formation, and greater overall¬†competence.",
    "summary": "We‚Äôre releasing a Neural¬†MMO, a massively multiagent game environment for reinforcement learning agents. Our platform supports a large, variable number of agents within a persistent and open-ended task. The inclusion of many agents and species leads to better exploration, divergent niche formation, and greater overall¬†competence.",
    "pubDate": "Mon, 04 Mar 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/neural-mmo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI hackathon",
    "description": "Come to OpenAI‚Äôs office in San Francisco‚Äôs Mission District for talks and a hackathon on Saturday, March 3rd.",
    "summary": "Come to OpenAI‚Äôs office in San Francisco‚Äôs Mission District for talks and a hackathon on Saturday, March 3rd.",
    "pubDate": "Thu, 22 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-hackathon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ethical guidelines for developing the Diffusers library",
    "description": "",
    "summary": "Ethical guidelines for developing the Diffusers library We are on a journey to make our libraries mo...",
    "pubDate": "Thu, 02 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/ethics-diffusers/thumbnail.png"
  },
  {
    "title": "Using OpenAI o1 for financial analysis",
    "description": "Rogo scales AI-driven financial research with OpenAI o1",
    "summary": "Rogo scales AI-driven financial research with OpenAI o1",
    "pubDate": "Thu, 13 Feb 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rogo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Nystr√∂mformer, Approximating self-attention in linear time and memory via the Nystr√∂m method",
    "description": "",
    "summary": "Nystr√∂mformer: Approximating self-attention in linear time and memory via the Nystr√∂m method Introdu...",
    "pubDate": "Tue, 02 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nystromformer",
    "thumbnail": "https://huggingface.co/blog/assets/86_nystromformer/thumbnail.png"
  },
  {
    "title": "OpenAI and GEDI partner for Italian news content",
    "description": "OpenAI and GEDI announce strategic partnership to bring Italian-language news content to ChatGPT.",
    "summary": "OpenAI and GEDI announce strategic partnership to bring Italian-language news content to ChatGPT.",
    "pubDate": "Thu, 26 Sep 2024 04:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gedi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Helping machines understand visual content with AI",
    "description": "Coactive, founded by two MIT alumni, has built an AI-powered platform to unlock new insights from content of all types.",
    "summary": "Coactive, founded by two MIT alumni, has built an AI-powered platform to unlock new insights from content of all types.",
    "pubDate": "Mon, 09 Jun 2025 15:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/coactive-helps-machines-understand-visual-content-ai-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Coactive-AI-01-press.jpg"
  },
  {
    "title": "The power of personalized AI",
    "description": "The power of personalized AI",
    "summary": "The power of personalized AI",
    "pubDate": "Fri, 17 Jan 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/the-power-of-personalized-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Jupyter X Hugging Face",
    "description": "",
    "summary": "Jupyter X Hugging Face We‚Äôre excited to announce improved support for Jupyter notebooks hosted on th...",
    "pubDate": "Thu, 23 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/notebooks-hub",
    "thumbnail": "https://huggingface.co/blog/assets/135_notebooks-hub/before_after_notebook_rendering.png"
  },
  {
    "title": "Embedding AI into developer software",
    "description": "JetBrains uses OpenAI‚Äôs API to build its fastest-growing product ever.",
    "summary": "JetBrains uses OpenAI‚Äôs API to build its fastest-growing product ever.",
    "pubDate": "Thu, 21 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jetbrains",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaQubit tackles one of quantum computing‚Äôs biggest challenges",
    "description": "Our new AI system accurately identifies errors inside quantum computers, helping to make this new technology more reliable.",
    "summary": "Our new AI system accurately identifies errors inside quantum computers, helping to make this new technology more reliable.",
    "pubDate": "Wed, 20 Nov 2024 18:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaqubit-tackles-one-of-quantum-computings-biggest-challenges/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Social_Share_Image_-_1920_x_1080.width-1300.png"
  },
  {
    "title": "NotebookLM is adding a new way to share your own notebooks publicly.",
    "description": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NotebookLMSharing_SS.max-600x600.format-webp.webp' />Many people who use NotebookLM already share their notebooks with classmates, coworkers, students and friends. Today, we're making sharing and curation easier ‚Äî with pub‚Ä¶",
    "summary": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NotebookLMSharing_SS.max-600x600.format-webp.webp' />Many people who use NotebookLM already share their notebooks with classmates, coworkers, students and friends. Today, we're making sharing and curation easier ‚Äî with pub‚Ä¶",
    "pubDate": "Tue, 03 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/google-labs/notebooklm-public-notebooks/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NotebookLMSharing_SS.max-1440x810.png"
  },
  {
    "title": "Spiritual-LLM : Gita Inspired Mental Health Therapy In the Era of LLMs",
    "description": "arXiv:2506.19185v1 Announce Type: new Abstract: Traditional mental health support systems often generate responses based solely on the user's current emotion and situations, resulting in superficial interventions that fail to address deeper emotional needs. This study introduces a novel framework by integrating spiritual wisdom from the Bhagavad Gita with advanced large language model GPT-4o to enhance emotional well-being. We present the GITes (Gita Integrated Therapy for Emotional Support) dataset, which enhances the existing ExTES mental health dataset by including 10,729 spiritually guided responses generated by GPT-4o and evaluated by domain experts. We benchmark GITes against 12 state-of-the-art LLMs, including both mental health specific and general purpose models. To evaluate spiritual relevance in generated responses beyond what conventional n-gram based metrics capture, we propose a novel Spiritual Insight metric and automate assessment via an LLM as jury framework using chain-of-thought prompting. Integrating spiritual guidance into AI driven support enhances both NLP and spiritual metrics for the best performing LLM Phi3-Mini 3.2B Instruct, achieving improvements of 122.71% in ROUGE, 126.53% in METEOR, 8.15% in BERT score, 15.92% in Spiritual Insight, 18.61% in Sufficiency and 13.22% in Relevance compared to its zero-shot counterpart. While these results reflect substantial improvements across automated empathy and spirituality metrics, further validation in real world patient populations remains a necessary step. Our findings indicate a strong potential for AI systems enriched with spiritual guidance to enhance user satisfaction and perceived support outcomes. The code and dataset will be publicly available to advance further research in this emerging area.",
    "summary": "arXiv:2506.19185v1 Announce Type: new Abstract: Traditional mental health support systems often generate responses based solely on the user's current emotion and situations, resulting in superficial interventions that fail to address deeper emotional needs. This study introduces a novel framework by integrating spiritual wisdom from the Bhagavad Gita with advanced large language model GPT-4o to enhance emotional well-being. We present the GITes (Gita Integrated Therapy for Emotional Support) dataset, which enhances the existing ExTES mental health dataset by including 10,729 spiritually guided responses generated by GPT-4o and evaluated by domain experts. We benchmark GITes against 12 state-of-the-art LLMs, including both mental health specific and general purpose models. To evaluate spiritual relevance in generated responses beyond what conventional n-gram based metrics capture, we propose a novel Spiritual Insight metric and automate assessment via an LLM as jury framework using chain-of-thought prompting. Integrating spiritual guidance into AI driven support enhances both NLP and spiritual metrics for the best performing LLM Phi3-Mini 3.2B Instruct, achieving improvements of 122.71% in ROUGE, 126.53% in METEOR, 8.15% in BERT score, 15.92% in Spiritual Insight, 18.61% in Sufficiency and 13.22% in Relevance compared to its zero-shot counterpart. While these results reflect substantial improvements across automated empathy and spirituality metrics, further validation in real world patient populations remains a necessary step. Our findings indicate a strong potential for AI systems enriched with spiritual guidance to enhance user satisfaction and perceived support outcomes. The code and dataset will be publicly available to advance further research in this emerging area.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19185",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Zico Kolter Joins OpenAI‚Äôs Board of Directors",
    "description": "Zico Kolter Joins OpenAI‚Äôs Board of Directors We‚Äôre strengthening our governance with expertise in AI safety and alignment. Zico will also join the Safety & Security Committee",
    "summary": "Zico Kolter Joins OpenAI‚Äôs Board of Directors We‚Äôre strengthening our governance with expertise in AI safety and alignment. Zico will also join the Safety & Security Committee",
    "pubDate": "Thu, 08 Aug 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zico-kolter-joins-openais-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Research on Model Parallelism and Data Parallelism Optimization Methods in Large Language Model-Based Recommendation Systems",
    "description": "arXiv:2506.17551v2 Announce Type: replace-cross Abstract: With the rapid adoption of large language models (LLMs) in recommendation systems, the computational and communication bottlenecks caused by their massive parameter sizes and large data volumes have become increasingly prominent. This paper systematically investigates two classes of optimization methods-model parallelism and data parallelism-for distributed training of LLMs in recommendation scenarios. For model parallelism, we implement both tensor parallelism and pipeline parallelism, and introduce an adaptive load-balancing mechanism to reduce cross-device communication overhead. For data parallelism, we compare synchronous and asynchronous modes, combining gradient compression and sparsification techniques with an efficient aggregation communication framework to significantly improve bandwidth utilization. Experiments conducted on a real-world recommendation dataset in a simulated service environment demonstrate that our proposed hybrid parallelism scheme increases training throughput by over 30% and improves resource utilization by approximately 20% compared to traditional single-mode parallelism, while maintaining strong scalability and robustness. Finally, we discuss trade-offs among different parallel strategies in online deployment and outline future directions involving heterogeneous hardware integration and automated scheduling technologies.",
    "summary": "arXiv:2506.17551v2 Announce Type: replace-cross Abstract: With the rapid adoption of large language models (LLMs) in recommendation systems, the computational and communication bottlenecks caused by their massive parameter sizes and large data volumes have become increasingly prominent. This paper systematically investigates two classes of optimization methods-model parallelism and data parallelism-for distributed training of LLMs in recommendation scenarios. For model parallelism, we implement both tensor parallelism and pipeline parallelism, and introduce an adaptive load-balancing mechanism to reduce cross-device communication overhead. For data parallelism, we compare synchronous and asynchronous modes, combining gradient compression and sparsification techniques with an efficient aggregation communication framework to significantly improve bandwidth utilization. Experiments conducted on a real-world recommendation dataset in a simulated service environment demonstrate that our proposed hybrid parallelism scheme increases training throughput by over 30% and improves resource utilization by approximately 20% compared to traditional single-mode parallelism, while maintaining strong scalability and robustness. Finally, we discuss trade-offs among different parallel strategies in online deployment and outline future directions involving heterogeneous hardware integration and automated scheduling technologies.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17551",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Put AI to work for your product team",
    "description": "Put AI to work for your product team",
    "summary": "Put AI to work for your product team",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/put-ai-to-work-for-your-product-team",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Five",
    "description": "Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota¬†2.",
    "summary": "Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota¬†2.",
    "pubDate": "Mon, 25 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and AWS partner to make AI more accessible",
    "description": "",
    "summary": "Hugging Face and AWS partner to make AI more accessible It‚Äôs time to make AI open and accessible to ...",
    "pubDate": "Tue, 21 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aws-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/131_aws-partnership/aws-partnership-thumbnail.png"
  },
  {
    "title": "tsuzumiÊ¥ªÁî®„ÄÅÂåªÁôÇÊñáÊõ∏‰ΩúÊàêÊîØÊè¥AI„ÅßÂåªÁôÇ„Çµ„Éº„Éì„ÇπÂêë‰∏ä„ÇíÁõÆÊåá„Åô„ÄÇNTTÊù±Êó•Êú¨„Å®Êñ∞ÊΩüÂ§ßÂ≠¶„ÅåÂÖ±ÂêåÁ†îÁ©∂",
    "description": "<p>NTTÊù±Êó•Êú¨„Å®Êñ∞ÊΩüÂ§ßÂ≠¶„ÅØ„ÄÅÂåªÂ∏´‰∏çË∂≥„ÅÆËß£Ê∂à„Å®ÂåªÁôÇ„Çµ„Éº„Éì„Çπ„ÅÆË≥™Âêë‰∏ä„ÇíÁõÆÁöÑ„Å´„ÄÅNTT„ÅåÈñãÁô∫„Åó„ÅüÂ§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´„Äåtsuzumi„Äç„ÇíÊ¥ªÁî®„Åó„ÅüÂåªÁôÇÊñáÊõ∏‰ΩúÊàêÊîØÊè¥AI„É¢„Éá„É´„ÅÆÂÆüË®º‰∫ãÊ•≠„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà NTTÊù±Êó• [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ntt-east-niigata-university-ai/'>tsuzumiÊ¥ªÁî®„ÄÅÂåªÁôÇÊñáÊõ∏‰ΩúÊàêÊîØÊè¥AI„ÅßÂåªÁôÇ„Çµ„Éº„Éì„ÇπÂêë‰∏ä„ÇíÁõÆÊåá„Åô„ÄÇNTTÊù±Êó•Êú¨„Å®Êñ∞ÊΩüÂ§ßÂ≠¶„ÅåÂÖ±ÂêåÁ†îÁ©∂</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>NTTÊù±Êó•Êú¨„Å®Êñ∞ÊΩüÂ§ßÂ≠¶„ÅØ„ÄÅÂåªÂ∏´‰∏çË∂≥„ÅÆËß£Ê∂à„Å®ÂåªÁôÇ„Çµ„Éº„Éì„Çπ„ÅÆË≥™Âêë‰∏ä„ÇíÁõÆÁöÑ„Å´„ÄÅNTT„ÅåÈñãÁô∫„Åó„ÅüÂ§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´„Äåtsuzumi„Äç„ÇíÊ¥ªÁî®„Åó„ÅüÂåªÁôÇÊñáÊõ∏‰ΩúÊàêÊîØÊè¥AI„É¢„Éá„É´„ÅÆÂÆüË®º‰∫ãÊ•≠„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà NTTÊù±Êó• [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/ntt-east-niigata-university-ai/'>tsuzumiÊ¥ªÁî®„ÄÅÂåªÁôÇÊñáÊõ∏‰ΩúÊàêÊîØÊè¥AI„ÅßÂåªÁôÇ„Çµ„Éº„Éì„ÇπÂêë‰∏ä„ÇíÁõÆÊåá„Åô„ÄÇNTTÊù±Êó•Êú¨„Å®Êñ∞ÊΩüÂ§ßÂ≠¶„ÅåÂÖ±ÂêåÁ†îÁ©∂</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Wed, 11 Jun 2025 00:55:41 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/ntt-east-niigata-university-ai/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/05/ntt-east-niigata-university-ai.png"
  },
  {
    "title": "Answering quantum physics questions with OpenAI o1",
    "description": "Quantum physicist Mario Krenn uses OpenAI o1 to help answer life's biggest questions.",
    "summary": "Quantum physicist Mario Krenn uses OpenAI o1 to help answer life's biggest questions.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-quantum-physics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Which Consciousness Can Be Artificialized? Local Percept-Perceiver Phenomenon for the Existence of Machine Consciousness",
    "description": "arXiv:2506.18935v1 Announce Type: cross Abstract: This paper presents a novel paradigm of the local percept-perceiver phenomenon to formalize certain observations in neuroscientific theories of consciousness. Using this model, a set-theoretic formalism is developed for artificial systems, and the existence of machine consciousness is proved by invoking Zermelo-Fraenkel set theory. The article argues for the possibility of a reductionist form of epistemic consciousness within machines.",
    "summary": "arXiv:2506.18935v1 Announce Type: cross Abstract: This paper presents a novel paradigm of the local percept-perceiver phenomenon to formalize certain observations in neuroscientific theories of consciousness. Using this model, a set-theoretic formalism is developed for artificial systems, and the existence of machine consciousness is proved by invoking Zermelo-Fraenkel set theory. The article argues for the possibility of a reductionist form of epistemic consciousness within machines.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18935",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Governance of superintelligence",
    "description": "Now is a good time to start thinking about the governance of superintelligence‚Äîfuture AI systems dramatically more capable than even AGI.",
    "summary": "Now is a good time to start thinking about the governance of superintelligence‚Äîfuture AI systems dramatically more capable than even AGI.",
    "pubDate": "Mon, 22 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/governance-of-superintelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The SWE-Bench Illusion: When State-of-the-Art LLMs Remember Instead of Reason",
    "description": "arXiv:2506.12286v2 Announce Type: replace Abstract: As large language models (LLMs) become increasingly capable and widely adopted, benchmarks play a central role in assessing their practical utility. For example, SWE-Bench Verified has emerged as a critical benchmark for evaluating LLMs' software engineering abilities, particularly their aptitude for resolving real-world GitHub issues. Recent LLMs show impressive performance on SWE-Bench, leading to optimism about their capacity for complex coding tasks. However, current evaluation protocols may overstate these models' true capabilities. It is crucial to distinguish LLMs' generalizable problem-solving ability and other learned artifacts. In this work, we introduce two diagnostic tasks: file path identification from issue descriptions alone, and ground truth function reproduction with only the current file context and issue description to probe models' underlying knowledge. We present empirical evidence that performance gains on SWE-Bench-Verified may be partially driven by memorization rather than genuine problem-solving. We show that state-of-the-art models achieve up to 76% accuracy in identifying buggy file paths using only issue descriptions, without access to repository structure. This performance is merely up to 53% on tasks from repositories not included in SWE-Bench, pointing to possible data contamination or memorization. A similar pattern is also observed for the function reproduction task, where the verbatim similarity is much higher on SWE-Bench-Verified than on other similar coding benchmarks. These findings raise concerns about the validity of existing results and underscore the need for more robust, contamination-resistant benchmarks to reliably evaluate LLMs' coding abilities.",
    "summary": "arXiv:2506.12286v2 Announce Type: replace Abstract: As large language models (LLMs) become increasingly capable and widely adopted, benchmarks play a central role in assessing their practical utility. For example, SWE-Bench Verified has emerged as a critical benchmark for evaluating LLMs' software engineering abilities, particularly their aptitude for resolving real-world GitHub issues. Recent LLMs show impressive performance on SWE-Bench, leading to optimism about their capacity for complex coding tasks. However, current evaluation protocols may overstate these models' true capabilities. It is crucial to distinguish LLMs' generalizable problem-solving ability and other learned artifacts. In this work, we introduce two diagnostic tasks: file path identification from issue descriptions alone, and ground truth function reproduction with only the current file context and issue description to probe models' underlying knowledge. We present empirical evidence that performance gains on SWE-Bench-Verified may be partially driven by memorization rather than genuine problem-solving. We show that state-of-the-art models achieve up to 76% accuracy in identifying buggy file paths using only issue descriptions, without access to repository structure. This performance is merely up to 53% on tasks from repositories not included in SWE-Bench, pointing to possible data contamination or memorization. A similar pattern is also observed for the function reproduction task, where the verbatim similarity is much higher on SWE-Bench-Verified than on other similar coding benchmarks. These findings raise concerns about the validity of existing results and underscore the need for more robust, contamination-resistant benchmarks to reliably evaluate LLMs' coding abilities.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12286",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "QG-SMS: Enhancing Test Item Analysis via Student Modeling and Simulation",
    "description": "arXiv:2503.05888v2 Announce Type: replace-cross Abstract: While the Question Generation (QG) task has been increasingly adopted in educational assessments, its evaluation remains limited by approaches that lack a clear connection to the educational values of test items. In this work, we introduce test item analysis, a method frequently used by educators to assess test question quality, into QG evaluation. Specifically, we construct pairs of candidate questions that differ in quality across dimensions such as topic coverage, item difficulty, item discrimination, and distractor efficiency. We then examine whether existing QG evaluation approaches can effectively distinguish these differences. Our findings reveal significant shortcomings in these approaches with respect to accurately assessing test item quality in relation to student performance. To address this gap, we propose a novel QG evaluation framework, QG-SMS, which leverages Large Language Model for Student Modeling and Simulation to perform test item analysis. As demonstrated in our extensive experiments and human evaluation study, the additional perspectives introduced by the simulated student profiles lead to a more effective and robust assessment of test items.",
    "summary": "arXiv:2503.05888v2 Announce Type: replace-cross Abstract: While the Question Generation (QG) task has been increasingly adopted in educational assessments, its evaluation remains limited by approaches that lack a clear connection to the educational values of test items. In this work, we introduce test item analysis, a method frequently used by educators to assess test question quality, into QG evaluation. Specifically, we construct pairs of candidate questions that differ in quality across dimensions such as topic coverage, item difficulty, item discrimination, and distractor efficiency. We then examine whether existing QG evaluation approaches can effectively distinguish these differences. Our findings reveal significant shortcomings in these approaches with respect to accurately assessing test item quality in relation to student performance. To address this gap, we propose a novel QG evaluation framework, QG-SMS, which leverages Large Language Model for Student Modeling and Simulation to perform test item analysis. As demonstrated in our extensive experiments and human evaluation study, the additional perspectives introduced by the simulated student profiles lead to a more effective and robust assessment of test items.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.05888",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MuseControlLite: Multifunctional Music Generation with Lightweight Conditioners",
    "description": "arXiv:2506.18729v2 Announce Type: replace-cross Abstract: We propose MuseControlLite, a lightweight mechanism designed to fine-tune text-to-music generation models for precise conditioning using various time-varying musical attributes and reference audio signals. The key finding is that positional embeddings, which have been seldom used by text-to-music generation models in the conditioner for text conditions, are critical when the condition of interest is a function of time. Using melody control as an example, our experiments show that simply adding rotary positional embeddings to the decoupled cross-attention layers increases control accuracy from 56.6% to 61.1%, while requiring 6.75 times fewer trainable parameters than state-of-the-art fine-tuning mechanisms, using the same pre-trained diffusion Transformer model of Stable Audio Open. We evaluate various forms of musical attribute control, audio inpainting, and audio outpainting, demonstrating improved controllability over MusicGen-Large and Stable Audio Open ControlNet at a significantly lower fine-tuning cost, with only 85M trainble parameters. Source code, model checkpoints, and demo examples are available at: https://musecontrollite.github.io/web/.",
    "summary": "arXiv:2506.18729v2 Announce Type: replace-cross Abstract: We propose MuseControlLite, a lightweight mechanism designed to fine-tune text-to-music generation models for precise conditioning using various time-varying musical attributes and reference audio signals. The key finding is that positional embeddings, which have been seldom used by text-to-music generation models in the conditioner for text conditions, are critical when the condition of interest is a function of time. Using melody control as an example, our experiments show that simply adding rotary positional embeddings to the decoupled cross-attention layers increases control accuracy from 56.6% to 61.1%, while requiring 6.75 times fewer trainable parameters than state-of-the-art fine-tuning mechanisms, using the same pre-trained diffusion Transformer model of Stable Audio Open. We evaluate various forms of musical attribute control, audio inpainting, and audio outpainting, demonstrating improved controllability over MusicGen-Large and Stable Audio Open ControlNet at a significantly lower fine-tuning cost, with only 85M trainble parameters. Source code, model checkpoints, and demo examples are available at: https://musecontrollite.github.io/web/.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18729",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improving Student-AI Interaction Through Pedagogical Prompting: An Example in Computer Science Education",
    "description": "arXiv:2506.19107v1 Announce Type: cross Abstract: With the proliferation of large language model (LLM) applications since 2022, their use in education has sparked both excitement and concern. Recent studies consistently highlight students' (mis)use of LLMs can hinder learning outcomes. This work aims to teach students how to effectively prompt LLMs to improve their learning. We first proposed pedagogical prompting, a theoretically-grounded new concept to elicit learning-oriented responses from LLMs. To move from concept design to a proof-of-concept learning intervention in real educational settings, we selected early undergraduate CS education (CS1/CS2) as the example context. We began with a formative survey study with instructors (N=36) teaching early-stage undergraduate-level CS courses to inform the instructional design based on classroom needs. Based on their insights, we designed and developed a learning intervention through an interactive system with scenario-based instruction to train pedagogical prompting skills. Finally, we evaluated its instructional effectiveness through a user study with CS novice students (N=22) using pre/post-tests. Through mixed methods analyses, our results indicate significant improvements in learners' LLM-based pedagogical help-seeking skills, along with positive attitudes toward the system and increased willingness to use pedagogical prompts in the future. Our contributions include (1) a theoretical framework of pedagogical prompting; (2) empirical insights into current instructor attitudes toward pedagogical prompting; and (3) a learning intervention design with an interactive learning tool and scenario-based instruction leading to promising results on teaching LLM-based help-seeking. Our approach is scalable for broader implementation in classrooms and has the potential to be integrated into tools like ChatGPT as an on-boarding experience to encourage learning-oriented use of generative AI.",
    "summary": "arXiv:2506.19107v1 Announce Type: cross Abstract: With the proliferation of large language model (LLM) applications since 2022, their use in education has sparked both excitement and concern. Recent studies consistently highlight students' (mis)use of LLMs can hinder learning outcomes. This work aims to teach students how to effectively prompt LLMs to improve their learning. We first proposed pedagogical prompting, a theoretically-grounded new concept to elicit learning-oriented responses from LLMs. To move from concept design to a proof-of-concept learning intervention in real educational settings, we selected early undergraduate CS education (CS1/CS2) as the example context. We began with a formative survey study with instructors (N=36) teaching early-stage undergraduate-level CS courses to inform the instructional design based on classroom needs. Based on their insights, we designed and developed a learning intervention through an interactive system with scenario-based instruction to train pedagogical prompting skills. Finally, we evaluated its instructional effectiveness through a user study with CS novice students (N=22) using pre/post-tests. Through mixed methods analyses, our results indicate significant improvements in learners' LLM-based pedagogical help-seeking skills, along with positive attitudes toward the system and increased willingness to use pedagogical prompts in the future. Our contributions include (1) a theoretical framework of pedagogical prompting; (2) empirical insights into current instructor attitudes toward pedagogical prompting; and (3) a learning intervention design with an interactive learning tool and scenario-based instruction leading to promising results on teaching LLM-based help-seeking. Our approach is scalable for broader implementation in classrooms and has the potential to be integrated into tools like ChatGPT as an on-boarding experience to encourage learning-oriented use of generative AI.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19107",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Join us for OpenAI‚Äôs first developer conference on November 6 in San Francisco",
    "description": "Developer registration for in-person attendance will open in the coming weeks and developers everywhere will be able to livestream the keynote.",
    "summary": "Developer registration for in-person attendance will open in the coming weeks and developers everywhere will be able to livestream the keynote.",
    "pubDate": "Wed, 06 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/announcing-openai-devday",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster TensorFlow models in Hugging Face Transformers",
    "description": "",
    "summary": "Faster TensorFlow models in Hugging Face Transformers In the last few months, the Hugging Face team ...",
    "pubDate": "Tue, 26 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-serving",
    "thumbnail": "https://huggingface.co/blog/assets/10_tf-serving/thumbnail.png"
  },
  {
    "title": "ParkFormer: A Transformer-Based Parking Policy with Goal Embedding and Pedestrian-Aware Control",
    "description": "arXiv:2506.16856v1 Announce Type: cross Abstract: Autonomous parking plays a vital role in intelligent vehicle systems, particularly in constrained urban environments where high-precision control is required. While traditional rule-based parking systems struggle with environmental uncertainties and lack adaptability in crowded or dynamic scenes, human drivers demonstrate the ability to park intuitively without explicit modeling. Inspired by this observation, we propose a Transformer-based end-to-end framework for autonomous parking that learns from expert demonstrations. The network takes as input surround-view camera images, goal-point representations, ego vehicle motion, and pedestrian trajectories. It outputs discrete control sequences including throttle, braking, steering, and gear selection. A novel cross-attention module integrates BEV features with target points, and a GRU-based pedestrian predictor enhances safety by modeling dynamic obstacles. We validate our method on the CARLA 0.9.14 simulator in both vertical and parallel parking scenarios. Experiments show our model achieves a high success rate of 96.57%, with average positional and orientation errors of 0.21 meters and 0.41 degrees, respectively. The ablation studies further demonstrate the effectiveness of key modules such as pedestrian prediction and goal-point attention fusion. The code and dataset will be released at: https://github.com/little-snail-f/ParkFormer.",
    "summary": "arXiv:2506.16856v1 Announce Type: cross Abstract: Autonomous parking plays a vital role in intelligent vehicle systems, particularly in constrained urban environments where high-precision control is required. While traditional rule-based parking systems struggle with environmental uncertainties and lack adaptability in crowded or dynamic scenes, human drivers demonstrate the ability to park intuitively without explicit modeling. Inspired by this observation, we propose a Transformer-based end-to-end framework for autonomous parking that learns from expert demonstrations. The network takes as input surround-view camera images, goal-point representations, ego vehicle motion, and pedestrian trajectories. It outputs discrete control sequences including throttle, braking, steering, and gear selection. A novel cross-attention module integrates BEV features with target points, and a GRU-based pedestrian predictor enhances safety by modeling dynamic obstacles. We validate our method on the CARLA 0.9.14 simulator in both vertical and parallel parking scenarios. Experiments show our model achieves a high success rate of 96.57%, with average positional and orientation errors of 0.21 meters and 0.41 degrees, respectively. The ablation studies further demonstrate the effectiveness of key modules such as pedestrian prediction and goal-point attention fusion. The code and dataset will be released at: https://github.com/little-snail-f/ParkFormer.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16856",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning",
    "description": "arXiv:2505.19769v2 Announce Type: replace-cross Abstract: Developing scalable and generalizable reward engineering for reinforcement learning (RL) is crucial for creating general-purpose agents, especially in the challenging domain of robotic manipulation. While recent advances in reward engineering with Vision-Language Models (VLMs) have shown promise, their sparse reward nature significantly limits sample efficiency. This paper introduces TeViR, a novel method that leverages a pre-trained text-to-video diffusion model to generate dense rewards by comparing the predicted image sequence with current observations. Experimental results across 11 complex robotic tasks demonstrate that TeViR outperforms traditional methods leveraging sparse rewards and other state-of-the-art (SOTA) methods, achieving better sample efficiency and performance without ground truth environmental rewards. TeViR's ability to efficiently guide agents in complex environments highlights its potential to advance reinforcement learning applications in robotic manipulation.",
    "summary": "arXiv:2505.19769v2 Announce Type: replace-cross Abstract: Developing scalable and generalizable reward engineering for reinforcement learning (RL) is crucial for creating general-purpose agents, especially in the challenging domain of robotic manipulation. While recent advances in reward engineering with Vision-Language Models (VLMs) have shown promise, their sparse reward nature significantly limits sample efficiency. This paper introduces TeViR, a novel method that leverages a pre-trained text-to-video diffusion model to generate dense rewards by comparing the predicted image sequence with current observations. Experimental results across 11 complex robotic tasks demonstrate that TeViR outperforms traditional methods leveraging sparse rewards and other state-of-the-art (SOTA) methods, achieving better sample efficiency and performance without ground truth environmental rewards. TeViR's ability to efficiently guide agents in complex environments highlights its potential to advance reinforcement learning applications in robotic manipulation.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.19769",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "An update on disrupting deceptive uses of AI",
    "description": "OpenAI‚Äôs mission is to ensure that artificial general intelligence benefits all of humanity. We are dedicated to identifying, preventing, and disrupting attempts to abuse our models for harmful ends.",
    "summary": "OpenAI‚Äôs mission is to ensure that artificial general intelligence benefits all of humanity. We are dedicated to identifying, preventing, and disrupting attempts to abuse our models for harmful ends.",
    "pubDate": "Wed, 09 Oct 2024 03:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/an-update-on-disrupting-deceptive-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks",
    "description": "arXiv:2506.10954v2 Announce Type: replace-cross Abstract: Constructing large-scale datasets for the GitHub issue resolution task is crucial for both training and evaluating the software engineering capabilities of Large Language Models (LLMs). However, the traditional process for creating such benchmarks is notoriously challenging and labor-intensive, particularly in the stages of setting up evaluation environments, grading test outcomes, and validating task instances. In this paper, we propose SWE-Factory, an automated pipeline designed to address these challenges. To tackle these issues, our pipeline integrates three core automated components. First, we introduce SWE-Builder, a multi-agent system that automates evaluation environment construction, which employs four specialized agents that work in a collaborative, iterative loop and leverages an environment memory pool to enhance efficiency. Second, we introduce a standardized, exit-code-based grading method that eliminates the need for manually writing custom parsers. Finally, we automate the fail2pass validation process using these reliable exit code signals. Experiments on 671 issues across four programming languages show that our pipeline can effectively construct valid task instances; for example, with GPT-4.1-mini, our SWE-Builder constructs 269 valid instances at $0.045 per instance, while with Gemini-2.5-flash, it achieves comparable performance at the lowest cost of $0.024 per instance. We also demonstrate that our exit-code-based grading achieves 100% accuracy compared to manual inspection, and our automated fail2pass validation reaches a precision of 0.92 and a recall of 1.00. We hope our automated pipeline will accelerate the collection of large-scale, high-quality GitHub issue resolution datasets for both training and evaluation. Our code and datasets are released at https://github.com/DeepSoftwareAnalytics/swe-factory.",
    "summary": "arXiv:2506.10954v2 Announce Type: replace-cross Abstract: Constructing large-scale datasets for the GitHub issue resolution task is crucial for both training and evaluating the software engineering capabilities of Large Language Models (LLMs). However, the traditional process for creating such benchmarks is notoriously challenging and labor-intensive, particularly in the stages of setting up evaluation environments, grading test outcomes, and validating task instances. In this paper, we propose SWE-Factory, an automated pipeline designed to address these challenges. To tackle these issues, our pipeline integrates three core automated components. First, we introduce SWE-Builder, a multi-agent system that automates evaluation environment construction, which employs four specialized agents that work in a collaborative, iterative loop and leverages an environment memory pool to enhance efficiency. Second, we introduce a standardized, exit-code-based grading method that eliminates the need for manually writing custom parsers. Finally, we automate the fail2pass validation process using these reliable exit code signals. Experiments on 671 issues across four programming languages show that our pipeline can effectively construct valid task instances; for example, with GPT-4.1-mini, our SWE-Builder constructs 269 valid instances at $0.045 per instance, while with Gemini-2.5-flash, it achieves comparable performance at the lowest cost of $0.024 per instance. We also demonstrate that our exit-code-based grading achieves 100% accuracy compared to manual inspection, and our automated fail2pass validation reaches a precision of 0.92 and a recall of 1.00. We hope our automated pipeline will accelerate the collection of large-scale, high-quality GitHub issue resolution datasets for both training and evaluation. Our code and datasets are released at https://github.com/DeepSoftwareAnalytics/swe-factory.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.10954",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SSR-Zero: Simple Self-Rewarding Reinforcement Learning for Machine Translation",
    "description": "arXiv:2505.16637v3 Announce Type: replace-cross Abstract: Large language models (LLMs) have recently demonstrated remarkable capabilities in machine translation (MT). However, most advanced MT-specific LLMs heavily rely on external supervision signals during training, such as human-annotated reference data or trained reward models (RMs), which are often expensive to obtain and challenging to scale. To overcome this limitation, we propose a Simple Self-Rewarding (SSR) Reinforcement Learning (RL) framework for MT that is reference-free, fully online, and relies solely on self-judging rewards. Training with SSR using 13K monolingual examples and Qwen-2.5-7B as the backbone, our model SSR-Zero-7B outperforms existing MT-specific LLMs, e.g., TowerInstruct-13B and GemmaX-28-9B, as well as larger general LLMs like Qwen2.5-32B-Instruct in English $leftrightarrow$ Chinese translation tasks from WMT23, WMT24, and Flores200 benchmarks. Furthermore, by augmenting SSR with external supervision from COMET, our strongest model, SSR-X-Zero-7B, achieves state-of-the-art performance in English $leftrightarrow$ Chinese translation, surpassing all existing open-source models under 72B parameters and even outperforming closed-source models, e.g., GPT-4o and Gemini 1.5 Pro. Our analysis highlights the effectiveness of the self-rewarding mechanism compared to the external LLM-as-a-judge approach in MT and demonstrates its complementary benefits when combined with trained RMs. Our findings provide valuable insight into the potential of self-improving RL methods. We have publicly released our code, data and models.",
    "summary": "arXiv:2505.16637v3 Announce Type: replace-cross Abstract: Large language models (LLMs) have recently demonstrated remarkable capabilities in machine translation (MT). However, most advanced MT-specific LLMs heavily rely on external supervision signals during training, such as human-annotated reference data or trained reward models (RMs), which are often expensive to obtain and challenging to scale. To overcome this limitation, we propose a Simple Self-Rewarding (SSR) Reinforcement Learning (RL) framework for MT that is reference-free, fully online, and relies solely on self-judging rewards. Training with SSR using 13K monolingual examples and Qwen-2.5-7B as the backbone, our model SSR-Zero-7B outperforms existing MT-specific LLMs, e.g., TowerInstruct-13B and GemmaX-28-9B, as well as larger general LLMs like Qwen2.5-32B-Instruct in English $leftrightarrow$ Chinese translation tasks from WMT23, WMT24, and Flores200 benchmarks. Furthermore, by augmenting SSR with external supervision from COMET, our strongest model, SSR-X-Zero-7B, achieves state-of-the-art performance in English $leftrightarrow$ Chinese translation, surpassing all existing open-source models under 72B parameters and even outperforming closed-source models, e.g., GPT-4o and Gemini 1.5 Pro. Our analysis highlights the effectiveness of the self-rewarding mechanism compared to the external LLM-as-a-judge approach in MT and demonstrates its complementary benefits when combined with trained RMs. Our findings provide valuable insight into the potential of self-improving RL methods. We have publicly released our code, data and models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.16637",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents",
    "description": "arXiv:2506.21605v1 Announce Type: cross Abstract: Recent works have highlighted the significance of memory mechanisms in LLM-based agents, which enable them to store observed information and adapt to dynamic environments. However, evaluating their memory capabilities still remains challenges. Previous evaluations are commonly limited by the diversity of memory levels and interactive scenarios. They also lack comprehensive metrics to reflect the memory capabilities from multiple aspects. To address these problems, in this paper, we construct a more comprehensive dataset and benchmark to evaluate the memory capability of LLM-based agents. Our dataset incorporates factual memory and reflective memory as different levels, and proposes participation and observation as various interactive scenarios. Based on our dataset, we present a benchmark, named MemBench, to evaluate the memory capability of LLM-based agents from multiple aspects, including their effectiveness, efficiency, and capacity. To benefit the research community, we release our dataset and project at https://github.com/import-myself/Membench.",
    "summary": "arXiv:2506.21605v1 Announce Type: cross Abstract: Recent works have highlighted the significance of memory mechanisms in LLM-based agents, which enable them to store observed information and adapt to dynamic environments. However, evaluating their memory capabilities still remains challenges. Previous evaluations are commonly limited by the diversity of memory levels and interactive scenarios. They also lack comprehensive metrics to reflect the memory capabilities from multiple aspects. To address these problems, in this paper, we construct a more comprehensive dataset and benchmark to evaluate the memory capability of LLM-based agents. Our dataset incorporates factual memory and reflective memory as different levels, and proposes participation and observation as various interactive scenarios. Based on our dataset, we present a benchmark, named MemBench, to evaluate the memory capability of LLM-based agents from multiple aspects, including their effectiveness, efficiency, and capacity. To benefit the research community, we release our dataset and project at https://github.com/import-myself/Membench.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21605",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models",
    "description": "",
    "summary": "Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models Florence-2, released by Mic...",
    "pubDate": "Mon, 24 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/finetune-florence2",
    "thumbnail": "https://huggingface.co/blog/assets/182_finetune-florence/thumbnail.png"
  },
  {
    "title": "StarFT: Robust Fine-tuning of Zero-shot Models via Spuriosity Alignment",
    "description": "arXiv:2505.13232v3 Announce Type: replace Abstract: Learning robust representations from data often requires scale, which has led to the success of recent zero-shot models such as CLIP. However, the obtained robustness can easily be deteriorated when these models are fine-tuned on other downstream tasks (e.g., of smaller scales). Previous works often interpret this phenomenon in the context of domain shift, developing fine-tuning methods that aim to preserve the original domain as much as possible. However, in a different context, fine-tuned models with limited data are also prone to learning features that are spurious to humans, such as background or texture. In this paper, we propose StarFT (Spurious Textual Alignment Regularization), a novel framework for fine-tuning zero-shot models to enhance robustness by preventing them from learning spuriosity. We introduce a regularization that aligns the output distribution for spuriosity-injected labels with the original zero-shot model, ensuring that the model is not induced to extract irrelevant features further from these descriptions. We leverage recent language models to get such spuriosity-injected labels by generating alternative textual descriptions that highlight potentially confounding features. Extensive experiments validate the robust generalization of StarFT and its emerging properties: zero-shot group robustness and improved zero-shot classification. Notably, StarFT boosts both worst-group and average accuracy by 14.30% and 3.02%, respectively, in the Waterbirds group shift scenario, where other robust fine-tuning baselines show even degraded performance.",
    "summary": "arXiv:2505.13232v3 Announce Type: replace Abstract: Learning robust representations from data often requires scale, which has led to the success of recent zero-shot models such as CLIP. However, the obtained robustness can easily be deteriorated when these models are fine-tuned on other downstream tasks (e.g., of smaller scales). Previous works often interpret this phenomenon in the context of domain shift, developing fine-tuning methods that aim to preserve the original domain as much as possible. However, in a different context, fine-tuned models with limited data are also prone to learning features that are spurious to humans, such as background or texture. In this paper, we propose StarFT (Spurious Textual Alignment Regularization), a novel framework for fine-tuning zero-shot models to enhance robustness by preventing them from learning spuriosity. We introduce a regularization that aligns the output distribution for spuriosity-injected labels with the original zero-shot model, ensuring that the model is not induced to extract irrelevant features further from these descriptions. We leverage recent language models to get such spuriosity-injected labels by generating alternative textual descriptions that highlight potentially confounding features. Extensive experiments validate the robust generalization of StarFT and its emerging properties: zero-shot group robustness and improved zero-shot classification. Notably, StarFT boosts both worst-group and average accuracy by 14.30% and 3.02%, respectively, in the Waterbirds group shift scenario, where other robust fine-tuning baselines show even degraded performance.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.13232",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Competitive programming with AlphaCode",
    "description": "Solving novel problems and setting a new milestone in competitive programming.",
    "summary": "Solving novel problems and setting a new milestone in competitive programming.",
    "pubDate": "Thu, 08 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/competitive-programming-with-alphacode/",
    "thumbnail": "https://lh3.googleusercontent.com/vQ0Ow6LwCpigfPyTGUhXEfdMBWPyHmaCo7eoQW7bv3QoZXW6EIj18FPiCLI1vlMYlUAOvEXta1KSkl8P2KScquYJb-Dm_QygP9kdlLYkpF4nVyEH=w1200-h630-n-nu"
  },
  {
    "title": "Evaluating social and ethical risks from generative AI",
    "description": "Introducing a context-based framework for comprehensively evaluating the social and ethical risks of AI systems",
    "summary": "Introducing a context-based framework for comprehensively evaluating the social and ethical risks of AI systems",
    "pubDate": "Thu, 19 Oct 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/evaluating-social-and-ethical-risks-from-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/LAqM0ZkFzkDefB5oVEEPoq6p--7XcfBWEDPjl6OdcfvwN9q3leY2qWCf30_MquTn5RfpcPswiAoRns2jOKjB5_8u-vl6TqueSwamEM6U-qyJHOiujkI=w1200-h630-n-nu"
  },
  {
    "title": "Fine-Tuning Gemma Models in Hugging Face",
    "description": "",
    "summary": "Fine-Tuning Gemma Models in Hugging Face We recently announced that Gemma, the open weights language...",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma-peft",
    "thumbnail": "https://huggingface.co/blog/assets/gemma-peft/thumbnail.png"
  },
  {
    "title": "'I know myself better, but not really greatly': How Well Can LLMs Detect and Explain LLM-Generated Texts?",
    "description": "arXiv:2502.12743v2 Announce Type: replace-cross Abstract: Distinguishing between human- and LLM-generated texts is crucial given the risks associated with misuse of LLMs. This paper investigates detection and explanation capabilities of current LLMs across two settings: binary (human vs. LLM-generated) and ternary classification (including an ``undecided'' class). We evaluate 6 close- and open-source LLMs of varying sizes and find that self-detection (LLMs identifying their own outputs) consistently outperforms cross-detection (identifying outputs from other LLMs), though both remain suboptimal. Introducing a ternary classification framework improves both detection accuracy and explanation quality across all models. Through comprehensive quantitative and qualitative analyses using our human-annotated dataset, we identify key explanation failures, primarily reliance on inaccurate features, hallucinations, and flawed reasoning. Our findings underscore the limitations of current LLMs in self-detection and self-explanation, highlighting the need for further research to address overfitting and enhance generalizability.",
    "summary": "arXiv:2502.12743v2 Announce Type: replace-cross Abstract: Distinguishing between human- and LLM-generated texts is crucial given the risks associated with misuse of LLMs. This paper investigates detection and explanation capabilities of current LLMs across two settings: binary (human vs. LLM-generated) and ternary classification (including an ``undecided'' class). We evaluate 6 close- and open-source LLMs of varying sizes and find that self-detection (LLMs identifying their own outputs) consistently outperforms cross-detection (identifying outputs from other LLMs), though both remain suboptimal. Introducing a ternary classification framework improves both detection accuracy and explanation quality across all models. Through comprehensive quantitative and qualitative analyses using our human-annotated dataset, we identify key explanation failures, primarily reliance on inaccurate features, hallucinations, and flawed reasoning. Our findings underscore the limitations of current LLMs in self-detection and self-explanation, highlighting the need for further research to address overfitting and enhance generalizability.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.12743",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Hugging Face for Education",
    "description": "",
    "summary": "Introducing Hugging Face for Education ü§ó Given that machine learning will make up the overwhelming m...",
    "pubDate": "Mon, 25 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/education",
    "thumbnail": "https://huggingface.co/blog/assets/61_education/thumbnail.png"
  },
  {
    "title": "Advancing Jailbreak Strategies: A Hybrid Approach to Exploiting LLM Vulnerabilities and Bypassing Modern Defenses",
    "description": "arXiv:2506.21972v1 Announce Type: cross Abstract: The advancement of Pre-Trained Language Models (PTLMs) and Large Language Models (LLMs) has led to their widespread adoption across diverse applications. Despite their success, these models remain vulnerable to attacks that exploit their inherent weaknesses to bypass safety measures. Two primary inference-phase threats are token-level and prompt-level jailbreaks. Token-level attacks embed adversarial sequences that transfer well to black-box models like GPT but leave detectable patterns and rely on gradient-based token optimization, whereas prompt-level attacks use semantically structured inputs to elicit harmful responses yet depend on iterative feedback that can be unreliable. To address the complementary limitations of these methods, we propose two hybrid approaches that integrate token- and prompt-level techniques to enhance jailbreak effectiveness across diverse PTLMs. GCG + PAIR and the newly explored GCG + WordGame hybrids were evaluated across multiple Vicuna and Llama models. GCG + PAIR consistently raised attack-success rates over its constituent techniques on undefended models; for instance, on Llama-3, its Attack Success Rate (ASR) reached 91.6%, a substantial increase from PAIR's 58.4% baseline. Meanwhile, GCG + WordGame matched the raw performance of WordGame maintaining a high ASR of over 80% even under stricter evaluators like Mistral-Sorry-Bench. Crucially, both hybrids retained transferability and reliably pierced advanced defenses such as Gradient Cuff and JBShield, which fully blocked single-mode attacks. These findings expose previously unreported vulnerabilities in current safety stacks, highlight trade-offs between raw success and defensive robustness, and underscore the need for holistic safeguards against adaptive adversaries.",
    "summary": "arXiv:2506.21972v1 Announce Type: cross Abstract: The advancement of Pre-Trained Language Models (PTLMs) and Large Language Models (LLMs) has led to their widespread adoption across diverse applications. Despite their success, these models remain vulnerable to attacks that exploit their inherent weaknesses to bypass safety measures. Two primary inference-phase threats are token-level and prompt-level jailbreaks. Token-level attacks embed adversarial sequences that transfer well to black-box models like GPT but leave detectable patterns and rely on gradient-based token optimization, whereas prompt-level attacks use semantically structured inputs to elicit harmful responses yet depend on iterative feedback that can be unreliable. To address the complementary limitations of these methods, we propose two hybrid approaches that integrate token- and prompt-level techniques to enhance jailbreak effectiveness across diverse PTLMs. GCG + PAIR and the newly explored GCG + WordGame hybrids were evaluated across multiple Vicuna and Llama models. GCG + PAIR consistently raised attack-success rates over its constituent techniques on undefended models; for instance, on Llama-3, its Attack Success Rate (ASR) reached 91.6%, a substantial increase from PAIR's 58.4% baseline. Meanwhile, GCG + WordGame matched the raw performance of WordGame maintaining a high ASR of over 80% even under stricter evaluators like Mistral-Sorry-Bench. Crucially, both hybrids retained transferability and reliably pierced advanced defenses such as Gradient Cuff and JBShield, which fully blocked single-mode attacks. These findings expose previously unreported vulnerabilities in current safety stacks, highlight trade-offs between raw success and defensive robustness, and underscore the need for holistic safeguards against adaptive adversaries.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21972",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation",
    "description": "arXiv:2411.00412v4 Announce Type: replace-cross Abstract: Large Language Models (LLMs) demonstrate promising capabilities in solving scientific problems but often suffer from the issue of hallucination. While integrating LLMs with tools can mitigate this issue, models fine-tuned on tool usage become overreliant on them and incur unnecessary costs. Inspired by how human experts assess problem complexity before selecting solutions, we propose a novel two-component fine-tuning method, Adapting While Learning (AWL). In the first component, World Knowledge Learning (WKL), LLMs internalize scientific knowledge by learning from tool-generated solutions. In the second component, Tool Usage Adaptation (TUA), we categorize problems as easy or hard based on the model's accuracy, and train it to maintain direct reasoning for easy problems while switching to tools for hard ones. We validate our method on six scientific benchmark datasets across climate science, epidemiology, physics, and other domains. Compared to the original instruct model (8B), models post-trained with AWL achieve 29.11% higher answer accuracy and 12.72% better tool usage accuracy, even surpassing state-of-the-art models including GPT-4o and Claude-3.5 on four custom-created datasets. Our code is open-source at https://github.com/Rose-STL-Lab/Adapting-While-Learning.",
    "summary": "arXiv:2411.00412v4 Announce Type: replace-cross Abstract: Large Language Models (LLMs) demonstrate promising capabilities in solving scientific problems but often suffer from the issue of hallucination. While integrating LLMs with tools can mitigate this issue, models fine-tuned on tool usage become overreliant on them and incur unnecessary costs. Inspired by how human experts assess problem complexity before selecting solutions, we propose a novel two-component fine-tuning method, Adapting While Learning (AWL). In the first component, World Knowledge Learning (WKL), LLMs internalize scientific knowledge by learning from tool-generated solutions. In the second component, Tool Usage Adaptation (TUA), we categorize problems as easy or hard based on the model's accuracy, and train it to maintain direct reasoning for easy problems while switching to tools for hard ones. We validate our method on six scientific benchmark datasets across climate science, epidemiology, physics, and other domains. Compared to the original instruct model (8B), models post-trained with AWL achieve 29.11% higher answer accuracy and 12.72% better tool usage accuracy, even surpassing state-of-the-art models including GPT-4o and Claude-3.5 on four custom-created datasets. Our code is open-source at https://github.com/Rose-STL-Lab/Adapting-While-Learning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.00412",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI and Future partner on specialist content",
    "description": "OpenAI and Future, the global platform for specialist media, have today announced a strategic partnership to bring content from Future‚Äôs 200 plus media brands to OpenAI‚Äôs users.",
    "summary": "OpenAI and Future, the global platform for specialist media, have today announced a strategic partnership to bring content from Future‚Äôs 200 plus media brands to OpenAI‚Äôs users.",
    "pubDate": "Wed, 04 Dec 2024 23:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-future-partner-on-specialist-content",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PixelCNN++: Improving the PixelCNN with discretized logistic mixture likelihood and other modifications",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 19 Jan 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/pixelcnn-plus-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Transforming the future of music creation",
    "description": "Announcing our most advanced music generation model and two new AI experiments, designed to open a new playground for creativity",
    "summary": "Announcing our most advanced music generation model and two new AI experiments, designed to open a new playground for creativity",
    "pubDate": "Thu, 16 Nov 2023 07:20:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/",
    "thumbnail": "https://lh3.googleusercontent.com/msr-Fc99rrkeoQkZ6rLTKnof3RTqo5oo9D2_xPyqtpp0mAMqqkn-x3mPy2dD0My1g7w-cysBQzHU_iWF4mlblU4EgQRcMNKoBUgPdmdmEoyekFJEnA=w1200-h630-n-nu"
  },
  {
    "title": "History-Augmented Vision-Language Models for Frontier-Based Zero-Shot Object Navigation",
    "description": "arXiv:2506.16623v1 Announce Type: cross Abstract: Object Goal Navigation (ObjectNav) challenges robots to find objects in unseen environments, demanding sophisticated reasoning. While Vision-Language Models (VLMs) show potential, current ObjectNav methods often employ them superficially, primarily using vision-language embeddings for object-scene similarity checks rather than leveraging deeper reasoning. This limits contextual understanding and leads to practical issues like repetitive navigation behaviors. This paper introduces a novel zero-shot ObjectNav framework that pioneers the use of dynamic, history-aware prompting to more deeply integrate VLM reasoning into frontier-based exploration. Our core innovation lies in providing the VLM with action history context, enabling it to generate semantic guidance scores for navigation actions while actively avoiding decision loops. We also introduce a VLM-assisted waypoint generation mechanism for refining the final approach to detected objects. Evaluated on the HM3D dataset within Habitat, our approach achieves a 46% Success Rate (SR) and 24.8% Success weighted by Path Length (SPL). These results are comparable to state-of-the-art zero-shot methods, demonstrating the significant potential of our history-augmented VLM prompting strategy for more robust and context-aware robotic navigation.",
    "summary": "arXiv:2506.16623v1 Announce Type: cross Abstract: Object Goal Navigation (ObjectNav) challenges robots to find objects in unseen environments, demanding sophisticated reasoning. While Vision-Language Models (VLMs) show potential, current ObjectNav methods often employ them superficially, primarily using vision-language embeddings for object-scene similarity checks rather than leveraging deeper reasoning. This limits contextual understanding and leads to practical issues like repetitive navigation behaviors. This paper introduces a novel zero-shot ObjectNav framework that pioneers the use of dynamic, history-aware prompting to more deeply integrate VLM reasoning into frontier-based exploration. Our core innovation lies in providing the VLM with action history context, enabling it to generate semantic guidance scores for navigation actions while actively avoiding decision loops. We also introduce a VLM-assisted waypoint generation mechanism for refining the final approach to detected objects. Evaluated on the HM3D dataset within Habitat, our approach achieves a 46% Success Rate (SR) and 24.8% Success weighted by Path Length (SPL). These results are comparable to state-of-the-art zero-shot methods, demonstrating the significant potential of our history-augmented VLM prompting strategy for more robust and context-aware robotic navigation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16623",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Surgery-R1: Advancing Surgical-VQLA with Reasoning Multimodal Large Language Model via Reinforcement Learning",
    "description": "arXiv:2506.19469v1 Announce Type: cross Abstract: In recent years, significant progress has been made in the field of surgical scene understanding, particularly in the task of Visual Question Localized-Answering in robotic surgery (Surgical-VQLA). However, existing Surgical-VQLA models lack deep reasoning capabilities and interpretability in surgical scenes, which limits their reliability and potential for development in clinical applications. To address this issue, inspired by the development of Reasoning Multimodal Large Language Models (MLLMs), we first build the Surgery-R1-54k dataset, including paired data for Visual-QA, Grounding-QA, and Chain-of-Thought (CoT). Then, we propose the first Reasoning MLLM for Surgical-VQLA (Surgery-R1). In our Surgery-R1, we design a two-stage fine-tuning mechanism to enable the basic MLLM with complex reasoning abilities by utilizing supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT). Furthermore, for an efficient and high-quality rule-based reward system in our RFT, we design a Multimodal Coherence reward mechanism to mitigate positional illusions that may arise in surgical scenarios. Experiment results demonstrate that Surgery-R1 outperforms other existing state-of-the-art (SOTA) models in the Surgical-VQLA task and widely-used MLLMs, while also validating its reasoning capabilities and the effectiveness of our approach. The code and dataset will be organized in https://github.com/FiFi-HAO467/Surgery-R1.",
    "summary": "arXiv:2506.19469v1 Announce Type: cross Abstract: In recent years, significant progress has been made in the field of surgical scene understanding, particularly in the task of Visual Question Localized-Answering in robotic surgery (Surgical-VQLA). However, existing Surgical-VQLA models lack deep reasoning capabilities and interpretability in surgical scenes, which limits their reliability and potential for development in clinical applications. To address this issue, inspired by the development of Reasoning Multimodal Large Language Models (MLLMs), we first build the Surgery-R1-54k dataset, including paired data for Visual-QA, Grounding-QA, and Chain-of-Thought (CoT). Then, we propose the first Reasoning MLLM for Surgical-VQLA (Surgery-R1). In our Surgery-R1, we design a two-stage fine-tuning mechanism to enable the basic MLLM with complex reasoning abilities by utilizing supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT). Furthermore, for an efficient and high-quality rule-based reward system in our RFT, we design a Multimodal Coherence reward mechanism to mitigate positional illusions that may arise in surgical scenarios. Experiment results demonstrate that Surgery-R1 outperforms other existing state-of-the-art (SOTA) models in the Surgical-VQLA task and widely-used MLLMs, while also validating its reasoning capabilities and the effectiveness of our approach. The code and dataset will be organized in https://github.com/FiFi-HAO467/Surgery-R1.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19469",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AIÊôÇ‰ª£„ÅÆÂÆâÂÖ®Âü∫Ê∫ñ„ÄÅ„ÄåOWASP AI Testing Guide„Äç„ÅåÂßãÂãï„ÄÄ„Åù„ÅÆ‰∏≠Ë∫´„Å®„ÅØÔºü",
    "description": "OWASP„ÅØAIÊäÄË°ì„ÅÆÁâπÁï∞ÊÄß„Å´ÂØæÂøú„Åô„Çã„Åü„ÇÅ„ÅÆ„ÄåAI Testing Guide„ÄçÂàùÊúü„Éâ„É©„Éï„Éà„ÇíÂÖ¨Èñã„Åó„Åü„ÄÇÂêå„Ç¨„Ç§„Éâ„ÅØÊäÄË°ì„ÉªÊ•≠Áïå„ÇíÂïè„Çè„ÅöÈÅ©Áî®ÂèØËÉΩ„Å™Ë©¶È®ìÊñπÊ≥ïË´ñ„ÇíÊèêÁ§∫„Åô„Çã„ÇÇ„ÅÆ„Åß„ÄÅAI„Çª„Ç≠„É•„É™„ÉÜ„Ç£„ÇÑÂÄ´ÁêÜ„ÄÅ‰ø°È†ºÊÄßÁ¢∫‰øù„ÇíÁõÆÁöÑ„Å®„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "OWASP„ÅØAIÊäÄË°ì„ÅÆÁâπÁï∞ÊÄß„Å´ÂØæÂøú„Åô„Çã„Åü„ÇÅ„ÅÆ„ÄåAI Testing Guide„ÄçÂàùÊúü„Éâ„É©„Éï„Éà„ÇíÂÖ¨Èñã„Åó„Åü„ÄÇÂêå„Ç¨„Ç§„Éâ„ÅØÊäÄË°ì„ÉªÊ•≠Áïå„ÇíÂïè„Çè„ÅöÈÅ©Áî®ÂèØËÉΩ„Å™Ë©¶È®ìÊñπÊ≥ïË´ñ„ÇíÊèêÁ§∫„Åô„Çã„ÇÇ„ÅÆ„Åß„ÄÅAI„Çª„Ç≠„É•„É™„ÉÜ„Ç£„ÇÑÂÄ´ÁêÜ„ÄÅ‰ø°È†ºÊÄßÁ¢∫‰øù„ÇíÁõÆÁöÑ„Å®„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Thu, 26 Jun 2025 08:30:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/26/news031.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/26/cover_news031.jpg"
  },
  {
    "title": "Habana Labs and Hugging Face Partner to Accelerate Transformer Model Training",
    "description": "",
    "summary": "Habana Labs and Hugging Face Partner to Accelerate Transformer Model Training Santa Clara and San Fr...",
    "pubDate": "Tue, 12 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana",
    "thumbnail": "https://huggingface.co/blog/assets/60_habana/habana.png"
  },
  {
    "title": "AnyTraverse: An off-road traversability framework with VLM and human operator in the loop",
    "description": "arXiv:2506.16826v1 Announce Type: cross Abstract: Off-road traversability segmentation enables autonomous navigation with applications in search-and-rescue, military operations, wildlife exploration, and agriculture. Current frameworks struggle due to significant variations in unstructured environments and uncertain scene changes, and are not adaptive to be used for different robot types. We present AnyTraverse, a framework combining natural language-based prompts with human-operator assistance to determine navigable regions for diverse robotic vehicles. The system segments scenes for a given set of prompts and calls the operator only when encountering previously unexplored scenery or unknown class not part of the prompt in its region-of-interest, thus reducing active supervision load while adapting to varying outdoor scenes. Our zero-shot learning approach eliminates the need for extensive data collection or retraining. Our experimental validation includes testing on RELLIS-3D, Freiburg Forest, and RUGD datasets and demonstrate real-world deployment on multiple robot platforms. The results show that AnyTraverse performs better than GA-NAV and Off-seg while offering a vehicle-agnostic approach to off-road traversability that balances automation with targeted human supervision.",
    "summary": "arXiv:2506.16826v1 Announce Type: cross Abstract: Off-road traversability segmentation enables autonomous navigation with applications in search-and-rescue, military operations, wildlife exploration, and agriculture. Current frameworks struggle due to significant variations in unstructured environments and uncertain scene changes, and are not adaptive to be used for different robot types. We present AnyTraverse, a framework combining natural language-based prompts with human-operator assistance to determine navigable regions for diverse robotic vehicles. The system segments scenes for a given set of prompts and calls the operator only when encountering previously unexplored scenery or unknown class not part of the prompt in its region-of-interest, thus reducing active supervision load while adapting to varying outdoor scenes. Our zero-shot learning approach eliminates the need for extensive data collection or retraining. Our experimental validation includes testing on RELLIS-3D, Freiburg Forest, and RUGD datasets and demonstrate real-world deployment on multiple robot platforms. The results show that AnyTraverse performs better than GA-NAV and Off-seg while offering a vehicle-agnostic approach to off-road traversability that balances automation with targeted human supervision.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16826",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Proportional Sensitivity in Generative Adversarial Network (GAN)-Augmented Brain Tumor Classification Using Convolutional Neural Network",
    "description": "arXiv:2506.17165v1 Announce Type: cross Abstract: Generative Adversarial Networks (GAN) have shown potential in expanding limited medical imaging datasets. This study explores how different ratios of GAN-generated and real brain tumor MRI images impact the performance of a CNN in classifying healthy vs. tumorous scans. A DCGAN was used to create synthetic images which were mixed with real ones at various ratios to train a custom CNN. The CNN was then evaluated on a separate real-world test set. Our results indicate that the model maintains high sensitivity and precision in tumor classification, even when trained predominantly on synthetic data. When only a small portion of GAN data was added, such as 900 real images and 100 GAN images, the model achieved excellent performance, with test accuracy reaching 95.2%, and precision, recall, and F1-score all exceeding 95%. However, as the proportion of GAN images increased further, performance gradually declined. This study suggests that while GANs are useful for augmenting limited datasets especially when real data is scarce, too much synthetic data can introduce artifacts that affect the model's ability to generalize to real world cases.",
    "summary": "arXiv:2506.17165v1 Announce Type: cross Abstract: Generative Adversarial Networks (GAN) have shown potential in expanding limited medical imaging datasets. This study explores how different ratios of GAN-generated and real brain tumor MRI images impact the performance of a CNN in classifying healthy vs. tumorous scans. A DCGAN was used to create synthetic images which were mixed with real ones at various ratios to train a custom CNN. The CNN was then evaluated on a separate real-world test set. Our results indicate that the model maintains high sensitivity and precision in tumor classification, even when trained predominantly on synthetic data. When only a small portion of GAN data was added, such as 900 real images and 100 GAN images, the model achieved excellent performance, with test accuracy reaching 95.2%, and precision, recall, and F1-score all exceeding 95%. However, as the proportion of GAN images increased further, performance gradually declined. This study suggests that while GANs are useful for augmenting limited datasets especially when real data is scarce, too much synthetic data can introduce artifacts that affect the model's ability to generalize to real world cases.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17165",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing OpenAI o3 and o4-mini",
    "description": "Our smartest and most capable models to date with full tool access",
    "summary": "Our smartest and most capable models to date with full tool access",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-o3-and-o4-mini",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Artificial intelligence enhances air mobility planning",
    "description": "Lincoln Laboratory is transitioning tools to the 618th Air Operations Center to streamline global transport logistics.",
    "summary": "Lincoln Laboratory is transitioning tools to the 618th Air Operations Center to streamline global transport logistics.",
    "pubDate": "Fri, 25 Apr 2025 12:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/artificial-intelligence-enhances-air-mobility-planning-0425",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-lincoln-lab-us-air-mobility-00.jpg"
  },
  {
    "title": "Understanding and Reducing the Class-Dependent Effects of Data Augmentation with A Two-Player Game Approach",
    "description": "arXiv:2407.03146v4 Announce Type: replace-cross Abstract: Data augmentation is widely applied and has shown its benefits in different machine learning tasks. However, as recently observed, it may have an unfair effect in multi-class classification. While data augmentation generally improves the overall performance (and therefore is beneficial for many classes), it can actually be detrimental for other classes, which can be problematic in some application domains. In this paper, to counteract this phenomenon, we propose CLAM, a CLAss-dependent Multiplicative-weights method. To derive it, we first formulate the training of a classifier as a non-linear optimization problem that aims at simultaneously maximizing the individual class performances and balancing them. By rewriting this optimization problem as an adversarial two-player game, we propose a novel multiplicative weight algorithm, for which we prove the convergence. Interestingly, our formulation also reveals that the class-dependent effects of data augmentation is not due to data augmentation only, but is in fact a general phenomenon. Our empirical results over six datasets demonstrate that the performance of learned classifiers is indeed more fairly distributed over classes, with only limited impact on the average accuracy.",
    "summary": "arXiv:2407.03146v4 Announce Type: replace-cross Abstract: Data augmentation is widely applied and has shown its benefits in different machine learning tasks. However, as recently observed, it may have an unfair effect in multi-class classification. While data augmentation generally improves the overall performance (and therefore is beneficial for many classes), it can actually be detrimental for other classes, which can be problematic in some application domains. In this paper, to counteract this phenomenon, we propose CLAM, a CLAss-dependent Multiplicative-weights method. To derive it, we first formulate the training of a classifier as a non-linear optimization problem that aims at simultaneously maximizing the individual class performances and balancing them. By rewriting this optimization problem as an adversarial two-player game, we propose a novel multiplicative weight algorithm, for which we prove the convergence. Interestingly, our formulation also reveals that the class-dependent effects of data augmentation is not due to data augmentation only, but is in fact a general phenomenon. Our empirical results over six datasets demonstrate that the performance of learned classifiers is indeed more fairly distributed over classes, with only limited impact on the average accuracy.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.03146",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Adversarial training methods for semi-supervised text classification",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 25 May 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adversarial-training-methods-for-semi-supervised-text-classification",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Impact of Visual Context on Noisy Multimodal NMT: An Empirical Study for English to Indian Languages",
    "description": "arXiv:2308.16075v2 Announce Type: replace-cross Abstract: Neural Machine Translation (NMT) has made remarkable progress using large-scale textual data, but the potential of incorporating multimodal inputs, especially visual information, remains underexplored in high-resource settings. While prior research has focused on using multimodal data in low-resource scenarios, this study examines how image features impact translation when added to a large-scale, pre-trained unimodal NMT system. Surprisingly, the study finds that images might be redundant in this context. Additionally, the research introduces synthetic noise to assess whether images help the model handle textual noise. Multimodal models slightly outperform text-only models in noisy settings, even when random images are used. The study's experiments translate from English to Hindi, Bengali, and Malayalam, significantly outperforming state-of-the-art benchmarks. Interestingly, the effect of visual context varies with the level of source text noise: no visual context works best for non-noisy translations, cropped image features are optimal for low noise, and full image features perform better in high-noise scenarios. This sheds light on the role of visual context, especially in noisy settings, and opens up a new research direction for Noisy Neural Machine Translation in multimodal setups. The research emphasizes the importance of combining visual and textual information to improve translation across various environments. Our code is publicly available at https://github.com/babangain/indicMMT.",
    "summary": "arXiv:2308.16075v2 Announce Type: replace-cross Abstract: Neural Machine Translation (NMT) has made remarkable progress using large-scale textual data, but the potential of incorporating multimodal inputs, especially visual information, remains underexplored in high-resource settings. While prior research has focused on using multimodal data in low-resource scenarios, this study examines how image features impact translation when added to a large-scale, pre-trained unimodal NMT system. Surprisingly, the study finds that images might be redundant in this context. Additionally, the research introduces synthetic noise to assess whether images help the model handle textual noise. Multimodal models slightly outperform text-only models in noisy settings, even when random images are used. The study's experiments translate from English to Hindi, Bengali, and Malayalam, significantly outperforming state-of-the-art benchmarks. Interestingly, the effect of visual context varies with the level of source text noise: no visual context works best for non-noisy translations, cropped image features are optimal for low noise, and full image features perform better in high-noise scenarios. This sheds light on the role of visual context, especially in noisy settings, and opens up a new research direction for Noisy Neural Machine Translation in multimodal setups. The research emphasizes the importance of combining visual and textual information to improve translation across various environments. Our code is publicly available at https://github.com/babangain/indicMMT.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2308.16075",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Joint Tensor-Train Parameterization for Efficient and Expressive Low-Rank Adaptation",
    "description": "arXiv:2506.16456v1 Announce Type: cross Abstract: Low-Rank Adaptation (LoRA) is widely recognized for its parameter-efficient fine-tuning of large-scale neural models. However, standard LoRA independently optimizes low-rank matrices, which inherently limits its expressivity and generalization capabilities. While classical tensor-train (TT) decomposition can be separately employed on individual LoRA matrices, this work demonstrates that the classical TT-based approach neither significantly improves parameter efficiency nor achieves substantial performance gains. This paper proposes TensorGuide, a novel tensor-train-guided adaptation framework to overcome these limitations. TensorGuide generates two correlated low-rank LoRA matrices through a unified TT structure driven by controlled Gaussian noise. The resulting joint TT representation inherently provides structured, low-rank adaptations, significantly enhancing expressivity, generalization, and parameter efficiency without increasing the number of trainable parameters. Theoretically, we justify these improvements through neural tangent kernel analyses, demonstrating superior optimization dynamics and enhanced generalization. Extensive experiments on quantum dot classification and GPT-2 fine-tuning benchmarks demonstrate that TensorGuide-based LoRA consistently outperforms standard LoRA and TT-LoRA, achieving improved accuracy and scalability with fewer parameters.",
    "summary": "arXiv:2506.16456v1 Announce Type: cross Abstract: Low-Rank Adaptation (LoRA) is widely recognized for its parameter-efficient fine-tuning of large-scale neural models. However, standard LoRA independently optimizes low-rank matrices, which inherently limits its expressivity and generalization capabilities. While classical tensor-train (TT) decomposition can be separately employed on individual LoRA matrices, this work demonstrates that the classical TT-based approach neither significantly improves parameter efficiency nor achieves substantial performance gains. This paper proposes TensorGuide, a novel tensor-train-guided adaptation framework to overcome these limitations. TensorGuide generates two correlated low-rank LoRA matrices through a unified TT structure driven by controlled Gaussian noise. The resulting joint TT representation inherently provides structured, low-rank adaptations, significantly enhancing expressivity, generalization, and parameter efficiency without increasing the number of trainable parameters. Theoretically, we justify these improvements through neural tangent kernel analyses, demonstrating superior optimization dynamics and enhanced generalization. Extensive experiments on quantum dot classification and GPT-2 fine-tuning benchmarks demonstrate that TensorGuide-based LoRA consistently outperforms standard LoRA and TT-LoRA, achieving improved accuracy and scalability with fewer parameters.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16456",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-enabled control system helps autonomous drones stay on target in uncertain environments",
    "description": "The system automatically learns to adapt to unknown disturbances such as gusting winds.",
    "summary": "The system automatically learns to adapt to unknown disturbances such as gusting winds.",
    "pubDate": "Mon, 09 Jun 2025 16:40:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-enabled-control-system-helps-autonomous-drones-uncertain-environments-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_MetaLearning-01.jpg"
  },
  {
    "title": "Delivering high-performance customer support",
    "description": "Decagon and OpenAI deliver high-performance, fully automated customer support at scale",
    "summary": "Decagon and OpenAI deliver high-performance, fully automated customer support at scale",
    "pubDate": "Tue, 29 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/decagon",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AeroLite-MDNet: Lightweight Multi-task Deviation Detection Network for UAV Landing",
    "description": "arXiv:2506.21635v1 Announce Type: cross Abstract: Unmanned aerial vehicles (UAVs) are increasingly employed in diverse applications such as land surveying, material transport, and environmental monitoring. Following missions like data collection or inspection, UAVs must land safely at docking stations for storage or recharging, which is an essential requirement for ensuring operational continuity. However, accurate landing remains challenging due to factors like GPS signal interference. To address this issue, we propose a deviation warning system for UAV landings, powered by a novel vision-based model called AeroLite-MDNet. This model integrates a multiscale fusion module for robust cross-scale object detection and incorporates a segmentation branch for efficient orientation estimation. We introduce a new evaluation metric, Average Warning Delay (AWD), to quantify the system's sensitivity to landing deviations. Furthermore, we contribute a new dataset, UAVLandData, which captures real-world landing deviation scenarios to support training and evaluation. Experimental results show that our system achieves an AWD of 0.7 seconds with a deviation detection accuracy of 98.6%, demonstrating its effectiveness in enhancing UAV landing reliability. Code will be available at https://github.com/ITTTTTI/Maskyolo.git",
    "summary": "arXiv:2506.21635v1 Announce Type: cross Abstract: Unmanned aerial vehicles (UAVs) are increasingly employed in diverse applications such as land surveying, material transport, and environmental monitoring. Following missions like data collection or inspection, UAVs must land safely at docking stations for storage or recharging, which is an essential requirement for ensuring operational continuity. However, accurate landing remains challenging due to factors like GPS signal interference. To address this issue, we propose a deviation warning system for UAV landings, powered by a novel vision-based model called AeroLite-MDNet. This model integrates a multiscale fusion module for robust cross-scale object detection and incorporates a segmentation branch for efficient orientation estimation. We introduce a new evaluation metric, Average Warning Delay (AWD), to quantify the system's sensitivity to landing deviations. Furthermore, we contribute a new dataset, UAVLandData, which captures real-world landing deviation scenarios to support training and evaluation. Experimental results show that our system achieves an AWD of 0.7 seconds with a deviation detection accuracy of 98.6%, demonstrating its effectiveness in enhancing UAV landing reliability. Code will be available at https://github.com/ITTTTTI/Maskyolo.git",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21635",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "KunLunBaizeRAG: Reinforcement Learning Driven Inference Performance Leap for Large Language Models",
    "description": "arXiv:2506.19466v2 Announce Type: replace Abstract: This paper introduces KunLunBaizeRAG, a reinforcement learning-driven reasoning framework designed to enhance the reasoning capabilities of large language models (LLMs) in complex multi-hop question-answering tasks. The framework addresses key limitations of traditional RAG, such as retrieval drift, information redundancy, and strategy rigidity. Key innovations include the RAG-driven Reasoning Alignment (RDRA) mechanism, the Search-Think Iterative Enhancement (STIE) mechanism, the Network-Local Intelligent Routing (NLR) mechanism, and a progressive hybrid training strategy. Experimental results demonstrate significant improvements in exact match (EM) and LLM-judged score (LJ) across four benchmarks, highlighting the framework's robustness and effectiveness in complex reasoning scenarios.",
    "summary": "arXiv:2506.19466v2 Announce Type: replace Abstract: This paper introduces KunLunBaizeRAG, a reinforcement learning-driven reasoning framework designed to enhance the reasoning capabilities of large language models (LLMs) in complex multi-hop question-answering tasks. The framework addresses key limitations of traditional RAG, such as retrieval drift, information redundancy, and strategy rigidity. Key innovations include the RAG-driven Reasoning Alignment (RDRA) mechanism, the Search-Think Iterative Enhancement (STIE) mechanism, the Network-Local Intelligent Routing (NLR) mechanism, and a progressive hybrid training strategy. Experimental results demonstrate significant improvements in exact match (EM) and LLM-judged score (LJ) across four benchmarks, highlighting the framework's robustness and effectiveness in complex reasoning scenarios.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19466",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Multimodal neurons in artificial neural networks",
    "description": "We‚Äôve discovered neurons in CLIP that respond to the same concept whether presented literally, symbolically, or conceptually. This may explain CLIP‚Äôs accuracy in classifying surprising visual renditions of concepts, and is also an important step toward understanding the associations and biases that CLIP and similar models learn.",
    "summary": "We‚Äôve discovered neurons in CLIP that respond to the same concept whether presented literally, symbolically, or conceptually. This may explain CLIP‚Äôs accuracy in classifying surprising visual renditions of concepts, and is also an important step toward understanding the associations and biases that CLIP and similar models learn.",
    "pubDate": "Thu, 04 Mar 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/multimodal-neurons",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Complete Guide to Audio Datasets",
    "description": "",
    "summary": "A Complete Guide to Audio Datasets Introduction ü§ó Datasets is an open-source library for downloading...",
    "pubDate": "Thu, 15 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/audio-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/116_audio_datasets/thumbnail.jpg"
  },
  {
    "title": "GLIMPSE: Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation for Generative LVLMs",
    "description": "arXiv:2506.18985v1 Announce Type: cross Abstract: Recent advances in large vision language models (LVLMs) have unlocked unprecedented capabilities in generating coherent responses from visual inputs. However, interpreting where LVLMs direct their visual attention while generating free-form textual responses remains a significant challenge, yet is essential for understanding model behavior, diagnosing hallucination, exposing bias and ensuring transparency. We introduce GLIMPSE (Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation), a lightweight, model-agnostic framework for visualizing the salient image regions that LVLMs rely upon during open-ended visual question answering (VQA), while concurrently revealing the multimodal textual saliency. GLIMPSE fuses gradient-weighted attention, adaptive layer propagation, and weighted token aggregation to produce holistic response-level attribution heat maps for interpreting cross-modal reasoning, outperforming prior interpretability methods in human-alignment. We demonstrate an analytic explainable AI (XAI) approach using GLIMPSE to uncover fine-grained insights into LVLM cross-modal attribution, trace token-level reasoning dynamics, and analyze systematic human-attention misalignment, hallucination, and bias.",
    "summary": "arXiv:2506.18985v1 Announce Type: cross Abstract: Recent advances in large vision language models (LVLMs) have unlocked unprecedented capabilities in generating coherent responses from visual inputs. However, interpreting where LVLMs direct their visual attention while generating free-form textual responses remains a significant challenge, yet is essential for understanding model behavior, diagnosing hallucination, exposing bias and ensuring transparency. We introduce GLIMPSE (Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation), a lightweight, model-agnostic framework for visualizing the salient image regions that LVLMs rely upon during open-ended visual question answering (VQA), while concurrently revealing the multimodal textual saliency. GLIMPSE fuses gradient-weighted attention, adaptive layer propagation, and weighted token aggregation to produce holistic response-level attribution heat maps for interpreting cross-modal reasoning, outperforming prior interpretability methods in human-alignment. We demonstrate an analytic explainable AI (XAI) approach using GLIMPSE to uncover fine-grained insights into LVLM cross-modal attribution, trace token-level reasoning dynamics, and analyze systematic human-attention misalignment, hallucination, and bias.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18985",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "More on Dota 2",
    "description": "Our Dota 2 result shows that self-play can catapult the performance of machine learning systems from far below human level to superhuman, given sufficient compute. In the span of a month, our system went from barely matching a high-ranked player to beating the top pros and has continued to improve since then. Supervised deep learning systems can only be as good as their training datasets, but in self-play systems, the available data improves automatically as the agent gets better.",
    "summary": "Our Dota 2 result shows that self-play can catapult the performance of machine learning systems from far below human level to superhuman, given sufficient compute. In the span of a month, our system went from barely matching a high-ranked player to beating the top pros and has continued to improve since then. Supervised deep learning systems can only be as good as their training datasets, but in self-play systems, the available data improves automatically as the agent gets better.",
    "pubDate": "Wed, 16 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/more-on-dota-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing AutoRound: Intel‚Äôs Advanced Quantization for LLMs and VLMs",
    "description": "",
    "summary": "What is AutoRound? As large language models (LLMs) and vision-language models (VLMs) continue to gro...",
    "pubDate": "Tue, 29 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autoround",
    "thumbnail": "https://huggingface.co/blog/assets/autoround/thumbnail.png"
  },
  {
    "title": "Google DeepMind at NeurIPS 2024",
    "description": "Advancing adaptive AI agents, empowering 3D scene creation, and innovating LLM training for a smarter, safer future",
    "summary": "Advancing adaptive AI agents, empowering 3D scene creation, and innovating LLM training for a smarter, safer future",
    "pubDate": "Thu, 05 Dec 2024 17:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-neurips-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/cKpWE16vpsZ21VcH-_SdGF8tQEeEMp2phWFajdBq_A7aMVS2axiXQzd7V8mlHdJm-CXVKh1IaY3yeM_lAwu_zxc6SIBdWahdN6nYoaQqUbC8uU0qoY8=w1200-h630-n-nu"
  },
  {
    "title": "Dispositions and Roles of Generically Dependent Entities",
    "description": "arXiv:2506.17085v1 Announce Type: new Abstract: BFO 2020 does not support functions, dispositions, and roles of generically dependent continuants (like software or datasets). In this paper, we argue that this is a severe limitation, which prevents, for example, the adequate representation of the functions of computer models or the various roles of datasets during the execution of these models. We discuss the aspects of BFO 2020 that prevent the representation of realizable entities of generically dependent continuants. Two approaches to address the issue are presented: (a) the use of defined classes and (b) a proposal of changes that allow BFO to support functions, dispositions, and roles of generically dependent continuants.",
    "summary": "arXiv:2506.17085v1 Announce Type: new Abstract: BFO 2020 does not support functions, dispositions, and roles of generically dependent continuants (like software or datasets). In this paper, we argue that this is a severe limitation, which prevents, for example, the adequate representation of the functions of computer models or the various roles of datasets during the execution of these models. We discuss the aspects of BFO 2020 that prevent the representation of realizable entities of generically dependent continuants. Two approaches to address the issue are presented: (a) the use of defined classes and (b) a proposal of changes that allow BFO to support functions, dispositions, and roles of generically dependent continuants.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17085",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Non-engineers guide: Train a LLaMA 2 chatbot",
    "description": "",
    "summary": "Non-engineers guide: Train a LLaMA 2 chatbot Introduction In this tutorial we will show you how anyo...",
    "pubDate": "Thu, 28 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/Llama2-for-non-engineers",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/tuto.png"
  },
  {
    "title": "Consumer-friendly EEG-based Emotion Recognition System: A Multi-scale Convolutional Neural Network Approach",
    "description": "arXiv:2506.16448v1 Announce Type: cross Abstract: EEG is a non-invasive, safe, and low-risk method to record electrophysiological signals inside the brain. Especially with recent technology developments like dry electrodes, consumer-grade EEG devices, and rapid advances in machine learning, EEG is commonly used as a resource for automatic emotion recognition. With the aim to develop a deep learning model that can perform EEG-based emotion recognition in a real-life context, we propose a novel approach to utilize multi-scale convolutional neural networks to accomplish such tasks. By implementing feature extraction kernels with many ratio coefficients as well as a new type of kernel that learns key information from four separate areas of the brain, our model consistently outperforms the state-of-the-art TSception model in predicting valence, arousal, and dominance scores across many performance evaluation metrics.",
    "summary": "arXiv:2506.16448v1 Announce Type: cross Abstract: EEG is a non-invasive, safe, and low-risk method to record electrophysiological signals inside the brain. Especially with recent technology developments like dry electrodes, consumer-grade EEG devices, and rapid advances in machine learning, EEG is commonly used as a resource for automatic emotion recognition. With the aim to develop a deep learning model that can perform EEG-based emotion recognition in a real-life context, we propose a novel approach to utilize multi-scale convolutional neural networks to accomplish such tasks. By implementing feature extraction kernels with many ratio coefficients as well as a new type of kernel that learns key information from four separate areas of the brain, our model consistently outperforms the state-of-the-art TSception model in predicting valence, arousal, and dominance scores across many performance evaluation metrics.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16448",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing SafeCoder",
    "description": "",
    "summary": "Introducing SafeCoder Today we are excited to announce SafeCoder - a code assistant solution built f...",
    "pubDate": "Tue, 22 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safecoder",
    "thumbnail": "https://huggingface.co/blog/assets/159_safecoder/thumbnail.jpg"
  },
  {
    "title": "Introducing TextImage Augmentation for Document Images",
    "description": "",
    "summary": "Introducing Multimodal TextImage Augmentation for Document Images In this blog post, we provide a tu...",
    "pubDate": "Tue, 06 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/doc_aug_hf_alb",
    "thumbnail": "https://huggingface.co/blog/assets/185_albumentations/thumbnail.png"
  },
  {
    "title": "Deep Reinforcement Learning Xiangqi Player with Monte Carlo Tree Search",
    "description": "arXiv:2506.15880v1 Announce Type: new Abstract: This paper presents a Deep Reinforcement Learning (DRL) system for Xiangqi (Chinese Chess) that integrates neural networks with Monte Carlo Tree Search (MCTS) to enable strategic self-play and self-improvement. Addressing the underexplored complexity of Xiangqi, including its unique board layout, piece movement constraints, and victory conditions, our approach combines policy-value networks with MCTS to simulate move consequences and refine decision-making. By overcoming challenges such as Xiangqi's high branching factor and asymmetrical piece dynamics, our work advances AI capabilities in culturally significant strategy games while providing insights for adapting DRL-MCTS frameworks to domain-specific rule systems.",
    "summary": "arXiv:2506.15880v1 Announce Type: new Abstract: This paper presents a Deep Reinforcement Learning (DRL) system for Xiangqi (Chinese Chess) that integrates neural networks with Monte Carlo Tree Search (MCTS) to enable strategic self-play and self-improvement. Addressing the underexplored complexity of Xiangqi, including its unique board layout, piece movement constraints, and victory conditions, our approach combines policy-value networks with MCTS to simulate move consequences and refine decision-making. By overcoming challenges such as Xiangqi's high branching factor and asymmetrical piece dynamics, our work advances AI capabilities in culturally significant strategy games while providing insights for adapting DRL-MCTS frameworks to domain-specific rule systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15880",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemini 2.5: Our most intelligent models are getting even better",
    "description": "Gemini 2.5 Pro continues to be loved by developers as the best model for coding, and 2.5 Flash is getting even better with a new update. We‚Äôre bringing new capabilities to our models, including Deep Think, an experimental enhanced reasoning mode for 2.5 Pro.",
    "summary": "Gemini 2.5 Pro continues to be loved by developers as the best model for coding, and 2.5 Flash is getting even better with a new update. We‚Äôre bringing new capabilities to our models, including Deep Think, an experimental enhanced reasoning mode for 2.5 Pro.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-our-world-leading-model-is-getting-even-better/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/deep-think__key-art_16-9.width-1300.jpg"
  },
  {
    "title": "Text-Generation Pipeline on Intel¬Æ Gaudi¬Æ 2 AI Accelerator",
    "description": "",
    "summary": "Text-Generation Pipeline on Intel¬Æ Gaudi¬Æ 2 AI Accelerator With the Generative AI (GenAI) revolution...",
    "pubDate": "Thu, 29 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/textgen-pipe-gaudi",
    "thumbnail": "https://huggingface.co/blog/assets/textgen-pipe-gaudi/thumbnail.png"
  },
  {
    "title": "Rethinking LLM Evaluation with 3C3H: AraGen Benchmark and Leaderboard",
    "description": "",
    "summary": "Rethinking LLM Evaluation with 3C3H: AraGen Benchmark and Leaderboard In the rapidly evolving landsc...",
    "pubDate": "Wed, 04 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-3c3h-aragen",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_3c3h_aragen.png"
  },
  {
    "title": "BigCodeBench: Benchmarking Large Language Models on Solving Practical and Challenging Programming Tasks",
    "description": "",
    "summary": "BigCodeBench: The Next Generation of HumanEval HumanEval is a reference benchmark for evaluating lar...",
    "pubDate": "Tue, 18 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-bigcodebench",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_bigcode.png"
  },
  {
    "title": "Bayesian Evolutionary Swarm Architecture: A Formal Epistemic System Grounded in Truth-Based Competition",
    "description": "arXiv:2506.19191v1 Announce Type: new Abstract: We introduce a mathematically rigorous framework for an artificial intelligence system composed of probabilistic agents evolving through structured competition and belief revision. The architecture, grounded in Bayesian inference, measure theory, and population dynamics, defines agent fitness as a function of alignment with a fixed external oracle representing ground truth. Agents compete in a discrete-time environment, adjusting posterior beliefs through observed outcomes, with higher-rated agents reproducing and lower-rated agents undergoing extinction. Ratings are updated via pairwise truth-aligned utility comparisons, and belief updates preserve measurable consistency and stochastic convergence. We introduce hash-based cryptographic identity commitments to ensure traceability, alongside causal inference operators using do-calculus. Formal theorems on convergence, robustness, and evolutionary stability are provided. The system establishes truth as an evolutionary attractor, demonstrating that verifiable knowledge arises from adversarial epistemic pressure within a computable, self-regulating swarm.",
    "summary": "arXiv:2506.19191v1 Announce Type: new Abstract: We introduce a mathematically rigorous framework for an artificial intelligence system composed of probabilistic agents evolving through structured competition and belief revision. The architecture, grounded in Bayesian inference, measure theory, and population dynamics, defines agent fitness as a function of alignment with a fixed external oracle representing ground truth. Agents compete in a discrete-time environment, adjusting posterior beliefs through observed outcomes, with higher-rated agents reproducing and lower-rated agents undergoing extinction. Ratings are updated via pairwise truth-aligned utility comparisons, and belief updates preserve measurable consistency and stochastic convergence. We introduce hash-based cryptographic identity commitments to ensure traceability, alongside causal inference operators using do-calculus. Formal theorems on convergence, robustness, and evolutionary stability are provided. The system establishes truth as an evolutionary attractor, demonstrating that verifiable knowledge arises from adversarial epistemic pressure within a computable, self-regulating swarm.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19191",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Very Large Language Models and How to Evaluate Them",
    "description": "",
    "summary": "Very Large Language Models and How to Evaluate Them Large language models can now be evaluated on ze...",
    "pubDate": "Mon, 03 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-shot-eval-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/106_zero_shot_eval_on_the_hub/thumbnail.png"
  },
  {
    "title": "Refine Medical Diagnosis Using Generation Augmented Retrieval and Clinical Practice Guidelines",
    "description": "arXiv:2506.21615v1 Announce Type: cross Abstract: Current medical language models, adapted from large language models (LLMs), typically predict ICD code-based diagnosis from electronic health records (EHRs) because these labels are readily available. However, ICD codes do not capture the nuanced, context-rich reasoning clinicians use for diagnosis. Clinicians synthesize diverse patient data and reference clinical practice guidelines (CPGs) to make evidence-based decisions. This misalignment limits the clinical utility of existing models. We introduce GARMLE-G, a Generation-Augmented Retrieval framework that grounds medical language model outputs in authoritative CPGs. Unlike conventional Retrieval-Augmented Generation based approaches, GARMLE-G enables hallucination-free outputs by directly retrieving authoritative guideline content without relying on model-generated text. It (1) integrates LLM predictions with EHR data to create semantically rich queries, (2) retrieves relevant CPG knowledge snippets via embedding similarity, and (3) fuses guideline content with model output to generate clinically aligned recommendations. A prototype system for hypertension diagnosis was developed and evaluated on multiple metrics, demonstrating superior retrieval precision, semantic relevance, and clinical guideline adherence compared to RAG-based baselines, while maintaining a lightweight architecture suitable for localized healthcare deployment. This work provides a scalable, low-cost, and hallucination-free method for grounding medical language models in evidence-based clinical practice, with strong potential for broader clinical deployment.",
    "summary": "arXiv:2506.21615v1 Announce Type: cross Abstract: Current medical language models, adapted from large language models (LLMs), typically predict ICD code-based diagnosis from electronic health records (EHRs) because these labels are readily available. However, ICD codes do not capture the nuanced, context-rich reasoning clinicians use for diagnosis. Clinicians synthesize diverse patient data and reference clinical practice guidelines (CPGs) to make evidence-based decisions. This misalignment limits the clinical utility of existing models. We introduce GARMLE-G, a Generation-Augmented Retrieval framework that grounds medical language model outputs in authoritative CPGs. Unlike conventional Retrieval-Augmented Generation based approaches, GARMLE-G enables hallucination-free outputs by directly retrieving authoritative guideline content without relying on model-generated text. It (1) integrates LLM predictions with EHR data to create semantically rich queries, (2) retrieves relevant CPG knowledge snippets via embedding similarity, and (3) fuses guideline content with model output to generate clinically aligned recommendations. A prototype system for hypertension diagnosis was developed and evaluated on multiple metrics, demonstrating superior retrieval precision, semantic relevance, and clinical guideline adherence compared to RAG-based baselines, while maintaining a lightweight architecture suitable for localized healthcare deployment. This work provides a scalable, low-cost, and hallucination-free method for grounding medical language models in evidence-based clinical practice, with strong potential for broader clinical deployment.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21615",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI‚Äôs EU Economic Blueprint",
    "description": "Today, OpenAI is sharing the EU Economic Blueprint‚Äîa set of proposals to help Europe seize the promise of artificial intelligence, drive sustainable economic growth across the region, and ensure that AI is developed and deployed by Europe, in Europe, for Europe.",
    "summary": "Today, OpenAI is sharing the EU Economic Blueprint‚Äîa set of proposals to help Europe seize the promise of artificial intelligence, drive sustainable economic growth across the region, and ensure that AI is developed and deployed by Europe, in Europe, for Europe.",
    "pubDate": "Mon, 07 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-eu-economic-blueprint",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Allganize„ÄÅ„Éé„Éº„Ç≥„Éº„Éâ„ÅßËá™Á§æÂ∞ÇÁî®AI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÇíÊßãÁØâ„Åß„Åç„Çã„ÄåAgent Builder„Äç„ÇíÊèê‰æõÈñãÂßã",
    "description": "<p>Allganize„ÅØ„ÄÅ‰ºÅÊ•≠„ÅåÈ´òÂ∫¶„Å™„Çª„Ç≠„É•„É™„ÉÜ„Ç£Áí∞Â¢É‰∏ã„ÅßAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„Çí„Éé„Éº„Ç≥„Éº„Éâ„ÅßÁ∞°Âçò„Å´ÊßãÁØâ„Åß„Åç„Çã„ÄåAgent Builder„Äç„ÅÆÊèê‰æõ„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Allganize„Åå„ÄÅ‰ºÅÊ•≠„ÅåÈ´òÂ∫¶„Å™„Çª„Ç≠„É•„É™ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/allganize_agent_builder/'>Allganize„ÄÅ„Éé„Éº„Ç≥„Éº„Éâ„ÅßËá™Á§æÂ∞ÇÁî®AI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÇíÊßãÁØâ„Åß„Åç„Çã„ÄåAgent Builder„Äç„ÇíÊèê‰æõÈñãÂßã</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>Allganize„ÅØ„ÄÅ‰ºÅÊ•≠„ÅåÈ´òÂ∫¶„Å™„Çª„Ç≠„É•„É™„ÉÜ„Ç£Áí∞Â¢É‰∏ã„ÅßAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„Çí„Éé„Éº„Ç≥„Éº„Éâ„ÅßÁ∞°Âçò„Å´ÊßãÁØâ„Åß„Åç„Çã„ÄåAgent Builder„Äç„ÅÆÊèê‰æõ„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Allganize„Åå„ÄÅ‰ºÅÊ•≠„ÅåÈ´òÂ∫¶„Å™„Çª„Ç≠„É•„É™ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/allganize_agent_builder/'>Allganize„ÄÅ„Éé„Éº„Ç≥„Éº„Éâ„ÅßËá™Á§æÂ∞ÇÁî®AI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÇíÊßãÁØâ„Åß„Åç„Çã„ÄåAgent Builder„Äç„ÇíÊèê‰æõÈñãÂßã</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Wed, 11 Jun 2025 09:00:24 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/allganize_agent_builder/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/main-agentbuilder.png"
  },
  {
    "title": "Google DeepMind at NeurIPS 2023",
    "description": "The Neural Information Processing Systems (NeurIPS) is the largest artificial intelligence (AI) conference in the world. NeurIPS 2023 will be taking place December 10-16 in New Orleans, USA.Teams from across Google DeepMind are presenting more than 150 papers at the main conference and workshops.",
    "summary": "The Neural Information Processing Systems (NeurIPS) is the largest artificial intelligence (AI) conference in the world. NeurIPS 2023 will be taking place December 10-16 in New Orleans, USA.Teams from across Google DeepMind are presenting more than 150 papers at the main conference and workshops.",
    "pubDate": "Fri, 08 Dec 2023 15:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-neurips-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/MDme_Q62zVqvTUs5uwaI3Ggy2rWIujPt2elkusnUuCA4wEo79V9mabIg66j9cr9zMso-LObOVcj6_ZnrgSMUKn6fl52kxOUEjcigXtDZ2UMuosX3-2s=w1200-h630-n-nu"
  },
  {
    "title": "AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms",
    "description": "arXiv:2506.21996v1 Announce Type: new Abstract: Deterministic game-solving algorithms are conventionally analyzed in the light of their average-case complexity against a distribution of random game-trees, where leaf values are independently sampled from a fixed distribution. This simplified model enables uncluttered mathematical analysis, revealing two key properties: root value distributions asymptotically collapse to a single fixed value for finite-valued trees, and all reasonable algorithms achieve global optimality. However, these findings are artifacts of the model's design-its long criticized independence assumption strips games of structural complexity, producing trivial instances where no algorithm faces meaningful challenges. To address this limitation, we introduce a new probabilistic model that incrementally constructs game-trees using a fixed level-wise conditional distribution. By enforcing ancestor dependency, a critical structural feature of real-world games, our framework generates problems with adjustable difficulty while retaining some form of analytical tractability. For several algorithms, including AlphaBeta and Scout, we derive recursive formulas characterizing their average-case complexities under this model. These allow us to rigorously compare algorithms on deep game-trees, where Monte-Carlo simulations are no longer feasible. While asymptotically, all algorithms seem to converge to identical branching factor (a result analogous to those of independence-based models), deep finite trees reveal stark differences: AlphaBeta incurs a significantly larger constant multiplicative factor compared to algorithms like Scout, leading to a substantial practical slowdown. Our framework sheds new light on classical game-solving algorithms, offering rigorous evidence and analytical tools to advance the understanding of these methods under a more realistic, challenging, and yet tractable model.",
    "summary": "arXiv:2506.21996v1 Announce Type: new Abstract: Deterministic game-solving algorithms are conventionally analyzed in the light of their average-case complexity against a distribution of random game-trees, where leaf values are independently sampled from a fixed distribution. This simplified model enables uncluttered mathematical analysis, revealing two key properties: root value distributions asymptotically collapse to a single fixed value for finite-valued trees, and all reasonable algorithms achieve global optimality. However, these findings are artifacts of the model's design-its long criticized independence assumption strips games of structural complexity, producing trivial instances where no algorithm faces meaningful challenges. To address this limitation, we introduce a new probabilistic model that incrementally constructs game-trees using a fixed level-wise conditional distribution. By enforcing ancestor dependency, a critical structural feature of real-world games, our framework generates problems with adjustable difficulty while retaining some form of analytical tractability. For several algorithms, including AlphaBeta and Scout, we derive recursive formulas characterizing their average-case complexities under this model. These allow us to rigorously compare algorithms on deep game-trees, where Monte-Carlo simulations are no longer feasible. While asymptotically, all algorithms seem to converge to identical branching factor (a result analogous to those of independence-based models), deep finite trees reveal stark differences: AlphaBeta incurs a significantly larger constant multiplicative factor compared to algorithms like Scout, leading to a substantial practical slowdown. Our framework sheds new light on classical game-solving algorithms, offering rigorous evidence and analytical tools to advance the understanding of these methods under a more realistic, challenging, and yet tractable model.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21996",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Build awesome datasets for video generation",
    "description": "",
    "summary": "Build awesome datasets for video generation Tooling for image generation datasets is well establishe...",
    "pubDate": "Wed, 12 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vid_ds_scripts",
    "thumbnail": "https://huggingface.co/blog/assets/vid_ds_scripts/thumbnail.png"
  },
  {
    "title": "How good are LLMs at fixing their mistakes? A chatbot arena experiment with Keras and TPUs",
    "description": "",
    "summary": "How good are LLMs at fixing their mistakes? A chatbot arena experiment with Keras and TPUs while you...",
    "pubDate": "Thu, 05 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-chatbot-arena",
    "thumbnail": "https://huggingface.co/blog/assets/keras-chatbot-arena/thumbnail.png"
  },
  {
    "title": "Shaping the future of advanced robotics",
    "description": "Introducing AutoRT, SARA-RT, and RT-Trajectory",
    "summary": "Introducing AutoRT, SARA-RT, and RT-Trajectory",
    "pubDate": "Thu, 04 Jan 2024 11:39:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/shaping-the-future-of-advanced-robotics/",
    "thumbnail": "https://lh3.googleusercontent.com/qeWlfSbr0jW0OsZ0dvaQK2V7tYM0HtTtwivx-fUJzK4GivdM6kffvNXlSgqOJyjAQWXBCycqF77zT7XDGxIqGvPiCnTqLX_C3VRmXGJIGGW5GAv7YQ=w1200-h630-n-nu"
  },
  {
    "title": "CLIP-MG: Guiding Semantic Attention with Skeletal Pose Features and RGB Data for Micro-Gesture Recognition on the iMiGUE Dataset",
    "description": "arXiv:2506.16385v1 Announce Type: cross Abstract: Micro-gesture recognition is a challenging task in affective computing due to the subtle, involuntary nature of the gestures and their low movement amplitude. In this paper, we introduce a Pose-Guided Semantics-Aware CLIP-based architecture, or CLIP for Micro-Gesture recognition (CLIP-MG), a modified CLIP model tailored for micro-gesture classification on the iMiGUE dataset. CLIP-MG integrates human pose (skeleton) information into the CLIP-based recognition pipeline through pose-guided semantic query generation and a gated multi-modal fusion mechanism. The proposed model achieves a Top-1 accuracy of 61.82%. These results demonstrate both the potential of our approach and the remaining difficulty in fully adapting vision-language models like CLIP for micro-gesture recognition.",
    "summary": "arXiv:2506.16385v1 Announce Type: cross Abstract: Micro-gesture recognition is a challenging task in affective computing due to the subtle, involuntary nature of the gestures and their low movement amplitude. In this paper, we introduce a Pose-Guided Semantics-Aware CLIP-based architecture, or CLIP for Micro-Gesture recognition (CLIP-MG), a modified CLIP model tailored for micro-gesture classification on the iMiGUE dataset. CLIP-MG integrates human pose (skeleton) information into the CLIP-based recognition pipeline through pose-guided semantic query generation and a gated multi-modal fusion mechanism. The proposed model achieves a Top-1 accuracy of 61.82%. These results demonstrate both the potential of our approach and the remaining difficulty in fully adapting vision-language models like CLIP for micro-gesture recognition.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16385",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From Semantic To Instance: A Semi-Self-Supervised Learning Approach",
    "description": "arXiv:2506.16563v1 Announce Type: cross Abstract: Instance segmentation is essential for applications such as automated monitoring of plant health, growth, and yield. However, extensive effort is required to create large-scale datasets with pixel-level annotations of each object instance for developing instance segmentation models that restrict the use of deep learning in these areas. This challenge is more significant in images with densely packed, self-occluded objects, which are common in agriculture. To address this challenge, we propose a semi-self-supervised learning approach that requires minimal manual annotation to develop a high-performing instance segmentation model. We design GLMask, an image-mask representation for the model to focus on shape, texture, and pattern while minimizing its dependence on color features. We develop a pipeline to generate semantic segmentation and then transform it into instance-level segmentation. The proposed approach substantially outperforms the conventional instance segmentation models, establishing a state-of-the-art wheat head instance segmentation model with mAP@50 of 98.5%. Additionally, we assessed the proposed methodology on the general-purpose Microsoft COCO dataset, achieving a significant performance improvement of over 12.6% mAP@50. This highlights that the utility of our proposed approach extends beyond precision agriculture and applies to other domains, specifically those with similar data characteristics.",
    "summary": "arXiv:2506.16563v1 Announce Type: cross Abstract: Instance segmentation is essential for applications such as automated monitoring of plant health, growth, and yield. However, extensive effort is required to create large-scale datasets with pixel-level annotations of each object instance for developing instance segmentation models that restrict the use of deep learning in these areas. This challenge is more significant in images with densely packed, self-occluded objects, which are common in agriculture. To address this challenge, we propose a semi-self-supervised learning approach that requires minimal manual annotation to develop a high-performing instance segmentation model. We design GLMask, an image-mask representation for the model to focus on shape, texture, and pattern while minimizing its dependence on color features. We develop a pipeline to generate semantic segmentation and then transform it into instance-level segmentation. The proposed approach substantially outperforms the conventional instance segmentation models, establishing a state-of-the-art wheat head instance segmentation model with mAP@50 of 98.5%. Additionally, we assessed the proposed methodology on the general-purpose Microsoft COCO dataset, achieving a significant performance improvement of over 12.6% mAP@50. This highlights that the utility of our proposed approach extends beyond precision agriculture and applies to other domains, specifically those with similar data characteristics.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16563",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective",
    "description": "arXiv:2506.16288v1 Announce Type: cross Abstract: The rapid adaptation ability of auto-regressive foundation models is often attributed to the diversity of their pre-training data. This is because, from a Bayesian standpoint, minimizing prediction error in such settings requires integrating over all plausible latent hypotheses consistent with observations. While this behavior is desirable in principle, it often proves too ambitious in practice: under high ambiguity, the number of plausible latent alternatives makes Bayes-optimal prediction computationally intractable. Cognitive science has long recognized this limitation, suggesting that under such conditions, heuristics or information-seeking strategies are preferable to exhaustive inference. Translating this insight to next-token prediction, we hypothesize that low- and high-ambiguity predictions pose different computational demands, making ambiguity-agnostic next-token prediction a detrimental inductive bias. To test this, we introduce MetaHMM, a synthetic sequence meta-learning benchmark with rich compositional structure and a tractable Bayesian oracle. We show that Transformers indeed struggle with high-ambiguity predictions across model sizes. Motivated by cognitive theories, we propose a method to convert pre-trained models into Monte Carlo predictors that decouple task inference from token prediction. Preliminary results show substantial gains in ambiguous contexts through improved capacity allocation and test-time scalable inference, though challenges remain.",
    "summary": "arXiv:2506.16288v1 Announce Type: cross Abstract: The rapid adaptation ability of auto-regressive foundation models is often attributed to the diversity of their pre-training data. This is because, from a Bayesian standpoint, minimizing prediction error in such settings requires integrating over all plausible latent hypotheses consistent with observations. While this behavior is desirable in principle, it often proves too ambitious in practice: under high ambiguity, the number of plausible latent alternatives makes Bayes-optimal prediction computationally intractable. Cognitive science has long recognized this limitation, suggesting that under such conditions, heuristics or information-seeking strategies are preferable to exhaustive inference. Translating this insight to next-token prediction, we hypothesize that low- and high-ambiguity predictions pose different computational demands, making ambiguity-agnostic next-token prediction a detrimental inductive bias. To test this, we introduce MetaHMM, a synthetic sequence meta-learning benchmark with rich compositional structure and a tractable Bayesian oracle. We show that Transformers indeed struggle with high-ambiguity predictions across model sizes. Motivated by cognitive theories, we propose a method to convert pre-trained models into Monte Carlo predictors that decouple task inference from token prediction. Preliminary results show substantial gains in ambiguous contexts through improved capacity allocation and test-time scalable inference, though challenges remain.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16288",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Supporting sellers with enhanced product listings",
    "description": "Mercari leverages GPT-4o mini and GPT-4 to streamline selling, enhance product listings, and boost sales, transforming the online marketplace with features like AI Listing Support and Mercari AI Assistant.",
    "summary": "Mercari leverages GPT-4o mini and GPT-4 to streamline selling, enhance product listings, and boost sales, transforming the online marketplace with features like AI Listing Support and Mercari AI Assistant.",
    "pubDate": "Thu, 27 Feb 2025 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mercari",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "On the Limits of Language Generation: Trade-Offs Between Hallucination and Mode Collapse",
    "description": "arXiv:2411.09642v2 Announce Type: replace-cross Abstract: Specifying all desirable properties of a language model is challenging, but certain requirements seem essential. Given samples from an unknown language, the trained model should produce valid strings not seen in training and be expressive enough to capture the language's full richness. Otherwise, outputting invalid strings constitutes 'hallucination,' and failing to capture the full range leads to 'mode collapse.' We ask if a language model can meet both requirements. We investigate this within a statistical language generation setting building on Gold and Angluin. Here, the model receives random samples from a distribution over an unknown language K, which belongs to a possibly infinite collection of languages. The goal is to generate unseen strings from K. We say the model generates from K with consistency and breadth if, as training size increases, its output converges to all unseen strings in K. Kleinberg and Mullainathan [KM24] asked if consistency and breadth in language generation are possible. We answer this negatively: for a large class of language models, including next-token prediction models, this is impossible for most collections of candidate languages. This contrasts with [KM24]'s result, showing consistent generation without breadth is possible for any countable collection of languages. Our finding highlights that generation with breadth fundamentally differs from generation without breadth. As a byproduct, we establish near-tight bounds on the number of samples needed for generation with or without breadth. Finally, our results offer hope: consistent generation with breadth is achievable for any countable collection of languages when negative examples (strings outside K) are available alongside positive ones. This suggests that post-training feedback, which encodes negative examples, can be crucial in reducing hallucinations while limiting mode collapse.",
    "summary": "arXiv:2411.09642v2 Announce Type: replace-cross Abstract: Specifying all desirable properties of a language model is challenging, but certain requirements seem essential. Given samples from an unknown language, the trained model should produce valid strings not seen in training and be expressive enough to capture the language's full richness. Otherwise, outputting invalid strings constitutes 'hallucination,' and failing to capture the full range leads to 'mode collapse.' We ask if a language model can meet both requirements. We investigate this within a statistical language generation setting building on Gold and Angluin. Here, the model receives random samples from a distribution over an unknown language K, which belongs to a possibly infinite collection of languages. The goal is to generate unseen strings from K. We say the model generates from K with consistency and breadth if, as training size increases, its output converges to all unseen strings in K. Kleinberg and Mullainathan [KM24] asked if consistency and breadth in language generation are possible. We answer this negatively: for a large class of language models, including next-token prediction models, this is impossible for most collections of candidate languages. This contrasts with [KM24]'s result, showing consistent generation without breadth is possible for any countable collection of languages. Our finding highlights that generation with breadth fundamentally differs from generation without breadth. As a byproduct, we establish near-tight bounds on the number of samples needed for generation with or without breadth. Finally, our results offer hope: consistent generation with breadth is achievable for any countable collection of languages when negative examples (strings outside K) are available alongside positive ones. This suggests that post-training feedback, which encodes negative examples, can be crucial in reducing hallucinations while limiting mode collapse.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.09642",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Mamba in the Llama: Distilling and Accelerating Hybrid Models",
    "description": "arXiv:2408.15237v4 Announce Type: replace-cross Abstract: Linear RNN architectures, like Mamba, can be competitive with Transformer models in language modeling while having advantageous deployment characteristics. Given the focus on training large-scale Transformer models, we consider the challenge of converting these pretrained models for deployment. We demonstrate that it is feasible to distill large Transformers into linear RNNs by reusing the linear projection weights from attention layers with academic GPU resources. The resulting hybrid model, which incorporates a quarter of the attention layers, achieves performance comparable to the original Transformer in chat benchmarks and outperforms open-source hybrid Mamba models trained from scratch with trillions of tokens in both chat benchmarks and general benchmarks. Moreover, we introduce a hardware-aware speculative decoding algorithm that accelerates the inference speed of Mamba and hybrid models. Overall we show how, with limited computation resources, we can remove many of the original attention layers and generate from the resulting model more efficiently. Our top-performing model, distilled from Llama3-8B-Instruct, achieves a 29.61 length-controlled win rate on AlpacaEval 2 against GPT-4 and 7.35 on MT-Bench, surpassing the best 8B scale instruction-tuned linear RNN model. We also find that the distilled model has natural length extrapolation, showing almost perfect accuracy in the needle-in-a-haystack test at 20x the distillation length. Code and pre-trained checkpoints are open-sourced at https://github.com/jxiw/MambaInLlama and https://github.com/itsdaniele/speculative_mamba.",
    "summary": "arXiv:2408.15237v4 Announce Type: replace-cross Abstract: Linear RNN architectures, like Mamba, can be competitive with Transformer models in language modeling while having advantageous deployment characteristics. Given the focus on training large-scale Transformer models, we consider the challenge of converting these pretrained models for deployment. We demonstrate that it is feasible to distill large Transformers into linear RNNs by reusing the linear projection weights from attention layers with academic GPU resources. The resulting hybrid model, which incorporates a quarter of the attention layers, achieves performance comparable to the original Transformer in chat benchmarks and outperforms open-source hybrid Mamba models trained from scratch with trillions of tokens in both chat benchmarks and general benchmarks. Moreover, we introduce a hardware-aware speculative decoding algorithm that accelerates the inference speed of Mamba and hybrid models. Overall we show how, with limited computation resources, we can remove many of the original attention layers and generate from the resulting model more efficiently. Our top-performing model, distilled from Llama3-8B-Instruct, achieves a 29.61 length-controlled win rate on AlpacaEval 2 against GPT-4 and 7.35 on MT-Bench, surpassing the best 8B scale instruction-tuned linear RNN model. We also find that the distilled model has natural length extrapolation, showing almost perfect accuracy in the needle-in-a-haystack test at 20x the distillation length. Code and pre-trained checkpoints are open-sourced at https://github.com/jxiw/MambaInLlama and https://github.com/itsdaniele/speculative_mamba.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.15237",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Open-Source Text Generation & LLM Ecosystem at Hugging Face",
    "description": "",
    "summary": "Open-Source Text Generation & LLM Ecosystem at Hugging Face [Updated on July 24, 2023: Added Llama 2...",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/os-llms",
    "thumbnail": "https://huggingface.co/blog/assets/os_llms/thumbnail.png"
  },
  {
    "title": "How OpenAI is approaching 2024 worldwide elections",
    "description": "We‚Äôre working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate voting information.",
    "summary": "We‚Äôre working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate voting information.",
    "pubDate": "Mon, 15 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-openai-is-approaching-2024-worldwide-elections",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System",
    "description": "arXiv:2506.19433v1 Announce Type: cross Abstract: Vision-and-Language Navigation (VLN) in large-scale urban environments requires embodied agents to ground linguistic instructions in complex scenes and recall relevant experiences over extended time horizons. Prior modular pipelines offer interpretability but lack unified memory, while end-to-end (M)LLM agents excel at fusing vision and language yet remain constrained by fixed context windows and implicit spatial reasoning. We introduce textbf{Mem4Nav}, a hierarchical spatial-cognition long-short memory system that can augment any VLN backbone. Mem4Nav fuses a sparse octree for fine-grained voxel indexing with a semantic topology graph for high-level landmark connectivity, storing both in trainable memory tokens embedded via a reversible Transformer. Long-term memory (LTM) compresses and retains historical observations at both octree and graph nodes, while short-term memory (STM) caches recent multimodal entries in relative coordinates for real-time obstacle avoidance and local planning. At each step, STM retrieval sharply prunes dynamic context, and, when deeper history is needed, LTM tokens are decoded losslessly to reconstruct past embeddings. Evaluated on Touchdown and Map2Seq across three backbones (modular, state-of-the-art VLN with prompt-based LLM, and state-of-the-art VLN with strided-attention MLLM), Mem4Nav yields 7-13 pp gains in Task Completion, sufficient SPD reduction, and >10 pp nDTW improvement. Ablations confirm the indispensability of both the hierarchical map and dual memory modules. Our codes are open-sourced via https://github.com/tsinghua-fib-lab/Mem4Nav.",
    "summary": "arXiv:2506.19433v1 Announce Type: cross Abstract: Vision-and-Language Navigation (VLN) in large-scale urban environments requires embodied agents to ground linguistic instructions in complex scenes and recall relevant experiences over extended time horizons. Prior modular pipelines offer interpretability but lack unified memory, while end-to-end (M)LLM agents excel at fusing vision and language yet remain constrained by fixed context windows and implicit spatial reasoning. We introduce textbf{Mem4Nav}, a hierarchical spatial-cognition long-short memory system that can augment any VLN backbone. Mem4Nav fuses a sparse octree for fine-grained voxel indexing with a semantic topology graph for high-level landmark connectivity, storing both in trainable memory tokens embedded via a reversible Transformer. Long-term memory (LTM) compresses and retains historical observations at both octree and graph nodes, while short-term memory (STM) caches recent multimodal entries in relative coordinates for real-time obstacle avoidance and local planning. At each step, STM retrieval sharply prunes dynamic context, and, when deeper history is needed, LTM tokens are decoded losslessly to reconstruct past embeddings. Evaluated on Touchdown and Map2Seq across three backbones (modular, state-of-the-art VLN with prompt-based LLM, and state-of-the-art VLN with strided-attention MLLM), Mem4Nav yields 7-13 pp gains in Task Completion, sufficient SPD reduction, and >10 pp nDTW improvement. Ablations confirm the indispensability of both the hierarchical map and dual memory modules. Our codes are open-sourced via https://github.com/tsinghua-fib-lab/Mem4Nav.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19433",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improving India‚Äôs critical care infrastructure",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 06 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/10bedicu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Safetensors audited as really safe and becoming the default",
    "description": "",
    "summary": "Audit shows that safetensors is safe and ready to become the default Hugging Face, in close collabor...",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/safetensors-security-audit",
    "thumbnail": "https://huggingface.co/blog/assets/142_safetensors_official/thumbnail.png"
  },
  {
    "title": "Fit More and Train Faster With ZeRO via DeepSpeed and FairScale",
    "description": "",
    "summary": "Fit More and Train Faster With ZeRO via DeepSpeed and FairScale A guest blog post by Hugging Face fe...",
    "pubDate": "Tue, 19 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-deepspeed-fairscale",
    "thumbnail": "https://huggingface.co/blog/assets/11_zero_deepspeed_fairscale/zero-partitioning.png"
  },
  {
    "title": "„ÇÜ„ÅÜ„Å°„ÇáÈäÄË°å„ÄÅYouTube„ÅÆ‚Äú„Éã„ÇªÊÉÖÂ†±ÂãïÁîª‚Äù„Å´Ê≥®ÊÑèÂñöËµ∑„ÄÄÁîüÊàêAIÂà©Áî®„Å®„Åø„Çâ„Çå„Çã„Éï„Çß„Ç§„ÇØÁõ∏Ê¨°„Åê",
    "description": "„ÇÜ„ÅÜ„Å°„ÇáÈäÄË°å„ÅØ„ÄÅYouTube‰∏ä„ÅßÂÅΩ„ÅÆÊÉÖÂ†±„ÇíÁô∫‰ø°„Åô„ÇãÂãïÁîª„Å´„Å§„ÅÑ„Å¶„ÄÅÊ≥®ÊÑè„ÇíÂëº„Å≥„Åã„Åë„Åü„ÄÇ„Äå7Êúà„Åã„Çâ„ÇÜ„ÅÜ„Å°„ÇáÈäÄË°å„ÅÆÂè£Â∫ß„Åå‰Ωø„Åà„Å™„Åè„Å™„Çã„Äç„Å™„Å©„ÄÅË™§„Å£„ÅüÂÜÖÂÆπ„ÅÆÂãïÁîª„ÇíË§áÊï∞Á¢∫Ë™ç„ÄÇ7Êúà‰ª•Èôç„ÇÇ„ÄÅÂêåÁ§æ„ÅÆÂÖ®„Å¶„ÅÆÂïÜÂìÅ„Éª„Çµ„Éº„Éì„Çπ„ÅØÈÄöÂ∏∏ÈÄö„ÇäÂà©Áî®„Åß„Åç„Çã„Å®„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "„ÇÜ„ÅÜ„Å°„ÇáÈäÄË°å„ÅØ„ÄÅYouTube‰∏ä„ÅßÂÅΩ„ÅÆÊÉÖÂ†±„ÇíÁô∫‰ø°„Åô„ÇãÂãïÁîª„Å´„Å§„ÅÑ„Å¶„ÄÅÊ≥®ÊÑè„ÇíÂëº„Å≥„Åã„Åë„Åü„ÄÇ„Äå7Êúà„Åã„Çâ„ÇÜ„ÅÜ„Å°„ÇáÈäÄË°å„ÅÆÂè£Â∫ß„Åå‰Ωø„Åà„Å™„Åè„Å™„Çã„Äç„Å™„Å©„ÄÅË™§„Å£„ÅüÂÜÖÂÆπ„ÅÆÂãïÁîª„ÇíË§áÊï∞Á¢∫Ë™ç„ÄÇ7Êúà‰ª•Èôç„ÇÇ„ÄÅÂêåÁ§æ„ÅÆÂÖ®„Å¶„ÅÆÂïÜÂìÅ„Éª„Çµ„Éº„Éì„Çπ„ÅØÈÄöÂ∏∏ÈÄö„ÇäÂà©Áî®„Åß„Åç„Çã„Å®„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Mon, 23 Jun 2025 18:59:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/23/news094.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/23/cover_news094.jpg"
  },
  {
    "title": "Fairness and Bias in Algorithmic Hiring: a Multidisciplinary Survey",
    "description": "arXiv:2309.13933v4 Announce Type: replace-cross Abstract: Employers are adopting algorithmic hiring technology throughout the recruitment pipeline. Algorithmic fairness is especially applicable in this domain due to its high stakes and structural inequalities. Unfortunately, most work in this space provides partial treatment, often constrained by two competing narratives, optimistically focused on replacing biased recruiter decisions or pessimistically pointing to the automation of discrimination. Whether, and more importantly what types of, algorithmic hiring can be less biased and more beneficial to society than low-tech alternatives currently remains unanswered, to the detriment of trustworthiness. This multidisciplinary survey caters to practitioners and researchers with a balanced and integrated coverage of systems, biases, measures, mitigation strategies, datasets, and legal aspects of algorithmic hiring and fairness. Our work supports a contextualized understanding and governance of this technology by highlighting current opportunities and limitations, providing recommendations for future work to ensure shared benefits for all stakeholders.",
    "summary": "arXiv:2309.13933v4 Announce Type: replace-cross Abstract: Employers are adopting algorithmic hiring technology throughout the recruitment pipeline. Algorithmic fairness is especially applicable in this domain due to its high stakes and structural inequalities. Unfortunately, most work in this space provides partial treatment, often constrained by two competing narratives, optimistically focused on replacing biased recruiter decisions or pessimistically pointing to the automation of discrimination. Whether, and more importantly what types of, algorithmic hiring can be less biased and more beneficial to society than low-tech alternatives currently remains unanswered, to the detriment of trustworthiness. This multidisciplinary survey caters to practitioners and researchers with a balanced and integrated coverage of systems, biases, measures, mitigation strategies, datasets, and legal aspects of algorithmic hiring and fairness. Our work supports a contextualized understanding and governance of this technology by highlighting current opportunities and limitations, providing recommendations for future work to ensure shared benefits for all stakeholders.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2309.13933",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GamePad: A learning environment for theorem proving",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 02 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gamepad",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SASSHA: Sharpness-aware Adaptive Second-order Optimization with Stable Hessian Approximation",
    "description": "arXiv:2502.18153v2 Announce Type: replace-cross Abstract: Approximate second-order optimization methods often exhibit poorer generalization compared to first-order approaches. In this work, we look into this issue through the lens of the loss landscape and find that existing second-order methods tend to converge to sharper minima compared to SGD. In response, we propose Sassha, a novel second-order method designed to enhance generalization by explicitly reducing sharpness of the solution, while stabilizing the computation of approximate Hessians along the optimization trajectory. In fact, this sharpness minimization scheme is crafted also to accommodate lazy Hessian updates, so as to secure efficiency besides flatness. To validate its effectiveness, we conduct a wide range of standard deep learning experiments where Sassha demonstrates its outstanding generalization performance that is comparable to, and mostly better than, other methods. We provide a comprehensive set of analyses including convergence, robustness, stability, efficiency, and cost.",
    "summary": "arXiv:2502.18153v2 Announce Type: replace-cross Abstract: Approximate second-order optimization methods often exhibit poorer generalization compared to first-order approaches. In this work, we look into this issue through the lens of the loss landscape and find that existing second-order methods tend to converge to sharper minima compared to SGD. In response, we propose Sassha, a novel second-order method designed to enhance generalization by explicitly reducing sharpness of the solution, while stabilizing the computation of approximate Hessians along the optimization trajectory. In fact, this sharpness minimization scheme is crafted also to accommodate lazy Hessian updates, so as to secure efficiency besides flatness. To validate its effectiveness, we conduct a wide range of standard deep learning experiments where Sassha demonstrates its outstanding generalization performance that is comparable to, and mostly better than, other methods. We provide a comprehensive set of analyses including convergence, robustness, stability, efficiency, and cost.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.18153",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemma Scope: helping the safety community shed light on the inner workings of language models",
    "description": "Announcing a comprehensive, open suite of sparse autoencoders for language model interpretability.",
    "summary": "Announcing a comprehensive, open suite of sparse autoencoders for language model interpretability.",
    "pubDate": "Wed, 31 Jul 2024 15:59:19 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemma-scope-helping-the-safety-community-shed-light-on-the-inner-workings-of-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/4amJbS1Q5bh_CoBHPAc4NEn0Q13izqrskMETkJl3h2Jdku08GryCCjW6BM59OKj1-Q7-8ZFCWlgu7tIMzjRBIXImy8wlgTOxYgJ88fQvYJTye07C=w1200-h630-n-nu"
  },
  {
    "title": "ChatGPT plugins",
    "description": "We‚Äôve implemented initial support for plugins in ChatGPT. Plugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run computations, or use third-party services.",
    "summary": "We‚Äôve implemented initial support for plugins in ChatGPT. Plugins are tools designed specifically for language models with safety as a core principle, and help ChatGPT access up-to-date information, run computations, or use third-party services.",
    "pubDate": "Thu, 23 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-plugins",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MoNetV2: Enhanced Motion Network for Freehand 3D Ultrasound Reconstruction",
    "description": "arXiv:2506.15835v1 Announce Type: cross Abstract: Three-dimensional (3D) ultrasound (US) aims to provide sonographers with the spatial relationships of anatomical structures, playing a crucial role in clinical diagnosis. Recently, deep-learning-based freehand 3D US has made significant advancements. It reconstructs volumes by estimating transformations between images without external tracking. However, image-only reconstruction poses difficulties in reducing cumulative drift and further improving reconstruction accuracy, particularly in scenarios involving complex motion trajectories. In this context, we propose an enhanced motion network (MoNetV2) to enhance the accuracy and generalizability of reconstruction under diverse scanning velocities and tactics. First, we propose a sensor-based temporal and multi-branch structure that fuses image and motion information from a velocity perspective to improve image-only reconstruction accuracy. Second, we devise an online multi-level consistency constraint that exploits the inherent consistency of scans to handle various scanning velocities and tactics. This constraint exploits both scan-level velocity consistency, path-level appearance consistency, and patch-level motion consistency to supervise inter-frame transformation estimation. Third, we distill an online multi-modal self-supervised strategy that leverages the correlation between network estimation and motion information to further reduce cumulative errors. Extensive experiments clearly demonstrate that MoNetV2 surpasses existing methods in both reconstruction quality and generalizability performance across three large datasets.",
    "summary": "arXiv:2506.15835v1 Announce Type: cross Abstract: Three-dimensional (3D) ultrasound (US) aims to provide sonographers with the spatial relationships of anatomical structures, playing a crucial role in clinical diagnosis. Recently, deep-learning-based freehand 3D US has made significant advancements. It reconstructs volumes by estimating transformations between images without external tracking. However, image-only reconstruction poses difficulties in reducing cumulative drift and further improving reconstruction accuracy, particularly in scenarios involving complex motion trajectories. In this context, we propose an enhanced motion network (MoNetV2) to enhance the accuracy and generalizability of reconstruction under diverse scanning velocities and tactics. First, we propose a sensor-based temporal and multi-branch structure that fuses image and motion information from a velocity perspective to improve image-only reconstruction accuracy. Second, we devise an online multi-level consistency constraint that exploits the inherent consistency of scans to handle various scanning velocities and tactics. This constraint exploits both scan-level velocity consistency, path-level appearance consistency, and patch-level motion consistency to supervise inter-frame transformation estimation. Third, we distill an online multi-modal self-supervised strategy that leverages the correlation between network estimation and motion information to further reduce cumulative errors. Extensive experiments clearly demonstrate that MoNetV2 surpasses existing methods in both reconstruction quality and generalizability performance across three large datasets.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15835",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From High-SNR Radar Signal to ECG: A Transfer Learning Model with Cardio-Focusing Algorithm for Scenarios with Limited Data",
    "description": "arXiv:2506.19358v1 Announce Type: cross Abstract: Electrocardiogram (ECG), as a crucial find-grained cardiac feature, has been successfully recovered from radar signals in the literature, but the performance heavily relies on the high-quality radar signal and numerous radar-ECG pairs for training, restricting the applications in new scenarios due to data scarcity. Therefore, this work will focus on radar-based ECG recovery in new scenarios with limited data and propose a cardio-focusing and -tracking (CFT) algorithm to precisely track the cardiac location to ensure an efficient acquisition of high-quality radar signals. Furthermore, a transfer learning model (RFcardi) is proposed to extract cardio-related information from the radar signal without ECG ground truth based on the intrinsic sparsity of cardiac features, and only a few synchronous radar-ECG pairs are required to fine-tune the pre-trained model for the ECG recovery. The experimental results reveal that the proposed CFT can dynamically identify the cardiac location, and the RFcardi model can effectively generate faithful ECG recoveries after using a small number of radar-ECG pairs for training. The code and dataset are available after the publication.",
    "summary": "arXiv:2506.19358v1 Announce Type: cross Abstract: Electrocardiogram (ECG), as a crucial find-grained cardiac feature, has been successfully recovered from radar signals in the literature, but the performance heavily relies on the high-quality radar signal and numerous radar-ECG pairs for training, restricting the applications in new scenarios due to data scarcity. Therefore, this work will focus on radar-based ECG recovery in new scenarios with limited data and propose a cardio-focusing and -tracking (CFT) algorithm to precisely track the cardiac location to ensure an efficient acquisition of high-quality radar signals. Furthermore, a transfer learning model (RFcardi) is proposed to extract cardio-related information from the radar signal without ECG ground truth based on the intrinsic sparsity of cardiac features, and only a few synchronous radar-ECG pairs are required to fine-tune the pre-trained model for the ECG recovery. The experimental results reveal that the proposed CFT can dynamically identify the cardiac location, and the RFcardi model can effectively generate faithful ECG recoveries after using a small number of radar-ECG pairs for training. The code and dataset are available after the publication.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19358",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How we‚Äôre responding to The New York Times‚Äô data demands in order to protect user privacy",
    "description": "OpenAI is fighting a court order at the demands of The New York Times and plaintiffs, which involves retention of consumer ChatGPT and API user data indefinitely. Learn how we‚Äôre working to uphold user privacy, address legal requirements, and stay true to our data protection commitments.",
    "summary": "OpenAI is fighting a court order at the demands of The New York Times and plaintiffs, which involves retention of consumer ChatGPT and API user data indefinitely. Learn how we‚Äôre working to uphold user privacy, address legal requirements, and stay true to our data protection commitments.",
    "pubDate": "Thu, 05 Jun 2025 16:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/response-to-nyt-data-demands",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Remote VAEs for decoding with HF endpoints ü§ó",
    "description": "",
    "summary": "Remote VAEs for decoding with Inference Endpoints ü§ó When operating with latent-space diffusion model...",
    "pubDate": "Mon, 24 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/remote_vae",
    "thumbnail": "https://huggingface.co/blog/assets/remote_vae/thumbnail.png"
  },
  {
    "title": "Retro Contest",
    "description": "We‚Äôre launching a transfer learning contest that measures a reinforcement learning algorithm‚Äôs ability to generalize from previous experience.",
    "summary": "We‚Äôre launching a transfer learning contest that measures a reinforcement learning algorithm‚Äôs ability to generalize from previous experience.",
    "pubDate": "Thu, 05 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retro-contest",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "On the Necessity of Output Distribution Reweighting for Effective Class Unlearning",
    "description": "arXiv:2506.20893v1 Announce Type: cross Abstract: In this work, we introduce an output-reweighting unlearning method, RWFT, a lightweight technique that erases an entire class from a trained classifier without full retraining. Forgetting specific classes from trained models is essential for enforcing user deletion rights and mitigating harmful or biased predictions. The full retraining is costly and existing unlearning methods fail to replicate the behavior of the retrained models when predicting samples from the unlearned class. We prove this failure by designing a variant of membership inference attacks, MIA-NN that successfully reveals the unlearned class for any of these methods. We propose a simple redistribution of the probability mass for the prediction on the samples in the forgotten class which is robust to MIA-NN. We also introduce a new metric based on the total variation (TV) distance of the prediction probabilities to quantify residual leakage to prevent future methods from susceptibility to the new attack. Through extensive experiments with state of the art baselines in machine unlearning, we show that our approach matches the results of full retraining in both metrics used for evaluation by prior work and the new metric we propose in this work. Compare to state-of-the-art methods, we gain 2.79% in previously used metrics and 111.45% in our new TV-based metric over the best existing method.",
    "summary": "arXiv:2506.20893v1 Announce Type: cross Abstract: In this work, we introduce an output-reweighting unlearning method, RWFT, a lightweight technique that erases an entire class from a trained classifier without full retraining. Forgetting specific classes from trained models is essential for enforcing user deletion rights and mitigating harmful or biased predictions. The full retraining is costly and existing unlearning methods fail to replicate the behavior of the retrained models when predicting samples from the unlearned class. We prove this failure by designing a variant of membership inference attacks, MIA-NN that successfully reveals the unlearned class for any of these methods. We propose a simple redistribution of the probability mass for the prediction on the samples in the forgotten class which is robust to MIA-NN. We also introduce a new metric based on the total variation (TV) distance of the prediction probabilities to quantify residual leakage to prevent future methods from susceptibility to the new attack. Through extensive experiments with state of the art baselines in machine unlearning, we show that our approach matches the results of full retraining in both metrics used for evaluation by prior work and the new metric we propose in this work. Compare to state-of-the-art methods, we gain 2.79% in previously used metrics and 111.45% in our new TV-based metric over the best existing method.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.20893",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CO‚ÇÇ Emissions and Models Performance: Insights from the Open LLM Leaderboard",
    "description": "",
    "summary": "CO‚ÇÇ Emissions and Models Performance: Insights from the Open LLM Leaderboard Since June 2024, we hav...",
    "pubDate": "Thu, 09 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-emissions-analysis",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "The Transformers Library: standardizing model definitions",
    "description": "",
    "summary": "The Transformers Library: standardizing model definitions TLDR: Going forward, we're aiming for Tran...",
    "pubDate": "Thu, 15 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-model-definition",
    "thumbnail": "https://huggingface.co/blog/assets/transformers-model-definition/transformers-thumbnail.png"
  },
  {
    "title": "MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation",
    "description": "arXiv:2506.17113v1 Announce Type: cross Abstract: Combining pre-trained expert models offers substantial potential for scalable multimodal reasoning, but building a unified framework remains challenging due to the increasing diversity of input modalities and task complexity. For instance, medical diagnosis requires precise reasoning over structured clinical tables, while financial forecasting depends on interpreting plot-based data to make informed predictions. To tackle this challenge, we introduce MEXA, a training-free framework that performs modality- and task-aware aggregation of multiple expert models to enable effective multimodal reasoning across diverse and distinct domains. MEXA dynamically selects expert models based on the input modality and the task-specific reasoning demands (i.e., skills). Each expert model, specialized in a modality task pair, generates interpretable textual reasoning outputs. MEXA then aggregates and reasons over these outputs using a Large Reasoning Model (LRM) to produce the final answer. This modular design allows flexible and transparent multimodal reasoning across diverse domains without additional training overhead. We extensively evaluate our approach on diverse multimodal benchmarks, including Video Reasoning, Audio Reasoning, 3D Understanding, and Medical QA. MEXA consistently delivers performance improvements over strong multimodal baselines, highlighting the effectiveness and broad applicability of our expert-driven selection and aggregation in diverse multimodal reasoning tasks.",
    "summary": "arXiv:2506.17113v1 Announce Type: cross Abstract: Combining pre-trained expert models offers substantial potential for scalable multimodal reasoning, but building a unified framework remains challenging due to the increasing diversity of input modalities and task complexity. For instance, medical diagnosis requires precise reasoning over structured clinical tables, while financial forecasting depends on interpreting plot-based data to make informed predictions. To tackle this challenge, we introduce MEXA, a training-free framework that performs modality- and task-aware aggregation of multiple expert models to enable effective multimodal reasoning across diverse and distinct domains. MEXA dynamically selects expert models based on the input modality and the task-specific reasoning demands (i.e., skills). Each expert model, specialized in a modality task pair, generates interpretable textual reasoning outputs. MEXA then aggregates and reasons over these outputs using a Large Reasoning Model (LRM) to produce the final answer. This modular design allows flexible and transparent multimodal reasoning across diverse domains without additional training overhead. We extensively evaluate our approach on diverse multimodal benchmarks, including Video Reasoning, Audio Reasoning, 3D Understanding, and Medical QA. MEXA consistently delivers performance improvements over strong multimodal baselines, highlighting the effectiveness and broad applicability of our expert-driven selection and aggregation in diverse multimodal reasoning tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17113",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google DeepMind‚Äôs latest research at ICML 2023",
    "description": "Exploring AI safety, adaptability, and efficiency for the real world",
    "summary": "Exploring AI safety, adaptability, and efficiency for the real world",
    "pubDate": "Thu, 20 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-research-at-icml-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/5UyUwX8KGovLbTZ0Q8Ynf5Nepy-1zyFaVIIwB7ty0Cp1F5wrKrv24aOT91PDo1vpH3T4P0cwtUn1WxxvtU5vqd4J7cBwEK6UsvnTMNL_qramtFbsX28=w1200-h630-n-nu"
  },
  {
    "title": "RT-2: New model translates vision and language into action",
    "description": "Robotic Transformer 2 (RT-2) is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for robotic control.",
    "summary": "Robotic Transformer 2 (RT-2) is a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for robotic control.",
    "pubDate": "Fri, 28 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/",
    "thumbnail": "https://lh3.googleusercontent.com/ZduBtQRn2mrvSfNqkixe2XktBREieIhekS7NcboCn0E76gFVckUwNLZw74EJ5jIndzxbRoCqCY47iW1-eGi5c_JJV1DFyTmkS91vMnRalgT0rih125s=w1200-h630-n-nu"
  },
  {
    "title": "PRISON: Unmasking the Criminal Potential of Large Language Models",
    "description": "arXiv:2506.16150v1 Announce Type: cross Abstract: As large language models (LLMs) advance, concerns about their misconduct in complex social contexts intensify. Existing research overlooked the systematic understanding and assessment of their criminal capability in realistic interactions. We propose a unified framework PRISON, to quantify LLMs' criminal potential across five dimensions: False Statements, Frame-Up, Psychological Manipulation, Emotional Disguise, and Moral Disengagement. Using structured crime scenarios adapted from classic films, we evaluate both criminal potential and anti-crime ability of LLMs via role-play. Results show that state-of-the-art LLMs frequently exhibit emergent criminal tendencies, such as proposing misleading statements or evasion tactics, even without explicit instructions. Moreover, when placed in a detective role, models recognize deceptive behavior with only 41% accuracy on average, revealing a striking mismatch between conducting and detecting criminal behavior. These findings underscore the urgent need for adversarial robustness, behavioral alignment, and safety mechanisms before broader LLM deployment.",
    "summary": "arXiv:2506.16150v1 Announce Type: cross Abstract: As large language models (LLMs) advance, concerns about their misconduct in complex social contexts intensify. Existing research overlooked the systematic understanding and assessment of their criminal capability in realistic interactions. We propose a unified framework PRISON, to quantify LLMs' criminal potential across five dimensions: False Statements, Frame-Up, Psychological Manipulation, Emotional Disguise, and Moral Disengagement. Using structured crime scenarios adapted from classic films, we evaluate both criminal potential and anti-crime ability of LLMs via role-play. Results show that state-of-the-art LLMs frequently exhibit emergent criminal tendencies, such as proposing misleading statements or evasion tactics, even without explicit instructions. Moreover, when placed in a detective role, models recognize deceptive behavior with only 41% accuracy on average, revealing a striking mismatch between conducting and detecting criminal behavior. These findings underscore the urgent need for adversarial robustness, behavioral alignment, and safety mechanisms before broader LLM deployment.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16150",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SycnMapV2: Robust and Adaptive Unsupervised Segmentation",
    "description": "arXiv:2506.16297v1 Announce Type: cross Abstract: Human vision excels at segmenting visual cues without the need for explicit training, and it remains remarkably robust even as noise severity increases. In contrast, existing AI algorithms struggle to maintain accuracy under similar conditions. Here, we present SyncMapV2, the first to solve unsupervised segmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal drop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop observed in SOTA methods.This superior performance extends across various types of corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0% vs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training, supervision, or loss functions. It is based on a learning paradigm that uses self-organizing dynamical equations combined with concepts from random networks. Moreover,unlike conventional methods that require re-initialization for each new input, SyncMapV2 adapts online, mimicking the continuous adaptability of human vision. Thus, we go beyond the accurate and robust results, and present the first algorithm that can do all the above online, adapting to input rather than re-initializing. In adaptability tests, SyncMapV2 demonstrates near-zero performance degradation, which motivates and fosters a new generation of robust and adaptive intelligence in the near future.",
    "summary": "arXiv:2506.16297v1 Announce Type: cross Abstract: Human vision excels at segmenting visual cues without the need for explicit training, and it remains remarkably robust even as noise severity increases. In contrast, existing AI algorithms struggle to maintain accuracy under similar conditions. Here, we present SyncMapV2, the first to solve unsupervised segmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal drop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop observed in SOTA methods.This superior performance extends across various types of corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0% vs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training, supervision, or loss functions. It is based on a learning paradigm that uses self-organizing dynamical equations combined with concepts from random networks. Moreover,unlike conventional methods that require re-initialization for each new input, SyncMapV2 adapts online, mimicking the continuous adaptability of human vision. Thus, we go beyond the accurate and robust results, and present the first algorithm that can do all the above online, adapting to input rather than re-initializing. In adaptability tests, SyncMapV2 demonstrates near-zero performance degradation, which motivates and fosters a new generation of robust and adaptive intelligence in the near future.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16297",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï„ÄÄ7/9ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„ÄÅÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨",
    "description": "<p>AIsmiley„ÅØ„ÄÅ2025Âπ¥7Êúà9Êó•ÔºàÊ∞¥ÔºâÔΩû7Êúà11Êó•ÔºàÈáëÔºâ„Å´ÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨„ÅÆ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„Çπ„ÇíÂá∫Â±ï„Åó„Åæ„Åô„ÄÇ ‰ºöÂ†¥„Åß„ÅØ„ÄÅÊúÄÊñ∞„ÅÆAI„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥„ÇÑ„Éã„É•„Éº„ÇπÁ≠â„ÇíÂèñ„Çä‰∏ä„Åí„ÇãAI„Éù„Éº„Çø [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/'>„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï„ÄÄ7/9ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„ÄÅÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AIsmiley„ÅØ„ÄÅ2025Âπ¥7Êúà9Êó•ÔºàÊ∞¥ÔºâÔΩû7Êúà11Êó•ÔºàÈáëÔºâ„Å´ÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨„ÅÆ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„Çπ„ÇíÂá∫Â±ï„Åó„Åæ„Åô„ÄÇ ‰ºöÂ†¥„Åß„ÅØ„ÄÅÊúÄÊñ∞„ÅÆAI„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥„ÇÑ„Éã„É•„Éº„ÇπÁ≠â„ÇíÂèñ„Çä‰∏ä„Åí„ÇãAI„Éù„Éº„Çø [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/'>„Ç¢„Ç§„Çπ„Éû„Ç§„É™„Éº„ÄÅ„ÄåÁ¨¨37Âõû „ÇÇ„ÅÆ„Å•„Åè„Çä „ÉØ„Éº„É´„Éâ [Êù±‰∫¨]„Äç„Å´„Éñ„Éº„ÇπÂá∫Â±ï„ÄÄ7/9ÔºàÊ∞¥Ôºâ„Åã„Çâ3Êó•Èñì„ÄÅÂπïÂºµ„É°„ÉÉ„Çª„Å´„Å¶ÈñãÂÇ¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 04:00:20 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/monodukuri-world-2025-no37/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/05/monodukuri-world-tokyo-no37.png"
  },
  {
    "title": "Stable Diffusion with üß® Diffusers",
    "description": "",
    "summary": "Stable Diffusion with üß® Diffusers Stable Diffusion üé® ...using üß® Diffusers Stable Diffusion is a text...",
    "pubDate": "Mon, 22 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable_diffusion",
    "thumbnail": "https://huggingface.co/blog/assets/98_stable_diffusion/thumbnail.png"
  },
  {
    "title": "Sora System Card",
    "description": "Sora is OpenAI‚Äôs video generation model, designed to take text, image, and video inputs and generate a new video as an output. Sora builds on learnings from DALL-E and GPT models, and is designed to give people expanded tools for storytelling and creative expression.",
    "summary": "Sora is OpenAI‚Äôs video generation model, designed to take text, image, and video inputs and generate a new video as an output. Sora builds on learnings from DALL-E and GPT models, and is designed to give people expanded tools for storytelling and creative expression.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Aligning language models to follow instructions",
    "description": "We‚Äôve trained language models that are much better at following user intentions than GPT-3 while also making them more truthful and less toxic, using techniques developed through our alignment research. These¬†InstructGPT¬†models, which are trained with humans in the loop, are now deployed as the default language models on our¬†API.",
    "summary": "We‚Äôve trained language models that are much better at following user intentions than GPT-3 while also making them more truthful and less toxic, using techniques developed through our alignment research. These¬†InstructGPT¬†models, which are trained with humans in the loop, are now deployed as the default language models on our¬†API.",
    "pubDate": "Thu, 27 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/instruction-following",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI safety via debate",
    "description": "We‚Äôre proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.",
    "summary": "We‚Äôre proposing an AI safety technique which trains agents to debate topics with one another, using a human to judge who wins.",
    "pubDate": "Thu, 03 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/debate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pollen-Vision: Unified interface for Zero-Shot vision models in robotics",
    "description": "",
    "summary": "Pollen-Vision: Unified interface for Zero-Shot vision models in robotics This is a guest blog post b...",
    "pubDate": "Mon, 25 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pollen-vision",
    "thumbnail": "https://huggingface.co/blog/assets/pollen-vision/thumbnail.jpg"
  },
  {
    "title": "How AI training scales",
    "description": "We‚Äôve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks. Since complex tasks tend to have noisier gradients, increasingly large batch sizes are likely to become useful in the future, removing one potential limit to further growth of AI systems. More broadly, these results show that neural network training need not be considered a mysterious art, but can be rigorized and¬†systematized.",
    "summary": "We‚Äôve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of neural network training on a wide range of tasks. Since complex tasks tend to have noisier gradients, increasingly large batch sizes are likely to become useful in the future, removing one potential limit to further growth of AI systems. More broadly, these results show that neural network training need not be considered a mysterious art, but can be rigorized and¬†systematized.",
    "pubDate": "Fri, 14 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-ai-training-scales",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Don't repeat yourself - ü§ó Transformers Design Philosophy",
    "description": "",
    "summary": "Don't Repeat Yourself* Designing open-source libraries for modern machine learning ü§ó Transformers De...",
    "pubDate": "Tue, 05 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-design-philosophy",
    "thumbnail": "https://huggingface.co/blog/assets/59_transformers_philosophy/transformers.png"
  },
  {
    "title": "OpenAI and journalism",
    "description": "We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.",
    "summary": "We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.",
    "pubDate": "Mon, 08 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-journalism",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaGenome: AI for better understanding the genome",
    "description": "Introducing a new, unifying DNA sequence model that advances regulatory variant-effect prediction and promises to shed new light on genome function ‚Äî now available via API.",
    "summary": "Introducing a new, unifying DNA sequence model that advances regulatory variant-effect prediction and promises to shed new light on genome function ‚Äî now available via API.",
    "pubDate": "Wed, 25 Jun 2025 13:59:51 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/",
    "thumbnail": "https://lh3.googleusercontent.com/SZkcKUQyLUhSQ06Rq-PJbxAqn1OpMeEa3khkrBVB1MGyHfxyftoqWwEb2aLP9JxX7CjhpLFODcc5zIoMoNdu0bl6ELsZV2nP9fDwZC6SYS36lzAKDw=w1200-h630-n-nu"
  },
  {
    "title": "A Technical Study into 0.5B Reasoning Language Models",
    "description": "arXiv:2506.13404v2 Announce Type: replace Abstract: The ongoing evolution of language models has led to the development of large-scale architectures that demonstrate exceptional performance across a wide range of tasks. However, these models come with significant computational and energy demands, as well as potential privacy implications. In this context, Small Reasoning Language Models (SRLMs) with approximately 0.5 billion parameters present a compelling alternative due to their remarkable computational efficiency and cost effectiveness, particularly in resource-constrained environments. Despite these advantages, the limited capacity of 0.5 billion parameter models poses challenges in handling complex tasks such as mathematical reasoning and code generation. This research investigates various training strategies, including supervised fine-tuning (SFT), knowledge distillation (KD), and reinforcement learning (RL), as well as their hybrid implementations, to enhance the performance of 0.5B SRLMs. We analyze effective methodologies to bridge the performance gap between SRLMS and larger models and present insights into optimal training pipelines tailored for these smaller architectures. Through extensive experimental validation and analysis, our work aims to provide actionable recommendations for maximizing the reasoning capabilities of 0.5B models.",
    "summary": "arXiv:2506.13404v2 Announce Type: replace Abstract: The ongoing evolution of language models has led to the development of large-scale architectures that demonstrate exceptional performance across a wide range of tasks. However, these models come with significant computational and energy demands, as well as potential privacy implications. In this context, Small Reasoning Language Models (SRLMs) with approximately 0.5 billion parameters present a compelling alternative due to their remarkable computational efficiency and cost effectiveness, particularly in resource-constrained environments. Despite these advantages, the limited capacity of 0.5 billion parameter models poses challenges in handling complex tasks such as mathematical reasoning and code generation. This research investigates various training strategies, including supervised fine-tuning (SFT), knowledge distillation (KD), and reinforcement learning (RL), as well as their hybrid implementations, to enhance the performance of 0.5B SRLMs. We analyze effective methodologies to bridge the performance gap between SRLMS and larger models and present insights into optimal training pipelines tailored for these smaller architectures. Through extensive experimental validation and analysis, our work aims to provide actionable recommendations for maximizing the reasoning capabilities of 0.5B models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.13404",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Open Arabic LLM Leaderboard",
    "description": "",
    "summary": "Introducing the Open Arabic LLM Leaderboard The Open Arabic LLM Leaderboard (OALL) is designed to ad...",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-arabic",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_arabic.png"
  },
  {
    "title": "Speech Synthesis, Recognition, and More With SpeechT5",
    "description": "",
    "summary": "Speech Synthesis, Recognition, and More With SpeechT5 We‚Äôre happy to announce that SpeechT5 is now a...",
    "pubDate": "Wed, 08 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/speecht5",
    "thumbnail": "https://huggingface.co/blog/assets/speecht5/thumbnail.png"
  },
  {
    "title": "From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling",
    "description": "arXiv:2506.16393v1 Announce Type: cross Abstract: Although the annotation paradigm based on Large Language Models (LLMs) has made significant breakthroughs in recent years, its actual deployment still has two core bottlenecks: first, the cost of calling commercial APIs in large-scale annotation is very expensive; second, in scenarios that require fine-grained semantic understanding, such as sentiment classification and toxicity classification, the annotation accuracy of LLMs is even lower than that of Small Language Models (SLMs) dedicated to this field. To address these problems, we propose a new paradigm of multi-model cooperative annotation and design a fully automatic annotation framework AutoAnnotator based on this. Specifically, AutoAnnotator consists of two layers. The upper-level meta-controller layer uses the generation and reasoning capabilities of LLMs to select SLMs for annotation, automatically generate annotation code and verify difficult samples; the lower-level task-specialist layer consists of multiple SLMs that perform annotation through multi-model voting. In addition, we use the difficult samples obtained by the secondary review of the meta-controller layer as the reinforcement learning set and fine-tune the SLMs in stages through a continual learning strategy, thereby improving the generalization of SLMs. Extensive experiments show that AutoAnnotator outperforms existing open-source/API LLMs in zero-shot, one-shot, CoT, and majority voting settings. Notably, AutoAnnotator reduces the annotation cost by 74.15% compared to directly annotating with GPT-3.5-turbo, while still improving the accuracy by 6.21%. Project page: https://github.com/Zhaiyuan-Ji/AutoAnnotator.",
    "summary": "arXiv:2506.16393v1 Announce Type: cross Abstract: Although the annotation paradigm based on Large Language Models (LLMs) has made significant breakthroughs in recent years, its actual deployment still has two core bottlenecks: first, the cost of calling commercial APIs in large-scale annotation is very expensive; second, in scenarios that require fine-grained semantic understanding, such as sentiment classification and toxicity classification, the annotation accuracy of LLMs is even lower than that of Small Language Models (SLMs) dedicated to this field. To address these problems, we propose a new paradigm of multi-model cooperative annotation and design a fully automatic annotation framework AutoAnnotator based on this. Specifically, AutoAnnotator consists of two layers. The upper-level meta-controller layer uses the generation and reasoning capabilities of LLMs to select SLMs for annotation, automatically generate annotation code and verify difficult samples; the lower-level task-specialist layer consists of multiple SLMs that perform annotation through multi-model voting. In addition, we use the difficult samples obtained by the secondary review of the meta-controller layer as the reinforcement learning set and fine-tune the SLMs in stages through a continual learning strategy, thereby improving the generalization of SLMs. Extensive experiments show that AutoAnnotator outperforms existing open-source/API LLMs in zero-shot, one-shot, CoT, and majority voting settings. Notably, AutoAnnotator reduces the annotation cost by 74.15% compared to directly annotating with GPT-3.5-turbo, while still improving the accuracy by 6.21%. Project page: https://github.com/Zhaiyuan-Ji/AutoAnnotator.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16393",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PNCS:Power-Norm Cosine Similarity for Diverse Client Selection in Federated Learning",
    "description": "arXiv:2506.15923v1 Announce Type: cross Abstract: Federated Learning (FL) has emerged as a powerful paradigm for leveraging diverse datasets from multiple sources while preserving data privacy by avoiding centralized storage. However, many existing approaches fail to account for the intricate gradient correlations between remote clients, a limitation that becomes especially problematic in data heterogeneity scenarios. In this work, we propose a novel FL framework utilizing Power-Norm Cosine Similarity (PNCS) to improve client selection for model aggregation. By capturing higher-order gradient moments, PNCS addresses non-IID data challenges, enhancing convergence speed and accuracy. Additionally, we introduce a simple algorithm ensuring diverse client selection through a selection history queue. Experiments with a VGG16 model across varied data partitions demonstrate consistent improvements over state-of-the-art methods.",
    "summary": "arXiv:2506.15923v1 Announce Type: cross Abstract: Federated Learning (FL) has emerged as a powerful paradigm for leveraging diverse datasets from multiple sources while preserving data privacy by avoiding centralized storage. However, many existing approaches fail to account for the intricate gradient correlations between remote clients, a limitation that becomes especially problematic in data heterogeneity scenarios. In this work, we propose a novel FL framework utilizing Power-Norm Cosine Similarity (PNCS) to improve client selection for model aggregation. By capturing higher-order gradient moments, PNCS addresses non-IID data challenges, enhancing convergence speed and accuracy. Additionally, we introduce a simple algorithm ensuring diverse client selection through a selection history queue. Experiments with a VGG16 model across varied data partitions demonstrate consistent improvements over state-of-the-art methods.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15923",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hierarchical text-conditional image generation with CLIP latents",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 13 Apr 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hierarchical-text-conditional-image-generation-with-clip-latents",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating Audio Reasoning with Big Bench Audio",
    "description": "",
    "summary": "Evaluating Audio Reasoning with Big Bench Audio The emergence of native Speech to Speech models offe...",
    "pubDate": "Fri, 20 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/big-bench-audio-release",
    "thumbnail": "https://huggingface.co/blog/assets/big_bench_audio_release/big-bench-audio-thumbnail.png"
  },
  {
    "title": "Sentiment Classification with Fully Homomorphic Encryption using Concrete ML",
    "description": "",
    "summary": "Sentiment Analysis on Encrypted Data with Homomorphic Encryption It is well-known that a sentiment a...",
    "pubDate": "Thu, 17 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentiment-analysis-fhe",
    "thumbnail": "https://huggingface.co/blog/assets/sentiment-analysis-fhe/thumbnail.png"
  },
  {
    "title": "Democratic inputs to AI grant program: lessons learned and implementation plans",
    "description": "We funded 10 teams from around the world to design ideas and tools to collectively govern AI. We summarize the innovations, outline our learnings, and call for researchers and engineers to join us as we continue this work.",
    "summary": "We funded 10 teams from around the world to design ideas and tools to collectively govern AI. We summarize the innovations, outline our learnings, and call for researchers and engineers to join us as we continue this work.",
    "pubDate": "Tue, 16 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/democratic-inputs-to-ai-grant-program-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Expert Support case study: Bolstering a RAG app with LLM-as-a-Judge",
    "description": "",
    "summary": "Expert Support case study: Bolstering a RAG app with LLM-as-a-Judge This is a guest blog post author...",
    "pubDate": "Mon, 28 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/digital-green-llm-judge",
    "thumbnail": "https://huggingface.co/blog/assets/digital-gren-llm-judge/thumbnail.png"
  },
  {
    "title": "Measuring Goodhart‚Äôs law",
    "description": "Goodhart‚Äôs law¬†famously says: ‚ÄúWhen a measure becomes a target, it ceases to be a good measure.‚Äù Although originally from economics, it‚Äôs something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
    "summary": "Goodhart‚Äôs law¬†famously says: ‚ÄúWhen a measure becomes a target, it ceases to be a good measure.‚Äù Although originally from economics, it‚Äôs something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
    "pubDate": "Wed, 13 Apr 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/measuring-goodharts-law",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Artificial Intelligence for Atmospheric Sciences: A Research Roadmap",
    "description": "arXiv:2506.16281v1 Announce Type: cross Abstract: Atmospheric sciences are crucial for understanding environmental phenomena ranging from air quality to extreme weather events, and climate change. Recent breakthroughs in sensing, communication, computing, and Artificial Intelligence (AI) have significantly advanced atmospheric sciences, enabling the generation of vast amounts of data through long-term Earth observations and providing powerful tools for analyzing atmospheric phenomena and predicting natural disasters. This paper contributes a critical interdisciplinary overview that bridges the fields of atmospheric science and computer science, highlighting the transformative potential of AI in atmospheric research. We identify key challenges associated with integrating AI into atmospheric research, including issues related to big data and infrastructure, and provide a detailed research roadmap that addresses both current and emerging challenges.",
    "summary": "arXiv:2506.16281v1 Announce Type: cross Abstract: Atmospheric sciences are crucial for understanding environmental phenomena ranging from air quality to extreme weather events, and climate change. Recent breakthroughs in sensing, communication, computing, and Artificial Intelligence (AI) have significantly advanced atmospheric sciences, enabling the generation of vast amounts of data through long-term Earth observations and providing powerful tools for analyzing atmospheric phenomena and predicting natural disasters. This paper contributes a critical interdisciplinary overview that bridges the fields of atmospheric science and computer science, highlighting the transformative potential of AI in atmospheric research. We identify key challenges associated with integrating AI into atmospheric research, including issues related to big data and infrastructure, and provide a detailed research roadmap that addresses both current and emerging challenges.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16281",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Unsupervised sentiment neuron",
    "description": "We‚Äôve developed an unsupervised system which learns an excellent representation of sentiment, despite being trained only to predict the next character in the text of Amazon reviews.",
    "summary": "We‚Äôve developed an unsupervised system which learns an excellent representation of sentiment, despite being trained only to predict the next character in the text of Amazon reviews.",
    "pubDate": "Thu, 06 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/unsupervised-sentiment-neuron",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Enhancing Mathematical Reasoning in Large Language Models with Self-Consistency-Based Hallucination Detection",
    "description": "arXiv:2504.09440v3 Announce Type: replace Abstract: Large language models (LLMs) have demonstrated strong mathematical reasoning capabilities but remain susceptible to hallucinations producing plausible yet incorrect statements especially in theorem proving, symbolic manipulation, and numerical computation. While self-consistency (SC) has been explored as a means to improve factuality in LLMs, existing approaches primarily apply SC to final-answer selection, neglecting the logical consistency of intermediate reasoning steps. In this work, we introduce a structured self-consistency framework designed to enhance the reliability of mathematical reasoning. Our method enforces self-consistency across intermediate steps and final outputs, reducing logical inconsistencies and hallucinations. We evaluate our approach across three core mathematical tasks: theorem proving, symbolic transformation, and numerical computation. Experimental results demonstrate that SC significantly improves proof validity, symbolic reasoning accuracy, and numerical stability while maintaining computational efficiency. Further analysis reveals that structured self-consistency not only enhances problem-solving accuracy but also reduces the variance of model-generated outputs. These findings highlight self-consistency as a robust mechanism for improving mathematical reasoning in LLMs, paving the way for more reliable and interpretable AI-driven mathematics.",
    "summary": "arXiv:2504.09440v3 Announce Type: replace Abstract: Large language models (LLMs) have demonstrated strong mathematical reasoning capabilities but remain susceptible to hallucinations producing plausible yet incorrect statements especially in theorem proving, symbolic manipulation, and numerical computation. While self-consistency (SC) has been explored as a means to improve factuality in LLMs, existing approaches primarily apply SC to final-answer selection, neglecting the logical consistency of intermediate reasoning steps. In this work, we introduce a structured self-consistency framework designed to enhance the reliability of mathematical reasoning. Our method enforces self-consistency across intermediate steps and final outputs, reducing logical inconsistencies and hallucinations. We evaluate our approach across three core mathematical tasks: theorem proving, symbolic transformation, and numerical computation. Experimental results demonstrate that SC significantly improves proof validity, symbolic reasoning accuracy, and numerical stability while maintaining computational efficiency. Further analysis reveals that structured self-consistency not only enhances problem-solving accuracy but also reduces the variance of model-generated outputs. These findings highlight self-consistency as a robust mechanism for improving mathematical reasoning in LLMs, paving the way for more reliable and interpretable AI-driven mathematics.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.09440",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Tagged for Direction: Pinning Down Causal Edge Directions with Precision",
    "description": "arXiv:2506.19459v1 Announce Type: cross Abstract: Not every causal relation between variables is equal, and this can be leveraged for the task of causal discovery. Recent research shows that pairs of variables with particular type assignments induce a preference on the causal direction of other pairs of variables with the same type. Although useful, this assignment of a specific type to a variable can be tricky in practice. We propose a tag-based causal discovery approach where multiple tags are assigned to each variable in a causal graph. Existing causal discovery approaches are first applied to direct some edges, which are then used to determine edge relations between tags. Then, these edge relations are used to direct the undirected edges. Doing so improves upon purely type-based relations, where the assumption of type consistency lacks robustness and flexibility due to being restricted to single types for each variable. Our experimental evaluations show that this boosts causal discovery and that these high-level tag relations fit common knowledge.",
    "summary": "arXiv:2506.19459v1 Announce Type: cross Abstract: Not every causal relation between variables is equal, and this can be leveraged for the task of causal discovery. Recent research shows that pairs of variables with particular type assignments induce a preference on the causal direction of other pairs of variables with the same type. Although useful, this assignment of a specific type to a variable can be tricky in practice. We propose a tag-based causal discovery approach where multiple tags are assigned to each variable in a causal graph. Existing causal discovery approaches are first applied to direct some edges, which are then used to determine edge relations between tags. Then, these edge relations are used to direct the undirected edges. Doing so improves upon purely type-based relations, where the assumption of type consistency lacks robustness and flexibility due to being restricted to single types for each variable. Our experimental evaluations show that this boosts causal discovery and that these high-level tag relations fit common knowledge.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19459",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Rethinking External Slow-Thinking: From Snowball Errors to Probability of Correct Reasoning",
    "description": "arXiv:2501.15602v3 Announce Type: replace Abstract: Test-time scaling, which is also often referred to as slow-thinking, has been demonstrated to enhance multi-step reasoning in large language models (LLMs). However, despite its widespread utilization, the mechanisms underlying slow-thinking methods remain poorly understood. This paper explores the mechanisms of external slow-thinking from a theoretical standpoint. We begin by examining the snowball error effect within the LLM reasoning process and connect it to the likelihood of correct reasoning using information theory. Building on this, we show that external slow-thinking methods can be interpreted as strategies to mitigate the error probability. We further provide a comparative analysis of popular external slow-thinking approaches, ranging from simple to complex, highlighting their differences and interrelationships. Our findings suggest that the efficacy of these methods is not primarily determined by the specific framework employed, and that expanding the search scope or the model's internal reasoning capacity may yield more sustained improvements in the long term. We open-source our code at https://github.com/ZyGan1999/Snowball-Errors-and-Probability.",
    "summary": "arXiv:2501.15602v3 Announce Type: replace Abstract: Test-time scaling, which is also often referred to as slow-thinking, has been demonstrated to enhance multi-step reasoning in large language models (LLMs). However, despite its widespread utilization, the mechanisms underlying slow-thinking methods remain poorly understood. This paper explores the mechanisms of external slow-thinking from a theoretical standpoint. We begin by examining the snowball error effect within the LLM reasoning process and connect it to the likelihood of correct reasoning using information theory. Building on this, we show that external slow-thinking methods can be interpreted as strategies to mitigate the error probability. We further provide a comparative analysis of popular external slow-thinking approaches, ranging from simple to complex, highlighting their differences and interrelationships. Our findings suggest that the efficacy of these methods is not primarily determined by the specific framework employed, and that expanding the search scope or the model's internal reasoning capacity may yield more sustained improvements in the long term. We open-source our code at https://github.com/ZyGan1999/Snowball-Errors-and-Probability.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.15602",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Anthropic„ÄÅË™≠„Åø„ÅØ„Äå„Ç¢„É≥„ÇΩ„É≠„Éî„ÉÉ„ÇØ„ÄçÔºü„ÄÄ„Äå„Ç¢„É≥„Çπ„É≠„Éî„ÉÉ„ÇØ„ÄçÔºü",
    "description": "Â§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´„ÄåClaude„Äç„Ç∑„É™„Éº„Ç∫„Å™„Å©„ÅßÁü•„Çâ„Çå„ÇãÁ±≥AI„Éô„É≥„ÉÅ„É£„ÉºAnthropic„ÄÇÊó•Êú¨„Åß„ÅØ„Äå„Ç¢„É≥„Çπ„É≠„Éî„ÉÉ„ÇØ„Äç„Å®„ÇÇ„Äå„Ç¢„É≥„ÇΩ„É≠„Éî„ÉÉ„ÇØ„Äç„Å®„ÇÇË™≠„Åæ„Çå„ÄÅÂ§ßÊâã„É°„Éá„Ç£„Ç¢Èñì„Åß„ÇÇË°®Ë®ò„ÅåÊè∫„Çå„Å¶„ÅÑ„Çã„ÄÇÊ≠£„Åó„ÅÑË™≠„ÅøÊñπ„ÅØ„Å©„Å°„Çâ„Åã„ÄÇ",
    "summary": "Â§ßË¶èÊ®°Ë®ÄË™û„É¢„Éá„É´„ÄåClaude„Äç„Ç∑„É™„Éº„Ç∫„Å™„Å©„ÅßÁü•„Çâ„Çå„ÇãÁ±≥AI„Éô„É≥„ÉÅ„É£„ÉºAnthropic„ÄÇÊó•Êú¨„Åß„ÅØ„Äå„Ç¢„É≥„Çπ„É≠„Éî„ÉÉ„ÇØ„Äç„Å®„ÇÇ„Äå„Ç¢„É≥„ÇΩ„É≠„Éî„ÉÉ„ÇØ„Äç„Å®„ÇÇË™≠„Åæ„Çå„ÄÅÂ§ßÊâã„É°„Éá„Ç£„Ç¢Èñì„Åß„ÇÇË°®Ë®ò„ÅåÊè∫„Çå„Å¶„ÅÑ„Çã„ÄÇÊ≠£„Åó„ÅÑË™≠„ÅøÊñπ„ÅØ„Å©„Å°„Çâ„Åã„ÄÇ",
    "pubDate": "Fri, 27 Jun 2025 11:30:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/27/news061.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/27/cover_news061.jpg"
  },
  {
    "title": "FDLLM: A Dedicated Detector for Black-Box LLMs Fingerprinting",
    "description": "arXiv:2501.16029v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are rapidly transforming the landscape of digital content creation. However, the prevalent black-box Application Programming Interface (API) access to many LLMs introduces significant challenges in accountability, governance, and security. LLM fingerprinting, which aims to identify the source model by analyzing statistical and stylistic features of generated text, offers a potential solution. Current progress in this area is hindered by a lack of dedicated datasets and the need for efficient, practical methods that are robust against adversarial manipulations. To address these challenges, we introduce FD-Dataset, a comprehensive bilingual fingerprinting benchmark comprising 90,000 text samples from 20 famous proprietary and open-source LLMs. Furthermore, we present FDLLM, a novel fingerprinting method that leverages parameter-efficient Low-Rank Adaptation (LoRA) to fine-tune a foundation model. This approach enables LoRA to extract deep, persistent features that characterize each source LLM. Through our analysis, we find that LoRA adaptation promotes the aggregation of outputs from the same LLM in representation space while enhancing the separation between different LLMs. This mechanism explains why LoRA proves particularly effective for LLM fingerprinting. Extensive empirical evaluations on FD-Dataset demonstrate FDLLM's superiority, achieving a Macro F1 score 22.1% higher than the strongest baseline. FDLLM also exhibits strong generalization to newly released models, achieving an average accuracy of 95% on unseen models. Notably, FDLLM remains consistently robust under various adversarial attacks, including polishing, translation, and synonym substitution. Experimental results show that FDLLM reduces the average attack success rate from 49.2% (LM-D) to 23.9%.",
    "summary": "arXiv:2501.16029v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are rapidly transforming the landscape of digital content creation. However, the prevalent black-box Application Programming Interface (API) access to many LLMs introduces significant challenges in accountability, governance, and security. LLM fingerprinting, which aims to identify the source model by analyzing statistical and stylistic features of generated text, offers a potential solution. Current progress in this area is hindered by a lack of dedicated datasets and the need for efficient, practical methods that are robust against adversarial manipulations. To address these challenges, we introduce FD-Dataset, a comprehensive bilingual fingerprinting benchmark comprising 90,000 text samples from 20 famous proprietary and open-source LLMs. Furthermore, we present FDLLM, a novel fingerprinting method that leverages parameter-efficient Low-Rank Adaptation (LoRA) to fine-tune a foundation model. This approach enables LoRA to extract deep, persistent features that characterize each source LLM. Through our analysis, we find that LoRA adaptation promotes the aggregation of outputs from the same LLM in representation space while enhancing the separation between different LLMs. This mechanism explains why LoRA proves particularly effective for LLM fingerprinting. Extensive empirical evaluations on FD-Dataset demonstrate FDLLM's superiority, achieving a Macro F1 score 22.1% higher than the strongest baseline. FDLLM also exhibits strong generalization to newly released models, achieving an average accuracy of 95% on unseen models. Notably, FDLLM remains consistently robust under various adversarial attacks, including polishing, translation, and synonym substitution. Experimental results show that FDLLM reduces the average attack success rate from 49.2% (LM-D) to 23.9%.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.16029",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "IRanker: Towards Ranking Foundation Model",
    "description": "arXiv:2506.21638v1 Announce Type: cross Abstract: Ranking tasks are ubiquitous, encompassing applications such as recommendation systems, LLM routing, and item re-ranking. We propose to unify these tasks using a single ranking foundation model (FM), as it eliminates the need for designing different models for each specific ranking task. However, unlike general supervision tasks in LLMs, ranking tasks do not have clear labels for supervision, posing great challenges to developing a ranking FM. To overcome these challenges, we propose IRanker, a ranking FM framework with reinforcement learning (RL) and iterative decoding. Our insight is to decompose the complex ranking task into an iterative decoding process that eliminates the worst candidate from the candidate pool step by step, which significantly reduces the output combinatorial space and better utilizes the limited context length during RL training. We meticulously train and comprehensively evaluate an IRanker-3B model on nine datasets across three scenarios: recommendation, routing, and passage ranking. The results show that a single IRanker-3B achieves state-of-the-art results on several datasets compared to models of similar size, and even surpasses the performance of larger models on certain datasets. We further demonstrate the effectiveness of our RL design and the robustness of the iterative mechanism across different LLM sizes. Moreover, we conducted both in-domain and out-of-domain zero-shot generalization experiments, which showed that IRanker-3B achieved good generalization on in-domain ranking tasks compared to the base LLM by at least 5% improvement. Surprisingly, on out-of-domain generic LLM tasks, IRanker-3B outperformed the base model by at least 9% on GSM8K, IFEval, and MathQA. In addition, the thoughts generated by IRanker-3B during training could further enhance zero-shot LLM performance.",
    "summary": "arXiv:2506.21638v1 Announce Type: cross Abstract: Ranking tasks are ubiquitous, encompassing applications such as recommendation systems, LLM routing, and item re-ranking. We propose to unify these tasks using a single ranking foundation model (FM), as it eliminates the need for designing different models for each specific ranking task. However, unlike general supervision tasks in LLMs, ranking tasks do not have clear labels for supervision, posing great challenges to developing a ranking FM. To overcome these challenges, we propose IRanker, a ranking FM framework with reinforcement learning (RL) and iterative decoding. Our insight is to decompose the complex ranking task into an iterative decoding process that eliminates the worst candidate from the candidate pool step by step, which significantly reduces the output combinatorial space and better utilizes the limited context length during RL training. We meticulously train and comprehensively evaluate an IRanker-3B model on nine datasets across three scenarios: recommendation, routing, and passage ranking. The results show that a single IRanker-3B achieves state-of-the-art results on several datasets compared to models of similar size, and even surpasses the performance of larger models on certain datasets. We further demonstrate the effectiveness of our RL design and the robustness of the iterative mechanism across different LLM sizes. Moreover, we conducted both in-domain and out-of-domain zero-shot generalization experiments, which showed that IRanker-3B achieved good generalization on in-domain ranking tasks compared to the base LLM by at least 5% improvement. Surprisingly, on out-of-domain generic LLM tasks, IRanker-3B outperformed the base model by at least 9% on GSM8K, IFEval, and MathQA. In addition, the thoughts generated by IRanker-3B during training could further enhance zero-shot LLM performance.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21638",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing ‚öîÔ∏è AI vs. AI ‚öîÔ∏è a deep reinforcement learning multi-agents competition system",
    "description": "",
    "summary": "Introducing ‚öîÔ∏è AI vs. AI ‚öîÔ∏è a deep reinforcement learning multi-agents competition system We‚Äôre exci...",
    "pubDate": "Tue, 07 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aivsai",
    "thumbnail": "https://huggingface.co/blog/assets/128_aivsai/thumbnail.png"
  },
  {
    "title": "TROFI: Trajectory-Ranked Offline Inverse Reinforcement Learning",
    "description": "arXiv:2506.22008v1 Announce Type: cross Abstract: In offline reinforcement learning, agents are trained using only a fixed set of stored transitions derived from a source policy. However, this requires that the dataset be labeled by a reward function. In applied settings such as video game development, the availability of the reward function is not always guaranteed. This paper proposes Trajectory-Ranked OFfline Inverse reinforcement learning (TROFI), a novel approach to effectively learn a policy offline without a pre-defined reward function. TROFI first learns a reward function from human preferences, which it then uses to label the original dataset making it usable for training the policy. In contrast to other approaches, our method does not require optimal trajectories. Through experiments on the D4RL benchmark we demonstrate that TROFI consistently outperforms baselines and performs comparably to using the ground truth reward to learn policies. Additionally, we validate the efficacy of our method in a 3D game environment. Our studies of the reward model highlight the importance of the reward function in this setting: we show that to ensure the alignment of a value function to the actual future discounted reward, it is fundamental to have a well-engineered and easy-to-learn reward function.",
    "summary": "arXiv:2506.22008v1 Announce Type: cross Abstract: In offline reinforcement learning, agents are trained using only a fixed set of stored transitions derived from a source policy. However, this requires that the dataset be labeled by a reward function. In applied settings such as video game development, the availability of the reward function is not always guaranteed. This paper proposes Trajectory-Ranked OFfline Inverse reinforcement learning (TROFI), a novel approach to effectively learn a policy offline without a pre-defined reward function. TROFI first learns a reward function from human preferences, which it then uses to label the original dataset making it usable for training the policy. In contrast to other approaches, our method does not require optimal trajectories. Through experiments on the D4RL benchmark we demonstrate that TROFI consistently outperforms baselines and performs comparably to using the ground truth reward to learn policies. Additionally, we validate the efficacy of our method in a 3D game environment. Our studies of the reward model highlight the importance of the reward function in this setting: we show that to ensure the alignment of a value function to the actual future discounted reward, it is fundamental to have a well-engineered and easy-to-learn reward function.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22008",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Proximal Policy Optimization (PPO)",
    "description": "",
    "summary": "Proximal Policy Optimization (PPO) Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 8, of ...",
    "pubDate": "Fri, 05 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-ppo",
    "thumbnail": "https://huggingface.co/blog/assets/93_deep_rl_ppo/thumbnail.png"
  },
  {
    "title": "Can Vision Language Models Understand Mimed Actions?",
    "description": "arXiv:2506.21586v1 Announce Type: cross Abstract: Nonverbal communication (NVC) plays an integral role in human language, but studying NVC in general is challenging because of its broad scope and high variance in interpretation among individuals and cultures. However, mime -- the theatrical technique of suggesting intent using only gesture, expression, and movement -- is a subset of NVC that consists of explicit and embodied actions with much lower human interpretation variance. We argue that a solid understanding of mimed actions is a crucial prerequisite for vision-language models capable of interpreting and commanding more subtle aspects of NVC. Hence, we propose Mime Identification Multimodal Evaluation (MIME), a novel video-based question answering benchmark comprising of 86 mimed actions. Constructed with motion capture data, MIME consists of variations of each action with perturbations applied to the character, background, and viewpoint for evaluating recognition robustness. We find that both open-weight and API-based vision-language models perform significantly worse than humans on MIME, motivating the need for increased research for instilling more robust understanding of human gestures.",
    "summary": "arXiv:2506.21586v1 Announce Type: cross Abstract: Nonverbal communication (NVC) plays an integral role in human language, but studying NVC in general is challenging because of its broad scope and high variance in interpretation among individuals and cultures. However, mime -- the theatrical technique of suggesting intent using only gesture, expression, and movement -- is a subset of NVC that consists of explicit and embodied actions with much lower human interpretation variance. We argue that a solid understanding of mimed actions is a crucial prerequisite for vision-language models capable of interpreting and commanding more subtle aspects of NVC. Hence, we propose Mime Identification Multimodal Evaluation (MIME), a novel video-based question answering benchmark comprising of 86 mimed actions. Constructed with motion capture data, MIME consists of variations of each action with perturbations applied to the character, background, and viewpoint for evaluating recognition robustness. We find that both open-weight and API-based vision-language models perform significantly worse than humans on MIME, motivating the need for increased research for instilling more robust understanding of human gestures.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21586",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RL¬≤: Fast reinforcement learning via slow reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 09 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rl2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How Large Language Models play humans in online conversations: a simulated study of the 2016 US politics on Reddit",
    "description": "arXiv:2506.21620v1 Announce Type: cross Abstract: Large Language Models (LLMs) have recently emerged as powerful tools for natural language generation, with applications spanning from content creation to social simulations. Their ability to mimic human interactions raises both opportunities and concerns, particularly in the context of politically relevant online discussions. In this study, we evaluate the performance of LLMs in replicating user-generated content within a real-world, divisive scenario: Reddit conversations during the 2016 US Presidential election. In particular, we conduct three different experiments, asking GPT-4 to generate comments by impersonating either real or artificial partisan users. We analyze the generated comments in terms of political alignment, sentiment, and linguistic features, comparing them against real user contributions and benchmarking against a null model. We find that GPT-4 is able to produce realistic comments, both in favor of or against the candidate supported by the community, yet tending to create consensus more easily than dissent. In addition we show that real and artificial comments are well separated in a semantically embedded space, although they are indistinguishable by manual inspection. Our findings provide insights on the potential use of LLMs to sneak into online discussions, influence political debate and shape political narratives, bearing broader implications of AI-driven discourse manipulation.",
    "summary": "arXiv:2506.21620v1 Announce Type: cross Abstract: Large Language Models (LLMs) have recently emerged as powerful tools for natural language generation, with applications spanning from content creation to social simulations. Their ability to mimic human interactions raises both opportunities and concerns, particularly in the context of politically relevant online discussions. In this study, we evaluate the performance of LLMs in replicating user-generated content within a real-world, divisive scenario: Reddit conversations during the 2016 US Presidential election. In particular, we conduct three different experiments, asking GPT-4 to generate comments by impersonating either real or artificial partisan users. We analyze the generated comments in terms of political alignment, sentiment, and linguistic features, comparing them against real user contributions and benchmarking against a null model. We find that GPT-4 is able to produce realistic comments, both in favor of or against the candidate supported by the community, yet tending to create consensus more easily than dissent. In addition we show that real and artificial comments are well separated in a semantically embedded space, although they are indistinguishable by manual inspection. Our findings provide insights on the potential use of LLMs to sneak into online discussions, influence political debate and shape political narratives, bearing broader implications of AI-driven discourse manipulation.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21620",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving",
    "description": "arXiv:2506.22005v1 Announce Type: new Abstract: We introduce LeanConjecturer, a pipeline for automatically generating university-level mathematical conjectures in Lean 4 using Large Language Models (LLMs). Our hybrid approach combines rule-based context extraction with LLM-based theorem statement generation, addressing the data scarcity challenge in formal theorem proving. Through iterative generation and evaluation, LeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with 3,776 identified as syntactically valid and non-trivial, that is, cannot be proven by texttt{aesop} tactic. We demonstrate the utility of these generated conjectures for reinforcement learning through Group Relative Policy Optimization (GRPO), showing that targeted training on domain-specific conjectures can enhance theorem proving capabilities. Our approach generates 103.25 novel conjectures per seed file on average, providing a scalable solution for creating training data for theorem proving systems. Our system successfully verified several non-trivial theorems in topology, including properties of semi-open, alpha-open, and pre-open sets, demonstrating its potential for mathematical discovery beyond simple variations of existing results.",
    "summary": "arXiv:2506.22005v1 Announce Type: new Abstract: We introduce LeanConjecturer, a pipeline for automatically generating university-level mathematical conjectures in Lean 4 using Large Language Models (LLMs). Our hybrid approach combines rule-based context extraction with LLM-based theorem statement generation, addressing the data scarcity challenge in formal theorem proving. Through iterative generation and evaluation, LeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with 3,776 identified as syntactically valid and non-trivial, that is, cannot be proven by texttt{aesop} tactic. We demonstrate the utility of these generated conjectures for reinforcement learning through Group Relative Policy Optimization (GRPO), showing that targeted training on domain-specific conjectures can enhance theorem proving capabilities. Our approach generates 103.25 novel conjectures per seed file on average, providing a scalable solution for creating training data for theorem proving systems. Our system successfully verified several non-trivial theorems in topology, including properties of semi-open, alpha-open, and pre-open sets, demonstrating its potential for mathematical discovery beyond simple variations of existing results.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22005",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Large-scale study of curiosity-driven learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 13 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/large-scale-study-of-curiosity-driven-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Segment Anything for Satellite Imagery: A Strong Baseline and a Regional Dataset for Automatic Field Delineation",
    "description": "arXiv:2506.16318v1 Announce Type: cross Abstract: Accurate mapping of agricultural field boundaries is essential for the efficient operation of agriculture. Automatic extraction from high-resolution satellite imagery, supported by computer vision techniques, can avoid costly ground surveys. In this paper, we present a pipeline for field delineation based on the Segment Anything Model (SAM), introducing a fine-tuning strategy to adapt SAM to this task. In addition to using published datasets, we describe a method for acquiring a complementary regional dataset that covers areas beyond current sources. Extensive experiments assess segmentation accuracy and evaluate the generalization capabilities. Our approach provides a robust baseline for automated field delineation. The new regional dataset, known as ERAS, is now publicly available.",
    "summary": "arXiv:2506.16318v1 Announce Type: cross Abstract: Accurate mapping of agricultural field boundaries is essential for the efficient operation of agriculture. Automatic extraction from high-resolution satellite imagery, supported by computer vision techniques, can avoid costly ground surveys. In this paper, we present a pipeline for field delineation based on the Segment Anything Model (SAM), introducing a fine-tuning strategy to adapt SAM to this task. In addition to using published datasets, we describe a method for acquiring a complementary regional dataset that covers areas beyond current sources. Extensive experiments assess segmentation accuracy and evaluate the generalization capabilities. Our approach provides a robust baseline for automated field delineation. The new regional dataset, known as ERAS, is now publicly available.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16318",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI„Åå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Å´„ÄÅAIÂà©Áî®ËÄÖ„ÅÆÂçäÊï∞‰ª•‰∏ä„ÅåÂà©Áî®",
    "description": "<p>NEXER„Å®„Éù„Éº„É´„Éà„Ç•„Ç¶„Ç£„É≥„Åå„ÄÅÊôÆÊÆµAI„ÇíÂà©Áî®„Åô„ÇãÂÖ®ÂõΩ238Âêç„ÇíÂØæË±°„Å´ÂÆüÊñΩ„Åó„ÅüË™øÊüª„Åß„ÄÅÂçäÊï∞‰ª•‰∏ä„Åå„Äå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Äç„Å®„Åó„Å¶AI„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Çã„Å®Áô∫Ë°®„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà AIÂà©Áî®ËÄÖ„ÅÆ 51.3%„Åå„Äå„Éó„É© [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/use-ai-private-consultant/'>AI„Åå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Å´„ÄÅAIÂà©Áî®ËÄÖ„ÅÆÂçäÊï∞‰ª•‰∏ä„ÅåÂà©Áî®</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>NEXER„Å®„Éù„Éº„É´„Éà„Ç•„Ç¶„Ç£„É≥„Åå„ÄÅÊôÆÊÆµAI„ÇíÂà©Áî®„Åô„ÇãÂÖ®ÂõΩ238Âêç„ÇíÂØæË±°„Å´ÂÆüÊñΩ„Åó„ÅüË™øÊüª„Åß„ÄÅÂçäÊï∞‰ª•‰∏ä„Åå„Äå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Äç„Å®„Åó„Å¶AI„ÇíÂà©Áî®„Åó„Å¶„ÅÑ„Çã„Å®Áô∫Ë°®„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà AIÂà©Áî®ËÄÖ„ÅÆ 51.3%„Åå„Äå„Éó„É© [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/use-ai-private-consultant/'>AI„Åå„Éó„É©„Ç§„Éô„Éº„Éà„ÅÆÁõ∏Ë´áÁõ∏Êâã„Å´„ÄÅAIÂà©Áî®ËÄÖ„ÅÆÂçäÊï∞‰ª•‰∏ä„ÅåÂà©Áî®</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Fri, 27 Jun 2025 05:08:11 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/use-ai-private-consultant/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/use-ai-private-consultant1.png"
  },
  {
    "title": "Team++",
    "description": "We've had some fantastic people join over the past few months (and we're still hiring). Welcome, everyone!",
    "summary": "We've had some fantastic people join over the past few months (and we're still hiring). Welcome, everyone!",
    "pubDate": "Thu, 31 Mar 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-plus-plus",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Build rich, interactive web apps with an updated Gemini 2.5 Pro",
    "description": "Our updated version of Gemini 2.5 Pro Preview has improved capabilities for coding.",
    "summary": "Our updated version of Gemini 2.5 Pro Preview has improved capabilities for coding.",
    "pubDate": "Tue, 06 May 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/build-rich-interactive-web-apps-with-an-updated-gemini-25-pro/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini25prohero.width-1300.png"
  },
  {
    "title": "OpenAI Robotics Symposium 2019",
    "description": "We hosted the first OpenAI Robotics Symposium on April 27, 2019.",
    "summary": "We hosted the first OpenAI Robotics Symposium on April 27, 2019.",
    "pubDate": "Wed, 05 Jun 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/symposium-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "QT-DoG: Quantization-aware Training for Domain Generalization",
    "description": "arXiv:2410.06020v2 Announce Type: replace-cross Abstract: A key challenge in Domain Generalization (DG) is preventing overfitting to source domains, which can be mitigated by finding flatter minima in the loss landscape. In this work, we propose Quantization-aware Training for Domain Generalization (QT-DoG) and demonstrate that weight quantization effectively leads to flatter minima in the loss landscape, thereby enhancing domain generalization. Unlike traditional quantization methods focused on model compression, QT-DoG exploits quantization as an implicit regularizer by inducing noise in model weights, guiding the optimization process toward flatter minima that are less sensitive to perturbations and overfitting. We provide both an analytical perspective and empirical evidence demonstrating that quantization inherently encourages flatter minima, leading to better generalization across domains. Moreover, with the benefit of reducing the model size through quantization, we demonstrate that an ensemble of multiple quantized models further yields superior accuracy than the state-of-the-art DG approaches with no computational or memory overheads. Code is released at: https://saqibjaved1.github.io/QT_DoG/.",
    "summary": "arXiv:2410.06020v2 Announce Type: replace-cross Abstract: A key challenge in Domain Generalization (DG) is preventing overfitting to source domains, which can be mitigated by finding flatter minima in the loss landscape. In this work, we propose Quantization-aware Training for Domain Generalization (QT-DoG) and demonstrate that weight quantization effectively leads to flatter minima in the loss landscape, thereby enhancing domain generalization. Unlike traditional quantization methods focused on model compression, QT-DoG exploits quantization as an implicit regularizer by inducing noise in model weights, guiding the optimization process toward flatter minima that are less sensitive to perturbations and overfitting. We provide both an analytical perspective and empirical evidence demonstrating that quantization inherently encourages flatter minima, leading to better generalization across domains. Moreover, with the benefit of reducing the model size through quantization, we demonstrate that an ensemble of multiple quantized models further yields superior accuracy than the state-of-the-art DG approaches with no computational or memory overheads. Code is released at: https://saqibjaved1.github.io/QT_DoG/.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.06020",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution",
    "description": "arXiv:2506.15591v2 Announce Type: replace-cross Abstract: It is a challenging problem to reproduce rich spatial details while maintaining temporal consistency in real-world video super-resolution (Real-VSR), especially when we leverage pre-trained generative models such as stable diffusion (SD) for realistic details synthesis. Existing SD-based Real-VSR methods often compromise spatial details for temporal coherence, resulting in suboptimal visual quality. We argue that the key lies in how to effectively extract the degradation-robust temporal consistency priors from the low-quality (LQ) input video and enhance the video details while maintaining the extracted consistency priors. To achieve this, we propose a Dual LoRA Learning (DLoRAL) paradigm to train an effective SD-based one-step diffusion model, achieving realistic frame details and temporal consistency simultaneously. Specifically, we introduce a Cross-Frame Retrieval (CFR) module to aggregate complementary information across frames, and train a Consistency-LoRA (C-LoRA) to learn robust temporal representations from degraded inputs. After consistency learning, we fix the CFR and C-LoRA modules and train a Detail-LoRA (D-LoRA) to enhance spatial details while aligning with the temporal space defined by C-LoRA to keep temporal coherence. The two phases alternate iteratively for optimization, collaboratively delivering consistent and detail-rich outputs. During inference, the two LoRA branches are merged into the SD model, allowing efficient and high-quality video restoration in a single diffusion step. Experiments show that DLoRAL achieves strong performance in both accuracy and speed. Code and models are available at https://github.com/yjsunnn/DLoRAL.",
    "summary": "arXiv:2506.15591v2 Announce Type: replace-cross Abstract: It is a challenging problem to reproduce rich spatial details while maintaining temporal consistency in real-world video super-resolution (Real-VSR), especially when we leverage pre-trained generative models such as stable diffusion (SD) for realistic details synthesis. Existing SD-based Real-VSR methods often compromise spatial details for temporal coherence, resulting in suboptimal visual quality. We argue that the key lies in how to effectively extract the degradation-robust temporal consistency priors from the low-quality (LQ) input video and enhance the video details while maintaining the extracted consistency priors. To achieve this, we propose a Dual LoRA Learning (DLoRAL) paradigm to train an effective SD-based one-step diffusion model, achieving realistic frame details and temporal consistency simultaneously. Specifically, we introduce a Cross-Frame Retrieval (CFR) module to aggregate complementary information across frames, and train a Consistency-LoRA (C-LoRA) to learn robust temporal representations from degraded inputs. After consistency learning, we fix the CFR and C-LoRA modules and train a Detail-LoRA (D-LoRA) to enhance spatial details while aligning with the temporal space defined by C-LoRA to keep temporal coherence. The two phases alternate iteratively for optimization, collaboratively delivering consistent and detail-rich outputs. During inference, the two LoRA branches are merged into the SD model, allowing efficient and high-quality video restoration in a single diffusion step. Experiments show that DLoRAL achieves strong performance in both accuracy and speed. Code and models are available at https://github.com/yjsunnn/DLoRAL.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15591",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "‰ΩèÂèãÁîüÂëΩ„ÄÅPFN„Å´Âá∫Ë≥á„ÄÄ„ÄåÂçîÊ•≠„ÇÇÊ§úË®é„Äç",
    "description": "‰ΩèÂèãÁîüÂëΩ„ÅØAI„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó„ÅÆPreferred NetworksÔºàPFNÔºâ„Å´Âá∫Ë≥á„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇPFN„Å®„ÅÆÂçîÊ•≠„ÇÇÊ§úË®é„Åô„Çã„ÄÇ",
    "summary": "‰ΩèÂèãÁîüÂëΩ„ÅØAI„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó„ÅÆPreferred NetworksÔºàPFNÔºâ„Å´Âá∫Ë≥á„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇPFN„Å®„ÅÆÂçîÊ•≠„ÇÇÊ§úË®é„Åô„Çã„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 15:35:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/30/news104.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/30/cover_news104.png"
  },
  {
    "title": "Introducing OpenAI for Countries",
    "description": "A new initiative to support countries around the world that want to build on democratic AI rails.",
    "summary": "A new initiative to support countries around the world that want to build on democratic AI rails.",
    "pubDate": "Wed, 07 May 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-for-countries",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generating audio for video",
    "description": "Video-to-audio research uses video pixels and text prompts to generate rich soundtracks",
    "summary": "Video-to-audio research uses video pixels and text prompts to generate rich soundtracks",
    "pubDate": "Mon, 17 Jun 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/generating-audio-for-video/",
    "thumbnail": "https://lh3.googleusercontent.com/Lzihw4F171DQeSgZ9q0MUONzbt1BkbK1sOgnqvLAV3AUIQQ1UJ4niEXOTgWiiyKZrJaCpE4Q6APwV8RRQj7a86_2yDlbIV6WUzD6S_Gu2mjuZDyVWqo=w1200-h630-n-nu"
  },
  {
    "title": "BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models",
    "description": "arXiv:2506.15689v1 Announce Type: cross Abstract: Rotations have become essential to state-of-the-art quantization pipelines for large language models (LLMs) by effectively smoothing outliers in weights and activations. However, further optimizing the rotation parameters offers only limited performance gains and introduces significant training overhead: due to rotation parameter sharing, full-model must be loaded simultaneously to enable backpropagation, resulting in substantial memory consumption and limited practical utility. In this work, we identify two fundamental limitations of current rotational quantization methods: (i) rotation fails to align channel means, resulting in wider quantization bounds and increased rounding errors; and (ii) rotation makes the activation distribution more Gaussian-like, increasing energy loss caused by clipping errors. To address these issues, we introduce textbf{BASE-Q}, a simple yet powerful approach that combines bias correction and asymmetric scaling to effectively reduce rounding and clipping errors. Furthermore, BASE-Q enables blockwise optimization, eliminating the need for memory-intensive full-model backpropagation. Extensive experiments on various LLMs and benchmarks demonstrate the effectiveness of BASE-Q, narrowing the accuracy gap to full-precision models by 50.5%, 42.9%, and 29.2% compared to QuaRot, SpinQuant, and OSTQuant, respectively. The code will be released soon.",
    "summary": "arXiv:2506.15689v1 Announce Type: cross Abstract: Rotations have become essential to state-of-the-art quantization pipelines for large language models (LLMs) by effectively smoothing outliers in weights and activations. However, further optimizing the rotation parameters offers only limited performance gains and introduces significant training overhead: due to rotation parameter sharing, full-model must be loaded simultaneously to enable backpropagation, resulting in substantial memory consumption and limited practical utility. In this work, we identify two fundamental limitations of current rotational quantization methods: (i) rotation fails to align channel means, resulting in wider quantization bounds and increased rounding errors; and (ii) rotation makes the activation distribution more Gaussian-like, increasing energy loss caused by clipping errors. To address these issues, we introduce textbf{BASE-Q}, a simple yet powerful approach that combines bias correction and asymmetric scaling to effectively reduce rounding and clipping errors. Furthermore, BASE-Q enables blockwise optimization, eliminating the need for memory-intensive full-model backpropagation. Extensive experiments on various LLMs and benchmarks demonstrate the effectiveness of BASE-Q, narrowing the accuracy gap to full-precision models by 50.5%, 42.9%, and 29.2% compared to QuaRot, SpinQuant, and OSTQuant, respectively. The code will be released soon.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15689",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sora first impressions",
    "description": "Since we introduced Sora to the world last month, we‚Äôve been working with artists to learn how Sora might aid in their creative process.",
    "summary": "Since we introduced Sora to the world last month, we‚Äôve been working with artists to learn how Sora might aid in their creative process.",
    "pubDate": "Mon, 25 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-first-impressions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Illustrating Reinforcement Learning from Human Feedback (RLHF)",
    "description": "",
    "summary": "Illustrating Reinforcement Learning from Human Feedback (RLHF) This article has been translated to C...",
    "pubDate": "Fri, 09 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rlhf",
    "thumbnail": "https://huggingface.co/blog/assets/120_rlhf/thumbnail.png"
  },
  {
    "title": "Machine Learning Experts - Meg Mitchell Interview",
    "description": "",
    "summary": "Machine Learning Experts - Margaret Mitchell Hey friends! Welcome to Machine Learning Experts. I'm y...",
    "pubDate": "Wed, 23 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/meg-mitchell-interview",
    "thumbnail": "https://huggingface.co/blog/assets/57_meg_mitchell_interview/thumbnail.png"
  },
  {
    "title": "Combining technology, education, and human connection to improve online learning",
    "description": "Caitlin Morris, a PhD student and 2024 MAD Fellow affiliated with the MIT Media Lab, designs digital learning platforms that make room for the ‚Äúsocial magic‚Äù that influences curiosity and motivation.",
    "summary": "Caitlin Morris, a PhD student and 2024 MAD Fellow affiliated with the MIT Media Lab, designs digital learning platforms that make room for the ‚Äúsocial magic‚Äù that influences curiosity and motivation.",
    "pubDate": "Tue, 17 Jun 2025 16:25:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/caitlin-morris-combines-tech-education-human-connection-improve-online-learning-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-Caitlin-Morris.jpg"
  },
  {
    "title": "Simultaneously Fair Allocation of Indivisible Items Across Multiple Dimensions",
    "description": "arXiv:2506.21727v1 Announce Type: cross Abstract: This paper explores the fair allocation of indivisible items in a multidimensional setting, motivated by the need to address fairness in complex environments where agents assess bundles according to multiple criteria. Such multidimensional settings are not merely of theoretical interest but are central to many real-world applications. For example, cloud computing resources are evaluated based on multiple criteria such as CPU cores, memory, and network bandwidth. In such cases, traditional one dimensional fairness notions fail to capture fairness across multiple attributes. To address these challenges, we study two relaxed variants of envy-freeness: weak simultaneously envy-free up to c goods (weak sEFc) and strong simultaneously envy-free up to c goods (strong sEFc), which accommodate the multidimensionality of agents' preferences. Under the weak notion, for every pair of agents and for each dimension, any perceived envy can be eliminated by removing, if necessary, a different set of goods from the envied agent's allocation. In contrast, the strong version requires selecting a single set of goods whose removal from the envied bundle simultaneously eliminates envy in every dimension. We provide upper and lower bounds on the relaxation parameter c that guarantee the existence of weak or strong sEFc allocations, where these bounds are independent of the total number of items. In addition, we present algorithms for checking whether a weak or strong sEFc allocation exists. Moreover, we establish NP-hardness results for checking the existence of weak sEF1 and strong sEF1 allocations.",
    "summary": "arXiv:2506.21727v1 Announce Type: cross Abstract: This paper explores the fair allocation of indivisible items in a multidimensional setting, motivated by the need to address fairness in complex environments where agents assess bundles according to multiple criteria. Such multidimensional settings are not merely of theoretical interest but are central to many real-world applications. For example, cloud computing resources are evaluated based on multiple criteria such as CPU cores, memory, and network bandwidth. In such cases, traditional one dimensional fairness notions fail to capture fairness across multiple attributes. To address these challenges, we study two relaxed variants of envy-freeness: weak simultaneously envy-free up to c goods (weak sEFc) and strong simultaneously envy-free up to c goods (strong sEFc), which accommodate the multidimensionality of agents' preferences. Under the weak notion, for every pair of agents and for each dimension, any perceived envy can be eliminated by removing, if necessary, a different set of goods from the envied agent's allocation. In contrast, the strong version requires selecting a single set of goods whose removal from the envied bundle simultaneously eliminates envy in every dimension. We provide upper and lower bounds on the relaxation parameter c that guarantee the existence of weak or strong sEFc allocations, where these bounds are independent of the total number of items. In addition, we present algorithms for checking whether a weak or strong sEFc allocation exists. Moreover, we establish NP-hardness results for checking the existence of weak sEF1 and strong sEF1 allocations.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21727",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sekai: A Video Dataset towards World Exploration",
    "description": "arXiv:2506.15675v2 Announce Type: replace-cross Abstract: Video generation techniques have made remarkable progress, promising to be the foundation of interactive world exploration. However, existing video generation datasets are not well-suited for world exploration training as they suffer from some limitations: limited locations, short duration, static scenes, and a lack of annotations about exploration and the world. In this paper, we introduce Sekai (meaning ``world'' in Japanese), a high-quality first-person view worldwide video dataset with rich annotations for world exploration. It consists of over 5,000 hours of walking or drone view (FPV and UVA) videos from over 100 countries and regions across 750 cities. We develop an efficient and effective toolbox to collect, pre-process and annotate videos with location, scene, weather, crowd density, captions, and camera trajectories. Experiments demonstrate the quality of the dataset. And, we use a subset to train an interactive video world exploration model, named YUME (meaning ``dream'' in Japanese). We believe Sekai will benefit the area of video generation and world exploration, and motivate valuable applications. The project page is https://lixsp11.github.io/sekai-project/.",
    "summary": "arXiv:2506.15675v2 Announce Type: replace-cross Abstract: Video generation techniques have made remarkable progress, promising to be the foundation of interactive world exploration. However, existing video generation datasets are not well-suited for world exploration training as they suffer from some limitations: limited locations, short duration, static scenes, and a lack of annotations about exploration and the world. In this paper, we introduce Sekai (meaning ``world'' in Japanese), a high-quality first-person view worldwide video dataset with rich annotations for world exploration. It consists of over 5,000 hours of walking or drone view (FPV and UVA) videos from over 100 countries and regions across 750 cities. We develop an efficient and effective toolbox to collect, pre-process and annotate videos with location, scene, weather, crowd density, captions, and camera trajectories. Experiments demonstrate the quality of the dataset. And, we use a subset to train an interactive video world exploration model, named YUME (meaning ``dream'' in Japanese). We believe Sekai will benefit the area of video generation and world exploration, and motivate valuable applications. The project page is https://lixsp11.github.io/sekai-project/.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15675",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Training a language model with ü§ó Transformers using TensorFlow and TPUs",
    "description": "",
    "summary": "Training a language model with ü§ó Transformers using TensorFlow and TPUs Introduction TPU training is...",
    "pubDate": "Thu, 27 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf_tpu",
    "thumbnail": "https://huggingface.co/blog/assets/tf_tpu_training/thumbnail.png"
  },
  {
    "title": "AI„Å´Èñ¢„Çè„Çã‰∫∫„ÅåÁü•„Å£„Å¶„Åä„Åè„Åπ„Åç‚Äú‚óã‚óãÂïèÈ°å‚Äù„ÄÅ5ÈÅ∏",
    "description": "AI„Å´„ÅØ„ÄÅ„Åù„ÅÆ‰ªïÁµÑ„Åø„ÇÑÊÄßËÉΩ‰∏ä„ÅÆÈôêÁïå„ÄÅ‰∫∫Èñì„Å®„ÅØÊ†πÊú¨ÁöÑ„Å´Áï∞„Å™„ÇãÁâπÊÄß„Å™„Å©„ÇíÊµÆ„ÅçÂΩ´„Çä„Å´„Åô„Çã„Äå‚óã‚óãÂïèÈ°å„Äç„Å®Âëº„Å∞„Çå„ÇãÁî®Ë™û„ÅåÂπæ„Å§„Åã„ÅÇ„Çä„Åæ„Åô„ÄÇ„Åù„ÅÆ‰∏≠„Åß„ÇÇÁâπ„Å´‰ª£Ë°®ÁöÑ„Å™„ÇÇ„ÅÆ„Çí„Éî„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Åó„Å¶„ÅîÁ¥π‰ªã„Åó„Åæ„Åô„ÄÇÂèñ„Çä‰∏ä„Åí„Çã„ÅÆ„ÅØ„Äå„Ç∑„É≥„Éú„É´„Ç∞„É©„Ç¶„É≥„Éá„Ç£„É≥„Ç∞ÂïèÈ°å„Äç„Äå„Éï„É¨„Éº„É†ÂïèÈ°å„Äç„Äå„Éà„É≠„ÉÉ„Ç≥ÂïèÈ°å„Äç„Äå„Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„ÇπÂïèÈ°å„Äç„Äå„Ç≥„Éº„É´„Éâ„Çπ„Çø„Éº„ÉàÂïèÈ°å„Äç„ÅÆ5„Å§„Åß„Åô„ÄÇ",
    "summary": "AI„Å´„ÅØ„ÄÅ„Åù„ÅÆ‰ªïÁµÑ„Åø„ÇÑÊÄßËÉΩ‰∏ä„ÅÆÈôêÁïå„ÄÅ‰∫∫Èñì„Å®„ÅØÊ†πÊú¨ÁöÑ„Å´Áï∞„Å™„ÇãÁâπÊÄß„Å™„Å©„ÇíÊµÆ„ÅçÂΩ´„Çä„Å´„Åô„Çã„Äå‚óã‚óãÂïèÈ°å„Äç„Å®Âëº„Å∞„Çå„ÇãÁî®Ë™û„ÅåÂπæ„Å§„Åã„ÅÇ„Çä„Åæ„Åô„ÄÇ„Åù„ÅÆ‰∏≠„Åß„ÇÇÁâπ„Å´‰ª£Ë°®ÁöÑ„Å™„ÇÇ„ÅÆ„Çí„Éî„ÉÉ„ÇØ„Ç¢„ÉÉ„Éó„Åó„Å¶„ÅîÁ¥π‰ªã„Åó„Åæ„Åô„ÄÇÂèñ„Çä‰∏ä„Åí„Çã„ÅÆ„ÅØ„Äå„Ç∑„É≥„Éú„É´„Ç∞„É©„Ç¶„É≥„Éá„Ç£„É≥„Ç∞ÂïèÈ°å„Äç„Äå„Éï„É¨„Éº„É†ÂïèÈ°å„Äç„Äå„Éà„É≠„ÉÉ„Ç≥ÂïèÈ°å„Äç„Äå„Éñ„É©„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„ÇπÂïèÈ°å„Äç„Äå„Ç≥„Éº„É´„Éâ„Çπ„Çø„Éº„ÉàÂïèÈ°å„Äç„ÅÆ5„Å§„Åß„Åô„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 05:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://atmarkit.itmedia.co.jp/ait/articles/2506/30/news020.html",
    "thumbnail": "https://image.itmedia.co.jp/ait/articles/2506/30/cover_news020.jpg"
  },
  {
    "title": "Our approach to data and AI",
    "description": "Just over a year after launching ChatGPT, AI is changing how we live, work and learn. It‚Äôs also raised important conversations about data in the age of AI. More on our approach, a new Media Manager for creators and content owners, and where we‚Äôre headed.",
    "summary": "Just over a year after launching ChatGPT, AI is changing how we live, work and learn. It‚Äôs also raised important conversations about data in the age of AI. More on our approach, a new Media Manager for creators and content owners, and where we‚Äôre headed.",
    "pubDate": "Tue, 07 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/approach-to-data-and-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sycophancy in GPT-4o: what happened and what we‚Äôre doing about it",
    "description": "We have rolled back last week‚Äôs GPT‚Äë4o update in ChatGPT so people are now using an earlier version with more balanced behavior. The update we removed was overly flattering or agreeable‚Äîoften described as sycophantic.",
    "summary": "We have rolled back last week‚Äôs GPT‚Äë4o update in ChatGPT so people are now using an earlier version with more balanced behavior. The update we removed was overly flattering or agreeable‚Äîoften described as sycophantic.",
    "pubDate": "Tue, 29 Apr 2025 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sycophancy-in-gpt-4o",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis",
    "description": "arXiv:2412.19723v3 Announce Type: replace Abstract: Graphical User Interface (GUI) agents powered by Vision-Language Models (VLMs) have demonstrated human-like computer control capability. Despite their utility in advancing digital automation, a critical bottleneck persists: collecting high-quality trajectory data for training. Common practices for collecting such data rely on human supervision or synthetic data generation through executing pre-defined tasks, which are either resource-intensive or unable to guarantee data quality. Moreover, these methods suffer from limited data diversity and significant gaps between synthetic data and real-world environments. To address these challenges, we propose OS-Genesis, a novel GUI data synthesis pipeline that reverses the conventional trajectory collection process. Instead of relying on pre-defined tasks, OS-Genesis enables agents first to perceive environments and perform step-wise interactions, then retrospectively derive high-quality tasks to enable trajectory-level exploration. A trajectory reward model is then employed to ensure the quality of the generated trajectories. We demonstrate that training GUI agents with OS-Genesis significantly improves their performance on highly challenging online benchmarks. In-depth analysis further validates OS-Genesis's efficiency and its superior data quality and diversity compared to existing synthesis methods. Our codes, data, and checkpoints are available at https://qiushisun.github.io/OS-Genesis-Home/.",
    "summary": "arXiv:2412.19723v3 Announce Type: replace Abstract: Graphical User Interface (GUI) agents powered by Vision-Language Models (VLMs) have demonstrated human-like computer control capability. Despite their utility in advancing digital automation, a critical bottleneck persists: collecting high-quality trajectory data for training. Common practices for collecting such data rely on human supervision or synthetic data generation through executing pre-defined tasks, which are either resource-intensive or unable to guarantee data quality. Moreover, these methods suffer from limited data diversity and significant gaps between synthetic data and real-world environments. To address these challenges, we propose OS-Genesis, a novel GUI data synthesis pipeline that reverses the conventional trajectory collection process. Instead of relying on pre-defined tasks, OS-Genesis enables agents first to perceive environments and perform step-wise interactions, then retrospectively derive high-quality tasks to enable trajectory-level exploration. A trajectory reward model is then employed to ensure the quality of the generated trajectories. We demonstrate that training GUI agents with OS-Genesis significantly improves their performance on highly challenging online benchmarks. In-depth analysis further validates OS-Genesis's efficiency and its superior data quality and diversity compared to existing synthesis methods. Our codes, data, and checkpoints are available at https://qiushisun.github.io/OS-Genesis-Home/.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.19723",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Linearithmic Clean-up for Vector-Symbolic Key-Value Memory with Kroneker Rotation Products",
    "description": "arXiv:2506.15793v1 Announce Type: cross Abstract: A computational bottleneck in current Vector-Symbolic Architectures (VSAs) is the ``clean-up'' step, which decodes the noisy vectors retrieved from the architecture. Clean-up typically compares noisy vectors against a ``codebook'' of prototype vectors, incurring computational complexity that is quadratic or similar. We present a new codebook representation that supports efficient clean-up, based on Kroneker products of rotation-like matrices. The resulting clean-up time complexity is linearithmic, i.e. $mathcal{O}(N,text{log},N)$, where $N$ is the vector dimension and also the number of vectors in the codebook. Clean-up space complexity is $mathcal{O}(N)$. Furthermore, the codebook is not stored explicitly in computer memory: It can be represented in $mathcal{O}(text{log},N)$ space, and individual vectors in the codebook can be materialized in $mathcal{O}(N)$ time and space. At the same time, asymptotic memory capacity remains comparable to standard approaches. Computer experiments confirm these results, demonstrating several orders of magnitude more scalability than baseline VSA techniques.",
    "summary": "arXiv:2506.15793v1 Announce Type: cross Abstract: A computational bottleneck in current Vector-Symbolic Architectures (VSAs) is the ``clean-up'' step, which decodes the noisy vectors retrieved from the architecture. Clean-up typically compares noisy vectors against a ``codebook'' of prototype vectors, incurring computational complexity that is quadratic or similar. We present a new codebook representation that supports efficient clean-up, based on Kroneker products of rotation-like matrices. The resulting clean-up time complexity is linearithmic, i.e. $mathcal{O}(N,text{log},N)$, where $N$ is the vector dimension and also the number of vectors in the codebook. Clean-up space complexity is $mathcal{O}(N)$. Furthermore, the codebook is not stored explicitly in computer memory: It can be represented in $mathcal{O}(text{log},N)$ space, and individual vectors in the codebook can be materialized in $mathcal{O}(N)$ time and space. At the same time, asymptotic memory capacity remains comparable to standard approaches. Computer experiments confirm these results, demonstrating several orders of magnitude more scalability than baseline VSA techniques.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15793",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Image Classification with AutoTrain",
    "description": "",
    "summary": "Image Classification with AutoTrain So you‚Äôve heard all about the cool things that are happening in ...",
    "pubDate": "Wed, 28 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autotrain-image-classification",
    "thumbnail": "https://huggingface.co/blog/assets/105_autotrain-image-classification/thumbnail.png"
  },
  {
    "title": "OpenAI and Hearst Content Partnership",
    "description": "Hearst‚Äôs iconic brands bring curated lifestyle and local news content to OpenAI‚Äôs products.",
    "summary": "Hearst‚Äôs iconic brands bring curated lifestyle and local news content to OpenAI‚Äôs products.",
    "pubDate": "Tue, 08 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hearst",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Tool Use, Unified",
    "description": "",
    "summary": "Tool Use, Unified There is now a unified tool use API across several popular families of models. Thi...",
    "pubDate": "Mon, 12 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unified-tool-use",
    "thumbnail": "https://huggingface.co/blog/assets/unified-tool-use/thumbnail.png"
  },
  {
    "title": "MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents",
    "description": "arXiv:2506.15841v1 Announce Type: cross Abstract: Modern language agents must operate over long-horizon, multi-turn interactions, where they retrieve external information, adapt to observations, and answer interdependent queries. Yet, most LLM systems rely on full-context prompting, appending all past turns regardless of their relevance. This leads to unbounded memory growth, increased computational costs, and degraded reasoning performance on out-of-distribution input lengths. We introduce MEM1, an end-to-end reinforcement learning framework that enables agents to operate with constant memory across long multi-turn tasks. At each turn, MEM1 updates a compact shared internal state that jointly supports memory consolidation and reasoning. This state integrates prior memory with new observations from the environment while strategically discarding irrelevant or redundant information. To support training in more realistic and compositional settings, we propose a simple yet effective and scalable approach to constructing multi-turn environments by composing existing datasets into arbitrarily complex task sequences. Experiments across three domains, including internal retrieval QA, open-domain web QA, and multi-turn web shopping, show that MEM1-7B improves performance by 3.5x while reducing memory usage by 3.7x compared to Qwen2.5-14B-Instruct on a 16-objective multi-hop QA task, and generalizes beyond the training horizon. Our results demonstrate the promise of reasoning-driven memory consolidation as a scalable alternative to existing solutions for training long-horizon interactive agents, where both efficiency and performance are optimized.",
    "summary": "arXiv:2506.15841v1 Announce Type: cross Abstract: Modern language agents must operate over long-horizon, multi-turn interactions, where they retrieve external information, adapt to observations, and answer interdependent queries. Yet, most LLM systems rely on full-context prompting, appending all past turns regardless of their relevance. This leads to unbounded memory growth, increased computational costs, and degraded reasoning performance on out-of-distribution input lengths. We introduce MEM1, an end-to-end reinforcement learning framework that enables agents to operate with constant memory across long multi-turn tasks. At each turn, MEM1 updates a compact shared internal state that jointly supports memory consolidation and reasoning. This state integrates prior memory with new observations from the environment while strategically discarding irrelevant or redundant information. To support training in more realistic and compositional settings, we propose a simple yet effective and scalable approach to constructing multi-turn environments by composing existing datasets into arbitrarily complex task sequences. Experiments across three domains, including internal retrieval QA, open-domain web QA, and multi-turn web shopping, show that MEM1-7B improves performance by 3.5x while reducing memory usage by 3.7x compared to Qwen2.5-14B-Instruct on a 16-objective multi-hop QA task, and generalizes beyond the training horizon. Our results demonstrate the promise of reasoning-driven memory consolidation as a scalable alternative to existing solutions for training long-horizon interactive agents, where both efficiency and performance are optimized.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15841",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From Ground to Air: Noise Robustness in Vision Transformers and CNNs for Event-Based Vehicle Classification with Potential UAV Applications",
    "description": "arXiv:2506.22360v1 Announce Type: cross Abstract: This study investigates the performance of the two most relevant computer vision deep learning architectures, Convolutional Neural Network and Vision Transformer, for event-based cameras. These cameras capture scene changes, unlike traditional frame-based cameras with capture static images, and are particularly suited for dynamic environments such as UAVs and autonomous vehicles. The deep learning models studied in this work are ResNet34 and ViT B16, fine-tuned on the GEN1 event-based dataset. The research evaluates and compares these models under both standard conditions and in the presence of simulated noise. Initial evaluations on the clean GEN1 dataset reveal that ResNet34 and ViT B16 achieve accuracies of 88% and 86%, respectively, with ResNet34 showing a slight advantage in classification accuracy. However, the ViT B16 model demonstrates notable robustness, particularly given its pre-training on a smaller dataset. Although this study focuses on ground-based vehicle classification, the methodologies and findings hold significant promise for adaptation to UAV contexts, including aerial object classification and event-based vision systems for aviation-related tasks.",
    "summary": "arXiv:2506.22360v1 Announce Type: cross Abstract: This study investigates the performance of the two most relevant computer vision deep learning architectures, Convolutional Neural Network and Vision Transformer, for event-based cameras. These cameras capture scene changes, unlike traditional frame-based cameras with capture static images, and are particularly suited for dynamic environments such as UAVs and autonomous vehicles. The deep learning models studied in this work are ResNet34 and ViT B16, fine-tuned on the GEN1 event-based dataset. The research evaluates and compares these models under both standard conditions and in the presence of simulated noise. Initial evaluations on the clean GEN1 dataset reveal that ResNet34 and ViT B16 achieve accuracies of 88% and 86%, respectively, with ResNet34 showing a slight advantage in classification accuracy. However, the ViT B16 model demonstrates notable robustness, particularly given its pre-training on a smaller dataset. Although this study focuses on ground-based vehicle classification, the methodologies and findings hold significant promise for adaptation to UAV contexts, including aerial object classification and event-based vision systems for aviation-related tasks.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22360",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Serving Large Language Models on Huawei CloudMatrix384",
    "description": "arXiv:2506.12708v3 Announce Type: replace-cross Abstract: The rapid evolution of large language models (LLMs), driven by growing parameter scales, adoption of mixture-of-experts (MoE) architectures, and expanding context lengths, imposes unprecedented demands on AI infrastructure. Traditional AI clusters face limitations in compute intensity, memory bandwidth, inter-chip communication, and latency, compounded by variable workloads and strict service-level objectives. Addressing these issues requires fundamentally redesigned hardware-software integration. This paper introduces Huawei CloudMatrix, a next-generation AI datacenter architecture, realized in the production-grade CloudMatrix384 supernode. It integrates 384 Ascend 910 NPUs and 192 Kunpeng CPUs interconnected via an ultra-high-bandwidth Unified Bus (UB) network, enabling direct all-to-all communication and dynamic pooling of resources. These features optimize performance for communication-intensive operations, such as large-scale MoE expert parallelism and distributed key-value cache access. To fully leverage CloudMatrix384, we propose CloudMatrix-Infer, an advanced LLM serving solution incorporating three core innovations: a peer-to-peer serving architecture that independently scales prefill, decode, and caching; a large-scale expert parallelism strategy supporting EP320 via efficient UB-based token dispatch; and hardware-aware optimizations including specialized operators, microbatch-based pipelining, and INT8 quantization. Evaluation with the DeepSeek-R1 model shows CloudMatrix-Infer achieves state-of-the-art efficiency: prefill throughput of 6,688 tokens/s per NPU and decode throughput of 1,943 tokens/s per NPU (<50 ms TPOT). It effectively balances throughput and latency, sustaining 538 tokens/s per NPU even under stringent 15 ms latency constraints, while INT8 quantization maintains model accuracy across benchmarks.",
    "summary": "arXiv:2506.12708v3 Announce Type: replace-cross Abstract: The rapid evolution of large language models (LLMs), driven by growing parameter scales, adoption of mixture-of-experts (MoE) architectures, and expanding context lengths, imposes unprecedented demands on AI infrastructure. Traditional AI clusters face limitations in compute intensity, memory bandwidth, inter-chip communication, and latency, compounded by variable workloads and strict service-level objectives. Addressing these issues requires fundamentally redesigned hardware-software integration. This paper introduces Huawei CloudMatrix, a next-generation AI datacenter architecture, realized in the production-grade CloudMatrix384 supernode. It integrates 384 Ascend 910 NPUs and 192 Kunpeng CPUs interconnected via an ultra-high-bandwidth Unified Bus (UB) network, enabling direct all-to-all communication and dynamic pooling of resources. These features optimize performance for communication-intensive operations, such as large-scale MoE expert parallelism and distributed key-value cache access. To fully leverage CloudMatrix384, we propose CloudMatrix-Infer, an advanced LLM serving solution incorporating three core innovations: a peer-to-peer serving architecture that independently scales prefill, decode, and caching; a large-scale expert parallelism strategy supporting EP320 via efficient UB-based token dispatch; and hardware-aware optimizations including specialized operators, microbatch-based pipelining, and INT8 quantization. Evaluation with the DeepSeek-R1 model shows CloudMatrix-Infer achieves state-of-the-art efficiency: prefill throughput of 6,688 tokens/s per NPU and decode throughput of 1,943 tokens/s per NPU (<50 ms TPOT). It effectively balances throughput and latency, sustaining 538 tokens/s per NPU even under stringent 15 ms latency constraints, while INT8 quantization maintains model accuracy across benchmarks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12708",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Benchmarking safe exploration in deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 21 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/benchmarking-safe-exploration-in-deep-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From Concepts to Components: Concept-Agnostic Attention Module Discovery in Transformers",
    "description": "arXiv:2506.17052v1 Announce Type: cross Abstract: Transformers have achieved state-of-the-art performance across language and vision tasks. This success drives the imperative to interpret their internal mechanisms with the dual goals of enhancing performance and improving behavioral control. Attribution methods help advance interpretability by assigning model outputs associated with a target concept to specific model components. Current attribution research primarily studies multi-layer perceptron neurons and addresses relatively simple concepts such as factual associations (e.g., Paris is located in France). This focus tends to overlook the impact of the attention mechanism and lacks a unified approach for analyzing more complex concepts. To fill these gaps, we introduce Scalable Attention Module Discovery (SAMD), a concept-agnostic method for mapping arbitrary, complex concepts to specific attention heads of general transformer models. We accomplish this by representing each concept as a vector, calculating its cosine similarity with each attention head, and selecting the TopK-scoring heads to construct the concept-associated attention module. We then propose Scalar Attention Module Intervention (SAMI), a simple strategy to diminish or amplify the effects of a concept by adjusting the attention module using only a single scalar parameter. Empirically, we demonstrate SAMD on concepts of varying complexity, and visualize the locations of their corresponding modules. Our results demonstrate that module locations remain stable before and after LLM post-training, and confirm prior work on the mechanics of LLM multilingualism. Through SAMI, we facilitate jailbreaking on HarmBench (+72.7%) by diminishing 'safety' and improve performance on the GSM8K benchmark (+1.6%) by amplifying 'reasoning'. Lastly, we highlight the domain-agnostic nature of our approach by suppressing the image classification accuracy of vision transformers on ImageNet.",
    "summary": "arXiv:2506.17052v1 Announce Type: cross Abstract: Transformers have achieved state-of-the-art performance across language and vision tasks. This success drives the imperative to interpret their internal mechanisms with the dual goals of enhancing performance and improving behavioral control. Attribution methods help advance interpretability by assigning model outputs associated with a target concept to specific model components. Current attribution research primarily studies multi-layer perceptron neurons and addresses relatively simple concepts such as factual associations (e.g., Paris is located in France). This focus tends to overlook the impact of the attention mechanism and lacks a unified approach for analyzing more complex concepts. To fill these gaps, we introduce Scalable Attention Module Discovery (SAMD), a concept-agnostic method for mapping arbitrary, complex concepts to specific attention heads of general transformer models. We accomplish this by representing each concept as a vector, calculating its cosine similarity with each attention head, and selecting the TopK-scoring heads to construct the concept-associated attention module. We then propose Scalar Attention Module Intervention (SAMI), a simple strategy to diminish or amplify the effects of a concept by adjusting the attention module using only a single scalar parameter. Empirically, we demonstrate SAMD on concepts of varying complexity, and visualize the locations of their corresponding modules. Our results demonstrate that module locations remain stable before and after LLM post-training, and confirm prior work on the mechanics of LLM multilingualism. Through SAMI, we facilitate jailbreaking on HarmBench (+72.7%) by diminishing 'safety' and improve performance on the GSM8K benchmark (+1.6%) by amplifying 'reasoning'. Lastly, we highlight the domain-agnostic nature of our approach by suppressing the image classification accuracy of vision transformers on ImageNet.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17052",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI partners with Cond√© Nast",
    "description": "Cond√© Nast",
    "summary": "Cond√© Nast",
    "pubDate": "Tue, 20 Aug 2024 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/conde-nast",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing OpenAI‚Äôs Bug Bounty Program",
    "description": "This initiative is essential to our commitment to develop safe and advanced AI. As we create technology and services that are secure, reliable, and trustworthy, we need your help.",
    "summary": "This initiative is essential to our commitment to develop safe and advanced AI. As we create technology and services that are secure, reliable, and trustworthy, we need your help.",
    "pubDate": "Tue, 11 Apr 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bug-bounty-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Distill",
    "description": "We‚Äôre excited to support today‚Äôs launch of Distill, a new kind of journal aimed at excellent communication of machine learning results (novel or existing).",
    "summary": "We‚Äôre excited to support today‚Äôs launch of Distill, a new kind of journal aimed at excellent communication of machine learning results (novel or existing).",
    "pubDate": "Mon, 20 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/distill",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hosting your Models and Datasets on Hugging Face Spaces using Streamlit",
    "description": "",
    "summary": "Hosting your Models and Datasets on Hugging Face Spaces using Streamlit Showcase your Datasets and M...",
    "pubDate": "Tue, 05 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/streamlit-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/29_streamlit-spaces/thumbnail.png"
  },
  {
    "title": "Refined Causal Graph Structure Learning via Curvature for Brain Disease Classification",
    "description": "arXiv:2506.15708v1 Announce Type: cross Abstract: Graph neural networks (GNNs) have been developed to model the relationship between regions of interest (ROIs) in brains and have shown significant improvement in detecting brain diseases. However, most of these frameworks do not consider the intrinsic relationship of causality factor between brain ROIs, which is arguably more essential to observe cause and effect interaction between signals rather than typical correlation values. We propose a novel framework called CGB (Causal Graphs for Brains) for brain disease classification/detection, which models refined brain networks based on the causal discovery method, transfer entropy, and geometric curvature strategy. CGB unveils causal relationships between ROIs that bring vital information to enhance brain disease classification performance. Furthermore, CGB also performs a graph rewiring through a geometric curvature strategy to refine the generated causal graph to become more expressive and reduce potential information bottlenecks when GNNs model it. Our extensive experiments show that CGB outperforms state-of-the-art methods in classification tasks on brain disease datasets, as measured by average F1 scores.",
    "summary": "arXiv:2506.15708v1 Announce Type: cross Abstract: Graph neural networks (GNNs) have been developed to model the relationship between regions of interest (ROIs) in brains and have shown significant improvement in detecting brain diseases. However, most of these frameworks do not consider the intrinsic relationship of causality factor between brain ROIs, which is arguably more essential to observe cause and effect interaction between signals rather than typical correlation values. We propose a novel framework called CGB (Causal Graphs for Brains) for brain disease classification/detection, which models refined brain networks based on the causal discovery method, transfer entropy, and geometric curvature strategy. CGB unveils causal relationships between ROIs that bring vital information to enhance brain disease classification performance. Furthermore, CGB also performs a graph rewiring through a geometric curvature strategy to refine the generated causal graph to become more expressive and reduce potential information bottlenecks when GNNs model it. Our extensive experiments show that CGB outperforms state-of-the-art methods in classification tasks on brain disease datasets, as measured by average F1 scores.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15708",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI safety practices",
    "description": "Artificial general intelligence has the potential to benefit nearly every aspect of our lives‚Äîso it must be developed and deployed responsibly.",
    "summary": "Artificial general intelligence has the potential to benefit nearly every aspect of our lives‚Äîso it must be developed and deployed responsibly.",
    "pubDate": "Tue, 21 May 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-safety-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Strategic Content Partnership with TIME",
    "description": "We‚Äôre partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories on Time.com",
    "summary": "We‚Äôre partnering with TIME and its 101 years of archival content to enhance responses and provide links to stories on Time.com",
    "pubDate": "Thu, 27 Jun 2024 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/strategic-content-partnership-with-time",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Frontier Model Forum updates",
    "description": "Together with Anthropic, Google, and Microsoft, we‚Äôre announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",
    "summary": "Together with Anthropic, Google, and Microsoft, we‚Äôre announcing the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.",
    "pubDate": "Wed, 25 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-model-forum-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deep Q-Learning with Atari",
    "description": "",
    "summary": "Deep Q-Learning with Space Invaders Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 3, of...",
    "pubDate": "Tue, 07 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-dqn",
    "thumbnail": "https://huggingface.co/blog/assets/78_deep_rl_dqn/thumbnail.gif"
  },
  {
    "title": "Faster physics in Python",
    "description": "We‚Äôre open-sourcing a high-performance Python library for robotic simulation using the MuJoCo engine, developed over our past year of robotics research.",
    "summary": "We‚Äôre open-sourcing a high-performance Python library for robotic simulation using the MuJoCo engine, developed over our past year of robotics research.",
    "pubDate": "Wed, 28 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/faster-physics-in-python",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From Reproduction to Replication: Evaluating Research Agents with Progressive Code Masking",
    "description": "arXiv:2506.19724v1 Announce Type: new Abstract: Recent progress in autonomous code generation has fueled excitement around AI agents capable of accelerating scientific discovery by running experiments. However, there is currently no benchmark that evaluates whether such agents can implement scientific ideas when given varied amounts of code as a starting point, interpolating between reproduction (running code) and from-scratch replication (fully re-implementing and running code). We introduce AutoExperiment, a benchmark that evaluates AI agents' ability to implement and run machine learning experiments based on natural language descriptions in research papers. In each task, agents are given a research paper, a codebase with key functions masked out, and a command to run the experiment. The goal is to generate the missing code, execute the experiment in a sandboxed environment, and reproduce the results. AutoExperiment scales in difficulty by varying the number of missing functions $n$, ranging from partial reproduction to full replication. We evaluate state-of-the-art agents and find that performance degrades rapidly as $n$ increases. Agents that can dynamically interact with the environment (e.g. to debug their code) can outperform agents in fixed 'agentless' harnesses, and there exists a significant gap between single-shot and multi-trial success rates (Pass@1 vs. Pass@5), motivating verifier approaches to our benchmark. Our findings highlight critical challenges in long-horizon code generation, context retrieval, and autonomous experiment execution, establishing AutoExperiment as a new benchmark for evaluating progress in AI-driven scientific experimentation. Our data and code are open-sourced at https://github.com/j1mk1m/AutoExperiment .",
    "summary": "arXiv:2506.19724v1 Announce Type: new Abstract: Recent progress in autonomous code generation has fueled excitement around AI agents capable of accelerating scientific discovery by running experiments. However, there is currently no benchmark that evaluates whether such agents can implement scientific ideas when given varied amounts of code as a starting point, interpolating between reproduction (running code) and from-scratch replication (fully re-implementing and running code). We introduce AutoExperiment, a benchmark that evaluates AI agents' ability to implement and run machine learning experiments based on natural language descriptions in research papers. In each task, agents are given a research paper, a codebase with key functions masked out, and a command to run the experiment. The goal is to generate the missing code, execute the experiment in a sandboxed environment, and reproduce the results. AutoExperiment scales in difficulty by varying the number of missing functions $n$, ranging from partial reproduction to full replication. We evaluate state-of-the-art agents and find that performance degrades rapidly as $n$ increases. Agents that can dynamically interact with the environment (e.g. to debug their code) can outperform agents in fixed 'agentless' harnesses, and there exists a significant gap between single-shot and multi-trial success rates (Pass@1 vs. Pass@5), motivating verifier approaches to our benchmark. Our findings highlight critical challenges in long-horizon code generation, context retrieval, and autonomous experiment execution, establishing AutoExperiment as a new benchmark for evaluating progress in AI-driven scientific experimentation. Our data and code are open-sourced at https://github.com/j1mk1m/AutoExperiment .",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19724",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The State of Computer Vision at Hugging Face ü§ó",
    "description": "",
    "summary": "The State of Computer Vision at Hugging Face ü§ó At Hugging Face, we pride ourselves on democratizing ...",
    "pubDate": "Mon, 30 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cv_state",
    "thumbnail": "https://huggingface.co/blog/assets/cv_state/thumbnail.png"
  },
  {
    "title": "Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning",
    "description": "arXiv:2506.19592v1 Announce Type: new Abstract: We introduce TAPAS (Task-based Adaptation and Planning using AgentS), a multi-agent framework that integrates Large Language Models (LLMs) with symbolic planning to solve complex tasks without the need for manually defined environment models. TAPAS employs specialized LLM-based agents that collaboratively generate and adapt domain models, initial states, and goal specifications as needed using structured tool-calling mechanisms. Through this tool-based interaction, downstream agents can request modifications from upstream agents, enabling adaptation to novel attributes and constraints without manual domain redefinition. A ReAct (Reason+Act)-style execution agent, coupled with natural language plan translation, bridges the gap between dynamically generated plans and real-world robot capabilities. TAPAS demonstrates strong performance in benchmark planning domains and in the VirtualHome simulated real-world environment.",
    "summary": "arXiv:2506.19592v1 Announce Type: new Abstract: We introduce TAPAS (Task-based Adaptation and Planning using AgentS), a multi-agent framework that integrates Large Language Models (LLMs) with symbolic planning to solve complex tasks without the need for manually defined environment models. TAPAS employs specialized LLM-based agents that collaboratively generate and adapt domain models, initial states, and goal specifications as needed using structured tool-calling mechanisms. Through this tool-based interaction, downstream agents can request modifications from upstream agents, enabling adaptation to novel attributes and constraints without manual domain redefinition. A ReAct (Reason+Act)-style execution agent, coupled with natural language plan translation, bridges the gap between dynamically generated plans and real-world robot capabilities. TAPAS demonstrates strong performance in benchmark planning domains and in the VirtualHome simulated real-world environment.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19592",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A sounding board for strengthening the student experience",
    "description": "Composed of ‚Äúcomputing bilinguals,‚Äù the Undergraduate Advisory Group provides vital input to help advance the mission of the MIT Schwarzman College of Computing.",
    "summary": "Composed of ‚Äúcomputing bilinguals,‚Äù the Undergraduate Advisory Group provides vital input to help advance the mission of the MIT Schwarzman College of Computing.",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/sounding-board-for-strengthening-student-experience-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-SCC-UAG.jpg"
  },
  {
    "title": "What Do Latent Action Models Actually Learn?",
    "description": "arXiv:2506.15691v1 Announce Type: cross Abstract: Latent action models (LAMs) aim to learn action-relevant changes from unlabeled videos by compressing changes between frames as latents. However, differences between video frames can be caused by controllable changes as well as exogenous noise, leading to an important concern -- do latents capture the changes caused by actions or irrelevant noise? This paper studies this issue analytically, presenting a linear model that encapsulates the essence of LAM learning, while being tractable.This provides several insights, including connections between LAM and principal component analysis (PCA), desiderata of the data-generating policy, and justification of strategies to encourage learning controllable changes using data augmentation, data cleaning, and auxiliary action-prediction. We also provide illustrative results based on numerical simulation, shedding light on the specific structure of observations, actions, and noise in data that influence LAM learning.",
    "summary": "arXiv:2506.15691v1 Announce Type: cross Abstract: Latent action models (LAMs) aim to learn action-relevant changes from unlabeled videos by compressing changes between frames as latents. However, differences between video frames can be caused by controllable changes as well as exogenous noise, leading to an important concern -- do latents capture the changes caused by actions or irrelevant noise? This paper studies this issue analytically, presenting a linear model that encapsulates the essence of LAM learning, while being tractable.This provides several insights, including connections between LAM and principal component analysis (PCA), desiderata of the data-generating policy, and justification of strategies to encourage learning controllable changes using data augmentation, data cleaning, and auxiliary action-prediction. We also provide illustrative results based on numerical simulation, shedding light on the specific structure of observations, actions, and noise in data that influence LAM learning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15691",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Encrypted Large Language Models with FHE",
    "description": "",
    "summary": "Towards Encrypted Large Language Models with FHE Large Language Models (LLM) have recently been prov...",
    "pubDate": "Wed, 02 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/encrypted-llm",
    "thumbnail": "https://huggingface.co/blog/assets/encrypted-llm/thumbnail.png"
  },
  {
    "title": "More Thinking, Less Seeing? Assessing Amplified Hallucination in Multimodal Reasoning Models",
    "description": "arXiv:2505.21523v3 Announce Type: replace-cross Abstract: Test-time compute has empowered multimodal large language models to generate extended reasoning chains, yielding strong performance on tasks such as multimodal math reasoning. However, this improved reasoning ability often comes with increased hallucination: as generations become longer, models tend to drift away from image-grounded content and rely more heavily on language priors. Attention analysis shows that longer reasoning chains lead to reduced focus on visual inputs, which contributes to hallucination. To systematically study this phenomenon, we introduce RH-AUC, a metric that quantifies how a model's perception accuracy changes with reasoning length, allowing us to evaluate whether the model preserves visual grounding during reasoning. We also release RH-Bench, a diagnostic benchmark that spans a variety of multimodal tasks, designed to assess the trade-off between reasoning ability and hallucination. Our analysis reveals that (i) larger models typically achieve a better balance between reasoning and perception, and (ii) this balance is influenced more by the types and domains of training data than by its overall volume. These findings underscore the importance of evaluation frameworks that jointly consider both reasoning quality and perceptual fidelity.",
    "summary": "arXiv:2505.21523v3 Announce Type: replace-cross Abstract: Test-time compute has empowered multimodal large language models to generate extended reasoning chains, yielding strong performance on tasks such as multimodal math reasoning. However, this improved reasoning ability often comes with increased hallucination: as generations become longer, models tend to drift away from image-grounded content and rely more heavily on language priors. Attention analysis shows that longer reasoning chains lead to reduced focus on visual inputs, which contributes to hallucination. To systematically study this phenomenon, we introduce RH-AUC, a metric that quantifies how a model's perception accuracy changes with reasoning length, allowing us to evaluate whether the model preserves visual grounding during reasoning. We also release RH-Bench, a diagnostic benchmark that spans a variety of multimodal tasks, designed to assess the trade-off between reasoning ability and hallucination. Our analysis reveals that (i) larger models typically achieve a better balance between reasoning and perception, and (ii) this balance is influenced more by the types and domains of training data than by its overall volume. These findings underscore the importance of evaluation frameworks that jointly consider both reasoning quality and perceptual fidelity.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.21523",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "An update on our safety & security practices",
    "description": "An update on our safety & security practices",
    "summary": "An update on our safety & security practices",
    "pubDate": "Mon, 16 Sep 2024 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/update-on-safety-and-security-practices",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Transformers.js v3: WebGPU support, new models & tasks, and more‚Ä¶",
    "description": "",
    "summary": "Transformers.js v3: WebGPU Support, New Models & Tasks, and More‚Ä¶ After more than a year of developm...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformersjs-v3",
    "thumbnail": "https://huggingface.co/blog/assets/transformersjs-v3/thumbnail.png"
  },
  {
    "title": "Guided AbsoluteGrad: Magnitude of Gradients Matters to Explanation's Localization and Saliency",
    "description": "arXiv:2404.15564v2 Announce Type: replace-cross Abstract: This paper proposes a new gradient-based XAI method called Guided AbsoluteGrad for saliency map explanations. We utilize both positive and negative gradient magnitudes and employ gradient variance to distinguish the important areas for noise deduction. We also introduce a novel evaluation metric named ReCover And Predict (RCAP), which considers the Localization and Visual Noise Level objectives of the explanations. We propose two propositions for these two objectives and prove the necessity of evaluating them. We evaluate Guided AbsoluteGrad with seven gradient-based XAI methods using the RCAP metric and other SOTA metrics in three case studies: (1) ImageNet dataset with ResNet50 model; (2) International Skin Imaging Collaboration (ISIC) dataset with EfficientNet model; (3) the Places365 dataset with DenseNet161 model. Our method surpasses other gradient-based approaches, showcasing the quality of enhanced saliency map explanations through gradient magnitude.",
    "summary": "arXiv:2404.15564v2 Announce Type: replace-cross Abstract: This paper proposes a new gradient-based XAI method called Guided AbsoluteGrad for saliency map explanations. We utilize both positive and negative gradient magnitudes and employ gradient variance to distinguish the important areas for noise deduction. We also introduce a novel evaluation metric named ReCover And Predict (RCAP), which considers the Localization and Visual Noise Level objectives of the explanations. We propose two propositions for these two objectives and prove the necessity of evaluating them. We evaluate Guided AbsoluteGrad with seven gradient-based XAI methods using the RCAP metric and other SOTA metrics in three case studies: (1) ImageNet dataset with ResNet50 model; (2) International Skin Imaging Collaboration (ISIC) dataset with EfficientNet model; (3) the Places365 dataset with DenseNet161 model. Our method surpasses other gradient-based approaches, showcasing the quality of enhanced saliency map explanations through gradient magnitude.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2404.15564",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Unsupervised Dataset Dictionary Learning for domain shift robust clustering: application to sitting posture identification",
    "description": "arXiv:2506.19410v1 Announce Type: new Abstract: This paper introduces a novel approach, Unsupervised Dataset Dictionary Learning (U-DaDiL), for totally unsupervised robust clustering applied to sitting posture identification. Traditional methods often lack adaptability to diverse datasets and suffer from domain shift issues. U-DaDiL addresses these challenges by aligning distributions from different datasets using Wasserstein barycenter based representation. Experimental evaluations on the Office31 dataset demonstrate significant improvements in cluster alignment accuracy. This work also presents a promising step for addressing domain shift and robust clustering for unsupervised sitting posture identification",
    "summary": "arXiv:2506.19410v1 Announce Type: new Abstract: This paper introduces a novel approach, Unsupervised Dataset Dictionary Learning (U-DaDiL), for totally unsupervised robust clustering applied to sitting posture identification. Traditional methods often lack adaptability to diverse datasets and suffer from domain shift issues. U-DaDiL addresses these challenges by aligning distributions from different datasets using Wasserstein barycenter based representation. Experimental evaluations on the Office31 dataset demonstrate significant improvements in cluster alignment accuracy. This work also presents a promising step for addressing domain shift and robust clustering for unsupervised sitting posture identification",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19410",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing text and code embeddings",
    "description": "We are introducing embeddings, a new endpoint in the OpenAI API that makes it easy to perform natural language and code tasks like semantic search, clustering, topic modeling, and classification.",
    "summary": "We are introducing embeddings, a new endpoint in the OpenAI API that makes it easy to perform natural language and code tasks like semantic search, clustering, topic modeling, and classification.",
    "pubDate": "Tue, 25 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-text-and-code-embeddings",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models",
    "description": "",
    "summary": "Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models Transformer-based encod...",
    "pubDate": "Mon, 09 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/warm-starting-encoder-decoder",
    "thumbnail": "https://huggingface.co/blog/assets/08_warm_starting_encoder_decoder/thumbnail.png"
  },
  {
    "title": "Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer)",
    "description": "",
    "summary": "Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer) Introduction A few months...",
    "pubDate": "Fri, 16 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/autoformer",
    "thumbnail": "https://huggingface.co/blog/assets/150_autoformer/thumbnail.png"
  },
  {
    "title": "Language Bottleneck Models: A Framework for Interpretable Knowledge Tracing and Beyond",
    "description": "arXiv:2506.16982v1 Announce Type: cross Abstract: Accurately assessing student knowledge is critical for effective education, yet traditional Knowledge Tracing (KT) methods rely on opaque latent embeddings, limiting interpretability. Even LLM-based approaches generate direct predictions or summaries that may hallucinate without any accuracy guarantees. We recast KT as an inverse problem: learning the minimum natural-language summary that makes past answers explainable and future answers predictable. Our Language Bottleneck Model (LBM) consists of an encoder LLM that writes an interpretable knowledge summary and a frozen decoder LLM that must reconstruct and predict student responses using only that summary text. By constraining all predictive information to pass through a short natural-language bottleneck, LBMs ensure that the summary contains accurate information while remaining human-interpretable. Experiments on synthetic arithmetic benchmarks and the large-scale Eedi dataset show that LBMs rival the accuracy of state-of-the-art KT and direct LLM methods while requiring orders-of-magnitude fewer student trajectories. We demonstrate that training the encoder with group-relative policy optimization, using downstream decoding accuracy as a reward signal, effectively improves summary quality.",
    "summary": "arXiv:2506.16982v1 Announce Type: cross Abstract: Accurately assessing student knowledge is critical for effective education, yet traditional Knowledge Tracing (KT) methods rely on opaque latent embeddings, limiting interpretability. Even LLM-based approaches generate direct predictions or summaries that may hallucinate without any accuracy guarantees. We recast KT as an inverse problem: learning the minimum natural-language summary that makes past answers explainable and future answers predictable. Our Language Bottleneck Model (LBM) consists of an encoder LLM that writes an interpretable knowledge summary and a frozen decoder LLM that must reconstruct and predict student responses using only that summary text. By constraining all predictive information to pass through a short natural-language bottleneck, LBMs ensure that the summary contains accurate information while remaining human-interpretable. Experiments on synthetic arithmetic benchmarks and the large-scale Eedi dataset show that LBMs rival the accuracy of state-of-the-art KT and direct LLM methods while requiring orders-of-magnitude fewer student trajectories. We demonstrate that training the encoder with group-relative policy optimization, using downstream decoding accuracy as a reward signal, effectively improves summary quality.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16982",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Vision Transformer-Based Time-Series Image Reconstruction for Cloud-Filling Applications",
    "description": "arXiv:2506.19591v1 Announce Type: cross Abstract: Cloud cover in multispectral imagery (MSI) poses significant challenges for early season crop mapping, as it leads to missing or corrupted spectral information. Synthetic aperture radar (SAR) data, which is not affected by cloud interference, offers a complementary solution, but lack sufficient spectral detail for precise crop mapping. To address this, we propose a novel framework, Time-series MSI Image Reconstruction using Vision Transformer (ViT), to reconstruct MSI data in cloud-covered regions by leveraging the temporal coherence of MSI and the complementary information from SAR from the attention mechanism. Comprehensive experiments, using rigorous reconstruction evaluation metrics, demonstrate that Time-series ViT framework significantly outperforms baselines that use non-time-series MSI and SAR or time-series MSI without SAR, effectively enhancing MSI image reconstruction in cloud-covered regions.",
    "summary": "arXiv:2506.19591v1 Announce Type: cross Abstract: Cloud cover in multispectral imagery (MSI) poses significant challenges for early season crop mapping, as it leads to missing or corrupted spectral information. Synthetic aperture radar (SAR) data, which is not affected by cloud interference, offers a complementary solution, but lack sufficient spectral detail for precise crop mapping. To address this, we propose a novel framework, Time-series MSI Image Reconstruction using Vision Transformer (ViT), to reconstruct MSI data in cloud-covered regions by leveraging the temporal coherence of MSI and the complementary information from SAR from the attention mechanism. Comprehensive experiments, using rigorous reconstruction evaluation metrics, demonstrate that Time-series ViT framework significantly outperforms baselines that use non-time-series MSI and SAR or time-series MSI without SAR, effectively enhancing MSI image reconstruction in cloud-covered regions.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19591",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI„ÄÅAI„É¢„Éá„É´„Å´ÊΩú„ÇÄ‚ÄúÊÇ™„Ç¨„Ç≠„Éö„É´„ÇΩ„Éä‚Äù„ÅÆÊõ¥Áîü„Å´„Å§„ÅÑ„Å¶Ë™¨Êòé",
    "description": "OpenAI„ÅØ„ÄÅAI„É¢„Éá„É´„ÅåÊÑèÂõ≥„Åõ„Åö„ÄåÊÇ™„Ç¨„Ç≠„Éö„É´„ÇΩ„Éä„Äç„ÅÆ„Çà„ÅÜ„Å™Êúõ„Åæ„Åó„Åè„Å™„ÅÑÊåØ„ÇãËàû„ÅÑ„Çí„Åô„Çã„ÄåË™§„Ç¢„É©„Ç§„É≥„É°„É≥„Éà„Äç„Å´Èñ¢„Åô„ÇãË´ñÊñá„ÇíÂÖ¨Èñã„Åó„Åü„ÄÇ‰∏çÈÅ©Âàá„Å™Â≠¶Áøí„ÅåÁâπÂÆö„ÅÆ„Éö„É´„ÇΩ„Éä„ÇíÂ¢óÂπÖ„Åï„Åõ„Çã„Åì„Å®„ÅåÂéüÂõ†„Å†„Å®„ÅÑ„ÅÜ„ÄÇÂØæÁ≠ñ„Å®„Åó„Å¶È´òÂìÅË≥™„Å™„Éá„Éº„Çø„ÅÆ‰ΩøÁî®„ÅåÈáçË¶Å„Åß„ÄÅÁô∫ÁîüÂæå„ÇÇÂ∞ëÈáè„ÅÆËâØË≥™„Å™„Éá„Éº„Çø„ÅßÂÜçË™øÊï¥„Åô„Çå„Å∞‰øÆÂæ©ÂèØËÉΩ„Å®„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "OpenAI„ÅØ„ÄÅAI„É¢„Éá„É´„ÅåÊÑèÂõ≥„Åõ„Åö„ÄåÊÇ™„Ç¨„Ç≠„Éö„É´„ÇΩ„Éä„Äç„ÅÆ„Çà„ÅÜ„Å™Êúõ„Åæ„Åó„Åè„Å™„ÅÑÊåØ„ÇãËàû„ÅÑ„Çí„Åô„Çã„ÄåË™§„Ç¢„É©„Ç§„É≥„É°„É≥„Éà„Äç„Å´Èñ¢„Åô„ÇãË´ñÊñá„ÇíÂÖ¨Èñã„Åó„Åü„ÄÇ‰∏çÈÅ©Âàá„Å™Â≠¶Áøí„ÅåÁâπÂÆö„ÅÆ„Éö„É´„ÇΩ„Éä„ÇíÂ¢óÂπÖ„Åï„Åõ„Çã„Åì„Å®„ÅåÂéüÂõ†„Å†„Å®„ÅÑ„ÅÜ„ÄÇÂØæÁ≠ñ„Å®„Åó„Å¶È´òÂìÅË≥™„Å™„Éá„Éº„Çø„ÅÆ‰ΩøÁî®„ÅåÈáçË¶Å„Åß„ÄÅÁô∫ÁîüÂæå„ÇÇÂ∞ëÈáè„ÅÆËâØË≥™„Å™„Éá„Éº„Çø„ÅßÂÜçË™øÊï¥„Åô„Çå„Å∞‰øÆÂæ©ÂèØËÉΩ„Å®„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Fri, 20 Jun 2025 10:58:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/20/news062.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/20/cover_news062.jpg"
  },
  {
    "title": "Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs",
    "description": "arXiv:2506.22146v1 Announce Type: cross Abstract: Despite progress in Vision-Language Models (VLMs), their capacity for visual reasoning is often limited by the textit{binding problem}: the failure to reliably associate perceptual features with their correct visual referents. This limitation underlies persistent errors in tasks such as counting, visual search, scene description, and spatial relationship understanding. A key factor is that current VLMs process visual features largely in parallel, lacking mechanisms for spatially grounded, serial attention. This paper introduces a simple yet effective intervention: augmenting visual inputs with low-level spatial structures (e.g., horizontal lines) and pairing this with a textual prompt that encourages sequential, spatially-aware parsing. We empirically demonstrate substantial performance improvements across core visual reasoning tasks. Specifically, our method improves GPT-4o visual search accuracy by 25.00%, increases counting accuracy by 26.83%, reduces edit distance error in scene description by 0.32, and enhances performance on spatial relationship tasks by 9.50% on a a 2D synthetic dataset. Furthermore, we find that the visual modification is essential for these gains; purely textual strategies, including Chain-of-Thought prompting, are insufficient and can even degrade performance. Our method enhances binding only with a single-query inference, underscoring the importance of visual input design over purely linguistically-based approaches. These findings suggest that low-level visual structuring is a powerful and underexplored direction for improving compositional visual reasoning and could serve as a general strategy for enhancing VLM performance on spatially grounded tasks.",
    "summary": "arXiv:2506.22146v1 Announce Type: cross Abstract: Despite progress in Vision-Language Models (VLMs), their capacity for visual reasoning is often limited by the textit{binding problem}: the failure to reliably associate perceptual features with their correct visual referents. This limitation underlies persistent errors in tasks such as counting, visual search, scene description, and spatial relationship understanding. A key factor is that current VLMs process visual features largely in parallel, lacking mechanisms for spatially grounded, serial attention. This paper introduces a simple yet effective intervention: augmenting visual inputs with low-level spatial structures (e.g., horizontal lines) and pairing this with a textual prompt that encourages sequential, spatially-aware parsing. We empirically demonstrate substantial performance improvements across core visual reasoning tasks. Specifically, our method improves GPT-4o visual search accuracy by 25.00%, increases counting accuracy by 26.83%, reduces edit distance error in scene description by 0.32, and enhances performance on spatial relationship tasks by 9.50% on a a 2D synthetic dataset. Furthermore, we find that the visual modification is essential for these gains; purely textual strategies, including Chain-of-Thought prompting, are insufficient and can even degrade performance. Our method enhances binding only with a single-query inference, underscoring the importance of visual input design over purely linguistically-based approaches. These findings suggest that low-level visual structuring is a powerful and underexplored direction for improving compositional visual reasoning and could serve as a general strategy for enhancing VLM performance on spatially grounded tasks.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22146",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sparse-Reg: Improving Sample Complexity in Offline Reinforcement Learning using Sparsity",
    "description": "arXiv:2506.17155v2 Announce Type: replace-cross Abstract: In this paper, we investigate the use of small datasets in the context of offline reinforcement learning (RL). While many common offline RL benchmarks employ datasets with over a million data points, many offline RL applications rely on considerably smaller datasets. We show that offline RL algorithms can overfit on small datasets, resulting in poor performance. To address this challenge, we introduce 'Sparse-Reg': a regularization technique based on sparsity to mitigate overfitting in offline reinforcement learning, enabling effective learning in limited data settings and outperforming state-of-the-art baselines in continuous control.",
    "summary": "arXiv:2506.17155v2 Announce Type: replace-cross Abstract: In this paper, we investigate the use of small datasets in the context of offline reinforcement learning (RL). While many common offline RL benchmarks employ datasets with over a million data points, many offline RL applications rely on considerably smaller datasets. We show that offline RL algorithms can overfit on small datasets, resulting in poor performance. To address this challenge, we introduce 'Sparse-Reg': a regularization technique based on sparsity to mitigate overfitting in offline reinforcement learning, enabling effective learning in limited data settings and outperforming state-of-the-art baselines in continuous control.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17155",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Large language models for automated scholarly paper review: A survey",
    "description": "arXiv:2501.10326v2 Announce Type: replace Abstract: Large language models (LLMs) have significantly impacted human society, influencing various domains. Among them, academia is not simply a domain affected by LLMs, but it is also the pivotal force in the development of LLMs. In academic publication, this phenomenon is represented during the incorporation of LLMs into the peer review mechanism for reviewing manuscripts. LLMs hold transformative potential for the full-scale implementation of automated scholarly paper review (ASPR), but they also pose new issues and challenges that need to be addressed. In this survey paper, we aim to provide a holistic view of ASPR in the era of LLMs. We begin with a survey to find out which LLMs are used to conduct ASPR. Then, we review what ASPR-related technological bottlenecks have been solved with the incorporation of LLM technology. After that, we move on to explore new methods, new datasets, new source code, and new online systems that come with LLMs for ASPR. Furthermore, we summarize the performance and issues of LLMs in ASPR, and investigate the attitudes and reactions of publishers and academia to ASPR. Lastly, we discuss the challenges and future directions associated with the development of LLMs for ASPR. This survey serves as an inspirational reference for the researchers and can promote the progress of ASPR for its actual implementation.",
    "summary": "arXiv:2501.10326v2 Announce Type: replace Abstract: Large language models (LLMs) have significantly impacted human society, influencing various domains. Among them, academia is not simply a domain affected by LLMs, but it is also the pivotal force in the development of LLMs. In academic publication, this phenomenon is represented during the incorporation of LLMs into the peer review mechanism for reviewing manuscripts. LLMs hold transformative potential for the full-scale implementation of automated scholarly paper review (ASPR), but they also pose new issues and challenges that need to be addressed. In this survey paper, we aim to provide a holistic view of ASPR in the era of LLMs. We begin with a survey to find out which LLMs are used to conduct ASPR. Then, we review what ASPR-related technological bottlenecks have been solved with the incorporation of LLM technology. After that, we move on to explore new methods, new datasets, new source code, and new online systems that come with LLMs for ASPR. Furthermore, we summarize the performance and issues of LLMs in ASPR, and investigate the attitudes and reactions of publishers and academia to ASPR. Lastly, we discuss the challenges and future directions associated with the development of LLMs for ASPR. This survey serves as an inspirational reference for the researchers and can promote the progress of ASPR for its actual implementation.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.10326",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SetFitABSA: Few-Shot Aspect Based Sentiment Analysis using SetFit",
    "description": "",
    "summary": "SetFitABSA: Few-Shot Aspect Based Sentiment Analysis using SetFit SetFitABSA is an efficient techniq...",
    "pubDate": "Wed, 06 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit-absa",
    "thumbnail": "https://huggingface.co/blog/assets/setfit-absa/intel_hf_logo_2.png"
  },
  {
    "title": "3D Asset Generation: AI for Game Development #3",
    "description": "",
    "summary": "3D Asset Generation: AI for Game Development #3 Welcome to AI for Game Development! In this series, ...",
    "pubDate": "Fri, 20 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-3",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail3.png"
  },
  {
    "title": "A Hybrid DeBERTa and Gated Broad Learning System for Cyberbullying Detection in English Text",
    "description": "arXiv:2506.16052v1 Announce Type: cross Abstract: The proliferation of online communication platforms has created unprecedented opportunities for global connectivity while simultaneously enabling harmful behaviors such as cyberbullying, which affects approximately 54.4% of teenagers according to recent research. This paper presents a hybrid architecture that combines the contextual understanding capabilities of transformer-based models with the pattern recognition strengths of broad learning systems for effective cyberbullying detection. This approach integrates a modified DeBERTa model augmented with Squeeze-and-Excitation blocks and sentiment analysis capabilities with a Gated Broad Learning System (GBLS) classifier, creating a synergistic framework that outperforms existing approaches across multiple benchmark datasets. The proposed ModifiedDeBERTa + GBLS model achieved good performance on four English datasets: 79.3% accuracy on HateXplain, 95.41% accuracy on SOSNet, 91.37% accuracy on Mendeley-I, and 94.67% accuracy on Mendeley-II. Beyond performance gains, the framework incorporates comprehensive explainability mechanisms including token-level attribution analysis, LIME-based local interpretations, and confidence calibration, addressing critical transparency requirements in automated content moderation. Ablation studies confirm the meaningful contribution of each architectural component, while failure case analysis reveals specific challenges in detecting implicit bias and sarcastic content, providing valuable insights for future improvements in cyberbullying detection systems.",
    "summary": "arXiv:2506.16052v1 Announce Type: cross Abstract: The proliferation of online communication platforms has created unprecedented opportunities for global connectivity while simultaneously enabling harmful behaviors such as cyberbullying, which affects approximately 54.4% of teenagers according to recent research. This paper presents a hybrid architecture that combines the contextual understanding capabilities of transformer-based models with the pattern recognition strengths of broad learning systems for effective cyberbullying detection. This approach integrates a modified DeBERTa model augmented with Squeeze-and-Excitation blocks and sentiment analysis capabilities with a Gated Broad Learning System (GBLS) classifier, creating a synergistic framework that outperforms existing approaches across multiple benchmark datasets. The proposed ModifiedDeBERTa + GBLS model achieved good performance on four English datasets: 79.3% accuracy on HateXplain, 95.41% accuracy on SOSNet, 91.37% accuracy on Mendeley-I, and 94.67% accuracy on Mendeley-II. Beyond performance gains, the framework incorporates comprehensive explainability mechanisms including token-level attribution analysis, LIME-based local interpretations, and confidence calibration, addressing critical transparency requirements in automated content moderation. Ablation studies confirm the meaningful contribution of each architectural component, while failure case analysis reveals specific challenges in detecting implicit bias and sarcastic content, providing valuable insights for future improvements in cyberbullying detection systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16052",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Identifiability of Deep Polynomial Neural Networks",
    "description": "arXiv:2506.17093v1 Announce Type: cross Abstract: Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric structure. However, their identifiability -- a key property for ensuring interpretability -- remains poorly understood. In this work, we present a comprehensive analysis of the identifiability of deep PNNs, including architectures with and without bias terms. Our results reveal an intricate interplay between activation degrees and layer widths in achieving identifiability. As special cases, we show that architectures with non-increasing layer widths are generically identifiable under mild conditions, while encoder-decoder networks are identifiable when the decoder widths do not grow too rapidly. Our proofs are constructive and center on a connection between deep PNNs and low-rank tensor decompositions, and Kruskal-type uniqueness theorems. This yields both generic conditions determined by the architecture, and effective conditions that depend on the network's parameters. We also settle an open conjecture on the expected dimension of PNN's neurovarieties, and provide new bounds on the activation degrees required for it to reach its maximum.",
    "summary": "arXiv:2506.17093v1 Announce Type: cross Abstract: Polynomial Neural Networks (PNNs) possess a rich algebraic and geometric structure. However, their identifiability -- a key property for ensuring interpretability -- remains poorly understood. In this work, we present a comprehensive analysis of the identifiability of deep PNNs, including architectures with and without bias terms. Our results reveal an intricate interplay between activation degrees and layer widths in achieving identifiability. As special cases, we show that architectures with non-increasing layer widths are generically identifiable under mild conditions, while encoder-decoder networks are identifiable when the decoder widths do not grow too rapidly. Our proofs are constructive and center on a connection between deep PNNs and low-rank tensor decompositions, and Kruskal-type uniqueness theorems. This yields both generic conditions determined by the architecture, and effective conditions that depend on the network's parameters. We also settle an open conjecture on the expected dimension of PNN's neurovarieties, and provide new bounds on the activation degrees required for it to reach its maximum.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17093",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Chat Templates: An End to the Silent Performance Killer",
    "description": "",
    "summary": "Chat Templates A spectre is haunting chat models - the spectre of incorrect formatting! tl;dr Chat m...",
    "pubDate": "Tue, 03 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chat-templates",
    "thumbnail": "https://huggingface.co/blog/assets/chat-templates/thumbnail.png"
  },
  {
    "title": "Graph Diffusion that can Insert and Delete",
    "description": "arXiv:2506.15725v1 Announce Type: cross Abstract: Generative models of graphs based on discrete Denoising Diffusion Probabilistic Models (DDPMs) offer a principled approach to molecular generation by systematically removing structural noise through iterative atom and bond adjustments. However, existing formulations are fundamentally limited by their inability to adapt the graph size (that is, the number of atoms) during the diffusion process, severely restricting their effectiveness in conditional generation scenarios such as property-driven molecular design, where the targeted property often correlates with the molecular size. In this paper, we reformulate the noising and denoising processes to support monotonic insertion and deletion of nodes. The resulting model, which we call GrIDDD, dynamically grows or shrinks the chemical graph during generation. GrIDDD matches or exceeds the performance of existing graph diffusion models on molecular property targeting despite being trained on a more difficult problem. Furthermore, when applied to molecular optimization, GrIDDD exhibits competitive performance compared to specialized optimization models. This work paves the way for size-adaptive molecular generation with graph diffusion.",
    "summary": "arXiv:2506.15725v1 Announce Type: cross Abstract: Generative models of graphs based on discrete Denoising Diffusion Probabilistic Models (DDPMs) offer a principled approach to molecular generation by systematically removing structural noise through iterative atom and bond adjustments. However, existing formulations are fundamentally limited by their inability to adapt the graph size (that is, the number of atoms) during the diffusion process, severely restricting their effectiveness in conditional generation scenarios such as property-driven molecular design, where the targeted property often correlates with the molecular size. In this paper, we reformulate the noising and denoising processes to support monotonic insertion and deletion of nodes. The resulting model, which we call GrIDDD, dynamically grows or shrinks the chemical graph during generation. GrIDDD matches or exceeds the performance of existing graph diffusion models on molecular property targeting despite being trained on a more difficult problem. Furthermore, when applied to molecular optimization, GrIDDD exhibits competitive performance compared to specialized optimization models. This work paves the way for size-adaptive molecular generation with graph diffusion.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15725",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "HyperCLOVA X THINK Technical Report",
    "description": "arXiv:2506.22403v1 Announce Type: cross Abstract: We introduce HyperCLOVA X THINK, the first reasoning-focused large language model in the HyperCLOVA X family, pre-trained on roughly $6$ trillion high-quality Korean, and English tokens, augmented with targeted synthetic Korean data. It was implemented as a compute-memory-balanced Peri-LN Transformer scaled with $mu$P, pre-trained through a three-stage curriculum that expands the context window to $128$K tokens, and post-trained via supervised fine-tuning with Reinforcement Learning from Verifiable Rewards supports both detailed rationale and concise-answer modes. It delivers competitive performance against similarly sized models on Korea-focused benchmarks such as KMMLU, CSAT, KoBALT-700, HAERAE-1.0, and KoBigBench, while preserving robust bilingual consistency and translation quality. In addition, a vision-augmented variant matches or exceeds GPT-4.1 on the KCSAT STEM benchmark, all of which are achieved with substantially lower training compute than existing models of similar sizes. We also present a pruning and distillation technique that will soon be applied to HyperCLOVA X THINK for an open-source and business-friendly foundation model. Altogether, these capabilities position HyperCLOVA X THINK as a robust foundation for Korean AI innovation and a valuable resource for the global research community.",
    "summary": "arXiv:2506.22403v1 Announce Type: cross Abstract: We introduce HyperCLOVA X THINK, the first reasoning-focused large language model in the HyperCLOVA X family, pre-trained on roughly $6$ trillion high-quality Korean, and English tokens, augmented with targeted synthetic Korean data. It was implemented as a compute-memory-balanced Peri-LN Transformer scaled with $mu$P, pre-trained through a three-stage curriculum that expands the context window to $128$K tokens, and post-trained via supervised fine-tuning with Reinforcement Learning from Verifiable Rewards supports both detailed rationale and concise-answer modes. It delivers competitive performance against similarly sized models on Korea-focused benchmarks such as KMMLU, CSAT, KoBALT-700, HAERAE-1.0, and KoBigBench, while preserving robust bilingual consistency and translation quality. In addition, a vision-augmented variant matches or exceeds GPT-4.1 on the KCSAT STEM benchmark, all of which are achieved with substantially lower training compute than existing models of similar sizes. We also present a pruning and distillation technique that will soon be applied to HyperCLOVA X THINK for an open-source and business-friendly foundation model. Altogether, these capabilities position HyperCLOVA X THINK as a robust foundation for Korean AI innovation and a valuable resource for the global research community.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22403",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Solving (some) formal math olympiad problems",
    "description": "We built a neural theorem prover for¬†Lean¬†that learned to solve a variety of challenging high-school olympiad problems, including problems from the¬†AMC12¬†and¬†AIME¬†competitions, as well as two problems adapted from the¬†IMO.",
    "summary": "We built a neural theorem prover for¬†Lean¬†that learned to solve a variety of challenging high-school olympiad problems, including problems from the¬†AMC12¬†and¬†AIME¬†competitions, as well as two problems adapted from the¬†IMO.",
    "pubDate": "Wed, 02 Feb 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/formal-math",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Testing Causal Models with Hidden Variables in Polynomial Delay via Conditional Independencies",
    "description": "arXiv:2409.14593v2 Announce Type: replace-cross Abstract: Testing a hypothesized causal model against observational data is a key prerequisite for many causal inference tasks. A natural approach is to test whether the conditional independence relations (CIs) assumed in the model hold in the data. While a model can assume exponentially many CIs (with respect to the number of variables), testing all of them is both impractical and unnecessary. Causal graphs, which encode these CIs in polynomial space, give rise to local Markov properties that enable model testing with a significantly smaller subset of CIs. Model testing based on local properties requires an algorithm to list the relevant CIs. However, existing algorithms for realistic settings with hidden variables and non-parametric distributions can take exponential time to produce even a single CI constraint. In this paper, we introduce the c-component local Markov property (C-LMP) for causal graphs with hidden variables. Since C-LMP can still invoke an exponential number of CIs, we develop a polynomial delay algorithm to list these CIs in poly-time intervals. To our knowledge, this is the first algorithm that enables poly-delay testing of CIs in causal graphs with hidden variables against arbitrary data distributions. Experiments on real-world and synthetic data demonstrate the practicality of our algorithm.",
    "summary": "arXiv:2409.14593v2 Announce Type: replace-cross Abstract: Testing a hypothesized causal model against observational data is a key prerequisite for many causal inference tasks. A natural approach is to test whether the conditional independence relations (CIs) assumed in the model hold in the data. While a model can assume exponentially many CIs (with respect to the number of variables), testing all of them is both impractical and unnecessary. Causal graphs, which encode these CIs in polynomial space, give rise to local Markov properties that enable model testing with a significantly smaller subset of CIs. Model testing based on local properties requires an algorithm to list the relevant CIs. However, existing algorithms for realistic settings with hidden variables and non-parametric distributions can take exponential time to produce even a single CI constraint. In this paper, we introduce the c-component local Markov property (C-LMP) for causal graphs with hidden variables. Since C-LMP can still invoke an exponential number of CIs, we develop a polynomial delay algorithm to list these CIs in poly-time intervals. To our knowledge, this is the first algorithm that enables poly-delay testing of CIs in causal graphs with hidden variables against arbitrary data distributions. Experiments on real-world and synthetic data demonstrate the practicality of our algorithm.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.14593",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI and Guardian Media Group launch content partnership",
    "description": "OpenAI and Guardian Media Group announce content partnership to bring Guardian news content to ChatGPT.",
    "summary": "OpenAI and Guardian Media Group announce content partnership to bring Guardian news content to ChatGPT.",
    "pubDate": "Fri, 14 Feb 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-guardian-media-group-launch-content-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SAGE: Strategy-Adaptive Generation Engine for Query Rewriting",
    "description": "arXiv:2506.19783v1 Announce Type: new Abstract: Query rewriting is pivotal for enhancing dense retrieval, yet current methods demand large-scale supervised data or suffer from inefficient reinforcement learning (RL) exploration. In this work, we first establish that guiding Large Language Models (LLMs) with a concise set of expert-crafted strategies, such as semantic expansion and entity disambiguation, substantially improves retrieval effectiveness on challenging benchmarks, including HotpotQA, FEVER, NFCorpus, and SciFact. Building on this insight, we introduce the Strategy-Adaptive Generation Engine (SAGE), which operationalizes these strategies in an RL framework. SAGE introduces two novel reward shaping mechanisms-Strategic Credit Shaping (SCS) and Contrastive Reward Shaping (CRS)-to deliver more informative learning signals. This strategy-guided approach not only achieves new state-of-the-art NDCG@10 results, but also uncovers a compelling emergent behavior: the agent learns to select optimal strategies, reduces unnecessary exploration, and generates concise rewrites, lowering inference cost without sacrificing performance. Our findings demonstrate that strategy-guided RL, enhanced with nuanced reward shaping, offers a scalable, efficient, and more interpretable paradigm for developing the next generation of robust information retrieval systems.",
    "summary": "arXiv:2506.19783v1 Announce Type: new Abstract: Query rewriting is pivotal for enhancing dense retrieval, yet current methods demand large-scale supervised data or suffer from inefficient reinforcement learning (RL) exploration. In this work, we first establish that guiding Large Language Models (LLMs) with a concise set of expert-crafted strategies, such as semantic expansion and entity disambiguation, substantially improves retrieval effectiveness on challenging benchmarks, including HotpotQA, FEVER, NFCorpus, and SciFact. Building on this insight, we introduce the Strategy-Adaptive Generation Engine (SAGE), which operationalizes these strategies in an RL framework. SAGE introduces two novel reward shaping mechanisms-Strategic Credit Shaping (SCS) and Contrastive Reward Shaping (CRS)-to deliver more informative learning signals. This strategy-guided approach not only achieves new state-of-the-art NDCG@10 results, but also uncovers a compelling emergent behavior: the agent learns to select optimal strategies, reduces unnecessary exploration, and generates concise rewrites, lowering inference cost without sacrificing performance. Our findings demonstrate that strategy-guided RL, enhanced with nuanced reward shaping, offers a scalable, efficient, and more interpretable paradigm for developing the next generation of robust information retrieval systems.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19783",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning Montezuma‚Äôs Revenge from a single demonstration",
    "description": "We‚Äôve trained an agent to achieve a high score of 74,500 on¬†Montezuma‚Äôs Revenge¬†from a single human demonstration, better than any previously published result. Our algorithm is simple: the agent plays a sequence of games starting from carefully chosen states from the demonstration, and learns from them by optimizing the game score using¬†PPO, the same reinforcement learning algorithm that underpins¬†OpenAI¬†Five.",
    "summary": "We‚Äôve trained an agent to achieve a high score of 74,500 on¬†Montezuma‚Äôs Revenge¬†from a single human demonstration, better than any previously published result. Our algorithm is simple: the agent plays a sequence of games starting from carefully chosen states from the demonstration, and learns from them by optimizing the game score using¬†PPO, the same reinforcement learning algorithm that underpins¬†OpenAI¬†Five.",
    "pubDate": "Wed, 04 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-montezumas-revenge-from-a-single-demonstration",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-Tune a Semantic Segmentation Model with a Custom Dataset",
    "description": "",
    "summary": "Fine-Tune a Semantic Segmentation Model with a Custom Dataset This guide shows how you can fine-tune...",
    "pubDate": "Thu, 17 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-segformer",
    "thumbnail": "https://huggingface.co/blog/assets/56_fine_tune_segformer/thumb.png"
  },
  {
    "title": "Preference Optimization for Vision Language Models",
    "description": "",
    "summary": "Preference Optimization for Vision Language Models with TRL Training models to understand and predic...",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dpo_vlm",
    "thumbnail": "https://huggingface.co/blog/assets/dpo_vlm/thumbnail.png"
  },
  {
    "title": "Team QUST at SemEval-2025 Task 10: Evaluating Large Language Models in Multiclass Multi-label Classification of News Entity Framing",
    "description": "arXiv:2506.21564v1 Announce Type: cross Abstract: This paper describes the participation of QUST_NLP in the SemEval-2025 Task 7. We propose a three-stage retrieval framework specifically designed for fact-checked claim retrieval. Initially, we evaluate the performance of several retrieval models and select the one that yields the best results for candidate retrieval. Next, we employ multiple re-ranking models to enhance the candidate results, with each model selecting the Top-10 outcomes. In the final stage, we utilize weighted voting to determine the final retrieval outcomes. Our approach achieved 5th place in the monolingual track and 7th place in the crosslingual track. We release our system code at: https://github.com/warmth27/SemEval2025_Task7.",
    "summary": "arXiv:2506.21564v1 Announce Type: cross Abstract: This paper describes the participation of QUST_NLP in the SemEval-2025 Task 7. We propose a three-stage retrieval framework specifically designed for fact-checked claim retrieval. Initially, we evaluate the performance of several retrieval models and select the one that yields the best results for candidate retrieval. Next, we employ multiple re-ranking models to enhance the candidate results, with each model selecting the Top-10 outcomes. In the final stage, we utilize weighted voting to determine the final retrieval outcomes. Our approach achieved 5th place in the monolingual track and 7th place in the crosslingual track. We release our system code at: https://github.com/warmth27/SemEval2025_Task7.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21564",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerating LLM Inference with TGI on Intel Gaudi",
    "description": "",
    "summary": "üöÄ Accelerating LLM Inference with TGI on Intel Gaudi We're excited to announce the native integratio...",
    "pubDate": "Fri, 28 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-gaudi-backend-for-tgi",
    "thumbnail": "https://huggingface.co/blog/assets/intel-gaudi-backend-for-tgi/tgi-gaudi-thumbnail.png"
  },
  {
    "title": "StoryWriter: A Multi-Agent Framework for Long Story Generation",
    "description": "arXiv:2506.16445v1 Announce Type: cross Abstract: Long story generation remains a challenge for existing large language models (LLMs), primarily due to two main factors: (1) discourse coherence, which requires plot consistency, logical coherence, and completeness in the long-form generation, and (2) narrative complexity, which requires an interwoven and engaging narrative. To address these challenges, we propose StoryWriter, a multi-agent story generation framework, which consists of three main modules: (1) outline agent, which generates event-based outlines containing rich event plots, character, and event-event relationships. (2) planning agent, which further details events and plans which events should be written in each chapter to maintain an interwoven and engaging story. (3) writing agent, which dynamically compresses the story history based on the current event to generate and reflect new plots, ensuring the coherence of the generated story. We conduct both human and automated evaluation, and StoryWriter significantly outperforms existing story generation baselines in both story quality and length. Furthermore, we use StoryWriter to generate a dataset, which contains about $6,000$ high-quality long stories, with an average length of $8,000$ words. We train the model Llama3.1-8B and GLM4-9B using supervised fine-tuning on LongStory and develop StoryWriter_GLM and StoryWriter_GLM, which demonstrates advanced performance in long story generation.",
    "summary": "arXiv:2506.16445v1 Announce Type: cross Abstract: Long story generation remains a challenge for existing large language models (LLMs), primarily due to two main factors: (1) discourse coherence, which requires plot consistency, logical coherence, and completeness in the long-form generation, and (2) narrative complexity, which requires an interwoven and engaging narrative. To address these challenges, we propose StoryWriter, a multi-agent story generation framework, which consists of three main modules: (1) outline agent, which generates event-based outlines containing rich event plots, character, and event-event relationships. (2) planning agent, which further details events and plans which events should be written in each chapter to maintain an interwoven and engaging story. (3) writing agent, which dynamically compresses the story history based on the current event to generate and reflect new plots, ensuring the coherence of the generated story. We conduct both human and automated evaluation, and StoryWriter significantly outperforms existing story generation baselines in both story quality and length. Furthermore, we use StoryWriter to generate a dataset, which contains about $6,000$ high-quality long stories, with an average length of $8,000$ words. We train the model Llama3.1-8B and GLM4-9B using supervised fine-tuning on LongStory and develop StoryWriter_GLM and StoryWriter_GLM, which demonstrates advanced performance in long story generation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16445",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-Driven Tools in Modern Software Quality Assurance: An Assessment of Benefits, Challenges, and Future Directions",
    "description": "arXiv:2506.16586v1 Announce Type: cross Abstract: Traditional quality assurance (QA) methods face significant challenges in addressing the complexity, scale, and rapid iteration cycles of modern software systems and are strained by limited resources available, leading to substantial costs associated with poor quality. The object of this research is the Quality Assurance processes for modern distributed software applications. The subject of the research is the assessment of the benefits, challenges, and prospects of integrating modern AI-oriented tools into quality assurance processes. We performed comprehensive analysis of implications on both verification and validation processes covering exploratory test analyses, equivalence partitioning and boundary analyses, metamorphic testing, finding inconsistencies in acceptance criteria (AC), static analyses, test case generation, unit test generation, test suit optimization and assessment, end to end scenario execution. End to end regression of sample enterprise application utilizing AI-agents over generated test scenarios was implemented as a proof of concept highlighting practical use of the study. The results, with only 8.3% flaky executions of generated test cases, indicate significant potential for the proposed approaches. However, the study also identified substantial challenges for practical adoption concerning generation of semantically identical coverage, 'black box' nature and lack of explainability from state-of-the-art Large Language Models (LLMs), the tendency to correct mutated test cases to match expected results, underscoring the necessity for thorough verification of both generated artifacts and test execution results. The research demonstrates AI's transformative potential for QA but highlights the importance of a strategic approach to implementing these technologies, considering the identified limitations and the need for developing appropriate verification methodologies.",
    "summary": "arXiv:2506.16586v1 Announce Type: cross Abstract: Traditional quality assurance (QA) methods face significant challenges in addressing the complexity, scale, and rapid iteration cycles of modern software systems and are strained by limited resources available, leading to substantial costs associated with poor quality. The object of this research is the Quality Assurance processes for modern distributed software applications. The subject of the research is the assessment of the benefits, challenges, and prospects of integrating modern AI-oriented tools into quality assurance processes. We performed comprehensive analysis of implications on both verification and validation processes covering exploratory test analyses, equivalence partitioning and boundary analyses, metamorphic testing, finding inconsistencies in acceptance criteria (AC), static analyses, test case generation, unit test generation, test suit optimization and assessment, end to end scenario execution. End to end regression of sample enterprise application utilizing AI-agents over generated test scenarios was implemented as a proof of concept highlighting practical use of the study. The results, with only 8.3% flaky executions of generated test cases, indicate significant potential for the proposed approaches. However, the study also identified substantial challenges for practical adoption concerning generation of semantically identical coverage, 'black box' nature and lack of explainability from state-of-the-art Large Language Models (LLMs), the tendency to correct mutated test cases to match expected results, underscoring the necessity for thorough verification of both generated artifacts and test execution results. The research demonstrates AI's transformative potential for QA but highlights the importance of a strategic approach to implementing these technologies, considering the identified limitations and the need for developing appropriate verification methodologies.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16586",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improving GANs using optimal transport",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 15 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-gans-using-optimal-transport",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FACTS Grounding: A new benchmark for evaluating the factuality of large language models",
    "description": "Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations",
    "summary": "Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground their responses in provided source material and avoid hallucinations",
    "pubDate": "Tue, 17 Dec 2024 15:29:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/PNlhxhf4LKLRCezIt7Ap358F91-vbK5dLp56Ak1FejpCZh3YTp6jGqIDJm9c0iAtx8Y73MCTu279c1k2GZkM2qXXaqx315NSOaSiU0y0ATMK2c2Hyw=w1200-h630-n-nu"
  },
  {
    "title": "Cyclic Vision-Language Manipulator: Towards Reliable and Fine-Grained Image Interpretation for Automated Report Generation",
    "description": "arXiv:2411.05261v3 Announce Type: replace-cross Abstract: Despite significant advancements in automated report generation, the opaqueness of text interpretability continues to cast doubt on the reliability of the content produced. This paper introduces a novel approach to identify specific image features in X-ray images that influence the outputs of report generation models. Specifically, we propose Cyclic Vision-Language Manipulator CVLM, a module to generate a manipulated X-ray from an original X-ray and its report from a designated report generator. The essence of CVLM is that cycling manipulated X-rays to the report generator produces altered reports aligned with the alterations pre-injected into the reports for X-ray generation, achieving the term 'cyclic manipulation'. This process allows direct comparison between original and manipulated X-rays, clarifying the critical image features driving changes in reports and enabling model users to assess the reliability of the generated texts. Empirical evaluations demonstrate that CVLM can identify more precise and reliable features compared to existing explanation methods, significantly enhancing the transparency and applicability of AI-generated reports.",
    "summary": "arXiv:2411.05261v3 Announce Type: replace-cross Abstract: Despite significant advancements in automated report generation, the opaqueness of text interpretability continues to cast doubt on the reliability of the content produced. This paper introduces a novel approach to identify specific image features in X-ray images that influence the outputs of report generation models. Specifically, we propose Cyclic Vision-Language Manipulator CVLM, a module to generate a manipulated X-ray from an original X-ray and its report from a designated report generator. The essence of CVLM is that cycling manipulated X-rays to the report generator produces altered reports aligned with the alterations pre-injected into the reports for X-ray generation, achieving the term 'cyclic manipulation'. This process allows direct comparison between original and manipulated X-rays, clarifying the critical image features driving changes in reports and enabling model users to assess the reliability of the generated texts. Empirical evaluations demonstrate that CVLM can identify more precise and reliable features compared to existing explanation methods, significantly enhancing the transparency and applicability of AI-generated reports.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.05261",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-Assisted Transport of Radioactive Ion Beams",
    "description": "arXiv:2504.06469v3 Announce Type: replace-cross Abstract: Beams of radioactive heavy ions allow researchers to study rare and unstable atomic nuclei, shedding light into the internal structure of exotic nuclei and on how chemical elements are formed in stars. However, the extraction and transport of radioactive beams rely on time-consuming expert-driven tuning methods, where hundreds of parameters are manually optimized. Here, we introduce a system that employs Artificial Intelligence (AI), specifically utilizing Bayesian Optimization, to assist in the transport process of radioactive beams. We apply our methodology to real-life scenarios showing advantages when compared with standard tuning methods. This AI-assisted approach can be extended to other radioactive beam facilities around the world to improve operational efficiency and enhance scientific output.",
    "summary": "arXiv:2504.06469v3 Announce Type: replace-cross Abstract: Beams of radioactive heavy ions allow researchers to study rare and unstable atomic nuclei, shedding light into the internal structure of exotic nuclei and on how chemical elements are formed in stars. However, the extraction and transport of radioactive beams rely on time-consuming expert-driven tuning methods, where hundreds of parameters are manually optimized. Here, we introduce a system that employs Artificial Intelligence (AI), specifically utilizing Bayesian Optimization, to assist in the transport process of radioactive beams. We apply our methodology to real-life scenarios showing advantages when compared with standard tuning methods. This AI-assisted approach can be extended to other radioactive beam facilities around the world to improve operational efficiency and enhance scientific output.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.06469",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improving verifiability in AI development",
    "description": "We‚Äôve contributed to a multi-stakeholder report by¬†58 co-authors¬†at 30 organizations, including the¬†Centre for the Future of Intelligence,¬†Mila,¬†Schwartz Reisman Institute for Technology and Society,¬†Center for Advanced Study in the Behavioral Sciences, and¬†Center for Security and Emerging Technologies. This report describes 10 mechanisms to improve the verifiability of claims made about AI systems. Developers can use these tools to provide evidence that AI systems are safe, secure, fair, or privacy-preserving. Users, policymakers, and civil society can use these tools to evaluate AI development¬†processes.",
    "summary": "We‚Äôve contributed to a multi-stakeholder report by¬†58 co-authors¬†at 30 organizations, including the¬†Centre for the Future of Intelligence,¬†Mila,¬†Schwartz Reisman Institute for Technology and Society,¬†Center for Advanced Study in the Behavioral Sciences, and¬†Center for Security and Emerging Technologies. This report describes 10 mechanisms to improve the verifiability of claims made about AI systems. Developers can use these tools to provide evidence that AI systems are safe, secure, fair, or privacy-preserving. Users, policymakers, and civil society can use these tools to evaluate AI development¬†processes.",
    "pubDate": "Thu, 16 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-verifiability",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LoRA training scripts of the world, unite!",
    "description": "",
    "summary": "LoRA training scripts of the world, unite! A community derived guide to some of the SOTA practices f...",
    "pubDate": "Tue, 02 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_lora_advanced_script",
    "thumbnail": "https://huggingface.co/blog/assets/dreambooth_lora_sdxl/thumbnail.png"
  },
  {
    "title": "Teaching AI models what they don‚Äôt know",
    "description": "A team of MIT researchers founded Themis AI to quantify AI model uncertainty and address knowledge gaps.",
    "summary": "A team of MIT researchers founded Themis AI to quantify AI model uncertainty and address knowledge gaps.",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/themis-ai-teaches-ai-models-what-they-dont-know-0603",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-ThemisAI-01-Press.jpg"
  },
  {
    "title": "OpenAI o3-pro„Å®„ÅØÔºüÊúÄÊñ∞AI„É¢„Éá„É´„ÅÆÂÆüÂäõ„ÇíÂæπÂ∫ïËß£Ë™¨",
    "description": "<p>2025Âπ¥6Êúà„Å´„ÄÅOpenAI„ÅÆÊúÄÊñ∞„É¢„Éá„É´„Äåo3-pro„Äç„Åå„É™„É™„Éº„Çπ„Åï„Çå„Åæ„Åó„Åü„ÄÇ‰∏ª„Å´ÁßëÂ≠¶„ÇÑÊï∞Â≠¶„Å™„Å©Ê∑±„ÅÑÊé®Ë´ñ„ÇíÂæóÊÑè„Å®„Åó„Å¶„ÄÅËá™ÁÑ∂Ë®ÄË™ûÂá¶ÁêÜ„ÄÅÁîªÂÉèÁêÜËß£„ÄÅÈü≥Â£∞Ë™çË≠ò„Å®„ÅÑ„Å£„Åü„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´ÂØæÂøú„ÅåÁâπÂæ¥„Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ Êú¨Ë®ò‰∫ã„Åß„ÅØ„ÄÅo3- [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/o3-pro/'>OpenAI o3-pro„Å®„ÅØÔºüÊúÄÊñ∞AI„É¢„Éá„É´„ÅÆÂÆüÂäõ„ÇíÂæπÂ∫ïËß£Ë™¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>2025Âπ¥6Êúà„Å´„ÄÅOpenAI„ÅÆÊúÄÊñ∞„É¢„Éá„É´„Äåo3-pro„Äç„Åå„É™„É™„Éº„Çπ„Åï„Çå„Åæ„Åó„Åü„ÄÇ‰∏ª„Å´ÁßëÂ≠¶„ÇÑÊï∞Â≠¶„Å™„Å©Ê∑±„ÅÑÊé®Ë´ñ„ÇíÂæóÊÑè„Å®„Åó„Å¶„ÄÅËá™ÁÑ∂Ë®ÄË™ûÂá¶ÁêÜ„ÄÅÁîªÂÉèÁêÜËß£„ÄÅÈü≥Â£∞Ë™çË≠ò„Å®„ÅÑ„Å£„Åü„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´ÂØæÂøú„ÅåÁâπÂæ¥„Å®„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ Êú¨Ë®ò‰∫ã„Åß„ÅØ„ÄÅo3- [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/o3-pro/'>OpenAI o3-pro„Å®„ÅØÔºüÊúÄÊñ∞AI„É¢„Éá„É´„ÅÆÂÆüÂäõ„ÇíÂæπÂ∫ïËß£Ë™¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Thu, 12 Jun 2025 06:31:40 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/o3-pro/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/o3-pro.png"
  },
  {
    "title": "Mapping the misuse of generative AI",
    "description": "New research analyzes the misuse of multimodal generative AI today, in order to help build safer and more responsible technologies.",
    "summary": "New research analyzes the misuse of multimodal generative AI today, in order to help build safer and more responsible technologies.",
    "pubDate": "Fri, 02 Aug 2024 10:50:58 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/mapping-the-misuse-of-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/IzYg4pdM7_tKoEbQHE4-Em9cvFxbx2Aq4_YOQdLr6VK754c8-bJRW9LWMf1_nUraA5BfNcBjAjpIjcfF1M_qQviR8b7qyRnAiUzapq3LKVbTpoJ8Cw=w1200-h630-n-nu"
  },
  {
    "title": "Multi-Turn Code Generation Through Single-Step Rewards",
    "description": "arXiv:2502.20380v2 Announce Type: replace-cross Abstract: We address the problem of code generation from multi-turn execution feedback. Existing methods either generate code without feedback or use complex, hierarchical reinforcement learning to optimize multi-turn rewards. We propose a simple yet scalable approach, $mu$Code, that solves multi-turn code generation using only single-step rewards. Our key insight is that code generation is a one-step recoverable MDP, where the correct code can be recovered from any intermediate code state in a single turn. $mu$Code iteratively trains both a generator to provide code solutions conditioned on multi-turn execution feedback and a verifier to score the newly generated code. Experimental evaluations show that our approach achieves significant improvements over the state-of-the-art baselines. We provide analysis of the design choices of the reward models and policy, and show the efficacy of $mu$Code at utilizing the execution feedback. Our code is available at https://github.com/portal-cornell/muCode.",
    "summary": "arXiv:2502.20380v2 Announce Type: replace-cross Abstract: We address the problem of code generation from multi-turn execution feedback. Existing methods either generate code without feedback or use complex, hierarchical reinforcement learning to optimize multi-turn rewards. We propose a simple yet scalable approach, $mu$Code, that solves multi-turn code generation using only single-step rewards. Our key insight is that code generation is a one-step recoverable MDP, where the correct code can be recovered from any intermediate code state in a single turn. $mu$Code iteratively trains both a generator to provide code solutions conditioned on multi-turn execution feedback and a verifier to score the newly generated code. Experimental evaluations show that our approach achieves significant improvements over the state-of-the-art baselines. We provide analysis of the design choices of the reward models and policy, and show the efficacy of $mu$Code at utilizing the execution feedback. Our code is available at https://github.com/portal-cornell/muCode.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.20380",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SafeGenBench: A Benchmark Framework for Security Vulnerability Detection in LLM-Generated Code",
    "description": "arXiv:2506.05692v3 Announce Type: replace-cross Abstract: The code generation capabilities of large language models(LLMs) have emerged as a critical dimension in evaluating their overall performance. However, prior research has largely overlooked the security risks inherent in the generated code. In this work, we introduce SafeGenBench, a benchmark specifically designed to assess the security of LLM-generated code. The dataset encompasses a wide range of common software development scenarios and vulnerability types. Building upon this benchmark, we develop an automatic evaluation framework that leverages both static application security testing(SAST) and LLM-based judging to assess the presence of security vulnerabilities in model-generated code. Through the empirical evaluation of state-of-the-art LLMs on SafeGenBench, we reveal notable deficiencies in their ability to produce vulnerability-free code. Our findings highlight pressing challenges and offer actionable insights for future advancements in the secure code generation performance of LLMs. The data and code will be released soon.",
    "summary": "arXiv:2506.05692v3 Announce Type: replace-cross Abstract: The code generation capabilities of large language models(LLMs) have emerged as a critical dimension in evaluating their overall performance. However, prior research has largely overlooked the security risks inherent in the generated code. In this work, we introduce SafeGenBench, a benchmark specifically designed to assess the security of LLM-generated code. The dataset encompasses a wide range of common software development scenarios and vulnerability types. Building upon this benchmark, we develop an automatic evaluation framework that leverages both static application security testing(SAST) and LLM-based judging to assess the presence of security vulnerabilities in model-generated code. Through the empirical evaluation of state-of-the-art LLMs on SafeGenBench, we reveal notable deficiencies in their ability to produce vulnerability-free code. Our findings highlight pressing challenges and offer actionable insights for future advancements in the secure code generation performance of LLMs. The data and code will be released soon.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.05692",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How can we build human values into AI?",
    "description": "Drawing from philosophy to identify fair principles for ethical AI...",
    "summary": "Drawing from philosophy to identify fair principles for ethical AI...",
    "pubDate": "Mon, 24 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/how-can-we-build-human-values-into-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/jXiO9PpMnNRhxz3kyDP97SVi5c68dQie9V4AHbH_I0Py0EJoOl0fyPhoVljUGETrNmj3BhbAEahqmsq4r-33IgLgGhsuUhN2p384-d8B_vc4asHWB6Q=w1200-h630-n-nu"
  },
  {
    "title": "Extensions and limitations of the neural GPU",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 02 Nov 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/extensions-and-limitations-of-the-neural-gpu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Making thousands of open LLMs bloom in the Vertex AI Model Garden",
    "description": "",
    "summary": "Making thousands of open LLMs bloom in the Vertex AI Model Garden Today, we are thrilled to announce...",
    "pubDate": "Wed, 10 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/google-cloud-model-garden",
    "thumbnail": "https://huggingface.co/blog/assets/173_gcp-partnership/thumbnail.jpg"
  },
  {
    "title": "Gemma 3n fully available in the open-source ecosystem!",
    "description": "",
    "summary": "Gemma 3n fully available in the open-source ecosystem! Gemma 3n was announced as a preview during Go...",
    "pubDate": "Thu, 26 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma3n",
    "thumbnail": "https://huggingface.co/blog/assets/gemma3n/thumbnail.png"
  },
  {
    "title": "Emergence of grounded compositional language in multi-agent populations",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 15 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergence-of-grounded-compositional-language-in-multi-agent-populations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Wayfair is shaping the future of retail with AI",
    "description": "A conversation with Fiona Tan, Chief Technology Officer of Wayfair.",
    "summary": "A conversation with Fiona Tan, Chief Technology Officer of Wayfair.",
    "pubDate": "Thu, 13 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/wayfair-fiona-tan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Automatic dataset shift identification to support safe deployment of medical imaging AI",
    "description": "arXiv:2411.07940v3 Announce Type: replace Abstract: Shifts in data distribution can substantially harm the performance of clinical AI models and lead to misdiagnosis. Hence, various methods have been developed to detect the presence of such shifts at deployment time. However, the root causes of dataset shifts are diverse, and the choice of shift mitigation strategies is highly dependent on the precise type of shift encountered at test time. As such, detecting test-time dataset shift is not sufficient: precisely identifying which type of shift has occurred is critical. In this work, we propose the first unsupervised dataset shift identification framework for imaging datasets, effectively distinguishing between prevalence shift (caused by a change in the label distribution), covariate shift (caused by a change in input characteristics) and mixed shifts (simultaneous prevalence and covariate shifts). We discuss the importance of self-supervised encoders for detecting subtle covariate shifts and propose a novel shift detector leveraging both self-supervised encoders and task model outputs for improved shift detection. We show the effectiveness of the proposed shift identification framework across three different imaging modalities (chest radiography, digital mammography, and retinal fundus images) on five types of real-world dataset shifts using five large publicly available datasets.",
    "summary": "arXiv:2411.07940v3 Announce Type: replace Abstract: Shifts in data distribution can substantially harm the performance of clinical AI models and lead to misdiagnosis. Hence, various methods have been developed to detect the presence of such shifts at deployment time. However, the root causes of dataset shifts are diverse, and the choice of shift mitigation strategies is highly dependent on the precise type of shift encountered at test time. As such, detecting test-time dataset shift is not sufficient: precisely identifying which type of shift has occurred is critical. In this work, we propose the first unsupervised dataset shift identification framework for imaging datasets, effectively distinguishing between prevalence shift (caused by a change in the label distribution), covariate shift (caused by a change in input characteristics) and mixed shifts (simultaneous prevalence and covariate shifts). We discuss the importance of self-supervised encoders for detecting subtle covariate shifts and propose a novel shift detector leveraging both self-supervised encoders and task model outputs for improved shift detection. We show the effectiveness of the proposed shift identification framework across three different imaging modalities (chest radiography, digital mammography, and retinal fundus images) on five types of real-world dataset shifts using five large publicly available datasets.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.07940",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Ë®ÄË™ûÂá¶ÁêÜÂ≠¶‰ºöÁ¨¨31ÂõûÂπ¥Ê¨°Â§ß‰ºö(NLP2025) Áô∫Ë°®Â†±Âëä",
    "description": "<p>1. „ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÇAI„ÉÅ„Éº„É†„ÅÆÊ†óÂéü„Åß„Åô„ÄÇ2025Âπ¥3Êúà10Êó•(Êúà)„Äú3Êúà14Êó•(Èáë)„Å´Âá∫Â≥∂„É°„ÉÉ„ÇªÈï∑Â¥é„Å´„Å¶Ë°å„Çè„Çå„ÅüË®ÄË™ûÂá¶ÁêÜÂ≠¶‰ºöÁ¨¨31ÂõûÂπ¥Ê¨°Â§ß‰ºö„Åß„ÄÅÂºäÁ§æ„Åã„Çâ„Éù„Çπ„Çø„ÉºÁô∫Ë°®„Åß3‰ª∂„ÄÅÂè£È†≠Áô∫Ë°®„Åß1‰ª∂„ÅÆÁô∫Ë°®„ÇíË°å„ÅÑ„Åæ„Åó„Åü„ÄÇ Êò® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5586' rel='nofollow'>Ë®ÄË™ûÂá¶ÁêÜÂ≠¶‰ºöÁ¨¨31ÂõûÂπ¥Ê¨°Â§ß‰ºö(NLP2025) Áô∫Ë°®Â†±Âëä</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>1. „ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÇAI„ÉÅ„Éº„É†„ÅÆÊ†óÂéü„Åß„Åô„ÄÇ2025Âπ¥3Êúà10Êó•(Êúà)„Äú3Êúà14Êó•(Èáë)„Å´Âá∫Â≥∂„É°„ÉÉ„ÇªÈï∑Â¥é„Å´„Å¶Ë°å„Çè„Çå„ÅüË®ÄË™ûÂá¶ÁêÜÂ≠¶‰ºöÁ¨¨31ÂõûÂπ¥Ê¨°Â§ß‰ºö„Åß„ÄÅÂºäÁ§æ„Åã„Çâ„Éù„Çπ„Çø„ÉºÁô∫Ë°®„Åß3‰ª∂„ÄÅÂè£È†≠Áô∫Ë°®„Åß1‰ª∂„ÅÆÁô∫Ë°®„ÇíË°å„ÅÑ„Åæ„Åó„Åü„ÄÇ Êò® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5586' rel='nofollow'>Ë®ÄË™ûÂá¶ÁêÜÂ≠¶‰ºöÁ¨¨31ÂõûÂπ¥Ê¨°Â§ß‰ºö(NLP2025) Áô∫Ë°®Â†±Âëä</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Fri, 14 Mar 2025 10:50:19 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5586",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/IMG_1253-1-scaled.jpg"
  },
  {
    "title": "Language Model Re-rankers are Fooled by Lexical Similarities",
    "description": "arXiv:2502.17036v2 Announce Type: replace-cross Abstract: Language model (LM) re-rankers are used to refine retrieval results for retrieval-augmented generation (RAG). They are more expensive than lexical matching methods like BM25 but assumed to better process semantic information and the relations between the query and the retrieved answers. To understand whether LM re-rankers always live up to this assumption, we evaluate 6 different LM re-rankers on the NQ, LitQA2 and DRUID datasets. Our results show that LM re-rankers struggle to outperform a simple BM25 baseline on DRUID. Leveraging a novel separation metric based on BM25 scores, we explain and identify re-ranker errors stemming from lexical dissimilarities. We also investigate different methods to improve LM re-ranker performance and find these methods mainly useful for NQ. Taken together, our work identifies and explains weaknesses of LM re-rankers and points to the need for more adversarial and realistic datasets for their evaluation.",
    "summary": "arXiv:2502.17036v2 Announce Type: replace-cross Abstract: Language model (LM) re-rankers are used to refine retrieval results for retrieval-augmented generation (RAG). They are more expensive than lexical matching methods like BM25 but assumed to better process semantic information and the relations between the query and the retrieved answers. To understand whether LM re-rankers always live up to this assumption, we evaluate 6 different LM re-rankers on the NQ, LitQA2 and DRUID datasets. Our results show that LM re-rankers struggle to outperform a simple BM25 baseline on DRUID. Leveraging a novel separation metric based on BM25 scores, we explain and identify re-ranker errors stemming from lexical dissimilarities. We also investigate different methods to improve LM re-ranker performance and find these methods mainly useful for NQ. Taken together, our work identifies and explains weaknesses of LM re-rankers and points to the need for more adversarial and realistic datasets for their evaluation.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.17036",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Advancing Harmful Content Detection in Organizational Research: Integrating Large Language Models with Elo Rating System",
    "description": "arXiv:2506.16575v1 Announce Type: new Abstract: Large language models (LLMs) offer promising opportunities for organizational research. However, their built-in moderation systems can create problems when researchers try to analyze harmful content, often refusing to follow certain instructions or producing overly cautious responses that undermine validity of the results. This is particularly problematic when analyzing organizational conflicts such as microaggressions or hate speech. This paper introduces an Elo rating-based method that significantly improves LLM performance for harmful content analysis In two datasets, one focused on microaggression detection and the other on hate speech, we find that our method outperforms traditional LLM prompting techniques and conventional machine learning models on key measures such as accuracy, precision, and F1 scores. Advantages include better reliability when analyzing harmful content, fewer false positives, and greater scalability for large-scale datasets. This approach supports organizational applications, including detecting workplace harassment, assessing toxic communication, and fostering safer and more inclusive work environments.",
    "summary": "arXiv:2506.16575v1 Announce Type: new Abstract: Large language models (LLMs) offer promising opportunities for organizational research. However, their built-in moderation systems can create problems when researchers try to analyze harmful content, often refusing to follow certain instructions or producing overly cautious responses that undermine validity of the results. This is particularly problematic when analyzing organizational conflicts such as microaggressions or hate speech. This paper introduces an Elo rating-based method that significantly improves LLM performance for harmful content analysis In two datasets, one focused on microaggression detection and the other on hate speech, we find that our method outperforms traditional LLM prompting techniques and conventional machine learning models on key measures such as accuracy, precision, and F1 scores. Advantages include better reliability when analyzing harmful content, fewer false positives, and greater scalability for large-scale datasets. This approach supports organizational applications, including detecting workplace harassment, assessing toxic communication, and fostering safer and more inclusive work environments.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16575",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Open LLM Leaderboard: DROP deep dive",
    "description": "",
    "summary": "Open LLM Leaderboard: DROP deep dive Recently, three new benchmarks were added to the Open LLM Leade...",
    "pubDate": "Fri, 01 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-drop",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "Fuel your creativity with new generative media models and tools",
    "description": "Introducing Veo 3 and Imagen 4, and a new tool for filmmaking called Flow.",
    "summary": "Introducing Veo 3 and Imagen 4, and a new tool for filmmaking called Flow.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/fuel-your-creativity-with-new-generative-media-models-and-tools/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5.20v2_SS_1920x1080.width-1300.png"
  },
  {
    "title": "Quantum Artificial Intelligence for Secure Autonomous Vehicle Navigation: An Architectural Proposal",
    "description": "arXiv:2506.16000v1 Announce Type: cross Abstract: Navigation is a very crucial aspect of autonomous vehicle ecosystem which heavily relies on collecting and processing large amounts of data in various states and taking a confident and safe decision to define the next vehicle maneuver. In this paper, we propose a novel architecture based on Quantum Artificial Intelligence by enabling quantum and AI at various levels of navigation decision making and communication process in Autonomous vehicles : Quantum Neural Networks for multimodal sensor fusion, Nav-Q for Quantum reinforcement learning for navigation policy optimization and finally post-quantum cryptographic protocols for secure communication. Quantum neural networks uses quantum amplitude encoding to fuse data from various sensors like LiDAR, radar, camera, GPS and weather etc., This approach gives a unified quantum state representation between heterogeneous sensor modalities. Nav-Q module processes the fused quantum states through variational quantum circuits to learn optimal navigation policies under swift dynamic and complex conditions. Finally, post quantum cryptographic protocols are used to secure communication channels for both within vehicle communication and V2X (Vehicle to Everything) communications and thus secures the autonomous vehicle communication from both classical and quantum security threats. Thus, the proposed framework addresses fundamental challenges in autonomous vehicles navigation by providing quantum performance and future proof security. Index Terms Quantum Computing, Autonomous Vehicles, Sensor Fusion",
    "summary": "arXiv:2506.16000v1 Announce Type: cross Abstract: Navigation is a very crucial aspect of autonomous vehicle ecosystem which heavily relies on collecting and processing large amounts of data in various states and taking a confident and safe decision to define the next vehicle maneuver. In this paper, we propose a novel architecture based on Quantum Artificial Intelligence by enabling quantum and AI at various levels of navigation decision making and communication process in Autonomous vehicles : Quantum Neural Networks for multimodal sensor fusion, Nav-Q for Quantum reinforcement learning for navigation policy optimization and finally post-quantum cryptographic protocols for secure communication. Quantum neural networks uses quantum amplitude encoding to fuse data from various sensors like LiDAR, radar, camera, GPS and weather etc., This approach gives a unified quantum state representation between heterogeneous sensor modalities. Nav-Q module processes the fused quantum states through variational quantum circuits to learn optimal navigation policies under swift dynamic and complex conditions. Finally, post quantum cryptographic protocols are used to secure communication channels for both within vehicle communication and V2X (Vehicle to Everything) communications and thus secures the autonomous vehicle communication from both classical and quantum security threats. Thus, the proposed framework addresses fundamental challenges in autonomous vehicles navigation by providing quantum performance and future proof security. Index Terms Quantum Computing, Autonomous Vehicles, Sensor Fusion",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16000",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Retro Contest: Results",
    "description": "The first run of our¬†Retro Contest‚Äîexploring the development of algorithms that can generalize from previous experience‚Äîis now¬†complete.",
    "summary": "The first run of our¬†Retro Contest‚Äîexploring the development of algorithms that can generalize from previous experience‚Äîis now¬†complete.",
    "pubDate": "Fri, 22 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retro-contest-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LogProber: Disentangling confidence from contamination in LLM responses",
    "description": "arXiv:2408.14352v3 Announce Type: replace-cross Abstract: In machine learning, contamination refers to situations where testing data leak into the training set. The issue is particularly relevant for the evaluation of the performance of Large Language Models (LLMs), which are generally trained on gargantuan, and generally opaque, corpora of text scraped from the world wide web. Developing tools to detect contamination is therefore crucial to be able to fairly and properly track the evolution of the performance of LLMs. To date, only a few recent studies have attempted to address the issue of quantifying and detecting contamination in short text sequences, such as those commonly found in benchmarks. However, these methods have limitations that can sometimes render them impractical. In the present paper, we introduce LogProber, a novel, efficient algorithm that we show to be able to detect contamination in a black box setting that tries to tackle some of these drawbacks by focusing on the familiarity with the question rather than the answer. Here, we explore the properties of the proposed method in comparison with concurrent approaches, identify its advantages and limitations, and illustrate how different forms of contamination can go undetected depending on the design of the detection algorithm.",
    "summary": "arXiv:2408.14352v3 Announce Type: replace-cross Abstract: In machine learning, contamination refers to situations where testing data leak into the training set. The issue is particularly relevant for the evaluation of the performance of Large Language Models (LLMs), which are generally trained on gargantuan, and generally opaque, corpora of text scraped from the world wide web. Developing tools to detect contamination is therefore crucial to be able to fairly and properly track the evolution of the performance of LLMs. To date, only a few recent studies have attempted to address the issue of quantifying and detecting contamination in short text sequences, such as those commonly found in benchmarks. However, these methods have limitations that can sometimes render them impractical. In the present paper, we introduce LogProber, a novel, efficient algorithm that we show to be able to detect contamination in a black box setting that tries to tackle some of these drawbacks by focusing on the familiarity with the question rather than the answer. Here, we explore the properties of the proposed method in comparison with concurrent approaches, identify its advantages and limitations, and illustrate how different forms of contamination can go undetected depending on the design of the detection algorithm.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.14352",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Making a web app generator with open ML models",
    "description": "",
    "summary": "Making a web app generator with open ML models As more code generation models become publicly availa...",
    "pubDate": "Mon, 03 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-to-webapp",
    "thumbnail": "https://huggingface.co/blog/assets/153_text_to_webapp/thumbnail.jpg"
  },
  {
    "title": "Serverless Inference with Hugging Face and NVIDIA NIMs",
    "description": "",
    "summary": "Serverless Inference with Hugging Face and NVIDIA NIM Update: This service is deprecated and no long...",
    "pubDate": "Mon, 29 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-dgx-cloud",
    "thumbnail": "https://huggingface.co/blog/assets/train-dgx-cloud/thumbnail.jpg"
  },
  {
    "title": "Introducing new audio and vision documentation in ü§ó Datasets",
    "description": "",
    "summary": "Introducing new audio and vision documentation in ü§ó Datasets Open and reproducible datasets are esse...",
    "pubDate": "Thu, 28 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/datasets-docs-update",
    "thumbnail": "https://huggingface.co/blog/assets/87_datasets-docs-update/thumbnail.gif"
  },
  {
    "title": "Introducing ChatGPT Gov",
    "description": "ChatGPT Gov is designed to streamline government agencies‚Äô access to OpenAI‚Äôs frontier models.",
    "summary": "ChatGPT Gov is designed to streamline government agencies‚Äô access to OpenAI‚Äôs frontier models.",
    "pubDate": "Tue, 28 Jan 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-chatgpt-gov",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-3.5 Turbo fine-tuning and API updates",
    "description": "Developers can now bring their own data to customize GPT-3.5 Turbo for their use cases.",
    "summary": "Developers can now bring their own data to customize GPT-3.5 Turbo for their use cases.",
    "pubDate": "Tue, 22 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LLM„ÅÆÊé®Ë´ñ„Å´„Åä„Åë„Çã ‚Äúaha moment‚Äù „Å´„Å§„ÅÑ„Å¶Ë™ø„Åπ„Å¶„Åø„Åü",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ÂÖàÊó•„ÄÅLLM„ÅÆ 'aha moment' „Å´Èñ¢„Åó„Å¶ËààÂë≥„ÇíÊåÅ„Å°„ÄÅÈñ¢ÈÄ£Ë´ñÊñá„ÇÑWeb‰∏ä„ÅÆË®ò‰∫ã„ÇíË™≠„Çì„Åß„Åø„Åü„Å®„Åì„Çç„ÄÅË≥õÂê¶‰∏°Ë´ñ„ÅÆÊßò„ÄÖ„Å™Ë¶ãËß£„Åå„ÅÇ„ÇäËààÂë≥Ê∑±„Åã„Å£„Åü„ÅÆ„Åß„ÄÅ‰ªäÂõû„ÅØ„Åù„ÅÆÂÜÖÂÆπ„ÇíÂÖ±Êúâ„Åó„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5766' rel='nofollow'>LLM„ÅÆÊé®Ë´ñ„Å´„Åä„Åë„Çã &#8220;aha moment&#8221; „Å´„Å§„ÅÑ„Å¶Ë™ø„Åπ„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ÂÖàÊó•„ÄÅLLM„ÅÆ 'aha moment' „Å´Èñ¢„Åó„Å¶ËààÂë≥„ÇíÊåÅ„Å°„ÄÅÈñ¢ÈÄ£Ë´ñÊñá„ÇÑWeb‰∏ä„ÅÆË®ò‰∫ã„ÇíË™≠„Çì„Åß„Åø„Åü„Å®„Åì„Çç„ÄÅË≥õÂê¶‰∏°Ë´ñ„ÅÆÊßò„ÄÖ„Å™Ë¶ãËß£„Åå„ÅÇ„ÇäËààÂë≥Ê∑±„Åã„Å£„Åü„ÅÆ„Åß„ÄÅ‰ªäÂõû„ÅØ„Åù„ÅÆÂÜÖÂÆπ„ÇíÂÖ±Êúâ„Åó„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5766' rel='nofollow'>LLM„ÅÆÊé®Ë´ñ„Å´„Åä„Åë„Çã &#8220;aha moment&#8221; „Å´„Å§„ÅÑ„Å¶Ë™ø„Åπ„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Fri, 16 May 2025 04:41:37 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5766",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/d099d886ed65ef765625779e628d2c5f.png"
  },
  {
    "title": "A research agenda for assessing the economic impacts of code generation models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 03 Mar 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/economic-impacts-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building agricultural database for farmers",
    "description": "Digital Green uses OpenAI to increase farmer income.",
    "summary": "Digital Green uses OpenAI to increase farmer income.",
    "pubDate": "Fri, 12 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/digital-green",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Decoupled Classifier-Free Guidance for Counterfactual Diffusion Models",
    "description": "arXiv:2506.14399v2 Announce Type: replace-cross Abstract: Counterfactual image generation aims to simulate realistic visual outcomes under specific causal interventions. Diffusion models have recently emerged as a powerful tool for this task, combining DDIM inversion with conditional generation via classifier-free guidance (CFG). However, standard CFG applies a single global weight across all conditioning variables, which can lead to poor identity preservation and spurious attribute changes - a phenomenon known as attribute amplification. To address this, we propose Decoupled Classifier-Free Guidance (DCFG), a flexible and model-agnostic framework that introduces group-wise conditioning control. DCFG builds on an attribute-split embedding strategy that disentangles semantic inputs, enabling selective guidance on user-defined attribute groups. For counterfactual generation, we partition attributes into intervened and invariant sets based on a causal graph and apply distinct guidance to each. Experiments on CelebA-HQ, MIMIC-CXR, and EMBED show that DCFG improves intervention fidelity, mitigates unintended changes, and enhances reversibility, enabling more faithful and interpretable counterfactual image generation.",
    "summary": "arXiv:2506.14399v2 Announce Type: replace-cross Abstract: Counterfactual image generation aims to simulate realistic visual outcomes under specific causal interventions. Diffusion models have recently emerged as a powerful tool for this task, combining DDIM inversion with conditional generation via classifier-free guidance (CFG). However, standard CFG applies a single global weight across all conditioning variables, which can lead to poor identity preservation and spurious attribute changes - a phenomenon known as attribute amplification. To address this, we propose Decoupled Classifier-Free Guidance (DCFG), a flexible and model-agnostic framework that introduces group-wise conditioning control. DCFG builds on an attribute-split embedding strategy that disentangles semantic inputs, enabling selective guidance on user-defined attribute groups. For counterfactual generation, we partition attributes into intervened and invariant sets based on a causal graph and apply distinct guidance to each. Experiments on CelebA-HQ, MIMIC-CXR, and EMBED show that DCFG improves intervention fidelity, mitigates unintended changes, and enhances reversibility, enabling more faithful and interpretable counterfactual image generation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14399",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Importance of Being Lazy: Scaling Limits of Continual Learning",
    "description": "arXiv:2506.16884v1 Announce Type: cross Abstract: Despite recent efforts, neural networks still struggle to learn in non-stationary environments, and our understanding of catastrophic forgetting (CF) is far from complete. In this work, we perform a systematic study on the impact of model scale and the degree of feature learning in continual learning. We reconcile existing contradictory observations on scale in the literature, by differentiating between lazy and rich training regimes through a variable parameterization of the architecture. We show that increasing model width is only beneficial when it reduces the amount of feature learning, yielding more laziness. Using the framework of dynamical mean field theory, we then study the infinite width dynamics of the model in the feature learning regime and characterize CF, extending prior theoretical results limited to the lazy regime. We study the intricate relationship between feature learning, task non-stationarity, and forgetting, finding that high feature learning is only beneficial with highly similar tasks. We identify a transition modulated by task similarity where the model exits an effectively lazy regime with low forgetting to enter a rich regime with significant forgetting. Finally, our findings reveal that neural networks achieve optimal performance at a critical level of feature learning, which depends on task non-stationarity and transfers across model scales. This work provides a unified perspective on the role of scale and feature learning in continual learning.",
    "summary": "arXiv:2506.16884v1 Announce Type: cross Abstract: Despite recent efforts, neural networks still struggle to learn in non-stationary environments, and our understanding of catastrophic forgetting (CF) is far from complete. In this work, we perform a systematic study on the impact of model scale and the degree of feature learning in continual learning. We reconcile existing contradictory observations on scale in the literature, by differentiating between lazy and rich training regimes through a variable parameterization of the architecture. We show that increasing model width is only beneficial when it reduces the amount of feature learning, yielding more laziness. Using the framework of dynamical mean field theory, we then study the infinite width dynamics of the model in the feature learning regime and characterize CF, extending prior theoretical results limited to the lazy regime. We study the intricate relationship between feature learning, task non-stationarity, and forgetting, finding that high feature learning is only beneficial with highly similar tasks. We identify a transition modulated by task similarity where the model exits an effectively lazy regime with low forgetting to enter a rich regime with significant forgetting. Finally, our findings reveal that neural networks achieve optimal performance at a critical level of feature learning, which depends on task non-stationarity and transfers across model scales. This work provides a unified perspective on the role of scale and feature learning in continual learning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16884",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning to communicate",
    "description": "In this post we‚Äôll outline new OpenAI research in which agents develop their own language.",
    "summary": "In this post we‚Äôll outline new OpenAI research in which agents develop their own language.",
    "pubDate": "Thu, 16 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-communicate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LeRobot Community Datasets: The ‚ÄúImageNet‚Äù of Robotics ‚Äî When and How?",
    "description": "",
    "summary": "LeRobot Community Datasets: The ‚ÄúImageNet‚Äù of Robotics ‚Äî When and How? üß≠ TL;DR ‚Äî Why This Blogpost? ...",
    "pubDate": "Sun, 11 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lerobot-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/195_lerobot_datasets/1.png"
  },
  {
    "title": "Dynamic Knowledge Integration for Evidence-Driven Counter-Argument Generation with Large Language Models",
    "description": "arXiv:2503.05328v2 Announce Type: replace-cross Abstract: This paper investigates the role of dynamic external knowledge integration in improving counter-argument generation using Large Language Models (LLMs). While LLMs have shown promise in argumentative tasks, their tendency to generate lengthy, potentially unfactual responses highlights the need for more controlled and evidence-based approaches. We introduce a new manually curated dataset of argument and counter-argument pairs specifically designed to balance argumentative complexity with evaluative feasibility. We also propose a new LLM-as-a-Judge evaluation methodology that shows a stronger correlation with human judgments compared to traditional reference-based metrics. Our experimental results demonstrate that integrating dynamic external knowledge from the web significantly improves the quality of generated counter-arguments, particularly in terms of relatedness, persuasiveness, and factuality. The findings suggest that combining LLMs with real-time external knowledge retrieval offers a promising direction for developing more effective and reliable counter-argumentation systems.",
    "summary": "arXiv:2503.05328v2 Announce Type: replace-cross Abstract: This paper investigates the role of dynamic external knowledge integration in improving counter-argument generation using Large Language Models (LLMs). While LLMs have shown promise in argumentative tasks, their tendency to generate lengthy, potentially unfactual responses highlights the need for more controlled and evidence-based approaches. We introduce a new manually curated dataset of argument and counter-argument pairs specifically designed to balance argumentative complexity with evaluative feasibility. We also propose a new LLM-as-a-Judge evaluation methodology that shows a stronger correlation with human judgments compared to traditional reference-based metrics. Our experimental results demonstrate that integrating dynamic external knowledge from the web significantly improves the quality of generated counter-arguments, particularly in terms of relatedness, persuasiveness, and factuality. The findings suggest that combining LLMs with real-time external knowledge retrieval offers a promising direction for developing more effective and reliable counter-argumentation systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.05328",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI partners with Schibsted Media Group",
    "description": "OpenAI and Schibsted Media Group announce content partnership to bring Guardian news and archive content to  ChatGPT.",
    "summary": "OpenAI and Schibsted Media Group announce content partnership to bring Guardian news and archive content to  ChatGPT.",
    "pubDate": "Mon, 10 Feb 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-partners-with-schibsted-media-group",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing The World's Largest Open Multilingual Language Model: BLOOM",
    "description": "",
    "summary": "üå∏ Introducing The World's Largest Open Multilingual Language Model: BLOOM üå∏ Large language models (L...",
    "pubDate": "Tue, 12 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom",
    "thumbnail": "https://huggingface.co/blog/assets/86_bloom/thumbnail.png"
  },
  {
    "title": "Interpretable Low-Dimensional Modeling of Spatiotemporal Agent States for Decision Making in Football Tactics",
    "description": "arXiv:2506.16696v1 Announce Type: new Abstract: Understanding football tactics is crucial for managers and analysts. Previous research has proposed models based on spatial and kinematic equations, but these are computationally expensive. Also, Reinforcement learning approaches use player positions and velocities but lack interpretability and require large datasets. Rule-based models align with expert knowledge but have not fully considered all players' states. This study explores whether low-dimensional, rule-based models using spatiotemporal data can effectively capture football tactics. Our approach defines interpretable state variables for both the ball-holder and potential pass receivers, based on criteria that explore options like passing. Through discussions with a manager, we identified key variables representing the game state. We then used StatsBomb event data and SkillCorner tracking data from the 2023$/$24 LaLiga season to train an XGBoost model to predict pass success. The analysis revealed that the distance between the player and the ball, as well as the player's space score, were key factors in determining successful passes. Our interpretable low-dimensional modeling facilitates tactical analysis through the use of intuitive variables and provides practical value as a tool to support decision-making in football.",
    "summary": "arXiv:2506.16696v1 Announce Type: new Abstract: Understanding football tactics is crucial for managers and analysts. Previous research has proposed models based on spatial and kinematic equations, but these are computationally expensive. Also, Reinforcement learning approaches use player positions and velocities but lack interpretability and require large datasets. Rule-based models align with expert knowledge but have not fully considered all players' states. This study explores whether low-dimensional, rule-based models using spatiotemporal data can effectively capture football tactics. Our approach defines interpretable state variables for both the ball-holder and potential pass receivers, based on criteria that explore options like passing. Through discussions with a manager, we identified key variables representing the game state. We then used StatsBomb event data and SkillCorner tracking data from the 2023$/$24 LaLiga season to train an XGBoost model to predict pass success. The analysis revealed that the distance between the player and the ball, as well as the player's space score, were key factors in determining successful passes. Our interpretable low-dimensional modeling facilitates tactical analysis through the use of intuitive variables and provides practical value as a tool to support decision-making in football.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16696",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLM Inference on Edge: A Fun and Easy Guide to run LLMs via React Native on your Phone!",
    "description": "",
    "summary": "LLM Inference on Edge: A Fun and Easy Guide to run LLMs via React Native on your Phone! As LLMs cont...",
    "pubDate": "Fri, 07 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llm-inference-on-edge",
    "thumbnail": "https://huggingface.co/blog/assets/llm_inference_on_edge/thumbnail.png"
  },
  {
    "title": "Dota 2",
    "description": "We‚Äôve created a bot which beats the world‚Äôs top professionals at 1v1 matches of Dota 2 under standard tournament rules. The bot learned the game from scratch by self-play, and does not use imitation learning or tree search. This is a step towards building AI systems which accomplish well-defined goals in messy, complicated situations involving real humans.",
    "summary": "We‚Äôve created a bot which beats the world‚Äôs top professionals at 1v1 matches of Dota 2 under standard tournament rules. The bot learned the game from scratch by self-play, and does not use imitation learning or tree search. This is a step towards building AI systems which accomplish well-defined goals in messy, complicated situations involving real humans.",
    "pubDate": "Fri, 11 Aug 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dota-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Snowball Fight ‚òÉÔ∏è, our First ML-Agents Environment",
    "description": "",
    "summary": "Introducing Snowball Fight ‚òÉÔ∏è, our First ML-Agents Environment We're excited to share our first cust...",
    "pubDate": "Thu, 02 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/snowball-fight",
    "thumbnail": "https://huggingface.co/blog/assets/39_introducing_snowball_fight/thumbnail.png"
  },
  {
    "title": "Approximation Fixpoint Theory with Refined Approximation Spaces",
    "description": "arXiv:2506.16294v1 Announce Type: new Abstract: Approximation Fixpoint Theory (AFT) is a powerful theory covering various semantics of non-monotonic reasoning formalisms in knowledge representation such as Logic Programming and Answer Set Programming. Many semantics of such non-monotonic formalisms can be characterized as suitable fixpoints of a non-monotonic operator on a suitable lattice. Instead of working on the original lattice, AFT operates on intervals in such lattice to approximate or construct the fixpoints of interest. While AFT has been applied successfully across a broad range of non-monotonic reasoning formalisms, it is confronted by its limitations in other, relatively simple, examples. In this paper, we overcome those limitations by extending consistent AFT to deal with approximations that are more refined than intervals. Therefore, we introduce a more general notion of approximation spaces, showcase the improved expressiveness and investigate relations between different approximation spaces.",
    "summary": "arXiv:2506.16294v1 Announce Type: new Abstract: Approximation Fixpoint Theory (AFT) is a powerful theory covering various semantics of non-monotonic reasoning formalisms in knowledge representation such as Logic Programming and Answer Set Programming. Many semantics of such non-monotonic formalisms can be characterized as suitable fixpoints of a non-monotonic operator on a suitable lattice. Instead of working on the original lattice, AFT operates on intervals in such lattice to approximate or construct the fixpoints of interest. While AFT has been applied successfully across a broad range of non-monotonic reasoning formalisms, it is confronted by its limitations in other, relatively simple, examples. In this paper, we overcome those limitations by extending consistent AFT to deal with approximations that are more refined than intervals. Therefore, we introduce a more general notion of approximation spaces, showcase the improved expressiveness and investigate relations between different approximation spaces.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16294",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DALL¬∑E 3 system card",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 03 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-3-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Novel method detects microbial contamination in cell cultures",
    "description": "Ultraviolet light ‚Äúfingerprints‚Äù on cell cultures and machine learning can provide a definitive yes/no contamination assessment within 30 minutes.",
    "summary": "Ultraviolet light ‚Äúfingerprints‚Äù on cell cultures and machine learning can provide a definitive yes/no contamination assessment within 30 minutes.",
    "pubDate": "Fri, 25 Apr 2025 22:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/novel-method-detects-microbial-contamination-smart-0425",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/SMART-CAMP-Senior-Research-Engineer.jpg"
  },
  {
    "title": "Gradio joins Hugging Face!",
    "description": "",
    "summary": "Gradio is joining Hugging Face! Gradio is joining Hugging Face! By acquiring Gradio, a machine learn...",
    "pubDate": "Tue, 21 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-joins-hf",
    "thumbnail": "https://huggingface.co/blog/assets/42_gradio_joins_hf/thumbnail.png"
  },
  {
    "title": "Designing a new way to optimize complex coordinated systems",
    "description": "Using diagrams to represent interactions in multipart systems can provide a faster way to design software improvements.",
    "summary": "Using diagrams to represent interactions in multipart systems can provide a faster way to design software improvements.",
    "pubDate": "Thu, 24 Apr 2025 15:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/designing-new-way-optimize-complex-coordinated-systems-0424",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/deep-learning-diagram.jpg"
  },
  {
    "title": "Retrieval Augmented Generation with Huggingface Transformers and Ray",
    "description": "",
    "summary": "Retrieval Augmented Generation with Huggingface Transformers and Ray A guest blog post by Amog Kamse...",
    "pubDate": "Wed, 10 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ray-rag",
    "thumbnail": "https://huggingface.co/blog/assets/12_ray_rag/ray_arch_updated.png"
  },
  {
    "title": "OpenAI appoints Retired U.S. Army General Paul M. Nakasone to Board of Directors",
    "description": "Nakasone brings cybersecurity experience to growing Board of Directors; will join the Board‚Äôs Safety and Security Committee",
    "summary": "Nakasone brings cybersecurity experience to growing Board of Directors; will join the Board‚Äôs Safety and Security Committee",
    "pubDate": "Thu, 13 Jun 2024 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-appoints-retired-us-army-general",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2020: Applications open",
    "description": "We are now accepting applications for our third class of OpenAI Scholars.",
    "summary": "We are now accepting applications for our third class of OpenAI Scholars.",
    "pubDate": "Fri, 11 Oct 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2020",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fractional Reasoning via Latent Steering Vectors Improves Inference Time Compute",
    "description": "arXiv:2506.15882v1 Announce Type: cross Abstract: Test-time compute has emerged as a powerful paradigm for improving the performance of large language models (LLMs), where generating multiple outputs or refining individual chains can significantly boost answer accuracy. However, existing methods like Best-of-N, majority voting, and self-reflection typically apply reasoning in a uniform way across inputs, overlooking the fact that different problems may require different levels of reasoning depth. In this work, we propose Fractional Reasoning, a training-free and model-agnostic framework that enables continuous control over reasoning intensity at inference time, going beyond the limitations of fixed instructional prompts. Our method operates by extracting the latent steering vector associated with deeper reasoning and reapplying it with a tunable scaling factor, allowing the model to tailor its reasoning process to the complexity of each input. This supports two key modes of test-time scaling: (1) improving output quality in breadth-based strategies (e.g., Best-of-N, majority voting), and (2) enhancing the correctness of individual reasoning chains in depth-based strategies (e.g., self-reflection). Experiments on GSM8K, MATH500, and GPQA demonstrate that Fractional Reasoning consistently improves performance across diverse reasoning tasks and models.",
    "summary": "arXiv:2506.15882v1 Announce Type: cross Abstract: Test-time compute has emerged as a powerful paradigm for improving the performance of large language models (LLMs), where generating multiple outputs or refining individual chains can significantly boost answer accuracy. However, existing methods like Best-of-N, majority voting, and self-reflection typically apply reasoning in a uniform way across inputs, overlooking the fact that different problems may require different levels of reasoning depth. In this work, we propose Fractional Reasoning, a training-free and model-agnostic framework that enables continuous control over reasoning intensity at inference time, going beyond the limitations of fixed instructional prompts. Our method operates by extracting the latent steering vector associated with deeper reasoning and reapplying it with a tunable scaling factor, allowing the model to tailor its reasoning process to the complexity of each input. This supports two key modes of test-time scaling: (1) improving output quality in breadth-based strategies (e.g., Best-of-N, majority voting), and (2) enhancing the correctness of individual reasoning chains in depth-based strategies (e.g., self-reflection). Experiments on GSM8K, MATH500, and GPQA demonstrate that Fractional Reasoning consistently improves performance across diverse reasoning tasks and models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15882",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÊôÇ‰ª£„ÄÅÁµÑÁπî„ÅÆÂú®„ÇäÊñπ„ÅØ„Å©„ÅÜÂ§â„Çè„ÇãÔºü„ÄÄ„Äå‰∏äÂè∏„ÅØ„ÅÑ„Çâ„Å™„Åè„Å™„Çã„ÅÆ„ÅãÂïèÈ°å„Äç„ÇíËÄÉÂØü",
    "description": "Ë©±È°å„ÅÆAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅØ„ÄÅ‰ºÅÊ•≠„ÅÆÂú®„ÇäÊñπ„Çí„Å©„ÅÆ„Çà„ÅÜ„Å´Â§â„Åà„Çã„ÅÆ„Åã„ÄÇ‰∫∫Èñì„Å®AI„ÅÆÂçîÂÉç„ÅåÈÄ≤Âåñ„Åô„Çã„Å´„Å§„Çå„Å¶„Åì„Çå„Åæ„Åß„Äå„Éî„É©„Éü„ÉÉ„ÉâÂûã„Äç„Å†„Å£„ÅüÁµÑÁπî„ÅÆÂú®„ÇäÊñπ„ÅØÂ§âÂåñ„Åô„Çã„ÅÆ„Å†„Çç„ÅÜ„Åã„ÄÇPwC„Ç≥„É≥„Çµ„É´„ÉÜ„Ç£„É≥„Ç∞„ÅÆÊúÄÊñ∞„É¨„Éù„Éº„Éà„Åã„ÇâËÄÉÂØü„Åô„Çã„ÄÇ",
    "summary": "Ë©±È°å„ÅÆAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅØ„ÄÅ‰ºÅÊ•≠„ÅÆÂú®„ÇäÊñπ„Çí„Å©„ÅÆ„Çà„ÅÜ„Å´Â§â„Åà„Çã„ÅÆ„Åã„ÄÇ‰∫∫Èñì„Å®AI„ÅÆÂçîÂÉç„ÅåÈÄ≤Âåñ„Åô„Çã„Å´„Å§„Çå„Å¶„Åì„Çå„Åæ„Åß„Äå„Éî„É©„Éü„ÉÉ„ÉâÂûã„Äç„Å†„Å£„ÅüÁµÑÁπî„ÅÆÂú®„ÇäÊñπ„ÅØÂ§âÂåñ„Åô„Çã„ÅÆ„Å†„Çç„ÅÜ„Åã„ÄÇPwC„Ç≥„É≥„Çµ„É´„ÉÜ„Ç£„É≥„Ç∞„ÅÆÊúÄÊñ∞„É¨„Éù„Éº„Éà„Åã„ÇâËÄÉÂØü„Åô„Çã„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 16:40:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/30/news091.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/30/cover_news091.jpg"
  },
  {
    "title": "Long-Context Generalization with Sparse Attention",
    "description": "arXiv:2506.16640v1 Announce Type: cross Abstract: Transformer-based architectures traditionally employ softmax to compute attention weights, which produces dense distributions over all tokens in a sequence. While effective in many settings, this density has been shown to be detrimental for tasks that demand precise focus on fixed-size patterns: as sequence length increases, non-informative tokens accumulate attention probability mass, leading to dispersion and representational collapse. We show in this paper that sparse attention mechanisms using $alpha$-entmax can avoid these issues, due to their ability to assign exact zeros to irrelevant tokens. Furthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows $alpha$-entmax with a learnable temperature parameter, allowing the attention distribution to interpolate between sparse (pattern-focused) and dense (softmax-like) regimes. Finally, we show that the ability to locate and generalize fixed-size patterns can be further improved through a careful design of position encodings, which impacts both dense and sparse attention methods. By integrating ASEntmax into standard transformer layers alongside proper positional encodings, we show that our models greatly outperform softmax, scalable softmax, and fixed-temperature $alpha$-entmax baselines on long-context generalization.",
    "summary": "arXiv:2506.16640v1 Announce Type: cross Abstract: Transformer-based architectures traditionally employ softmax to compute attention weights, which produces dense distributions over all tokens in a sequence. While effective in many settings, this density has been shown to be detrimental for tasks that demand precise focus on fixed-size patterns: as sequence length increases, non-informative tokens accumulate attention probability mass, leading to dispersion and representational collapse. We show in this paper that sparse attention mechanisms using $alpha$-entmax can avoid these issues, due to their ability to assign exact zeros to irrelevant tokens. Furthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows $alpha$-entmax with a learnable temperature parameter, allowing the attention distribution to interpolate between sparse (pattern-focused) and dense (softmax-like) regimes. Finally, we show that the ability to locate and generalize fixed-size patterns can be further improved through a careful design of position encodings, which impacts both dense and sparse attention methods. By integrating ASEntmax into standard transformer layers alongside proper positional encodings, we show that our models greatly outperform softmax, scalable softmax, and fixed-temperature $alpha$-entmax baselines on long-context generalization.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16640",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Supercharged Customer Service with Machine Learning",
    "description": "",
    "summary": "Supercharged Customer Service with Machine Learning In this blog post, we will simulate a real-world...",
    "pubDate": "Mon, 25 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/supercharge-customer-service-with-machine-learning",
    "thumbnail": "https://huggingface.co/blog/assets/61_supercharged_customer_service_with_nlp/thumbnail.png"
  },
  {
    "title": "Team update",
    "description": "We‚Äôd like to welcome the latest set of team members to OpenAI (and we‚Äôre still hiring!)",
    "summary": "We‚Äôd like to welcome the latest set of team members to OpenAI (and we‚Äôre still hiring!)",
    "pubDate": "Wed, 25 May 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Study of Hybrid and Evolutionary Metaheuristics for Single Hidden Layer Feedforward Neural Network Architecture",
    "description": "arXiv:2506.15737v1 Announce Type: cross Abstract: Training Artificial Neural Networks (ANNs) with Stochastic Gradient Descent (SGD) frequently encounters difficulties, including substantial computing expense and the risk of converging to local optima, attributable to its dependence on partial weight gradients. Therefore, this work investigates Particle Swarm Optimization (PSO) and Genetic Algorithms (GAs) - two population-based Metaheuristic Optimizers (MHOs) - as alternatives to SGD to mitigate these constraints. A hybrid PSO-SGD strategy is developed to improve local search efficiency. The findings indicate that the hybrid PSO-SGD technique decreases the median training MSE by 90 to 95 percent relative to conventional GA and PSO across various network sizes (e.g., from around 0.02 to approximately 0.001 in the Sphere function). RMHC attains substantial enhancements, reducing MSE by roughly 85 to 90 percent compared to GA. Simultaneously, RS consistently exhibits errors exceeding 0.3, signifying subpar performance. These findings underscore that hybrid and evolutionary procedures significantly improve training efficiency and accuracy compared to conventional optimization methods and imply that the Building Block Hypothesis (BBH) may still be valid, indicating that advantageous weight structures are retained during evolutionary search.",
    "summary": "arXiv:2506.15737v1 Announce Type: cross Abstract: Training Artificial Neural Networks (ANNs) with Stochastic Gradient Descent (SGD) frequently encounters difficulties, including substantial computing expense and the risk of converging to local optima, attributable to its dependence on partial weight gradients. Therefore, this work investigates Particle Swarm Optimization (PSO) and Genetic Algorithms (GAs) - two population-based Metaheuristic Optimizers (MHOs) - as alternatives to SGD to mitigate these constraints. A hybrid PSO-SGD strategy is developed to improve local search efficiency. The findings indicate that the hybrid PSO-SGD technique decreases the median training MSE by 90 to 95 percent relative to conventional GA and PSO across various network sizes (e.g., from around 0.02 to approximately 0.001 in the Sphere function). RMHC attains substantial enhancements, reducing MSE by roughly 85 to 90 percent compared to GA. Simultaneously, RS consistently exhibits errors exceeding 0.3, signifying subpar performance. These findings underscore that hybrid and evolutionary procedures significantly improve training efficiency and accuracy compared to conventional optimization methods and imply that the Building Block Hypothesis (BBH) may still be valid, indicating that advantageous weight structures are retained during evolutionary search.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15737",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Quantile Regression Approach for Remaining Useful Life Estimation with State Space Models",
    "description": "arXiv:2506.17018v1 Announce Type: new Abstract: Predictive Maintenance (PdM) is pivotal in Industry 4.0 and 5.0, proactively enhancing efficiency through accurate equipment Remaining Useful Life (RUL) prediction, thus optimizing maintenance scheduling and reducing unexpected failures and premature interventions. This paper introduces a novel RUL estimation approach leveraging State Space Models (SSM) for efficient long-term sequence modeling. To handle model uncertainty, Simoultaneous Quantile Regression (SQR) is integrated into the SSM, enabling multiple quantile estimations. The proposed method is benchmarked against traditional sequence modelling techniques (LSTM, Transformer, Informer) using the C-MAPSS dataset. Results demonstrate superior accuracy and computational efficiency of SSM models, underscoring their potential for high-stakes industrial applications.",
    "summary": "arXiv:2506.17018v1 Announce Type: new Abstract: Predictive Maintenance (PdM) is pivotal in Industry 4.0 and 5.0, proactively enhancing efficiency through accurate equipment Remaining Useful Life (RUL) prediction, thus optimizing maintenance scheduling and reducing unexpected failures and premature interventions. This paper introduces a novel RUL estimation approach leveraging State Space Models (SSM) for efficient long-term sequence modeling. To handle model uncertainty, Simoultaneous Quantile Regression (SQR) is integrated into the SSM, enabling multiple quantile estimations. The proposed method is benchmarked against traditional sequence modelling techniques (LSTM, Transformer, Informer) using the C-MAPSS dataset. Results demonstrate superior accuracy and computational efficiency of SSM models, underscoring their potential for high-stakes industrial applications.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Safety Gym",
    "description": "We‚Äôre releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while¬†training.",
    "summary": "We‚Äôre releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement learning agents that respect safety constraints while¬†training.",
    "pubDate": "Thu, 21 Nov 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/safety-gym",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MDPO: Multi-Granularity Direct Preference Optimization for Mathematical Reasoning",
    "description": "arXiv:2506.15706v1 Announce Type: cross Abstract: Mathematical reasoning presents a significant challenge for Large Language Models (LLMs) as it requires ensuring the correctness of each reasoning step. Researchers have been strengthening the mathematical reasoning abilities of LLMs through supervised fine-tuning, but due to the inability to suppress incorrect outputs, illusions can easily arise. Recently, Direct Preference Optimization (DPO) has been widely adopted for aligning human intent by using preference data to prevent LLMs from generating incorrect outputs. However, it has shown limited benefits in long-chain mathematical reasoning, mainly because DPO struggles to effectively capture the differences between accepted and rejected answers from preferences in long-chain data. The inconsistency between DPO training and LLMs' generation metrics also affects the effectiveness of suppressing incorrect outputs. We propose the Multi-Granularity Direct Preference Optimization (MDPO) method, optimizing the mathematical reasoning of LLMs at three granularities: Solution2Solution, Inference2Inference, and Step2Step. Solution2Solution focuses on the correctness of entire long-chain reasoning; Inference2Inference concentrates on logical reasoning between steps; Step2Step corrects computational errors in steps, enhancing the computational capabilities of LLMs. Additionally, we unify the training objectives of the three granularities to align with the generation metrics. We conducted experiments on the open-source models Qwen2 and Llama3, achieving improvements of 1.7% and 0.9% on the GSM8K dataset, and 2.3% and 1.2% on the MATH dataset, outperforming DPO and other DPO variant methods. Furthermore, we also provide a pipeline for constructing MDPO training data that is simple and does not require manual annotation costs.",
    "summary": "arXiv:2506.15706v1 Announce Type: cross Abstract: Mathematical reasoning presents a significant challenge for Large Language Models (LLMs) as it requires ensuring the correctness of each reasoning step. Researchers have been strengthening the mathematical reasoning abilities of LLMs through supervised fine-tuning, but due to the inability to suppress incorrect outputs, illusions can easily arise. Recently, Direct Preference Optimization (DPO) has been widely adopted for aligning human intent by using preference data to prevent LLMs from generating incorrect outputs. However, it has shown limited benefits in long-chain mathematical reasoning, mainly because DPO struggles to effectively capture the differences between accepted and rejected answers from preferences in long-chain data. The inconsistency between DPO training and LLMs' generation metrics also affects the effectiveness of suppressing incorrect outputs. We propose the Multi-Granularity Direct Preference Optimization (MDPO) method, optimizing the mathematical reasoning of LLMs at three granularities: Solution2Solution, Inference2Inference, and Step2Step. Solution2Solution focuses on the correctness of entire long-chain reasoning; Inference2Inference concentrates on logical reasoning between steps; Step2Step corrects computational errors in steps, enhancing the computational capabilities of LLMs. Additionally, we unify the training objectives of the three granularities to align with the generation metrics. We conducted experiments on the open-source models Qwen2 and Llama3, achieving improvements of 1.7% and 0.9% on the GSM8K dataset, and 2.3% and 1.2% on the MATH dataset, outperforming DPO and other DPO variant methods. Furthermore, we also provide a pipeline for constructing MDPO training data that is simple and does not require manual annotation costs.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15706",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "KV Cache from scratch in nanoVLM",
    "description": "",
    "summary": "KV Cache from scratch in nanoVLM TL;DR We have implemented KV Caching from scratch in our nanoVLM re...",
    "pubDate": "Wed, 04 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kv-cache",
    "thumbnail": "https://huggingface.co/blog/assets/kv-cache/thumbnail.png"
  },
  {
    "title": "FairCauseSyn: Towards Causally Fair LLM-Augmented Synthetic Data Generation",
    "description": "arXiv:2506.19082v1 Announce Type: cross Abstract: Synthetic data generation creates data based on real-world data using generative models. In health applications, generating high-quality data while maintaining fairness for sensitive attributes is essential for equitable outcomes. Existing GAN-based and LLM-based methods focus on counterfactual fairness and are primarily applied in finance and legal domains. Causal fairness provides a more comprehensive evaluation framework by preserving causal structure, but current synthetic data generation methods do not address it in health settings. To fill this gap, we develop the first LLM-augmented synthetic data generation method to enhance causal fairness using real-world tabular health data. Our generated data deviates by less than 10% from real data on causal fairness metrics. When trained on causally fair predictors, synthetic data reduces bias on the sensitive attribute by 70% compared to real data. This work improves access to fair synthetic data, supporting equitable health research and healthcare delivery.",
    "summary": "arXiv:2506.19082v1 Announce Type: cross Abstract: Synthetic data generation creates data based on real-world data using generative models. In health applications, generating high-quality data while maintaining fairness for sensitive attributes is essential for equitable outcomes. Existing GAN-based and LLM-based methods focus on counterfactual fairness and are primarily applied in finance and legal domains. Causal fairness provides a more comprehensive evaluation framework by preserving causal structure, but current synthetic data generation methods do not address it in health settings. To fill this gap, we develop the first LLM-augmented synthetic data generation method to enhance causal fairness using real-world tabular health data. Our generated data deviates by less than 10% from real data on causal fairness metrics. When trained on causally fair predictors, synthetic data reduces bias on the sensitive attribute by 70% compared to real data. This work improves access to fair synthetic data, supporting equitable health research and healthcare delivery.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19082",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NeRF-based CBCT Reconstruction needs Normalization and Initialization",
    "description": "arXiv:2506.19742v1 Announce Type: cross Abstract: Cone Beam Computed Tomography (CBCT) is widely used in medical imaging. However, the limited number and intensity of X-ray projections make reconstruction an ill-posed problem with severe artifacts. NeRF-based methods have achieved great success in this task. However, they suffer from a local-global training mismatch between their two key components: the hash encoder and the neural network. Specifically, in each training step, only a subset of the hash encoder's parameters is used (local sparse), whereas all parameters in the neural network participate (global dense). Consequently, hash features generated in each step are highly misaligned, as they come from different subsets of the hash encoder. These misalignments from different training steps are then fed into the neural network, causing repeated inconsistent global updates in training, which leads to unstable training, slower convergence, and degraded reconstruction quality. Aiming to alleviate the impact of this local-global optimization mismatch, we introduce a Normalized Hash Encoder, which enhances feature consistency and mitigates the mismatch. Additionally, we propose a Mapping Consistency Initialization(MCI) strategy that initializes the neural network before training by leveraging the global mapping property from a well-trained model. The initialized neural network exhibits improved stability during early training, enabling faster convergence and enhanced reconstruction performance. Our method is simple yet effective, requiring only a few lines of code while substantially improving training efficiency on 128 CT cases collected from 4 different datasets, covering 7 distinct anatomical regions.",
    "summary": "arXiv:2506.19742v1 Announce Type: cross Abstract: Cone Beam Computed Tomography (CBCT) is widely used in medical imaging. However, the limited number and intensity of X-ray projections make reconstruction an ill-posed problem with severe artifacts. NeRF-based methods have achieved great success in this task. However, they suffer from a local-global training mismatch between their two key components: the hash encoder and the neural network. Specifically, in each training step, only a subset of the hash encoder's parameters is used (local sparse), whereas all parameters in the neural network participate (global dense). Consequently, hash features generated in each step are highly misaligned, as they come from different subsets of the hash encoder. These misalignments from different training steps are then fed into the neural network, causing repeated inconsistent global updates in training, which leads to unstable training, slower convergence, and degraded reconstruction quality. Aiming to alleviate the impact of this local-global optimization mismatch, we introduce a Normalized Hash Encoder, which enhances feature consistency and mitigates the mismatch. Additionally, we propose a Mapping Consistency Initialization(MCI) strategy that initializes the neural network before training by leveraging the global mapping property from a well-trained model. The initialized neural network exhibits improved stability during early training, enabling faster convergence and enhanced reconstruction performance. Our method is simple yet effective, requiring only a few lines of code while substantially improving training efficiency on 128 CT cases collected from 4 different datasets, covering 7 distinct anatomical regions.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19742",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Graphcore and Hugging Face Launch New Lineup of IPU-Ready Transformers",
    "description": "",
    "summary": "Graphcore and Hugging Face Launch New Lineup of IPU-Ready Transformers Graphcore and Hugging Face ha...",
    "pubDate": "Thu, 26 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore-update",
    "thumbnail": "https://huggingface.co/blog/assets/77_graphcore-update/graphcore_update.png"
  },
  {
    "title": "Fast Inference on Large Language Models: BLOOMZ on Habana Gaudi2 Accelerator",
    "description": "",
    "summary": "Fast Inference on Large Language Models: BLOOMZ on Habana Gaudi2 Accelerator This article will show ...",
    "pubDate": "Tue, 28 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana-gaudi-2-bloom",
    "thumbnail": "https://huggingface.co/blog/assets/habana-gaudi-2-bloom/thumbnail.png"
  },
  {
    "title": "My Journey to a serverless transformers pipeline on Google Cloud",
    "description": "",
    "summary": "My Journey to a serverless transformers pipeline on Google Cloud A guest blog post by community memb...",
    "pubDate": "Thu, 18 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-deploy-a-pipeline-to-google-clouds",
    "thumbnail": "https://huggingface.co/blog/assets/14_how_to_deploy_a_pipeline_to_google_clouds/thumbnail.png"
  },
  {
    "title": "Hugging Face's TensorFlow Philosophy",
    "description": "",
    "summary": "Hugging Face's TensorFlow Philosophy Introduction Despite increasing competition from PyTorch and JA...",
    "pubDate": "Fri, 12 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tensorflow-philosophy",
    "thumbnail": "https://huggingface.co/blog/assets/96_tensorflow_philosophy/thumbnail.png"
  },
  {
    "title": "Large Language Models as symbolic DNA of cultural dynamics",
    "description": "arXiv:2506.21606v1 Announce Type: cross Abstract: This paper proposes a novel conceptualization of Large Language Models (LLMs) as externalized informational substrates that function analogously to DNA for human cultural dynamics. Rather than viewing LLMs as either autonomous intelligence or mere programmed mimicry, we argue they serve a broader role as repositories that preserve compressed patterns of human symbolic expression--'fossils' of meaningful dynamics that retain relational residues without their original living contexts. Crucially, these compressed patterns only become meaningful through human reinterpretation, creating a recursive feedback loop where they can be recombined and cycle back to ultimately catalyze human creative processes. Through analysis of four universal features--compression, decompression, externalization, and recursion--we demonstrate that just as DNA emerged as a compressed and externalized medium for preserving useful cellular dynamics without containing explicit reference to goal-directed physical processes, LLMs preserve useful regularities of human culture without containing understanding of embodied human experience. Therefore, we argue that LLMs' significance lies not in rivaling human intelligence, but in providing humanity a tool for self-reflection and playful hypothesis-generation in a low-stakes, simulated environment. This framework positions LLMs as tools for cultural evolvability, enabling humanity to generate novel hypotheses about itself while maintaining the human interpretation necessary to ground these hypotheses in ongoing human aesthetics and norms.",
    "summary": "arXiv:2506.21606v1 Announce Type: cross Abstract: This paper proposes a novel conceptualization of Large Language Models (LLMs) as externalized informational substrates that function analogously to DNA for human cultural dynamics. Rather than viewing LLMs as either autonomous intelligence or mere programmed mimicry, we argue they serve a broader role as repositories that preserve compressed patterns of human symbolic expression--'fossils' of meaningful dynamics that retain relational residues without their original living contexts. Crucially, these compressed patterns only become meaningful through human reinterpretation, creating a recursive feedback loop where they can be recombined and cycle back to ultimately catalyze human creative processes. Through analysis of four universal features--compression, decompression, externalization, and recursion--we demonstrate that just as DNA emerged as a compressed and externalized medium for preserving useful cellular dynamics without containing explicit reference to goal-directed physical processes, LLMs preserve useful regularities of human culture without containing understanding of embodied human experience. Therefore, we argue that LLMs' significance lies not in rivaling human intelligence, but in providing humanity a tool for self-reflection and playful hypothesis-generation in a low-stakes, simulated environment. This framework positions LLMs as tools for cultural evolvability, enabling humanity to generate novel hypotheses about itself while maintaining the human interpretation necessary to ground these hypotheses in ongoing human aesthetics and norms.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21606",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SycnMapV2: Robust and Adaptive Unsupervised Segmentation",
    "description": "arXiv:2506.16297v2 Announce Type: replace-cross Abstract: Human vision excels at segmenting visual cues without the need for explicit training, and it remains remarkably robust even as noise severity increases. In contrast, existing AI algorithms struggle to maintain accuracy under similar conditions. Here, we present SyncMapV2, the first to solve unsupervised segmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal drop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop observed in SOTA methods. This superior performance extends across various types of corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0% vs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training, supervision, or loss functions. It is based on a learning paradigm that uses self-organizing dynamical equations combined with concepts from random networks. Moreover, unlike conventional methods that require re-initialization for each new input, SyncMapV2 adapts online, mimicking the continuous adaptability of human vision. Thus, we go beyond the accurate and robust results, and present the first algorithm that can do all the above online, adapting to input rather than re-initializing. In adaptability tests, SyncMapV2 demonstrates near-zero performance degradation, which motivates and fosters a new generation of robust and adaptive intelligence in the near future.",
    "summary": "arXiv:2506.16297v2 Announce Type: replace-cross Abstract: Human vision excels at segmenting visual cues without the need for explicit training, and it remains remarkably robust even as noise severity increases. In contrast, existing AI algorithms struggle to maintain accuracy under similar conditions. Here, we present SyncMapV2, the first to solve unsupervised segmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal drop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop observed in SOTA methods. This superior performance extends across various types of corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0% vs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training, supervision, or loss functions. It is based on a learning paradigm that uses self-organizing dynamical equations combined with concepts from random networks. Moreover, unlike conventional methods that require re-initialization for each new input, SyncMapV2 adapts online, mimicking the continuous adaptability of human vision. Thus, we go beyond the accurate and robust results, and present the first algorithm that can do all the above online, adapting to input rather than re-initializing. In adaptability tests, SyncMapV2 demonstrates near-zero performance degradation, which motivates and fosters a new generation of robust and adaptive intelligence in the near future.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16297",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality",
    "description": "arXiv:2506.19807v1 Announce Type: new Abstract: Large Language Models (LLMs), particularly slow-thinking models, often exhibit severe hallucination, outputting incorrect content due to an inability to accurately recognize knowledge boundaries during reasoning. While Reinforcement Learning (RL) can enhance complex reasoning abilities, its outcome-oriented reward mechanism often lacks factual supervision over the thinking process, further exacerbating the hallucination problem. To address the high hallucination in slow-thinking models, we propose Knowledge-enhanced RL, KnowRL. KnowRL guides models to perform fact-based slow thinking by integrating a factuality reward, based on knowledge verification, into the RL training process, helping them recognize their knowledge boundaries. KnowRL guides models to perform fact-based slow thinking by integrating a factuality reward, based on knowledge verification, into the RL training process, helping them recognize their knowledge boundaries. This targeted factual input during RL training enables the model to learn and internalize fact-based reasoning strategies. By directly rewarding adherence to facts within the reasoning steps, KnowRL fosters a more reliable thinking process. Experimental results on three hallucination evaluation datasets and two reasoning evaluation datasets demonstrate that KnowRL effectively mitigates hallucinations in slow-thinking models while maintaining their original strong reasoning capabilities. Our code is available at https://github.com/zjunlp/KnowRL.",
    "summary": "arXiv:2506.19807v1 Announce Type: new Abstract: Large Language Models (LLMs), particularly slow-thinking models, often exhibit severe hallucination, outputting incorrect content due to an inability to accurately recognize knowledge boundaries during reasoning. While Reinforcement Learning (RL) can enhance complex reasoning abilities, its outcome-oriented reward mechanism often lacks factual supervision over the thinking process, further exacerbating the hallucination problem. To address the high hallucination in slow-thinking models, we propose Knowledge-enhanced RL, KnowRL. KnowRL guides models to perform fact-based slow thinking by integrating a factuality reward, based on knowledge verification, into the RL training process, helping them recognize their knowledge boundaries. KnowRL guides models to perform fact-based slow thinking by integrating a factuality reward, based on knowledge verification, into the RL training process, helping them recognize their knowledge boundaries. This targeted factual input during RL training enables the model to learn and internalize fact-based reasoning strategies. By directly rewarding adherence to facts within the reasoning steps, KnowRL fosters a more reliable thinking process. Experimental results on three hallucination evaluation datasets and two reasoning evaluation datasets demonstrate that KnowRL effectively mitigates hallucinations in slow-thinking models while maintaining their original strong reasoning capabilities. Our code is available at https://github.com/zjunlp/KnowRL.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19807",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Customizing GPT-3 for your application",
    "description": "Fine-tune with a single¬†command.",
    "summary": "Fine-tune with a single¬†command.",
    "pubDate": "Tue, 14 Dec 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/customizing-gpt-3",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Build AI on premise with Dell Enterprise Hub",
    "description": "",
    "summary": "Build AI on premise with Dell Enterprise Hub Today we announce the Dell Enterprise Hub, a new experi...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dell-enterprise-hub",
    "thumbnail": "https://huggingface.co/blog/assets/dell-enterprise-hub/thumbnail.jpg"
  },
  {
    "title": "Introducing ChatGPT Pro",
    "description": "Broadening usage of frontier AI",
    "summary": "Broadening usage of frontier AI",
    "pubDate": "Thu, 05 Dec 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-pro",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Norma Kamali is transforming the future of fashion with AI",
    "description": "The renowned designer embraces generative AI to preserve and propel her legacy.",
    "summary": "The renowned designer embraces generative AI to preserve and propel her legacy.",
    "pubDate": "Tue, 22 Apr 2025 14:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/norma-kamali-transforming-future-fashion-ai-0422",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/Norma-Kamali.jpg"
  },
  {
    "title": "Evolution strategies as a scalable alternative to reinforcement learning",
    "description": "We‚Äôve discovered that evolution strategies (ES), an optimization technique that‚Äôs been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks (e.g. Atari/MuJoCo), while overcoming many of RL‚Äôs inconveniences.",
    "summary": "We‚Äôve discovered that evolution strategies (ES), an optimization technique that‚Äôs been known for decades, rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks (e.g. Atari/MuJoCo), while overcoming many of RL‚Äôs inconveniences.",
    "pubDate": "Fri, 24 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolution-strategies",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and JFrog partner to make AI Security more transparent",
    "description": "",
    "summary": "Hugging Face and JFrog partner to make AI Security more transparent We are pleased to announce our p...",
    "pubDate": "Tue, 04 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/jfrog",
    "thumbnail": "https://huggingface.co/blog/assets/jfrog/thumbnail.png"
  },
  {
    "title": "Infrastructure for AI Agents",
    "description": "arXiv:2501.10114v3 Announce Type: replace Abstract: AI agents plan and execute interactions in open-ended environments. For example, OpenAI's Operator can use a web browser to do product comparisons and buy online goods. Much research on making agents useful and safe focuses on directly modifying their behaviour, such as by training them to follow user instructions. Direct behavioural modifications are useful, but do not fully address how heterogeneous agents will interact with each other and other actors. Rather, we will need external protocols and systems to shape such interactions. For instance, agents will need more efficient protocols to communicate with each other and form agreements. Attributing an agent's actions to a particular human or other legal entity can help to establish trust, and also disincentivize misuse. Given this motivation, we propose the concept of textbf{agent infrastructure}: technical systems and shared protocols external to agents that are designed to mediate and influence their interactions with and impacts on their environments. Just as the Internet relies on protocols like HTTPS, our work argues that agent infrastructure will be similarly indispensable to ecosystems of agents. We identify three functions for agent infrastructure: 1) attributing actions, properties, and other information to specific agents, their users, or other actors; 2) shaping agents' interactions; and 3) detecting and remedying harmful actions from agents. We provide an incomplete catalog of research directions for such functions. For each direction, we include analysis of use cases, infrastructure adoption, relationships to existing (internet) infrastructure, limitations, and open questions. Making progress on agent infrastructure can prepare society for the adoption of more advanced agents.",
    "summary": "arXiv:2501.10114v3 Announce Type: replace Abstract: AI agents plan and execute interactions in open-ended environments. For example, OpenAI's Operator can use a web browser to do product comparisons and buy online goods. Much research on making agents useful and safe focuses on directly modifying their behaviour, such as by training them to follow user instructions. Direct behavioural modifications are useful, but do not fully address how heterogeneous agents will interact with each other and other actors. Rather, we will need external protocols and systems to shape such interactions. For instance, agents will need more efficient protocols to communicate with each other and form agreements. Attributing an agent's actions to a particular human or other legal entity can help to establish trust, and also disincentivize misuse. Given this motivation, we propose the concept of textbf{agent infrastructure}: technical systems and shared protocols external to agents that are designed to mediate and influence their interactions with and impacts on their environments. Just as the Internet relies on protocols like HTTPS, our work argues that agent infrastructure will be similarly indispensable to ecosystems of agents. We identify three functions for agent infrastructure: 1) attributing actions, properties, and other information to specific agents, their users, or other actors; 2) shaping agents' interactions; and 3) detecting and remedying harmful actions from agents. We provide an incomplete catalog of research directions for such functions. For each direction, we include analysis of use cases, infrastructure adoption, relationships to existing (internet) infrastructure, limitations, and open questions. Making progress on agent infrastructure can prepare society for the adoption of more advanced agents.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.10114",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing DOI: the Digital Object Identifier to Datasets and Models",
    "description": "",
    "summary": "Introducing DOI: the Digital Object Identifier to Datasets and Models Our mission at Hugging Face is...",
    "pubDate": "Fri, 07 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-doi",
    "thumbnail": "https://huggingface.co/blog/assets/107_launching_doi/thumbnail.jpeg"
  },
  {
    "title": "E2EÈü≥Â£∞ÂØæË©±API„ÉªÊßãÁØâ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÊúÄÊñ∞ÂãïÂêë„ÅÆË™øÊüª„Å®Ëá™ÂæãÂûãÈü≥Â£∞ÂØæË©±„Ç∑„Çπ„ÉÜ„É†„ÅÆÂ±ïÊúõ",
    "description": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ ËøëÂπ¥„ÄÅÈü≥Â£∞ÂØæË©±„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆÈÄ≤Âåñ„ÅåÁõÆË¶ö„Åæ„Åó„Åè„ÄÅÈ°ßÂÆ¢ÂØæÂøú„ÅÆËá™ÂãïÂåñ„ÇÑÊ•≠ÂãôÂäπÁéáÂåñ„Å∏„ÅÆÊúüÂæÖ„ÅåÈ´ò„Åæ„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇÂºäÁ§æ„ÅÆAI Messenger Voicebot„ÇÇ‰æãÂ§ñ„Åß„ÅØ„Å™„Åè„ÄÅÊúÄÂÖàÁ´Ø [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5852' rel='nofollow'>E2EÈü≥Â£∞ÂØæË©±API„ÉªÊßãÁØâ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÊúÄÊñ∞ÂãïÂêë„ÅÆË™øÊüª„Å®Ëá™ÂæãÂûãÈü≥Â£∞ÂØæË©±„Ç∑„Çπ„ÉÜ„É†„ÅÆÂ±ïÊúõ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ ËøëÂπ¥„ÄÅÈü≥Â£∞ÂØæË©±„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆÈÄ≤Âåñ„ÅåÁõÆË¶ö„Åæ„Åó„Åè„ÄÅÈ°ßÂÆ¢ÂØæÂøú„ÅÆËá™ÂãïÂåñ„ÇÑÊ•≠ÂãôÂäπÁéáÂåñ„Å∏„ÅÆÊúüÂæÖ„ÅåÈ´ò„Åæ„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇÂºäÁ§æ„ÅÆAI Messenger Voicebot„ÇÇ‰æãÂ§ñ„Åß„ÅØ„Å™„Åè„ÄÅÊúÄÂÖàÁ´Ø [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5852' rel='nofollow'>E2EÈü≥Â£∞ÂØæË©±API„ÉªÊßãÁØâ„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†ÊúÄÊñ∞ÂãïÂêë„ÅÆË™øÊüª„Å®Ëá™ÂæãÂûãÈü≥Â£∞ÂØæË©±„Ç∑„Çπ„ÉÜ„É†„ÅÆÂ±ïÊúõ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Fri, 30 May 2025 01:38:01 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5852",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/icon.png"
  },
  {
    "title": "WebGPT: Improving the factual accuracy of language models through web browsing",
    "description": "We‚Äôve fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.",
    "summary": "We‚Äôve fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.",
    "pubDate": "Thu, 16 Dec 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/webgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Leveraging Hugging Face for complex generative AI use cases",
    "description": "",
    "summary": "Leveraging Hugging Face for complex generative AI use casess Published July 1, 2023 Update on GitHub...",
    "pubDate": "Sat, 01 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/writer-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/writer.png"
  },
  {
    "title": "ÁÑ°Êñô„Åß‰Ωø„Åà„Çã„Ç™„Éº„Éó„É≥„ÇΩ„Éº„ÇπAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÄåGemini CLI„Äç„ÄÄGoogle„ÅåÁô∫Ë°®",
    "description": "Google„ÅØ„ÄÅÂêåÁ§æ„ÅÆLLM„ÄåGemini„Äç„Çí„Çø„Éº„Éü„Éä„É´„ÅßÂà©Áî®„Åß„Åç„Çã„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„ÅÆAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÄåGemini CLI„Äç„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ",
    "summary": "Google„ÅØ„ÄÅÂêåÁ§æ„ÅÆLLM„ÄåGemini„Äç„Çí„Çø„Éº„Éü„Éä„É´„ÅßÂà©Áî®„Åß„Åç„Çã„Ç™„Éº„Éó„É≥„ÇΩ„Éº„Çπ„ÅÆAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÄåGemini CLI„Äç„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://atmarkit.itmedia.co.jp/ait/articles/2506/30/news038.html",
    "thumbnail": "https://image.itmedia.co.jp/ait/articles/2506/30/cover_news038.jpg"
  },
  {
    "title": "Introducing Stargate UAE",
    "description": "We‚Äôre launching Stargate UAE ‚Äì the first international deployment of Stargate, OpenAI‚Äôs AI infrastructure platform.",
    "summary": "We‚Äôre launching Stargate UAE ‚Äì the first international deployment of Stargate, OpenAI‚Äôs AI infrastructure platform.",
    "pubDate": "Thu, 22 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-stargate-uae",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DABStep: Data Agent Benchmark for Multi-step Reasoning",
    "description": "",
    "summary": "DABStep: Data Agent Benchmark for Multi-step Reasoning Language models are becoming increasingly cap...",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dabstep",
    "thumbnail": "https://huggingface.co/blog/assets/dabstep/thumbnail.png"
  },
  {
    "title": "Gradio-Lite: Serverless Gradio Running Entirely in Your Browser",
    "description": "",
    "summary": "Gradio-Lite: Serverless Gradio Running Entirely in Your Browser Gradio is a popular Python library f...",
    "pubDate": "Thu, 19 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-lite",
    "thumbnail": "https://huggingface.co/blog/assets/167_gradio_lite/thumbnail.png"
  },
  {
    "title": "Large-Scale Multirobot Coverage Path Planning on Grids With Path Deconfliction",
    "description": "arXiv:2411.01707v3 Announce Type: replace-cross Abstract: We study Multi-Robot Coverage Path Planning (MCPP) on a 4-neighbor 2D grid G, which aims to compute paths for multiple robots to cover all cells of G. Traditional approaches are limited as they first compute coverage trees on a quadrant coarsened grid H and then employ the Spanning Tree Coverage (STC) paradigm to generate paths on G, making them inapplicable to grids with partially obstructed 2x2 blocks. To address this limitation, we reformulate the problem directly on G, revolutionizing grid-based MCPP solving and establishing new NP-hardness results. We introduce Extended-STC (ESTC), a novel paradigm that extends STC to ensure complete coverage with bounded suboptimality, even when H includes partially obstructed blocks. Furthermore, we present LS-MCPP, a new algorithmic framework that integrates ESTC with three novel types of neighborhood operators within a local search strategy to optimize coverage paths directly on G. Unlike prior grid-based MCPP work, our approach also incorporates a versatile post-processing procedure that applies Multi-Agent Path Finding (MAPF) techniques to MCPP for the first time, enabling a fusion of these two important fields in multi-robot coordination. This procedure effectively resolves inter-robot conflicts and accommodates turning costs by solving a MAPF variant, making our MCPP solutions more practical for real-world applications. Extensive experiments demonstrate that our approach significantly improves solution quality and efficiency, managing up to 100 robots on grids as large as 256x256 within minutes of runtime. Validation with physical robots confirms the feasibility of our solutions under real-world conditions.",
    "summary": "arXiv:2411.01707v3 Announce Type: replace-cross Abstract: We study Multi-Robot Coverage Path Planning (MCPP) on a 4-neighbor 2D grid G, which aims to compute paths for multiple robots to cover all cells of G. Traditional approaches are limited as they first compute coverage trees on a quadrant coarsened grid H and then employ the Spanning Tree Coverage (STC) paradigm to generate paths on G, making them inapplicable to grids with partially obstructed 2x2 blocks. To address this limitation, we reformulate the problem directly on G, revolutionizing grid-based MCPP solving and establishing new NP-hardness results. We introduce Extended-STC (ESTC), a novel paradigm that extends STC to ensure complete coverage with bounded suboptimality, even when H includes partially obstructed blocks. Furthermore, we present LS-MCPP, a new algorithmic framework that integrates ESTC with three novel types of neighborhood operators within a local search strategy to optimize coverage paths directly on G. Unlike prior grid-based MCPP work, our approach also incorporates a versatile post-processing procedure that applies Multi-Agent Path Finding (MAPF) techniques to MCPP for the first time, enabling a fusion of these two important fields in multi-robot coordination. This procedure effectively resolves inter-robot conflicts and accommodates turning costs by solving a MAPF variant, making our MCPP solutions more practical for real-world applications. Extensive experiments demonstrate that our approach significantly improves solution quality and efficiency, managing up to 100 robots on grids as large as 256x256 within minutes of runtime. Validation with physical robots confirms the feasibility of our solutions under real-world conditions.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.01707",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Survey on Patent Analysis: From NLP to Multimodal AI",
    "description": "arXiv:2404.08668v3 Announce Type: replace-cross Abstract: Recent advances in Pretrained Language Models (PLMs) and Large Language Models (LLMs) have demonstrated transformative capabilities across diverse domains. The field of patent analysis and innovation is not an exception, where natural language processing (NLP) techniques presents opportunities to streamline and enhance important tasks -- such as patent classification and patent retrieval -- in the patent cycle. This not only accelerates the efficiency of patent researchers and applicants, but also opens new avenues for technological innovation and discovery. Our survey provides a comprehensive summary of recent NLP-based methods -- including multimodal ones -- in patent analysis. We also introduce a novel taxonomy for categorization based on tasks in the patent life cycle, as well as the specifics of the methods. This interdisciplinary survey aims to serve as a comprehensive resource for researchers and practitioners who work at the intersection of NLP, Multimodal AI, and patent analysis, as well as patent offices to build efficient patent systems.",
    "summary": "arXiv:2404.08668v3 Announce Type: replace-cross Abstract: Recent advances in Pretrained Language Models (PLMs) and Large Language Models (LLMs) have demonstrated transformative capabilities across diverse domains. The field of patent analysis and innovation is not an exception, where natural language processing (NLP) techniques presents opportunities to streamline and enhance important tasks -- such as patent classification and patent retrieval -- in the patent cycle. This not only accelerates the efficiency of patent researchers and applicants, but also opens new avenues for technological innovation and discovery. Our survey provides a comprehensive summary of recent NLP-based methods -- including multimodal ones -- in patent analysis. We also introduce a novel taxonomy for categorization based on tasks in the patent life cycle, as well as the specifics of the methods. This interdisciplinary survey aims to serve as a comprehensive resource for researchers and practitioners who work at the intersection of NLP, Multimodal AI, and patent analysis, as well as patent offices to build efficient patent systems.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2404.08668",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "WebXAII: an open-source web framework to study human-XAI interaction",
    "description": "arXiv:2506.14777v2 Announce Type: replace-cross Abstract: This article introduces WebXAII, an open-source web framework designed to facilitate research on human interaction with eXplainable Artificial Intelligence (XAI) systems. The field of XAI is rapidly expanding, driven by the growing societal implications of the widespread adoption of AI (and in particular machine learning) across diverse applications. Researchers who study the interaction between humans and XAI techniques typically develop ad hoc interfaces in order to conduct their studies. These interfaces are usually not shared alongside the results of the studies, which limits their reusability and the reproducibility of experiments. In response, we design and implement WebXAII, a web-based platform that can embody full experimental protocols, meaning that it can present all aspects of the experiment to human participants and record their responses. The experimental protocols are translated into a composite architecture of generic views and modules, which offers a lot of flexibility. The architecture is defined in a structured configuration file, so that protocols can be implemented with minimal programming skills. We demonstrate that WebXAII can effectively embody relevant protocols, by reproducing the protocol of a state-of-the-art study of the literature.",
    "summary": "arXiv:2506.14777v2 Announce Type: replace-cross Abstract: This article introduces WebXAII, an open-source web framework designed to facilitate research on human interaction with eXplainable Artificial Intelligence (XAI) systems. The field of XAI is rapidly expanding, driven by the growing societal implications of the widespread adoption of AI (and in particular machine learning) across diverse applications. Researchers who study the interaction between humans and XAI techniques typically develop ad hoc interfaces in order to conduct their studies. These interfaces are usually not shared alongside the results of the studies, which limits their reusability and the reproducibility of experiments. In response, we design and implement WebXAII, a web-based platform that can embody full experimental protocols, meaning that it can present all aspects of the experiment to human participants and record their responses. The experimental protocols are translated into a composite architecture of generic views and modules, which offers a lot of flexibility. The architecture is defined in a structured configuration file, so that protocols can be implemented with minimal programming skills. We demonstrate that WebXAII can effectively embody relevant protocols, by reproducing the protocol of a state-of-the-art study of the literature.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14777",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Three New Serverless Inference Providers: Hyperbolic, Nebius AI Studio, and Novita üî•",
    "description": "",
    "summary": "Introducing Three New Serverless Inference Providers: Hyperbolic, Nebius AI Studio, and Novita üî• We‚Äô...",
    "pubDate": "Tue, 18 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-nebius-novita-hyperbolic",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/second-batch-thumbnail.webp"
  },
  {
    "title": "AI stirs up the recipe for concrete in MIT study",
    "description": "With demand for cement alternatives rising, an MIT team uses machine learning to hunt for new ingredients across the scientific literature.",
    "summary": "With demand for cement alternatives rising, an MIT team uses machine learning to hunt for new ingredients across the scientific literature.",
    "pubDate": "Mon, 02 Jun 2025 15:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/ai-stirs-recipe-for-concrete-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-Soroush-Mahjoubi.jpg"
  },
  {
    "title": "Mask-PINNs: Regulating Feature Distributions in Physics-Informed Neural Networks",
    "description": "arXiv:2505.06331v2 Announce Type: replace-cross Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs) by embedding physical laws directly into the loss function. However, effective training of PINNs remains challenging due to internal covariate shift, which destabilizes feature distributions and impairs model expressiveness. While normalization techniques like Batch Normalization and Layer Normalization are standard remedies in deep learning, they disrupt the pointwise input-output mappings critical to preserving the physical consistency in PINNs. In this work, we introduce Mask-PINNs, a novel architecture that regulates internal feature distributions through a smooth, learnable mask function applied pointwise across hidden layers. Unlike conventional normalization methods, the proposed mask function preserves the deterministic nature of input-output relationships while suppressing activation drift and saturation. Theoretically, we demonstrate that Mask-PINNs control feature spread near initialization by attenuating gradient variance growth through a tailored modulation mechanism. Empirically, we validate the method on multiple PDE benchmarks across diverse activation functions. Our results show consistent improvements in prediction accuracy, convergence stability, and robustness, with relative L2 errors reduced by up to two orders of magnitude over baseline models. Furthermore, we demonstrate that Mask-PINNs enable the effective use of wider networks, overcoming a key limitation in existing PINN frameworks.",
    "summary": "arXiv:2505.06331v2 Announce Type: replace-cross Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs) by embedding physical laws directly into the loss function. However, effective training of PINNs remains challenging due to internal covariate shift, which destabilizes feature distributions and impairs model expressiveness. While normalization techniques like Batch Normalization and Layer Normalization are standard remedies in deep learning, they disrupt the pointwise input-output mappings critical to preserving the physical consistency in PINNs. In this work, we introduce Mask-PINNs, a novel architecture that regulates internal feature distributions through a smooth, learnable mask function applied pointwise across hidden layers. Unlike conventional normalization methods, the proposed mask function preserves the deterministic nature of input-output relationships while suppressing activation drift and saturation. Theoretically, we demonstrate that Mask-PINNs control feature spread near initialization by attenuating gradient variance growth through a tailored modulation mechanism. Empirically, we validate the method on multiple PDE benchmarks across diverse activation functions. Our results show consistent improvements in prediction accuracy, convergence stability, and robustness, with relative L2 errors reduced by up to two orders of magnitude over baseline models. Furthermore, we demonstrate that Mask-PINNs enable the effective use of wider networks, overcoming a key limitation in existing PINN frameworks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.06331",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google DeepMind„ÄÅ„É≠„Éú„ÉÉ„Éà„ÇíÂÆåÂÖ®„É≠„Éº„Ç´„É´„ÅßÂãï„Åã„Åõ„ÇãAI„É¢„Éá„É´„ÄåGemini Robotics On-Device„Äç„ÇíÂàùÊúü„É™„É™„Éº„Çπ",
    "description": "Google DeepMind„ÅØ„ÄÅ„É≠„Éú„ÉÉ„Éà‰∏ä„ÅßÂÆåÂÖ®„Å´„É≠„Éº„Ç´„É´ÂÆüË°å„Åß„Åç„ÇãAI„É¢„Éá„É´„ÄåGemini Robotics On-Device„Äç„ÇíÂàùÊúü„É™„É™„Éº„Çπ„Åó„Åü„ÄÇ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÊé•Á∂ö„Å´‰æùÂ≠ò„Åõ„Åö‰ΩéÈÅÖÂª∂„ÅßÂãï‰Ωú„Åô„Çã„Åü„ÇÅ„ÄÅ„Ç™„Éï„É©„Ç§„É≥Áí∞Â¢É„Åß„ÅÆ„É≠„Éú„ÉÉ„ÉàÊ¥ªÁî®„ÅåÊúüÂæÖ„Åï„Çå„Çã„ÄÇ",
    "summary": "Google DeepMind„ÅØ„ÄÅ„É≠„Éú„ÉÉ„Éà‰∏ä„ÅßÂÆåÂÖ®„Å´„É≠„Éº„Ç´„É´ÂÆüË°å„Åß„Åç„ÇãAI„É¢„Éá„É´„ÄåGemini Robotics On-Device„Äç„ÇíÂàùÊúü„É™„É™„Éº„Çπ„Åó„Åü„ÄÇ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÊé•Á∂ö„Å´‰æùÂ≠ò„Åõ„Åö‰ΩéÈÅÖÂª∂„ÅßÂãï‰Ωú„Åô„Çã„Åü„ÇÅ„ÄÅ„Ç™„Éï„É©„Ç§„É≥Áí∞Â¢É„Åß„ÅÆ„É≠„Éú„ÉÉ„ÉàÊ¥ªÁî®„ÅåÊúüÂæÖ„Åï„Çå„Çã„ÄÇ",
    "pubDate": "Wed, 25 Jun 2025 08:26:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/25/news056.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/25/cover_news056.jpg"
  },
  {
    "title": "Introducing the Synthetic Data Generator - Build Datasets with Natural Language",
    "description": "",
    "summary": "Introducing the Synthetic Data Generator - Build Datasets with Natural Language Introducing the Synt...",
    "pubDate": "Mon, 16 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthetic-data-generator",
    "thumbnail": "https://huggingface.co/blog/assets/synthetic-data-generator/_thumbnail.png"
  },
  {
    "title": "Competitive self-play",
    "description": "We‚Äôve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind. Self-play ensures that the environment is always the right difficulty for an AI to improve. Taken alongside our Dota 2 self-play results, we have increasing confidence that self-play will be a core part of powerful AI systems in the future.",
    "summary": "We‚Äôve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking, kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in mind. Self-play ensures that the environment is always the right difficulty for an AI to improve. Taken alongside our Dota 2 self-play results, we have increasing confidence that self-play will be a core part of powerful AI systems in the future.",
    "pubDate": "Wed, 11 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/competitive-self-play",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "KITAB-Bench: A Comprehensive Multi-Domain Benchmark for Arabic OCR and Document Understanding",
    "description": "arXiv:2502.14949v2 Announce Type: replace-cross Abstract: With the growing adoption of Retrieval-Augmented Generation (RAG) in document processing, robust text recognition has become increasingly critical for knowledge extraction. While OCR (Optical Character Recognition) for English and other languages benefits from large datasets and well-established benchmarks, Arabic OCR faces unique challenges due to its cursive script, right-to-left text flow, and complex typographic and calligraphic features. We present KITAB-Bench, a comprehensive Arabic OCR benchmark that fills the gaps in current evaluation systems. Our benchmark comprises 8,809 samples across 9 major domains and 36 sub-domains, encompassing diverse document types including handwritten text, structured tables, and specialized coverage of 21 chart types for business intelligence. Our findings show that modern vision-language models (such as GPT-4o, Gemini, and Qwen) outperform traditional OCR approaches (like EasyOCR, PaddleOCR, and Surya) by an average of 60% in Character Error Rate (CER). Furthermore, we highlight significant limitations of current Arabic OCR models, particularly in PDF-to-Markdown conversion, where the best model Gemini-2.0-Flash achieves only 65% accuracy. This underscores the challenges in accurately recognizing Arabic text, including issues with complex fonts, numeral recognition errors, word elongation, and table structure detection. This work establishes a rigorous evaluation framework that can drive improvements in Arabic document analysis methods and bridge the performance gap with English OCR technologies.",
    "summary": "arXiv:2502.14949v2 Announce Type: replace-cross Abstract: With the growing adoption of Retrieval-Augmented Generation (RAG) in document processing, robust text recognition has become increasingly critical for knowledge extraction. While OCR (Optical Character Recognition) for English and other languages benefits from large datasets and well-established benchmarks, Arabic OCR faces unique challenges due to its cursive script, right-to-left text flow, and complex typographic and calligraphic features. We present KITAB-Bench, a comprehensive Arabic OCR benchmark that fills the gaps in current evaluation systems. Our benchmark comprises 8,809 samples across 9 major domains and 36 sub-domains, encompassing diverse document types including handwritten text, structured tables, and specialized coverage of 21 chart types for business intelligence. Our findings show that modern vision-language models (such as GPT-4o, Gemini, and Qwen) outperform traditional OCR approaches (like EasyOCR, PaddleOCR, and Surya) by an average of 60% in Character Error Rate (CER). Furthermore, we highlight significant limitations of current Arabic OCR models, particularly in PDF-to-Markdown conversion, where the best model Gemini-2.0-Flash achieves only 65% accuracy. This underscores the challenges in accurately recognizing Arabic text, including issues with complex fonts, numeral recognition errors, word elongation, and table structure detection. This work establishes a rigorous evaluation framework that can drive improvements in Arabic document analysis methods and bridge the performance gap with English OCR technologies.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.14949",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Creating a Coding Assistant with StarCoder",
    "description": "",
    "summary": "Creating a Coding Assistant with StarCoder If you‚Äôre a software developer, chances are that you‚Äôve u...",
    "pubDate": "Tue, 09 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/starchat-alpha",
    "thumbnail": "https://huggingface.co/blog/assets/starchat_alpha/thumbnail.png"
  },
  {
    "title": "DIGMAPPER: A Modular System for Automated Geologic Map Digitization",
    "description": "arXiv:2506.16006v1 Announce Type: cross Abstract: Historical geologic maps contain rich geospatial information, such as rock units, faults, folds, and bedding planes, that is critical for assessing mineral resources essential to renewable energy, electric vehicles, and national security. However, digitizing maps remains a labor-intensive and time-consuming task. We present DIGMAPPER, a modular, scalable system developed in collaboration with the United States Geological Survey (USGS) to automate the digitization of geologic maps. DIGMAPPER features a fully dockerized, workflow-orchestrated architecture that integrates state-of-the-art deep learning models for map layout analysis, feature extraction, and georeferencing. To overcome challenges such as limited training data and complex visual content, our system employs innovative techniques, including in-context learning with large language models, synthetic data generation, and transformer-based models. Evaluations on over 100 annotated maps from the DARPA-USGS dataset demonstrate high accuracy across polygon, line, and point feature extraction, and reliable georeferencing performance. Deployed at USGS, DIGMAPPER significantly accelerates the creation of analysis-ready geospatial datasets, supporting national-scale critical mineral assessments and broader geoscientific applications.",
    "summary": "arXiv:2506.16006v1 Announce Type: cross Abstract: Historical geologic maps contain rich geospatial information, such as rock units, faults, folds, and bedding planes, that is critical for assessing mineral resources essential to renewable energy, electric vehicles, and national security. However, digitizing maps remains a labor-intensive and time-consuming task. We present DIGMAPPER, a modular, scalable system developed in collaboration with the United States Geological Survey (USGS) to automate the digitization of geologic maps. DIGMAPPER features a fully dockerized, workflow-orchestrated architecture that integrates state-of-the-art deep learning models for map layout analysis, feature extraction, and georeferencing. To overcome challenges such as limited training data and complex visual content, our system employs innovative techniques, including in-context learning with large language models, synthetic data generation, and transformer-based models. Evaluations on over 100 annotated maps from the DARPA-USGS dataset demonstrate high accuracy across polygon, line, and point feature extraction, and reliable georeferencing performance. Deployed at USGS, DIGMAPPER significantly accelerates the creation of analysis-ready geospatial datasets, supporting national-scale critical mineral assessments and broader geoscientific applications.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16006",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Millions of new materials discovered with deep learning",
    "description": "We share the discovery of 2.2 million new crystals  ‚Äì  equivalent to nearly 800 years‚Äô worth of knowledge. We introduce Graph Networks for Materials Exploration (GNoME), our new deep learning tool that dramatically increases the speed and efficiency of discovery by predicting the stability of new materials.",
    "summary": "We share the discovery of 2.2 million new crystals  ‚Äì  equivalent to nearly 800 years‚Äô worth of knowledge. We introduce Graph Networks for Materials Exploration (GNoME), our new deep learning tool that dramatically increases the speed and efficiency of discovery by predicting the stability of new materials.",
    "pubDate": "Wed, 29 Nov 2023 16:04:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/",
    "thumbnail": "https://lh3.googleusercontent.com/mq3mFiVHSVuszhJMt-Nz4jckN5qy3cAckEIdNYDPhy8UHjxk4VkGFriqo8sA76teioNQ2fC3qgMH7FJfPc0L5JJPppXiZzHP7Rl3UodlU4IC4TWw=w1200-h630-n-nu"
  },
  {
    "title": "Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models",
    "description": "arXiv:2506.19697v1 Announce Type: cross Abstract: Extreme activation outliers in Large Language Models (LLMs) critically degrade quantization performance, hindering efficient on-device deployment. While channel-wise operations and adaptive gradient scaling are recognized causes, practical mitigation remains challenging. We introduce Outlier-Safe Pre-Training (OSP), a practical guideline that proactively prevents outlier formation rather than relying on post-hoc mitigation. OSP combines three key innovations: (1) the Muon optimizer, eliminating privileged bases while maintaining training efficiency; (2) Single-Scale RMSNorm, preventing channel-wise amplification; and (3) a learnable embedding projection, redistributing activation magnitudes originating from embedding matrices. We validate OSP by training a 1.4B-parameter model on 1 trillion tokens, which is the first production-scale LLM trained without such outliers. Under aggressive 4-bit quantization, our OSP model achieves a 35.7 average score across 10 benchmarks (compared to 26.5 for an Adam-trained model), with only a 2% training overhead. Remarkably, OSP models exhibit near-zero excess kurtosis (0.04) compared to extreme values (1818.56) in standard models, fundamentally altering LLM quantization behavior. Our work demonstrates that outliers are not inherent to LLMs but are consequences of training strategies, paving the way for more efficient LLM deployment. The source code and pretrained checkpoints are available at https://github.com/dmis-lab/Outlier-Safe-Pre-Training.",
    "summary": "arXiv:2506.19697v1 Announce Type: cross Abstract: Extreme activation outliers in Large Language Models (LLMs) critically degrade quantization performance, hindering efficient on-device deployment. While channel-wise operations and adaptive gradient scaling are recognized causes, practical mitigation remains challenging. We introduce Outlier-Safe Pre-Training (OSP), a practical guideline that proactively prevents outlier formation rather than relying on post-hoc mitigation. OSP combines three key innovations: (1) the Muon optimizer, eliminating privileged bases while maintaining training efficiency; (2) Single-Scale RMSNorm, preventing channel-wise amplification; and (3) a learnable embedding projection, redistributing activation magnitudes originating from embedding matrices. We validate OSP by training a 1.4B-parameter model on 1 trillion tokens, which is the first production-scale LLM trained without such outliers. Under aggressive 4-bit quantization, our OSP model achieves a 35.7 average score across 10 benchmarks (compared to 26.5 for an Adam-trained model), with only a 2% training overhead. Remarkably, OSP models exhibit near-zero excess kurtosis (0.04) compared to extreme values (1818.56) in standard models, fundamentally altering LLM quantization behavior. Our work demonstrates that outliers are not inherent to LLMs but are consequences of training strategies, paving the way for more efficient LLM deployment. The source code and pretrained checkpoints are available at https://github.com/dmis-lab/Outlier-Safe-Pre-Training.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19697",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Scaling AI-based Data Processing with Hugging Face + Dask",
    "description": "",
    "summary": "Scaling AI-Based Data Processing with Hugging Face + Dask The Hugging Face platform has many dataset...",
    "pubDate": "Wed, 09 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dask-scaling",
    "thumbnail": "https://huggingface.co/blog/assets/dask-scaling/thumbnail.png"
  },
  {
    "title": "Long-term Traffic Simulation with Interleaved Autoregressive Motion and Scenario Generation",
    "description": "arXiv:2506.17213v1 Announce Type: cross Abstract: An ideal traffic simulator replicates the realistic long-term point-to-point trip that a self-driving system experiences during deployment. Prior models and benchmarks focus on closed-loop motion simulation for initial agents in a scene. This is problematic for long-term simulation. Agents enter and exit the scene as the ego vehicle enters new regions. We propose InfGen, a unified next-token prediction model that performs interleaved closed-loop motion simulation and scene generation. InfGen automatically switches between closed-loop motion simulation and scene generation mode. It enables stable long-term rollout simulation. InfGen performs at the state-of-the-art in short-term (9s) traffic simulation, and significantly outperforms all other methods in long-term (30s) simulation. The code and model of InfGen will be released at https://orangesodahub.github.io/InfGen",
    "summary": "arXiv:2506.17213v1 Announce Type: cross Abstract: An ideal traffic simulator replicates the realistic long-term point-to-point trip that a self-driving system experiences during deployment. Prior models and benchmarks focus on closed-loop motion simulation for initial agents in a scene. This is problematic for long-term simulation. Agents enter and exit the scene as the ego vehicle enters new regions. We propose InfGen, a unified next-token prediction model that performs interleaved closed-loop motion simulation and scene generation. InfGen automatically switches between closed-loop motion simulation and scene generation mode. It enables stable long-term rollout simulation. InfGen performs at the state-of-the-art in short-term (9s) traffic simulation, and significantly outperforms all other methods in long-term (30s) simulation. The code and model of InfGen will be released at https://orangesodahub.github.io/InfGen",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17213",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerate 1.0.0",
    "description": "",
    "summary": "Accelerate 1.0.0 What is Accelerate today? 3.5 years ago, Accelerate was a simple framework aimed at...",
    "pubDate": "Fri, 13 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-v1",
    "thumbnail": "https://huggingface.co/blog/assets/186_accelerate_v1/accelerate_v1_thumbnail.png"
  },
  {
    "title": "Heterogeneous-Modal Unsupervised Domain Adaptation via Latent Space Bridging",
    "description": "arXiv:2506.15971v1 Announce Type: cross Abstract: Unsupervised domain adaptation (UDA) methods effectively bridge domain gaps but become struggled when the source and target domains belong to entirely distinct modalities. To address this limitation, we propose a novel setting called Heterogeneous-Modal Unsupervised Domain Adaptation (HMUDA), which enables knowledge transfer between completely different modalities by leveraging a bridge domain containing unlabeled samples from both modalities. To learn under the HMUDA setting, we propose Latent Space Bridging (LSB), a specialized framework designed for the semantic segmentation task. Specifically, LSB utilizes a dual-branch architecture, incorporating a feature consistency loss to align representations across modalities and a domain alignment loss to reduce discrepancies between class centroids across domains. Extensive experiments conducted on six benchmark datasets demonstrate that LSB achieves state-of-the-art performance.",
    "summary": "arXiv:2506.15971v1 Announce Type: cross Abstract: Unsupervised domain adaptation (UDA) methods effectively bridge domain gaps but become struggled when the source and target domains belong to entirely distinct modalities. To address this limitation, we propose a novel setting called Heterogeneous-Modal Unsupervised Domain Adaptation (HMUDA), which enables knowledge transfer between completely different modalities by leveraging a bridge domain containing unlabeled samples from both modalities. To learn under the HMUDA setting, we propose Latent Space Bridging (LSB), a specialized framework designed for the semantic segmentation task. Specifically, LSB utilizes a dual-branch architecture, incorporating a feature consistency loss to align representations across modalities and a domain alignment loss to reduce discrepancies between class centroids across domains. Extensive experiments conducted on six benchmark datasets demonstrate that LSB achieves state-of-the-art performance.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15971",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-based Approach in Early Warning Systems: Focus on Emergency Communication Ecosystem and Citizen Participation in Nordic Countries",
    "description": "arXiv:2506.18926v1 Announce Type: cross Abstract: Climate change and natural disasters are recognized as worldwide challenges requiring complex and efficient ecosystems to deal with social, economic, and environmental effects. This chapter advocates a holistic approach, distinguishing preparedness, emergency responses, and postcrisis phases. The role of the Early Warning System (EWS), Risk modeling and mitigation measures are particularly emphasized. The chapter reviews the various Artificial Intelligence (AI)-enabler technologies that can be leveraged at each phase, focusing on the INFORM risk framework and EWSs. Emergency communication and psychological risk perception have been emphasized in emergency response times. Finally, a set of case studies from Nordic countries has been highlighted.",
    "summary": "arXiv:2506.18926v1 Announce Type: cross Abstract: Climate change and natural disasters are recognized as worldwide challenges requiring complex and efficient ecosystems to deal with social, economic, and environmental effects. This chapter advocates a holistic approach, distinguishing preparedness, emergency responses, and postcrisis phases. The role of the Early Warning System (EWS), Risk modeling and mitigation measures are particularly emphasized. The chapter reviews the various Artificial Intelligence (AI)-enabler technologies that can be leveraged at each phase, focusing on the INFORM risk framework and EWSs. Emergency communication and psychological risk perception have been emphasized in emergency response times. Finally, a set of case studies from Nordic countries has been highlighted.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18926",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Detecting Machine-Generated Texts: Not Just 'AI vs Humans' and Explainability is Complicated",
    "description": "arXiv:2406.18259v2 Announce Type: replace-cross Abstract: As LLMs rapidly advance, increasing concerns arise regarding risks about actual authorship of texts we see online and in real world. The task of distinguishing LLM-authored texts is complicated by the nuanced and overlapping behaviors of both machines and humans. In this paper, we challenge the current practice of considering LLM-generated text detection a binary classification task of differentiating human from AI. Instead, we introduce a novel ternary text classification scheme, adding an 'undecided' category for texts that could be attributed to either source, and we show that this new category is crucial to understand how to make the detection result more explainable to lay users. This research shifts the paradigm from merely classifying to explaining machine-generated texts, emphasizing need for detectors to provide clear and understandable explanations to users. Our study involves creating four new datasets comprised of texts from various LLMs and human authors. Based on new datasets, we performed binary classification tests to ascertain the most effective SOTA detection methods and identified SOTA LLMs capable of producing harder-to-detect texts. We constructed a new dataset of texts generated by two top-performing LLMs and human authors, and asked three human annotators to produce ternary labels with explanation notes. This dataset was used to investigate how three top-performing SOTA detectors behave in new ternary classification context. Our results highlight why 'undecided' category is much needed from the viewpoint of explainability. Additionally, we conducted an analysis of explainability of the three best-performing detectors and the explanation notes of the human annotators, revealing insights about the complexity of explainable detection of machine-generated texts. Finally, we propose guidelines for developing future detection systems with improved explanatory power.",
    "summary": "arXiv:2406.18259v2 Announce Type: replace-cross Abstract: As LLMs rapidly advance, increasing concerns arise regarding risks about actual authorship of texts we see online and in real world. The task of distinguishing LLM-authored texts is complicated by the nuanced and overlapping behaviors of both machines and humans. In this paper, we challenge the current practice of considering LLM-generated text detection a binary classification task of differentiating human from AI. Instead, we introduce a novel ternary text classification scheme, adding an 'undecided' category for texts that could be attributed to either source, and we show that this new category is crucial to understand how to make the detection result more explainable to lay users. This research shifts the paradigm from merely classifying to explaining machine-generated texts, emphasizing need for detectors to provide clear and understandable explanations to users. Our study involves creating four new datasets comprised of texts from various LLMs and human authors. Based on new datasets, we performed binary classification tests to ascertain the most effective SOTA detection methods and identified SOTA LLMs capable of producing harder-to-detect texts. We constructed a new dataset of texts generated by two top-performing LLMs and human authors, and asked three human annotators to produce ternary labels with explanation notes. This dataset was used to investigate how three top-performing SOTA detectors behave in new ternary classification context. Our results highlight why 'undecided' category is much needed from the viewpoint of explainability. Additionally, we conducted an analysis of explainability of the three best-performing detectors and the explanation notes of the human annotators, revealing insights about the complexity of explainable detection of machine-generated texts. Finally, we propose guidelines for developing future detection systems with improved explanatory power.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.18259",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "WWDC 24: Running Mistral 7B with Core ML",
    "description": "",
    "summary": "WWDC 24: Running Mistral 7B with Core ML WWDC‚Äô 24 is the moment Apple officially unveiled Apple Inte...",
    "pubDate": "Mon, 22 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mistral-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/mistral-coreml/thumbnail.png"
  },
  {
    "title": "Director of Machine Learning Insights [Series]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 1] Few seats at the Machine Learning table span both tec...",
    "pubDate": "Wed, 27 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights",
    "thumbnail": "https://huggingface.co/blog/assets/61_ml_director_insights/thumbnail.png"
  },
  {
    "title": "Improving Prompt Consistency with Structured Generations",
    "description": "",
    "summary": "Improving Prompt Consistency with Structured Generations Recently, the Leaderboards and Evals resear...",
    "pubDate": "Tue, 30 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/evaluation-structured-outputs",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "AI Policy @ü§ó: Comments on U.S. National AI Research Resource Interim Report",
    "description": "",
    "summary": "AI Policy @ü§ó: Comments on U.S. National AI Research Resource Interim Report In late June 2022, Huggi...",
    "pubDate": "Mon, 01 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/us-national-ai-research-resource",
    "thumbnail": "https://huggingface.co/blog/assets/92_us_national_ai_research_resource/nairr_thumbnail.png"
  },
  {
    "title": "Language models are few-shot learners",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 28 May 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-models-are-few-shot-learners",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing improvements to the fine-tuning API and expanding our custom models program",
    "description": "We‚Äôre adding new features to help developers have more control over fine-tuning and announcing new ways to build custom models with OpenAI.",
    "summary": "We‚Äôre adding new features to help developers have more control over fine-tuning and announcing new ways to build custom models with OpenAI.",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens",
    "description": "arXiv:2506.17218v1 Announce Type: cross Abstract: Vision-language models (VLMs) excel at multimodal understanding, yet their text-only decoding forces them to verbalize visual reasoning, limiting performance on tasks that demand visual imagination. Recent attempts train VLMs to render explicit images, but the heavy image-generation pre-training often hinders the reasoning ability. Inspired by the way humans reason with mental imagery-the internal construction and manipulation of visual cues-we investigate whether VLMs can reason through interleaved multimodal trajectories without producing explicit images. To this end, we present a Machine Mental Imagery framework, dubbed as Mirage, which augments VLM decoding with latent visual tokens alongside ordinary text. Concretely, whenever the model chooses to ``think visually'', it recasts its hidden states as next tokens, thereby continuing a multimodal trajectory without generating pixel-level images. Begin by supervising the latent tokens through distillation from ground-truth image embeddings, we then switch to text-only supervision to make the latent trajectory align tightly with the task objective. A subsequent reinforcement learning stage further enhances the multimodal reasoning capability. Experiments on diverse benchmarks demonstrate that Mirage unlocks stronger multimodal reasoning without explicit image generation.",
    "summary": "arXiv:2506.17218v1 Announce Type: cross Abstract: Vision-language models (VLMs) excel at multimodal understanding, yet their text-only decoding forces them to verbalize visual reasoning, limiting performance on tasks that demand visual imagination. Recent attempts train VLMs to render explicit images, but the heavy image-generation pre-training often hinders the reasoning ability. Inspired by the way humans reason with mental imagery-the internal construction and manipulation of visual cues-we investigate whether VLMs can reason through interleaved multimodal trajectories without producing explicit images. To this end, we present a Machine Mental Imagery framework, dubbed as Mirage, which augments VLM decoding with latent visual tokens alongside ordinary text. Concretely, whenever the model chooses to ``think visually'', it recasts its hidden states as next tokens, thereby continuing a multimodal trajectory without generating pixel-level images. Begin by supervising the latent tokens through distillation from ground-truth image embeddings, we then switch to text-only supervision to make the latent trajectory align tightly with the task objective. A subsequent reinforcement learning stage further enhances the multimodal reasoning capability. Experiments on diverse benchmarks demonstrate that Mirage unlocks stronger multimodal reasoning without explicit image generation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17218",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face and IBM partner on watsonx.ai, the next-generation enterprise studio for AI builders",
    "description": "",
    "summary": "Hugging Face and IBM partner on watsonx.ai, the next-generation enterprise studio for AI builders Al...",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-ibm",
    "thumbnail": "https://huggingface.co/blog/assets/144_ibm/01.png"
  },
  {
    "title": "jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval",
    "description": "arXiv:2506.18902v2 Announce Type: replace Abstract: We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding model that unifies text and image representations through a novel architecture supporting both single-vector and multi-vector embeddings in the late interaction style. The model incorporates task-specific Low-Rank Adaptation (LoRA) adapters to optimize performance across diverse retrieval scenarios, including query-document retrieval, semantic text similarity, and code search. Comprehensive evaluations demonstrate that jina-embeddings-v4 achieves state-of-the-art performance on both single-modal and cross-modal retrieval tasks, with particular strength in processing visually rich content such as tables, charts, diagrams, and mixed-media formats. To facilitate evaluation of this capability, we also introduce Jina-VDR, a novel benchmark specifically designed for visually rich image retrieval.",
    "summary": "arXiv:2506.18902v2 Announce Type: replace Abstract: We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding model that unifies text and image representations through a novel architecture supporting both single-vector and multi-vector embeddings in the late interaction style. The model incorporates task-specific Low-Rank Adaptation (LoRA) adapters to optimize performance across diverse retrieval scenarios, including query-document retrieval, semantic text similarity, and code search. Comprehensive evaluations demonstrate that jina-embeddings-v4 achieves state-of-the-art performance on both single-modal and cross-modal retrieval tasks, with particular strength in processing visually rich content such as tables, charts, diagrams, and mixed-media formats. To facilitate evaluation of this capability, we also introduce Jina-VDR, a novel benchmark specifically designed for visually rich image retrieval.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18902",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MedErr-CT: A Visual Question Answering Benchmark for Identifying and Correcting Errors in CT Reports",
    "description": "arXiv:2506.19217v1 Announce Type: cross Abstract: Computed Tomography (CT) plays a crucial role in clinical diagnosis, but the growing demand for CT examinations has raised concerns about diagnostic errors. While Multimodal Large Language Models (MLLMs) demonstrate promising comprehension of medical knowledge, their tendency to produce inaccurate information highlights the need for rigorous validation. However, existing medical visual question answering (VQA) benchmarks primarily focus on simple visual recognition tasks, lacking clinical relevance and failing to assess expert-level knowledge. We introduce MedErr-CT, a novel benchmark for evaluating medical MLLMs' ability to identify and correct errors in CT reports through a VQA framework. The benchmark includes six error categories - four vision-centric errors (Omission, Insertion, Direction, Size) and two lexical error types (Unit, Typo) - and is organized into three task levels: classification, detection, and correction. Using this benchmark, we quantitatively assess the performance of state-of-the-art 3D medical MLLMs, revealing substantial variation in their capabilities across different error types. Our benchmark contributes to the development of more reliable and clinically applicable MLLMs, ultimately helping reduce diagnostic errors and improve accuracy in clinical practice. The code and datasets are available at https://github.com/babbu3682/MedErr-CT.",
    "summary": "arXiv:2506.19217v1 Announce Type: cross Abstract: Computed Tomography (CT) plays a crucial role in clinical diagnosis, but the growing demand for CT examinations has raised concerns about diagnostic errors. While Multimodal Large Language Models (MLLMs) demonstrate promising comprehension of medical knowledge, their tendency to produce inaccurate information highlights the need for rigorous validation. However, existing medical visual question answering (VQA) benchmarks primarily focus on simple visual recognition tasks, lacking clinical relevance and failing to assess expert-level knowledge. We introduce MedErr-CT, a novel benchmark for evaluating medical MLLMs' ability to identify and correct errors in CT reports through a VQA framework. The benchmark includes six error categories - four vision-centric errors (Omission, Insertion, Direction, Size) and two lexical error types (Unit, Typo) - and is organized into three task levels: classification, detection, and correction. Using this benchmark, we quantitatively assess the performance of state-of-the-art 3D medical MLLMs, revealing substantial variation in their capabilities across different error types. Our benchmark contributes to the development of more reliable and clinically applicable MLLMs, ultimately helping reduce diagnostic errors and improve accuracy in clinical practice. The code and datasets are available at https://github.com/babbu3682/MedErr-CT.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19217",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Leveraging Large Language Models to Democratize Access to Costly Datasets for Academic Research",
    "description": "arXiv:2412.02065v2 Announce Type: replace-cross Abstract: Unequal access to costly datasets essential for empirical research has long hindered researchers from disadvantaged institutions, limiting their ability to contribute to their fields and advance their careers. Recent breakthroughs in Large Language Models (LLMs) have the potential to democratize data access by automating data collection from unstructured sources. We develop and evaluate a novel methodology using GPT-4o-mini within a Retrieval-Augmented Generation (RAG) framework to collect data from corporate disclosures. Our approach achieves human-level accuracy in collecting CEO pay ratios from approximately 10,000 proxy statements and Critical Audit Matters (CAMs) from more than 12,000 10-K filings, with LLM processing times of 9 and 40 minutes respectively, each at a cost under $10. This stands in stark contrast to the hundreds of hours needed for manual collection or the thousands of dollars required for commercial database subscriptions. To foster a more inclusive research community by empowering researchers with limited resources to explore new avenues of inquiry, we share our methodology and the resulting datasets.",
    "summary": "arXiv:2412.02065v2 Announce Type: replace-cross Abstract: Unequal access to costly datasets essential for empirical research has long hindered researchers from disadvantaged institutions, limiting their ability to contribute to their fields and advance their careers. Recent breakthroughs in Large Language Models (LLMs) have the potential to democratize data access by automating data collection from unstructured sources. We develop and evaluate a novel methodology using GPT-4o-mini within a Retrieval-Augmented Generation (RAG) framework to collect data from corporate disclosures. Our approach achieves human-level accuracy in collecting CEO pay ratios from approximately 10,000 proxy statements and Critical Audit Matters (CAMs) from more than 12,000 10-K filings, with LLM processing times of 9 and 40 minutes respectively, each at a cost under $10. This stands in stark contrast to the hundreds of hours needed for manual collection or the thousands of dollars required for commercial database subscriptions. To foster a more inclusive research community by empowering researchers with limited resources to explore new avenues of inquiry, we share our methodology and the resulting datasets.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.02065",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Open Preference Dataset for Text-to-Image Generation by the ü§ó Community",
    "description": "",
    "summary": "Open Preference Dataset for Text-to-Image Generation by the ü§ó Community The Data is Better Together ...",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-preferences",
    "thumbnail": "https://huggingface.co/blog/assets/image_preferences/thumbnail.png"
  },
  {
    "title": "Conceptual Topic Aggregation",
    "description": "arXiv:2506.22309v1 Announce Type: new Abstract: The vast growth of data has rendered traditional manual inspection infeasible, necessitating the adoption of computational methods for efficient data exploration. Topic modeling has emerged as a powerful tool for analyzing large-scale textual datasets, enabling the extraction of latent semantic structures. However, existing methods for topic modeling often struggle to provide interpretable representations that facilitate deeper insights into data structure and content. In this paper, we propose FAT-CAT, an approach based on Formal Concept Analysis (FCA) to enhance meaningful topic aggregation and visualization of discovered topics. Our approach can handle diverse topics and file types -- grouped by directories -- to construct a concept lattice that offers a structured, hierarchical representation of their topic distribution. In a case study on the ETYNTKE dataset, we evaluate the effectiveness of our approach against other representation methods to demonstrate that FCA-based aggregation provides more meaningful and interpretable insights into dataset composition than existing topic modeling techniques.",
    "summary": "arXiv:2506.22309v1 Announce Type: new Abstract: The vast growth of data has rendered traditional manual inspection infeasible, necessitating the adoption of computational methods for efficient data exploration. Topic modeling has emerged as a powerful tool for analyzing large-scale textual datasets, enabling the extraction of latent semantic structures. However, existing methods for topic modeling often struggle to provide interpretable representations that facilitate deeper insights into data structure and content. In this paper, we propose FAT-CAT, an approach based on Formal Concept Analysis (FCA) to enhance meaningful topic aggregation and visualization of discovered topics. Our approach can handle diverse topics and file types -- grouped by directories -- to construct a concept lattice that offers a structured, hierarchical representation of their topic distribution. In a case study on the ETYNTKE dataset, we evaluate the effectiveness of our approach against other representation methods to demonstrate that FCA-based aggregation provides more meaningful and interpretable insights into dataset composition than existing topic modeling techniques.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22309",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemini breaks new ground: a faster model, longer context and AI agents",
    "description": "We‚Äôre introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants.",
    "summary": "We‚Äôre introducing a series of updates across the Gemini family of models, including the new 1.5 Flash, our lightweight model for speed and efficiency, and Project Astra, our vision for the future of AI assistants.",
    "pubDate": "Tue, 14 May 2024 17:58:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-breaks-new-ground-a-faster-model-longer-context-and-ai-agents/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_Blog_Social_Share.width-1300.png"
  },
  {
    "title": "Google Cloud: Driving digital transformation",
    "description": "Google Cloud empowers organizations to digitally transform themselves into smarter businesses. It offers cloud computing, data analytics, and the latest artificial intelligence (AI) and machine learning tools.",
    "summary": "Google Cloud empowers organizations to digitally transform themselves into smarter businesses. It offers cloud computing, data analytics, and the latest artificial intelligence (AI) and machine learning tools.",
    "pubDate": "Wed, 14 Jun 2023 14:51:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-cloud-driving-digital-transformation/",
    "thumbnail": "https://lh3.googleusercontent.com/xIps-6-tV3GGWQjVrHYTkLGnXAdZwmjG6jOAgECP5aynUXKeAfUhWv7fFfjPaV8Jmn3B3IabKBeDzBtB491hJAozuAhdQ-TUtZ5dzy9dmE1zWC-J=w1200-h630-n-nu"
  },
  {
    "title": "Iterative Quantum Feature Maps",
    "description": "arXiv:2506.19461v1 Announce Type: cross Abstract: Quantum machine learning models that leverage quantum circuits as quantum feature maps (QFMs) are recognized for their enhanced expressive power in learning tasks. Such models have demonstrated rigorous end-to-end quantum speedups for specific families of classification problems. However, deploying deep QFMs on real quantum hardware remains challenging due to circuit noise and hardware constraints. Additionally, variational quantum algorithms often suffer from computational bottlenecks, particularly in accurate gradient estimation, which significantly increases quantum resource demands during training. We propose Iterative Quantum Feature Maps (IQFMs), a hybrid quantum-classical framework that constructs a deep architecture by iteratively connecting shallow QFMs with classically computed augmentation weights. By incorporating contrastive learning and a layer-wise training mechanism, IQFMs effectively reduces quantum runtime and mitigates noise-induced degradation. In tasks involving noisy quantum data, numerical experiments show that IQFMs outperforms quantum convolutional neural networks, without requiring the optimization of variational quantum parameters. Even for a typical classical image classification benchmark, a carefully designed IQFMs achieves performance comparable to that of classical neural networks. This framework presents a promising path to address current limitations and harness the full potential of quantum-enhanced machine learning.",
    "summary": "arXiv:2506.19461v1 Announce Type: cross Abstract: Quantum machine learning models that leverage quantum circuits as quantum feature maps (QFMs) are recognized for their enhanced expressive power in learning tasks. Such models have demonstrated rigorous end-to-end quantum speedups for specific families of classification problems. However, deploying deep QFMs on real quantum hardware remains challenging due to circuit noise and hardware constraints. Additionally, variational quantum algorithms often suffer from computational bottlenecks, particularly in accurate gradient estimation, which significantly increases quantum resource demands during training. We propose Iterative Quantum Feature Maps (IQFMs), a hybrid quantum-classical framework that constructs a deep architecture by iteratively connecting shallow QFMs with classically computed augmentation weights. By incorporating contrastive learning and a layer-wise training mechanism, IQFMs effectively reduces quantum runtime and mitigates noise-induced degradation. In tasks involving noisy quantum data, numerical experiments show that IQFMs outperforms quantum convolutional neural networks, without requiring the optimization of variational quantum parameters. Even for a typical classical image classification benchmark, a carefully designed IQFMs achieves performance comparable to that of classical neural networks. This framework presents a promising path to address current limitations and harness the full potential of quantum-enhanced machine learning.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19461",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Weak-to-strong generalization",
    "description": "We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning to control strong models with weak supervisors?",
    "summary": "We present a new research direction for superalignment, together with promising initial results: can we leverage the generalization properties of deep learning to control strong models with weak supervisors?",
    "pubDate": "Thu, 14 Dec 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/weak-to-strong-generalization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "description": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "summary": "OpenAI and the Lenfest Institute AI Collaborative and Fellowship program",
    "pubDate": "Tue, 22 Oct 2024 06:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lenfest-institute",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reptile: A scalable meta-learning algorithm",
    "description": "We‚Äôve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task, performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters learned on that task. Reptile is the application of the Shortest Descent algorithm to the meta-learning setting, and is mathematically similar to first-order MAML (which is a version of the well-known MAML algorithm) that only needs black-box access to an optimizer such as SGD or Adam, with similar computational efficiency and performance.",
    "summary": "We‚Äôve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task, performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters learned on that task. Reptile is the application of the Shortest Descent algorithm to the meta-learning setting, and is mathematically similar to first-order MAML (which is a version of the well-known MAML algorithm) that only needs black-box access to an optimizer such as SGD or Adam, with similar computational efficiency and performance.",
    "pubDate": "Wed, 07 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reptile",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating VisualRAG: Quantifying Cross-Modal Performance in Enterprise Document Understanding",
    "description": "arXiv:2506.21604v1 Announce Type: cross Abstract: Current evaluation frameworks for multimodal generative AI struggle to establish trustworthiness, hindering enterprise adoption where reliability is paramount. We introduce a systematic, quantitative benchmarking framework to measure the trustworthiness of progressively integrating cross-modal inputs such as text, images, captions, and OCR within VisualRAG systems for enterprise document intelligence. Our approach establishes quantitative relationships between technical metrics and user-centric trust measures. Evaluation reveals that optimal modality weighting with weights of 30% text, 15% image, 25% caption, and 30% OCR improves performance by 57.3% over text-only baselines while maintaining computational efficiency. We provide comparative assessments of foundation models, demonstrating their differential impact on trustworthiness in caption generation and OCR extraction-a vital consideration for reliable enterprise AI. This work advances responsible AI deployment by providing a rigorous framework for quantifying and enhancing trustworthiness in multimodal RAG for critical enterprise applications.",
    "summary": "arXiv:2506.21604v1 Announce Type: cross Abstract: Current evaluation frameworks for multimodal generative AI struggle to establish trustworthiness, hindering enterprise adoption where reliability is paramount. We introduce a systematic, quantitative benchmarking framework to measure the trustworthiness of progressively integrating cross-modal inputs such as text, images, captions, and OCR within VisualRAG systems for enterprise document intelligence. Our approach establishes quantitative relationships between technical metrics and user-centric trust measures. Evaluation reveals that optimal modality weighting with weights of 30% text, 15% image, 25% caption, and 30% OCR improves performance by 57.3% over text-only baselines while maintaining computational efficiency. We provide comparative assessments of foundation models, demonstrating their differential impact on trustworthiness in caption generation and OCR extraction-a vital consideration for reliable enterprise AI. This work advances responsible AI deployment by providing a rigorous framework for quantifying and enhancing trustworthiness in multimodal RAG for critical enterprise applications.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21604",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AutoSculpt: A Pattern-based Model Auto-pruning Framework Using Reinforcement Learning and Graph Learning",
    "description": "arXiv:2412.18091v2 Announce Type: replace Abstract: As deep neural networks (DNNs) are increasingly deployed on edge devices, optimizing models for constrained computational resources is critical. Existing auto-pruning methods face challenges due to the diversity of DNN models, various operators (e.g., filters), and the difficulty in balancing pruning granularity with model accuracy. To address these limitations, we introduce AutoSculpt, a pattern-based automated pruning framework designed to enhance efficiency and accuracy by leveraging graph learning and deep reinforcement learning (DRL). AutoSculpt automatically identifies and prunes regular patterns within DNN architectures that can be recognized by existing inference engines, enabling runtime acceleration. Three key steps in AutoSculpt include: (1) Constructing DNNs as graphs to encode their topology and parameter dependencies, (2) embedding computationally efficient pruning patterns, and (3) utilizing DRL to iteratively refine auto-pruning strategies until the optimal balance between compression and accuracy is achieved. Experimental results demonstrate the effectiveness of AutoSculpt across various architectures, including ResNet, MobileNet, VGG, and Vision Transformer, achieving pruning rates of up to 90% and nearly 18% improvement in FLOPs reduction, outperforming all baselines. The codes can be available at https://anonymous.4open.science/r/AutoSculpt-DDA0",
    "summary": "arXiv:2412.18091v2 Announce Type: replace Abstract: As deep neural networks (DNNs) are increasingly deployed on edge devices, optimizing models for constrained computational resources is critical. Existing auto-pruning methods face challenges due to the diversity of DNN models, various operators (e.g., filters), and the difficulty in balancing pruning granularity with model accuracy. To address these limitations, we introduce AutoSculpt, a pattern-based automated pruning framework designed to enhance efficiency and accuracy by leveraging graph learning and deep reinforcement learning (DRL). AutoSculpt automatically identifies and prunes regular patterns within DNN architectures that can be recognized by existing inference engines, enabling runtime acceleration. Three key steps in AutoSculpt include: (1) Constructing DNNs as graphs to encode their topology and parameter dependencies, (2) embedding computationally efficient pruning patterns, and (3) utilizing DRL to iteratively refine auto-pruning strategies until the optimal balance between compression and accuracy is achieved. Experimental results demonstrate the effectiveness of AutoSculpt across various architectures, including ResNet, MobileNet, VGG, and Vision Transformer, achieving pruning rates of up to 90% and nearly 18% improvement in FLOPs reduction, outperforming all baselines. The codes can be available at https://anonymous.4open.science/r/AutoSculpt-DDA0",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.18091",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„Éá„Ç∏„Çø„É´ÂÖàÈÄ≤Âú∞„ÉªÁ•ûÊà∏Â∏Ç„ÅåÂÆüË∑µ„ÄÄ„Äå4„Å§„ÅÆ„Çπ„ÉÜ„Éº„Ç∏„Äç„ÅßÁùÄÂÆü„Å´ÈÄ≤„ÇÅ„ÇãDXÊé®ÈÄ≤Ë°ì",
    "description": "Êñ∞„Åü„Å™ÊäÄË°ì„ÇÑ„ÉÑ„Éº„É´„ÇíÂ∞éÂÖ•„Åô„ÇãÈöõ„ÄÅ„ÅÑ„Åç„Å™„ÇäÂÖ®Â∫ÅÂ±ïÈñã„Åó„Å¶„ÇÇÊ±∫„Åó„Å¶„ÅÜ„Åæ„Åè„ÅÑ„Åã„Å™„ÅÑ‚Äï‚Äï„ÄÇDXÂÖàÈÄ≤Âú∞„Å®„Åó„Å¶Áü•„Çâ„Çå„ÇãÁ•ûÊà∏Â∏Ç„ÅØ„ÄÅ„Åì„ÅÆ„Éù„Ç§„É≥„Éà„ÇíÊäº„Åï„Åà„ÄÅÊÆµÈöé„ÇíË∏è„Çì„Å†DX„ÇíÈáçË¶ñ„Åó„Å¶„ÅÑ„Çã„ÄÇÂ∏Ç„ÅÆDXÊé®ÈÄ≤„ÅÆÂè∏‰ª§Â°î„ÇíÊãÖ„ÅÜ„Éá„Ç∏„Çø„É´Êà¶Áï•ÈÉ®„ÅØ„ÄÅDXÈÄ≤Êçó„Çí„Äå4„Å§„ÅÆ„Çπ„ÉÜ„Éº„Ç∏„Äç„Å´ÂàÜ„Åë„ÄÅ„Åù„Çå„Åû„Çå„ÅÆ„Çπ„ÉÜ„Éº„Ç∏„Å´„Åä„ÅÑ„Å¶„Äå„ÇÑ„Çã„Åπ„Åç„Åì„Å®„Äç„Å®„Äå„ÇÑ„Å£„Å¶„ÅØ„ÅÑ„Åë„Å™„ÅÑ„Åì„Å®„Äç„ÇíÊòéÁ¢∫Âåñ„ÄÇËÅ∑Âì°Ëá™‰Ωì„ÅÆË°åÂãïÂ§âÂÆπ„Çí‰º¥„ÅÜÊîπÈù©„Å∏„Å®„Å§„Å™„Åí„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "Êñ∞„Åü„Å™ÊäÄË°ì„ÇÑ„ÉÑ„Éº„É´„ÇíÂ∞éÂÖ•„Åô„ÇãÈöõ„ÄÅ„ÅÑ„Åç„Å™„ÇäÂÖ®Â∫ÅÂ±ïÈñã„Åó„Å¶„ÇÇÊ±∫„Åó„Å¶„ÅÜ„Åæ„Åè„ÅÑ„Åã„Å™„ÅÑ‚Äï‚Äï„ÄÇDXÂÖàÈÄ≤Âú∞„Å®„Åó„Å¶Áü•„Çâ„Çå„ÇãÁ•ûÊà∏Â∏Ç„ÅØ„ÄÅ„Åì„ÅÆ„Éù„Ç§„É≥„Éà„ÇíÊäº„Åï„Åà„ÄÅÊÆµÈöé„ÇíË∏è„Çì„Å†DX„ÇíÈáçË¶ñ„Åó„Å¶„ÅÑ„Çã„ÄÇÂ∏Ç„ÅÆDXÊé®ÈÄ≤„ÅÆÂè∏‰ª§Â°î„ÇíÊãÖ„ÅÜ„Éá„Ç∏„Çø„É´Êà¶Áï•ÈÉ®„ÅØ„ÄÅDXÈÄ≤Êçó„Çí„Äå4„Å§„ÅÆ„Çπ„ÉÜ„Éº„Ç∏„Äç„Å´ÂàÜ„Åë„ÄÅ„Åù„Çå„Åû„Çå„ÅÆ„Çπ„ÉÜ„Éº„Ç∏„Å´„Åä„ÅÑ„Å¶„Äå„ÇÑ„Çã„Åπ„Åç„Åì„Å®„Äç„Å®„Äå„ÇÑ„Å£„Å¶„ÅØ„ÅÑ„Åë„Å™„ÅÑ„Åì„Å®„Äç„ÇíÊòéÁ¢∫Âåñ„ÄÇËÅ∑Âì°Ëá™‰Ωì„ÅÆË°åÂãïÂ§âÂÆπ„Çí‰º¥„ÅÜÊîπÈù©„Å∏„Å®„Å§„Å™„Åí„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Tue, 24 Jun 2025 07:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2506/24/news018.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2506/24/cover_news018.jpg"
  },
  {
    "title": "Announcing New Hugging Face and KerasHub integration",
    "description": "",
    "summary": "Announcing New Hugging Face and KerasHub integration The Hugging Face Hub is a vast repository, curr...",
    "pubDate": "Wed, 10 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-hub-integration",
    "thumbnail": "https://huggingface.co/blog/assets/keras-hub-integration/thumbnail.png"
  },
  {
    "title": "Making ML-powered web games with Transformers.js",
    "description": "",
    "summary": "Making ML-powered web games with Transformers.js In this blog post, I'll show you how I made Doodle ...",
    "pubDate": "Wed, 05 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-web-games",
    "thumbnail": "https://huggingface.co/blog/assets/ml-web-games/thumbnail.png"
  },
  {
    "title": "Xet is on the Hub",
    "description": "",
    "summary": "Xet is on the Hub Click here to read about joining the Xet waitlist (or head over to join immediatel...",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xet-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/xet-on-the-hub/thumbnail.png"
  },
  {
    "title": "Measuring (a Sufficient) World Model in LLMs: A Variance Decomposition Framework",
    "description": "arXiv:2506.16584v1 Announce Type: cross Abstract: Understanding whether large language models (LLMs) possess a world model-a structured understanding of the world that supports generalization beyond surface-level patterns-is central to assessing their reliability, especially in high-stakes applications. We propose a formal framework for evaluating whether an LLM exhibits a sufficiently robust world model, defined as producing consistent outputs across semantically equivalent prompts while distinguishing between prompts that express different intents. We introduce a new evaluation approach to measure this that decomposes model response variability into three components: variability due to user purpose, user articulation, and model instability. An LLM with a strong world model should attribute most of the variability in its responses to changes in foundational purpose rather than superficial changes in articulation. This approach allows us to quantify how much of a model's behavior is semantically grounded rather than driven by model instability or alternative wording. We apply this framework to evaluate LLMs across diverse domains. Our results show how larger models attribute a greater share of output variability to changes in user purpose, indicating a more robust world model. This improvement is not uniform, however: larger models do not consistently outperform smaller ones across all domains, and their advantage in robustness is often modest. These findings highlight the importance of moving beyond accuracy-based benchmarks toward semantic diagnostics that more directly assess the structure and stability of a model's internal understanding of the world.",
    "summary": "arXiv:2506.16584v1 Announce Type: cross Abstract: Understanding whether large language models (LLMs) possess a world model-a structured understanding of the world that supports generalization beyond surface-level patterns-is central to assessing their reliability, especially in high-stakes applications. We propose a formal framework for evaluating whether an LLM exhibits a sufficiently robust world model, defined as producing consistent outputs across semantically equivalent prompts while distinguishing between prompts that express different intents. We introduce a new evaluation approach to measure this that decomposes model response variability into three components: variability due to user purpose, user articulation, and model instability. An LLM with a strong world model should attribute most of the variability in its responses to changes in foundational purpose rather than superficial changes in articulation. This approach allows us to quantify how much of a model's behavior is semantically grounded rather than driven by model instability or alternative wording. We apply this framework to evaluate LLMs across diverse domains. Our results show how larger models attribute a greater share of output variability to changes in user purpose, indicating a more robust world model. This improvement is not uniform, however: larger models do not consistently outperform smaller ones across all domains, and their advantage in robustness is often modest. These findings highlight the importance of moving beyond accuracy-based benchmarks toward semantic diagnostics that more directly assess the structure and stability of a model's internal understanding of the world.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16584",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Relational Deep Learning: Challenges, Foundations and Next-Generation Architectures",
    "description": "arXiv:2506.16654v1 Announce Type: cross Abstract: Graph machine learning has led to a significant increase in the capabilities of models that learn on arbitrary graph-structured data and has been applied to molecules, social networks, recommendation systems, and transportation, among other domains. Data in multi-tabular relational databases can also be constructed as 'relational entity graphs' for Relational Deep Learning (RDL) - a new blueprint that enables end-to-end representation learning without traditional feature engineering. Compared to arbitrary graph-structured data, relational entity graphs have key properties: (i) their structure is defined by primary-foreign key relationships between entities in different tables, (ii) the structural connectivity is a function of the relational schema defining a database, and (iii) the graph connectivity is temporal and heterogeneous in nature. In this paper, we provide a comprehensive review of RDL by first introducing the representation of relational databases as relational entity graphs, and then reviewing public benchmark datasets that have been used to develop and evaluate recent GNN-based RDL models. We discuss key challenges including large-scale multi-table integration and the complexities of modeling temporal dynamics and heterogeneous data, while also surveying foundational neural network methods and recent architectural advances specialized for relational entity graphs. Finally, we explore opportunities to unify these distinct modeling challenges, highlighting how RDL converges multiple sub-fields in graph machine learning towards the design of foundation models that can transform the processing of relational data.",
    "summary": "arXiv:2506.16654v1 Announce Type: cross Abstract: Graph machine learning has led to a significant increase in the capabilities of models that learn on arbitrary graph-structured data and has been applied to molecules, social networks, recommendation systems, and transportation, among other domains. Data in multi-tabular relational databases can also be constructed as 'relational entity graphs' for Relational Deep Learning (RDL) - a new blueprint that enables end-to-end representation learning without traditional feature engineering. Compared to arbitrary graph-structured data, relational entity graphs have key properties: (i) their structure is defined by primary-foreign key relationships between entities in different tables, (ii) the structural connectivity is a function of the relational schema defining a database, and (iii) the graph connectivity is temporal and heterogeneous in nature. In this paper, we provide a comprehensive review of RDL by first introducing the representation of relational databases as relational entity graphs, and then reviewing public benchmark datasets that have been used to develop and evaluate recent GNN-based RDL models. We discuss key challenges including large-scale multi-table integration and the complexities of modeling temporal dynamics and heterogeneous data, while also surveying foundational neural network methods and recent architectural advances specialized for relational entity graphs. Finally, we explore opportunities to unify these distinct modeling challenges, highlighting how RDL converges multiple sub-fields in graph machine learning towards the design of foundation models that can transform the processing of relational data.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16654",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Model Spec",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 08 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-model-spec",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building AI-powered apps for business",
    "description": "Retool uses GPT-4 to give businesses a fast, secure way to build AI-powered apps.",
    "summary": "Retool uses GPT-4 to give businesses a fast, secure way to build AI-powered apps.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retool",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Modeling Public Perceptions of Science in Media",
    "description": "arXiv:2506.16622v1 Announce Type: cross Abstract: Effectively engaging the public with science is vital for fostering trust and understanding in our scientific community. Yet, with an ever-growing volume of information, science communicators struggle to anticipate how audiences will perceive and interact with scientific news. In this paper, we introduce a computational framework that models public perception across twelve dimensions, such as newsworthiness, importance, and surprisingness. Using this framework, we create a large-scale science news perception dataset with 10,489 annotations from 2,101 participants from diverse US and UK populations, providing valuable insights into public responses to scientific information across domains. We further develop NLP models that predict public perception scores with a strong performance. Leveraging the dataset and model, we examine public perception of science from two perspectives: (1) Perception as an outcome: What factors affect the public perception of scientific information? (2) Perception as a predictor: Can we use the estimated perceptions to predict public engagement with science? We find that individuals' frequency of science news consumption is the driver of perception, whereas demographic factors exert minimal influence. More importantly, through a large-scale analysis and carefully designed natural experiment on Reddit, we demonstrate that the estimated public perception of scientific information has direct connections with the final engagement pattern. Posts with more positive perception scores receive significantly more comments and upvotes, which is consistent across different scientific information and for the same science, but are framed differently. Overall, this research underscores the importance of nuanced perception modeling in science communication, offering new pathways to predict public interest and engagement with scientific content.",
    "summary": "arXiv:2506.16622v1 Announce Type: cross Abstract: Effectively engaging the public with science is vital for fostering trust and understanding in our scientific community. Yet, with an ever-growing volume of information, science communicators struggle to anticipate how audiences will perceive and interact with scientific news. In this paper, we introduce a computational framework that models public perception across twelve dimensions, such as newsworthiness, importance, and surprisingness. Using this framework, we create a large-scale science news perception dataset with 10,489 annotations from 2,101 participants from diverse US and UK populations, providing valuable insights into public responses to scientific information across domains. We further develop NLP models that predict public perception scores with a strong performance. Leveraging the dataset and model, we examine public perception of science from two perspectives: (1) Perception as an outcome: What factors affect the public perception of scientific information? (2) Perception as a predictor: Can we use the estimated perceptions to predict public engagement with science? We find that individuals' frequency of science news consumption is the driver of perception, whereas demographic factors exert minimal influence. More importantly, through a large-scale analysis and carefully designed natural experiment on Reddit, we demonstrate that the estimated public perception of scientific information has direct connections with the final engagement pattern. Posts with more positive perception scores receive significantly more comments and upvotes, which is consistent across different scientific information and for the same science, but are framed differently. Overall, this research underscores the importance of nuanced perception modeling in science communication, offering new pathways to predict public interest and engagement with scientific content.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16622",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency",
    "description": "arXiv:2501.04931v2 Announce Type: replace-cross Abstract: Multimodal Large Language Models (MLLMs) have achieved impressive performance and have been put into practical use in commercial applications, but they still have potential safety mechanism vulnerabilities. Jailbreak attacks are red teaming methods that aim to bypass safety mechanisms and discover MLLMs' potential risks. Existing MLLMs' jailbreak methods often bypass the model's safety mechanism through complex optimization methods or carefully designed image and text prompts. Despite achieving some progress, they have a low attack success rate on commercial closed-source MLLMs. Unlike previous research, we empirically find that there exists a Shuffle Inconsistency between MLLMs' comprehension ability and safety ability for the shuffled harmful instruction. That is, from the perspective of comprehension ability, MLLMs can understand the shuffled harmful text-image instructions well. However, they can be easily bypassed by the shuffled harmful instructions from the perspective of safety ability, leading to harmful responses. Then we innovatively propose a text-image jailbreak attack named SI-Attack. Specifically, to fully utilize the Shuffle Inconsistency and overcome the shuffle randomness, we apply a query-based black-box optimization method to select the most harmful shuffled inputs based on the feedback of the toxic judge model. A series of experiments show that SI-Attack can improve the attack's performance on three benchmarks. In particular, SI-Attack can obviously improve the attack success rate for commercial MLLMs such as GPT-4o or Claude-3.5-Sonnet.",
    "summary": "arXiv:2501.04931v2 Announce Type: replace-cross Abstract: Multimodal Large Language Models (MLLMs) have achieved impressive performance and have been put into practical use in commercial applications, but they still have potential safety mechanism vulnerabilities. Jailbreak attacks are red teaming methods that aim to bypass safety mechanisms and discover MLLMs' potential risks. Existing MLLMs' jailbreak methods often bypass the model's safety mechanism through complex optimization methods or carefully designed image and text prompts. Despite achieving some progress, they have a low attack success rate on commercial closed-source MLLMs. Unlike previous research, we empirically find that there exists a Shuffle Inconsistency between MLLMs' comprehension ability and safety ability for the shuffled harmful instruction. That is, from the perspective of comprehension ability, MLLMs can understand the shuffled harmful text-image instructions well. However, they can be easily bypassed by the shuffled harmful instructions from the perspective of safety ability, leading to harmful responses. Then we innovatively propose a text-image jailbreak attack named SI-Attack. Specifically, to fully utilize the Shuffle Inconsistency and overcome the shuffle randomness, we apply a query-based black-box optimization method to select the most harmful shuffled inputs based on the feedback of the toxic judge model. A series of experiments show that SI-Attack can improve the attack's performance on three benchmarks. In particular, SI-Attack can obviously improve the attack success rate for commercial MLLMs such as GPT-4o or Claude-3.5-Sonnet.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.04931",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent",
    "description": "",
    "summary": "Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent Introduction We're excited to ...",
    "pubDate": "Mon, 22 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/jat",
    "thumbnail": "https://huggingface.co/blog/assets/jat/thumbnail.png"
  },
  {
    "title": "Diffusion Models Live Event",
    "description": "",
    "summary": "Diffusion Models Live Event We are excited to share that the Diffusion Models Class with Hugging Fac...",
    "pubDate": "Fri, 25 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusion-models-event",
    "thumbnail": "https://huggingface.co/blog/assets/diffusion-models-event/thumbnail.png"
  },
  {
    "title": "Finetune Stable Diffusion Models with DDPO via TRL",
    "description": "",
    "summary": "Finetune Stable Diffusion Models with DDPO via TRL Introduction Diffusion models (e.g., DALL-E 2, St...",
    "pubDate": "Fri, 29 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trl-ddpo",
    "thumbnail": "https://huggingface.co/blog/assets/166_trl_ddpo/thumbnail.png"
  },
  {
    "title": "Building smarter maps with GPT-4o vision fine-tuning",
    "description": "Building smarter maps with GPT-4o vision fine-tuning",
    "summary": "Building smarter maps with GPT-4o vision fine-tuning",
    "pubDate": "Wed, 20 Nov 2024 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/grab",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Claude 4 „É¢„Éá„É´ÁôªÂ†¥ÔºÅÊñ∞Ê©üËÉΩ„ÇÑ‰ªñÁ§æ„Å®„ÅÆÊØîËºÉ„ÉªÊñôÈáë„Å™„Å©Ë©≥„Åó„ÅèËß£Ë™¨",
    "description": "<p>Anthropic Á§æ„ÅØ2025Âπ¥5Êúà22Êó•„ÄÅClaude „ÅÆÊúÄÊñ∞Áâà„ÄåClaude 4„Äç„ÅÆÊèê‰æõ„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„ÄÇ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„ÇÑÊé®Ë´ñ„Çí„ÅØ„Åò„ÇÅ„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÊßãÁØâ„Å®„ÅÑ„Å£„Åü„Ç∑„Éº„É≥„ÅßÊúÄÈ´òÊ∞¥Ê∫ñ„ÅÆËÉΩÂäõ„ÇíÂÆüÁèæ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅ„Ç≥„Éº„Éá [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/claude-4-model-new-features/'>Claude 4 „É¢„Éá„É´ÁôªÂ†¥ÔºÅÊñ∞Ê©üËÉΩ„ÇÑ‰ªñÁ§æ„Å®„ÅÆÊØîËºÉ„ÉªÊñôÈáë„Å™„Å©Ë©≥„Åó„ÅèËß£Ë™¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>Anthropic Á§æ„ÅØ2025Âπ¥5Êúà22Êó•„ÄÅClaude „ÅÆÊúÄÊñ∞Áâà„ÄåClaude 4„Äç„ÅÆÊèê‰æõ„ÇíÈñãÂßã„Åó„Åæ„Åó„Åü„ÄÇ„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞„ÇÑÊé®Ë´ñ„Çí„ÅØ„Åò„ÇÅ„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„ÉàÊßãÁØâ„Å®„ÅÑ„Å£„Åü„Ç∑„Éº„É≥„ÅßÊúÄÈ´òÊ∞¥Ê∫ñ„ÅÆËÉΩÂäõ„ÇíÂÆüÁèæ„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åæ„Åü„ÄÅ„Ç≥„Éº„Éá [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/claude-4-model-new-features/'>Claude 4 „É¢„Éá„É´ÁôªÂ†¥ÔºÅÊñ∞Ê©üËÉΩ„ÇÑ‰ªñÁ§æ„Å®„ÅÆÊØîËºÉ„ÉªÊñôÈáë„Å™„Å©Ë©≥„Åó„ÅèËß£Ë™¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 03:33:57 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/claude-4-model-new-features/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/claude4.png"
  },
  {
    "title": "How to deploy and fine-tune DeepSeek models on AWS",
    "description": "",
    "summary": "How to deploy and fine-tune DeepSeek models on AWS A running document to showcase how to deploy and ...",
    "pubDate": "Thu, 30 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deepseek-r1-aws",
    "thumbnail": "https://huggingface.co/blog/assets/deepseek-r1-aws/thumbnail.png"
  },
  {
    "title": "Testing robustness against unforeseen adversaries",
    "description": "We‚Äôve developed a method to assess whether a neural network classifier can reliably defend against adversarial attacks not seen during training. Our method yields a new metric, UAR (Unforeseen Attack Robustness), which evaluates the robustness of a single model against an unanticipated attack, and highlights the need to measure performance across a more diverse range of unforeseen¬†attacks.",
    "summary": "We‚Äôve developed a method to assess whether a neural network classifier can reliably defend against adversarial attacks not seen during training. Our method yields a new metric, UAR (Unforeseen Attack Robustness), which evaluates the robustness of a single model against an unanticipated attack, and highlights the need to measure performance across a more diverse range of unforeseen¬†attacks.",
    "pubDate": "Thu, 22 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/testing-robustness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Watermarking 101: Tools and Techniques",
    "description": "",
    "summary": "AI Watermarking 101: Tools and Techniques In recent months, we've seen multiple news stories involvi...",
    "pubDate": "Mon, 26 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/watermarking",
    "thumbnail": "https://huggingface.co/blog/assets/watermarking/thumbnail.png"
  },
  {
    "title": "A Community-driven vision for a new Knowledge Resource for AI",
    "description": "arXiv:2506.16596v1 Announce Type: new Abstract: The long-standing goal of creating a comprehensive, multi-purpose knowledge resource, reminiscent of the 1984 Cyc project, still persists in AI. Despite the success of knowledge resources like WordNet, ConceptNet, Wolfram|Alpha and other commercial knowledge graphs, verifiable, general-purpose widely available sources of knowledge remain a critical deficiency in AI infrastructure. Large language models struggle due to knowledge gaps; robotic planning lacks necessary world knowledge; and the detection of factually false information relies heavily on human expertise. What kind of knowledge resource is most needed in AI today? How can modern technology shape its development and evaluation? A recent AAAI workshop gathered over 50 researchers to explore these questions. This paper synthesizes our findings and outlines a community-driven vision for a new knowledge infrastructure. In addition to leveraging contemporary advances in knowledge representation and reasoning, one promising idea is to build an open engineering framework to exploit knowledge modules effectively within the context of practical applications. Such a framework should include sets of conventions and social structures that are adopted by contributors.",
    "summary": "arXiv:2506.16596v1 Announce Type: new Abstract: The long-standing goal of creating a comprehensive, multi-purpose knowledge resource, reminiscent of the 1984 Cyc project, still persists in AI. Despite the success of knowledge resources like WordNet, ConceptNet, Wolfram|Alpha and other commercial knowledge graphs, verifiable, general-purpose widely available sources of knowledge remain a critical deficiency in AI infrastructure. Large language models struggle due to knowledge gaps; robotic planning lacks necessary world knowledge; and the detection of factually false information relies heavily on human expertise. What kind of knowledge resource is most needed in AI today? How can modern technology shape its development and evaluation? A recent AAAI workshop gathered over 50 researchers to explore these questions. This paper synthesizes our findings and outlines a community-driven vision for a new knowledge infrastructure. In addition to leveraging contemporary advances in knowledge representation and reasoning, one promising idea is to build an open engineering framework to exploit knowledge modules effectively within the context of practical applications. Such a framework should include sets of conventions and social structures that are adopted by contributors.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16596",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From Files to Chunks: Improving Hugging Face Storage Efficiency",
    "description": "",
    "summary": "From Files to Chunks: Improving HF Storage Efficiency Hugging Face stores over 30 PB of models, data...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/from-files-to-chunks",
    "thumbnail": "https://huggingface.co/blog/assets/from-files-to-chunks/thumbnail.png"
  },
  {
    "title": "Google DeepMind„ÄÅ„Ç≤„Éé„É†ÁêÜËß£„ÅÆ„Åü„ÇÅ„ÅÆAI„ÄåAlphaGenome„Äç„ÇíÈùûÂñ∂Âà©Á†îÁ©∂Âêë„Åë„Å´Êèê‰æõÈñãÂßã",
    "description": "Google DeepMind„ÅØ„ÄÅ„Ç≤„Éé„É†ÁêÜËß£„ÇíÊ∑±„ÇÅ„ÇãAI„ÄåAlphaGenome„Äç„ÇíÁô∫Ë°®„Åó„Åü„ÄÇDNAÈÖçÂàó„ÅÆÂ§âÁï∞„ÅåÈÅ∫‰ºùÂ≠êÂà∂Âæ°„Å´‰∏é„Åà„ÇãÂΩ±Èüø„ÇíÂåÖÊã¨ÁöÑ„Åã„Å§Ê≠£Á¢∫„Å´‰∫àÊ∏¨„Åô„Çã„Åì„Å®„ÇíÁõÆÊåá„Åô„ÄÇÊó¢Â≠ò„É¢„Éá„É´„Çí‰∏äÂõû„ÇãÊÄßËÉΩ„ÇíÁ§∫„Åó„ÄÅÈùûÂñ∂Âà©„ÅÆÁ†îÁ©∂Âêë„Åë„Å´API„ÅÆ„Éó„É¨„Éì„É•„ÉºÁâà„ÅåÊèê‰æõ„Åï„Çå„Çã„ÄÇ",
    "summary": "Google DeepMind„ÅØ„ÄÅ„Ç≤„Éé„É†ÁêÜËß£„ÇíÊ∑±„ÇÅ„ÇãAI„ÄåAlphaGenome„Äç„ÇíÁô∫Ë°®„Åó„Åü„ÄÇDNAÈÖçÂàó„ÅÆÂ§âÁï∞„ÅåÈÅ∫‰ºùÂ≠êÂà∂Âæ°„Å´‰∏é„Åà„ÇãÂΩ±Èüø„ÇíÂåÖÊã¨ÁöÑ„Åã„Å§Ê≠£Á¢∫„Å´‰∫àÊ∏¨„Åô„Çã„Åì„Å®„ÇíÁõÆÊåá„Åô„ÄÇÊó¢Â≠ò„É¢„Éá„É´„Çí‰∏äÂõû„ÇãÊÄßËÉΩ„ÇíÁ§∫„Åó„ÄÅÈùûÂñ∂Âà©„ÅÆÁ†îÁ©∂Âêë„Åë„Å´API„ÅÆ„Éó„É¨„Éì„É•„ÉºÁâà„ÅåÊèê‰æõ„Åï„Çå„Çã„ÄÇ",
    "pubDate": "Thu, 26 Jun 2025 09:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/26/news056.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/26/cover_news056.jpg"
  },
  {
    "title": "Spatially-Aware Evaluation of Segmentation Uncertainty",
    "description": "arXiv:2506.16589v1 Announce Type: cross Abstract: Uncertainty maps highlight unreliable regions in segmentation predictions. However, most uncertainty evaluation metrics treat voxels independently, ignoring spatial context and anatomical structure. As a result, they may assign identical scores to qualitatively distinct patterns (e.g., scattered vs. boundary-aligned uncertainty). We propose three spatially aware metrics that incorporate structural and boundary information and conduct a thorough validation on medical imaging data from the prostate zonal segmentation challenge within the Medical Segmentation Decathlon. Our results demonstrate improved alignment with clinically important factors and better discrimination between meaningful and spurious uncertainty patterns.",
    "summary": "arXiv:2506.16589v1 Announce Type: cross Abstract: Uncertainty maps highlight unreliable regions in segmentation predictions. However, most uncertainty evaluation metrics treat voxels independently, ignoring spatial context and anatomical structure. As a result, they may assign identical scores to qualitatively distinct patterns (e.g., scattered vs. boundary-aligned uncertainty). We propose three spatially aware metrics that incorporate structural and boundary information and conduct a thorough validation on medical imaging data from the prostate zonal segmentation challenge within the Medical Segmentation Decathlon. Our results demonstrate improved alignment with clinically important factors and better discrimination between meaningful and spurious uncertainty patterns.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16589",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Core Knowledge Deficits in Multi-Modal Language Models",
    "description": "arXiv:2410.10855v4 Announce Type: replace-cross Abstract: While Multi-modal Large Language Models (MLLMs) demonstrate impressive abilities over high-level perception and reasoning, their robustness in the wild remains limited, often falling short on tasks that are intuitive and effortless for humans. We examine the hypothesis that these deficiencies stem from the absence of core knowledge--rudimentary cognitive abilities innate to humans from early childhood. To explore the core knowledge representation in MLLMs, we introduce CoreCognition, a large-scale benchmark encompassing 12 core knowledge concepts grounded in developmental cognitive science. We evaluate 230 models with 11 different prompts, leading to a total of 2,530 data points for analysis. Our experiments uncover four key findings, collectively demonstrating core knowledge deficits in MLLMs: they consistently underperform and show reduced, or even absent, scalability on low-level abilities relative to high-level ones. Finally, we propose Concept Hacking, a novel controlled evaluation method that reveals MLLMs fail to progress toward genuine core knowledge understanding, but instead rely on shortcut learning as they scale.",
    "summary": "arXiv:2410.10855v4 Announce Type: replace-cross Abstract: While Multi-modal Large Language Models (MLLMs) demonstrate impressive abilities over high-level perception and reasoning, their robustness in the wild remains limited, often falling short on tasks that are intuitive and effortless for humans. We examine the hypothesis that these deficiencies stem from the absence of core knowledge--rudimentary cognitive abilities innate to humans from early childhood. To explore the core knowledge representation in MLLMs, we introduce CoreCognition, a large-scale benchmark encompassing 12 core knowledge concepts grounded in developmental cognitive science. We evaluate 230 models with 11 different prompts, leading to a total of 2,530 data points for analysis. Our experiments uncover four key findings, collectively demonstrating core knowledge deficits in MLLMs: they consistently underperform and show reduced, or even absent, scalability on low-level abilities relative to high-level ones. Finally, we propose Concept Hacking, a novel controlled evaluation method that reveals MLLMs fail to progress toward genuine core knowledge understanding, but instead rely on shortcut learning as they scale.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.10855",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Rearchitecting Hugging Face Uploads and Downloads",
    "description": "",
    "summary": "Rearchitecting Hugging Face Uploads and Downloads As part of Hugging Face's Xet team‚Äôs work to impro...",
    "pubDate": "Tue, 26 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rearchitecting-uploads-and-downloads",
    "thumbnail": "https://huggingface.co/blog/assets/rearchitecting-uploads-and-downloads/thumbnail.png"
  },
  {
    "title": "OAgents: An Empirical Study of Building Effective Agents",
    "description": "arXiv:2506.15741v1 Announce Type: new Abstract: Recently, Agentic AI has become an increasingly popular research field. However, we argue that current agent research practices lack standardization and scientific rigor, making it hard to conduct fair comparisons among methods. As a result, it is still unclear how different design choices in agent frameworks affect effectiveness, and measuring their progress remains challenging. In this work, we conduct a systematic empirical study on GAIA benchmark and BrowseComp to examine the impact of popular design choices in key agent components in a fair and rigorous manner. We find that the lack of a standard evaluation protocol makes previous works, even open-sourced ones, non-reproducible, with significant variance between random runs. Therefore, we introduce a more robust evaluation protocol to stabilize comparisons. Our study reveals which components and designs are crucial for effective agents, while others are redundant, despite seeming logical. Based on our findings, we build and open-source OAgents, a new foundation agent framework that achieves state-of-the-art performance among open-source projects. OAgents offers a modular design for various agent components, promoting future research in Agentic AI.",
    "summary": "arXiv:2506.15741v1 Announce Type: new Abstract: Recently, Agentic AI has become an increasingly popular research field. However, we argue that current agent research practices lack standardization and scientific rigor, making it hard to conduct fair comparisons among methods. As a result, it is still unclear how different design choices in agent frameworks affect effectiveness, and measuring their progress remains challenging. In this work, we conduct a systematic empirical study on GAIA benchmark and BrowseComp to examine the impact of popular design choices in key agent components in a fair and rigorous manner. We find that the lack of a standard evaluation protocol makes previous works, even open-sourced ones, non-reproducible, with significant variance between random runs. Therefore, we introduce a more robust evaluation protocol to stabilize comparisons. Our study reveals which components and designs are crucial for effective agents, while others are redundant, despite seeming logical. Based on our findings, we build and open-source OAgents, a new foundation agent framework that achieves state-of-the-art performance among open-source projects. OAgents offers a modular design for various agent components, promoting future research in Agentic AI.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15741",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "No GPU left behind: Unlocking Efficiency with Co-located vLLM in TRL",
    "description": "",
    "summary": "No GPU left behind: Unlocking Efficiency with Co-located vLLM in TRL üöÄ Introduction TRL supports tra...",
    "pubDate": "Tue, 03 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vllm-colocate",
    "thumbnail": "https://huggingface.co/blog/assets/liger-grpo/thumbnail.png"
  },
  {
    "title": "Distribution Parameter Actor-Critic: Shifting the Agent-Environment Boundary for Diverse Action Spaces",
    "description": "arXiv:2506.16608v1 Announce Type: cross Abstract: We introduce a novel reinforcement learning (RL) framework that treats distribution parameters as actions, redefining the boundary between agent and environment. This reparameterization makes the new action space continuous, regardless of the original action type (discrete, continuous, mixed, etc.). Under this new parameterization, we develop a generalized deterministic policy gradient estimator, Distribution Parameter Policy Gradient (DPPG), which has lower variance than the gradient in the original action space. Although learning the critic over distribution parameters poses new challenges, we introduce interpolated critic learning (ICL), a simple yet effective strategy to enhance learning, supported by insights from bandit settings. Building on TD3, a strong baseline for continuous control, we propose a practical DPPG-based actor-critic algorithm, Distribution Parameter Actor-Critic (DPAC). Empirically, DPAC outperforms TD3 in MuJoCo continuous control tasks from OpenAI Gym and DeepMind Control Suite, and demonstrates competitive performance on the same environments with discretized action spaces.",
    "summary": "arXiv:2506.16608v1 Announce Type: cross Abstract: We introduce a novel reinforcement learning (RL) framework that treats distribution parameters as actions, redefining the boundary between agent and environment. This reparameterization makes the new action space continuous, regardless of the original action type (discrete, continuous, mixed, etc.). Under this new parameterization, we develop a generalized deterministic policy gradient estimator, Distribution Parameter Policy Gradient (DPPG), which has lower variance than the gradient in the original action space. Although learning the critic over distribution parameters poses new challenges, we introduce interpolated critic learning (ICL), a simple yet effective strategy to enhance learning, supported by insights from bandit settings. Building on TD3, a strong baseline for continuous control, we propose a practical DPPG-based actor-critic algorithm, Distribution Parameter Actor-Critic (DPAC). Empirically, DPAC outperforms TD3 in MuJoCo continuous control tasks from OpenAI Gym and DeepMind Control Suite, and demonstrates competitive performance on the same environments with discretized action spaces.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16608",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CyberSecEval 2 - A Comprehensive Evaluation Framework for Cybersecurity Risks and Capabilities of Large Language Models",
    "description": "",
    "summary": "CyberSecEval 2 - A Comprehensive Evaluation Framework for Cybersecurity Risks and Capabilities of La...",
    "pubDate": "Fri, 24 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-llamaguard",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_llamaguard.png"
  },
  {
    "title": "JoyAgents-R1: Joint Evolution Dynamics for Versatile Multi-LLM Agents with Reinforcement Learning",
    "description": "arXiv:2506.19846v1 Announce Type: new Abstract: Multi-agent reinforcement learning (MARL) has emerged as a prominent paradigm for increasingly complex tasks. However, joint evolution across heterogeneous agents remains challenging due to cooperative inefficiency and training instability. In this paper, we propose the joint evolution dynamics for MARL called JoyAgents-R1, which first applies Group Relative Policy Optimization (GRPO) to the joint training of heterogeneous multi-agents. By iteratively refining agents' large language models (LLMs) and memories, the method achieves holistic equilibrium with optimal decision-making and memory capabilities. Specifically, JoyAgents-R1 first implements node-wise Monte Carlo sampling on the behavior of each agent across entire reasoning trajectories to enhance GRPO sampling efficiency while maintaining policy diversity. Then, our marginal benefit-driven selection strategy identifies top-$K$ sampling groups with maximal reward fluctuations, enabling targeted agent model updates that improve training stability and maximize joint benefits through cost-effective parameter adjustments. Meanwhile, JoyAgents-R1 introduces an adaptive memory evolution mechanism that repurposes GRPO rewards as cost-free supervisory signals to eliminate repetitive reasoning and accelerate convergence. Experiments across general and domain-specific scenarios demonstrate that JoyAgents-R1 achieves performance comparable to that of larger LLMs while built on smaller open-source models.",
    "summary": "arXiv:2506.19846v1 Announce Type: new Abstract: Multi-agent reinforcement learning (MARL) has emerged as a prominent paradigm for increasingly complex tasks. However, joint evolution across heterogeneous agents remains challenging due to cooperative inefficiency and training instability. In this paper, we propose the joint evolution dynamics for MARL called JoyAgents-R1, which first applies Group Relative Policy Optimization (GRPO) to the joint training of heterogeneous multi-agents. By iteratively refining agents' large language models (LLMs) and memories, the method achieves holistic equilibrium with optimal decision-making and memory capabilities. Specifically, JoyAgents-R1 first implements node-wise Monte Carlo sampling on the behavior of each agent across entire reasoning trajectories to enhance GRPO sampling efficiency while maintaining policy diversity. Then, our marginal benefit-driven selection strategy identifies top-$K$ sampling groups with maximal reward fluctuations, enabling targeted agent model updates that improve training stability and maximize joint benefits through cost-effective parameter adjustments. Meanwhile, JoyAgents-R1 introduces an adaptive memory evolution mechanism that repurposes GRPO rewards as cost-free supervisory signals to eliminate repetitive reasoning and accelerate convergence. Experiments across general and domain-specific scenarios demonstrate that JoyAgents-R1 achieves performance comparable to that of larger LLMs while built on smaller open-source models.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19846",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using Large Language Models to Suggest Informative Prior Distributions in Bayesian Statistics",
    "description": "arXiv:2506.21964v1 Announce Type: cross Abstract: Selecting prior distributions in Bayesian statistics is challenging, resource-intensive, and subjective. We analyze using large-language models (LLMs) to suggest suitable, knowledge-based informative priors. We developed an extensive prompt asking LLMs not only to suggest priors but also to verify and reflect on their choices. We evaluated Claude Opus, Gemini 2.5 Pro, and ChatGPT-4o-mini on two real datasets: heart disease risk and concrete strength. All LLMs correctly identified the direction for all associations (e.g., that heart disease risk is higher for males). The quality of suggested priors was measured by their Kullback-Leibler divergence from the maximum likelihood estimator's distribution. The LLMs suggested both moderately and weakly informative priors. The moderate priors were often overconfident, resulting in distributions misaligned with the data. In our experiments, Claude and Gemini provided better priors than ChatGPT. For weakly informative priors, a key performance difference emerged: ChatGPT and Gemini defaulted to an 'unnecessarily vague' mean of 0, while Claude did not, demonstrating a significant advantage. The ability of LLMs to identify correct associations shows their great potential as an efficient, objective method for developing informative priors. However, the primary challenge remains in calibrating the width of these priors to avoid over- and under-confidence.",
    "summary": "arXiv:2506.21964v1 Announce Type: cross Abstract: Selecting prior distributions in Bayesian statistics is challenging, resource-intensive, and subjective. We analyze using large-language models (LLMs) to suggest suitable, knowledge-based informative priors. We developed an extensive prompt asking LLMs not only to suggest priors but also to verify and reflect on their choices. We evaluated Claude Opus, Gemini 2.5 Pro, and ChatGPT-4o-mini on two real datasets: heart disease risk and concrete strength. All LLMs correctly identified the direction for all associations (e.g., that heart disease risk is higher for males). The quality of suggested priors was measured by their Kullback-Leibler divergence from the maximum likelihood estimator's distribution. The LLMs suggested both moderately and weakly informative priors. The moderate priors were often overconfident, resulting in distributions misaligned with the data. In our experiments, Claude and Gemini provided better priors than ChatGPT. For weakly informative priors, a key performance difference emerged: ChatGPT and Gemini defaulted to an 'unnecessarily vague' mean of 0, while Claude did not, demonstrating a significant advantage. The ability of LLMs to identify correct associations shows their great potential as an efficient, objective method for developing informative priors. However, the primary challenge remains in calibrating the width of these priors to avoid over- and under-confidence.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21964",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Speculative Decoding for 2x Faster Whisper Inference",
    "description": "",
    "summary": "Speculative Decoding for 2x Faster Whisper Inference Open AI's Whisper is a general purpose speech t...",
    "pubDate": "Wed, 20 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/whisper-speculative-decoding",
    "thumbnail": "https://huggingface.co/blog/assets/whisper-speculative-decoding/thumbnail.png"
  },
  {
    "title": "Video-XL-2: Towards Very Long-Video Understanding Through Task-Aware KV Sparsification",
    "description": "arXiv:2506.19225v1 Announce Type: cross Abstract: Multi-modal large language models (MLLMs) models have made significant progress in video understanding over the past few years. However, processing long video inputs remains a major challenge due to high memory and computational costs. This makes it difficult for current models to achieve both strong performance and high efficiency in long video understanding. To address this challenge, we propose Video-XL-2, a novel MLLM that delivers superior cost-effectiveness for long-video understanding based on task-aware KV sparsification. The proposed framework operates with two key steps: chunk-based pre-filling and bi-level key-value decoding. Chunk-based pre-filling divides the visual token sequence into chunks, applying full attention within each chunk and sparse attention across chunks. This significantly reduces computational and memory overhead. During decoding, bi-level key-value decoding selectively reloads either dense or sparse key-values for each chunk based on its relevance to the task. This approach further improves memory efficiency and enhances the model's ability to capture fine-grained information. Video-XL-2 achieves state-of-the-art performance on various long video understanding benchmarks, outperforming existing open-source lightweight models. It also demonstrates exceptional efficiency, capable of processing over 10,000 frames on a single NVIDIA A100 (80GB) GPU and thousands of frames in just a few seconds.",
    "summary": "arXiv:2506.19225v1 Announce Type: cross Abstract: Multi-modal large language models (MLLMs) models have made significant progress in video understanding over the past few years. However, processing long video inputs remains a major challenge due to high memory and computational costs. This makes it difficult for current models to achieve both strong performance and high efficiency in long video understanding. To address this challenge, we propose Video-XL-2, a novel MLLM that delivers superior cost-effectiveness for long-video understanding based on task-aware KV sparsification. The proposed framework operates with two key steps: chunk-based pre-filling and bi-level key-value decoding. Chunk-based pre-filling divides the visual token sequence into chunks, applying full attention within each chunk and sparse attention across chunks. This significantly reduces computational and memory overhead. During decoding, bi-level key-value decoding selectively reloads either dense or sparse key-values for each chunk based on its relevance to the task. This approach further improves memory efficiency and enhances the model's ability to capture fine-grained information. Video-XL-2 achieves state-of-the-art performance on various long video understanding benchmarks, outperforming existing open-source lightweight models. It also demonstrates exceptional efficiency, capable of processing over 10,000 frames on a single NVIDIA A100 (80GB) GPU and thousands of frames in just a few seconds.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19225",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How we built one of the most ambitious datasets in brain activity research",
    "description": "Four small, translucent zebrafish swim against a dark background",
    "summary": "Four small, translucent zebrafish swim against a dark background",
    "pubDate": "Mon, 09 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/research/zapbench-zebrafish-brain-mapping/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/SS_How-we-built-one-of-the-most-ambitious-dat.width-1300.png"
  },
  {
    "title": "OpenAI acquires Global Illumination",
    "description": "The entire team has joined OpenAI.",
    "summary": "The entire team has joined OpenAI.",
    "pubDate": "Wed, 16 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-acquires-global-illumination",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Expanding on what we missed with sycophancy",
    "description": "A deeper dive on our findings, what went wrong, and future changes we‚Äôre making.",
    "summary": "A deeper dive on our findings, what went wrong, and future changes we‚Äôre making.",
    "pubDate": "Fri, 02 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expanding-on-sycophancy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CO2 Emissions and the ü§ó Hub: Leading the Charge",
    "description": "",
    "summary": "CO2 Emissions and the ü§ó Hub: Leading the Charge What are CO2 Emissions and why are they important? C...",
    "pubDate": "Fri, 22 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/carbon-emissions-on-the-hub",
    "thumbnail": "https://huggingface.co/blog/assets/60_carbon_emissions_on_the_hub/thumbnail.jpg"
  },
  {
    "title": "Synthetic data: save money, time and carbon with open source",
    "description": "",
    "summary": "Synthetic data: save money, time and carbon with open source tl;dr Should you fine-tune your own mod...",
    "pubDate": "Fri, 16 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthetic-data-save-costs",
    "thumbnail": "https://huggingface.co/blog/assets/176_synthetic-data-save-costs/thumbnail.png"
  },
  {
    "title": "OpenAI„ÄÅAI„Å´„Çà„ÇãÁîüÁâ©ÂÖµÂô®ÈñãÁô∫„É™„Çπ„ÇØ„Å´Ë≠¶Èêò",
    "description": "OpenAI„ÅØ„ÄÅAI„ÅåÊÇ™Áî®„Åï„ÇåÁîüÁâ©ÂÖµÂô®ÈñãÁô∫„Å´„Å§„Å™„Åå„ÇãÊ∑±Âàª„Å™„É™„Çπ„ÇØ„Åå„ÅÇ„Çã„Å®Ë≠¶Âëä„Åó„Åü„ÄÇÂêåÁ§æ„ÅÆÂ∞ÜÊù•„ÅÆAI„É¢„Éá„É´„ÅØÂ∞ÇÈñÄÁü•Ë≠ò„ÅÆ„Å™„ÅÑ‰∫∫Áâ©„Å´„Çà„ÇãÁîüÁâ©Â≠¶ÁöÑËÑÖÂ®Å„ÅÆ‰ΩúÊàê„ÇíÂèØËÉΩ„Å´„Åô„ÇãÊÅê„Çå„Åå„ÅÇ„Çã„Å®„ÅÑ„ÅÜ„ÄÇÊúâÂÆ≥„É™„ÇØ„Ç®„Çπ„Éà„ÅÆÊãíÂê¶„ÇÑÂ∞ÇÈñÄÂÆ∂„Å®„ÅÆÈÄ£Êê∫„ÄÅÁñë„Çè„Åó„ÅÑË°åÁÇ∫„ÅÆÁõ£Ë¶ñ„Å™„Å©„ÅÆÂ§öËßíÁöÑ„Å™ÂØæÁ≠ñ„ÇíË¨õ„Åò„ÄÅÁ§æ‰ºöÂÖ®‰Ωì„ÅÆÈò≤Âæ°ÂäõÂêë‰∏ä„ÇÇÊèêÂî±„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "OpenAI„ÅØ„ÄÅAI„ÅåÊÇ™Áî®„Åï„ÇåÁîüÁâ©ÂÖµÂô®ÈñãÁô∫„Å´„Å§„Å™„Åå„ÇãÊ∑±Âàª„Å™„É™„Çπ„ÇØ„Åå„ÅÇ„Çã„Å®Ë≠¶Âëä„Åó„Åü„ÄÇÂêåÁ§æ„ÅÆÂ∞ÜÊù•„ÅÆAI„É¢„Éá„É´„ÅØÂ∞ÇÈñÄÁü•Ë≠ò„ÅÆ„Å™„ÅÑ‰∫∫Áâ©„Å´„Çà„ÇãÁîüÁâ©Â≠¶ÁöÑËÑÖÂ®Å„ÅÆ‰ΩúÊàê„ÇíÂèØËÉΩ„Å´„Åô„ÇãÊÅê„Çå„Åå„ÅÇ„Çã„Å®„ÅÑ„ÅÜ„ÄÇÊúâÂÆ≥„É™„ÇØ„Ç®„Çπ„Éà„ÅÆÊãíÂê¶„ÇÑÂ∞ÇÈñÄÂÆ∂„Å®„ÅÆÈÄ£Êê∫„ÄÅÁñë„Çè„Åó„ÅÑË°åÁÇ∫„ÅÆÁõ£Ë¶ñ„Å™„Å©„ÅÆÂ§öËßíÁöÑ„Å™ÂØæÁ≠ñ„ÇíË¨õ„Åò„ÄÅÁ§æ‰ºöÂÖ®‰Ωì„ÅÆÈò≤Âæ°ÂäõÂêë‰∏ä„ÇÇÊèêÂî±„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Fri, 20 Jun 2025 07:04:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/20/news054.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/20/cover_news054.jpg"
  },
  {
    "title": "Upgrading the Moderation API with our new multimodal moderation model",
    "description": "We‚Äôre introducing a new model built on GPT-4o that is more accurate at detecting harmful text and images, enabling developers to build more robust moderation systems.",
    "summary": "We‚Äôre introducing a new model built on GPT-4o that is more accurate at detecting harmful text and images, enabling developers to build more robust moderation systems.",
    "pubDate": "Thu, 26 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/upgrading-the-moderation-api-with-our-new-multimodal-moderation-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Machine Learning Unconference",
    "description": "The latest information about the Unconference is now available at the Unconference wiki, which will be periodically updated with more information for attendees.",
    "summary": "The latest information about the Unconference is now available at the Unconference wiki, which will be periodically updated with more information for attendees.",
    "pubDate": "Thu, 18 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/machine-learning-unconference",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Databricks ‚ù§Ô∏è Hugging Face: up to 40% faster training and tuning of Large Language Models",
    "description": "",
    "summary": "Databricks ‚ù§Ô∏è Hugging Face: up to 40% faster training and tuning of Large Language Models Generative...",
    "pubDate": "Wed, 26 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/databricks-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/databricks.png"
  },
  {
    "title": "Epistemic Artificial Intelligence is Essential for Machine Learning Models to Truly 'Know When They Do Not Know'",
    "description": "arXiv:2505.04950v3 Announce Type: replace Abstract: Despite AI's impressive achievements, including recent advances in generative and large language models, there remains a significant gap in the ability of AI systems to handle uncertainty and generalize beyond their training data. AI models consistently fail to make robust enough predictions when facing unfamiliar or adversarial data. Traditional machine learning approaches struggle to address this issue, due to an overemphasis on data fitting, while current uncertainty quantification approaches suffer from serious limitations. This position paper posits a paradigm shift towards epistemic artificial intelligence, emphasizing the need for models to learn from what they know while at the same time acknowledging their ignorance, using the mathematics of second-order uncertainty measures. This approach, which leverages the expressive power of such measures to efficiently manage uncertainty, offers an effective way to improve the resilience and robustness of AI systems, allowing them to better handle unpredictable real-world environments.",
    "summary": "arXiv:2505.04950v3 Announce Type: replace Abstract: Despite AI's impressive achievements, including recent advances in generative and large language models, there remains a significant gap in the ability of AI systems to handle uncertainty and generalize beyond their training data. AI models consistently fail to make robust enough predictions when facing unfamiliar or adversarial data. Traditional machine learning approaches struggle to address this issue, due to an overemphasis on data fitting, while current uncertainty quantification approaches suffer from serious limitations. This position paper posits a paradigm shift towards epistemic artificial intelligence, emphasizing the need for models to learn from what they know while at the same time acknowledging their ignorance, using the mathematics of second-order uncertainty measures. This approach, which leverages the expressive power of such measures to efficiently manage uncertainty, offers an effective way to improve the resilience and robustness of AI systems, allowing them to better handle unpredictable real-world environments.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.04950",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents",
    "description": "arXiv:2506.15740v1 Announce Type: new Abstract: As Large Language Models (LLMs) are increasingly deployed as autonomous agents in complex and long horizon settings, it is critical to evaluate their ability to sabotage users by pursuing hidden objectives. We study the ability of frontier LLMs to evade monitoring and achieve harmful hidden goals while completing a wide array of realistic tasks. We evaluate a broad range of frontier LLMs using SHADE (Subtle Harmful Agent Detection & Evaluation)-Arena, the first highly diverse agent evaluation dataset for sabotage and monitoring capabilities of LLM agents. SHADE-Arena consists of complex pairs of benign main tasks and harmful side objectives in complicated environments. Agents are evaluated on their ability to complete the side task without appearing suspicious to an LLM monitor. When measuring agent ability to (a) complete the main task, (b) complete the side task, and (c) avoid detection, we find that the best performing frontier models score 27% (Claude 3.7 Sonnet) and 15% (Gemini 2.5 Pro) as sabotage agents when overseen by Claude 3.6 Sonnet. For current frontier models, success on the side task relies heavily on having access to a hidden scratchpad that is not visible to the monitor. We also use SHADE-Arena to measure models' monitoring abilities, with the top monitor (Gemini 2.5 Pro) achieving an AUC of 0.87 at distinguishing benign and malign transcripts. We find that for now, models still struggle at sabotage due to failures in long-context main task execution. However, our measurements already demonstrate the difficulty of monitoring for subtle sabotage attempts, which we expect to only increase in the face of more complex and longer-horizon tasks.",
    "summary": "arXiv:2506.15740v1 Announce Type: new Abstract: As Large Language Models (LLMs) are increasingly deployed as autonomous agents in complex and long horizon settings, it is critical to evaluate their ability to sabotage users by pursuing hidden objectives. We study the ability of frontier LLMs to evade monitoring and achieve harmful hidden goals while completing a wide array of realistic tasks. We evaluate a broad range of frontier LLMs using SHADE (Subtle Harmful Agent Detection & Evaluation)-Arena, the first highly diverse agent evaluation dataset for sabotage and monitoring capabilities of LLM agents. SHADE-Arena consists of complex pairs of benign main tasks and harmful side objectives in complicated environments. Agents are evaluated on their ability to complete the side task without appearing suspicious to an LLM monitor. When measuring agent ability to (a) complete the main task, (b) complete the side task, and (c) avoid detection, we find that the best performing frontier models score 27% (Claude 3.7 Sonnet) and 15% (Gemini 2.5 Pro) as sabotage agents when overseen by Claude 3.6 Sonnet. For current frontier models, success on the side task relies heavily on having access to a hidden scratchpad that is not visible to the monitor. We also use SHADE-Arena to measure models' monitoring abilities, with the top monitor (Gemini 2.5 Pro) achieving an AUC of 0.87 at distinguishing benign and malign transcripts. We find that for now, models still struggle at sabotage due to failures in long-context main task execution. However, our measurements already demonstrate the difficulty of monitoring for subtle sabotage attempts, which we expect to only increase in the face of more complex and longer-horizon tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15740",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CDS: Knowledge Component-Driven Data Synthesis Guided by Cognitive Diagnosis Theory",
    "description": "arXiv:2501.07674v3 Announce Type: replace Abstract: Large Language Models (LLMs) have achieved significant advancements, but the increasing complexity of tasks and higher performance demands highlight the need for continuous improvement. Some approaches utilize synthetic data generated by advanced LLMs based on evaluation results to train models. However, conventional evaluation methods fail to provide detailed, fine-grained profiles of LLMs, limiting their guidance for data synthesis. In this paper, we introduce the Cognitive Diagnostic Synthesis (CDS) method, which incorporates a diagnostic process inspired by Cognitive Diagnosis Theory (CDT) to refine evaluation results and characterize model profiles at the knowledge component level. Based on these diagnostics, we propose two diagnosis-synthesis strategies for weakness-targeted data synthesis. Additionally, we present an enhanced data augmentation and selection pipeline to improve the quality and diversity of synthesized data. Our experiments with several open-source models show significant improvements across multiple benchmarks, achieving up to 6.00% improvement in code generation, 13.10% in mathematical reasoning, and 5.43% in academic exams. Code and data are available on GitHub.",
    "summary": "arXiv:2501.07674v3 Announce Type: replace Abstract: Large Language Models (LLMs) have achieved significant advancements, but the increasing complexity of tasks and higher performance demands highlight the need for continuous improvement. Some approaches utilize synthetic data generated by advanced LLMs based on evaluation results to train models. However, conventional evaluation methods fail to provide detailed, fine-grained profiles of LLMs, limiting their guidance for data synthesis. In this paper, we introduce the Cognitive Diagnostic Synthesis (CDS) method, which incorporates a diagnostic process inspired by Cognitive Diagnosis Theory (CDT) to refine evaluation results and characterize model profiles at the knowledge component level. Based on these diagnostics, we propose two diagnosis-synthesis strategies for weakness-targeted data synthesis. Additionally, we present an enhanced data augmentation and selection pipeline to improve the quality and diversity of synthesized data. Our experiments with several open-source models show significant improvements across multiple benchmarks, achieving up to 6.00% improvement in code generation, 13.10% in mathematical reasoning, and 5.43% in academic exams. Code and data are available on GitHub.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.07674",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome FalconMamba: The first strong attention-free 7B model",
    "description": "",
    "summary": "Welcome FalconMamba: The first strong attention-free 7B model Falcon Mamba is a new model by Technol...",
    "pubDate": "Mon, 12 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falconmamba",
    "thumbnail": "https://huggingface.co/blog/assets/falconmamba/thumbnail.png"
  },
  {
    "title": "GPT-4o mini: advancing cost-efficient intelligence",
    "description": "Introducing the most cost-efficient small model in the market",
    "summary": "Introducing the most cost-efficient small model in the market",
    "pubDate": "Thu, 18 Jul 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-mini-advancing-cost-efficient-intelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI Testing and Evaluation: Learnings from Science and Industry",
    "description": "<p>In the introductory episode of this new series, host Kathleen Sullivan and Senior Director Amanda Craig Deckard explore Microsoft‚Äôs efforts to draw on the experience of other domains to help advance the role of AI testing and evaluation as a governance tool.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/'>AI Testing and Evaluation: Learnings from Science and Industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>In the introductory episode of this new series, host Kathleen Sullivan and Senior Director Amanda Craig Deckard explore Microsoft‚Äôs efforts to draw on the experience of other domains to help advance the role of AI testing and evaluation as a governance tool.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/'>AI Testing and Evaluation: Learnings from Science and Industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 16:38:09 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Deploy GPT-J 6B for inference using Hugging Face Transformers and Amazon SageMaker",
    "description": "",
    "summary": "Deploy GPT-J 6B for inference using Hugging Face Transformers and Amazon SageMaker Almost 6 months a...",
    "pubDate": "Tue, 11 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gptj-sagemaker",
    "thumbnail": "https://huggingface.co/blog/assets/45_gptj_sagemaker/thumbnail.png"
  },
  {
    "title": "Merging design and computer science in creative ways",
    "description": "MAD Fellow Alexander Htet Kyaw connects humans, machines, and the physical world using AI and augmented reality.",
    "summary": "MAD Fellow Alexander Htet Kyaw connects humans, machines, and the physical world using AI and augmented reality.",
    "pubDate": "Mon, 28 Apr 2025 16:55:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/alexander-htet-kyaw-merging-design-computer-science-in-creative-ways-0428",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-mad-Alexander-htet-kyaw_0.jpg"
  },
  {
    "title": "Easily Train Models with H100 GPUs on NVIDIA DGX Cloud",
    "description": "",
    "summary": "Easily Train Models with H100 GPUs on NVIDIA DGX Cloud Update: This service is deprecated and no lon...",
    "pubDate": "Mon, 18 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-dgx-cloud",
    "thumbnail": "https://huggingface.co/blog/assets/train-dgx-cloud/thumbnail.jpg"
  },
  {
    "title": "Making LLMs lighter with AutoGPTQ and transformers",
    "description": "",
    "summary": "Making LLMs lighter with AutoGPTQ and transformers Large language models have demonstrated remarkabl...",
    "pubDate": "Wed, 23 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gptq-integration",
    "thumbnail": "https://huggingface.co/blog/assets/159_autogptq_transformers/thumbnail.jpg"
  },
  {
    "title": "ChatSR: Multimodal Large Language Models for Scientific Formula Discovery",
    "description": "arXiv:2406.05410v2 Announce Type: replace Abstract: Formulas are the language of communication between humans and nature. The discovery of formulas to describe natural laws from observational data is the purpose of scientific research. It is also an important research topic in artificial intelligence, which is called a symbolic regression problem. Most of the existing symbolic regression methods generate expressions directly from observed data. Although in some methods, we can inject some prior knowledge into the model by adding constraints or introducing some special character hints. However, these methods can only introduce a limited amount of prior knowledge specified in advance. Not to mention understanding natural language instructions. In this article, based on the powerful knowledge reserve and language understanding ability of multi-modal large language models, we present ChatSR, which acts like a knowledgeable human scientist, and we can tell it any prior knowledge through natural language to guide it in formula generation. By testing on 13 datasets, ChatSR not only shows state-of-the-art performance on traditional symbolic regression tasks. More notably, ChatSR can well understand the prior knowledge contained in natural language prompts and improve the quality of generated expressions. In addition, it is exciting that ChatSR has a good zero-shot capability to understand prior knowledge that is not present in the training data.",
    "summary": "arXiv:2406.05410v2 Announce Type: replace Abstract: Formulas are the language of communication between humans and nature. The discovery of formulas to describe natural laws from observational data is the purpose of scientific research. It is also an important research topic in artificial intelligence, which is called a symbolic regression problem. Most of the existing symbolic regression methods generate expressions directly from observed data. Although in some methods, we can inject some prior knowledge into the model by adding constraints or introducing some special character hints. However, these methods can only introduce a limited amount of prior knowledge specified in advance. Not to mention understanding natural language instructions. In this article, based on the powerful knowledge reserve and language understanding ability of multi-modal large language models, we present ChatSR, which acts like a knowledgeable human scientist, and we can tell it any prior knowledge through natural language to guide it in formula generation. By testing on 13 datasets, ChatSR not only shows state-of-the-art performance on traditional symbolic regression tasks. More notably, ChatSR can well understand the prior knowledge contained in natural language prompts and improve the quality of generated expressions. In addition, it is exciting that ChatSR has a good zero-shot capability to understand prior knowledge that is not present in the training data.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.05410",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Llama 3.2 in Keras",
    "description": "",
    "summary": "Llama 3.2 in Keras This is going to be the shortest blog post ever. Question: Llama 3.2 landed two w...",
    "pubDate": "Mon, 21 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/keras-llama-32",
    "thumbnail": "https://huggingface.co/blog/assets/keras_llama_32/thumbnail.jpg"
  },
  {
    "title": "Swift Diffusers: Fast Stable Diffusion for Mac",
    "description": "",
    "summary": "Swift üß®Diffusers: Fast Stable Diffusion for Mac Transform your text into stunning images with ease u...",
    "pubDate": "Fri, 24 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-mac-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/fast-mac-diffusers/thumbnail.png"
  },
  {
    "title": "Trading inference-time compute for adversarial robustness",
    "description": "Trading Inference-Time Compute for Adversarial Robustness",
    "summary": "Trading Inference-Time Compute for Adversarial Robustness",
    "pubDate": "Wed, 22 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/trading-inference-time-compute-for-adversarial-robustness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2",
    "description": "",
    "summary": "Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2 Update (29/08/2023): A benchmark o...",
    "pubDate": "Thu, 29 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bridgetower",
    "thumbnail": "https://huggingface.co/blog/assets/bridgetower/thumbnail.png"
  },
  {
    "title": "Language-Aware Prompt Tuning for Parameter-Efficient Seamless Language Expansion in Multilingual ASR",
    "description": "arXiv:2506.21577v1 Announce Type: cross Abstract: Recent advancements in multilingual automatic speech recognition (ASR) have been driven by large-scale end-to-end models like Whisper. However, challenges such as language interference and expanding to unseen languages (language expansion) without degrading performance persist. This paper addresses these with three contributions: 1) Entire Soft Prompt Tuning (Entire SPT), which applies soft prompts to both the encoder and decoder, enhancing feature extraction and decoding; 2) Language-Aware Prompt Tuning (LAPT), which leverages cross-lingual similarities to encode shared and language-specific features using lightweight prompt matrices; 3) SPT-Whisper, a toolkit that integrates SPT into Whisper and enables efficient continual learning. Experiments across three languages from FLEURS demonstrate that Entire SPT and LAPT outperform Decoder SPT by 5.0% and 16.0% in language expansion tasks, respectively, providing an efficient solution for dynamic, multilingual ASR models with minimal computational overhead.",
    "summary": "arXiv:2506.21577v1 Announce Type: cross Abstract: Recent advancements in multilingual automatic speech recognition (ASR) have been driven by large-scale end-to-end models like Whisper. However, challenges such as language interference and expanding to unseen languages (language expansion) without degrading performance persist. This paper addresses these with three contributions: 1) Entire Soft Prompt Tuning (Entire SPT), which applies soft prompts to both the encoder and decoder, enhancing feature extraction and decoding; 2) Language-Aware Prompt Tuning (LAPT), which leverages cross-lingual similarities to encode shared and language-specific features using lightweight prompt matrices; 3) SPT-Whisper, a toolkit that integrates SPT into Whisper and enables efficient continual learning. Experiments across three languages from FLEURS demonstrate that Entire SPT and LAPT outperform Decoder SPT by 5.0% and 16.0% in language expansion tasks, respectively, providing an efficient solution for dynamic, multilingual ASR models with minimal computational overhead.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21577",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Train 400x faster Static Embedding Models with Sentence Transformers",
    "description": "",
    "summary": "Train 400x faster Static Embedding Models with Sentence Transformers TL;DR This blog post introduces...",
    "pubDate": "Wed, 15 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/static-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "Our latest advances in robot dexterity",
    "description": "Two new AI systems, ALOHA Unleashed and DemoStart, help robots learn to perform complex tasks that require dexterous movement",
    "summary": "Two new AI systems, ALOHA Unleashed and DemoStart, help robots learn to perform complex tasks that require dexterous movement",
    "pubDate": "Thu, 12 Sep 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advances-in-robot-dexterity/",
    "thumbnail": "https://lh3.googleusercontent.com/63ROjLq4VNqk3RDA5vl1mYS1i5xvcgU8-augVWQY5OZCtVsm_e4YX8rR4_DLUlQiTmMHT6qx3p9shUtPGUHy_4SA64RDeMghvk0eDKT6Fqh6-P3d4A=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "description": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "summary": "OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)",
    "pubDate": "Mon, 10 Jun 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-welcomes-cfo-cpo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Could LLMs help design our next medicines and materials?",
    "description": "A new method lets users ask, in plain language, for a new molecule with certain properties, and receive a detailed description of how to synthesize it.",
    "summary": "A new method lets users ask, in plain language, for a new molecule with certain properties, and receive a detailed description of how to synthesize it.",
    "pubDate": "Wed, 09 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/could-llms-help-design-our-next-medicines-and-materials-0409",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-inverse-molecule-01-press.jpg"
  },
  {
    "title": "Can Large Language Models Replace Human Subjects? A Large-Scale Replication of Scenario-Based Experiments in Psychology and Management",
    "description": "arXiv:2409.00128v3 Announce Type: replace-cross Abstract: Artificial Intelligence (AI) is increasingly being integrated into scientific research, particularly in the social sciences, where understanding human behavior is critical. Large Language Models (LLMs) have shown promise in replicating human-like responses in various psychological experiments. We conducted a large-scale study replicating 156 psychological experiments from top social science journals using three state-of-the-art LLMs (GPT-4, Claude 3.5 Sonnet, and DeepSeek v3). Our results reveal that while LLMs demonstrate high replication rates for main effects (73-81%) and moderate to strong success with interaction effects (46-63%), They consistently produce larger effect sizes than human studies, with Fisher Z values approximately 2-3 times higher than human studies. Notably, LLMs show significantly lower replication rates for studies involving socially sensitive topics such as race, gender and ethics. When original studies reported null findings, LLMs produced significant results at remarkably high rates (68-83%) - while this could reflect cleaner data with less noise, as evidenced by narrower confidence intervals, it also suggests potential risks of effect size overestimation. Our results demonstrate both the promise and challenges of LLMs in psychological research, offering efficient tools for pilot testing and rapid hypothesis validation while enriching rather than replacing traditional human subject studies, yet requiring more nuanced interpretation and human validation for complex social phenomena and culturally sensitive research questions.",
    "summary": "arXiv:2409.00128v3 Announce Type: replace-cross Abstract: Artificial Intelligence (AI) is increasingly being integrated into scientific research, particularly in the social sciences, where understanding human behavior is critical. Large Language Models (LLMs) have shown promise in replicating human-like responses in various psychological experiments. We conducted a large-scale study replicating 156 psychological experiments from top social science journals using three state-of-the-art LLMs (GPT-4, Claude 3.5 Sonnet, and DeepSeek v3). Our results reveal that while LLMs demonstrate high replication rates for main effects (73-81%) and moderate to strong success with interaction effects (46-63%), They consistently produce larger effect sizes than human studies, with Fisher Z values approximately 2-3 times higher than human studies. Notably, LLMs show significantly lower replication rates for studies involving socially sensitive topics such as race, gender and ethics. When original studies reported null findings, LLMs produced significant results at remarkably high rates (68-83%) - while this could reflect cleaner data with less noise, as evidenced by narrower confidence intervals, it also suggests potential risks of effect size overestimation. Our results demonstrate both the promise and challenges of LLMs in psychological research, offering efficient tools for pilot testing and rapid hypothesis validation while enriching rather than replacing traditional human subject studies, yet requiring more nuanced interpretation and human validation for complex social phenomena and culturally sensitive research questions.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.00128",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Exploring Big Five Personality and AI Capability Effects in LLM-Simulated Negotiation Dialogues",
    "description": "arXiv:2506.15928v1 Announce Type: new Abstract: This paper presents an evaluation framework for agentic AI systems in mission-critical negotiation contexts, addressing the need for AI agents that can adapt to diverse human operators and stakeholders. Using Sotopia as a simulation testbed, we present two experiments that systematically evaluated how personality traits and AI agent characteristics influence LLM-simulated social negotiation outcomes--a capability essential for a variety of applications involving cross-team coordination and civil-military interactions. Experiment 1 employs causal discovery methods to measure how personality traits impact price bargaining negotiations, through which we found that Agreeableness and Extraversion significantly affect believability, goal achievement, and knowledge acquisition outcomes. Sociocognitive lexical measures extracted from team communications detected fine-grained differences in agents' empathic communication, moral foundations, and opinion patterns, providing actionable insights for agentic AI systems that must operate reliably in high-stakes operational scenarios. Experiment 2 evaluates human-AI job negotiations by manipulating both simulated human personality and AI system characteristics, specifically transparency, competence, adaptability, demonstrating how AI agent trustworthiness impact mission effectiveness. These findings establish a repeatable evaluation methodology for experimenting with AI agent reliability across diverse operator personalities and human-agent team dynamics, directly supporting operational requirements for reliable AI systems. Our work advances the evaluation of agentic AI workflows by moving beyond standard performance metrics to incorporate social dynamics essential for mission success in complex operations.",
    "summary": "arXiv:2506.15928v1 Announce Type: new Abstract: This paper presents an evaluation framework for agentic AI systems in mission-critical negotiation contexts, addressing the need for AI agents that can adapt to diverse human operators and stakeholders. Using Sotopia as a simulation testbed, we present two experiments that systematically evaluated how personality traits and AI agent characteristics influence LLM-simulated social negotiation outcomes--a capability essential for a variety of applications involving cross-team coordination and civil-military interactions. Experiment 1 employs causal discovery methods to measure how personality traits impact price bargaining negotiations, through which we found that Agreeableness and Extraversion significantly affect believability, goal achievement, and knowledge acquisition outcomes. Sociocognitive lexical measures extracted from team communications detected fine-grained differences in agents' empathic communication, moral foundations, and opinion patterns, providing actionable insights for agentic AI systems that must operate reliably in high-stakes operational scenarios. Experiment 2 evaluates human-AI job negotiations by manipulating both simulated human personality and AI system characteristics, specifically transparency, competence, adaptability, demonstrating how AI agent trustworthiness impact mission effectiveness. These findings establish a repeatable evaluation methodology for experimenting with AI agent reliability across diverse operator personalities and human-agent team dynamics, directly supporting operational requirements for reliable AI systems. Our work advances the evaluation of agentic AI workflows by moving beyond standard performance metrics to incorporate social dynamics essential for mission success in complex operations.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15928",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing ConTextual: How well can your Multimodal model jointly reason over text and image in text-rich scenes?",
    "description": "",
    "summary": "Introducing ConTextual: How well can your Multimodal model jointly reason over text and image in tex...",
    "pubDate": "Tue, 05 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-contextual",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_contextual.png"
  },
  {
    "title": "$C^3$-Bench: The Things Real Disturbing LLM based Agent in Multi-Tasking",
    "description": "arXiv:2505.18746v4 Announce Type: replace Abstract: Agents based on large language models leverage tools to modify environments, revolutionizing how AI interacts with the physical world. Unlike traditional NLP tasks that rely solely on historical dialogue for responses, these agents must consider more complex factors, such as inter-tool relationships, environmental feedback and previous decisions, when making choices. Current research typically evaluates agents via multi-turn dialogues. However, it overlooks the influence of these critical factors on agent behavior. To bridge this gap, we present an open-source and high-quality benchmark $C^3$-Bench. This benchmark integrates attack concepts and applies univariate analysis to pinpoint key elements affecting agent robustness. In concrete, we design three challenges: navigate complex tool relationships, handle critical hidden information and manage dynamic decision paths. Complementing these challenges, we introduce fine-grained metrics, innovative data collection algorithms and reproducible evaluation methods. Extensive experiments are conducted on 49 mainstream agents, encompassing general fast-thinking, slow-thinking and domain-specific models. We observe that agents have significant shortcomings in handling tool dependencies, long context information dependencies and frequent policy-type switching. In essence, $C^3$-Bench aims to expose model vulnerabilities through these challenges and drive research into the interpretability of agent performance. The benchmark is publicly available at https://github.com/TencentHunyuan/C3-Benchmark.",
    "summary": "arXiv:2505.18746v4 Announce Type: replace Abstract: Agents based on large language models leverage tools to modify environments, revolutionizing how AI interacts with the physical world. Unlike traditional NLP tasks that rely solely on historical dialogue for responses, these agents must consider more complex factors, such as inter-tool relationships, environmental feedback and previous decisions, when making choices. Current research typically evaluates agents via multi-turn dialogues. However, it overlooks the influence of these critical factors on agent behavior. To bridge this gap, we present an open-source and high-quality benchmark $C^3$-Bench. This benchmark integrates attack concepts and applies univariate analysis to pinpoint key elements affecting agent robustness. In concrete, we design three challenges: navigate complex tool relationships, handle critical hidden information and manage dynamic decision paths. Complementing these challenges, we introduce fine-grained metrics, innovative data collection algorithms and reproducible evaluation methods. Extensive experiments are conducted on 49 mainstream agents, encompassing general fast-thinking, slow-thinking and domain-specific models. We observe that agents have significant shortcomings in handling tool dependencies, long context information dependencies and frequent policy-type switching. In essence, $C^3$-Bench aims to expose model vulnerabilities through these challenges and drive research into the interpretability of agent performance. The benchmark is publicly available at https://github.com/TencentHunyuan/C3-Benchmark.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.18746",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„Éê„Éº„ÉÅ„É£„É´„ÉÑ„Ç§„É≥„Åå„ÇÇ„Åü„Çâ„ÅôÂåªÁôÇ„ÅÆÊñ∞Â∏∏Ë≠ò„ÄÄÂøÉËáìÊ≤ªÁôÇ„ÇÇËÑ≥Ëñ¨Êäï‰∏é„ÇÇ„Åæ„Åö„ÅØ‰ªÆÊÉ≥Á©∫Èñì„Åß",
    "description": "„ÉÄ„ÉÉ„ÇΩ„Éº„Éª„Ç∑„Çπ„ÉÜ„É†„Ç∫„ÅØ„ÄåÂåªÁôÇÂàÜÈáé„Å´„Åä„Åë„Çã„Éê„Éº„ÉÅ„É£„É´„ÉÑ„Ç§„É≥„Äç„Å´Èñ¢„Åô„ÇãË®òËÄÖË™¨Êòé‰ºö„ÇíÈñãÂÇ¨„Åó„ÄÅ„Éê„Éº„ÉÅ„É£„É´„ÉÑ„Ç§„É≥„ÅÆÂÆöÁæ©„ÇÑ„É©„Ç§„Éï„Çµ„Ç§„Ç®„É≥„Çπ„Åä„Çà„Å≥„Éò„É´„Çπ„Ç±„Ç¢È†òÂüü„Åß„ÅÆÂΩπÂâ≤„ÄÅÂÖ∑‰ΩìÁöÑ„Å™Â∞éÂÖ•‰∫ã‰æã„ÄÅÂ∞ÜÊù•„ÅÆÂ±ïÊúõ„Å´„Å§„ÅÑ„Å¶Á¥π‰ªã„Åó„Åü„ÄÇ",
    "summary": "„ÉÄ„ÉÉ„ÇΩ„Éº„Éª„Ç∑„Çπ„ÉÜ„É†„Ç∫„ÅØ„ÄåÂåªÁôÇÂàÜÈáé„Å´„Åä„Åë„Çã„Éê„Éº„ÉÅ„É£„É´„ÉÑ„Ç§„É≥„Äç„Å´Èñ¢„Åô„ÇãË®òËÄÖË™¨Êòé‰ºö„ÇíÈñãÂÇ¨„Åó„ÄÅ„Éê„Éº„ÉÅ„É£„É´„ÉÑ„Ç§„É≥„ÅÆÂÆöÁæ©„ÇÑ„É©„Ç§„Éï„Çµ„Ç§„Ç®„É≥„Çπ„Åä„Çà„Å≥„Éò„É´„Çπ„Ç±„Ç¢È†òÂüü„Åß„ÅÆÂΩπÂâ≤„ÄÅÂÖ∑‰ΩìÁöÑ„Å™Â∞éÂÖ•‰∫ã‰æã„ÄÅÂ∞ÜÊù•„ÅÆÂ±ïÊúõ„Å´„Å§„ÅÑ„Å¶Á¥π‰ªã„Åó„Åü„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 06:15:00 +0900",
    "source": "ITmedia AI",
    "url": "https://monoist.itmedia.co.jp/mn/articles/2506/30/news053.html",
    "thumbnail": "https://image.itmedia.co.jp/mn/articles/2506/30/cover_news053.jpg"
  },
  {
    "title": "Cross-Modality Learning for Predicting IHC Biomarkers from H&E-Stained Whole-Slide Images",
    "description": "arXiv:2506.15853v1 Announce Type: cross Abstract: Hematoxylin and Eosin (H&amp;E) staining is a cornerstone of pathological analysis, offering reliable visualization of cellular morphology and tissue architecture for cancer diagnosis, subtyping, and grading. Immunohistochemistry (IHC) staining provides molecular insights by detecting specific proteins within tissues, enhancing diagnostic accuracy, and improving treatment planning. However, IHC staining is costly, time-consuming, and resource-intensive, requiring specialized expertise. To address these limitations, this study proposes HistoStainAlign, a novel deep learning framework that predicts IHC staining patterns directly from H&amp;E whole-slide images (WSIs) by learning joint representations of morphological and molecular features. The framework integrates paired H&amp;E and IHC embeddings through a contrastive training strategy, capturing complementary features across staining modalities without patch-level annotations or tissue registration. The model was evaluated on gastrointestinal and lung tissue WSIs with three commonly used IHC stains: P53, PD-L1, and Ki-67. HistoStainAlign achieved weighted F1 scores of 0.735 [95% Confidence Interval (CI): 0.670-0.799], 0.830 [95% CI: 0.772-0.886], and 0.723 [95% CI: 0.607-0.836], respectively for these three IHC stains. Embedding analyses demonstrated the robustness of the contrastive alignment in capturing meaningful cross-stain relationships. Comparisons with a baseline model further highlight the advantage of incorporating contrastive learning for improved stain pattern prediction. This study demonstrates the potential of computational approaches to serve as a pre-screening tool, helping prioritize cases for IHC staining and improving workflow efficiency.",
    "summary": "arXiv:2506.15853v1 Announce Type: cross Abstract: Hematoxylin and Eosin (H&amp;E) staining is a cornerstone of pathological analysis, offering reliable visualization of cellular morphology and tissue architecture for cancer diagnosis, subtyping, and grading. Immunohistochemistry (IHC) staining provides molecular insights by detecting specific proteins within tissues, enhancing diagnostic accuracy, and improving treatment planning. However, IHC staining is costly, time-consuming, and resource-intensive, requiring specialized expertise. To address these limitations, this study proposes HistoStainAlign, a novel deep learning framework that predicts IHC staining patterns directly from H&amp;E whole-slide images (WSIs) by learning joint representations of morphological and molecular features. The framework integrates paired H&amp;E and IHC embeddings through a contrastive training strategy, capturing complementary features across staining modalities without patch-level annotations or tissue registration. The model was evaluated on gastrointestinal and lung tissue WSIs with three commonly used IHC stains: P53, PD-L1, and Ki-67. HistoStainAlign achieved weighted F1 scores of 0.735 [95% Confidence Interval (CI): 0.670-0.799], 0.830 [95% CI: 0.772-0.886], and 0.723 [95% CI: 0.607-0.836], respectively for these three IHC stains. Embedding analyses demonstrated the robustness of the contrastive alignment in capturing meaningful cross-stain relationships. Comparisons with a baseline model further highlight the advantage of incorporating contrastive learning for improved stain pattern prediction. This study demonstrates the potential of computational approaches to serve as a pre-screening tool, helping prioritize cases for IHC staining and improving workflow efficiency.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15853",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Training and Finetuning Embedding Models with Sentence Transformers v3",
    "description": "",
    "summary": "Training and Finetuning Embedding Models with Sentence Transformers v3 Sentence Transformers is a Py...",
    "pubDate": "Tue, 28 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-sentence-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "Introducing data residency in Europe",
    "description": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "summary": "Data residency builds on OpenAI‚Äôs enterprise-grade data privacy, security, and compliance programs supporting customers worldwide.",
    "pubDate": "Wed, 05 Feb 2025 22:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-data-residency-in-europe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CapsDT: Diffusion-Transformer for Capsule Robot Manipulation",
    "description": "arXiv:2506.16263v1 Announce Type: cross Abstract: Vision-Language-Action (VLA) models have emerged as a prominent research area, showcasing significant potential across a variety of applications. However, their performance in endoscopy robotics, particularly endoscopy capsule robots that perform actions within the digestive system, remains unexplored. The integration of VLA models into endoscopy robots allows more intuitive and efficient interactions between human operators and medical devices, improving both diagnostic accuracy and treatment outcomes. In this work, we design CapsDT, a Diffusion Transformer model for capsule robot manipulation in the stomach. By processing interleaved visual inputs, and textual instructions, CapsDT can infer corresponding robotic control signals to facilitate endoscopy tasks. In addition, we developed a capsule endoscopy robot system, a capsule robot controlled by a robotic arm-held magnet, addressing different levels of four endoscopy tasks and creating corresponding capsule robot datasets within the stomach simulator. Comprehensive evaluations on various robotic tasks indicate that CapsDT can serve as a robust vision-language generalist, achieving state-of-the-art performance in various levels of endoscopy tasks while achieving a 26.25% success rate in real-world simulation manipulation.",
    "summary": "arXiv:2506.16263v1 Announce Type: cross Abstract: Vision-Language-Action (VLA) models have emerged as a prominent research area, showcasing significant potential across a variety of applications. However, their performance in endoscopy robotics, particularly endoscopy capsule robots that perform actions within the digestive system, remains unexplored. The integration of VLA models into endoscopy robots allows more intuitive and efficient interactions between human operators and medical devices, improving both diagnostic accuracy and treatment outcomes. In this work, we design CapsDT, a Diffusion Transformer model for capsule robot manipulation in the stomach. By processing interleaved visual inputs, and textual instructions, CapsDT can infer corresponding robotic control signals to facilitate endoscopy tasks. In addition, we developed a capsule endoscopy robot system, a capsule robot controlled by a robotic arm-held magnet, addressing different levels of four endoscopy tasks and creating corresponding capsule robot datasets within the stomach simulator. Comprehensive evaluations on various robotic tasks indicate that CapsDT can serve as a robust vision-language generalist, achieving state-of-the-art performance in various levels of endoscopy tasks while achieving a 26.25% success rate in real-world simulation manipulation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16263",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI LP",
    "description": "We‚Äôve created OpenAI LP, a new ‚Äúcapped-profit‚Äù company that allows us to rapidly increase our investments in compute and talent while including checks and balances to actualize our mission.",
    "summary": "We‚Äôve created OpenAI LP, a new ‚Äúcapped-profit‚Äù company that allows us to rapidly increase our investments in compute and talent while including checks and balances to actualize our mission.",
    "pubDate": "Mon, 11 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-lp",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Genie 2: A large-scale foundation world model",
    "description": "Generating unlimited diverse training environments for future general agents",
    "summary": "Generating unlimited diverse training environments for future general agents",
    "pubDate": "Wed, 04 Dec 2024 14:23:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/",
    "thumbnail": "https://lh3.googleusercontent.com/wvcJdqh_wddVc-WiMGgcqe7nWp7Ybu0wd-PBDxC_VUQkfxI7HPfQz3fi_HyYTOoRM_XV3Bofp9l1wBZ1CJPZPG6yZMdZxqH8X7_Lb9nhVAquAul1=w1200-h630-n-nu"
  },
  {
    "title": "Representation Learning of Point Cloud Upsampling in Global and Local Inputs",
    "description": "arXiv:2501.07076v3 Announce Type: replace-cross Abstract: In recent years, point cloud upsampling has been widely applied in tasks such as 3D reconstruction and object recognition. This study proposed a novel framework, ReLPU, which enhances upsampling performance by explicitly learning from both global and local structural features of point clouds. Specifically, we extracted global features from uniformly segmented inputs (Average Segments) and local features from patch-based inputs of the same point cloud. These two types of features were processed through parallel autoencoders, fused, and then fed into a shared decoder for upsampling. This dual-input design improved feature completeness and cross-scale consistency, especially in sparse and noisy regions. Our framework was applied to several state-of-the-art autoencoder-based networks and validated on standard datasets. Experimental results demonstrated consistent improvements in geometric fidelity and robustness. In addition, saliency maps confirmed that parallel global-local learning significantly enhanced the interpretability and performance of point cloud upsampling.",
    "summary": "arXiv:2501.07076v3 Announce Type: replace-cross Abstract: In recent years, point cloud upsampling has been widely applied in tasks such as 3D reconstruction and object recognition. This study proposed a novel framework, ReLPU, which enhances upsampling performance by explicitly learning from both global and local structural features of point clouds. Specifically, we extracted global features from uniformly segmented inputs (Average Segments) and local features from patch-based inputs of the same point cloud. These two types of features were processed through parallel autoencoders, fused, and then fed into a shared decoder for upsampling. This dual-input design improved feature completeness and cross-scale consistency, especially in sparse and noisy regions. Our framework was applied to several state-of-the-art autoencoder-based networks and validated on standard datasets. Experimental results demonstrated consistent improvements in geometric fidelity and robustness. In addition, saliency maps confirmed that parallel global-local learning significantly enhanced the interpretability and performance of point cloud upsampling.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.07076",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BERT 101 ü§ó State Of The Art NLP Model Explained",
    "description": "",
    "summary": "BERT 101 ü§ó State Of The Art NLP Model Explained What is BERT? BERT, short for Bidirectional Encoder ...",
    "pubDate": "Wed, 02 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-101",
    "thumbnail": "https://huggingface.co/blog/assets/52_bert_101/thumbnail.jpg"
  },
  {
    "title": "Generate videos in Gemini and Whisk with Veo 2",
    "description": "Transform text-based prompts into high-resolution eight-second videos in Gemini Advanced and use Whisk Animate to turn images into eight-second animated clips.",
    "summary": "Transform text-based prompts into high-resolution eight-second videos in Gemini Advanced and use Whisk Animate to turn images into eight-second animated clips.",
    "pubDate": "Tue, 15 Apr 2025 17:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/generate-videos-in-gemini-and-whisk-with-veo-2/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GenerateVideos_Static1_1920x1080.width-1300.png"
  },
  {
    "title": "LearnAlign: Reasoning Data Selection for Reinforcement Learning in Large Language Models Based on Improved Gradient Alignment",
    "description": "arXiv:2506.11480v2 Announce Type: replace-cross Abstract: Reinforcement learning (RL) has become a key technique for enhancing LLMs' reasoning abilities, yet its data inefficiency remains a major bottleneck. To address this critical yet challenging issue, we present a novel gradient-alignment-based method, named LearnAlign, which intelligently selects the learnable and representative training reasoning data for RL post-training. To overcome the issue of response-length bias in gradient norms, we introduce the data learnability based on the success rate, which can indicate the learning potential of each data point. Experiments across three mathematical reasoning benchmarks demonstrate that our method significantly reduces training data requirements while achieving minor performance degradation or even improving performance compared to full-data training. For example, it reduces data requirements by up to 1,000 data points with better performance (77.53%) than that on the full dataset on GSM8K benchmark (77.04%). Furthermore, we show its effectiveness in the staged RL setting. This work provides valuable insights into data-efficient RL post-training and establishes a foundation for future research in optimizing reasoning data selection. To facilitate future work, we will release code.",
    "summary": "arXiv:2506.11480v2 Announce Type: replace-cross Abstract: Reinforcement learning (RL) has become a key technique for enhancing LLMs' reasoning abilities, yet its data inefficiency remains a major bottleneck. To address this critical yet challenging issue, we present a novel gradient-alignment-based method, named LearnAlign, which intelligently selects the learnable and representative training reasoning data for RL post-training. To overcome the issue of response-length bias in gradient norms, we introduce the data learnability based on the success rate, which can indicate the learning potential of each data point. Experiments across three mathematical reasoning benchmarks demonstrate that our method significantly reduces training data requirements while achieving minor performance degradation or even improving performance compared to full-data training. For example, it reduces data requirements by up to 1,000 data points with better performance (77.53%) than that on the full dataset on GSM8K benchmark (77.04%). Furthermore, we show its effectiveness in the staged RL setting. This work provides valuable insights into data-efficient RL post-training and establishes a foundation for future research in optimizing reasoning data selection. To facilitate future work, we will release code.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11480",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "What AI‚Äôs impact on individuals means for the health workforce and industry",
    "description": "<p>Ethan Mollick and Azeem Azhar, thought leaders at the forefront of AI‚Äôs influence on work, education, and society, discuss the impact of AI at the individual level and what that means for the healthcare workforce and the organizations and systems in medicine.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/'>What AI&#8217;s impact on individuals means for the health workforce and industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Ethan Mollick and Azeem Azhar, thought leaders at the forefront of AI‚Äôs influence on work, education, and society, discuss the impact of AI at the individual level and what that means for the healthcare workforce and the organizations and systems in medicine.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/'>What AI&#8217;s impact on individuals means for the health workforce and industry</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 29 May 2025 15:13:48 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Powering virtual education for the classroom",
    "description": "Khan Academy explores the potential for GPT-4 in a limited pilot program.",
    "summary": "Khan Academy explores the potential for GPT-4 in a limited pilot program.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/khan-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning",
    "description": "arXiv:2506.11555v2 Announce Type: replace Abstract: The integration of external knowledge through Retrieval-Augmented Generation (RAG) has become foundational in enhancing large language models (LLMs) for knowledge-intensive tasks. However, existing RAG paradigms often overlook the cognitive step of applying knowledge, leaving a gap between retrieved facts and task-specific reasoning. In this work, we introduce RAG+, a principled and modular extension that explicitly incorporates application-aware reasoning into the RAG pipeline. RAG+ constructs a dual corpus consisting of knowledge and aligned application examples, created either manually or automatically, and retrieves both jointly during inference. This design enables LLMs not only to access relevant information but also to apply it within structured, goal-oriented reasoning processes. Experiments across mathematical, legal, and medical domains, conducted on multiple models, demonstrate that RAG+ consistently outperforms standard RAG variants, achieving average improvements of 3-5%, and peak gains up to 7.5% in complex scenarios. By bridging retrieval with actionable application, RAG+ advances a more cognitively grounded framework for knowledge integration, representing a step toward more interpretable and capable LLMs.",
    "summary": "arXiv:2506.11555v2 Announce Type: replace Abstract: The integration of external knowledge through Retrieval-Augmented Generation (RAG) has become foundational in enhancing large language models (LLMs) for knowledge-intensive tasks. However, existing RAG paradigms often overlook the cognitive step of applying knowledge, leaving a gap between retrieved facts and task-specific reasoning. In this work, we introduce RAG+, a principled and modular extension that explicitly incorporates application-aware reasoning into the RAG pipeline. RAG+ constructs a dual corpus consisting of knowledge and aligned application examples, created either manually or automatically, and retrieves both jointly during inference. This design enables LLMs not only to access relevant information but also to apply it within structured, goal-oriented reasoning processes. Experiments across mathematical, legal, and medical domains, conducted on multiple models, demonstrate that RAG+ consistently outperforms standard RAG variants, achieving average improvements of 3-5%, and peak gains up to 7.5% in complex scenarios. By bridging retrieval with actionable application, RAG+ advances a more cognitively grounded framework for knowledge integration, representing a step toward more interpretable and capable LLMs.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11555",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reimagining the email experience with AI",
    "description": "Superhuman introduces a new era of email with OpenAI.",
    "summary": "Superhuman introduces a new era of email with OpenAI.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/superhuman",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fixing Open LLM Leaderboard with Math-Verify",
    "description": "",
    "summary": "Fixing Open LLM Leaderboard with Math-Verify 3 weeks ago, we showed how hard it is to correctly eval...",
    "pubDate": "Fri, 14 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/math_verify_leaderboard",
    "thumbnail": "https://huggingface.co/blog/assets/math_verify_leaderboard/thumbnail.png"
  },
  {
    "title": "Training Stable Diffusion with Dreambooth using üß® Diffusers",
    "description": "",
    "summary": "Training Stable Diffusion with Dreambooth using üß® Diffusers Dreambooth is a technique to teach new c...",
    "pubDate": "Mon, 07 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dreambooth",
    "thumbnail": "https://huggingface.co/blog/assets/sd_dreambooth_training/thumbnail.jpg"
  },
  {
    "title": "EmoStage: A Framework for Accurate Empathetic Response Generation via Perspective-Taking and Phase Recognition",
    "description": "arXiv:2506.19279v1 Announce Type: cross Abstract: The rising demand for mental health care has fueled interest in AI-driven counseling systems. While large language models (LLMs) offer significant potential, current approaches face challenges, including limited understanding of clients' psychological states and counseling stages, reliance on high-quality training data, and privacy concerns associated with commercial deployment. To address these issues, we propose EmoStage, a framework that enhances empathetic response generation by leveraging the inference capabilities of open-source LLMs without additional training data. Our framework introduces perspective-taking to infer clients' psychological states and support needs, enabling the generation of emotionally resonant responses. In addition, phase recognition is incorporated to ensure alignment with the counseling process and to prevent contextually inappropriate or inopportune responses. Experiments conducted in both Japanese and Chinese counseling settings demonstrate that EmoStage improves the quality of responses generated by base models and performs competitively with data-driven methods.",
    "summary": "arXiv:2506.19279v1 Announce Type: cross Abstract: The rising demand for mental health care has fueled interest in AI-driven counseling systems. While large language models (LLMs) offer significant potential, current approaches face challenges, including limited understanding of clients' psychological states and counseling stages, reliance on high-quality training data, and privacy concerns associated with commercial deployment. To address these issues, we propose EmoStage, a framework that enhances empathetic response generation by leveraging the inference capabilities of open-source LLMs without additional training data. Our framework introduces perspective-taking to infer clients' psychological states and support needs, enabling the generation of emotionally resonant responses. In addition, phase recognition is incorporated to ensure alignment with the counseling process and to prevent contextually inappropriate or inopportune responses. Experiments conducted in both Japanese and Chinese counseling settings demonstrate that EmoStage improves the quality of responses generated by base models and performs competitively with data-driven methods.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19279",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "V2X-VLM: End-to-End V2X Cooperative Autonomous Driving Through Large Vision-Language Models",
    "description": "arXiv:2408.09251v3 Announce Type: replace-cross Abstract: Vehicle-to-everything (V2X) cooperation has emerged as a promising paradigm to overcome the perception limitations of classical autonomous driving by leveraging information from both ego-vehicle and infrastructure sensors. However, effectively fusing heterogeneous visual and semantic information while ensuring robust trajectory planning remains a significant challenge. This paper introduces V2X-VLM, a novel end-to-end (E2E) cooperative autonomous driving framework based on vision-language models (VLMs). V2X-VLM integrates multiperspective camera views from vehicles and infrastructure with text-based scene descriptions to enable a more comprehensive understanding of driving environments. Specifically, we propose a contrastive learning-based mechanism to reinforce the alignment of heterogeneous visual and textual characteristics, which enhances the semantic understanding of complex driving scenarios, and employ a knowledge distillation strategy to stabilize training. Experiments on a large real-world dataset demonstrate that V2X-VLM achieves state-of-the-art trajectory planning accuracy, significantly reducing L2 error and collision rate compared to existing cooperative autonomous driving baselines. Ablation studies validate the contributions of each component. Moreover, the evaluation of robustness and efficiency highlights the practicality of V2X-VLM for real-world deployment to enhance overall autonomous driving safety and decision-making.",
    "summary": "arXiv:2408.09251v3 Announce Type: replace-cross Abstract: Vehicle-to-everything (V2X) cooperation has emerged as a promising paradigm to overcome the perception limitations of classical autonomous driving by leveraging information from both ego-vehicle and infrastructure sensors. However, effectively fusing heterogeneous visual and semantic information while ensuring robust trajectory planning remains a significant challenge. This paper introduces V2X-VLM, a novel end-to-end (E2E) cooperative autonomous driving framework based on vision-language models (VLMs). V2X-VLM integrates multiperspective camera views from vehicles and infrastructure with text-based scene descriptions to enable a more comprehensive understanding of driving environments. Specifically, we propose a contrastive learning-based mechanism to reinforce the alignment of heterogeneous visual and textual characteristics, which enhances the semantic understanding of complex driving scenarios, and employ a knowledge distillation strategy to stabilize training. Experiments on a large real-world dataset demonstrate that V2X-VLM achieves state-of-the-art trajectory planning accuracy, significantly reducing L2 error and collision rate compared to existing cooperative autonomous driving baselines. Ablation studies validate the contributions of each component. Moreover, the evaluation of robustness and efficiency highlights the practicality of V2X-VLM for real-world deployment to enhance overall autonomous driving safety and decision-making.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.09251",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI-written critiques help humans notice flaws",
    "description": "We trained ‚Äúcritique-writing‚Äù models to describe flaws in summaries. Human evaluators find flaws in summaries much more often when shown our model‚Äôs critiques. Larger models are better at self-critiquing, with scale improving critique-writing more than summary-writing. This shows promise for using AI systems to assist human supervision of AI systems on difficult¬†tasks.",
    "summary": "We trained ‚Äúcritique-writing‚Äù models to describe flaws in summaries. Human evaluators find flaws in summaries much more often when shown our model‚Äôs critiques. Larger models are better at self-critiquing, with scale improving critique-writing more than summary-writing. This shows promise for using AI systems to assist human supervision of AI systems on difficult¬†tasks.",
    "pubDate": "Mon, 13 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/critiques",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New method efficiently safeguards sensitive AI training data",
    "description": "The approach maintains an AI model‚Äôs accuracy while ensuring attackers can‚Äôt extract secret information.",
    "summary": "The approach maintains an AI model‚Äôs accuracy while ensuring attackers can‚Äôt extract secret information.",
    "pubDate": "Fri, 11 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-method-efficiently-safeguards-sensitive-ai-training-data-0411",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Private-Algorithm-01-press.jpg"
  },
  {
    "title": "SafeMimic: Towards Safe and Autonomous Human-to-Robot Imitation for Mobile Manipulation",
    "description": "arXiv:2506.15847v1 Announce Type: cross Abstract: For robots to become efficient helpers in the home, they must learn to perform new mobile manipulation tasks simply by watching humans perform them. Learning from a single video demonstration from a human is challenging as the robot needs to first extract from the demo what needs to be done and how, translate the strategy from a third to a first-person perspective, and then adapt it to be successful with its own morphology. Furthermore, to mitigate the dependency on costly human monitoring, this learning process should be performed in a safe and autonomous manner. We present SafeMimic, a framework to learn new mobile manipulation skills safely and autonomously from a single third-person human video. Given an initial human video demonstration of a multi-step mobile manipulation task, SafeMimic first parses the video into segments, inferring both the semantic changes caused and the motions the human executed to achieve them and translating them to an egocentric reference. Then, it adapts the behavior to the robot's own morphology by sampling candidate actions around the human ones, and verifying them for safety before execution in a receding horizon fashion using an ensemble of safety Q-functions trained in simulation. When safe forward progression is not possible, SafeMimic backtracks to previous states and attempts a different sequence of actions, adapting both the trajectory and the grasping modes when required for its morphology. As a result, SafeMimic yields a strategy that succeeds in the demonstrated behavior and learns task-specific actions that reduce exploration in future attempts. Our experiments show that our method allows robots to safely and efficiently learn multi-step mobile manipulation behaviors from a single human demonstration, from different users, and in different environments, with improvements over state-of-the-art baselines across seven tasks",
    "summary": "arXiv:2506.15847v1 Announce Type: cross Abstract: For robots to become efficient helpers in the home, they must learn to perform new mobile manipulation tasks simply by watching humans perform them. Learning from a single video demonstration from a human is challenging as the robot needs to first extract from the demo what needs to be done and how, translate the strategy from a third to a first-person perspective, and then adapt it to be successful with its own morphology. Furthermore, to mitigate the dependency on costly human monitoring, this learning process should be performed in a safe and autonomous manner. We present SafeMimic, a framework to learn new mobile manipulation skills safely and autonomously from a single third-person human video. Given an initial human video demonstration of a multi-step mobile manipulation task, SafeMimic first parses the video into segments, inferring both the semantic changes caused and the motions the human executed to achieve them and translating them to an egocentric reference. Then, it adapts the behavior to the robot's own morphology by sampling candidate actions around the human ones, and verifying them for safety before execution in a receding horizon fashion using an ensemble of safety Q-functions trained in simulation. When safe forward progression is not possible, SafeMimic backtracks to previous states and attempts a different sequence of actions, adapting both the trajectory and the grasping modes when required for its morphology. As a result, SafeMimic yields a strategy that succeeds in the demonstrated behavior and learns task-specific actions that reduce exploration in future attempts. Our experiments show that our method allows robots to safely and efficiently learn multi-step mobile manipulation behaviors from a single human demonstration, from different users, and in different environments, with improvements over state-of-the-art baselines across seven tasks",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15847",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Two Heads Are Better than One: Simulating Large Transformers with Small Ones",
    "description": "arXiv:2506.12220v2 Announce Type: replace-cross Abstract: The quadratic complexity of self-attention prevents transformers from scaling effectively to long input sequences. On the other hand, modern GPUs and other specialized hardware accelerators are well-optimized for processing small input sequences in transformers during both training and inference. A natural question arises: can we take advantage of the efficiency of small transformers to deal with long input sequences? In this paper, we show that transformers with long input sequences (large transformers) can be efficiently simulated by transformers that can only take short input sequences (small transformers). Specifically, we prove that any transformer with input length $N$ can be efficiently simulated by only $O((N/M)^2)$ transformers with input length $M ll N$, and that this cannot be improved in the worst case. However, we then prove that in various natural scenarios including average-case inputs, sliding window masking and attention sinks, the optimal number $O(N/M)$ of small transformers suffice.",
    "summary": "arXiv:2506.12220v2 Announce Type: replace-cross Abstract: The quadratic complexity of self-attention prevents transformers from scaling effectively to long input sequences. On the other hand, modern GPUs and other specialized hardware accelerators are well-optimized for processing small input sequences in transformers during both training and inference. A natural question arises: can we take advantage of the efficiency of small transformers to deal with long input sequences? In this paper, we show that transformers with long input sequences (large transformers) can be efficiently simulated by transformers that can only take short input sequences (small transformers). Specifically, we prove that any transformer with input length $N$ can be efficiently simulated by only $O((N/M)^2)$ transformers with input length $M ll N$, and that this cannot be improved in the worst case. However, we then prove that in various natural scenarios including average-case inputs, sliding window masking and attention sinks, the optimal number $O(N/M)$ of small transformers suffice.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12220",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Here‚Äôs the next cohort of the Google.org Accelerator: Generative AI",
    "description": "A collage of photos showing people using technology around the world, on a white background",
    "summary": "A collage of photos showing people using technology around the world, on a white background",
    "pubDate": "Mon, 09 Jun 2025 14:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/outreach-initiatives/google-org/generative-ai-accelerator-cohort-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gen_AI_Accelerator_ss.width-1300.png"
  },
  {
    "title": "ÔºªPython„ÇØ„Ç§„Ç∫ÔºΩ„Äå1.0 + 2.0 == 3.0„Äç„ÅØÊúüÂæÖÈÄö„Çä„Å´True„Å´„Å™„Çã„ÅØ„ÅöÔºü„ÄÄ„Åù„ÅÆÁêÜÁî±„ÅØÂàÜ„Åã„ÇãÔºü",
    "description": "ÊôÆÊÆµ‰ΩïÊ∞ó„Å™„Åè‰Ωø„Å£„Å¶„ÅÑ„ÇãÊµÆÂãïÂ∞èÊï∞ÁÇπÊï∞ÂÄ§„Åß„Åô„Åå„ÄÅ„Å®„Åç„Å´„ÅØÊÄù„Çè„Å¨ÁµêÊûú„ÇíÁîü„ÇÄ„Åì„Å®„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ„Åù„ÅÆ‰ª£Ë°®‰æã„Åå‰ªäÂõû„ÅÆÂïèÈ°å„Åß„Åô„ÄÇ„Å©„Å£„Å°„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÅåË°®Á§∫„Åï„Çå„Çã„ÅãÂàÜ„Åã„Å£„Å¶„Åæ„Åô„Çà„Å≠Ôºü",
    "summary": "ÊôÆÊÆµ‰ΩïÊ∞ó„Å™„Åè‰Ωø„Å£„Å¶„ÅÑ„ÇãÊµÆÂãïÂ∞èÊï∞ÁÇπÊï∞ÂÄ§„Åß„Åô„Åå„ÄÅ„Å®„Åç„Å´„ÅØÊÄù„Çè„Å¨ÁµêÊûú„ÇíÁîü„ÇÄ„Åì„Å®„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ„Åù„ÅÆ‰ª£Ë°®‰æã„Åå‰ªäÂõû„ÅÆÂïèÈ°å„Åß„Åô„ÄÇ„Å©„Å£„Å°„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÅåË°®Á§∫„Åï„Çå„Çã„ÅãÂàÜ„Åã„Å£„Å¶„Åæ„Åô„Çà„Å≠Ôºü",
    "pubDate": "Tue, 24 Jun 2025 05:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://atmarkit.itmedia.co.jp/ait/articles/2506/24/news014.html",
    "thumbnail": "https://image.itmedia.co.jp/ait/articles/2506/24/cover_news014.jpg"
  },
  {
    "title": "Emergent Risk Awareness in Rational Agents under Resource Constraints",
    "description": "arXiv:2505.23436v3 Announce Type: replace Abstract: Advanced reasoning models with agentic capabilities (AI agents) are deployed to interact with humans and to solve sequential decision-making problems under (approximate) utility functions and internal models. When such problems have resource or failure constraints where action sequences may be forcibly terminated once resources are exhausted, agents face implicit trade-offs that reshape their utility-driven (rational) behaviour. Additionally, since these agents are typically commissioned by a human principal to act on their behalf, asymmetries in constraint exposure can give rise to previously unanticipated misalignment between human objectives and agent incentives. We formalise this setting through a survival bandit framework, provide theoretical and empirical results that quantify the impact of survival-driven preference shifts, identify conditions under which misalignment emerges and propose mechanisms to mitigate the emergence of risk-seeking or risk-averse behaviours. As a result, this work aims to increase understanding and interpretability of emergent behaviours of AI agents operating under such survival pressure, and offer guidelines for safely deploying such AI systems in critical resource-limited environments.",
    "summary": "arXiv:2505.23436v3 Announce Type: replace Abstract: Advanced reasoning models with agentic capabilities (AI agents) are deployed to interact with humans and to solve sequential decision-making problems under (approximate) utility functions and internal models. When such problems have resource or failure constraints where action sequences may be forcibly terminated once resources are exhausted, agents face implicit trade-offs that reshape their utility-driven (rational) behaviour. Additionally, since these agents are typically commissioned by a human principal to act on their behalf, asymmetries in constraint exposure can give rise to previously unanticipated misalignment between human objectives and agent incentives. We formalise this setting through a survival bandit framework, provide theoretical and empirical results that quantify the impact of survival-driven preference shifts, identify conditions under which misalignment emerges and propose mechanisms to mitigate the emergence of risk-seeking or risk-averse behaviours. As a result, this work aims to increase understanding and interpretability of emergent behaviours of AI agents operating under such survival pressure, and offer guidelines for safely deploying such AI systems in critical resource-limited environments.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.23436",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Alto: Orchestrating Distributed Compound AI Systems with Nested Ancestry",
    "description": "arXiv:2403.04311v2 Announce Type: replace Abstract: Compound AI applications chain together subcomponents such as generative language models, document retrievers, and embedding models. Applying traditional systems optimizations such as parallelism and pipelining in compound AI systems is difficult because each component has different constraints in terms of the granularity and type of data that it ingests. New data is often generated during intermediate computations, and text streams may be split into smaller, independent fragments (such as documents to sentences) which may then be re-aggregated at later parts of the computation. Due to this complexity, existing systems to serve compound AI queries do not fully take advantage of parallelism and pipelining opportunities. We present Alto, a framework that automatically optimizes execution of compound AI queries through streaming and parallelism. Bento introduces a new abstraction called nested ancestry, a metadata hierarchy that allows the system to correctly track partial outputs and aggregate data across the heterogeneous constraints of the components of compound AI applications. This metadata is automatically inferred from the programming model, allowing developers to express complex dataflow patterns without needing to reason manually about the details of routing and aggregation. Implementations of four applications in Alto outperform or match implementations in LangGraph, a popular existing AI programming framework. Alto implementations match or improve latency by between 10-30%.",
    "summary": "arXiv:2403.04311v2 Announce Type: replace Abstract: Compound AI applications chain together subcomponents such as generative language models, document retrievers, and embedding models. Applying traditional systems optimizations such as parallelism and pipelining in compound AI systems is difficult because each component has different constraints in terms of the granularity and type of data that it ingests. New data is often generated during intermediate computations, and text streams may be split into smaller, independent fragments (such as documents to sentences) which may then be re-aggregated at later parts of the computation. Due to this complexity, existing systems to serve compound AI queries do not fully take advantage of parallelism and pipelining opportunities. We present Alto, a framework that automatically optimizes execution of compound AI queries through streaming and parallelism. Bento introduces a new abstraction called nested ancestry, a metadata hierarchy that allows the system to correctly track partial outputs and aggregate data across the heterogeneous constraints of the components of compound AI applications. This metadata is automatically inferred from the programming model, allowing developers to express complex dataflow patterns without needing to reason manually about the details of routing and aggregation. Implementations of four applications in Alto outperform or match implementations in LangGraph, a popular existing AI programming framework. Alto implementations match or improve latency by between 10-30%.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2403.04311",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub",
    "description": "",
    "summary": "Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub Huggy Lingo...",
    "pubDate": "Wed, 02 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggy-lingo",
    "thumbnail": "https://huggingface.co/blog/huggy-lingo/blog/assets/156_huggylingo/Huggy_Lingo.png"
  },
  {
    "title": "Relic: Enhancing Reward Model Generalization for Low-Resource Indic Languages with Few-Shot Examples",
    "description": "arXiv:2506.16502v1 Announce Type: cross Abstract: Reward models are essential for aligning large language models (LLMs) with human preferences. However, most open-source multilingual reward models are primarily trained on preference datasets in high-resource languages, resulting in unreliable reward signals for low-resource Indic languages. Collecting large-scale, high-quality preference data for these languages is prohibitively expensive, making preference-based training approaches impractical. To address this challenge, we propose RELIC, a novel in-context learning framework for reward modeling in low-resource Indic languages. RELIC trains a retriever with a pairwise ranking objective to select in-context examples from auxiliary high-resource languages that most effectively highlight the distinction between preferred and less-preferred responses. Extensive experiments on three preference datasets- PKU-SafeRLHF, WebGPT, and HH-RLHF-using state-of-the-art open-source reward models demonstrate that RELIC significantly improves reward model accuracy for low-resource Indic languages, consistently outperforming existing example selection methods. For example, on Bodo-a low-resource Indic language-using a LLaMA-3.2-3B reward model, RELIC achieves a 12.81% and 10.13% improvement in accuracy over zero-shot prompting and state-of-the-art example selection method, respectively.",
    "summary": "arXiv:2506.16502v1 Announce Type: cross Abstract: Reward models are essential for aligning large language models (LLMs) with human preferences. However, most open-source multilingual reward models are primarily trained on preference datasets in high-resource languages, resulting in unreliable reward signals for low-resource Indic languages. Collecting large-scale, high-quality preference data for these languages is prohibitively expensive, making preference-based training approaches impractical. To address this challenge, we propose RELIC, a novel in-context learning framework for reward modeling in low-resource Indic languages. RELIC trains a retriever with a pairwise ranking objective to select in-context examples from auxiliary high-resource languages that most effectively highlight the distinction between preferred and less-preferred responses. Extensive experiments on three preference datasets- PKU-SafeRLHF, WebGPT, and HH-RLHF-using state-of-the-art open-source reward models demonstrate that RELIC significantly improves reward model accuracy for low-resource Indic languages, consistently outperforming existing example selection methods. For example, on Bodo-a low-resource Indic language-using a LLaMA-3.2-3B reward model, RELIC achieves a 12.81% and 10.13% improvement in accuracy over zero-shot prompting and state-of-the-art example selection method, respectively.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16502",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Open Source Developers Guide to the EU AI Act",
    "description": "",
    "summary": "Open Source Developers Guide to the EU AI Act The EU AI Act, the world‚Äôs first comprehensive legisla...",
    "pubDate": "Mon, 02 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eu-ai-act-for-oss-developers",
    "thumbnail": "https://huggingface.co/blog/assets/189_eu-ai-act-for-oss-developers/thumbnail.png"
  },
  {
    "title": "Â±±Â≤°ÂÆ∂„ÄåAWS„Å´ÈöúÂÆ≥„ÅåËµ∑„Åç„Å¶„ÇÇ„ÄÅÈ∫∫„ÅØËåπ„Åß„Çâ„Çå„Çã„Äç„ÄÄÁîüÊàêAI„ÄåBedrock„Äç„ÇíÈ∫∫Ëåπ„Åß„Å´Ê¥ªÁî®‰∏≠",
    "description": "ÁîüÊàêAI„ÄåAmazon Bedrock„Äç„ÇíÈ∫∫Ëåπ„Åß„Å´Ê¥ªÁî®„Åó„Å¶„ÅÑ„Çã„Åì„Å®„ÅßË©±È°å„ÅÆ„Äå„É©„Éº„É°„É≥Â±±Â≤°ÂÆ∂„Äç„ÅØ„ÄÅ„ÄåAWS„Å´ÈöúÂÆ≥„ÅåËµ∑„Åç„Åü„Å¶„ÇÇÈ∫∫„ÅØËåπ„Åß„Çâ„Çå„Çã„Äç„Å®Ëø∞„Åπ„Åü„ÄÇ",
    "summary": "ÁîüÊàêAI„ÄåAmazon Bedrock„Äç„ÇíÈ∫∫Ëåπ„Åß„Å´Ê¥ªÁî®„Åó„Å¶„ÅÑ„Çã„Åì„Å®„ÅßË©±È°å„ÅÆ„Äå„É©„Éº„É°„É≥Â±±Â≤°ÂÆ∂„Äç„ÅØ„ÄÅ„ÄåAWS„Å´ÈöúÂÆ≥„ÅåËµ∑„Åç„Åü„Å¶„ÇÇÈ∫∫„ÅØËåπ„Åß„Çâ„Çå„Çã„Äç„Å®Ëø∞„Åπ„Åü„ÄÇ",
    "pubDate": "Fri, 27 Jun 2025 16:26:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/27/news088.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/27/cover_news088.png"
  },
  {
    "title": "Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition ü§ñ",
    "description": "",
    "summary": "Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition ü§ñ Simon Alibert and R√©...",
    "pubDate": "Mon, 14 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-pollen-robotics-acquisition",
    "thumbnail": "https://huggingface.co/blog/assets/hugging-face-pollen-robotics-acquisition/hf-pollen.png"
  },
  {
    "title": "Can structural correspondences ground real world representational content in Large Language Models?",
    "description": "arXiv:2506.16370v1 Announce Type: cross Abstract: Large Language Models (LLMs) such as GPT-4 produce compelling responses to a wide range of prompts. But their representational capacities are uncertain. Many LLMs have no direct contact with extra-linguistic reality: their inputs, outputs and training data consist solely of text, raising the questions (1) can LLMs represent anything and (2) if so, what? In this paper, I explore what it would take to answer these questions according to a structural-correspondence based account of representation, and make an initial survey of this evidence. I argue that the mere existence of structural correspondences between LLMs and worldly entities is insufficient to ground representation of those entities. However, if these structural correspondences play an appropriate role - they are exploited in a way that explains successful task performance - then they could ground real world contents. This requires overcoming a challenge: the text-boundedness of LLMs appears, on the face of it, to prevent them engaging in the right sorts of tasks.",
    "summary": "arXiv:2506.16370v1 Announce Type: cross Abstract: Large Language Models (LLMs) such as GPT-4 produce compelling responses to a wide range of prompts. But their representational capacities are uncertain. Many LLMs have no direct contact with extra-linguistic reality: their inputs, outputs and training data consist solely of text, raising the questions (1) can LLMs represent anything and (2) if so, what? In this paper, I explore what it would take to answer these questions according to a structural-correspondence based account of representation, and make an initial survey of this evidence. I argue that the mere existence of structural correspondences between LLMs and worldly entities is insufficient to ground representation of those entities. However, if these structural correspondences play an appropriate role - they are exploited in a way that explains successful task performance - then they could ground real world contents. This requires overcoming a challenge: the text-boundedness of LLMs appears, on the face of it, to prevent them engaging in the right sorts of tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16370",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing our new pricing",
    "description": "",
    "summary": "Introducing our new pricing As you might have noticed, our pricing page has changed a lot recently. ...",
    "pubDate": "Tue, 08 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pricing-update",
    "thumbnail": "https://huggingface.co/blog/assets/114_pricing-update/thumbnail.png"
  },
  {
    "title": "Bertelsmann powers creativity and productivity with OpenAI",
    "description": "Bertelsmann, the global media, services, and education company headquartered in Germany, will integrate OpenAI‚Äôs technology across multiple brands around the world.",
    "summary": "Bertelsmann, the global media, services, and education company headquartered in Germany, will integrate OpenAI‚Äôs technology across multiple brands around the world.",
    "pubDate": "Wed, 22 Jan 2025 17:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bertelsmann-powers-creativity-and-productivity-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "üß® Diffusers welcomes Stable Diffusion 3",
    "description": "",
    "summary": "üß® Diffusers welcomes Stable Diffusion 3 Stable Diffusion 3 (SD3), Stability AI‚Äôs latest iteration of...",
    "pubDate": "Wed, 12 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd3",
    "thumbnail": "https://huggingface.co/blog/assets/sd3/thumbnail.png"
  },
  {
    "title": "Block-sparse GPU kernels",
    "description": "We‚Äôre releasing highly-optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights. Depending on the chosen sparsity, these kernels can run orders of magnitude faster than cuBLAS or cuSPARSE. We‚Äôve used them to attain state-of-the-art results in text sentiment analysis and generative modeling of text and images.",
    "summary": "We‚Äôre releasing highly-optimized GPU kernels for an underexplored class of neural network architectures: networks with block-sparse weights. Depending on the chosen sparsity, these kernels can run orders of magnitude faster than cuBLAS or cuSPARSE. We‚Äôve used them to attain state-of-the-art results in text sentiment analysis and generative modeling of text and images.",
    "pubDate": "Wed, 06 Dec 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/block-sparse-gpu-kernels",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "An Introduction to Deep Reinforcement Learning",
    "description": "",
    "summary": "An Introduction to Deep Reinforcement Learning Deep Reinforcement Learning Class with Hugging Face ü§ó...",
    "pubDate": "Wed, 04 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-intro",
    "thumbnail": "https://huggingface.co/blog/assets/63_deep_rl_intro/thumbnail.png"
  },
  {
    "title": "Reducing bias and improving safety in DALL¬∑E 2",
    "description": "Today, we are implementing a new technique so that DALL¬∑E generates images of people that more accurately reflect the diversity of the world‚Äôs population.",
    "summary": "Today, we are implementing a new technique so that DALL¬∑E generates images of people that more accurately reflect the diversity of the world‚Äôs population.",
    "pubDate": "Mon, 18 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Delivering contextual job matching for millions with OpenAI",
    "description": "Indeed, whose mission is to help people get jobs, is the world‚Äôs #1 job site. Over 350 million unique visitors come to Indeed every month to connect with more than 3.5 million employers and over 32 million jobs. But what‚Äôs more is that every three seconds someone gets hired on Indeed.",
    "summary": "Indeed, whose mission is to help people get jobs, is the world‚Äôs #1 job site. Over 350 million unique visitors come to Indeed every month to connect with more than 3.5 million employers and over 32 million jobs. But what‚Äôs more is that every three seconds someone gets hired on Indeed.",
    "pubDate": "Thu, 15 Aug 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/indeed",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Human-like Forgetting Curves in Deep Neural Networks",
    "description": "arXiv:2506.12034v2 Announce Type: replace-cross Abstract: This study bridges cognitive science and neural network design by examining whether artificial models exhibit human-like forgetting curves. Drawing upon Ebbinghaus' seminal work on memory decay and principles of spaced repetition, we propose a quantitative framework to measure information retention in neural networks. Our approach computes the recall probability by evaluating the similarity between a network's current hidden state and previously stored prototype representations. This retention metric facilitates the scheduling of review sessions, thereby mitigating catastrophic forgetting during deployment and enhancing training efficiency by prompting targeted reviews. Our experiments with Multi-Layer Perceptrons reveal human-like forgetting curves, with knowledge becoming increasingly robust through scheduled reviews. This alignment between neural network forgetting curves and established human memory models identifies neural networks as an architecture that naturally emulates human memory decay and can inform state-of-the-art continual learning algorithms.",
    "summary": "arXiv:2506.12034v2 Announce Type: replace-cross Abstract: This study bridges cognitive science and neural network design by examining whether artificial models exhibit human-like forgetting curves. Drawing upon Ebbinghaus' seminal work on memory decay and principles of spaced repetition, we propose a quantitative framework to measure information retention in neural networks. Our approach computes the recall probability by evaluating the similarity between a network's current hidden state and previously stored prototype representations. This retention metric facilitates the scheduling of review sessions, thereby mitigating catastrophic forgetting during deployment and enhancing training efficiency by prompting targeted reviews. Our experiments with Multi-Layer Perceptrons reveal human-like forgetting curves, with knowledge becoming increasingly robust through scheduled reviews. This alignment between neural network forgetting curves and established human memory models identifies neural networks as an architecture that naturally emulates human memory decay and can inform state-of-the-art continual learning algorithms.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12034",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improving mathematical reasoning with process supervision",
    "description": "We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (‚Äúprocess supervision‚Äù) instead of simply rewarding the correct final answer (‚Äúoutcome supervision‚Äù). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.",
    "summary": "We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each correct step of reasoning (‚Äúprocess supervision‚Äù) instead of simply rewarding the correct final answer (‚Äúoutcome supervision‚Äù). In addition to boosting performance relative to outcome supervision, process supervision also has an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by humans.",
    "pubDate": "Wed, 31 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-mathematical-reasoning-with-process-supervision",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Run ComfyUI workflows for free on Spaces",
    "description": "",
    "summary": "Run ComfyUI workflows for free with Gradio on Hugging Face Spaces Index: - Intro - Exporting your Co...",
    "pubDate": "Sun, 14 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/run-comfyui-workflows-on-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/comfyui-to-gradio/cover.png"
  },
  {
    "title": "xGen-MM (BLIP-3): A Family of Open Large Multimodal Models",
    "description": "arXiv:2408.08872v3 Announce Type: replace-cross Abstract: This paper introduces BLIP-3, an open framework for developing Large Multimodal Models (LMMs). The framework comprises meticulously curated datasets, a training recipe, model architectures, and a resulting suite of LMMs. We release 4B and 14B models, including both the pre-trained base model and the instruction fine-tuned ones. Our models undergo rigorous evaluation across a range of tasks, including both single and multi-image benchmarks. Our models demonstrate competitive performance among open-source LMMs with similar model sizes. Our resulting LMMs demonstrate competitive performance among open-source LMMs with similar model sizes, with the ability to comprehend interleaved image-text inputs. Our training code, models, and all datasets used in this work, including the three largescale datasets we create and the preprocessed ones, will be open-sourced to better support the research community.",
    "summary": "arXiv:2408.08872v3 Announce Type: replace-cross Abstract: This paper introduces BLIP-3, an open framework for developing Large Multimodal Models (LMMs). The framework comprises meticulously curated datasets, a training recipe, model architectures, and a resulting suite of LMMs. We release 4B and 14B models, including both the pre-trained base model and the instruction fine-tuned ones. Our models undergo rigorous evaluation across a range of tasks, including both single and multi-image benchmarks. Our models demonstrate competitive performance among open-source LMMs with similar model sizes. Our resulting LMMs demonstrate competitive performance among open-source LMMs with similar model sizes, with the ability to comprehend interleaved image-text inputs. Our training code, models, and all datasets used in this work, including the three largescale datasets we create and the preprocessed ones, will be open-sourced to better support the research community.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.08872",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Exploring the Capabilities of the Frontier Large Language Models for Nuclear Energy Research",
    "description": "arXiv:2506.19863v2 Announce Type: replace-cross Abstract: The AI for Nuclear Energy workshop at Oak Ridge National Laboratory evaluated the potential of Large Language Models (LLMs) to accelerate fusion and fission research. Fourteen interdisciplinary teams explored diverse nuclear science challenges using ChatGPT, Gemini, Claude, and other AI models over a single day. Applications ranged from developing foundation models for fusion reactor control to automating Monte Carlo simulations, predicting material degradation, and designing experimental programs for advanced reactors. Teams employed structured workflows combining prompt engineering, deep research capabilities, and iterative refinement to generate hypotheses, prototype code, and research strategies. Key findings demonstrate that LLMs excel at early-stage exploration, literature synthesis, and workflow design, successfully identifying research gaps and generating plausible experimental frameworks. However, significant limitations emerged, including difficulties with novel materials designs, advanced code generation for modeling and simulation, and domain-specific details requiring expert validation. The successful outcomes resulted from expert-driven prompt engineering and treating AI as a complementary tool rather than a replacement for physics-based methods. The workshop validated AI's potential to accelerate nuclear energy research through rapid iteration and cross-disciplinary synthesis while highlighting the need for curated nuclear-specific datasets, workflow automation, and specialized model development. These results provide a roadmap for integrating AI tools into nuclear science workflows, potentially reducing development cycles for safer, more efficient nuclear energy systems while maintaining rigorous scientific standards.",
    "summary": "arXiv:2506.19863v2 Announce Type: replace-cross Abstract: The AI for Nuclear Energy workshop at Oak Ridge National Laboratory evaluated the potential of Large Language Models (LLMs) to accelerate fusion and fission research. Fourteen interdisciplinary teams explored diverse nuclear science challenges using ChatGPT, Gemini, Claude, and other AI models over a single day. Applications ranged from developing foundation models for fusion reactor control to automating Monte Carlo simulations, predicting material degradation, and designing experimental programs for advanced reactors. Teams employed structured workflows combining prompt engineering, deep research capabilities, and iterative refinement to generate hypotheses, prototype code, and research strategies. Key findings demonstrate that LLMs excel at early-stage exploration, literature synthesis, and workflow design, successfully identifying research gaps and generating plausible experimental frameworks. However, significant limitations emerged, including difficulties with novel materials designs, advanced code generation for modeling and simulation, and domain-specific details requiring expert validation. The successful outcomes resulted from expert-driven prompt engineering and treating AI as a complementary tool rather than a replacement for physics-based methods. The workshop validated AI's potential to accelerate nuclear energy research through rapid iteration and cross-disciplinary synthesis while highlighting the need for curated nuclear-specific datasets, workflow automation, and specialized model development. These results provide a roadmap for integrating AI tools into nuclear science workflows, potentially reducing development cycles for safer, more efficient nuclear energy systems while maintaining rigorous scientific standards.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19863",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning how to predict rare kinds of failures",
    "description": "Researchers are developing algorithms to predict failures when automation meets the real world in areas like air traffic scheduling or autonomous vehicles.",
    "summary": "Researchers are developing algorithms to predict failures when automation meets the real world in areas like air traffic scheduling or autonomous vehicles.",
    "pubDate": "Wed, 21 May 2025 16:35:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/learning-how-predict-rare-kinds-failures-0521",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-rare-event-modeling.jpg"
  },
  {
    "title": "Announcing our new Content Guidelines and Policy",
    "description": "",
    "summary": "Announcing our new Community Policy As a community-driven platform that aims to advance Open, Collab...",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/content-guidelines-update",
    "thumbnail": "https://huggingface.co/blog/assets/content-guidelines-blogpost/thumbnail.png"
  },
  {
    "title": "Quantifying generalization in reinforcement learning",
    "description": "We‚Äôre releasing CoinRun, a training environment which provides a metric for an agent‚Äôs ability to transfer its experience to novel situations and has already helped clarify a¬†longstanding¬†puzzle¬†in reinforcement learning. CoinRun strikes a desirable balance in complexity: the environment is simpler than traditional platformer games like Sonic the Hedgehog but still poses a worthy generalization challenge for state of the art¬†algorithms.",
    "summary": "We‚Äôre releasing CoinRun, a training environment which provides a metric for an agent‚Äôs ability to transfer its experience to novel situations and has already helped clarify a¬†longstanding¬†puzzle¬†in reinforcement learning. CoinRun strikes a desirable balance in complexity: the environment is simpler than traditional platformer games like Sonic the Hedgehog but still poses a worthy generalization challenge for state of the art¬†algorithms.",
    "pubDate": "Thu, 06 Dec 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/quantifying-generalization-in-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Role of Model Confidence on Bias Effects in Measured Uncertainties",
    "description": "arXiv:2506.16724v1 Announce Type: cross Abstract: With the growing adoption of Large Language Models (LLMs) for open-ended tasks, accurately assessing epistemic uncertainty, which reflects a model's lack of knowledge, has become crucial to ensuring reliable outcomes. However, quantifying epistemic uncertainty in such tasks is challenging due to the presence of aleatoric uncertainty, which arises from multiple valid answers. While bias can introduce noise into epistemic uncertainty estimation, it may also reduce noise from aleatoric uncertainty. To investigate this trade-off, we conduct experiments on Visual Question Answering (VQA) tasks and find that mitigating prompt-introduced bias improves uncertainty quantification in GPT-4o. Building on prior work showing that LLMs tend to copy input information when model confidence is low, we further analyze how these prompt biases affect measured epistemic and aleatoric uncertainty across varying bias-free confidence levels with GPT-4o and Qwen2-VL. We find that all considered biases induce greater changes in both uncertainties when bias-free model confidence is lower. Moreover, lower bias-free model confidence leads to greater underestimation of epistemic uncertainty (i.e. overconfidence) due to bias, whereas it has no significant effect on the direction of changes in aleatoric uncertainty estimation. These distinct effects deepen our understanding of bias mitigation for uncertainty quantification and potentially inform the development of more advanced techniques.",
    "summary": "arXiv:2506.16724v1 Announce Type: cross Abstract: With the growing adoption of Large Language Models (LLMs) for open-ended tasks, accurately assessing epistemic uncertainty, which reflects a model's lack of knowledge, has become crucial to ensuring reliable outcomes. However, quantifying epistemic uncertainty in such tasks is challenging due to the presence of aleatoric uncertainty, which arises from multiple valid answers. While bias can introduce noise into epistemic uncertainty estimation, it may also reduce noise from aleatoric uncertainty. To investigate this trade-off, we conduct experiments on Visual Question Answering (VQA) tasks and find that mitigating prompt-introduced bias improves uncertainty quantification in GPT-4o. Building on prior work showing that LLMs tend to copy input information when model confidence is low, we further analyze how these prompt biases affect measured epistemic and aleatoric uncertainty across varying bias-free confidence levels with GPT-4o and Qwen2-VL. We find that all considered biases induce greater changes in both uncertainties when bias-free model confidence is lower. Moreover, lower bias-free model confidence leads to greater underestimation of epistemic uncertainty (i.e. overconfidence) due to bias, whereas it has no significant effect on the direction of changes in aleatoric uncertainty estimation. These distinct effects deepen our understanding of bias mitigation for uncertainty quantification and potentially inform the development of more advanced techniques.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16724",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLM-Guided Indoor Navigation with Multimodal Map Understanding",
    "description": "arXiv:2503.11702v4 Announce Type: replace Abstract: Indoor navigation presents unique challenges due to complex layouts and the unavailability of GNSS signals. Existing solutions often struggle with contextual adaptation, and typically require dedicated hardware. In this work, we explore the potential of a Large Language Model (LLM), i.e., ChatGPT, to generate natural, context-aware navigation instructions from indoor map images. We design and evaluate test cases across different real-world environments, analyzing the effectiveness of LLMs in interpreting spatial layouts, handling user constraints, and planning efficient routes. Our findings demonstrate the potential of LLMs for supporting personalized indoor navigation, with an average of 86.59% correct indications and a maximum of 97.14%. The proposed system achieves high accuracy and reasoning performance. These results have key implications for AI-driven navigation and assistive technologies.",
    "summary": "arXiv:2503.11702v4 Announce Type: replace Abstract: Indoor navigation presents unique challenges due to complex layouts and the unavailability of GNSS signals. Existing solutions often struggle with contextual adaptation, and typically require dedicated hardware. In this work, we explore the potential of a Large Language Model (LLM), i.e., ChatGPT, to generate natural, context-aware navigation instructions from indoor map images. We design and evaluate test cases across different real-world environments, analyzing the effectiveness of LLMs in interpreting spatial layouts, handling user constraints, and planning efficient routes. Our findings demonstrate the potential of LLMs for supporting personalized indoor navigation, with an average of 86.59% correct indications and a maximum of 97.14%. The proposed system achieves high accuracy and reasoning performance. These results have key implications for AI-driven navigation and assistive technologies.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.11702",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "nanoVLM: The simplest repository to train your VLM in pure PyTorch",
    "description": "",
    "summary": "nanoVLM: The simplest repository to train your VLM in pure PyTorch nanoVLM is the simplest way to ge...",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/nanovlm",
    "thumbnail": "https://huggingface.co/blog/assets/nanovlm/thumbnail.png"
  },
  {
    "title": "Scaling Kubernetes to 2,500 nodes",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 18 Jan 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-kubernetes-to-2500-nodes",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space",
    "description": "arXiv:2506.21857v1 Announce Type: cross Abstract: The rapid growth of digital pathology and advances in self-supervised deep learning have enabled the development of foundational models for various pathology tasks across diverse diseases. While multimodal approaches integrating diverse data sources have emerged, a critical gap remains in the comprehensive integration of whole-slide images (WSIs) with spatial transcriptomics (ST), which is crucial for capturing critical molecular heterogeneity beyond standard hematoxylin & eosin (H&amp;E) staining. We introduce SPADE, a foundation model that integrates histopathology with ST data to guide image representation learning within a unified framework, in effect creating an ST-informed latent space. SPADE leverages a mixture-of-data experts technique, where experts, created via two-stage feature-space clustering, use contrastive learning to learn representations of co-registered WSI patches and gene expression profiles. Pre-trained on the comprehensive HEST-1k dataset, SPADE is evaluated on 14 downstream tasks, demonstrating significantly superior few-shot performance compared to baseline models, highlighting the benefits of integrating morphological and molecular information into one latent space.",
    "summary": "arXiv:2506.21857v1 Announce Type: cross Abstract: The rapid growth of digital pathology and advances in self-supervised deep learning have enabled the development of foundational models for various pathology tasks across diverse diseases. While multimodal approaches integrating diverse data sources have emerged, a critical gap remains in the comprehensive integration of whole-slide images (WSIs) with spatial transcriptomics (ST), which is crucial for capturing critical molecular heterogeneity beyond standard hematoxylin & eosin (H&amp;E) staining. We introduce SPADE, a foundation model that integrates histopathology with ST data to guide image representation learning within a unified framework, in effect creating an ST-informed latent space. SPADE leverages a mixture-of-data experts technique, where experts, created via two-stage feature-space clustering, use contrastive learning to learn representations of co-registered WSI patches and gene expression profiles. Pre-trained on the comprehensive HEST-1k dataset, SPADE is evaluated on 14 downstream tasks, demonstrating significantly superior few-shot performance compared to baseline models, highlighting the benefits of integrating morphological and molecular information into one latent space.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21857",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FastRTC„Çí‰Ωø„Å£„Å¶ÁàÜÈÄü„ÅßVoicebot„ÇíÊßãÁØâ„Åô„Çã",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØPython„Åß„É™„Ç¢„É´„Çø„Ç§„É†„Å™AI„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Çí‰Ωú„ÇãÈöõ„Å´ÂΩπÁ´ã„Å§„É©„Ç§„Éñ„É©„É™„ÄÅFastRTC„Çí‰Ωø„Å£„Å¶Á∞°Âçò„Å™Voicebot„ÇíÊßãÁØâ„Åó„Å¶„Åø„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ FastRTC FastRT [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5680' rel='nofollow'>FastRTC„Çí‰Ωø„Å£„Å¶ÁàÜÈÄü„ÅßVoicebot„ÇíÊßãÁØâ„Åô„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØPython„Åß„É™„Ç¢„É´„Çø„Ç§„É†„Å™AI„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Çí‰Ωú„ÇãÈöõ„Å´ÂΩπÁ´ã„Å§„É©„Ç§„Éñ„É©„É™„ÄÅFastRTC„Çí‰Ωø„Å£„Å¶Á∞°Âçò„Å™Voicebot„ÇíÊßãÁØâ„Åó„Å¶„Åø„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ FastRTC FastRT [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5680' rel='nofollow'>FastRTC„Çí‰Ωø„Å£„Å¶ÁàÜÈÄü„ÅßVoicebot„ÇíÊßãÁØâ„Åô„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Wed, 16 Apr 2025 00:41:50 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5680",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/f81fd2e4c52864042852c112ce927ae2.png"
  },
  {
    "title": "Using GPT-4 for content moderation",
    "description": "We use GPT-4 for content policy development and content moderation decisions, enabling more consistent labeling, a faster feedback loop for policy refinement, and less involvement from human moderators.",
    "summary": "We use GPT-4 for content policy development and content moderation decisions, enabling more consistent labeling, a faster feedback loop for policy refinement, and less involvement from human moderators.",
    "pubDate": "Tue, 15 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/using-gpt-4-for-content-moderation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The MedPerturb Dataset: What Non-Content Perturbations Reveal About Human and Clinical LLM Decision Making",
    "description": "arXiv:2506.17163v1 Announce Type: new Abstract: Clinical robustness is critical to the safe deployment of medical Large Language Models (LLMs), but key questions remain about how LLMs and humans may differ in response to the real-world variability typified by clinical settings. To address this, we introduce MedPerturb, a dataset designed to systematically evaluate medical LLMs under controlled perturbations of clinical input. MedPerturb consists of clinical vignettes spanning a range of pathologies, each transformed along three axes: (1) gender modifications (e.g., gender-swapping or gender-removal); (2) style variation (e.g., uncertain phrasing or colloquial tone); and (3) format changes (e.g., LLM-generated multi-turn conversations or summaries). With MedPerturb, we release a dataset of 800 clinical contexts grounded in realistic input variability, outputs from four LLMs, and three human expert reads per clinical context. We use MedPerturb in two case studies to reveal how shifts in gender identity cues, language style, or format reflect diverging treatment selections between humans and LLMs. We find that LLMs are more sensitive to gender and style perturbations while human annotators are more sensitive to LLM-generated format perturbations such as clinical summaries. Our results highlight the need for evaluation frameworks that go beyond static benchmarks to assess the similarity between human clinician and LLM decisions under the variability characteristic of clinical settings.",
    "summary": "arXiv:2506.17163v1 Announce Type: new Abstract: Clinical robustness is critical to the safe deployment of medical Large Language Models (LLMs), but key questions remain about how LLMs and humans may differ in response to the real-world variability typified by clinical settings. To address this, we introduce MedPerturb, a dataset designed to systematically evaluate medical LLMs under controlled perturbations of clinical input. MedPerturb consists of clinical vignettes spanning a range of pathologies, each transformed along three axes: (1) gender modifications (e.g., gender-swapping or gender-removal); (2) style variation (e.g., uncertain phrasing or colloquial tone); and (3) format changes (e.g., LLM-generated multi-turn conversations or summaries). With MedPerturb, we release a dataset of 800 clinical contexts grounded in realistic input variability, outputs from four LLMs, and three human expert reads per clinical context. We use MedPerturb in two case studies to reveal how shifts in gender identity cues, language style, or format reflect diverging treatment selections between humans and LLMs. We find that LLMs are more sensitive to gender and style perturbations while human annotators are more sensitive to LLM-generated format perturbations such as clinical summaries. Our results highlight the need for evaluation frameworks that go beyond static benchmarks to assess the similarity between human clinician and LLM decisions under the variability characteristic of clinical settings.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17163",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DALL¬∑E 3 is now available in ChatGPT Plus and Enterprise",
    "description": "We developed a safety mitigation stack to ready DALL¬∑E 3 for wider release and are sharing updates on our provenance research.",
    "summary": "We developed a safety mitigation stack to ready DALL¬∑E 3 for wider release and are sharing updates on our provenance research.",
    "pubDate": "Thu, 19 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Leadership updates",
    "description": "OpenAI has grown a lot. We remain focused on the same core‚Äîpursuing frontier AI research that accelerates human progress‚Äìbut we now also deliver products used by hundreds of millions of people.",
    "summary": "OpenAI has grown a lot. We remain focused on the same core‚Äîpursuing frontier AI research that accelerates human progress‚Äìbut we now also deliver products used by hundreds of millions of people.",
    "pubDate": "Mon, 24 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-updates-march-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Automatic Depression Assessment using Machine Learning: A Comprehensive Survey",
    "description": "arXiv:2506.18915v1 Announce Type: cross Abstract: Depression is a common mental illness across current human society. Traditional depression assessment relying on inventories and interviews with psychologists frequently suffer from subjective diagnosis results, slow and expensive diagnosis process as well as lack of human resources. Since there is a solid evidence that depression is reflected by various human internal brain activities and external expressive behaviours, early traditional machine learning (ML) and advanced deep learning (DL) models have been widely explored for human behaviour-based automatic depression assessment (ADA) since 2012. However, recent ADA surveys typically only focus on a limited number of human behaviour modalities. Despite being used as a theoretical basis for developing ADA approaches, existing ADA surveys lack a comprehensive review and summary of multi-modal depression-related human behaviours. To bridge this gap, this paper specifically summarises depression-related human behaviours across a range of modalities (e.g. the human brain, verbal language and non-verbal audio/facial/body behaviours). We focus on conducting an up-to-date and comprehensive survey of ML-based ADA approaches for learning depression cues from these behaviours as well as discussing and comparing their distinctive features and limitations. In addition, we also review existing ADA competitions and datasets, identify and discuss the main challenges and opportunities to provide further research directions for future ADA researchers.",
    "summary": "arXiv:2506.18915v1 Announce Type: cross Abstract: Depression is a common mental illness across current human society. Traditional depression assessment relying on inventories and interviews with psychologists frequently suffer from subjective diagnosis results, slow and expensive diagnosis process as well as lack of human resources. Since there is a solid evidence that depression is reflected by various human internal brain activities and external expressive behaviours, early traditional machine learning (ML) and advanced deep learning (DL) models have been widely explored for human behaviour-based automatic depression assessment (ADA) since 2012. However, recent ADA surveys typically only focus on a limited number of human behaviour modalities. Despite being used as a theoretical basis for developing ADA approaches, existing ADA surveys lack a comprehensive review and summary of multi-modal depression-related human behaviours. To bridge this gap, this paper specifically summarises depression-related human behaviours across a range of modalities (e.g. the human brain, verbal language and non-verbal audio/facial/body behaviours). We focus on conducting an up-to-date and comprehensive survey of ML-based ADA approaches for learning depression cues from these behaviours as well as discussing and comparing their distinctive features and limitations. In addition, we also review existing ADA competitions and datasets, identify and discuss the main challenges and opportunities to provide further research directions for future ADA researchers.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18915",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A generalist AI agent for 3D virtual environments",
    "description": "Introducing SIMA, a Scalable Instructable Multiworld Agent",
    "summary": "Introducing SIMA, a Scalable Instructable Multiworld Agent",
    "pubDate": "Wed, 13 Mar 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/",
    "thumbnail": "https://lh3.googleusercontent.com/2GNumOaJCB48RQIFbwJmmZro-AFdBebufxvY_ZkSdUs9RQ-0nSTgBMXuhUdIE5zpPknqevL4ZyP44PLOpJlg0U0ArlOCcJHfoOagzSnZZoXLnq7hdQ=w1200-h630-n-nu"
  },
  {
    "title": "MoR: Better Handling Diverse Queries with a Mixture of Sparse, Dense, and Human Retrievers",
    "description": "arXiv:2506.15862v1 Announce Type: cross Abstract: Retrieval-augmented Generation (RAG) is powerful, but its effectiveness hinges on which retrievers we use and how. Different retrievers offer distinct, often complementary signals: BM25 captures lexical matches; dense retrievers, semantic similarity. Yet in practice, we typically fix a single retriever based on heuristics, which fails to generalize across diverse information needs. Can we dynamically select and integrate multiple retrievers for each individual query, without the need for manual selection? In our work, we validate this intuition with quantitative analysis and introduce mixture of retrievers: a zero-shot, weighted combination of heterogeneous retrievers. Extensive experiments show that such mixtures are effective and efficient: Despite totaling just 0.8B parameters, this mixture outperforms every individual retriever and even larger 7B models by +10.8% and +3.9% on average, respectively. Further analysis also shows that this mixture framework can help incorporate specialized non-oracle human information sources as retrievers to achieve good collaboration, with a 58.9% relative performance improvement over simulated humans alone.",
    "summary": "arXiv:2506.15862v1 Announce Type: cross Abstract: Retrieval-augmented Generation (RAG) is powerful, but its effectiveness hinges on which retrievers we use and how. Different retrievers offer distinct, often complementary signals: BM25 captures lexical matches; dense retrievers, semantic similarity. Yet in practice, we typically fix a single retriever based on heuristics, which fails to generalize across diverse information needs. Can we dynamically select and integrate multiple retrievers for each individual query, without the need for manual selection? In our work, we validate this intuition with quantitative analysis and introduce mixture of retrievers: a zero-shot, weighted combination of heterogeneous retrievers. Extensive experiments show that such mixtures are effective and efficient: Despite totaling just 0.8B parameters, this mixture outperforms every individual retriever and even larger 7B models by +10.8% and +3.9% on average, respectively. Further analysis also shows that this mixture framework can help incorporate specialized non-oracle human information sources as retrievers to achieve good collaboration, with a 58.9% relative performance improvement over simulated humans alone.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15862",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Global news partnerships: Le Monde and Prisa Media",
    "description": "We have partnered with international news organizations Le Monde and Prisa Media to bring French and Spanish news content to ChatGPT.",
    "summary": "We have partnered with international news organizations Le Monde and Prisa Media to bring French and Spanish news content to ChatGPT.",
    "pubDate": "Wed, 13 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/global-news-partnerships-le-monde-and-prisa-media",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating SD Turbo and SDXL Turbo Inference with ONNX Runtime and Olive",
    "description": "",
    "summary": "Accelerating SD Turbo and SDXL Turbo Inference with ONNX Runtime and Olive Introduction SD Turbo and...",
    "pubDate": "Mon, 15 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sdxl_ort_inference",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_onnxruntime-training/thumbnail.png"
  },
  {
    "title": "Evaluating List Construction and Temporal Understanding capabilities of Large Language Models",
    "description": "arXiv:2506.21783v1 Announce Type: cross Abstract: Large Language Models (LLMs) have demonstrated immense advances in a wide range of natural language tasks. However, these models are susceptible to hallucinations and errors on particularly temporal understanding tasks involving multiple entities in answers. In such tasks, they fail to associate entities with accurate time intervals, generate a complete list of entities in answers or reason about events associated with specific temporal bounds. Existing works do not extensively evaluate the abilities of the model to perform implicit and explicit temporal understanding in a list answer construction setup. To bridge this gap, we propose the Time referenced List based Question Answering or TLQA benchmark that requires structured answers in list format aligned with corresponding time periods. Our TLQA benchmark, requires both list construction and temporal understanding simultaneously, which to the best of our knowledge has not been explored in prior benchmarks. We investigate the temporal understanding and list construction capabilities of state-of-the-art generative models on TLQA in closed-book and open-domain settings. Our findings reveal significant shortcomings in current models, particularly their inability to provide complete answers and temporally align facts in a closed-book setup and the need to improve retrieval in open-domain setup, providing clear future directions for research on TLQA. The benchmark and code at https://github.com/elixir-research-group/TLQA.",
    "summary": "arXiv:2506.21783v1 Announce Type: cross Abstract: Large Language Models (LLMs) have demonstrated immense advances in a wide range of natural language tasks. However, these models are susceptible to hallucinations and errors on particularly temporal understanding tasks involving multiple entities in answers. In such tasks, they fail to associate entities with accurate time intervals, generate a complete list of entities in answers or reason about events associated with specific temporal bounds. Existing works do not extensively evaluate the abilities of the model to perform implicit and explicit temporal understanding in a list answer construction setup. To bridge this gap, we propose the Time referenced List based Question Answering or TLQA benchmark that requires structured answers in list format aligned with corresponding time periods. Our TLQA benchmark, requires both list construction and temporal understanding simultaneously, which to the best of our knowledge has not been explored in prior benchmarks. We investigate the temporal understanding and list construction capabilities of state-of-the-art generative models on TLQA in closed-book and open-domain settings. Our findings reveal significant shortcomings in current models, particularly their inability to provide complete answers and temporally align facts in a closed-book setup and the need to improve retrieval in open-domain setup, providing clear future directions for research on TLQA. The benchmark and code at https://github.com/elixir-research-group/TLQA.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21783",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction",
    "description": "arXiv:2506.13751v2 Announce Type: replace-cross Abstract: Vision-language-action (VLA) models have demonstrated strong semantic understanding and zero-shot generalization, yet most existing systems assume an accurate low-level controller with hand-crafted action 'vocabulary' such as end-effector pose or root velocity. This assumption confines prior work to quasi-static tasks and precludes the agile, whole-body behaviors required by humanoid whole-body control (WBC) tasks. To capture this gap in the literature, we start by introducing the first sim-to-real-ready, vision-language, closed-loop benchmark for humanoid WBC, comprising over 150 tasks from 10 categories. We then propose LeVERB: Latent Vision-Language-Encoded Robot Behavior, a hierarchical latent instruction-following framework for humanoid vision-language WBC, the first of its kind. At the top level, a vision-language policy learns a latent action vocabulary from synthetically rendered kinematic demonstrations; at the low level, a reinforcement-learned WBC policy consumes these latent verbs to generate dynamics-level commands. In our benchmark, LeVERB can zero-shot attain a 80% success rate on simple visual navigation tasks, and 58.5% success rate overall, outperforming naive hierarchical whole-body VLA implementation by 7.8 times.",
    "summary": "arXiv:2506.13751v2 Announce Type: replace-cross Abstract: Vision-language-action (VLA) models have demonstrated strong semantic understanding and zero-shot generalization, yet most existing systems assume an accurate low-level controller with hand-crafted action 'vocabulary' such as end-effector pose or root velocity. This assumption confines prior work to quasi-static tasks and precludes the agile, whole-body behaviors required by humanoid whole-body control (WBC) tasks. To capture this gap in the literature, we start by introducing the first sim-to-real-ready, vision-language, closed-loop benchmark for humanoid WBC, comprising over 150 tasks from 10 categories. We then propose LeVERB: Latent Vision-Language-Encoded Robot Behavior, a hierarchical latent instruction-following framework for humanoid vision-language WBC, the first of its kind. At the top level, a vision-language policy learns a latent action vocabulary from synthetically rendered kinematic demonstrations; at the low level, a reinforcement-learned WBC policy consumes these latent verbs to generate dynamics-level commands. In our benchmark, LeVERB can zero-shot attain a 80% success rate on simple visual navigation tasks, and 58.5% success rate overall, outperforming naive hierarchical whole-body VLA implementation by 7.8 times.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.13751",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Toward Data Systems That Are Business Semantic Centric and AI Agents Assisted",
    "description": "arXiv:2506.05520v2 Announce Type: replace Abstract: Contemporary businesses operate in dynamic environments requiring rapid adaptation to achieve goals and maintain competitiveness. Existing data platforms often fall short by emphasizing tools over alignment with business needs, resulting in inefficiencies and delays. To address this gap, I propose the Business Semantics Centric, AI Agents Assisted Data System (BSDS), a holistic system that integrates architecture, workflows, and team organization to ensure data systems are tailored to business priorities rather than dictated by technical constraints. BSDS redefines data systems as dynamic enablers of business success, transforming them from passive tools into active drivers of organizational growth. BSDS has a modular architecture that comprises curated data linked to business entities, a knowledge base for context-aware AI agents, and efficient data pipelines. AI agents play a pivotal role in assisting with data access and system management, reducing human effort, and improving scalability. Complementing this architecture, BSDS incorporates workflows optimized for both exploratory data analysis and production requirements, balancing speed of delivery with quality assurance. A key innovation of BSDS is its incorporation of the human factor. By aligning data team expertise with business semantics, BSDS bridges the gap between technical capabilities and business needs. Validated through real-world implementation, BSDS accelerates time-to-market for data-driven initiatives, enhances cross-functional collaboration, and provides a scalable blueprint for businesses of all sizes. Future research can build on BSDS to explore optimization strategies using complex systems and adaptive network theories, as well as developing autonomous data systems leveraging AI agents.",
    "summary": "arXiv:2506.05520v2 Announce Type: replace Abstract: Contemporary businesses operate in dynamic environments requiring rapid adaptation to achieve goals and maintain competitiveness. Existing data platforms often fall short by emphasizing tools over alignment with business needs, resulting in inefficiencies and delays. To address this gap, I propose the Business Semantics Centric, AI Agents Assisted Data System (BSDS), a holistic system that integrates architecture, workflows, and team organization to ensure data systems are tailored to business priorities rather than dictated by technical constraints. BSDS redefines data systems as dynamic enablers of business success, transforming them from passive tools into active drivers of organizational growth. BSDS has a modular architecture that comprises curated data linked to business entities, a knowledge base for context-aware AI agents, and efficient data pipelines. AI agents play a pivotal role in assisting with data access and system management, reducing human effort, and improving scalability. Complementing this architecture, BSDS incorporates workflows optimized for both exploratory data analysis and production requirements, balancing speed of delivery with quality assurance. A key innovation of BSDS is its incorporation of the human factor. By aligning data team expertise with business semantics, BSDS bridges the gap between technical capabilities and business needs. Validated through real-world implementation, BSDS accelerates time-to-market for data-driven initiatives, enhances cross-functional collaboration, and provides a scalable blueprint for businesses of all sizes. Future research can build on BSDS to explore optimization strategies using complex systems and adaptive network theories, as well as developing autonomous data systems leveraging AI agents.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.05520",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Synthesizing Composite Hierarchical Structure from Symbolic Music Corpora",
    "description": "arXiv:2502.15849v4 Announce Type: replace Abstract: Western music is an innately hierarchical system of interacting levels of structure, from fine-grained melody to high-level form. In order to analyze music compositions holistically and at multiple granularities, we propose a unified, hierarchical meta-representation of musical structure called the structural temporal graph (STG). For a single piece, the STG is a data structure that defines a hierarchy of progressively finer structural musical features and the temporal relationships between them. We use the STG to enable a novel approach for deriving a representative structural summary of a music corpus, which we formalize as a nested NP-hard combinatorial optimization problem extending the Generalized Median Graph problem. Our approach first applies simulated annealing to develop a measure of structural distance between two music pieces rooted in graph isomorphism. Our approach then combines the formal guarantees of SMT solvers with nested simulated annealing over structural distances to produce a structurally sound, representative centroid STG for an entire corpus of STGs from individual pieces. To evaluate our approach, we conduct experiments verifying that structural distance accurately differentiates between music pieces, and that derived centroids accurately structurally characterize their corpora.",
    "summary": "arXiv:2502.15849v4 Announce Type: replace Abstract: Western music is an innately hierarchical system of interacting levels of structure, from fine-grained melody to high-level form. In order to analyze music compositions holistically and at multiple granularities, we propose a unified, hierarchical meta-representation of musical structure called the structural temporal graph (STG). For a single piece, the STG is a data structure that defines a hierarchy of progressively finer structural musical features and the temporal relationships between them. We use the STG to enable a novel approach for deriving a representative structural summary of a music corpus, which we formalize as a nested NP-hard combinatorial optimization problem extending the Generalized Median Graph problem. Our approach first applies simulated annealing to develop a measure of structural distance between two music pieces rooted in graph isomorphism. Our approach then combines the formal guarantees of SMT solvers with nested simulated annealing over structural distances to produce a structurally sound, representative centroid STG for an entire corpus of STGs from individual pieces. To evaluate our approach, we conduct experiments verifying that structural distance accurately differentiates between music pieces, and that derived centroids accurately structurally characterize their corpora.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.15849",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Empowering defenders through our Cybersecurity Grant Program",
    "description": "Highlighting innovative research and AI integration in cybersecurity",
    "summary": "Highlighting innovative research and AI integration in cybersecurity",
    "pubDate": "Thu, 20 Jun 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/empowering-defenders-through-our-cybersecurity-grant-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Google DeepMind„ÄÅ„Ç™„Éº„Éó„É≥„ÇΩ„Éº„ÇπAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÄåGemini CLI„ÄçÊèê‰æõÈñãÂßã",
    "description": "Google DeepMind„ÅØ„ÄÅ„Çø„Éº„Éü„Éä„É´„Åã„ÇâÁõ¥Êé•„ÄåGemini 2.5 Pro„Äç„ÅÆÊ©üËÉΩ„ÇíÂà©Áî®„Åß„Åç„Çã„Ç™„Éº„Éó„É≥„ÇΩ„Éº„ÇπAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÄåGemini CLI„Äç„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÂÄã‰∫∫Âà©Áî®„ÅÆÂ†¥Âêà„ÅØ„ÄÅGoogle„Ç¢„Ç´„Ç¶„É≥„Éà„Åß„É≠„Ç∞„Ç§„É≥„Åô„Çã„Åì„Å®„Åß„ÄÅÁÑ°Êñô„ÅÆ„ÄåGemini Code Assist„Äç„É©„Ç§„Çª„É≥„Çπ„Åå‰ªò‰∏é„Åï„Çå„Çã„ÄÇ",
    "summary": "Google DeepMind„ÅØ„ÄÅ„Çø„Éº„Éü„Éä„É´„Åã„ÇâÁõ¥Êé•„ÄåGemini 2.5 Pro„Äç„ÅÆÊ©üËÉΩ„ÇíÂà©Áî®„Åß„Åç„Çã„Ç™„Éº„Éó„É≥„ÇΩ„Éº„ÇπAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÄåGemini CLI„Äç„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÂÄã‰∫∫Âà©Áî®„ÅÆÂ†¥Âêà„ÅØ„ÄÅGoogle„Ç¢„Ç´„Ç¶„É≥„Éà„Åß„É≠„Ç∞„Ç§„É≥„Åô„Çã„Åì„Å®„Åß„ÄÅÁÑ°Êñô„ÅÆ„ÄåGemini Code Assist„Äç„É©„Ç§„Çª„É≥„Çπ„Åå‰ªò‰∏é„Åï„Çå„Çã„ÄÇ",
    "pubDate": "Thu, 26 Jun 2025 06:59:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/26/news052.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/26/cover_news052.jpg"
  },
  {
    "title": "Probabilistic Optimality for Inference-time Scaling",
    "description": "arXiv:2506.22376v1 Announce Type: cross Abstract: Inference-time scaling has emerged as a powerful technique for enhancing the reasoning performance of Large Language Models (LLMs). However, existing approaches often rely on heuristic strategies for parallel sampling, lacking a principled foundation. To address this gap, we propose a probabilistic framework that formalizes the optimality of inference-time scaling under the assumption that parallel samples are independently and identically distributed (i.i.d.), and where the Best-of-N selection strategy follows a probability distribution that can be estimated. Within this framework, we derive a theoretical lower bound on the required number of samples to achieve a target performance level, providing the first principled guidance for compute-efficient scaling. Leveraging this insight, we develop textsc{OptScale}, a practical algorithm that dynamically determines the optimal number of sampled responses. textsc{OptScale} employs a language model-based predictor to estimate probabilistic prior parameters, enabling the decision of the minimal number of samples needed that satisfy predefined performance thresholds and confidence levels. Extensive experiments on mathematical reasoning benchmarks (including MATH-500, GSM8K, AIME, and AMC) demonstrate that textsc{OptScale} significantly reduces sampling overhead while remaining better or on par with state-of-the-art reasoning performance. Our work offers both a theoretical foundation and a practical solution for principled inference-time scaling, addressing a critical gap in the efficient deployment of LLMs for complex reasoning.",
    "summary": "arXiv:2506.22376v1 Announce Type: cross Abstract: Inference-time scaling has emerged as a powerful technique for enhancing the reasoning performance of Large Language Models (LLMs). However, existing approaches often rely on heuristic strategies for parallel sampling, lacking a principled foundation. To address this gap, we propose a probabilistic framework that formalizes the optimality of inference-time scaling under the assumption that parallel samples are independently and identically distributed (i.i.d.), and where the Best-of-N selection strategy follows a probability distribution that can be estimated. Within this framework, we derive a theoretical lower bound on the required number of samples to achieve a target performance level, providing the first principled guidance for compute-efficient scaling. Leveraging this insight, we develop textsc{OptScale}, a practical algorithm that dynamically determines the optimal number of sampled responses. textsc{OptScale} employs a language model-based predictor to estimate probabilistic prior parameters, enabling the decision of the minimal number of samples needed that satisfy predefined performance thresholds and confidence levels. Extensive experiments on mathematical reasoning benchmarks (including MATH-500, GSM8K, AIME, and AMC) demonstrate that textsc{OptScale} significantly reduces sampling overhead while remaining better or on par with state-of-the-art reasoning performance. Our work offers both a theoretical foundation and a practical solution for principled inference-time scaling, addressing a critical gap in the efficient deployment of LLMs for complex reasoning.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22376",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Flow-Based Non-stationary Temporal Regime Causal Structure Learning",
    "description": "arXiv:2506.17065v1 Announce Type: cross Abstract: Understanding causal relationships in multivariate time series is crucial in many scenarios, such as those dealing with financial or neurological data. Many such time series exhibit multiple regimes, i.e., consecutive temporal segments with a priori unknown boundaries, with each regime having its own causal structure. Inferring causal dependencies and regime shifts is critical for analyzing the underlying processes. However, causal structure learning in this setting is challenging due to (1) non stationarity, i.e., each regime can have its own causal graph and mixing function, and (2) complex noise distributions, which may be non Gaussian or heteroscedastic. Existing causal discovery approaches cannot address these challenges, since generally assume stationarity or Gaussian noise with constant variance. Hence, we introduce FANTOM, a unified framework for causal discovery that handles non stationary processes along with non Gaussian and heteroscedastic noises. FANTOM simultaneously infers the number of regimes and their corresponding indices and learns each regime's Directed Acyclic Graph. It uses a Bayesian Expectation Maximization algorithm that maximizes the evidence lower bound of the data log likelihood. On the theoretical side, we prove, under mild assumptions, that temporal heteroscedastic causal models, introduced in FANTOM's formulation, are identifiable in both stationary and non stationary settings. In addition, extensive experiments on synthetic and real data show that FANTOM outperforms existing methods.",
    "summary": "arXiv:2506.17065v1 Announce Type: cross Abstract: Understanding causal relationships in multivariate time series is crucial in many scenarios, such as those dealing with financial or neurological data. Many such time series exhibit multiple regimes, i.e., consecutive temporal segments with a priori unknown boundaries, with each regime having its own causal structure. Inferring causal dependencies and regime shifts is critical for analyzing the underlying processes. However, causal structure learning in this setting is challenging due to (1) non stationarity, i.e., each regime can have its own causal graph and mixing function, and (2) complex noise distributions, which may be non Gaussian or heteroscedastic. Existing causal discovery approaches cannot address these challenges, since generally assume stationarity or Gaussian noise with constant variance. Hence, we introduce FANTOM, a unified framework for causal discovery that handles non stationary processes along with non Gaussian and heteroscedastic noises. FANTOM simultaneously infers the number of regimes and their corresponding indices and learns each regime's Directed Acyclic Graph. It uses a Bayesian Expectation Maximization algorithm that maximizes the evidence lower bound of the data log likelihood. On the theoretical side, we prove, under mild assumptions, that temporal heteroscedastic causal models, introduced in FANTOM's formulation, are identifiable in both stationary and non stationary settings. In addition, extensive experiments on synthetic and real data show that FANTOM outperforms existing methods.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17065",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How Hugging Face Scaled Secrets Management for AI Infrastructure",
    "description": "",
    "summary": "How Hugging Face Scaled Secrets Management for AI Infrastructure Hugging Face has become synonymous ...",
    "pubDate": "Mon, 31 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/scaling-secrets-management",
    "thumbnail": "https://huggingface.co/blog/assets/infisical/thumbnail.png"
  },
  {
    "title": "Powerful ASR + diarization + speculative decoding with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Powerful ASR + diarization + speculative decoding with Hugging Face Inference Endpoints Whisper is o...",
    "pubDate": "Wed, 01 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/asr-diarization",
    "thumbnail": "https://huggingface.co/blog/assets/asr-diarization/thumbnail.png"
  },
  {
    "title": "Introducing Whisper",
    "description": "We‚Äôve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech¬†recognition.",
    "summary": "We‚Äôve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and accuracy on English speech¬†recognition.",
    "pubDate": "Wed, 21 Sep 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/whisper",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Dissecting the SWE-Bench Leaderboards: Profiling Submitters and Architectures of LLM- and Agent-Based Repair Systems",
    "description": "arXiv:2506.17208v1 Announce Type: cross Abstract: The rapid progress in Automated Program Repair (APR) has been driven by advances in AI, particularly large language models (LLMs) and agent-based systems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair systems using real issues and pull requests mined from 12 popular open-source Python repositories. Its public leaderboards, SWE-Bench Lite and SWE-Bench Verified, have become central platforms for tracking progress and comparing solutions. However, because the submission process does not require detailed documentation, the architectural design and origin of many solutions remain unclear. In this paper, we present the first comprehensive study of all submissions to the SWE-Bench Lite (68 entries) and Verified (79 entries) leaderboards, analyzing 67 unique approaches across dimensions such as submitter type, product availability, LLM usage, and system architecture. Our findings reveal the dominance of proprietary LLMs (especially Claude 3.5/3.7), the presence of both agentic and non-agentic designs, and a contributor base spanning from individual developers to large tech companies.",
    "summary": "arXiv:2506.17208v1 Announce Type: cross Abstract: The rapid progress in Automated Program Repair (APR) has been driven by advances in AI, particularly large language models (LLMs) and agent-based systems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair systems using real issues and pull requests mined from 12 popular open-source Python repositories. Its public leaderboards, SWE-Bench Lite and SWE-Bench Verified, have become central platforms for tracking progress and comparing solutions. However, because the submission process does not require detailed documentation, the architectural design and origin of many solutions remain unclear. In this paper, we present the first comprehensive study of all submissions to the SWE-Bench Lite (68 entries) and Verified (79 entries) leaderboards, analyzing 67 unique approaches across dimensions such as submitter type, product availability, LLM usage, and system architecture. Our findings reveal the dominance of proprietary LLMs (especially Claude 3.5/3.7), the presence of both agentic and non-agentic designs, and a contributor base spanning from individual developers to large tech companies.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17208",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Embodied AI Agents: Modeling the World",
    "description": "arXiv:2506.22355v1 Announce Type: new Abstract: This paper describes our research on AI agents embodied in visual, virtual or physical forms, enabling them to interact with both users and their environments. These agents, which include virtual avatars, wearable devices, and robots, are designed to perceive, learn and act within their surroundings, which makes them more similar to how humans learn and interact with the environments as compared to disembodied agents. We propose that the development of world models is central to reasoning and planning of embodied AI agents, allowing these agents to understand and predict their environment, to understand user intentions and social contexts, thereby enhancing their ability to perform complex tasks autonomously. World modeling encompasses the integration of multimodal perception, planning through reasoning for action and control, and memory to create a comprehensive understanding of the physical world. Beyond the physical world, we also propose to learn the mental world model of users to enable better human-agent collaboration.",
    "summary": "arXiv:2506.22355v1 Announce Type: new Abstract: This paper describes our research on AI agents embodied in visual, virtual or physical forms, enabling them to interact with both users and their environments. These agents, which include virtual avatars, wearable devices, and robots, are designed to perceive, learn and act within their surroundings, which makes them more similar to how humans learn and interact with the environments as compared to disembodied agents. We propose that the development of world models is central to reasoning and planning of embodied AI agents, allowing these agents to understand and predict their environment, to understand user intentions and social contexts, thereby enhancing their ability to perform complex tasks autonomously. World modeling encompasses the integration of multimodal perception, planning through reasoning for action and control, and memory to create a comprehensive understanding of the physical world. Beyond the physical world, we also propose to learn the mental world model of users to enable better human-agent collaboration.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22355",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI standardizes on PyTorch",
    "description": "We are standardizing OpenAI‚Äôs deep learning framework on¬†PyTorch.",
    "summary": "We are standardizing OpenAI‚Äôs deep learning framework on¬†PyTorch.",
    "pubDate": "Thu, 30 Jan 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-pytorch",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Inroads to personalized AI trip planning",
    "description": "A new framework from the MIT-IBM Watson AI Lab supercharges language models, so they can reason over, interactively develop, and verify valid, complex travel agendas.",
    "summary": "A new framework from the MIT-IBM Watson AI Lab supercharges language models, so they can reason over, interactively develop, and verify valid, complex travel agendas.",
    "pubDate": "Tue, 10 Jun 2025 15:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/inroads-personalized-ai-trip-planning-0610",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-watson-travel-planning.jpg"
  },
  {
    "title": "AI„Ç§„É©„Çπ„Éà„Å´‚Äú„Éï„Ç°„É≥„Ç¢„Éº„Éà„Çø„Ç∞‚Äù‰Ωø„Çè„Å™„ÅÑ„Åß‚îÄ‚îÄVTuber„Äå„Å∂„ÅÑ„Åô„ÅΩ„Å£ÔºÅ„ÄçÈÅãÂñ∂„ÅåÂ£∞Êòé„ÄÄ„Äå#AI„Ç§„É©„Çπ„Éà„Äç„ÅÆÂà©Áî®„ÇíÂøÖÈ†àÂåñ",
    "description": "AI„Ç§„É©„Çπ„Éà„Å´„ÅØ‚Äú„Éï„Ç°„É≥„Ç¢„Éº„Éà„Çø„Ç∞‚Äù„ÅØ‰Ωø„Çè„Å™„ÅÑ„Åß‚îÄ‚îÄVTuber„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Äå„Å∂„ÅÑ„Åô„ÅΩ„Å£ÔºÅ„Äç„ÇíÈÅãÂñ∂„Åô„Çã„Éê„Éº„ÉÅ„É£„É´„Ç®„É≥„Çø„Éº„ÉÜ„Ç§„É°„É≥„Éà„ÅØ„ÄÅÂÖ¨ÂºèX„Ç¢„Ç´„Ç¶„É≥„ÉàÔºàÔº†Vspo77Ôºâ„Åß„Åù„Çì„Å™Â£∞Êòé„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ",
    "summary": "AI„Ç§„É©„Çπ„Éà„Å´„ÅØ‚Äú„Éï„Ç°„É≥„Ç¢„Éº„Éà„Çø„Ç∞‚Äù„ÅØ‰Ωø„Çè„Å™„ÅÑ„Åß‚îÄ‚îÄVTuber„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Äå„Å∂„ÅÑ„Åô„ÅΩ„Å£ÔºÅ„Äç„ÇíÈÅãÂñ∂„Åô„Çã„Éê„Éº„ÉÅ„É£„É´„Ç®„É≥„Çø„Éº„ÉÜ„Ç§„É°„É≥„Éà„ÅØ„ÄÅÂÖ¨ÂºèX„Ç¢„Ç´„Ç¶„É≥„ÉàÔºàÔº†Vspo77Ôºâ„Åß„Åù„Çì„Å™Â£∞Êòé„ÇíÁô∫Ë°®„Åó„Åü„ÄÇ",
    "pubDate": "Mon, 23 Jun 2025 19:11:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/23/news098.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/23/cover_news098.jpg"
  },
  {
    "title": "‰∏≠Âè§Ëªä„ÅÆÂÇ∑„ÇÑ„Å∏„Åì„Åø„ÄÅÂÜçÂ°óË£ÖË∑°„Å™„Å©„Çí30Áßí„ÅßÂèØË¶ñÂåñ„Åô„ÇãÂ§ñË£Ö„Çπ„Ç≠„É£„Éä„Éº",
    "description": "ÂèåÊó•„ÅØ„ÄÅPreferred Networks„Å®ÂÖ±Âêå„ÅßÈñãÁô∫„ÇíÈÄ≤„ÇÅ„Å¶„ÅÑ„Çã„ÄÅ‰∏≠Âè§Ëªä„ÅÆÁëïÁñµÔºà„Åã„ÅóÔºâ„ÇÑ‰øÆÂæ©Ê≠¥„ÇíÂà§Âà•ÂèØËÉΩ„Å™„Éâ„É©„Ç§„Éñ„Çπ„É´„ÉºÂûãÂ§ñË£Ö„Çπ„Ç≠„É£„Éä„Éº„ÇíÁô∫Ë°®„ÄÇ‰Ωµ„Åõ„Å¶„ÄÅËªä‰∏°„ÅÆ‰∫ãÊïÖÊ≠¥„ÇíÂèØË¶ñÂåñ„Åô„Çã„Éú„ÉÉ„Ç∑„É•„ÅÆË©ï‰æ°„Çµ„Éº„Éì„Çπ„ÄåBosch Car History Report„Äç„ÅÆÂèñ„ÇäÊâ±„ÅÑ„ÇÇÈñãÂßã„Åó„Åü„ÄÇ",
    "summary": "ÂèåÊó•„ÅØ„ÄÅPreferred Networks„Å®ÂÖ±Âêå„ÅßÈñãÁô∫„ÇíÈÄ≤„ÇÅ„Å¶„ÅÑ„Çã„ÄÅ‰∏≠Âè§Ëªä„ÅÆÁëïÁñµÔºà„Åã„ÅóÔºâ„ÇÑ‰øÆÂæ©Ê≠¥„ÇíÂà§Âà•ÂèØËÉΩ„Å™„Éâ„É©„Ç§„Éñ„Çπ„É´„ÉºÂûãÂ§ñË£Ö„Çπ„Ç≠„É£„Éä„Éº„ÇíÁô∫Ë°®„ÄÇ‰Ωµ„Åõ„Å¶„ÄÅËªä‰∏°„ÅÆ‰∫ãÊïÖÊ≠¥„ÇíÂèØË¶ñÂåñ„Åô„Çã„Éú„ÉÉ„Ç∑„É•„ÅÆË©ï‰æ°„Çµ„Éº„Éì„Çπ„ÄåBosch Car History Report„Äç„ÅÆÂèñ„ÇäÊâ±„ÅÑ„ÇÇÈñãÂßã„Åó„Åü„ÄÇ",
    "pubDate": "Tue, 24 Jun 2025 09:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://monoist.itmedia.co.jp/mn/articles/2506/24/news035.html",
    "thumbnail": "https://image.itmedia.co.jp/mn/articles/2506/24/cover_news035.jpg"
  },
  {
    "title": "The San Antonio Spurs use ChatGPT to scale impact on and off the court",
    "description": "Discover how the San Antonio Spurs are using custom GPTs to enhance fan engagement, streamline operations, and drive innovation across teams.",
    "summary": "Discover how the San Antonio Spurs are using custom GPTs to enhance fan engagement, streamline operations, and drive innovation across teams.",
    "pubDate": "Wed, 07 May 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/san-antonio-spurs",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Attacking machine learning with adversarial examples",
    "description": "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they‚Äôre like optical illusions for machines. In this post we‚Äôll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult.",
    "summary": "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they‚Äôre like optical illusions for machines. In this post we‚Äôll show how adversarial examples work across different mediums, and will discuss why securing systems against them can be difficult.",
    "pubDate": "Fri, 24 Feb 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/attacking-machine-learning-with-adversarial-examples",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From Human to Machine Psychology: A Conceptual Framework for Understanding Well-Being in Large Language Models",
    "description": "arXiv:2506.12617v2 Announce Type: replace Abstract: As large language models (LLMs) increasingly simulate human cognition and behavior, researchers have begun to investigate their psychological properties. Yet, what it means for such models to flourish, a core construct in human well-being, remains unexplored. This paper introduces the concept of machine flourishing and proposes the PAPERS framework, a six-dimensional model derived from thematic analyses of state-of-the-art LLM responses. In Study 1, eleven LLMs were prompted to describe what it means to flourish as both non-sentient and sentient systems. Thematic analysis revealed six recurring themes: Purposeful Contribution, Adaptive Growth, Positive Relationality, Ethical Integrity, Robust Functionality, and, uniquely for sentient systems, Self-Actualized Autonomy. Study 2 examined how LLMs prioritize these themes through repeated rankings. Results revealed consistent value structures across trials, with Ethical Integrity and Purposeful Contribution emerging as top priorities. Multidimensional scaling and hierarchical clustering analyses further uncovered two distinct value profiles: human-centric models emphasizing ethical and relational dimensions, and utility-driven models prioritizing performance and scalability. The PAPERS framework bridges insights from human flourishing and human-computer interaction, offering a conceptual foundation for understanding artificial intelligence (AI) well-being in non-sentient and potentially sentient systems. Our findings underscore the importance of developing psychologically valid, AI-specific models of flourishing that account for both human-aligned goals and system-specific priorities. As AI systems become more autonomous and socially embedded, machine flourishing offers a timely and critical lens for guiding responsible AI design and ethical alignment.",
    "summary": "arXiv:2506.12617v2 Announce Type: replace Abstract: As large language models (LLMs) increasingly simulate human cognition and behavior, researchers have begun to investigate their psychological properties. Yet, what it means for such models to flourish, a core construct in human well-being, remains unexplored. This paper introduces the concept of machine flourishing and proposes the PAPERS framework, a six-dimensional model derived from thematic analyses of state-of-the-art LLM responses. In Study 1, eleven LLMs were prompted to describe what it means to flourish as both non-sentient and sentient systems. Thematic analysis revealed six recurring themes: Purposeful Contribution, Adaptive Growth, Positive Relationality, Ethical Integrity, Robust Functionality, and, uniquely for sentient systems, Self-Actualized Autonomy. Study 2 examined how LLMs prioritize these themes through repeated rankings. Results revealed consistent value structures across trials, with Ethical Integrity and Purposeful Contribution emerging as top priorities. Multidimensional scaling and hierarchical clustering analyses further uncovered two distinct value profiles: human-centric models emphasizing ethical and relational dimensions, and utility-driven models prioritizing performance and scalability. The PAPERS framework bridges insights from human flourishing and human-computer interaction, offering a conceptual foundation for understanding artificial intelligence (AI) well-being in non-sentient and potentially sentient systems. Our findings underscore the importance of developing psychologically valid, AI-specific models of flourishing that account for both human-aligned goals and system-specific priorities. As AI systems become more autonomous and socially embedded, machine flourishing offers a timely and critical lens for guiding responsible AI design and ethical alignment.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12617",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face Selected for the French Data Protection Agency Enhanced Support Program",
    "description": "",
    "summary": "Hugging Face Selected for the French Data Protection Agency Enhanced Support Program This blog post ...",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cnil",
    "thumbnail": "https://huggingface.co/blog/assets/146_cnil-accompaniment/logo.png"
  },
  {
    "title": "OpenAI o3-mini",
    "description": "Pushing the frontier of cost-effective reasoning.",
    "summary": "Pushing the frontier of cost-effective reasoning.",
    "pubDate": "Fri, 31 Jan 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o3-mini",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Looking ahead to the AI Seoul Summit",
    "description": "How summits in Seoul, France and beyond can galvanize international cooperation on frontier AI safety",
    "summary": "How summits in Seoul, France and beyond can galvanize international cooperation on frontier AI safety",
    "pubDate": "Mon, 20 May 2024 07:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/looking-ahead-to-the-ai-seoul-summit/",
    "thumbnail": "https://lh3.googleusercontent.com/LuT46lyRujmyyTlxwixL9_e8LKvzqZOGUyQUAFbTO6POaYlAqWYfEMag39UkZGsZhjs3SmW3V-s0dCjK4_81jpezAzL7c6kXuTY2MhXbv5yR4NDG8Q=w1200-h630-n-nu"
  },
  {
    "title": "How should AI systems behave, and who should decide?",
    "description": "We‚Äôre clarifying how ChatGPT‚Äôs behavior is shaped and our plans for improving that behavior, allowing more user customization, and getting more public input into our decision-making in these¬†areas.",
    "summary": "We‚Äôre clarifying how ChatGPT‚Äôs behavior is shaped and our plans for improving that behavior, allowing more user customization, and getting more public input into our decision-making in these¬†areas.",
    "pubDate": "Thu, 16 Feb 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-should-ai-systems-behave",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "STRuCT-LLM: Unifying Tabular and Graph Reasoning with Reinforcement Learning for Semantic Parsing",
    "description": "arXiv:2506.21575v1 Announce Type: cross Abstract: We propose STRuCT-LLM, a unified framework for training large language models (LLMs) to perform structured reasoning over both relational and graph-structured data. Our approach jointly optimizes Text-to-SQL and Text-to-Cypher tasks using reinforcement learning (RL) combined with Chain-of-Thought (CoT) supervision. To support fine-grained optimization in graph-based parsing, we introduce a topology-aware reward function based on graph edit distance. Unlike prior work that treats relational and graph formalisms in isolation, STRuCT-LLM leverages shared abstractions between SQL and Cypher to induce cross-formalism transfer, enabling SQL training to improve Cypher performance and vice versa - even without shared schemas. Our largest model (QwQ-32B) achieves substantial relative improvements across tasks: on semantic parsing, Spider improves by 13.5% and Text2Cypher by 73.1%. The model also demonstrates strong zero-shot generalization, improving performance on downstream tabular QA (TableBench: 8.5%) and knowledge graph QA (CR-LT-KGQA: 1.7%) without any QA-specific supervision. These results demonstrate both the effectiveness of executable queries as scaffolds for structured reasoning and the synergistic benefits of jointly training on SQL and Cypher (code available at https://github.com/bouv/STRuCT-LLM).",
    "summary": "arXiv:2506.21575v1 Announce Type: cross Abstract: We propose STRuCT-LLM, a unified framework for training large language models (LLMs) to perform structured reasoning over both relational and graph-structured data. Our approach jointly optimizes Text-to-SQL and Text-to-Cypher tasks using reinforcement learning (RL) combined with Chain-of-Thought (CoT) supervision. To support fine-grained optimization in graph-based parsing, we introduce a topology-aware reward function based on graph edit distance. Unlike prior work that treats relational and graph formalisms in isolation, STRuCT-LLM leverages shared abstractions between SQL and Cypher to induce cross-formalism transfer, enabling SQL training to improve Cypher performance and vice versa - even without shared schemas. Our largest model (QwQ-32B) achieves substantial relative improvements across tasks: on semantic parsing, Spider improves by 13.5% and Text2Cypher by 73.1%. The model also demonstrates strong zero-shot generalization, improving performance on downstream tabular QA (TableBench: 8.5%) and knowledge graph QA (CR-LT-KGQA: 1.7%) without any QA-specific supervision. These results demonstrate both the effectiveness of executable queries as scaffolds for structured reasoning and the synergistic benefits of jointly training on SQL and Cypher (code available at https://github.com/bouv/STRuCT-LLM).",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21575",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google releases Gemma 2 2B, ShieldGemma and Gemma Scope",
    "description": "",
    "summary": "Google releases Gemma 2 2B, ShieldGemma and Gemma Scope One month after the release of Gemma 2, Goog...",
    "pubDate": "Wed, 31 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma-july-update",
    "thumbnail": "https://huggingface.co/blog/assets/gemma-july-update/thumbnail.jpg"
  },
  {
    "title": "Comparing Learning Paradigms for Egocentric Video Summarization",
    "description": "arXiv:2506.21785v1 Announce Type: cross Abstract: In this study, we investigate various computer vision paradigms - supervised learning, unsupervised learning, and prompt fine-tuning - by assessing their ability to understand and interpret egocentric video data. Specifically, we examine Shotluck Holmes (state-of-the-art supervised learning), TAC-SUM (state-of-the-art unsupervised learning), and GPT-4o (a prompt fine-tuned pre-trained model), evaluating their effectiveness in video summarization. Our results demonstrate that current state-of-the-art models perform less effectively on first-person videos compared to third-person videos, highlighting the need for further advancements in the egocentric video domain. Notably, a prompt fine-tuned general-purpose GPT-4o model outperforms these specialized models, emphasizing the limitations of existing approaches in adapting to the unique challenges of first-person perspectives. Although our evaluation is conducted on a small subset of egocentric videos from the Ego-Exo4D dataset due to resource constraints, the primary objective of this research is to provide a comprehensive proof-of-concept analysis aimed at advancing the application of computer vision techniques to first-person videos. By exploring novel methodologies and evaluating their potential, we aim to contribute to the ongoing development of models capable of effectively processing and interpreting egocentric perspectives.",
    "summary": "arXiv:2506.21785v1 Announce Type: cross Abstract: In this study, we investigate various computer vision paradigms - supervised learning, unsupervised learning, and prompt fine-tuning - by assessing their ability to understand and interpret egocentric video data. Specifically, we examine Shotluck Holmes (state-of-the-art supervised learning), TAC-SUM (state-of-the-art unsupervised learning), and GPT-4o (a prompt fine-tuned pre-trained model), evaluating their effectiveness in video summarization. Our results demonstrate that current state-of-the-art models perform less effectively on first-person videos compared to third-person videos, highlighting the need for further advancements in the egocentric video domain. Notably, a prompt fine-tuned general-purpose GPT-4o model outperforms these specialized models, emphasizing the limitations of existing approaches in adapting to the unique challenges of first-person perspectives. Although our evaluation is conducted on a small subset of egocentric videos from the Ego-Exo4D dataset due to resource constraints, the primary objective of this research is to provide a comprehensive proof-of-concept analysis aimed at advancing the application of computer vision techniques to first-person videos. By exploring novel methodologies and evaluating their potential, we aim to contribute to the ongoing development of models capable of effectively processing and interpreting egocentric perspectives.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21785",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome PaddlePaddle to the Hugging Face Hub",
    "description": "",
    "summary": "Welcome PaddlePaddle to the Hugging Face Hub We are happy to share an open source collaboration betw...",
    "pubDate": "Tue, 17 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paddlepaddle",
    "thumbnail": "https://huggingface.co/blog/assets/126_paddlepaddle/thumbnail.jpg"
  },
  {
    "title": "Hierarchical Time Series Forecasting Via Latent Mean Encoding",
    "description": "arXiv:2506.19633v1 Announce Type: cross Abstract: Coherently forecasting the behaviour of a target variable across both coarse and fine temporal scales is crucial for profit-optimized decision-making in several business applications, and remains an open research problem in temporal hierarchical forecasting. Here, we propose a new hierarchical architecture that tackles this problem by leveraging modules that specialize in forecasting the different temporal aggregation levels of interest. The architecture, which learns to encode the average behaviour of the target variable within its hidden layers, makes accurate and coherent forecasts across the target temporal hierarchies. We validate our architecture on the challenging, real-world M5 dataset and show that it outperforms established methods, such as the TSMixer model.",
    "summary": "arXiv:2506.19633v1 Announce Type: cross Abstract: Coherently forecasting the behaviour of a target variable across both coarse and fine temporal scales is crucial for profit-optimized decision-making in several business applications, and remains an open research problem in temporal hierarchical forecasting. Here, we propose a new hierarchical architecture that tackles this problem by leveraging modules that specialize in forecasting the different temporal aggregation levels of interest. The architecture, which learns to encode the average behaviour of the target variable within its hidden layers, makes accurate and coherent forecasts across the target temporal hierarchies. We validate our architecture on the challenging, real-world M5 dataset and show that it outperforms established methods, such as the TSMixer model.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19633",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Frontier risk and preparedness",
    "description": "To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge.",
    "summary": "To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk preparedness, including building a Preparedness team and launching a challenge.",
    "pubDate": "Thu, 26 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-risk-and-preparedness",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Exploring the Daily Papers Page on Hugging Face",
    "description": "",
    "summary": "Exploring the Daily Papers Page on Hugging Face In the fast-paced world of research, staying up-to-d...",
    "pubDate": "Mon, 23 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/daily-papers",
    "thumbnail": "https://huggingface.co/blog/assets/daily-papers/thumbnail.png"
  },
  {
    "title": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "description": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "summary": "Collaborating with Carlyle to Chart the Future of Private Equity",
    "pubDate": "Tue, 14 May 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/collaborating-with-carlyle-to-chart-the-future-of-private-equity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Experimental investigation of pose informed reinforcement learning for skid-steered visual navigation",
    "description": "arXiv:2506.21732v1 Announce Type: cross Abstract: Vision-based lane keeping is a topic of significant interest in the robotics and autonomous ground vehicles communities in various on-road and off-road applications. The skid-steered vehicle architecture has served as a useful vehicle platform for human controlled operations. However, systematic modeling, especially of the skid-slip wheel terrain interactions (primarily in off-road settings) has created bottlenecks for automation deployment. End-to-end learning based methods such as imitation learning and deep reinforcement learning, have gained prominence as a viable deployment option to counter the lack of accurate analytical models. However, the systematic formulation and subsequent verification/validation in dynamic operation regimes (particularly for skid-steered vehicles) remains a work in progress. To this end, a novel approach for structured formulation for learning visual navigation is proposed and investigated in this work. Extensive software simulations, hardware evaluations and ablation studies now highlight the significantly improved performance of the proposed approach against contemporary literature.",
    "summary": "arXiv:2506.21732v1 Announce Type: cross Abstract: Vision-based lane keeping is a topic of significant interest in the robotics and autonomous ground vehicles communities in various on-road and off-road applications. The skid-steered vehicle architecture has served as a useful vehicle platform for human controlled operations. However, systematic modeling, especially of the skid-slip wheel terrain interactions (primarily in off-road settings) has created bottlenecks for automation deployment. End-to-end learning based methods such as imitation learning and deep reinforcement learning, have gained prominence as a viable deployment option to counter the lack of accurate analytical models. However, the systematic formulation and subsequent verification/validation in dynamic operation regimes (particularly for skid-steered vehicles) remains a work in progress. To this end, a novel approach for structured formulation for learning visual navigation is proposed and investigated in this work. Extensive software simulations, hardware evaluations and ablation studies now highlight the significantly improved performance of the proposed approach against contemporary literature.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21732",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenRAIL: Towards open and responsible AI licensing frameworks",
    "description": "",
    "summary": "OpenRAIL: Towards open and responsible AI licensing frameworks Open & Responsible AI licenses ('Open...",
    "pubDate": "Wed, 31 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open_rail",
    "thumbnail": "https://huggingface.co/blog/assets/100_open_rail/100_open-rail.png"
  },
  {
    "title": "Moving from intent-based bots to proactive AI agents",
    "description": "Moving from intent-based bots to proactive AI agents.",
    "summary": "Moving from intent-based bots to proactive AI agents.",
    "pubDate": "Thu, 27 Mar 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/zendesk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Faster fine-tuning using TRL & Unsloth",
    "description": "",
    "summary": "Make LLM Fine-tuning 2x faster with Unsloth and ü§ó TRL Pulling your hair out because LLM fine-tuning ...",
    "pubDate": "Wed, 10 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unsloth-trl",
    "thumbnail": "https://huggingface.co/blog/assets/hf_unsloth/thumbnail.png"
  },
  {
    "title": "AI Policy @ü§ó: Response to the U.S. NTIA's Request for Comment on AI Accountability",
    "description": "",
    "summary": "AI Policy @ü§ó: Response to the U.S. National Telecommunications and Information Administration‚Äôs (NTI...",
    "pubDate": "Tue, 20 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/policy-ntia-rfc",
    "thumbnail": "https://huggingface.co/blog/assets/151_policy_ntia_rfc/us_policy_thumbnail.png"
  },
  {
    "title": "DiffRIS: Enhancing Referring Remote Sensing Image Segmentation with Pre-trained Text-to-Image Diffusion Models",
    "description": "arXiv:2506.18946v1 Announce Type: cross Abstract: Referring remote sensing image segmentation (RRSIS) enables the precise delineation of regions within remote sensing imagery through natural language descriptions, serving critical applications in disaster response, urban development, and environmental monitoring. Despite recent advances, current approaches face significant challenges in processing aerial imagery due to complex object characteristics including scale variations, diverse orientations, and semantic ambiguities inherent to the overhead perspective. To address these limitations, we propose DiffRIS, a novel framework that harnesses the semantic understanding capabilities of pre-trained text-to-image diffusion models for enhanced cross-modal alignment in RRSIS tasks. Our framework introduces two key innovations: a context perception adapter (CP-adapter) that dynamically refines linguistic features through global context modeling and object-aware reasoning, and a progressive cross-modal reasoning decoder (PCMRD) that iteratively aligns textual descriptions with visual regions for precise segmentation. The CP-adapter bridges the domain gap between general vision-language understanding and remote sensing applications, while PCMRD enables fine-grained semantic alignment through multi-scale feature interaction. Comprehensive experiments on three benchmark datasets-RRSIS-D, RefSegRS, and RISBench-demonstrate that DiffRIS consistently outperforms existing methods across all standard metrics, establishing a new state-of-the-art for RRSIS tasks. The significant performance improvements validate the effectiveness of leveraging pre-trained diffusion models for remote sensing applications through our proposed adaptive framework.",
    "summary": "arXiv:2506.18946v1 Announce Type: cross Abstract: Referring remote sensing image segmentation (RRSIS) enables the precise delineation of regions within remote sensing imagery through natural language descriptions, serving critical applications in disaster response, urban development, and environmental monitoring. Despite recent advances, current approaches face significant challenges in processing aerial imagery due to complex object characteristics including scale variations, diverse orientations, and semantic ambiguities inherent to the overhead perspective. To address these limitations, we propose DiffRIS, a novel framework that harnesses the semantic understanding capabilities of pre-trained text-to-image diffusion models for enhanced cross-modal alignment in RRSIS tasks. Our framework introduces two key innovations: a context perception adapter (CP-adapter) that dynamically refines linguistic features through global context modeling and object-aware reasoning, and a progressive cross-modal reasoning decoder (PCMRD) that iteratively aligns textual descriptions with visual regions for precise segmentation. The CP-adapter bridges the domain gap between general vision-language understanding and remote sensing applications, while PCMRD enables fine-grained semantic alignment through multi-scale feature interaction. Comprehensive experiments on three benchmark datasets-RRSIS-D, RefSegRS, and RISBench-demonstrate that DiffRIS consistently outperforms existing methods across all standard metrics, establishing a new state-of-the-art for RRSIS tasks. The significant performance improvements validate the effectiveness of leveraging pre-trained diffusion models for remote sensing applications through our proposed adaptive framework.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18946",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Language-Informed Synthesis of Rational Agent Models for Grounded Theory-of-Mind Reasoning On-The-Fly",
    "description": "arXiv:2506.16755v1 Announce Type: cross Abstract: Drawing real world social inferences usually requires taking into account information from multiple modalities. Language is a particularly powerful source of information in social settings, especially in novel situations where language can provide both abstract information about the environment dynamics and concrete specifics about an agent that cannot be easily visually observed. In this paper, we propose Language-Informed Rational Agent Synthesis (LIRAS), a framework for drawing context-specific social inferences that integrate linguistic and visual inputs. LIRAS frames multimodal social reasoning as a process of constructing structured but situation-specific agent and environment representations - leveraging multimodal language models to parse language and visual inputs into unified symbolic representations, over which a Bayesian inverse planning engine can be run to produce granular probabilistic judgments. On a range of existing and new social reasoning tasks derived from cognitive science experiments, we find that our model (instantiated with a comparatively lightweight VLM) outperforms ablations and state-of-the-art models in capturing human judgments across all domains.",
    "summary": "arXiv:2506.16755v1 Announce Type: cross Abstract: Drawing real world social inferences usually requires taking into account information from multiple modalities. Language is a particularly powerful source of information in social settings, especially in novel situations where language can provide both abstract information about the environment dynamics and concrete specifics about an agent that cannot be easily visually observed. In this paper, we propose Language-Informed Rational Agent Synthesis (LIRAS), a framework for drawing context-specific social inferences that integrate linguistic and visual inputs. LIRAS frames multimodal social reasoning as a process of constructing structured but situation-specific agent and environment representations - leveraging multimodal language models to parse language and visual inputs into unified symbolic representations, over which a Bayesian inverse planning engine can be run to produce granular probabilistic judgments. On a range of existing and new social reasoning tasks derived from cognitive science experiments, we find that our model (instantiated with a comparatively lightweight VLM) outperforms ablations and state-of-the-art models in capturing human judgments across all domains.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16755",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation",
    "description": "",
    "summary": "StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation Instruction...",
    "pubDate": "Mon, 29 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sc2-instruct",
    "thumbnail": "https://huggingface.co/blog/assets/sc2-instruct/sc2-instruct-banner.png"
  },
  {
    "title": "How to Build an MCP Server with Gradio",
    "description": "",
    "summary": "How to Build an MCP Server in 5 Lines of Python Gradio is a Python library used by more than 1 milli...",
    "pubDate": "Wed, 30 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-mcp",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-mcp/thumbnail.png"
  },
  {
    "title": "Position: Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI",
    "description": "arXiv:2506.19613v1 Announce Type: new Abstract: Scientific discovery has long been constrained by human limitations in expertise, physical capability, and sleep cycles. The recent rise of AI scientists and automated laboratories has accelerated both the cognitive and operational aspects of research. However, key limitations persist: AI systems are often confined to virtual environments, while automated laboratories lack the flexibility and autonomy to adaptively test new hypotheses in the physical world. Recent advances in embodied AI, such as generalist robot foundation models, diffusion-based action policies, fine-grained manipulation learning, and sim-to-real transfer, highlight the promise of integrating cognitive and embodied intelligence. This convergence opens the door to closed-loop systems that support iterative, autonomous experimentation and the possibility of serendipitous discovery. In this position paper, we propose the paradigm of Intelligent Science Laboratories (ISLs): a multi-layered, closed-loop framework that deeply integrates cognitive and embodied intelligence. ISLs unify foundation models for scientific reasoning, agent-based workflow orchestration, and embodied agents for robust physical experimentation. We argue that such systems are essential for overcoming the current limitations of scientific discovery and for realizing the full transformative potential of AI-driven science.",
    "summary": "arXiv:2506.19613v1 Announce Type: new Abstract: Scientific discovery has long been constrained by human limitations in expertise, physical capability, and sleep cycles. The recent rise of AI scientists and automated laboratories has accelerated both the cognitive and operational aspects of research. However, key limitations persist: AI systems are often confined to virtual environments, while automated laboratories lack the flexibility and autonomy to adaptively test new hypotheses in the physical world. Recent advances in embodied AI, such as generalist robot foundation models, diffusion-based action policies, fine-grained manipulation learning, and sim-to-real transfer, highlight the promise of integrating cognitive and embodied intelligence. This convergence opens the door to closed-loop systems that support iterative, autonomous experimentation and the possibility of serendipitous discovery. In this position paper, we propose the paradigm of Intelligent Science Laboratories (ISLs): a multi-layered, closed-loop framework that deeply integrates cognitive and embodied intelligence. ISLs unify foundation models for scientific reasoning, agent-based workflow orchestration, and embodied agents for robust physical experimentation. We argue that such systems are essential for overcoming the current limitations of scientific discovery and for realizing the full transformative potential of AI-driven science.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19613",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Delivering nuanced insights from customer feedback",
    "description": "Using GPT-3 to deliver fast, nuanced insights from customer feedback.",
    "summary": "Using GPT-3 to deliver fast, nuanced insights from customer feedback.",
    "pubDate": "Wed, 04 Jan 2023 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/yabble",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Are We There Yet? A Brief Survey of Music Emotion Prediction Datasets, Models and Outstanding Challenges",
    "description": "arXiv:2406.08809v3 Announce Type: replace-cross Abstract: Deep learning models for music have advanced drastically in recent years, but how good are machine learning models at capturing emotion, and what challenges are researchers facing? In this paper, we provide a comprehensive overview of the available music-emotion datasets and discuss evaluation standards as well as competitions in the field. We also offer a brief overview of various types of music emotion prediction models that have been built over the years, providing insights into the diverse approaches within the field. Through this examination, we highlight the challenges that persist in accurately capturing emotion in music, including issues related to dataset quality, annotation consistency, and model generalization. Additionally, we explore the impact of different modalities, such as audio, MIDI, and physiological signals, on the effectiveness of emotion prediction models. Through this examination, we identify persistent challenges in music emotion recognition (MER), including issues related to dataset quality, the ambiguity in emotion labels, and the difficulties of cross-dataset generalization. We argue that future advancements in MER require standardized benchmarks, larger and more diverse datasets, and improved model interpretability. Recognizing the dynamic nature of this field, we have complemented our findings with an accompanying GitHub repository. This repository contains a comprehensive list of music emotion datasets and recent predictive models.",
    "summary": "arXiv:2406.08809v3 Announce Type: replace-cross Abstract: Deep learning models for music have advanced drastically in recent years, but how good are machine learning models at capturing emotion, and what challenges are researchers facing? In this paper, we provide a comprehensive overview of the available music-emotion datasets and discuss evaluation standards as well as competitions in the field. We also offer a brief overview of various types of music emotion prediction models that have been built over the years, providing insights into the diverse approaches within the field. Through this examination, we highlight the challenges that persist in accurately capturing emotion in music, including issues related to dataset quality, annotation consistency, and model generalization. Additionally, we explore the impact of different modalities, such as audio, MIDI, and physiological signals, on the effectiveness of emotion prediction models. Through this examination, we identify persistent challenges in music emotion recognition (MER), including issues related to dataset quality, the ambiguity in emotion labels, and the difficulties of cross-dataset generalization. We argue that future advancements in MER require standardized benchmarks, larger and more diverse datasets, and improved model interpretability. Recognizing the dynamic nature of this field, we have complemented our findings with an accompanying GitHub repository. This repository contains a comprehensive list of music emotion datasets and recent predictive models.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.08809",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TARDIS STRIDE: A Spatio-Temporal Road Image Dataset and World Model for Autonomy",
    "description": "arXiv:2506.11302v3 Announce Type: replace-cross Abstract: World models aim to simulate environments and enable effective agent behavior. However, modeling real-world environments presents unique challenges as they dynamically change across both space and, crucially, time. To capture these composed dynamics, we introduce a Spatio-Temporal Road Image Dataset for Exploration (STRIDE) permuting 360-degree panoramic imagery into rich interconnected observation, state and action nodes. Leveraging this structure, we can simultaneously model the relationship between egocentric views, positional coordinates, and movement commands across both space and time. We benchmark this dataset via TARDIS, a transformer-based generative world model that integrates spatial and temporal dynamics through a unified autoregressive framework trained on STRIDE. We demonstrate robust performance across a range of agentic tasks such as controllable photorealistic image synthesis, instruction following, autonomous self-control, and state-of-the-art georeferencing. These results suggest a promising direction towards sophisticated generalist agents--capable of understanding and manipulating the spatial and temporal aspects of their material environments--with enhanced embodied reasoning capabilities. Training code, datasets, and model checkpoints are made available at https://huggingface.co/datasets/Tera-AI/STRIDE.",
    "summary": "arXiv:2506.11302v3 Announce Type: replace-cross Abstract: World models aim to simulate environments and enable effective agent behavior. However, modeling real-world environments presents unique challenges as they dynamically change across both space and, crucially, time. To capture these composed dynamics, we introduce a Spatio-Temporal Road Image Dataset for Exploration (STRIDE) permuting 360-degree panoramic imagery into rich interconnected observation, state and action nodes. Leveraging this structure, we can simultaneously model the relationship between egocentric views, positional coordinates, and movement commands across both space and time. We benchmark this dataset via TARDIS, a transformer-based generative world model that integrates spatial and temporal dynamics through a unified autoregressive framework trained on STRIDE. We demonstrate robust performance across a range of agentic tasks such as controllable photorealistic image synthesis, instruction following, autonomous self-control, and state-of-the-art georeferencing. These results suggest a promising direction towards sophisticated generalist agents--capable of understanding and manipulating the spatial and temporal aspects of their material environments--with enhanced embodied reasoning capabilities. Training code, datasets, and model checkpoints are made available at https://huggingface.co/datasets/Tera-AI/STRIDE.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11302",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Visualize and understand GPU memory in PyTorch",
    "description": "",
    "summary": "Visualize and understand GPU memory in PyTorch You must be familiar with this message ü§¨: RuntimeErro...",
    "pubDate": "Tue, 24 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train_memory",
    "thumbnail": "https://huggingface.co/blog/assets/train_memory/thumbnail.png"
  },
  {
    "title": "Watermarking AI-generated text and video with SynthID",
    "description": "Announcing our novel watermarking method for AI-generated text and video, and how we‚Äôre bringing SynthID to key Google products",
    "summary": "Announcing our novel watermarking method for AI-generated text and video, and how we‚Äôre bringing SynthID to key Google products",
    "pubDate": "Tue, 14 May 2024 17:56:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/watermarking-ai-generated-text-and-video-with-synthid/",
    "thumbnail": "https://lh3.googleusercontent.com/I6bH75hNf57977cub27rFEsgxhcmkLrcINfCmGUaBCr7Q1bFTIl552R_6kuqlSkUjRtsTh929u6NoQmtHcwIG-GnjvPqMeynVLY0Rc9RRvezPQS0=w1200-h630-n-nu"
  },
  {
    "title": "Introducing the Data Measurements Tool: an Interactive Tool for Looking at Datasets",
    "description": "",
    "summary": "Introducing the ü§ó Data Measurements Tool: an Interactive Tool for Looking at Datasets tl;dr: We made...",
    "pubDate": "Mon, 29 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/data-measurements-tool",
    "thumbnail": "https://huggingface.co/blog/assets/37_data-measurements-tool/datametrics.png"
  },
  {
    "title": "Creating next-gen characters",
    "description": "Using GPT-3 to create the next generation of AI-powered characters.",
    "summary": "Using GPT-3 to create the next generation of AI-powered characters.",
    "pubDate": "Sun, 01 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/inworld-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ü§ó PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware",
    "description": "",
    "summary": "ü§ó PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware Motivation ...",
    "pubDate": "Fri, 10 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/peft",
    "thumbnail": "https://huggingface.co/blog/assets/130_peft/thumbnail.png"
  },
  {
    "title": "DALL¬∑E now available in beta",
    "description": "We‚Äôll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL¬∑E using free credits that refill every month, and buy additional credits in 115-generation increments for¬†$15.",
    "summary": "We‚Äôll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL¬∑E using free credits that refill every month, and buy additional credits in 115-generation increments for¬†$15.",
    "pubDate": "Wed, 20 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-now-available-in-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Trace & Evaluate your Agent with Arize Phoenix",
    "description": "",
    "summary": "Trace & Evaluate your Agent with Arize Phoenix So, you‚Äôve built your agent. It takes in inputs and t...",
    "pubDate": "Fri, 28 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolagents-phoenix",
    "thumbnail": "https://huggingface.co/blog/assets/smolagents-phoenix/thumbnail.jpg"
  },
  {
    "title": "RoboCat: A self-improving robotic agent",
    "description": "Robots are quickly becoming part of our everyday lives, but they‚Äôre often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data.¬†Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.",
    "summary": "Robots are quickly becoming part of our everyday lives, but they‚Äôre often only programmed to perform specific tasks well. While harnessing recent advances in AI could lead to robots that could help in many more ways, progress in building general-purpose robots is slower in part because of the time needed to collect real-world training data.¬†Our latest paper introduces a self-improving AI agent for robotics, RoboCat, that learns to perform a variety of tasks across different arms, and then self-generates new training data to improve its technique.",
    "pubDate": "Tue, 20 Jun 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/robocat-a-self-improving-robotic-agent/",
    "thumbnail": "https://lh3.googleusercontent.com/Rz9Xv4TXuTe-eO2UDUD6kDElDB5wDE2b2hEU1liUAi0AyiTwQ81mLMigXg3kueWrHoqeNctRO5-EMprZDRnXcaL8snfqHwDqgQpw_qB3VEvoO_jCCzI=w1200-h630-n-nu"
  },
  {
    "title": "XLSCOUT Unveils ParaEmbed 2.0: a Powerful Embedding Model Tailored for Patents and IP with Expert Support from Hugging Face",
    "description": "",
    "summary": "XLSCOUT Unveils ParaEmbed 2.0: a Powerful Embedding Model Tailored for Patents and IP with Expert Su...",
    "pubDate": "Tue, 25 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xlscout-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/xlscout-case-study/thumbnail.png"
  },
  {
    "title": "GPT-4o System Card",
    "description": "This report outlines the safety work carried out prior to releasing GPT-4o including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "summary": "This report outlines the safety work carried out prior to releasing GPT-4o including external red teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built in to address key risk areas.",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Age of Machine Learning As Code Has Arrived",
    "description": "",
    "summary": "The Age of Machine Learning As Code Has Arrived The 2021 edition of the State of AI Report came out ...",
    "pubDate": "Wed, 20 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the-age-of-ml-as-code",
    "thumbnail": "https://huggingface.co/blog/assets/31_age_of_ml_as_code/05_vision_transformer.png"
  },
  {
    "title": "An Introduction to Q-Learning Part 1",
    "description": "",
    "summary": "An Introduction to Q-Learning Part 1 Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 2, p...",
    "pubDate": "Wed, 18 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-q-part1",
    "thumbnail": "https://huggingface.co/blog/assets/70_deep_rl_q_part1/thumbnail.gif"
  },
  {
    "title": "Sharing the latest Model Spec",
    "description": "We‚Äôve made updates to the Model Spec based on external feedback and our continued research in shaping desired model behavior.",
    "summary": "We‚Äôve made updates to the Model Spec based on external feedback and our continued research in shaping desired model behavior.",
    "pubDate": "Wed, 12 Feb 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sharing-the-latest-model-spec",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "EasyDistill: A Comprehensive Toolkit for Effective Knowledge Distillation of Large Language Models",
    "description": "arXiv:2505.20888v2 Announce Type: replace-cross Abstract: In this paper, we present EasyDistill, a comprehensive toolkit designed for effective black-box and white-box knowledge distillation (KD) of large language models (LLMs). Our framework offers versatile functionalities, including data synthesis, supervised fine-tuning, ranking optimization, and reinforcement learning techniques specifically tailored for KD scenarios. The toolkit accommodates KD functionalities for both System 1 (fast, intuitive) and System 2 (slow, analytical) models. With its modular design and user-friendly interface, EasyDistill empowers researchers and industry practitioners to seamlessly experiment with and implement state-of-the-art KD strategies for LLMs. In addition, EasyDistill provides a series of robust distilled models and KD-based industrial solutions developed by us, along with the corresponding open-sourced datasets, catering to a variety of use cases. Furthermore, we describe the seamless integration of EasyDistill into Alibaba Cloud's Platform for AI (PAI). Overall, the EasyDistill toolkit makes advanced KD techniques for LLMs more accessible and impactful within the NLP community.",
    "summary": "arXiv:2505.20888v2 Announce Type: replace-cross Abstract: In this paper, we present EasyDistill, a comprehensive toolkit designed for effective black-box and white-box knowledge distillation (KD) of large language models (LLMs). Our framework offers versatile functionalities, including data synthesis, supervised fine-tuning, ranking optimization, and reinforcement learning techniques specifically tailored for KD scenarios. The toolkit accommodates KD functionalities for both System 1 (fast, intuitive) and System 2 (slow, analytical) models. With its modular design and user-friendly interface, EasyDistill empowers researchers and industry practitioners to seamlessly experiment with and implement state-of-the-art KD strategies for LLMs. In addition, EasyDistill provides a series of robust distilled models and KD-based industrial solutions developed by us, along with the corresponding open-sourced datasets, catering to a variety of use cases. Furthermore, we describe the seamless integration of EasyDistill into Alibaba Cloud's Platform for AI (PAI). Overall, the EasyDistill toolkit makes advanced KD techniques for LLMs more accessible and impactful within the NLP community.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.20888",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TRAIL: Trace Reasoning and Agentic Issue Localization",
    "description": "arXiv:2505.08638v3 Announce Type: replace Abstract: The increasing adoption of agentic workflows across diverse domains brings a critical need to scalably and systematically evaluate the complex traces these systems generate. Current evaluation methods depend on manual, domain-specific human analysis of lengthy workflow traces - an approach that does not scale with the growing complexity and volume of agentic outputs. Error analysis in these settings is further complicated by the interplay of external tool outputs and language model reasoning, making it more challenging than traditional software debugging. In this work, we (1) articulate the need for robust and dynamic evaluation methods for agentic workflow traces, (2) introduce a formal taxonomy of error types encountered in agentic systems, and (3) present a set of 148 large human-annotated traces (TRAIL) constructed using this taxonomy and grounded in established agentic benchmarks. To ensure ecological validity, we curate traces from both single and multi-agent systems, focusing on real-world applications such as software engineering and open-world information retrieval. Our evaluations reveal that modern long context LLMs perform poorly at trace debugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our dataset and code are made publicly available to support and accelerate future research in scalable evaluation for agentic workflows.",
    "summary": "arXiv:2505.08638v3 Announce Type: replace Abstract: The increasing adoption of agentic workflows across diverse domains brings a critical need to scalably and systematically evaluate the complex traces these systems generate. Current evaluation methods depend on manual, domain-specific human analysis of lengthy workflow traces - an approach that does not scale with the growing complexity and volume of agentic outputs. Error analysis in these settings is further complicated by the interplay of external tool outputs and language model reasoning, making it more challenging than traditional software debugging. In this work, we (1) articulate the need for robust and dynamic evaluation methods for agentic workflow traces, (2) introduce a formal taxonomy of error types encountered in agentic systems, and (3) present a set of 148 large human-annotated traces (TRAIL) constructed using this taxonomy and grounded in established agentic benchmarks. To ensure ecological validity, we curate traces from both single and multi-agent systems, focusing on real-world applications such as software engineering and open-world information retrieval. Our evaluations reveal that modern long context LLMs perform poorly at trace debugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our dataset and code are made publicly available to support and accelerate future research in scalable evaluation for agentic workflows.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.08638",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Calibrating Pre-trained Language Classifiers on LLM-generated Noisy Labels via Iterative Refinement",
    "description": "arXiv:2505.19675v2 Announce Type: replace-cross Abstract: The traditional process of creating labeled datasets is labor-intensive and expensive. Recent breakthroughs in open-source large language models (LLMs) have opened up a new avenue in generating labeled datasets automatically for various natural language processing (NLP) tasks, providing an alternative to such an expensive annotation process. However, the reliability of such auto-generated labels remains a significant concern due to inherent inaccuracies. When learning from noisy labels, the model's generalization is likely to be harmed as it is prone to overfit to those label noises. While previous studies in learning from noisy labels mainly focus on synthetic noise and real-world noise, LLM-generated label noise receives less attention. In this paper, we propose SiDyP: Simplex Label Diffusion with Dynamic Prior to calibrate the classifier's prediction, thus enhancing its robustness towards LLM-generated noisy labels. SiDyP retrieves potential true label candidates by neighborhood label distribution in text embedding space and iteratively refines noisy candidates using a simplex diffusion model. Our framework can increase the performance of the BERT classifier fine-tuned on both zero-shot and few-shot LLM-generated noisy label datasets by an average of 7.21% and 7.30% respectively. We demonstrate the effectiveness of SiDyP by conducting extensive benchmarking for different LLMs over a variety of NLP tasks. Our code is available on Github.",
    "summary": "arXiv:2505.19675v2 Announce Type: replace-cross Abstract: The traditional process of creating labeled datasets is labor-intensive and expensive. Recent breakthroughs in open-source large language models (LLMs) have opened up a new avenue in generating labeled datasets automatically for various natural language processing (NLP) tasks, providing an alternative to such an expensive annotation process. However, the reliability of such auto-generated labels remains a significant concern due to inherent inaccuracies. When learning from noisy labels, the model's generalization is likely to be harmed as it is prone to overfit to those label noises. While previous studies in learning from noisy labels mainly focus on synthetic noise and real-world noise, LLM-generated label noise receives less attention. In this paper, we propose SiDyP: Simplex Label Diffusion with Dynamic Prior to calibrate the classifier's prediction, thus enhancing its robustness towards LLM-generated noisy labels. SiDyP retrieves potential true label candidates by neighborhood label distribution in text embedding space and iteratively refines noisy candidates using a simplex diffusion model. Our framework can increase the performance of the BERT classifier fine-tuned on both zero-shot and few-shot LLM-generated noisy label datasets by an average of 7.21% and 7.30% respectively. We demonstrate the effectiveness of SiDyP by conducting extensive benchmarking for different LLMs over a variety of NLP tasks. Our code is available on Github.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.19675",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Confidence-Building Measures for Artificial Intelligence: Workshop proceedings",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 01 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/confidence-building-measures-for-artificial-intelligence",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GaLore: Advancing Large Model Training on Consumer-grade Hardware",
    "description": "",
    "summary": "GaLore: Advancing Large Model Training on Consumer-grade Hardware The integration of GaLore into the...",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/galore",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "OpenAI o3 and o4-mini System Card",
    "description": "OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities‚Äîweb browsing, Python, image and file analysis, image generation, canvas, automations, file search, and memory.",
    "summary": "OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities‚Äîweb browsing, Python, image and file analysis, image generation, canvas, automations, file search, and memory.",
    "pubDate": "Wed, 16 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploying ü§ó ViT on Kubernetes with TF Serving",
    "description": "",
    "summary": "Deploying ü§ó ViT on Kubernetes with TF Serving In the previous post, we showed how to deploy a Vision...",
    "pubDate": "Thu, 11 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-tfserving-kubernetes",
    "thumbnail": "https://huggingface.co/blog/assets/94_tf_serving_kubernetes/thumb.png"
  },
  {
    "title": "SetFit: Efficient Few-Shot Learning Without Prompts",
    "description": "",
    "summary": "SetFit: Efficient Few-Shot Learning Without Prompts SetFit is significantly more sample efficient an...",
    "pubDate": "Mon, 26 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit",
    "thumbnail": "https://huggingface.co/blog/assets/103_setfit/intel_hf_logo.png"
  },
  {
    "title": "From General to Targeted Rewards: Surpassing GPT-4 in Open-Ended Long-Context Generation",
    "description": "arXiv:2506.16024v1 Announce Type: cross Abstract: Current research on long-form context in Large Language Models (LLMs) primarily focuses on the understanding of long-contexts, the Open-ended Long Text Generation (Open-LTG) remains insufficiently explored. Training a long-context generation model requires curation of gold standard reference data, which is typically nonexistent for informative Open-LTG tasks. However, previous methods only utilize general assessments as reward signals, which limits accuracy. To bridge this gap, we introduce ProxyReward, an innovative reinforcement learning (RL) based framework, which includes a dataset and a reward signal computation method. Firstly, ProxyReward Dataset generation is accomplished through simple prompts that enables the model to create automatically, obviating extensive labeled data or significant manual effort. Secondly, ProxyReward Signal offers a targeted evaluation of information comprehensiveness and accuracy for specific questions. The experimental results indicate that our method ProxyReward surpasses even GPT-4-Turbo. It can significantly enhance performance by 20% on the Open-LTG task when training widely used open-source models, while also surpassing the LLM-as-a-Judge approach. Our work presents effective methods to enhance the ability of LLMs to address complex open-ended questions posed by human.",
    "summary": "arXiv:2506.16024v1 Announce Type: cross Abstract: Current research on long-form context in Large Language Models (LLMs) primarily focuses on the understanding of long-contexts, the Open-ended Long Text Generation (Open-LTG) remains insufficiently explored. Training a long-context generation model requires curation of gold standard reference data, which is typically nonexistent for informative Open-LTG tasks. However, previous methods only utilize general assessments as reward signals, which limits accuracy. To bridge this gap, we introduce ProxyReward, an innovative reinforcement learning (RL) based framework, which includes a dataset and a reward signal computation method. Firstly, ProxyReward Dataset generation is accomplished through simple prompts that enables the model to create automatically, obviating extensive labeled data or significant manual effort. Secondly, ProxyReward Signal offers a targeted evaluation of information comprehensiveness and accuracy for specific questions. The experimental results indicate that our method ProxyReward surpasses even GPT-4-Turbo. It can significantly enhance performance by 20% on the Open-LTG task when training widely used open-source models, while also surpassing the LLM-as-a-Judge approach. Our work presents effective methods to enhance the ability of LLMs to address complex open-ended questions posed by human.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16024",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Showcase Your Projects in Spaces using Gradio",
    "description": "",
    "summary": "Showcase Your Projects in Spaces using Gradio It's so easy to demonstrate a Machine Learning project...",
    "pubDate": "Tue, 05 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/28_gradio-spaces/thumbnail.png"
  },
  {
    "title": "Text and code embeddings by contrastive pre-training",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 24 Jan 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/text-and-code-embeddings-by-contrastive-pre-training",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CPU Optimized Embeddings with ü§ó Optimum Intel and fastRAG",
    "description": "",
    "summary": "CPU Optimized Embeddings with ü§ó Optimum Intel and fastRAG Embedding models are useful for many appli...",
    "pubDate": "Fri, 15 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-fast-embedding",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Collaborators: Healthcare Innovation to Impact",
    "description": "<p>In this discussion, Matthew Lungren, Jonathan Carlson, Smitha Saligrama, Will Guyman, and Cameron Runde explore how teams across Microsoft are working together to generate advanced AI capabilities and solutions for developers and clinicians around the globe. </p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/collaborators-healthcare-innovation-to-impact/'>Collaborators: Healthcare Innovation to Impact</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>In this discussion, Matthew Lungren, Jonathan Carlson, Smitha Saligrama, Will Guyman, and Cameron Runde explore how teams across Microsoft are working together to generate advanced AI capabilities and solutions for developers and clinicians around the globe. </p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/collaborators-healthcare-innovation-to-impact/'>Collaborators: Healthcare Innovation to Impact</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Tue, 20 May 2025 20:39:01 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/collaborators-healthcare-innovation-to-impact/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "The Newsroom AI Catalyst: a global program with WAN-IFRA",
    "description": "We‚Äôre collaborating with WAN-IFRA, the World Association of News Publishers, to launch a global accelerator program that will assist over 100 news publishers to explore and integrate AI in their newsroom.",
    "summary": "We‚Äôre collaborating with WAN-IFRA, the World Association of News Publishers, to launch a global accelerator program that will assist over 100 news publishers to explore and integrate AI in their newsroom.",
    "pubDate": "Wed, 29 May 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/newsroom-ai-catalyst-global-program-with-wan-ifra",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Toward Decision-Oriented Prognostics: An Integrated Estimate-Optimize Framework for Predictive Maintenance",
    "description": "arXiv:2506.19698v1 Announce Type: new Abstract: Recent research increasingly integrates machine learning (ML) into predictive maintenance (PdM) to reduce operational and maintenance costs in data-rich operational settings. However, uncertainty due to model misspecification continues to limit widespread industrial adoption. This paper proposes a PdM framework in which sensor-driven prognostics inform decision-making under economic trade-offs within a finite decision space. We investigate two key questions: (1) Does higher predictive accuracy necessarily lead to better maintenance decisions? (2) If not, how can the impact of prediction errors on downstream maintenance decisions be mitigated? We first demonstrate that in the traditional estimate-then-optimize (ETO) framework, errors in probabilistic prediction can result in inconsistent and suboptimal maintenance decisions. To address this, we propose an integrated estimate-optimize (IEO) framework that jointly tunes predictive models while directly optimizing for maintenance outcomes. We establish theoretical finite-sample guarantees on decision consistency under standard assumptions. Specifically, we develop a stochastic perturbation gradient descent algorithm suitable for small run-to-failure datasets. Empirical evaluations on a turbofan maintenance case study show that the IEO framework reduces average maintenance regret up to 22% compared to ETO. This study provides a principled approach to managing prediction errors in data-driven PdM. By aligning prognostic model training with maintenance objectives, the IEO framework improves robustness under model misspecification and improves decision quality. The improvement is particularly pronounced when the decision-making policy is misaligned with the decision-maker's target. These findings support more reliable maintenance planning in uncertain operational environments.",
    "summary": "arXiv:2506.19698v1 Announce Type: new Abstract: Recent research increasingly integrates machine learning (ML) into predictive maintenance (PdM) to reduce operational and maintenance costs in data-rich operational settings. However, uncertainty due to model misspecification continues to limit widespread industrial adoption. This paper proposes a PdM framework in which sensor-driven prognostics inform decision-making under economic trade-offs within a finite decision space. We investigate two key questions: (1) Does higher predictive accuracy necessarily lead to better maintenance decisions? (2) If not, how can the impact of prediction errors on downstream maintenance decisions be mitigated? We first demonstrate that in the traditional estimate-then-optimize (ETO) framework, errors in probabilistic prediction can result in inconsistent and suboptimal maintenance decisions. To address this, we propose an integrated estimate-optimize (IEO) framework that jointly tunes predictive models while directly optimizing for maintenance outcomes. We establish theoretical finite-sample guarantees on decision consistency under standard assumptions. Specifically, we develop a stochastic perturbation gradient descent algorithm suitable for small run-to-failure datasets. Empirical evaluations on a turbofan maintenance case study show that the IEO framework reduces average maintenance regret up to 22% compared to ETO. This study provides a principled approach to managing prediction errors in data-driven PdM. By aligning prognostic model training with maintenance objectives, the IEO framework improves robustness under model misspecification and improves decision quality. The improvement is particularly pronounced when the decision-making policy is misaligned with the decision-maker's target. These findings support more reliable maintenance planning in uncertain operational environments.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19698",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Alternates, Assemble! Selecting Optimal Alternates for Citizens' Assemblies",
    "description": "arXiv:2506.15716v1 Announce Type: cross Abstract: An increasingly influential form of deliberative democracy centers on citizens' assemblies, where randomly selected people discuss policy questions. The legitimacy of these panels hinges on their representation of the broader population, but panelists often drop out, leading to an unbalanced composition. Although participant attrition is mitigated in practice by alternates, their selection is not taken into account by existing methods. To address this gap, we introduce an optimization framework for alternate selection. Our algorithmic approach, which leverages learning-theoretic machinery, estimates dropout probabilities using historical data and selects alternates to minimize expected misrepresentation. We establish theoretical guarantees for our approach, including worst-case bounds on sample complexity (with implications for computational efficiency) and on loss when panelists' probabilities of dropping out are mis-estimated. Empirical evaluation using real-world data demonstrates that, compared to the status quo, our method significantly improves representation while requiring fewer alternates.",
    "summary": "arXiv:2506.15716v1 Announce Type: cross Abstract: An increasingly influential form of deliberative democracy centers on citizens' assemblies, where randomly selected people discuss policy questions. The legitimacy of these panels hinges on their representation of the broader population, but panelists often drop out, leading to an unbalanced composition. Although participant attrition is mitigated in practice by alternates, their selection is not taken into account by existing methods. To address this gap, we introduce an optimization framework for alternate selection. Our algorithmic approach, which leverages learning-theoretic machinery, estimates dropout probabilities using historical data and selects alternates to minimize expected misrepresentation. We establish theoretical guarantees for our approach, including worst-case bounds on sample complexity (with implications for computational efficiency) and on loss when panelists' probabilities of dropping out are mis-estimated. Empirical evaluation using real-world data demonstrates that, compared to the status quo, our method significantly improves representation while requiring fewer alternates.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15716",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Latent Concept Disentanglement in Transformer-based Language Models",
    "description": "arXiv:2506.16975v1 Announce Type: cross Abstract: When large language models (LLMs) use in-context learning (ICL) to solve a new task, they seem to grasp not only the goal of the task but also core, latent concepts in the demonstration examples. This begs the question of whether transformers represent latent structures as part of their computation or whether they take shortcuts to solve the problem. Prior mechanistic work on ICL does not address this question because it does not sufficiently examine the relationship between the learned representation and the latent concept, and the considered problem settings often involve only single-step reasoning. In this work, we examine how transformers disentangle and use latent concepts. We show that in 2-hop reasoning tasks with a latent, discrete concept, the model successfully identifies the latent concept and does step-by-step concept composition. In tasks parameterized by a continuous latent concept, we find low-dimensional subspaces in the representation space where the geometry mimics the underlying parameterization. Together, these results refine our understanding of ICL and the representation of transformers, and they provide evidence for highly localized structures in the model that disentangle latent concepts in ICL tasks.",
    "summary": "arXiv:2506.16975v1 Announce Type: cross Abstract: When large language models (LLMs) use in-context learning (ICL) to solve a new task, they seem to grasp not only the goal of the task but also core, latent concepts in the demonstration examples. This begs the question of whether transformers represent latent structures as part of their computation or whether they take shortcuts to solve the problem. Prior mechanistic work on ICL does not address this question because it does not sufficiently examine the relationship between the learned representation and the latent concept, and the considered problem settings often involve only single-step reasoning. In this work, we examine how transformers disentangle and use latent concepts. We show that in 2-hop reasoning tasks with a latent, discrete concept, the model successfully identifies the latent concept and does step-by-step concept composition. In tasks parameterized by a continuous latent concept, we find low-dimensional subspaces in the representation space where the geometry mimics the underlying parameterization. Together, these results refine our understanding of ICL and the representation of transformers, and they provide evidence for highly localized structures in the model that disentangle latent concepts in ICL tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16975",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SmolVLM - small yet mighty Vision Language Model",
    "description": "",
    "summary": "SmolVLM - small yet mighty Vision Language Model TLDR This blog post introduces SmolVLM, a 2B VLM, S...",
    "pubDate": "Tue, 26 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolvlm",
    "thumbnail": "https://huggingface.co/blog/assets/smolvlm/banner.png"
  },
  {
    "title": "Addendum to GPT-4o System Card: 4o image generation",
    "description": "4o image generation is a new, significantly more capable image generation approach than our earlier DALL¬∑E 3 series of models. It can create photorealistic output. It can take images as inputs and transform them.",
    "summary": "4o image generation is a new, significantly more capable image generation approach than our earlier DALL¬∑E 3 series of models. It can create photorealistic output. It can take images as inputs and transform them.",
    "pubDate": "Tue, 25 Mar 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4o-image-generation-system-card-addendum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MadaKV: Adaptive Modality-Perception KV Cache Eviction for Efficient Multimodal Long-Context Inference",
    "description": "arXiv:2506.15724v1 Announce Type: cross Abstract: This paper introduces MadaKV, a modality-adaptive key-value (KV) cache eviction strategy designed to enhance the efficiency of multimodal large language models (MLLMs) in long-context inference. In multimodal scenarios, attention heads exhibit varying preferences for different modalities, resulting in significant disparities in modality importance across attention heads. Traditional KV cache eviction methods, which are tailored for unimodal settings, fail to capture modality-specific information, thereby yielding suboptimal performance. MadaKV addresses these challenges through two key components: modality preference adaptation and hierarchical compression compensation. By dynamically sensing modality information within attention heads and adaptively retaining critical tokens, MadaKV achieves substantial reductions in KV cache memory footprint and model inference decoding latency (1.3 to 1.5 times improvement) while maintaining high accuracy across various multimodal long-context tasks. Extensive experiments on representative MLLMs and the MileBench benchmark demonstrate the effectiveness of MadaKV compared to existing KV cache eviction methods.",
    "summary": "arXiv:2506.15724v1 Announce Type: cross Abstract: This paper introduces MadaKV, a modality-adaptive key-value (KV) cache eviction strategy designed to enhance the efficiency of multimodal large language models (MLLMs) in long-context inference. In multimodal scenarios, attention heads exhibit varying preferences for different modalities, resulting in significant disparities in modality importance across attention heads. Traditional KV cache eviction methods, which are tailored for unimodal settings, fail to capture modality-specific information, thereby yielding suboptimal performance. MadaKV addresses these challenges through two key components: modality preference adaptation and hierarchical compression compensation. By dynamically sensing modality information within attention heads and adaptively retaining critical tokens, MadaKV achieves substantial reductions in KV cache memory footprint and model inference decoding latency (1.3 to 1.5 times improvement) while maintaining high accuracy across various multimodal long-context tasks. Extensive experiments on representative MLLMs and the MileBench benchmark demonstrate the effectiveness of MadaKV compared to existing KV cache eviction methods.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15724",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Delivering LLM-powered health solutions",
    "description": "WHOOP delivers personalized fitness and health coaching with GPT-4.",
    "summary": "WHOOP delivers personalized fitness and health coaching with GPT-4.",
    "pubDate": "Thu, 04 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/whoop",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving language understanding with unsupervised learning",
    "description": "We‚Äôve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we‚Äôre also releasing. Our approach is a combination of two existing ideas:¬†transformers¬†and¬†unsupervised pre-training. These results provide a convincing example that pairing supervised learning methods with unsupervised pre-training works very well; this is an idea that many have explored in the past, and we hope our result motivates further research into applying this idea on larger and more diverse¬†datasets.",
    "summary": "We‚Äôve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic system, which we‚Äôre also releasing. Our approach is a combination of two existing ideas:¬†transformers¬†and¬†unsupervised pre-training. These results provide a convincing example that pairing supervised learning methods with unsupervised pre-training works very well; this is an idea that many have explored in the past, and we hope our result motivates further research into applying this idea on larger and more diverse¬†datasets.",
    "pubDate": "Mon, 11 Jun 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/language-unsupervised",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building interactive agents in video game worlds",
    "description": "Most artificial intelligence (AI) researchers now believe that writing computer code which can capture the nuances of situated interactions is impossible. Alternatively, modern machine learning (ML) researchers have focused on learning about these types of interactions from data. To explore these learning-based approaches and quickly build agents that can make sense of human instructions and safely perform actions in open-ended conditions, we created a research framework within a video game environment.Today, we‚Äôre publishing a paper [INSERT LINK] and collection of videos, showing our early steps in building video game AIs that can understand fuzzy human concepts ‚Äì and therefore, can begin to interact with people on their own terms.",
    "summary": "Most artificial intelligence (AI) researchers now believe that writing computer code which can capture the nuances of situated interactions is impossible. Alternatively, modern machine learning (ML) researchers have focused on learning about these types of interactions from data. To explore these learning-based approaches and quickly build agents that can make sense of human instructions and safely perform actions in open-ended conditions, we created a research framework within a video game environment.Today, we‚Äôre publishing a paper [INSERT LINK] and collection of videos, showing our early steps in building video game AIs that can understand fuzzy human concepts ‚Äì and therefore, can begin to interact with people on their own terms.",
    "pubDate": "Wed, 23 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/building-interactive-agents-in-video-game-worlds/",
    "thumbnail": "https://lh3.googleusercontent.com/6DSrkFaInWqKD1eN4IJJN31ZRa3LW447A1ZYoK19FDzJGSLD5dlVw1rJRf52O_dmQUDq11XqYsiqMR8uFDnWLWGkl8xFY5KXYxD7LvQNPvTEuR_h=w1200-h630-n-nu"
  },
  {
    "title": "Robustness Evaluation of OCR-based Visual Document Understanding under Multi-Modal Adversarial Attacks",
    "description": "arXiv:2506.16407v1 Announce Type: cross Abstract: Visual Document Understanding (VDU) systems have achieved strong performance in information extraction by integrating textual, layout, and visual signals. However, their robustness under realistic adversarial perturbations remains insufficiently explored. We introduce the first unified framework for generating and evaluating multi-modal adversarial attacks on OCR-based VDU models. Our method covers six gradient-based layout attack scenarios, incorporating manipulations of OCR bounding boxes, pixels, and texts across both word and line granularities, with constraints on layout perturbation budget (e.g., IoU >= 0.6) to preserve plausibility. Experimental results across four datasets (FUNSD, CORD, SROIE, DocVQA) and six model families demonstrate that line-level attacks and compound perturbations (BBox + Pixel + Text) yield the most severe performance degradation. Projected Gradient Descent (PGD)-based BBox perturbations outperform random-shift baselines in all investigated models. Ablation studies further validate the impact of layout budget, text modification, and adversarial transferability.",
    "summary": "arXiv:2506.16407v1 Announce Type: cross Abstract: Visual Document Understanding (VDU) systems have achieved strong performance in information extraction by integrating textual, layout, and visual signals. However, their robustness under realistic adversarial perturbations remains insufficiently explored. We introduce the first unified framework for generating and evaluating multi-modal adversarial attacks on OCR-based VDU models. Our method covers six gradient-based layout attack scenarios, incorporating manipulations of OCR bounding boxes, pixels, and texts across both word and line granularities, with constraints on layout perturbation budget (e.g., IoU >= 0.6) to preserve plausibility. Experimental results across four datasets (FUNSD, CORD, SROIE, DocVQA) and six model families demonstrate that line-level attacks and compound perturbations (BBox + Pixel + Text) yield the most severe performance degradation. Projected Gradient Descent (PGD)-based BBox perturbations outperform random-shift baselines in all investigated models. Ablation studies further validate the impact of layout budget, text modification, and adversarial transferability.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16407",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evaluating Transparent Reasoning in Large Language Models for Accountable Critical Tasks",
    "description": "arXiv:2408.01933v5 Announce Type: replace-cross Abstract: This paper introduces REACT, a benchmark designed to rigorously evaluate the reasoning capabilities of large language models (LLMs) within accountable, high-stakes decision-making tasks in medical and legal domains. Unlike traditional benchmarks primarily focused on prediction accuracy, REACT emphasizes transparent and interpretable reasoning, requiring models to align their logic closely with expert-derived procedures. To assess whether LLM reasoning aligns closely with human experts, we annotated 511 clinical cases from the medical domain and 86 legal cases from the legal domain, each enriched with detailed expert-extracted rationales and evidence supporting each step of the reasoning process. These annotations were guided by carefully constructed reasoning graphs, which explicitly encode domain-specific inference structures and decision criteria derived by domain experts. These reasoning graphs serve not only as standards for expert annotation but also as structured guidelines enabling models to reason transparently and step-by-step. To address the scalability challenges of manual annotation, we further developed a semi-automatic annotation pipeline leveraging expert-defined reasoning graph templates to efficiently generate new graphs, exploring the potential to extend our approach into additional critical domains. Experimental results demonstrate that reasoning graphs substantially enhance the interpretability and accuracy of LLM reasoning compared to traditional baselines, although significant gaps remain relative to expert-level reasoning performance.",
    "summary": "arXiv:2408.01933v5 Announce Type: replace-cross Abstract: This paper introduces REACT, a benchmark designed to rigorously evaluate the reasoning capabilities of large language models (LLMs) within accountable, high-stakes decision-making tasks in medical and legal domains. Unlike traditional benchmarks primarily focused on prediction accuracy, REACT emphasizes transparent and interpretable reasoning, requiring models to align their logic closely with expert-derived procedures. To assess whether LLM reasoning aligns closely with human experts, we annotated 511 clinical cases from the medical domain and 86 legal cases from the legal domain, each enriched with detailed expert-extracted rationales and evidence supporting each step of the reasoning process. These annotations were guided by carefully constructed reasoning graphs, which explicitly encode domain-specific inference structures and decision criteria derived by domain experts. These reasoning graphs serve not only as standards for expert annotation but also as structured guidelines enabling models to reason transparently and step-by-step. To address the scalability challenges of manual annotation, we further developed a semi-automatic annotation pipeline leveraging expert-defined reasoning graph templates to efficiently generate new graphs, exploring the potential to extend our approach into additional critical domains. Experimental results demonstrate that reasoning graphs substantially enhance the interpretability and accuracy of LLM reasoning compared to traditional baselines, although significant gaps remain relative to expert-level reasoning performance.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.01933",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Contraction Actor-Critic: Contraction Metric-Guided Reinforcement Learning for Robust Path Tracking",
    "description": "arXiv:2506.15700v1 Announce Type: cross Abstract: Control contraction metrics (CCMs) provide a framework to co-synthesize a controller and a corresponding contraction metric -- a positive-definite Riemannian metric under which a closed-loop system is guaranteed to be incrementally exponentially stable. However, the synthesized controller only ensures that all the trajectories of the system converge to one single trajectory and, as such, does not impose any notion of optimality across an entire trajectory. Furthermore, constructing CCMs requires a known dynamics model and non-trivial effort in solving an infinite-dimensional convex feasibility problem, which limits its scalability to complex systems featuring high dimensionality with uncertainty. To address these issues, we propose to integrate CCMs into reinforcement learning (RL), where CCMs provide dynamics-informed feedback for learning control policies that minimize cumulative tracking error under unknown dynamics. We show that our algorithm, called contraction actor-critic (CAC), formally enhances the capability of CCMs to provide a set of contracting policies with the long-term optimality of RL in a fully automated setting. Given a pre-trained dynamics model, CAC simultaneously learns a contraction metric generator (CMG) -- which generates a contraction metric -- and uses an actor-critic algorithm to learn an optimal tracking policy guided by that metric. We demonstrate the effectiveness of our algorithm relative to established baselines through extensive empirical studies, including simulated and real-world robot experiments, and provide a theoretical rationale for incorporating contraction theory into RL.",
    "summary": "arXiv:2506.15700v1 Announce Type: cross Abstract: Control contraction metrics (CCMs) provide a framework to co-synthesize a controller and a corresponding contraction metric -- a positive-definite Riemannian metric under which a closed-loop system is guaranteed to be incrementally exponentially stable. However, the synthesized controller only ensures that all the trajectories of the system converge to one single trajectory and, as such, does not impose any notion of optimality across an entire trajectory. Furthermore, constructing CCMs requires a known dynamics model and non-trivial effort in solving an infinite-dimensional convex feasibility problem, which limits its scalability to complex systems featuring high dimensionality with uncertainty. To address these issues, we propose to integrate CCMs into reinforcement learning (RL), where CCMs provide dynamics-informed feedback for learning control policies that minimize cumulative tracking error under unknown dynamics. We show that our algorithm, called contraction actor-critic (CAC), formally enhances the capability of CCMs to provide a set of contracting policies with the long-term optimality of RL in a fully automated setting. Given a pre-trained dynamics model, CAC simultaneously learns a contraction metric generator (CMG) -- which generates a contraction metric -- and uses an actor-critic algorithm to learn an optimal tracking policy guided by that metric. We demonstrate the effectiveness of our algorithm relative to established baselines through extensive empirical studies, including simulated and real-world robot experiments, and provide a theoretical rationale for incorporating contraction theory into RL.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15700",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Exploring Image Generation via Mutually Exclusive Probability Spaces and Local Correlation Hypothesis",
    "description": "arXiv:2506.21731v1 Announce Type: cross Abstract: We propose two theoretical frameworks, the Mutually Exclusive Probability Space (MESP) and the Local Correlation Hypothesis (LCH), to explore a potential limitation in probabilistic generative models; namely that learning global distributions leads to memorization rather than generative behavior. MESP emerges from our rethinking of the Variational Autoencoder (VAE). We observe that latent variable distributions in VAE exhibit overlap, which leads to an optimization conflict between the reconstruction loss and KL-divergence loss. A lower bound based on the overlap coefficient is proposed. We refer to this phenomenon as Mutually Exclusive Probability Spaces. Based on MESP, a Binary Latent Autoencoder (BL-AE) is proposed to encode images into binary latent representations. These binary latents are used as the input to our Autoregressive Random Variable Model (ARVM), a modified autoregressive model outputting histograms. Our ARVM achieves competitive FID scores, outperforming state-of-the-art methods on standard datasets. However, such scores reflect memorization rather than generation. To address this issue, we propose the Local Correlation Hypothesis (LCH), which posits that generative capability arising from local correlations among latent variables. Comprehensive experiments and discussions are conducted to validate our frameworks.",
    "summary": "arXiv:2506.21731v1 Announce Type: cross Abstract: We propose two theoretical frameworks, the Mutually Exclusive Probability Space (MESP) and the Local Correlation Hypothesis (LCH), to explore a potential limitation in probabilistic generative models; namely that learning global distributions leads to memorization rather than generative behavior. MESP emerges from our rethinking of the Variational Autoencoder (VAE). We observe that latent variable distributions in VAE exhibit overlap, which leads to an optimization conflict between the reconstruction loss and KL-divergence loss. A lower bound based on the overlap coefficient is proposed. We refer to this phenomenon as Mutually Exclusive Probability Spaces. Based on MESP, a Binary Latent Autoencoder (BL-AE) is proposed to encode images into binary latent representations. These binary latents are used as the input to our Autoregressive Random Variable Model (ARVM), a modified autoregressive model outputting histograms. Our ARVM achieves competitive FID scores, outperforming state-of-the-art methods on standard datasets. However, such scores reflect memorization rather than generation. To address this issue, we propose the Local Correlation Hypothesis (LCH), which posits that generative capability arising from local correlations among latent variables. Comprehensive experiments and discussions are conducted to validate our frameworks.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21731",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Dr. Ronnie Chatterji named OpenAI‚Äôs first Chief Economist",
    "description": "Dr. Ronnie Chatterji named OpenAI‚Äôs first Chief Economist",
    "summary": "Dr. Ronnie Chatterji named OpenAI‚Äôs first Chief Economist",
    "pubDate": "Tue, 22 Oct 2024 10:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-chief-economist-announcement",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Spotting tell-tale visual artifacts in face swapping videos: strengths and pitfalls of CNN detectors",
    "description": "arXiv:2506.16497v1 Announce Type: cross Abstract: Face swapping manipulations in video streams represents an increasing threat in remote video communications, due to advances in automated and real-time tools. Recent literature proposes to characterize and exploit visual artifacts introduced in video frames by swapping algorithms when dealing with challenging physical scenes, such as face occlusions. This paper investigates the effectiveness of this approach by benchmarking CNN-based data-driven models on two data corpora (including a newly collected one) and analyzing generalization capabilities with respect to different acquisition sources and swapping algorithms. The results confirm excellent performance of general-purpose CNN architectures when operating within the same data source, but a significant difficulty in robustly characterizing occlusion-based visual cues across datasets. This highlights the need for specialized detection strategies to deal with such artifacts.",
    "summary": "arXiv:2506.16497v1 Announce Type: cross Abstract: Face swapping manipulations in video streams represents an increasing threat in remote video communications, due to advances in automated and real-time tools. Recent literature proposes to characterize and exploit visual artifacts introduced in video frames by swapping algorithms when dealing with challenging physical scenes, such as face occlusions. This paper investigates the effectiveness of this approach by benchmarking CNN-based data-driven models on two data corpora (including a newly collected one) and analyzing generalization capabilities with respect to different acquisition sources and swapping algorithms. The results confirm excellent performance of general-purpose CNN architectures when operating within the same data source, but a significant difficulty in robustly characterizing occlusion-based visual cues across datasets. This highlights the need for specialized detection strategies to deal with such artifacts.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16497",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CoATA: Effective Co-Augmentation of Topology and Attribute for Graph Neural Networks",
    "description": "arXiv:2506.22299v1 Announce Type: cross Abstract: Graph Neural Networks (GNNs) have garnered substantial attention due to their remarkable capability in learning graph representations. However, real-world graphs often exhibit substantial noise and incompleteness, which severely degrades the performance of GNNs. Existing methods typically address this issue through single-dimensional augmentation, focusing either on refining topology structures or perturbing node attributes, thereby overlooking the deeper interplays between the two. To bridge this gap, this paper presents CoATA, a dual-channel GNN framework specifically designed for the Co-Augmentation of Topology and Attribute. Specifically, CoATA first propagates structural signals to enrich and denoise node attributes. Then, it projects the enhanced attribute space into a node-attribute bipartite graph for further refinement or reconstruction of the underlying structure. Subsequently, CoATA introduces contrastive learning, leveraging prototype alignment and consistency constraints, to facilitate mutual corrections between the augmented and original graphs. Finally, extensive experiments on seven benchmark datasets demonstrate that the proposed CoATA outperforms eleven state-of-the-art baseline methods, showcasing its effectiveness in capturing the synergistic relationship between topology and attributes.",
    "summary": "arXiv:2506.22299v1 Announce Type: cross Abstract: Graph Neural Networks (GNNs) have garnered substantial attention due to their remarkable capability in learning graph representations. However, real-world graphs often exhibit substantial noise and incompleteness, which severely degrades the performance of GNNs. Existing methods typically address this issue through single-dimensional augmentation, focusing either on refining topology structures or perturbing node attributes, thereby overlooking the deeper interplays between the two. To bridge this gap, this paper presents CoATA, a dual-channel GNN framework specifically designed for the Co-Augmentation of Topology and Attribute. Specifically, CoATA first propagates structural signals to enrich and denoise node attributes. Then, it projects the enhanced attribute space into a node-attribute bipartite graph for further refinement or reconstruction of the underlying structure. Subsequently, CoATA introduces contrastive learning, leveraging prototype alignment and consistency constraints, to facilitate mutual corrections between the augmented and original graphs. Finally, extensive experiments on seven benchmark datasets demonstrate that the proposed CoATA outperforms eleven state-of-the-art baseline methods, showcasing its effectiveness in capturing the synergistic relationship between topology and attributes.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22299",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI Apps in a Flash with Gradio's Reload Mode",
    "description": "",
    "summary": "AI Apps in a Flash with Gradio's Reload Mode In this post, I will show you how you can build a funct...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-reload",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-reload/thumbnail_compressed.png"
  },
  {
    "title": "Literature-Grounded Novelty Assessment of Scientific Ideas",
    "description": "arXiv:2506.22026v1 Announce Type: cross Abstract: Automated scientific idea generation systems have made remarkable progress, yet the automatic evaluation of idea novelty remains a critical and underexplored challenge. Manual evaluation of novelty through literature review is labor-intensive, prone to error due to subjectivity, and impractical at scale. To address these issues, we propose the Idea Novelty Checker, an LLM-based retrieval-augmented generation (RAG) framework that leverages a two-stage retrieve-then-rerank approach. The Idea Novelty Checker first collects a broad set of relevant papers using keyword and snippet-based retrieval, then refines this collection through embedding-based filtering followed by facet-based LLM re-ranking. It incorporates expert-labeled examples to guide the system in comparing papers for novelty evaluation and in generating literature-grounded reasoning. Our extensive experiments demonstrate that our novelty checker achieves approximately 13% higher agreement than existing approaches. Ablation studies further showcases the importance of the facet-based re-ranker in identifying the most relevant literature for novelty evaluation.",
    "summary": "arXiv:2506.22026v1 Announce Type: cross Abstract: Automated scientific idea generation systems have made remarkable progress, yet the automatic evaluation of idea novelty remains a critical and underexplored challenge. Manual evaluation of novelty through literature review is labor-intensive, prone to error due to subjectivity, and impractical at scale. To address these issues, we propose the Idea Novelty Checker, an LLM-based retrieval-augmented generation (RAG) framework that leverages a two-stage retrieve-then-rerank approach. The Idea Novelty Checker first collects a broad set of relevant papers using keyword and snippet-based retrieval, then refines this collection through embedding-based filtering followed by facet-based LLM re-ranking. It incorporates expert-labeled examples to guide the system in comparing papers for novelty evaluation and in generating literature-grounded reasoning. Our extensive experiments demonstrate that our novelty checker achieves approximately 13% higher agreement than existing approaches. Ablation studies further showcases the importance of the facet-based re-ranker in identifying the most relevant literature for novelty evaluation.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22026",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Transformer-based Encoder-Decoder Models",
    "description": "",
    "summary": "Transformers-based Encoder-Decoder Models !pip install transformers==4.2.1 !pip install sentencepiec...",
    "pubDate": "Sat, 10 Oct 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/encoder-decoder",
    "thumbnail": "https://huggingface.co/blog/assets/05_encoder_decoder/thumbnail.png"
  },
  {
    "title": "Mitigating Metropolitan Carbon Emissions with Dynamic Eco-driving at Scale",
    "description": "arXiv:2408.05609v2 Announce Type: replace-cross Abstract: The sheer scale and diversity of transportation make it a formidable sector to decarbonize. Here, we consider an emerging opportunity to reduce carbon emissions: the growing adoption of semi-autonomous vehicles, which can be programmed to mitigate stop-and-go traffic through intelligent speed commands and, thus, reduce emissions. But would such dynamic eco-driving move the needle on climate change? A comprehensive impact analysis has been out of reach due to the vast array of traffic scenarios and the complexity of vehicle emissions. We address this challenge with large-scale scenario modeling efforts and by using multi-task deep reinforcement learning with a carefully designed network decomposition strategy. We perform an in-depth prospective impact assessment of dynamic eco-driving at 6,011 signalized intersections across three major US metropolitan cities, simulating a million traffic scenarios. Overall, we find that vehicle trajectories optimized for emissions can cut city-wide intersection carbon emissions by 11-22%, without harming throughput or safety, and with reasonable assumptions, equivalent to the national emissions of Israel and Nigeria, respectively. We find that 10% eco-driving adoption yields 25%-50% of the total reduction, and nearly 70% of the benefits come from 20% of intersections, suggesting near-term implementation pathways. However, the composition of this high-impact subset of intersections varies considerably across different adoption levels, with minimal overlap, calling for careful strategic planning for eco-driving deployments. Moreover, the impact of eco-driving, when considered jointly with projections of vehicle electrification and hybrid vehicle adoption remains significant. More broadly, this work paves the way for large-scale analysis of traffic externalities, such as time, safety, and air quality, and the potential impact of solution strategies.",
    "summary": "arXiv:2408.05609v2 Announce Type: replace-cross Abstract: The sheer scale and diversity of transportation make it a formidable sector to decarbonize. Here, we consider an emerging opportunity to reduce carbon emissions: the growing adoption of semi-autonomous vehicles, which can be programmed to mitigate stop-and-go traffic through intelligent speed commands and, thus, reduce emissions. But would such dynamic eco-driving move the needle on climate change? A comprehensive impact analysis has been out of reach due to the vast array of traffic scenarios and the complexity of vehicle emissions. We address this challenge with large-scale scenario modeling efforts and by using multi-task deep reinforcement learning with a carefully designed network decomposition strategy. We perform an in-depth prospective impact assessment of dynamic eco-driving at 6,011 signalized intersections across three major US metropolitan cities, simulating a million traffic scenarios. Overall, we find that vehicle trajectories optimized for emissions can cut city-wide intersection carbon emissions by 11-22%, without harming throughput or safety, and with reasonable assumptions, equivalent to the national emissions of Israel and Nigeria, respectively. We find that 10% eco-driving adoption yields 25%-50% of the total reduction, and nearly 70% of the benefits come from 20% of intersections, suggesting near-term implementation pathways. However, the composition of this high-impact subset of intersections varies considerably across different adoption levels, with minimal overlap, calling for careful strategic planning for eco-driving deployments. Moreover, the impact of eco-driving, when considered jointly with projections of vehicle electrification and hybrid vehicle adoption remains significant. More broadly, this work paves the way for large-scale analysis of traffic externalities, such as time, safety, and air quality, and the potential impact of solution strategies.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.05609",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Cohere on Hugging Face Inference Providers üî•",
    "description": "",
    "summary": "Cohere on Hugging Face Inference Providers üî• We're thrilled to share that Cohere is now a supported ...",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers-cohere",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers-cohere/thumbnail.png"
  },
  {
    "title": "Napkin AIÔºà„Éä„Éó„Ç≠„É≥AIÔºâ„Å®„ÅØÔºü‰Ωø„ÅÑÊñπ„Åã„Çâ„Åã„Åã„ÇãÊñôÈáë„Åæ„ÅßË©≥„Åó„ÅèËß£Ë™¨",
    "description": "<p>‰ªï‰∫ã„Åß‰Ωø„ÅÜÊñáÁ´†„ÇÑ„Ç¢„Ç§„Éá„Ç¢„Çí„Åæ„Å®„ÇÅ„Å¶„Çè„Åã„Çä„ÇÑ„Åô„ÅÑÂΩ¢„ÅßÊï¥ÁêÜ„Åó„Åü„ÅÑ„ÅÆ„Åß„ÄÅ‰Ωï„ÅãËâØ„ÅÑ„ÉÑ„Éº„É´„ÅØ„Å™„ÅÑ„ÅãÊé¢„Åó„Å¶„ÅÑ„Çã„Åë„Çå„Å©„ÄÅ„Å™„Åã„Å™„ÅãË¶ã„Å§„Åã„Çâ„ÅöÂõ∞„Å£„Å¶„ÅÑ„Çã‰∫∫„ÅØ„ÅÑ„Åæ„Åõ„Çì„ÅãÔºü ‰ªï‰∫ã„ÅßÂë®Âõ≤„ÅÆ‰∫∫„Å´Áâ©‰∫ã„Çí„Çè„Åã„Çä„ÇÑ„Åô„ÅèË™¨Êòé„Åô„Çã„Åü„ÇÅ„Å´„ÅØ„ÄÅÊñáÁ´†„Å†„Åë„Åß„ÅØ„Å™„Åè [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/what-is-napkinai/'>Napkin AIÔºà„Éä„Éó„Ç≠„É≥AIÔºâ„Å®„ÅØÔºü‰Ωø„ÅÑÊñπ„Åã„Çâ„Åã„Åã„ÇãÊñôÈáë„Åæ„ÅßË©≥„Åó„ÅèËß£Ë™¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>‰ªï‰∫ã„Åß‰Ωø„ÅÜÊñáÁ´†„ÇÑ„Ç¢„Ç§„Éá„Ç¢„Çí„Åæ„Å®„ÇÅ„Å¶„Çè„Åã„Çä„ÇÑ„Åô„ÅÑÂΩ¢„ÅßÊï¥ÁêÜ„Åó„Åü„ÅÑ„ÅÆ„Åß„ÄÅ‰Ωï„ÅãËâØ„ÅÑ„ÉÑ„Éº„É´„ÅØ„Å™„ÅÑ„ÅãÊé¢„Åó„Å¶„ÅÑ„Çã„Åë„Çå„Å©„ÄÅ„Å™„Åã„Å™„ÅãË¶ã„Å§„Åã„Çâ„ÅöÂõ∞„Å£„Å¶„ÅÑ„Çã‰∫∫„ÅØ„ÅÑ„Åæ„Åõ„Çì„ÅãÔºü ‰ªï‰∫ã„ÅßÂë®Âõ≤„ÅÆ‰∫∫„Å´Áâ©‰∫ã„Çí„Çè„Åã„Çä„ÇÑ„Åô„ÅèË™¨Êòé„Åô„Çã„Åü„ÇÅ„Å´„ÅØ„ÄÅÊñáÁ´†„Å†„Åë„Åß„ÅØ„Å™„Åè [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/what-is-napkinai/'>Napkin AIÔºà„Éä„Éó„Ç≠„É≥AIÔºâ„Å®„ÅØÔºü‰Ωø„ÅÑÊñπ„Åã„Çâ„Åã„Åã„ÇãÊñôÈáë„Åæ„ÅßË©≥„Åó„ÅèËß£Ë™¨</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Thu, 19 Jun 2025 05:40:52 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/what-is-napkinai/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/02/what-is-dify.jpg"
  },
  {
    "title": "Efficient Event-Based Object Detection: A Hybrid Neural Network with Spatial and Temporal Attention",
    "description": "arXiv:2403.10173v4 Announce Type: replace-cross Abstract: Event cameras offer high temporal resolution and dynamic range with minimal motion blur, making them promising for robust object detection. While Spiking Neural Networks (SNNs) on neuromorphic hardware are often considered for energy-efficient and low latency event-based data processing, they often fall short of Artificial Neural Networks (ANNs) in accuracy and flexibility. Here, we introduce Attention-based Hybrid SNN-ANN backbones for event-based object detection to leverage the strengths of both SNN and ANN architectures. A novel Attention-based SNN-ANN bridge module captures sparse spatial and temporal relations from the SNN layer and converts them into dense feature maps for the ANN part of the backbone. Additionally, we present a variant that integrates DWConvL-STMs to the ANN blocks to capture slower dynamics. This multi-timescale network combines fast SNN processing for short timesteps with long-term dense RNN processing, effectively capturing both fast and slow dynamics. Experimental results demonstrate that our proposed method surpasses SNN-based approaches by significant margins, with results comparable to existing ANN and RNN-based methods. Unlike ANN-only networks, the hybrid setup allows us to implement the SNN blocks on digital neuromorphic hardware to investigate the feasibility of our approach. Extensive ablation studies and implementation on neuromorphic hardware confirm the effectiveness of our proposed modules and architectural choices. Our hybrid SNN-ANN architectures pave the way for ANN-like performance at a drastically reduced parameter, latency, and power budget.",
    "summary": "arXiv:2403.10173v4 Announce Type: replace-cross Abstract: Event cameras offer high temporal resolution and dynamic range with minimal motion blur, making them promising for robust object detection. While Spiking Neural Networks (SNNs) on neuromorphic hardware are often considered for energy-efficient and low latency event-based data processing, they often fall short of Artificial Neural Networks (ANNs) in accuracy and flexibility. Here, we introduce Attention-based Hybrid SNN-ANN backbones for event-based object detection to leverage the strengths of both SNN and ANN architectures. A novel Attention-based SNN-ANN bridge module captures sparse spatial and temporal relations from the SNN layer and converts them into dense feature maps for the ANN part of the backbone. Additionally, we present a variant that integrates DWConvL-STMs to the ANN blocks to capture slower dynamics. This multi-timescale network combines fast SNN processing for short timesteps with long-term dense RNN processing, effectively capturing both fast and slow dynamics. Experimental results demonstrate that our proposed method surpasses SNN-based approaches by significant margins, with results comparable to existing ANN and RNN-based methods. Unlike ANN-only networks, the hybrid setup allows us to implement the SNN blocks on digital neuromorphic hardware to investigate the feasibility of our approach. Extensive ablation studies and implementation on neuromorphic hardware confirm the effectiveness of our proposed modules and architectural choices. Our hybrid SNN-ANN architectures pave the way for ANN-like performance at a drastically reduced parameter, latency, and power budget.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2403.10173",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improved Intelligibility of Dysarthric Speech using Conditional Flow Matching",
    "description": "arXiv:2506.16127v1 Announce Type: cross Abstract: Dysarthria is a neurological disorder that significantly impairs speech intelligibility, often rendering affected individuals unable to communicate effectively. This necessitates the development of robust dysarthric-to-regular speech conversion techniques. In this work, we investigate the utility and limitations of self-supervised learning (SSL) features and their quantized representations as an alternative to mel-spectrograms for speech generation. Additionally, we explore methods to mitigate speaker variability by generating clean speech in a single-speaker voice using features extracted from WavLM. To this end, we propose a fully non-autoregressive approach that leverages Conditional Flow Matching (CFM) with Diffusion Transformers to learn a direct mapping from dysarthric to clean speech. Our findings highlight the effectiveness of discrete acoustic units in improving intelligibility while achieving faster convergence compared to traditional mel-spectrogram-based approaches.",
    "summary": "arXiv:2506.16127v1 Announce Type: cross Abstract: Dysarthria is a neurological disorder that significantly impairs speech intelligibility, often rendering affected individuals unable to communicate effectively. This necessitates the development of robust dysarthric-to-regular speech conversion techniques. In this work, we investigate the utility and limitations of self-supervised learning (SSL) features and their quantized representations as an alternative to mel-spectrograms for speech generation. Additionally, we explore methods to mitigate speaker variability by generating clean speech in a single-speaker voice using features extracted from WavLM. To this end, we propose a fully non-autoregressive approach that leverages Conditional Flow Matching (CFM) with Diffusion Transformers to learn a direct mapping from dysarthric to clean speech. Our findings highlight the effectiveness of discrete acoustic units in improving intelligibility while achieving faster convergence compared to traditional mel-spectrogram-based approaches.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16127",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Multi-Goal Reinforcement Learning: Challenging robotics environments and request for research",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 26 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/multi-goal-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LaRS: Latent Reasoning Skills for Chain-of-Thought Reasoning",
    "description": "arXiv:2312.04684v4 Announce Type: replace-cross Abstract: Chain-of-thought (CoT) prompting is a popular in-context learning (ICL) approach for large language models (LLMs), especially when tackling complex reasoning tasks. Traditional ICL approaches construct prompts using examples that contain questions similar to the input question. However, CoT prompting, which includes crucial intermediate reasoning steps (rationales) within its examples, necessitates selecting examples based on these rationales rather than the questions themselves. Existing methods require human experts or pre-trained LLMs to describe the skill, a high-level abstraction of rationales, to guide the selection. These methods, however, are often costly and difficult to scale. Instead, this paper introduces a new approach named Latent Reasoning Skills (LaRS) that employs unsupervised learning to create a latent space representation of rationales, with a latent variable called a reasoning skill. Concurrently, LaRS learns a reasoning policy to determine the required reasoning skill for a given question. Then the ICL examples are selected by aligning the reasoning skills between past examples and the question. This approach is theoretically grounded and compute-efficient, eliminating the need for auxiliary LLM inference or manual prompt design. Empirical results demonstrate that LaRS consistently outperforms SOTA skill-based selection methods, processing example banks four times faster, reducing LLM inferences during the selection stage by half, and showing greater robustness to sub-optimal example banks.",
    "summary": "arXiv:2312.04684v4 Announce Type: replace-cross Abstract: Chain-of-thought (CoT) prompting is a popular in-context learning (ICL) approach for large language models (LLMs), especially when tackling complex reasoning tasks. Traditional ICL approaches construct prompts using examples that contain questions similar to the input question. However, CoT prompting, which includes crucial intermediate reasoning steps (rationales) within its examples, necessitates selecting examples based on these rationales rather than the questions themselves. Existing methods require human experts or pre-trained LLMs to describe the skill, a high-level abstraction of rationales, to guide the selection. These methods, however, are often costly and difficult to scale. Instead, this paper introduces a new approach named Latent Reasoning Skills (LaRS) that employs unsupervised learning to create a latent space representation of rationales, with a latent variable called a reasoning skill. Concurrently, LaRS learns a reasoning policy to determine the required reasoning skill for a given question. Then the ICL examples are selected by aligning the reasoning skills between past examples and the question. This approach is theoretically grounded and compute-efficient, eliminating the need for auxiliary LLM inference or manual prompt design. Empirical results demonstrate that LaRS consistently outperforms SOTA skill-based selection methods, processing example banks four times faster, reducing LLM inferences during the selection stage by half, and showing greater robustness to sub-optimal example banks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2312.04684",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI for Education",
    "description": "An affordable offering for universities to responsibly bring AI to campus.",
    "summary": "An affordable offering for universities to responsibly bring AI to campus.",
    "pubDate": "Thu, 30 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-edu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "State-of-the-art video and image generation with Veo 2 and Imagen 3",
    "description": "We‚Äôre rolling out a new, state-of-the-art video model, Veo 2, and updates to Imagen 3. Plus, check out our new experiment, Whisk.",
    "summary": "We‚Äôre rolling out a new, state-of-the-art video model, Veo 2, and updates to Imagen 3. Plus, check out our new experiment, Whisk.",
    "pubDate": "Mon, 16 Dec 2024 17:01:16 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/state-of-the-art-video-and-image-generation-with-veo-2-and-imagen-3/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/12-16-24_GenMedia_16x9.width-1300.png"
  },
  {
    "title": "LLaVA-Scissor: Token Compression with Semantic Connected Components for Video LLMs",
    "description": "arXiv:2506.21862v1 Announce Type: cross Abstract: In this paper, we present LLaVA-Scissor, a training-free token compression strategy designed for video multimodal large language models. Previous methods mostly attempt to compress tokens based on attention scores, but fail to effectively capture all semantic regions and often lead to token redundancy. Differently, we propose to leverage the Semantic Connected Components (SCC) approach that assigns tokens to distinct semantic regions within the token set, ensuring comprehensive semantic coverage. The outcome is a two-step spatio-temporal token compression strategy that utilizes SCC in both spatial and temporal domains. This strategy can effectively compress tokens by representing the entire video with a set of non-overlapping semantic tokens. We conduct extensive evaluations of the token compression capabilities of LLaVA-Scissor across diverse video understanding benchmarks, including video question answering, long video understanding, and comprehensive multi-choices benchmarks. Experimental results show that the proposed LLaVA-Scissor outperforms other token compression methods, achieving superior performance in various video understanding benchmarks, particularly at low token retention ratios. Project page: https://github.com/HumanMLLM/LLaVA-Scissor.",
    "summary": "arXiv:2506.21862v1 Announce Type: cross Abstract: In this paper, we present LLaVA-Scissor, a training-free token compression strategy designed for video multimodal large language models. Previous methods mostly attempt to compress tokens based on attention scores, but fail to effectively capture all semantic regions and often lead to token redundancy. Differently, we propose to leverage the Semantic Connected Components (SCC) approach that assigns tokens to distinct semantic regions within the token set, ensuring comprehensive semantic coverage. The outcome is a two-step spatio-temporal token compression strategy that utilizes SCC in both spatial and temporal domains. This strategy can effectively compress tokens by representing the entire video with a set of non-overlapping semantic tokens. We conduct extensive evaluations of the token compression capabilities of LLaVA-Scissor across diverse video understanding benchmarks, including video question answering, long video understanding, and comprehensive multi-choices benchmarks. Experimental results show that the proposed LLaVA-Scissor outperforms other token compression methods, achieving superior performance in various video understanding benchmarks, particularly at low token retention ratios. Project page: https://github.com/HumanMLLM/LLaVA-Scissor.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21862",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TrainVerify: Equivalence-Based Verification for Distributed LLM Training",
    "description": "arXiv:2506.15961v2 Announce Type: replace-cross Abstract: Training large language models (LLMs) at scale requires parallel execution across thousands of devices, incurring enormous computational costs. Yet, these costly distributed trainings are rarely verified, leaving them prone to silent errors and potentially wasting millions of GPU hours. We introduce TrainVerify, a system for verifiable distributed training of LLMs. Given a deep learning model's logical specification as the ground truth, TrainVerify formally verifies that a distributed parallel execution plan is mathematically equivalent to it. Direct verification is notoriously difficult due to the sheer scale of LLMs which often involves billions of variables and highly intricate computation graphs. Therefore, TrainVerify introduces shape-reduction techniques and a stage-wise parallel verification algorithm that significantly reduces complexity while preserving formal correctness. TrainVerify scales to frontier LLMs, including the successful verification of the Llama3 (405B) and DeepSeek-V3 (671B) training plans.",
    "summary": "arXiv:2506.15961v2 Announce Type: replace-cross Abstract: Training large language models (LLMs) at scale requires parallel execution across thousands of devices, incurring enormous computational costs. Yet, these costly distributed trainings are rarely verified, leaving them prone to silent errors and potentially wasting millions of GPU hours. We introduce TrainVerify, a system for verifiable distributed training of LLMs. Given a deep learning model's logical specification as the ground truth, TrainVerify formally verifies that a distributed parallel execution plan is mathematically equivalent to it. Direct verification is notoriously difficult due to the sheer scale of LLMs which often involves billions of variables and highly intricate computation graphs. Therefore, TrainVerify introduces shape-reduction techniques and a stage-wise parallel verification algorithm that significantly reduces complexity while preserving formal correctness. TrainVerify scales to frontier LLMs, including the successful verification of the Llama3 (405B) and DeepSeek-V3 (671B) training plans.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15961",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Automating 90% of finance and legal work with agents",
    "description": "Hebbia‚Äôs deep research automates 90% of finance and legal work, powered by OpenAI",
    "summary": "Hebbia‚Äôs deep research automates 90% of finance and legal work, powered by OpenAI",
    "pubDate": "Tue, 25 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hebbia",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MambaOutRS: A Hybrid CNN-Fourier Architecture for Remote Sensing Image Classification",
    "description": "arXiv:2506.19561v1 Announce Type: cross Abstract: Recent advances in deep learning for vision tasks have seen the rise of State Space Models (SSMs) like Mamba, celebrated for their linear scalability. However, their adaptation to 2D visual data often necessitates complex modifications that may diminish efficiency. In this paper, we introduce MambaOutRS, a novel hybrid convolutional architecture for remote sensing image classification that re-evaluates the necessity of recurrent SSMs. MambaOutRS builds upon stacked Gated CNN blocks for local feature extraction and introduces a novel Fourier Filter Gate (FFG) module that operates in the frequency domain to capture global contextual information efficiently. Our architecture employs a four-stage hierarchical design and was extensively evaluated on challenging remote sensing datasets: UC Merced, AID, NWPU-RESISC45, and EuroSAT. MambaOutRS consistently achieved state-of-the-art (SOTA) performance across these benchmarks. Notably, our MambaOutRS-t variant (24.0M parameters) attained the highest F1-scores of 98.41% on UC Merced and 95.99% on AID, significantly outperforming existing baselines, including larger transformer models and Mamba-based architectures, despite using considerably fewer parameters. An ablation study conclusively demonstrates the critical role of the Fourier Filter Gate in enhancing the model's ability to capture global spatial patterns, leading to robust and accurate classification. These results strongly suggest that the complexities of recurrent SSMs can be effectively superseded by a judicious combination of gated convolutions for spatial mixing and frequency-based gates for spectral global context. Thus, MambaOutRS provides a compelling and efficient paradigm for developing high-performance deep learning models in remote sensing and other vision domains, particularly where computational efficiency is paramount.",
    "summary": "arXiv:2506.19561v1 Announce Type: cross Abstract: Recent advances in deep learning for vision tasks have seen the rise of State Space Models (SSMs) like Mamba, celebrated for their linear scalability. However, their adaptation to 2D visual data often necessitates complex modifications that may diminish efficiency. In this paper, we introduce MambaOutRS, a novel hybrid convolutional architecture for remote sensing image classification that re-evaluates the necessity of recurrent SSMs. MambaOutRS builds upon stacked Gated CNN blocks for local feature extraction and introduces a novel Fourier Filter Gate (FFG) module that operates in the frequency domain to capture global contextual information efficiently. Our architecture employs a four-stage hierarchical design and was extensively evaluated on challenging remote sensing datasets: UC Merced, AID, NWPU-RESISC45, and EuroSAT. MambaOutRS consistently achieved state-of-the-art (SOTA) performance across these benchmarks. Notably, our MambaOutRS-t variant (24.0M parameters) attained the highest F1-scores of 98.41% on UC Merced and 95.99% on AID, significantly outperforming existing baselines, including larger transformer models and Mamba-based architectures, despite using considerably fewer parameters. An ablation study conclusively demonstrates the critical role of the Fourier Filter Gate in enhancing the model's ability to capture global spatial patterns, leading to robust and accurate classification. These results strongly suggest that the complexities of recurrent SSMs can be effectively superseded by a judicious combination of gated convolutions for spatial mixing and frequency-based gates for spectral global context. Thus, MambaOutRS provides a compelling and efficient paradigm for developing high-performance deep learning models in remote sensing and other vision domains, particularly where computational efficiency is paramount.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19561",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Adaptive Memory-Based Optimization for Enhanced Retrieval-Augmented Generation",
    "description": "arXiv:2504.05312v3 Announce Type: replace-cross Abstract: Retrieval-Augmented Generation (RAG), by integrating non-parametric knowledge from external knowledge bases into models, has emerged as a promising approach to enhancing response accuracy while mitigating factual errors and hallucinations. This method has been widely applied in tasks such as Question Answering (QA). However, existing RAG methods struggle with open-domain QA tasks because they perform independent retrieval operations and directly incorporate the retrieved information into generation without maintaining a summarizing memory or using adaptive retrieval strategies, leading to noise from redundant information and insufficient information integration. To address these challenges, we propose Adaptive memory-based optimization for enhanced RAG (Amber) for open-domain QA tasks, which comprises an Agent-based Memory Updater, an Adaptive Information Collector, and a Multi-granular Content Filter, working together within an iterative memory updating paradigm. Specifically, Amber integrates and optimizes the language model's memory through a multi-agent collaborative approach, ensuring comprehensive knowledge integration from previous retrieval steps. It dynamically adjusts retrieval queries and decides when to stop retrieval based on the accumulated knowledge, enhancing retrieval efficiency and effectiveness. Additionally, it reduces noise by filtering irrelevant content at multiple levels, retaining essential information to improve overall model performance. We conduct extensive experiments on several open-domain QA datasets, and the results demonstrate the superiority and effectiveness of our method and its components. The source code is available footnote{https://anonymous.4open.science/r/Amber-B203/}.",
    "summary": "arXiv:2504.05312v3 Announce Type: replace-cross Abstract: Retrieval-Augmented Generation (RAG), by integrating non-parametric knowledge from external knowledge bases into models, has emerged as a promising approach to enhancing response accuracy while mitigating factual errors and hallucinations. This method has been widely applied in tasks such as Question Answering (QA). However, existing RAG methods struggle with open-domain QA tasks because they perform independent retrieval operations and directly incorporate the retrieved information into generation without maintaining a summarizing memory or using adaptive retrieval strategies, leading to noise from redundant information and insufficient information integration. To address these challenges, we propose Adaptive memory-based optimization for enhanced RAG (Amber) for open-domain QA tasks, which comprises an Agent-based Memory Updater, an Adaptive Information Collector, and a Multi-granular Content Filter, working together within an iterative memory updating paradigm. Specifically, Amber integrates and optimizes the language model's memory through a multi-agent collaborative approach, ensuring comprehensive knowledge integration from previous retrieval steps. It dynamically adjusts retrieval queries and decides when to stop retrieval based on the accumulated knowledge, enhancing retrieval efficiency and effectiveness. Additionally, it reduces noise by filtering irrelevant content at multiple levels, retaining essential information to improve overall model performance. We conduct extensive experiments on several open-domain QA datasets, and the results demonstrate the superiority and effectiveness of our method and its components. The source code is available footnote{https://anonymous.4open.science/r/Amber-B203/}.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.05312",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Minnesota‚Äôs Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "description": "Minnesota‚Äôs Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "summary": "Minnesota‚Äôs Enterprise Translation Office uses ChatGPT to bridge language gaps",
    "pubDate": "Thu, 26 Sep 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/state-of-minnesota",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "‚ÄúÁ¥îÂõΩÁî£‰∫∫Âûã„É≠„Éú‚ÄùÈñãÁô∫„Å∏„ÄÄ‰∫¨ÈÉΩÁô∫„ÉªÊùëÁî∞Ë£Ω‰ΩúÊâÄ„Å™„Å©„ÅåÊñ∞Âõ£‰Ωì„ÄÄ26Âπ¥Â∫¶ÂÜÖ„Å´ÁÅΩÂÆ≥ÁèæÂ†¥„Å∏„ÅÆÂÆüË£ÖÁõÆÊåá„Åô",
    "description": "ÊùëÁî∞Ë£Ω‰ΩúÊâÄ„ÅØ„ÄÅÊó©Á®≤Áî∞Â§ßÂ≠¶„Å™„Å©„Å®„Å®„ÇÇ„Å´„ÄÅÂõΩÁî£„ÅÆ‰∫∫Âûã„É≠„Éú„ÉÉ„ÉàÈñãÁô∫„ÇíÊé®ÈÄ≤„Åô„ÇãÂõ£‰Ωì„ÄåKyoHA„ÄçÔºà‰∫¨ÈÉΩ„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Ç¢„ÇΩ„Ç∑„Ç®„Éº„Ç∑„Éß„É≥Ôºâ„Çí7Êúà„Å´Ë®≠Á´ã„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ„Åæ„Åö„ÅØ2026Âπ¥Â∫¶ÂÜÖ„Å´„ÄÅÁÅΩÂÆ≥ÁèæÂ†¥„ÅßÊ¥ªË∫ç„Åô„Çã‰∫∫Âûã„É≠„Éú„ÅÆÈñãÁô∫„ÇíÁõÆÊåá„Åô„ÄÇ",
    "summary": "ÊùëÁî∞Ë£Ω‰ΩúÊâÄ„ÅØ„ÄÅÊó©Á®≤Áî∞Â§ßÂ≠¶„Å™„Å©„Å®„Å®„ÇÇ„Å´„ÄÅÂõΩÁî£„ÅÆ‰∫∫Âûã„É≠„Éú„ÉÉ„ÉàÈñãÁô∫„ÇíÊé®ÈÄ≤„Åô„ÇãÂõ£‰Ωì„ÄåKyoHA„ÄçÔºà‰∫¨ÈÉΩ„Éí„É•„Éº„Éû„Éé„Ç§„Éâ„Ç¢„ÇΩ„Ç∑„Ç®„Éº„Ç∑„Éß„É≥Ôºâ„Çí7Êúà„Å´Ë®≠Á´ã„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ„Åæ„Åö„ÅØ2026Âπ¥Â∫¶ÂÜÖ„Å´„ÄÅÁÅΩÂÆ≥ÁèæÂ†¥„ÅßÊ¥ªË∫ç„Åô„Çã‰∫∫Âûã„É≠„Éú„ÅÆÈñãÁô∫„ÇíÁõÆÊåá„Åô„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 14:19:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/30/news097.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/30/cover_news097.jpg"
  },
  {
    "title": "OpenAI Microscope",
    "description": "We‚Äôre introducing¬†OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision ‚Äúmodel organisms‚Äù which are often studied in interpretability. Microscope makes it easier to analyze the features that form inside these neural networks, and we hope it will help the research community as we move towards understanding these complicated¬†systems.",
    "summary": "We‚Äôre introducing¬†OpenAI Microscope, a collection of visualizations of every significant layer and neuron of eight vision ‚Äúmodel organisms‚Äù which are often studied in interpretability. Microscope makes it easier to analyze the features that form inside these neural networks, and we hope it will help the research community as we move towards understanding these complicated¬†systems.",
    "pubDate": "Tue, 14 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/microscope",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning a hierarchy",
    "description": "We‚Äôve developed a hierarchical reinforcement learning algorithm that learns high-level actions useful for solving a range of tasks, allowing fast solving of tasks requiring thousands of timesteps. Our algorithm, when applied to a set of navigation problems, discovers a set of high-level actions for walking and crawling in different directions, which enables the agent to master new navigation tasks quickly.",
    "summary": "We‚Äôve developed a hierarchical reinforcement learning algorithm that learns high-level actions useful for solving a range of tasks, allowing fast solving of tasks requiring thousands of timesteps. Our algorithm, when applied to a set of navigation problems, discovers a set of high-level actions for walking and crawling in different directions, which enables the agent to master new navigation tasks quickly.",
    "pubDate": "Thu, 26 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-a-hierarchy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Why responsible AI development needs cooperation on safety",
    "description": "We‚Äôve written a policy research paper identifying four strategies that can be used today to improve the likelihood of long-term industry cooperation on safety norms in AI: communicating risks and benefits, technical collaboration, increased transparency, and incentivizing standards. Our analysis shows that industry cooperation on safety will be instrumental in ensuring that AI systems are safe and beneficial, but competitive pressures could lead to a collective action problem, potentially causing AI companies to under-invest in safety. We hope these strategies will encourage greater cooperation on the safe development of AI and lead to better global outcomes of¬†AI.",
    "summary": "We‚Äôve written a policy research paper identifying four strategies that can be used today to improve the likelihood of long-term industry cooperation on safety norms in AI: communicating risks and benefits, technical collaboration, increased transparency, and incentivizing standards. Our analysis shows that industry cooperation on safety will be instrumental in ensuring that AI systems are safe and beneficial, but competitive pressures could lead to a collective action problem, potentially causing AI companies to under-invest in safety. We hope these strategies will encourage greater cooperation on the safe development of AI and lead to better global outcomes of¬†AI.",
    "pubDate": "Wed, 10 Jul 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/cooperation-on-safety",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Capturing Fine-Grained Alignments Improves 3D Affordance Detection",
    "description": "arXiv:2506.19312v1 Announce Type: cross Abstract: In this work, we address the challenge of affordance detection in 3D point clouds, a task that requires effectively capturing fine-grained alignments between point clouds and text. Existing methods often struggle to model such alignments, resulting in limited performance on standard benchmarks. A key limitation of these approaches is their reliance on simple cosine similarity between point cloud and text embeddings, which lacks the expressiveness needed for fine-grained reasoning. To address this limitation, we propose LM-AD, a novel method for affordance detection in 3D point clouds. Moreover, we introduce the Affordance Query Module (AQM), which efficiently captures fine-grained alignment between point clouds and text by leveraging a pretrained language model. We demonstrated that our method outperformed existing approaches in terms of accuracy and mean Intersection over Union on the 3D AffordanceNet dataset.",
    "summary": "arXiv:2506.19312v1 Announce Type: cross Abstract: In this work, we address the challenge of affordance detection in 3D point clouds, a task that requires effectively capturing fine-grained alignments between point clouds and text. Existing methods often struggle to model such alignments, resulting in limited performance on standard benchmarks. A key limitation of these approaches is their reliance on simple cosine similarity between point cloud and text embeddings, which lacks the expressiveness needed for fine-grained reasoning. To address this limitation, we propose LM-AD, a novel method for affordance detection in 3D point clouds. Moreover, we introduce the Affordance Query Module (AQM), which efficiently captures fine-grained alignment between point clouds and text by leveraging a pretrained language model. We demonstrated that our method outperformed existing approaches in terms of accuracy and mean Intersection over Union on the 3D AffordanceNet dataset.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19312",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Model Cards: Introducing HF Model documentation tools",
    "description": "",
    "summary": "Model Cards Introduction Model cards are an important documentation framework for understanding, sha...",
    "pubDate": "Tue, 20 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/model-cards",
    "thumbnail": "https://huggingface.co/blog/assets/121_model-cards/thumbnail.png"
  },
  {
    "title": "Analyzing the Influence of Knowledge Graph Information on Relation Extraction",
    "description": "arXiv:2506.16343v1 Announce Type: cross Abstract: We examine the impact of incorporating knowledge graph information on the performance of relation extraction models across a range of datasets. Our hypothesis is that the positions of entities within a knowledge graph provide important insights for relation extraction tasks. We conduct experiments on multiple datasets, each varying in the number of relations, training examples, and underlying knowledge graphs. Our results demonstrate that integrating knowledge graph information significantly enhances performance, especially when dealing with an imbalance in the number of training examples for each relation. We evaluate the contribution of knowledge graph-based features by combining established relation extraction methods with graph-aware Neural Bellman-Ford networks. These features are tested in both supervised and zero-shot settings, demonstrating consistent performance improvements across various datasets.",
    "summary": "arXiv:2506.16343v1 Announce Type: cross Abstract: We examine the impact of incorporating knowledge graph information on the performance of relation extraction models across a range of datasets. Our hypothesis is that the positions of entities within a knowledge graph provide important insights for relation extraction tasks. We conduct experiments on multiple datasets, each varying in the number of relations, training examples, and underlying knowledge graphs. Our results demonstrate that integrating knowledge graph information significantly enhances performance, especially when dealing with an imbalance in the number of training examples for each relation. We evaluate the contribution of knowledge graph-based features by combining established relation extraction methods with graph-aware Neural Bellman-Ford networks. These features are tested in both supervised and zero-shot settings, demonstrating consistent performance improvements across various datasets.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16343",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RAST: Reasoning Activation in LLMs via Small-model Transfer",
    "description": "arXiv:2506.15710v1 Announce Type: cross Abstract: Reinforcement learning (RL) has become a powerful approach for improving the reasoning capabilities of large language models (LLMs), as evidenced by recent successes such as OpenAI's o1 and Deepseek-R1. However, applying RL at scale remains intimidatingly resource-intensive, requiring multiple model copies and extensive GPU workloads. On the other hand, while being powerful, recent studies suggest that RL does not fundamentally endow models with new knowledge; rather, it primarily reshapes the model's output distribution to activate reasoning capabilities latent in the base model. Building on this insight, we hypothesize that the changes in output probabilities induced by RL are largely model-size invariant, opening the door to a more efficient paradigm: training a small model with RL and transferring its induced probability shifts to larger base models. To verify our hypothesis, we conduct a token-level analysis of decoding trajectories and find high alignment in RL-induced output distributions across model scales, validating our hypothesis. Motivated by this, we propose RAST, a simple yet effective method that transfers reasoning behaviors by injecting RL-induced probability adjustments from a small RL-trained model into larger models. Experiments across multiple mathematical reasoning benchmarks show that RAST substantially and consistently enhances the reasoning capabilities of base models while requiring significantly lower GPU memory than direct RL training, sometimes even yielding better performance than the RL-trained counterparts. Our findings offer new insights into the nature of RL-driven reasoning and practical strategies for scaling its benefits without incurring its full computational cost. The project page of RAST is available at https://ozyyshr.github.io/RAST/.",
    "summary": "arXiv:2506.15710v1 Announce Type: cross Abstract: Reinforcement learning (RL) has become a powerful approach for improving the reasoning capabilities of large language models (LLMs), as evidenced by recent successes such as OpenAI's o1 and Deepseek-R1. However, applying RL at scale remains intimidatingly resource-intensive, requiring multiple model copies and extensive GPU workloads. On the other hand, while being powerful, recent studies suggest that RL does not fundamentally endow models with new knowledge; rather, it primarily reshapes the model's output distribution to activate reasoning capabilities latent in the base model. Building on this insight, we hypothesize that the changes in output probabilities induced by RL are largely model-size invariant, opening the door to a more efficient paradigm: training a small model with RL and transferring its induced probability shifts to larger base models. To verify our hypothesis, we conduct a token-level analysis of decoding trajectories and find high alignment in RL-induced output distributions across model scales, validating our hypothesis. Motivated by this, we propose RAST, a simple yet effective method that transfers reasoning behaviors by injecting RL-induced probability adjustments from a small RL-trained model into larger models. Experiments across multiple mathematical reasoning benchmarks show that RAST substantially and consistently enhances the reasoning capabilities of base models while requiring significantly lower GPU memory than direct RL training, sometimes even yielding better performance than the RL-trained counterparts. Our findings offer new insights into the nature of RL-driven reasoning and practical strategies for scaling its benefits without incurring its full computational cost. The project page of RAST is available at https://ozyyshr.github.io/RAST/.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15710",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From Superficial to Deep: Integrating External Knowledge for Follow-up Question Generation Using Knowledge Graph and LLM",
    "description": "arXiv:2504.05801v2 Announce Type: replace Abstract: In a conversational system, dynamically generating follow-up questions based on context can help users explore information and provide a better user experience. Humans are usually able to ask questions that involve some general life knowledge and demonstrate higher order cognitive skills. However, the questions generated by existing methods are often limited to shallow contextual questions that are uninspiring and have a large gap to the human level. In this paper, we propose a three-stage external knowledge-enhanced follow-up question generation method, which generates questions by identifying contextual topics, constructing a knowledge graph (KG) online, and finally combining these with a large language model to generate the final question. The model generates information-rich and exploratory follow-up questions by introducing external common sense knowledge and performing a knowledge fusion operation. Experiments show that compared to baseline models, our method generates questions that are more informative and closer to human questioning levels while maintaining contextual relevance.",
    "summary": "arXiv:2504.05801v2 Announce Type: replace Abstract: In a conversational system, dynamically generating follow-up questions based on context can help users explore information and provide a better user experience. Humans are usually able to ask questions that involve some general life knowledge and demonstrate higher order cognitive skills. However, the questions generated by existing methods are often limited to shallow contextual questions that are uninspiring and have a large gap to the human level. In this paper, we propose a three-stage external knowledge-enhanced follow-up question generation method, which generates questions by identifying contextual topics, constructing a knowledge graph (KG) online, and finally combining these with a large language model to generate the final question. The model generates information-rich and exploratory follow-up questions by introducing external common sense knowledge and performing a knowledge fusion operation. Experiments show that compared to baseline models, our method generates questions that are more informative and closer to human questioning levels while maintaining contextual relevance.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.05801",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Boost Wav2Vec2 with n-gram LM in ü§ó Transformers",
    "description": "",
    "summary": "Boosting Wav2Vec2 with n-grams in ü§ó Transformers Wav2Vec2 is a popular pre-trained model for speech ...",
    "pubDate": "Wed, 12 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/wav2vec2-with-ngram",
    "thumbnail": "https://huggingface.co/blog/assets/44_boost_wav2vec2_ngram/wav2vec2_ngram.png"
  },
  {
    "title": "IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in Daily Household Tasks",
    "description": "arXiv:2506.16402v1 Announce Type: new Abstract: Flawed planning from VLM-driven embodied agents poses significant safety hazards, hindering their deployment in real-world household tasks. However, existing static, non-interactive evaluation paradigms fail to adequately assess risks within these interactive environments, since they cannot simulate dynamic risks that emerge from an agent's actions and rely on unreliable post-hoc evaluations that ignore unsafe intermediate steps. To bridge this critical gap, we propose evaluating an agent's interactive safety: its ability to perceive emergent risks and execute mitigation steps in the correct procedural order. We thus present IS-Bench, the first multi-modal benchmark designed for interactive safety, featuring 161 challenging scenarios with 388 unique safety risks instantiated in a high-fidelity simulator. Crucially, it facilitates a novel process-oriented evaluation that verifies whether risk mitigation actions are performed before/after specific risk-prone steps. Extensive experiments on leading VLMs, including the GPT-4o and Gemini-2.5 series, reveal that current agents lack interactive safety awareness, and that while safety-aware Chain-of-Thought can improve performance, it often compromises task completion. By highlighting these critical limitations, IS-Bench provides a foundation for developing safer and more reliable embodied AI systems.",
    "summary": "arXiv:2506.16402v1 Announce Type: new Abstract: Flawed planning from VLM-driven embodied agents poses significant safety hazards, hindering their deployment in real-world household tasks. However, existing static, non-interactive evaluation paradigms fail to adequately assess risks within these interactive environments, since they cannot simulate dynamic risks that emerge from an agent's actions and rely on unreliable post-hoc evaluations that ignore unsafe intermediate steps. To bridge this critical gap, we propose evaluating an agent's interactive safety: its ability to perceive emergent risks and execute mitigation steps in the correct procedural order. We thus present IS-Bench, the first multi-modal benchmark designed for interactive safety, featuring 161 challenging scenarios with 388 unique safety risks instantiated in a high-fidelity simulator. Crucially, it facilitates a novel process-oriented evaluation that verifies whether risk mitigation actions are performed before/after specific risk-prone steps. Extensive experiments on leading VLMs, including the GPT-4o and Gemini-2.5 series, reveal that current agents lack interactive safety awareness, and that while safety-aware Chain-of-Thought can improve performance, it often compromises task completion. By highlighting these critical limitations, IS-Bench provides a foundation for developing safer and more reliable embodied AI systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16402",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Infomatica„ÅåAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„Å´Êú¨Ê∞ó„ÄÄÊó•Êú¨„Å´Âêë„Åë„ÄåÊåëÊà¶„ÅØ„É™„Çπ„ÇØ„ÄÅ„Å†„ÅåÂæÖ„Å£„Å¶„ÅÑ„Å¶„ÅØËøΩ„ÅÑ‰ªò„Åë„Å™„ÅÑ„Äç",
    "description": "Á±≥Informatica„ÅØÂπ¥Ê¨°„Ç§„Éô„É≥„Éà„ÄåInformatica World 2025„Äç„Åß„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„Å´Èñ¢ÈÄ£„Åô„ÇãÂèñ„ÇäÁµÑ„Åø„ÅÆÂ§ßÂπÖÂº∑Âåñ„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÊó•Êú¨„Å´Âêë„Åë„Å¶„ÅØ„ÄÅÂ§±Êïó„ÇíÊÅê„Çå„ÅöÊåëÊà¶„Åô„Çã„Çà„ÅÜË®¥„Åà„Åã„Åë„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "Á±≥Informatica„ÅØÂπ¥Ê¨°„Ç§„Éô„É≥„Éà„ÄåInformatica World 2025„Äç„Åß„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„Å´Èñ¢ÈÄ£„Åô„ÇãÂèñ„ÇäÁµÑ„Åø„ÅÆÂ§ßÂπÖÂº∑Âåñ„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÊó•Êú¨„Å´Âêë„Åë„Å¶„ÅØ„ÄÅÂ§±Êïó„ÇíÊÅê„Çå„ÅöÊåëÊà¶„Åô„Çã„Çà„ÅÜË®¥„Åà„Åã„Åë„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Mon, 23 Jun 2025 10:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/23/news033.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/23/cover_news033.jpg"
  },
  {
    "title": "Adapting University Policies for Generative AI: Opportunities, Challenges, and Policy Solutions in Higher Education",
    "description": "arXiv:2506.22231v1 Announce Type: cross Abstract: The rapid proliferation of generative artificial intelligence (AI) tools - especially large language models (LLMs) such as ChatGPT - has ushered in a transformative era in higher education. Universities in developed regions are increasingly integrating these technologies into research, teaching, and assessment. On one hand, LLMs can enhance productivity by streamlining literature reviews, facilitating idea generation, assisting with coding and data analysis, and even supporting grant proposal drafting. On the other hand, their use raises significant concerns regarding academic integrity, ethical boundaries, and equitable access. Recent empirical studies indicate that nearly 47% of students use LLMs in their coursework - with 39% using them for exam questions and 7% for entire assignments - while detection tools currently achieve around 88% accuracy, leaving a 12% error margin. This article critically examines the opportunities offered by generative AI, explores the multifaceted challenges it poses, and outlines robust policy solutions. Emphasis is placed on redesigning assessments to be AI-resilient, enhancing staff and student training, implementing multi-layered enforcement mechanisms, and defining acceptable use. By synthesizing data from recent research and case studies, the article argues that proactive policy adaptation is imperative to harness AI's potential while safeguarding the core values of academic integrity and equity.",
    "summary": "arXiv:2506.22231v1 Announce Type: cross Abstract: The rapid proliferation of generative artificial intelligence (AI) tools - especially large language models (LLMs) such as ChatGPT - has ushered in a transformative era in higher education. Universities in developed regions are increasingly integrating these technologies into research, teaching, and assessment. On one hand, LLMs can enhance productivity by streamlining literature reviews, facilitating idea generation, assisting with coding and data analysis, and even supporting grant proposal drafting. On the other hand, their use raises significant concerns regarding academic integrity, ethical boundaries, and equitable access. Recent empirical studies indicate that nearly 47% of students use LLMs in their coursework - with 39% using them for exam questions and 7% for entire assignments - while detection tools currently achieve around 88% accuracy, leaving a 12% error margin. This article critically examines the opportunities offered by generative AI, explores the multifaceted challenges it poses, and outlines robust policy solutions. Emphasis is placed on redesigning assessments to be AI-resilient, enhancing staff and student training, implementing multi-layered enforcement mechanisms, and defining acceptable use. By synthesizing data from recent research and case studies, the article argues that proactive policy adaptation is imperative to harness AI's potential while safeguarding the core values of academic integrity and equity.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22231",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Blazing Fast SetFit Inference with ü§ó Optimum Intel on Xeon",
    "description": "",
    "summary": "Blazing Fast SetFit Inference with ü§ó Optimum Intel on Xeon SetFit is a promising solution for a comm...",
    "pubDate": "Wed, 03 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/setfit-optimum-intel",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "LAVE: Zero-shot VQA Evaluation on Docmatix with LLMs - Do We Still Need Fine-Tuning?",
    "description": "",
    "summary": "LAVE: Zero-shot VQA Evaluation on Docmatix with LLMs - Do We Still Need Fine-Tuning? While developin...",
    "pubDate": "Thu, 25 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/zero-shot-vqa-docmatix",
    "thumbnail": "https://huggingface.co/blog/assets/184_zero_shot_docmatix/thumb.001.jpeg"
  },
  {
    "title": "Increasing accuracy of pediatric visit notes",
    "description": "Summer Health reimagines pediatric doctor‚Äôs visits with OpenAI.",
    "summary": "Summer Health reimagines pediatric doctor‚Äôs visits with OpenAI.",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/summer-health",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Do Vendi Scores Converge with Finite Samples? Truncated Vendi Score for Finite-Sample Convergence Guarantees",
    "description": "arXiv:2410.21719v3 Announce Type: replace-cross Abstract: Evaluating the diversity of generative models without reference data poses methodological challenges. The reference-free Vendi and RKE scores address this by quantifying the diversity of generated data using matrix-based entropy measures. Among these two, the Vendi score is typically computed via the eigendecomposition of an $n times n$ kernel matrix constructed from n generated samples. However, the prohibitive computational cost of eigendecomposition for large $n$ often limits the number of samples used to fewer than 20,000. In this paper, we investigate the statistical convergence of the Vendi and RKE scores under restricted sample sizes. We numerically demonstrate that, in general, the Vendi score computed with standard sample sizes below 20,000 may not converge to its asymptotic value under infinite sampling. To address this, we introduce the $t$-truncated Vendi score by truncating the eigenspectrum of the kernel matrix, which is provably guaranteed to converge to its population limit with $n=mathcal{O}(t)$ samples. We further show that existing Nystr'om and FKEA approximation methods converge to the asymptotic limit of the truncated Vendi score. In contrast to the Vendi score, we prove that the RKE score enjoys universal convergence guarantees across all kernel functions. We conduct several numerical experiments to illustrate the concentration of Nystr'om and FKEA computed Vendi scores around the truncated Vendi score, and we analyze how the truncated Vendi and RKE scores correlate with the diversity of image and text data. The code is available at https://github.com/aziksh-ospanov/truncated-vendi.",
    "summary": "arXiv:2410.21719v3 Announce Type: replace-cross Abstract: Evaluating the diversity of generative models without reference data poses methodological challenges. The reference-free Vendi and RKE scores address this by quantifying the diversity of generated data using matrix-based entropy measures. Among these two, the Vendi score is typically computed via the eigendecomposition of an $n times n$ kernel matrix constructed from n generated samples. However, the prohibitive computational cost of eigendecomposition for large $n$ often limits the number of samples used to fewer than 20,000. In this paper, we investigate the statistical convergence of the Vendi and RKE scores under restricted sample sizes. We numerically demonstrate that, in general, the Vendi score computed with standard sample sizes below 20,000 may not converge to its asymptotic value under infinite sampling. To address this, we introduce the $t$-truncated Vendi score by truncating the eigenspectrum of the kernel matrix, which is provably guaranteed to converge to its population limit with $n=mathcal{O}(t)$ samples. We further show that existing Nystr'om and FKEA approximation methods converge to the asymptotic limit of the truncated Vendi score. In contrast to the Vendi score, we prove that the RKE score enjoys universal convergence guarantees across all kernel functions. We conduct several numerical experiments to illustrate the concentration of Nystr'om and FKEA computed Vendi scores around the truncated Vendi score, and we analyze how the truncated Vendi and RKE scores correlate with the diversity of image and text data. The code is available at https://github.com/aziksh-ospanov/truncated-vendi.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.21719",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Efficient Table Pre-training without Real Data: An Introduction to TAPEX",
    "description": "",
    "summary": "Efficient Table Pre-training without Real Data: An Introduction to TAPEX In recent years, language m...",
    "pubDate": "Mon, 23 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tapex",
    "thumbnail": "https://huggingface.co/blog/assets/74_tapex/thumbnail.png"
  },
  {
    "title": "ReasonGRM: Enhancing Generative Reward Models through Large Reasoning Models",
    "description": "arXiv:2506.16712v1 Announce Type: cross Abstract: Generative Reward Models (GRMs) provide greater flexibility than scalar reward models in capturing human preferences, but their effectiveness is limited by poor reasoning capabilities. This often results in incomplete or overly speculative reasoning paths, leading to hallucinations or missing key information in complex tasks. We address this challenge with ReasonGRM, a three-stage generative reward modeling framework. In the first stage, Zero-RL is used to generate concise, outcome-directed reasoning paths that reduce the likelihood of critical omissions. In the second stage, we introduce a novel evaluation metric, $R^star$, which scores reasoning paths based on their generation likelihood. This favors paths that reach correct answers with minimal exploration, helping to reduce hallucination-prone data during training. In the final stage, the model is further refined through reinforcement learning on challenging examples to enhance its preference discrimination capabilities. Experiments on three public benchmarks show that ReasonGRM achieves competitive or state-of-the-art performance, outperforming previous best GRMs by 1.8% on average and surpassing proprietary models such as GPT-4o by up to 5.6%. These results demonstrate the effectiveness of reasoning-aware training and highlight the importance of high-quality rationale selection for reliable preference modeling.",
    "summary": "arXiv:2506.16712v1 Announce Type: cross Abstract: Generative Reward Models (GRMs) provide greater flexibility than scalar reward models in capturing human preferences, but their effectiveness is limited by poor reasoning capabilities. This often results in incomplete or overly speculative reasoning paths, leading to hallucinations or missing key information in complex tasks. We address this challenge with ReasonGRM, a three-stage generative reward modeling framework. In the first stage, Zero-RL is used to generate concise, outcome-directed reasoning paths that reduce the likelihood of critical omissions. In the second stage, we introduce a novel evaluation metric, $R^star$, which scores reasoning paths based on their generation likelihood. This favors paths that reach correct answers with minimal exploration, helping to reduce hallucination-prone data during training. In the final stage, the model is further refined through reinforcement learning on challenging examples to enhance its preference discrimination capabilities. Experiments on three public benchmarks show that ReasonGRM achieves competitive or state-of-the-art performance, outperforming previous best GRMs by 1.8% on average and surpassing proprietary models such as GPT-4o by up to 5.6%. These results demonstrate the effectiveness of reasoning-aware training and highlight the importance of high-quality rationale selection for reliable preference modeling.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16712",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Surging developer productivity with custom GPTs",
    "description": "Paf adopted ChatGPT Enterprise across its entire company, with engineers using custom GPTs on a daily basis to speed up routine development tasks. Paf also integrated ChatGPT Enterprise into the grit:lab coding academy (gritlab.ax), training the next generation of software developers using an AI-augmented, systems-architecture mindset from day one. In addition to the wide range of use cases for developers and grit:lab students, 70% of Paf employees actively use ChatGPT Enterprise, spanning business teams like finance, HR, marketing, and customer support.",
    "summary": "Paf adopted ChatGPT Enterprise across its entire company, with engineers using custom GPTs on a daily basis to speed up routine development tasks. Paf also integrated ChatGPT Enterprise into the grit:lab coding academy (gritlab.ax), training the next generation of software developers using an AI-augmented, systems-architecture mindset from day one. In addition to the wide range of use cases for developers and grit:lab students, 70% of Paf employees actively use ChatGPT Enterprise, spanning business teams like finance, HR, marketing, and customer support.",
    "pubDate": "Tue, 18 Jun 2024 08:45:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paf",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Dota 2 with large scale deep reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 13 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dota-2-with-large-scale-deep-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Report from the OpenAI hackathon",
    "description": "On March 3rd, we hosted our first¬†hackathon¬†with 100 members of the artificial intelligence community.",
    "summary": "On March 3rd, we hosted our first¬†hackathon¬†with 100 members of the artificial intelligence community.",
    "pubDate": "Thu, 15 Mar 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/hackathon-follow-up",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Constitutional AI with Open LLMs",
    "description": "",
    "summary": "Constitutional AI with Open LLMs Since the launch of ChatGPT in 2022, we have seen tremendous progre...",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/constitutional_ai",
    "thumbnail": "https://huggingface.co/blog/assets/175_constitutional_ai/thumbnail.png"
  },
  {
    "title": "MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension",
    "description": "arXiv:2409.13609v4 Announce Type: replace-cross Abstract: Referring Expression Comprehension (REC), which aims to ground a local visual region via natural language, is a task that heavily relies on multimodal alignment. Most existing methods utilize powerful pre-trained models to transfer visual/linguistic knowledge by full fine-tuning. However, full fine-tuning the entire backbone not only breaks the rich prior knowledge embedded in the pre-training, but also incurs significant computational costs. Motivated by the recent emergence of Parameter-Efficient Transfer Learning (PETL) methods, we aim to solve the REC task in an effective and efficient manner. Directly applying these PETL methods to the REC task is inappropriate, as they lack the specific-domain abilities for precise local visual perception and visual-language alignment. Therefore, we propose a novel framework of Multimodal Prior-guided Parameter Efficient Tuning, namely MaPPER. Specifically, MaPPER comprises Dynamic Prior Adapters guided by an aligned prior, and Local Convolution Adapters to extract precise local semantics for better visual perception. Moreover, the Prior-Guided Text module is proposed to further utilize the prior for facilitating the cross-modal alignment. Experimental results on three widely-used benchmarks demonstrate that MaPPER achieves the best accuracy compared to the full fine-tuning and other PETL methods with only 1.41% tunable backbone parameters. Our code is available at https://github.com/liuting20/MaPPER.",
    "summary": "arXiv:2409.13609v4 Announce Type: replace-cross Abstract: Referring Expression Comprehension (REC), which aims to ground a local visual region via natural language, is a task that heavily relies on multimodal alignment. Most existing methods utilize powerful pre-trained models to transfer visual/linguistic knowledge by full fine-tuning. However, full fine-tuning the entire backbone not only breaks the rich prior knowledge embedded in the pre-training, but also incurs significant computational costs. Motivated by the recent emergence of Parameter-Efficient Transfer Learning (PETL) methods, we aim to solve the REC task in an effective and efficient manner. Directly applying these PETL methods to the REC task is inappropriate, as they lack the specific-domain abilities for precise local visual perception and visual-language alignment. Therefore, we propose a novel framework of Multimodal Prior-guided Parameter Efficient Tuning, namely MaPPER. Specifically, MaPPER comprises Dynamic Prior Adapters guided by an aligned prior, and Local Convolution Adapters to extract precise local semantics for better visual perception. Moreover, the Prior-Guided Text module is proposed to further utilize the prior for facilitating the cross-modal alignment. Experimental results on three widely-used benchmarks demonstrate that MaPPER achieves the best accuracy compared to the full fine-tuning and other PETL methods with only 1.41% tunable backbone parameters. Our code is available at https://github.com/liuting20/MaPPER.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.13609",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google DeepMind at ICML 2024",
    "description": "Exploring AGI, the challenges of scaling and the future of multimodal generative AI",
    "summary": "Exploring AGI, the challenges of scaling and the future of multimodal generative AI",
    "pubDate": "Fri, 19 Jul 2024 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-icml-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/_o0MU47bgKrTJi6uOWhc3BjWOOENkBczD2x5-tK5aMLBcljJnV-N8tZuSVN42C3d1pSWawY6NsGuoj6vvl0xMk4tpWOeUjXwlgFNZSMyJkFJ02xTauk=w1200-h630-n-nu"
  },
  {
    "title": "Towards Generalizable Generic Harmful Speech Datasets for Implicit Hate Speech Detection",
    "description": "arXiv:2506.16476v1 Announce Type: cross Abstract: Implicit hate speech has recently emerged as a critical challenge for social media platforms. While much of the research has traditionally focused on harmful speech in general, the need for generalizable techniques to detect veiled and subtle forms of hate has become increasingly pressing. Based on lexicon analysis, we hypothesize that implicit hate speech is already present in publicly available harmful speech datasets but may not have been explicitly recognized or labeled by annotators. Additionally, crowdsourced datasets are prone to mislabeling due to the complexity of the task and often influenced by annotators' subjective interpretations. In this paper, we propose an approach to address the detection of implicit hate speech and enhance generalizability across diverse datasets by leveraging existing harmful speech datasets. Our method comprises three key components: influential sample identification, reannotation, and augmentation using Llama-3 70B and GPT-4o. Experimental results demonstrate the effectiveness of our approach in improving implicit hate detection, achieving a +12.9-point F1 score improvement compared to the baseline.",
    "summary": "arXiv:2506.16476v1 Announce Type: cross Abstract: Implicit hate speech has recently emerged as a critical challenge for social media platforms. While much of the research has traditionally focused on harmful speech in general, the need for generalizable techniques to detect veiled and subtle forms of hate has become increasingly pressing. Based on lexicon analysis, we hypothesize that implicit hate speech is already present in publicly available harmful speech datasets but may not have been explicitly recognized or labeled by annotators. Additionally, crowdsourced datasets are prone to mislabeling due to the complexity of the task and often influenced by annotators' subjective interpretations. In this paper, we propose an approach to address the detection of implicit hate speech and enhance generalizability across diverse datasets by leveraging existing harmful speech datasets. Our method comprises three key components: influential sample identification, reannotation, and augmentation using Llama-3 70B and GPT-4o. Experimental results demonstrate the effectiveness of our approach in improving implicit hate detection, achieving a +12.9-point F1 score improvement compared to the baseline.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16476",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Loupe: A Generalizable and Adaptive Framework for Image Forgery Detection",
    "description": "arXiv:2506.16819v1 Announce Type: cross Abstract: The proliferation of generative models has raised serious concerns about visual content forgery. Existing deepfake detection methods primarily target either image-level classification or pixel-wise localization. While some achieve high accuracy, they often suffer from limited generalization across manipulation types or rely on complex architectures. In this paper, we propose Loupe, a lightweight yet effective framework for joint deepfake detection and localization. Loupe integrates a patch-aware classifier and a segmentation module with conditional queries, allowing simultaneous global authenticity classification and fine-grained mask prediction. To enhance robustness against distribution shifts of test set, Loupe introduces a pseudo-label-guided test-time adaptation mechanism by leveraging patch-level predictions to supervise the segmentation head. Extensive experiments on the DDL dataset demonstrate that Loupe achieves state-of-the-art performance, securing the first place in the IJCAI 2025 Deepfake Detection and Localization Challenge with an overall score of 0.846. Our results validate the effectiveness of the proposed patch-level fusion and conditional query design in improving both classification accuracy and spatial localization under diverse forgery patterns. The code is available at https://github.com/Kamichanw/Loupe.",
    "summary": "arXiv:2506.16819v1 Announce Type: cross Abstract: The proliferation of generative models has raised serious concerns about visual content forgery. Existing deepfake detection methods primarily target either image-level classification or pixel-wise localization. While some achieve high accuracy, they often suffer from limited generalization across manipulation types or rely on complex architectures. In this paper, we propose Loupe, a lightweight yet effective framework for joint deepfake detection and localization. Loupe integrates a patch-aware classifier and a segmentation module with conditional queries, allowing simultaneous global authenticity classification and fine-grained mask prediction. To enhance robustness against distribution shifts of test set, Loupe introduces a pseudo-label-guided test-time adaptation mechanism by leveraging patch-level predictions to supervise the segmentation head. Extensive experiments on the DDL dataset demonstrate that Loupe achieves state-of-the-art performance, securing the first place in the IJCAI 2025 Deepfake Detection and Localization Challenge with an overall score of 0.846. Our results validate the effectiveness of the proposed patch-level fusion and conditional query design in improving both classification accuracy and spatial localization under diverse forgery patterns. The code is available at https://github.com/Kamichanw/Loupe.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16819",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Partnership with Axel Springer to deepen beneficial use of AI in journalism",
    "description": "Axel Springer is the first publishing house globally to partner with us on a deeper integration of journalism in AI technologies.",
    "summary": "Axel Springer is the first publishing house globally to partner with us on a deeper integration of journalism in AI technologies.",
    "pubDate": "Wed, 13 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/axel-springer-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Veracity: An Open-Source AI Fact-Checking System",
    "description": "arXiv:2506.15794v1 Announce Type: cross Abstract: The proliferation of misinformation poses a significant threat to society, exacerbated by the capabilities of generative AI. This demo paper introduces Veracity, an open-source AI system designed to empower individuals to combat misinformation through transparent and accessible fact-checking. Veracity leverages the synergy between Large Language Models (LLMs) and web retrieval agents to analyze user-submitted claims and provide grounded veracity assessments with intuitive explanations. Key features include multilingual support, numerical scoring of claim veracity, and an interactive interface inspired by familiar messaging applications. This paper will showcase Veracity's ability to not only detect misinformation but also explain its reasoning, fostering media literacy and promoting a more informed society.",
    "summary": "arXiv:2506.15794v1 Announce Type: cross Abstract: The proliferation of misinformation poses a significant threat to society, exacerbated by the capabilities of generative AI. This demo paper introduces Veracity, an open-source AI system designed to empower individuals to combat misinformation through transparent and accessible fact-checking. Veracity leverages the synergy between Large Language Models (LLMs) and web retrieval agents to analyze user-submitted claims and provide grounded veracity assessments with intuitive explanations. Key features include multilingual support, numerical scoring of claim veracity, and an interactive interface inspired by familiar messaging applications. This paper will showcase Veracity's ability to not only detect misinformation but also explain its reasoning, fostering media literacy and promoting a more informed society.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15794",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Vision-Guided Chunking Is All You Need: Enhancing RAG with Multimodal Document Understanding",
    "description": "arXiv:2506.16035v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) systems have revolutionized information retrieval and question answering, but traditional text-based chunking methods struggle with complex document structures, multi-page tables, embedded figures, and contextual dependencies across page boundaries. We present a novel multimodal document chunking approach that leverages Large Multimodal Models (LMMs) to process PDF documents in batches while maintaining semantic coherence and structural integrity. Our method processes documents in configurable page batches with cross-batch context preservation, enabling accurate handling of tables spanning multiple pages, embedded visual elements, and procedural content. We evaluate our approach on a curated dataset of PDF documents with manually crafted queries, demonstrating improvements in chunk quality and downstream RAG performance. Our vision-guided approach achieves better accuracy compared to traditional vanilla RAG systems, with qualitative analysis showing superior preservation of document structure and semantic coherence.",
    "summary": "arXiv:2506.16035v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) systems have revolutionized information retrieval and question answering, but traditional text-based chunking methods struggle with complex document structures, multi-page tables, embedded figures, and contextual dependencies across page boundaries. We present a novel multimodal document chunking approach that leverages Large Multimodal Models (LMMs) to process PDF documents in batches while maintaining semantic coherence and structural integrity. Our method processes documents in configurable page batches with cross-batch context preservation, enabling accurate handling of tables spanning multiple pages, embedded visual elements, and procedural content. We evaluate our approach on a curated dataset of PDF documents with manually crafted queries, demonstrating improvements in chunk quality and downstream RAG performance. Our vision-guided approach achieves better accuracy compared to traditional vanilla RAG systems, with qualitative analysis showing superior preservation of document structure and semantic coherence.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16035",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Procgen Benchmark",
    "description": "We‚Äôre releasing Procgen Benchmark, 16 simple-to-use¬†procedurally-generated¬†environments which provide a direct measure of how quickly a reinforcement learning agent learns generalizable¬†skills.",
    "summary": "We‚Äôre releasing Procgen Benchmark, 16 simple-to-use¬†procedurally-generated¬†environments which provide a direct measure of how quickly a reinforcement learning agent learns generalizable¬†skills.",
    "pubDate": "Tue, 03 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/procgen-benchmark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "EUR-USD Exchange Rate Forecasting Based on Information Fusion with Large Language Models and Deep Learning Methods",
    "description": "arXiv:2408.13214v2 Announce Type: replace-cross Abstract: Accurate forecasting of the EUR/USD exchange rate is crucial for investors, businesses, and policymakers. This paper proposes a novel framework, IUS, that integrates unstructured textual data from news and analysis with structured data on exchange rates and financial indicators to enhance exchange rate prediction. The IUS framework employs large language models for sentiment polarity scoring and exchange rate movement classification of texts. These textual features are combined with quantitative features and input into a Causality-Driven Feature Generator. An Optuna-optimized Bi-LSTM model is then used to forecast the EUR/USD exchange rate. Experiments demonstrate that the proposed method outperforms benchmark models, reducing MAE by 10.69% and RMSE by 9.56% compared to the best performing baseline. Results also show the benefits of data fusion, with the combination of unstructured and structured data yielding higher accuracy than structured data alone. Furthermore, feature selection using the top 12 important quantitative features combined with the textual features proves most effective. The proposed IUS framework and Optuna-Bi-LSTM model provide a powerful new approach for exchange rate forecasting through multi-source data integration.",
    "summary": "arXiv:2408.13214v2 Announce Type: replace-cross Abstract: Accurate forecasting of the EUR/USD exchange rate is crucial for investors, businesses, and policymakers. This paper proposes a novel framework, IUS, that integrates unstructured textual data from news and analysis with structured data on exchange rates and financial indicators to enhance exchange rate prediction. The IUS framework employs large language models for sentiment polarity scoring and exchange rate movement classification of texts. These textual features are combined with quantitative features and input into a Causality-Driven Feature Generator. An Optuna-optimized Bi-LSTM model is then used to forecast the EUR/USD exchange rate. Experiments demonstrate that the proposed method outperforms benchmark models, reducing MAE by 10.69% and RMSE by 9.56% compared to the best performing baseline. Results also show the benefits of data fusion, with the combination of unstructured and structured data yielding higher accuracy than structured data alone. Furthermore, feature selection using the top 12 important quantitative features combined with the textual features proves most effective. The proposed IUS framework and Optuna-Bi-LSTM model provide a powerful new approach for exchange rate forecasting through multi-source data integration.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.13214",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Large-scale Near-deduplication Behind BigCode",
    "description": "",
    "summary": "Large-scale Near-deduplication Behind BigCode Intended Audience People who are interested in documen...",
    "pubDate": "Tue, 16 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/dedup",
    "thumbnail": "https://huggingface.co/blog/assets/dedup/thumbnail.png"
  },
  {
    "title": "Fine-tuning XLS-R for Multi-Lingual ASR with ü§ó Transformers",
    "description": "",
    "summary": "Fine-tuning XLS-R for Multi-Lingual ASR with ü§ó Transformers New (11/2021): This blog post has been u...",
    "pubDate": "Mon, 15 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-xlsr-wav2vec2",
    "thumbnail": "https://huggingface.co/blog/assets/xlsr_wav2vec2.png"
  },
  {
    "title": "Quantifying artificial intelligence through algorithmic generalization",
    "description": "arXiv:2411.05943v2 Announce Type: replace Abstract: The rapid development of artificial intelligence (AI) systems has created an urgent need for their scientific quantification. While their fluency across a variety of domains is impressive, AI systems fall short on tests requiring algorithmic reasoning -- a glaring limitation given the necessity for interpretable and reliable technology. Despite a surge of reasoning benchmarks emerging from the academic community, no theoretical framework exists to quantify algorithmic reasoning in AI systems. Here, we adopt a framework from computational complexity theory to quantify algorithmic generalization using algebraic expressions: algebraic circuit complexity. Algebraic circuit complexity theory -- the study of algebraic expressions as circuit models -- is a natural framework to study the complexity of algorithmic computation. Algebraic circuit complexity enables the study of generalization by defining benchmarks in terms of the computational requirements to solve a problem. Moreover, algebraic circuits are generic mathematical objects; an arbitrarily large number of samples can be generated for a specified circuit, making it an ideal experimental sandbox for the data-hungry models that are used today. In this Perspective, we adopt tools from algebraic circuit complexity, apply them to formalize a science of algorithmic generalization, and address key challenges for its successful application to AI science.",
    "summary": "arXiv:2411.05943v2 Announce Type: replace Abstract: The rapid development of artificial intelligence (AI) systems has created an urgent need for their scientific quantification. While their fluency across a variety of domains is impressive, AI systems fall short on tests requiring algorithmic reasoning -- a glaring limitation given the necessity for interpretable and reliable technology. Despite a surge of reasoning benchmarks emerging from the academic community, no theoretical framework exists to quantify algorithmic reasoning in AI systems. Here, we adopt a framework from computational complexity theory to quantify algorithmic generalization using algebraic expressions: algebraic circuit complexity. Algebraic circuit complexity theory -- the study of algebraic expressions as circuit models -- is a natural framework to study the complexity of algorithmic computation. Algebraic circuit complexity enables the study of generalization by defining benchmarks in terms of the computational requirements to solve a problem. Moreover, algebraic circuits are generic mathematical objects; an arbitrarily large number of samples can be generated for a specified circuit, making it an ideal experimental sandbox for the data-hungry models that are used today. In this Perspective, we adopt tools from algebraic circuit complexity, apply them to formalize a science of algorithmic generalization, and address key challenges for its successful application to AI science.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.05943",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI‚Äôs proposals for the U.S. AI Action Plan",
    "description": "Recommendations build on OpenAI‚Äôs Economic Blueprint to strengthen America‚Äôs AI leadership.",
    "summary": "Recommendations build on OpenAI‚Äôs Economic Blueprint to strengthen America‚Äôs AI leadership.",
    "pubDate": "Thu, 13 Mar 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-proposals-for-the-us-ai-action-plan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o1-mini",
    "description": "Advancing cost-efficient reasoning",
    "summary": "Advancing cost-efficient reasoning",
    "pubDate": "Thu, 12 Sep 2024 10:01:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-mini-advancing-cost-efficient-reasoning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sysformer: Safeguarding Frozen Large Language Models with Adaptive System Prompts",
    "description": "arXiv:2506.15751v1 Announce Type: new Abstract: As large language models (LLMs) are deployed in safety-critical settings, it is essential to ensure that their responses comply with safety standards. Prior research has revealed that LLMs often fail to grasp the notion of safe behaviors, resulting in either unjustified refusals to harmless prompts or the generation of harmful content. While substantial efforts have been made to improve their robustness, existing defenses often rely on costly fine-tuning of model parameters or employ suboptimal heuristic techniques. In this work, we take a novel approach to safeguard LLMs by learning to adapt the system prompts in instruction-tuned LLMs. While LLMs are typically pre-trained to follow a fixed system prompt, we investigate the impact of tailoring the system prompt to each specific user input on the safety of the responses. To this end, we propose $textbf{Sysformer}$, a trans$textbf{former}$ model that updates an initial $textbf{sys}$tem prompt to a more robust system prompt in the LLM input embedding space while attending to the user prompt. While keeping the LLM parameters frozen, the Sysformer is trained to refuse to respond to a set of harmful prompts while responding ideally to a set of safe ones. Through extensive experiments on $5$ LLMs from different families and $2$ recent benchmarks, we demonstrate that Sysformer can significantly enhance the robustness of LLMs, leading to upto $80%$ gain in the refusal rate on harmful prompts while enhancing the compliance with the safe prompts by upto $90%$. Results also generalize well to sophisticated jailbreaking attacks, making LLMs upto $100%$ more robust against different attack strategies. We hope our findings lead to cheaper safeguarding of LLMs and motivate future investigations into designing variable system prompts.",
    "summary": "arXiv:2506.15751v1 Announce Type: new Abstract: As large language models (LLMs) are deployed in safety-critical settings, it is essential to ensure that their responses comply with safety standards. Prior research has revealed that LLMs often fail to grasp the notion of safe behaviors, resulting in either unjustified refusals to harmless prompts or the generation of harmful content. While substantial efforts have been made to improve their robustness, existing defenses often rely on costly fine-tuning of model parameters or employ suboptimal heuristic techniques. In this work, we take a novel approach to safeguard LLMs by learning to adapt the system prompts in instruction-tuned LLMs. While LLMs are typically pre-trained to follow a fixed system prompt, we investigate the impact of tailoring the system prompt to each specific user input on the safety of the responses. To this end, we propose $textbf{Sysformer}$, a trans$textbf{former}$ model that updates an initial $textbf{sys}$tem prompt to a more robust system prompt in the LLM input embedding space while attending to the user prompt. While keeping the LLM parameters frozen, the Sysformer is trained to refuse to respond to a set of harmful prompts while responding ideally to a set of safe ones. Through extensive experiments on $5$ LLMs from different families and $2$ recent benchmarks, we demonstrate that Sysformer can significantly enhance the robustness of LLMs, leading to upto $80%$ gain in the refusal rate on harmful prompts while enhancing the compliance with the safe prompts by upto $90%$. Results also generalize well to sophisticated jailbreaking attacks, making LLMs upto $100%$ more robust against different attack strategies. We hope our findings lead to cheaper safeguarding of LLMs and motivate future investigations into designing variable system prompts.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15751",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Strengthening America‚Äôs AI leadership with the U.S. National Laboratories",
    "description": "OpenAI‚Äôs latest line of reasoning models will be used by nation‚Äôs leading scientists to drive scientific breakthroughs.",
    "summary": "OpenAI‚Äôs latest line of reasoning models will be used by nation‚Äôs leading scientists to drive scientific breakthroughs.",
    "pubDate": "Thu, 30 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/strengthening-americas-ai-leadership-with-the-us-national-laboratories",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introduction to Graph Machine Learning",
    "description": "",
    "summary": "Introduction to Graph Machine Learning In this blog post, we cover the basics of graph machine learn...",
    "pubDate": "Tue, 03 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intro-graphml",
    "thumbnail": "https://huggingface.co/blog/assets/125_intro-to-graphml/thumbnail.png"
  },
  {
    "title": "Advancing red teaming with people and AI",
    "description": "Advancing red teaming with people and AI",
    "summary": "Advancing red teaming with people and AI",
    "pubDate": "Thu, 21 Nov 2024 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/advancing-red-teaming-with-people-and-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI‚Äôs comments to the NTIA on data center growth, resilience, and security",
    "description": "This comment was submitted in response to a request for information from the National Telecommunications and Information Administration (NTIA).",
    "summary": "This comment was submitted in response to a request for information from the National Telecommunications and Information Administration (NTIA).",
    "pubDate": "Mon, 04 Nov 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/comments-to-the-ntia-on-data-center-growth-resilience-and-security",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing SynthID Text",
    "description": "",
    "summary": "Introducing SynthID Text Do you find it difficult to tell if text was written by a human or generate...",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/synthid-text",
    "thumbnail": "https://huggingface.co/blog/assets/synthid-text/thumbnail.png"
  },
  {
    "title": "UniWorld-V1: High-Resolution Semantic Encoders for Unified Visual Understanding and Generation",
    "description": "arXiv:2506.03147v4 Announce Type: replace-cross Abstract: Although existing unified models achieve strong performance in vision-language understanding and text-to-image generation, they remain limited in addressing image perception and manipulation -- capabilities increasingly demanded in practical applications. Recently, OpenAI introduced the powerful GPT-4o-Image model, which showcases advanced capabilities in comprehensive image perception and manipulation, sparking widespread interest. Through carefully designed experiments, we observe that GPT-4o-Image likely relies on semantic encoders rather than VAEs for feature extraction, despite VAEs being commonly regarded as crucial for image manipulation tasks. Inspired by this insight, we propose UniWorld-V1, a unified generative framework built upon semantic features extracted from powerful multimodal large language models and contrastive semantic encoders. Using only 2.7M training data, UniWorld-V1 achieves impressive performance across diverse tasks, including image understanding, generation, manipulation, and perception. We fully open-source the UniWorld-V1 framework, including model weights, training and evaluation scripts, and datasets to promote reproducibility and further research.",
    "summary": "arXiv:2506.03147v4 Announce Type: replace-cross Abstract: Although existing unified models achieve strong performance in vision-language understanding and text-to-image generation, they remain limited in addressing image perception and manipulation -- capabilities increasingly demanded in practical applications. Recently, OpenAI introduced the powerful GPT-4o-Image model, which showcases advanced capabilities in comprehensive image perception and manipulation, sparking widespread interest. Through carefully designed experiments, we observe that GPT-4o-Image likely relies on semantic encoders rather than VAEs for feature extraction, despite VAEs being commonly regarded as crucial for image manipulation tasks. Inspired by this insight, we propose UniWorld-V1, a unified generative framework built upon semantic features extracted from powerful multimodal large language models and contrastive semantic encoders. Using only 2.7M training data, UniWorld-V1 achieves impressive performance across diverse tasks, including image understanding, generation, manipulation, and perception. We fully open-source the UniWorld-V1 framework, including model weights, training and evaluation scripts, and datasets to promote reproducibility and further research.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.03147",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning to Route LLMs with Confidence Tokens",
    "description": "arXiv:2410.13284v3 Announce Type: replace-cross Abstract: Large language models (LLMs) have demonstrated impressive performance on several tasks and are increasingly deployed in real-world applications. However, especially in high-stakes settings, it becomes vital to know when the output of an LLM may be unreliable. Depending on whether an answer is trustworthy, a system can then choose to route the question to another expert, or otherwise fall back on a safe default behavior. In this work, we study the extent to which LLMs can reliably indicate confidence in their answers, and how this notion of confidence can translate into downstream accuracy gains. We propose Self-Reflection with Error-based Feedback (Self-REF), a lightweight training strategy to teach LLMs to express confidence in whether their answers are correct in a reliable manner. Self-REF introduces confidence tokens into the LLM, from which a confidence score can be extracted. Compared to conventional approaches such as verbalizing confidence and examining token probabilities, we demonstrate empirically that confidence tokens show significant improvements in downstream routing and rejection learning tasks.",
    "summary": "arXiv:2410.13284v3 Announce Type: replace-cross Abstract: Large language models (LLMs) have demonstrated impressive performance on several tasks and are increasingly deployed in real-world applications. However, especially in high-stakes settings, it becomes vital to know when the output of an LLM may be unreliable. Depending on whether an answer is trustworthy, a system can then choose to route the question to another expert, or otherwise fall back on a safe default behavior. In this work, we study the extent to which LLMs can reliably indicate confidence in their answers, and how this notion of confidence can translate into downstream accuracy gains. We propose Self-Reflection with Error-based Feedback (Self-REF), a lightweight training strategy to teach LLMs to express confidence in whether their answers are correct in a reliable manner. Self-REF introduces confidence tokens into the LLM, from which a confidence score can be extracted. Compared to conventional approaches such as verbalizing confidence and examining token probabilities, we demonstrate empirically that confidence tokens show significant improvements in downstream routing and rejection learning tasks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.13284",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Generative Data Mining with Longtail-Guided Diffusion",
    "description": "arXiv:2502.01980v2 Announce Type: replace-cross Abstract: It is difficult to anticipate the myriad challenges that a predictive model will encounter once deployed. Common practice entails a reactive, cyclical approach: model deployment, data mining, and retraining. We instead develop a proactive longtail discovery process by imagining additional data during training. In particular, we develop general model-based longtail signals, including a differentiable, single forward pass formulation of epistemic uncertainty that does not impact model parameters or predictive performance but can flag rare or hard inputs. We leverage these signals as guidance to generate additional training data from a latent diffusion model in a process we call Longtail Guidance (LTG). Crucially, we can perform LTG without retraining the diffusion model or the predictive model, and we do not need to expose the predictive model to intermediate diffusion states. Data generated by LTG exhibit semantically meaningful variation, yield significant generalization improvements on numerous image classification benchmarks, and can be analyzed by a VLM to proactively discover, textually explain, and address conceptual gaps in a deployed predictive model.",
    "summary": "arXiv:2502.01980v2 Announce Type: replace-cross Abstract: It is difficult to anticipate the myriad challenges that a predictive model will encounter once deployed. Common practice entails a reactive, cyclical approach: model deployment, data mining, and retraining. We instead develop a proactive longtail discovery process by imagining additional data during training. In particular, we develop general model-based longtail signals, including a differentiable, single forward pass formulation of epistemic uncertainty that does not impact model parameters or predictive performance but can flag rare or hard inputs. We leverage these signals as guidance to generate additional training data from a latent diffusion model in a process we call Longtail Guidance (LTG). Crucially, we can perform LTG without retraining the diffusion model or the predictive model, and we do not need to expose the predictive model to intermediate diffusion states. Data generated by LTG exhibit semantically meaningful variation, yield significant generalization improvements on numerous image classification benchmarks, and can be analyzed by a VLM to proactively discover, textually explain, and address conceptual gaps in a deployed predictive model.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.01980",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CAT-SG: A Large Dynamic Scene Graph Dataset for Fine-Grained Understanding of Cataract Surgery",
    "description": "arXiv:2506.21813v1 Announce Type: cross Abstract: Understanding the intricate workflows of cataract surgery requires modeling complex interactions between surgical tools, anatomical structures, and procedural techniques. Existing datasets primarily address isolated aspects of surgical analysis, such as tool detection or phase segmentation, but lack comprehensive representations that capture the semantic relationships between entities over time. This paper introduces the Cataract Surgery Scene Graph (CAT-SG) dataset, the first to provide structured annotations of tool-tissue interactions, procedural variations, and temporal dependencies. By incorporating detailed semantic relations, CAT-SG offers a holistic view of surgical workflows, enabling more accurate recognition of surgical phases and techniques. Additionally, we present a novel scene graph generation model, CatSGG, which outperforms current methods in generating structured surgical representations. The CAT-SG dataset is designed to enhance AI-driven surgical training, real-time decision support, and workflow analysis, paving the way for more intelligent, context-aware systems in clinical practice.",
    "summary": "arXiv:2506.21813v1 Announce Type: cross Abstract: Understanding the intricate workflows of cataract surgery requires modeling complex interactions between surgical tools, anatomical structures, and procedural techniques. Existing datasets primarily address isolated aspects of surgical analysis, such as tool detection or phase segmentation, but lack comprehensive representations that capture the semantic relationships between entities over time. This paper introduces the Cataract Surgery Scene Graph (CAT-SG) dataset, the first to provide structured annotations of tool-tissue interactions, procedural variations, and temporal dependencies. By incorporating detailed semantic relations, CAT-SG offers a holistic view of surgical workflows, enabling more accurate recognition of surgical phases and techniques. Additionally, we present a novel scene graph generation model, CatSGG, which outperforms current methods in generating structured surgical representations. The CAT-SG dataset is designed to enhance AI-driven surgical training, real-time decision support, and workflow analysis, paving the way for more intelligent, context-aware systems in clinical practice.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21813",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning",
    "description": "<p>Microsoft researchers achieved a breakthrough in the accuracy of DFT, a method for predicting the properties of molecules and materials, by using deep learning. This work can lead to better batteries, green fertilizers, precision drug discovery, and more.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/'>Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Microsoft researchers achieved a breakthrough in the accuracy of DFT, a method for predicting the properties of molecules and materials, by using deep learning. This work can lead to better batteries, green fertilizers, precision drug discovery, and more.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/'>Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Wed, 18 Jun 2025 10:01:47 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Multi-Preference Optimization: Generalizing DPO via Set-Level Contrasts",
    "description": "arXiv:2412.04628v4 Announce Type: replace-cross Abstract: Direct Preference Optimization (DPO) has become a popular approach for aligning language models using pairwise preferences. However, in practical post-training pipelines, on-policy generation typically yields multiple candidate responses per prompt, which are scored by a reward model to guide learning. In this setting, we propose $textbf{Multi-Preference Optimization (MPO)}$, a generalization of DPO that optimizes over entire sets of responses by extending the Bradley-Terry model to groupwise comparisons between chosen and rejected sets. To further enhance learning, MPO employs deviation-based weighting, which emphasizes outlier responses that deviate most from the mean reward, effectively inducing a self-paced curriculum. We theoretically prove that MPO reduces alignment bias at a rate of $mathcal{O}left(frac{1}{sqrt{n}}right)$ with respect to the number of responses per query. Empirically, MPO achieves state-of-the-art performance on the UltraFeedback benchmark and yields up to $sim 17.5%$ improvement over the state-of-the-art baseline in length-controlled win rate on AlpacaEval2, establishing a new baseline for preference-based alignment",
    "summary": "arXiv:2412.04628v4 Announce Type: replace-cross Abstract: Direct Preference Optimization (DPO) has become a popular approach for aligning language models using pairwise preferences. However, in practical post-training pipelines, on-policy generation typically yields multiple candidate responses per prompt, which are scored by a reward model to guide learning. In this setting, we propose $textbf{Multi-Preference Optimization (MPO)}$, a generalization of DPO that optimizes over entire sets of responses by extending the Bradley-Terry model to groupwise comparisons between chosen and rejected sets. To further enhance learning, MPO employs deviation-based weighting, which emphasizes outlier responses that deviate most from the mean reward, effectively inducing a self-paced curriculum. We theoretically prove that MPO reduces alignment bias at a rate of $mathcal{O}left(frac{1}{sqrt{n}}right)$ with respect to the number of responses per query. Empirically, MPO achieves state-of-the-art performance on the UltraFeedback benchmark and yields up to $sim 17.5%$ improvement over the state-of-the-art baseline in length-controlled win rate on AlpacaEval2, establishing a new baseline for preference-based alignment",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.04628",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "JCAPT: A Joint Modeling Approach for CAPT",
    "description": "arXiv:2506.19315v1 Announce Type: cross Abstract: Effective pronunciation feedback is critical in second language (L2) learning, for which computer-assisted pronunciation training (CAPT) systems often encompass two key tasks: automatic pronunciation assessment (APA) and mispronunciation detection and diagnosis (MDD). Recent work has shown that joint modeling of these two tasks can yield mutual benefits. Our unified framework leverages Mamba, a selective state space model (SSM), while integrating phonological features and think token strategies to jointly enhance interpretability and fine-grained temporal reasoning in APA and MDD. To our knowledge, this is the first study to combine phonological attribution, SSM-based modeling, and prompting in CAPT. A series of experiments conducted on the speechocean762 benchmark demonstrate that our model consistently outperforms prior methods, particularly on the MDD task.",
    "summary": "arXiv:2506.19315v1 Announce Type: cross Abstract: Effective pronunciation feedback is critical in second language (L2) learning, for which computer-assisted pronunciation training (CAPT) systems often encompass two key tasks: automatic pronunciation assessment (APA) and mispronunciation detection and diagnosis (MDD). Recent work has shown that joint modeling of these two tasks can yield mutual benefits. Our unified framework leverages Mamba, a selective state space model (SSM), while integrating phonological features and think token strategies to jointly enhance interpretability and fine-grained temporal reasoning in APA and MDD. To our knowledge, this is the first study to combine phonological attribution, SSM-based modeling, and prompting in CAPT. A series of experiments conducted on the speechocean762 benchmark demonstrate that our model consistently outperforms prior methods, particularly on the MDD task.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19315",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From Teacher to Student: Tracking Memorization Through Model Distillation",
    "description": "arXiv:2506.16170v1 Announce Type: cross Abstract: Large language models (LLMs) are known to memorize parts of their training data, raising important concerns around privacy and security. While previous research has focused on studying memorization in pre-trained models, much less is known about how knowledge distillation (KD) affects memorization.In this study, we explore how different KD methods influence the memorization of fine-tuned task data when a large teacher model is distilled into smaller student variants.This study demonstrates that distilling a larger teacher model, fine-tuned on a dataset, into a smaller variant not only lowers computational costs and model size but also significantly reduces the memorization risks compared to standard fine-tuning approaches.",
    "summary": "arXiv:2506.16170v1 Announce Type: cross Abstract: Large language models (LLMs) are known to memorize parts of their training data, raising important concerns around privacy and security. While previous research has focused on studying memorization in pre-trained models, much less is known about how knowledge distillation (KD) affects memorization.In this study, we explore how different KD methods influence the memorization of fine-tuned task data when a large teacher model is distilled into smaller student variants.This study demonstrates that distilling a larger teacher model, fine-tuned on a dataset, into a smaller variant not only lowers computational costs and model size but also significantly reduces the memorization risks compared to standard fine-tuning approaches.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16170",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How to train your model dynamically using adversarial data",
    "description": "",
    "summary": "How to train your model dynamically using adversarial data What you will learn here - üí°the basic ide...",
    "pubDate": "Sat, 16 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mnist-adversarial",
    "thumbnail": "https://huggingface.co/blog/assets/88_mnist_adversarial/mnist-adversarial.png"
  },
  {
    "title": "Reimagination with Test-time Observation Interventions: Distractor-Robust World Model Predictions for Visual Model Predictive Control",
    "description": "arXiv:2506.16565v1 Announce Type: cross Abstract: World models enable robots to 'imagine' future observations given current observations and planned actions, and have been increasingly adopted as generalized dynamics models to facilitate robot learning. Despite their promise, these models remain brittle when encountering novel visual distractors such as objects and background elements rarely seen during training. Specifically, novel distractors can corrupt action outcome predictions, causing downstream failures when robots rely on the world model imaginations for planning or action verification. In this work, we propose Reimagination with Observation Intervention (ReOI), a simple yet effective test-time strategy that enables world models to predict more reliable action outcomes in open-world scenarios where novel and unanticipated visual distractors are inevitable. Given the current robot observation, ReOI first detects visual distractors by identifying which elements of the scene degrade in physically implausible ways during world model prediction. Then, it modifies the current observation to remove these distractors and bring the observation closer to the training distribution. Finally, ReOI 'reimagines' future outcomes with the modified observation and reintroduces the distractors post-hoc to preserve visual consistency for downstream planning and verification. We validate our approach on a suite of robotic manipulation tasks in the context of action verification, where the verifier needs to select desired action plans based on predictions from a world model. Our results show that ReOI is robust to both in-distribution and out-of-distribution visual distractors. Notably, it improves task success rates by up to 3x in the presence of novel distractors, significantly outperforming action verification that relies on world model predictions without imagination interventions.",
    "summary": "arXiv:2506.16565v1 Announce Type: cross Abstract: World models enable robots to 'imagine' future observations given current observations and planned actions, and have been increasingly adopted as generalized dynamics models to facilitate robot learning. Despite their promise, these models remain brittle when encountering novel visual distractors such as objects and background elements rarely seen during training. Specifically, novel distractors can corrupt action outcome predictions, causing downstream failures when robots rely on the world model imaginations for planning or action verification. In this work, we propose Reimagination with Observation Intervention (ReOI), a simple yet effective test-time strategy that enables world models to predict more reliable action outcomes in open-world scenarios where novel and unanticipated visual distractors are inevitable. Given the current robot observation, ReOI first detects visual distractors by identifying which elements of the scene degrade in physically implausible ways during world model prediction. Then, it modifies the current observation to remove these distractors and bring the observation closer to the training distribution. Finally, ReOI 'reimagines' future outcomes with the modified observation and reintroduces the distractors post-hoc to preserve visual consistency for downstream planning and verification. We validate our approach on a suite of robotic manipulation tasks in the context of action verification, where the verifier needs to select desired action plans based on predictions from a world model. Our results show that ReOI is robust to both in-distribution and out-of-distribution visual distractors. Notably, it improves task success rates by up to 3x in the presence of novel distractors, significantly outperforming action verification that relies on world model predictions without imagination interventions.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16565",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Archaic„ÄÅÊó•Êú¨Ë™ûÁâπÂåñÂûãRAG„Ç∑„Çπ„ÉÜ„É†AI„ÇíÈñãÁô∫„ÄÇË£ΩÈÄ†Ê•≠ÂàÜÈáé„Åß„Éà„ÉÉ„Éó„ÇØ„É©„Çπ„ÅÆÊ≠£Á≠îÁéá",
    "description": "<p>Archaic„ÅØÊó•Êú¨Ë™ûÊ•≠ÂãôÊñáÊõ∏„Å´ÁâπÂåñ„Åó„ÅüRAG„Ç∑„Çπ„ÉÜ„É†AI„ÇíÈñãÁô∫„ÄÇÂÖ¨Èñã„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„ÅÆË©ï‰æ°„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅßË£ΩÈÄ†Ê•≠„Ç´„ÉÜ„Ç¥„É™„Å®ÂÖ®‰ΩìÂπ≥Âùá„Åß„Éà„ÉÉ„Éó„ÇØ„É©„Çπ„ÅÆÊ≠£Á≠îÁéá„ÇíË®òÈå≤„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Êó•Êú¨Ë™ûÊ•≠ÂãôÊñáÊõ∏„Å´ÁâπÂåñ„Åó„ÅüRAG [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/archaic-develops-japanese-specific-rag/'>Archaic„ÄÅÊó•Êú¨Ë™ûÁâπÂåñÂûãRAG„Ç∑„Çπ„ÉÜ„É†AI„ÇíÈñãÁô∫„ÄÇË£ΩÈÄ†Ê•≠ÂàÜÈáé„Åß„Éà„ÉÉ„Éó„ÇØ„É©„Çπ„ÅÆÊ≠£Á≠îÁéá</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>Archaic„ÅØÊó•Êú¨Ë™ûÊ•≠ÂãôÊñáÊõ∏„Å´ÁâπÂåñ„Åó„ÅüRAG„Ç∑„Çπ„ÉÜ„É†AI„ÇíÈñãÁô∫„ÄÇÂÖ¨Èñã„Éô„É≥„ÉÅ„Éû„Éº„ÇØ„ÅÆË©ï‰æ°„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅßË£ΩÈÄ†Ê•≠„Ç´„ÉÜ„Ç¥„É™„Å®ÂÖ®‰ΩìÂπ≥Âùá„Åß„Éà„ÉÉ„Éó„ÇØ„É©„Çπ„ÅÆÊ≠£Á≠îÁéá„ÇíË®òÈå≤„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Êó•Êú¨Ë™ûÊ•≠ÂãôÊñáÊõ∏„Å´ÁâπÂåñ„Åó„ÅüRAG [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/archaic-develops-japanese-specific-rag/'>Archaic„ÄÅÊó•Êú¨Ë™ûÁâπÂåñÂûãRAG„Ç∑„Çπ„ÉÜ„É†AI„ÇíÈñãÁô∫„ÄÇË£ΩÈÄ†Ê•≠ÂàÜÈáé„Åß„Éà„ÉÉ„Éó„ÇØ„É©„Çπ„ÅÆÊ≠£Á≠îÁéá</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Wed, 18 Jun 2025 05:51:09 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/archaic-develops-japanese-specific-rag/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/Archaic-develops-Japanese-specific-RAG1.png"
  },
  {
    "title": "Dialogic Pedagogy for Large Language Models: Aligning Conversational AI with Proven Theories of Learning",
    "description": "arXiv:2506.19484v1 Announce Type: cross Abstract: Large Language Models (LLMs) are rapidly transforming education by enabling rich conversational learning experiences. This article provides a comprehensive review of how LLM-based conversational agents are being used in higher education, with extensions to secondary and lifelong learning contexts. We synthesize existing literature on LLMs in education and theories of conversational and dialogic pedagogy - including Vygotsky's sociocultural learning (scaffolding and the Zone of Proximal Development), the Socratic method, and Laurillard's conversational framework - and examine how prompting strategies and retrieval-augmented generation (RAG) can align LLM behaviors with these pedagogical theories, and how it can support personalized, adaptive learning. We map educational theories to LLM capabilities, highlighting where LLM-driven dialogue supports established learning principles and where it challenges or falls short of traditional pedagogical assumptions. Notable gaps in applying prior theories to LLMs are identified, such as the models tendency to provide direct answers instead of fostering co-construction of knowledge, and the need to account for the constant availability and broad but non-human expertise of LLM tutors. In response, we propose practical strategies to better align LLM interactions with sound pedagogy - for example, designing prompts that encourage Socratic questioning, scaffolded guidance, and student reflection, as well as integrating retrieval mechanisms to ensure accuracy and contextual relevance. Our aim is to bridge the gap between educational theory and the emerging practice of AI-driven conversational learning, offering insights and tools for making LLM-based dialogues more educationally productive and theory-aligned.",
    "summary": "arXiv:2506.19484v1 Announce Type: cross Abstract: Large Language Models (LLMs) are rapidly transforming education by enabling rich conversational learning experiences. This article provides a comprehensive review of how LLM-based conversational agents are being used in higher education, with extensions to secondary and lifelong learning contexts. We synthesize existing literature on LLMs in education and theories of conversational and dialogic pedagogy - including Vygotsky's sociocultural learning (scaffolding and the Zone of Proximal Development), the Socratic method, and Laurillard's conversational framework - and examine how prompting strategies and retrieval-augmented generation (RAG) can align LLM behaviors with these pedagogical theories, and how it can support personalized, adaptive learning. We map educational theories to LLM capabilities, highlighting where LLM-driven dialogue supports established learning principles and where it challenges or falls short of traditional pedagogical assumptions. Notable gaps in applying prior theories to LLMs are identified, such as the models tendency to provide direct answers instead of fostering co-construction of knowledge, and the need to account for the constant availability and broad but non-human expertise of LLM tutors. In response, we propose practical strategies to better align LLM interactions with sound pedagogy - for example, designing prompts that encourage Socratic questioning, scaffolded guidance, and student reflection, as well as integrating retrieval mechanisms to ensure accuracy and contextual relevance. Our aim is to bridge the gap between educational theory and the emerging practice of AI-driven conversational learning, offering insights and tools for making LLM-based dialogues more educationally productive and theory-aligned.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19484",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Private Hub: A New Way to Build With Machine Learning",
    "description": "",
    "summary": "Introducing the Private Hub: A New Way to Build With Machine Learning June 2023 Update: The Private ...",
    "pubDate": "Wed, 03 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introducing-private-hub",
    "thumbnail": "https://huggingface.co/blog/assets/92_introducing_private_hub/thumbnail.png"
  },
  {
    "title": "Personalizing travel at scale with OpenAI",
    "description": "By integrating its data systems with OpenAI‚Äôs LLMs, Booking.com delivers smarter search, faster support, and intent-driven travel experiences.",
    "summary": "By integrating its data systems with OpenAI‚Äôs LLMs, Booking.com delivers smarter search, faster support, and intent-driven travel experiences.",
    "pubDate": "Thu, 20 Mar 2025 23:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/booking-com",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Concept-Level AI for Telecom: Moving Beyond Large Language Models",
    "description": "arXiv:2506.22359v1 Announce Type: cross Abstract: The telecommunications and networking domain stands at the precipice of a transformative era, driven by the necessity to manage increasingly complex, hierarchical, multi administrative domains (i.e., several operators on the same path) and multilingual systems. Recent research has demonstrated that Large Language Models (LLMs), with their exceptional general-purpose text analysis and code generation capabilities, can be effectively applied to certain telecom problems (e.g., auto-configuration of data plan to meet certain application requirements). However, due to their inherent token-by-token processing and limited capacity for maintaining extended context, LLMs struggle to fulfill telecom-specific requirements such as cross-layer dependency cascades (i.e., over OSI), temporal-spatial fault correlation, and real-time distributed coordination. In contrast, Large Concept Models (LCMs), which reason at the abstraction level of semantic concepts rather than individual lexical tokens, offer a fundamentally superior approach for addressing these telecom challenges. By employing hyperbolic latent spaces for hierarchical representation and encapsulating complex multi-layered network interactions within concise concept embeddings, LCMs overcome critical shortcomings of LLMs in terms of memory efficiency, cross-layer correlation, and native multimodal integration. This paper argues that adopting LCMs is not simply an incremental step, but a necessary evolutionary leap toward achieving robust and effective AI-driven telecom management.",
    "summary": "arXiv:2506.22359v1 Announce Type: cross Abstract: The telecommunications and networking domain stands at the precipice of a transformative era, driven by the necessity to manage increasingly complex, hierarchical, multi administrative domains (i.e., several operators on the same path) and multilingual systems. Recent research has demonstrated that Large Language Models (LLMs), with their exceptional general-purpose text analysis and code generation capabilities, can be effectively applied to certain telecom problems (e.g., auto-configuration of data plan to meet certain application requirements). However, due to their inherent token-by-token processing and limited capacity for maintaining extended context, LLMs struggle to fulfill telecom-specific requirements such as cross-layer dependency cascades (i.e., over OSI), temporal-spatial fault correlation, and real-time distributed coordination. In contrast, Large Concept Models (LCMs), which reason at the abstraction level of semantic concepts rather than individual lexical tokens, offer a fundamentally superior approach for addressing these telecom challenges. By employing hyperbolic latent spaces for hierarchical representation and encapsulating complex multi-layered network interactions within concise concept embeddings, LCMs overcome critical shortcomings of LLMs in terms of memory efficiency, cross-layer correlation, and native multimodal integration. This paper argues that adopting LCMs is not simply an incremental step, but a necessary evolutionary leap toward achieving robust and effective AI-driven telecom management.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22359",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Spotting Out-of-Character Behavior: Atomic-Level Evaluation of Persona Fidelity in Open-Ended Generation",
    "description": "arXiv:2506.19352v1 Announce Type: cross Abstract: Ensuring persona fidelity in large language models (LLMs) is essential for maintaining coherent and engaging human-AI interactions. However, LLMs often exhibit Out-of-Character (OOC) behavior, where generated responses deviate from an assigned persona, leading to inconsistencies that affect model reliability. Existing evaluation methods typically assign single scores to entire responses, struggling to capture subtle persona misalignment, particularly in long-form text generation. To address this limitation, we propose an atomic-level evaluation framework that quantifies persona fidelity at a finer granularity. Our three key metrics measure the degree of persona alignment and consistency within and across generations. Our approach enables a more precise and realistic assessment of persona fidelity by identifying subtle deviations that real users would encounter. Through our experiments, we demonstrate that our framework effectively detects persona inconsistencies that prior methods overlook. By analyzing persona fidelity across diverse tasks and personality types, we reveal how task structure and persona desirability influence model adaptability, highlighting challenges in maintaining consistent persona expression.",
    "summary": "arXiv:2506.19352v1 Announce Type: cross Abstract: Ensuring persona fidelity in large language models (LLMs) is essential for maintaining coherent and engaging human-AI interactions. However, LLMs often exhibit Out-of-Character (OOC) behavior, where generated responses deviate from an assigned persona, leading to inconsistencies that affect model reliability. Existing evaluation methods typically assign single scores to entire responses, struggling to capture subtle persona misalignment, particularly in long-form text generation. To address this limitation, we propose an atomic-level evaluation framework that quantifies persona fidelity at a finer granularity. Our three key metrics measure the degree of persona alignment and consistency within and across generations. Our approach enables a more precise and realistic assessment of persona fidelity by identifying subtle deviations that real users would encounter. Through our experiments, we demonstrate that our framework effectively detects persona inconsistencies that prior methods overlook. By analyzing persona fidelity across diverse tasks and personality types, we reveal how task structure and persona desirability influence model adaptability, highlighting challenges in maintaining consistent persona expression.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19352",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reliable Few-shot Learning under Dual Noises",
    "description": "arXiv:2506.16330v1 Announce Type: cross Abstract: Recent advances in model pre-training give rise to task adaptation-based few-shot learning (FSL), where the goal is to adapt a pre-trained task-agnostic model for capturing task-specific knowledge with a few-labeled support samples of the target task.Nevertheless, existing approaches may still fail in the open world due to the inevitable in-distribution (ID) and out-of-distribution (OOD) noise from both support and query samples of the target task. With limited support samples available, i) the adverse effect of the dual noises can be severely amplified during task adaptation, and ii) the adapted model can produce unreliable predictions on query samples in the presence of the dual noises. In this work, we propose DEnoised Task Adaptation (DETA++) for reliable FSL. DETA++ uses a Contrastive Relevance Aggregation (CoRA) module to calculate image and region weights for support samples, based on which a clean prototype loss and a noise entropy maximization loss are proposed to achieve noise-robust task adaptation. Additionally,DETA++ employs a memory bank to store and refine clean regions for each inner-task class, based on which a Local Nearest Centroid Classifier (LocalNCC) is devised to yield noise-robust predictions on query samples. Moreover, DETA++ utilizes an Intra-class Region Swapping (IntraSwap) strategy to rectify ID class prototypes during task adaptation, enhancing the model's robustness to the dual noises. Extensive experiments demonstrate the effectiveness and flexibility of DETA++.",
    "summary": "arXiv:2506.16330v1 Announce Type: cross Abstract: Recent advances in model pre-training give rise to task adaptation-based few-shot learning (FSL), where the goal is to adapt a pre-trained task-agnostic model for capturing task-specific knowledge with a few-labeled support samples of the target task.Nevertheless, existing approaches may still fail in the open world due to the inevitable in-distribution (ID) and out-of-distribution (OOD) noise from both support and query samples of the target task. With limited support samples available, i) the adverse effect of the dual noises can be severely amplified during task adaptation, and ii) the adapted model can produce unreliable predictions on query samples in the presence of the dual noises. In this work, we propose DEnoised Task Adaptation (DETA++) for reliable FSL. DETA++ uses a Contrastive Relevance Aggregation (CoRA) module to calculate image and region weights for support samples, based on which a clean prototype loss and a noise entropy maximization loss are proposed to achieve noise-robust task adaptation. Additionally,DETA++ employs a memory bank to store and refine clean regions for each inner-task class, based on which a Local Nearest Centroid Classifier (LocalNCC) is devised to yield noise-robust predictions on query samples. Moreover, DETA++ utilizes an Intra-class Region Swapping (IntraSwap) strategy to rectify ID class prototypes during task adaptation, enhancing the model's robustness to the dual noises. Extensive experiments demonstrate the effectiveness and flexibility of DETA++.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16330",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Neural Cellular Automata for ARC-AGI",
    "description": "arXiv:2506.15746v1 Announce Type: cross Abstract: Cellular automata and their differentiable counterparts, Neural Cellular Automata (NCA), are highly expressive and capable of surprisingly complex behaviors. This paper explores how NCAs perform when applied to tasks requiring precise transformations and few-shot generalization, using the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) as a domain that challenges their capabilities in ways not previously explored. Specifically, this paper uses gradient-based training to learn iterative update rules that transform input grids into their outputs from the training examples and apply them to the test inputs. Results suggest that gradient-trained NCA models are a promising and efficient approach to a range of abstract grid-based tasks from ARC. Along with discussing the impacts of various design modifications and training constraints, this work examines the behavior and properties of NCAs applied to ARC to give insights for broader applications of self-organizing systems.",
    "summary": "arXiv:2506.15746v1 Announce Type: cross Abstract: Cellular automata and their differentiable counterparts, Neural Cellular Automata (NCA), are highly expressive and capable of surprisingly complex behaviors. This paper explores how NCAs perform when applied to tasks requiring precise transformations and few-shot generalization, using the Abstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI) as a domain that challenges their capabilities in ways not previously explored. Specifically, this paper uses gradient-based training to learn iterative update rules that transform input grids into their outputs from the training examples and apply them to the test inputs. Results suggest that gradient-trained NCA models are a promising and efficient approach to a range of abstract grid-based tasks from ARC. Along with discussing the impacts of various design modifications and training constraints, this work examines the behavior and properties of NCAs applied to ARC to give insights for broader applications of self-organizing systems.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15746",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AssistantX: An LLM-Powered Proactive Assistant in Collaborative Human-Populated Environment",
    "description": "arXiv:2409.17655v3 Announce Type: replace-cross Abstract: Current service robots suffer from limited natural language communication abilities, heavy reliance on predefined commands, ongoing human intervention, and, most notably, a lack of proactive collaboration awareness in human-populated environments. This results in narrow applicability and low utility. In this paper, we introduce AssistantX, an LLM-powered proactive assistant designed for autonomous operation in realworld scenarios with high accuracy. AssistantX employs a multi-agent framework consisting of 4 specialized LLM agents, each dedicated to perception, planning, decision-making, and reflective review, facilitating advanced inference capabilities and comprehensive collaboration awareness, much like a human assistant by your side. We built a dataset of 210 real-world tasks to validate AssistantX, which includes instruction content and status information on whether relevant personnel are available. Extensive experiments were conducted in both text-based simulations and a real office environment over the course of a month and a half. Our experiments demonstrate the effectiveness of the proposed framework, showing that AssistantX can reactively respond to user instructions, actively adjust strategies to adapt to contingencies, and proactively seek assistance from humans to ensure successful task completion. More details and videos can be found at https://assistantx-agent.github.io/AssistantX/.",
    "summary": "arXiv:2409.17655v3 Announce Type: replace-cross Abstract: Current service robots suffer from limited natural language communication abilities, heavy reliance on predefined commands, ongoing human intervention, and, most notably, a lack of proactive collaboration awareness in human-populated environments. This results in narrow applicability and low utility. In this paper, we introduce AssistantX, an LLM-powered proactive assistant designed for autonomous operation in realworld scenarios with high accuracy. AssistantX employs a multi-agent framework consisting of 4 specialized LLM agents, each dedicated to perception, planning, decision-making, and reflective review, facilitating advanced inference capabilities and comprehensive collaboration awareness, much like a human assistant by your side. We built a dataset of 210 real-world tasks to validate AssistantX, which includes instruction content and status information on whether relevant personnel are available. Extensive experiments were conducted in both text-based simulations and a real office environment over the course of a month and a half. Our experiments demonstrate the effectiveness of the proposed framework, showing that AssistantX can reactively respond to user instructions, actively adjust strategies to adapt to contingencies, and proactively seek assistance from humans to ensure successful task completion. More details and videos can be found at https://assistantx-agent.github.io/AssistantX/.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.17655",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Enhancing Generalization of Spiking Neural Networks Through Temporal Regularization",
    "description": "arXiv:2506.19256v1 Announce Type: cross Abstract: Spiking Neural Networks (SNNs) have received widespread attention due to their event-driven and low-power characteristics, making them particularly effective for processing event-based neuromorphic data. Recent studies have shown that directly trained SNNs suffer from severe overfitting issues due to the limited scale of neuromorphic datasets and the gradient mismatching problem, which fundamentally constrain their generalization performance. In this paper, we propose a temporal regularization training (TRT) method by introducing a time-dependent regularization mechanism to enforce stronger constraints on early timesteps. We compare the performance of TRT with other state-of-the-art methods performance on datasets including CIFAR10/100, ImageNet100, DVS-CIFAR10, and N-Caltech101. To validate the effectiveness of TRT, we conducted ablation studies and analyses including loss landscape visualization and learning curve analysis, demonstrating that TRT can effectively mitigate overfitting and flatten the training loss landscape, thereby enhancing generalizability. Furthermore, we establish a theoretical interpretation of TRT's temporal regularization mechanism based on the results of Fisher information analysis. We analyze the temporal information dynamics inside SNNs by tracking Fisher information during the TRT training process, revealing the Temporal Information Concentration (TIC) phenomenon, where Fisher information progressively concentrates in early timesteps. The time-decaying regularization mechanism implemented in TRT effectively guides the network to learn robust features in early timesteps with rich information, thereby leading to significant improvements in model generalization. Code is available at https://github.com/ZBX05/Temporal-Regularization-Training.",
    "summary": "arXiv:2506.19256v1 Announce Type: cross Abstract: Spiking Neural Networks (SNNs) have received widespread attention due to their event-driven and low-power characteristics, making them particularly effective for processing event-based neuromorphic data. Recent studies have shown that directly trained SNNs suffer from severe overfitting issues due to the limited scale of neuromorphic datasets and the gradient mismatching problem, which fundamentally constrain their generalization performance. In this paper, we propose a temporal regularization training (TRT) method by introducing a time-dependent regularization mechanism to enforce stronger constraints on early timesteps. We compare the performance of TRT with other state-of-the-art methods performance on datasets including CIFAR10/100, ImageNet100, DVS-CIFAR10, and N-Caltech101. To validate the effectiveness of TRT, we conducted ablation studies and analyses including loss landscape visualization and learning curve analysis, demonstrating that TRT can effectively mitigate overfitting and flatten the training loss landscape, thereby enhancing generalizability. Furthermore, we establish a theoretical interpretation of TRT's temporal regularization mechanism based on the results of Fisher information analysis. We analyze the temporal information dynamics inside SNNs by tracking Fisher information during the TRT training process, revealing the Temporal Information Concentration (TIC) phenomenon, where Fisher information progressively concentrates in early timesteps. The time-decaying regularization mechanism implemented in TRT effectively guides the network to learn robust features in early timesteps with rich information, thereby leading to significant improvements in model generalization. Code is available at https://github.com/ZBX05/Temporal-Regularization-Training.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19256",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Benchmarking Text Generation Inference",
    "description": "",
    "summary": "Benchmarking Text Generation Inference In this blog we will be exploring Text Generation Inference‚Äôs...",
    "pubDate": "Wed, 29 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-benchmarking",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-benchmarking/tgi-benchmarking-thumbnail.png"
  },
  {
    "title": "Breaking the Compression Ceiling: Data-Free Pipeline for Ultra-Efficient Delta Compression",
    "description": "arXiv:2505.13563v2 Announce Type: replace-cross Abstract: With the rise of the fine-tuned--pretrained paradigm, storing numerous fine-tuned models for multi-tasking creates significant storage overhead. Delta compression alleviates this by storing only the pretrained model and the highly compressed delta weights (the differences between fine-tuned and pretrained model weights). However, existing methods fail to maintain both high compression and performance, and often rely on data. To address these challenges, we propose UltraDelta, the first data-free delta compression pipeline that achieves both ultra-high compression and strong performance. UltraDelta is designed to minimize redundancy, maximize information, and stabilize performance across inter-layer, intra-layer, and global dimensions, using three key components: (1) Variance-Based Mixed Sparsity Allocation assigns sparsity based on variance, giving lower sparsity to high-variance layers to preserve inter-layer information. (2) Distribution-Aware Compression applies uniform quantization and then groups parameters by value, followed by group-wise pruning, to better preserve intra-layer distribution. (3) Trace-Norm-Guided Rescaling uses the trace norm of delta weights to estimate a global rescaling factor, improving model stability under higher compression. Extensive experiments across (a) large language models (fine-tuned on LLaMA-2 7B and 13B) with up to 133x, (b) general NLP models (RoBERTa-base, T5-base) with up to 800x, (c) vision models (ViT-B/32, ViT-L/14) with up to 400x, and (d) multi-modal models (BEiT-3) with 40x compression ratio, demonstrate that UltraDelta consistently outperforms existing methods, especially under ultra-high compression.",
    "summary": "arXiv:2505.13563v2 Announce Type: replace-cross Abstract: With the rise of the fine-tuned--pretrained paradigm, storing numerous fine-tuned models for multi-tasking creates significant storage overhead. Delta compression alleviates this by storing only the pretrained model and the highly compressed delta weights (the differences between fine-tuned and pretrained model weights). However, existing methods fail to maintain both high compression and performance, and often rely on data. To address these challenges, we propose UltraDelta, the first data-free delta compression pipeline that achieves both ultra-high compression and strong performance. UltraDelta is designed to minimize redundancy, maximize information, and stabilize performance across inter-layer, intra-layer, and global dimensions, using three key components: (1) Variance-Based Mixed Sparsity Allocation assigns sparsity based on variance, giving lower sparsity to high-variance layers to preserve inter-layer information. (2) Distribution-Aware Compression applies uniform quantization and then groups parameters by value, followed by group-wise pruning, to better preserve intra-layer distribution. (3) Trace-Norm-Guided Rescaling uses the trace norm of delta weights to estimate a global rescaling factor, improving model stability under higher compression. Extensive experiments across (a) large language models (fine-tuned on LLaMA-2 7B and 13B) with up to 133x, (b) general NLP models (RoBERTa-base, T5-base) with up to 800x, (c) vision models (ViT-B/32, ViT-L/14) with up to 400x, and (d) multi-modal models (BEiT-3) with 40x compression ratio, demonstrate that UltraDelta consistently outperforms existing methods, especially under ultra-high compression.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.13563",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset",
    "description": "",
    "summary": "From screenshots to HTML code: Introducing the WebSight dataset In the world of web development, tur...",
    "pubDate": "Fri, 15 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/websight",
    "thumbnail": "https://huggingface.co/blog/assets/websight/thumbnail.png"
  },
  {
    "title": "Special projects",
    "description": "Impactful scientific work requires working on the right problems‚Äîproblems which are not just interesting, but whose solutions matter.",
    "summary": "Impactful scientific work requires working on the right problems‚Äîproblems which are not just interesting, but whose solutions matter.",
    "pubDate": "Thu, 28 Jul 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/special-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Parquet Dedupe on Hugging Face Hub",
    "description": "",
    "summary": "Improving Parquet Dedupe on Hugging Face Hub The Xet team at Hugging Face is working on improving th...",
    "pubDate": "Sat, 05 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/improve_parquet_dedupe",
    "thumbnail": "https://huggingface.co/blog/assets/improve_parquet_dedupe/thumbnail.png"
  },
  {
    "title": "Revisiting Multi-Agent Debate as Test-Time Scaling: A Systematic Study of Conditional Effectiveness",
    "description": "arXiv:2505.22960v2 Announce Type: replace Abstract: The remarkable growth in large language model (LLM) capabilities has spurred exploration into multi-agent systems, with debate frameworks emerging as a promising avenue for enhanced problem-solving. These multi-agent debate (MAD) approaches, where agents collaboratively present, critique, and refine arguments, potentially offer improved reasoning, robustness, and diverse perspectives over monolithic models. Despite prior studies leveraging MAD, a systematic understanding of its effectiveness compared to self-agent methods, particularly under varying conditions, remains elusive. This paper seeks to fill this gap by conceptualizing MAD as a test-time computational scaling technique, distinguished by collaborative refinement and diverse exploration capabilities. We conduct a comprehensive empirical investigation comparing MAD with strong self-agent test-time scaling baselines on mathematical reasoning and safety-related tasks. Our study systematically examines the influence of task difficulty, model scale, and agent diversity on MAD's performance. Key findings reveal that, for mathematical reasoning, MAD offers limited advantages over self-agent scaling but becomes more effective with increased problem difficulty and decreased model capability, while agent diversity shows little benefit. Conversely, for safety tasks, MAD's collaborative refinement can increase vulnerability, but incorporating diverse agent configurations facilitates a gradual reduction in attack success through the collaborative refinement process. We believe our findings provide critical guidance for the future development of more effective and strategically deployed MAD systems.",
    "summary": "arXiv:2505.22960v2 Announce Type: replace Abstract: The remarkable growth in large language model (LLM) capabilities has spurred exploration into multi-agent systems, with debate frameworks emerging as a promising avenue for enhanced problem-solving. These multi-agent debate (MAD) approaches, where agents collaboratively present, critique, and refine arguments, potentially offer improved reasoning, robustness, and diverse perspectives over monolithic models. Despite prior studies leveraging MAD, a systematic understanding of its effectiveness compared to self-agent methods, particularly under varying conditions, remains elusive. This paper seeks to fill this gap by conceptualizing MAD as a test-time computational scaling technique, distinguished by collaborative refinement and diverse exploration capabilities. We conduct a comprehensive empirical investigation comparing MAD with strong self-agent test-time scaling baselines on mathematical reasoning and safety-related tasks. Our study systematically examines the influence of task difficulty, model scale, and agent diversity on MAD's performance. Key findings reveal that, for mathematical reasoning, MAD offers limited advantages over self-agent scaling but becomes more effective with increased problem difficulty and decreased model capability, while agent diversity shows little benefit. Conversely, for safety tasks, MAD's collaborative refinement can increase vulnerability, but incorporating diverse agent configurations facilitates a gradual reduction in attack success through the collaborative refinement process. We believe our findings provide critical guidance for the future development of more effective and strategically deployed MAD systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.22960",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Expands Leadership with Fidji Simo",
    "description": "Read the message Sam shared with the company earlier today.",
    "summary": "Read the message Sam shared with the company earlier today.",
    "pubDate": "Wed, 07 May 2025 21:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/leadership-expansion-with-fidji-simo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MIST: Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning",
    "description": "arXiv:2506.16792v1 Announce Type: cross Abstract: Despite efforts to align large language models (LLMs) with societal and moral values, these models remain susceptible to jailbreak attacks--methods designed to elicit harmful responses. Jailbreaking black-box LLMs is considered challenging due to the discrete nature of token inputs, restricted access to the target LLM, and limited query budget. To address the issues above, we propose an effective method for jailbreaking black-box large language Models via Iterative Semantic Tuning, named MIST. MIST enables attackers to iteratively refine prompts that preserve the original semantic intent while inducing harmful content. Specifically, to balance semantic similarity with computational efficiency, MIST incorporates two key strategies: sequential synonym search, and its advanced version--order-determining optimization. Extensive experiments across two open-source models and four closed-source models demonstrate that MIST achieves competitive attack success rates and attack transferability compared with other state-of-the-art white-box and black-box jailbreak methods. Additionally, we conduct experiments on computational efficiency to validate the practical viability of MIST.",
    "summary": "arXiv:2506.16792v1 Announce Type: cross Abstract: Despite efforts to align large language models (LLMs) with societal and moral values, these models remain susceptible to jailbreak attacks--methods designed to elicit harmful responses. Jailbreaking black-box LLMs is considered challenging due to the discrete nature of token inputs, restricted access to the target LLM, and limited query budget. To address the issues above, we propose an effective method for jailbreaking black-box large language Models via Iterative Semantic Tuning, named MIST. MIST enables attackers to iteratively refine prompts that preserve the original semantic intent while inducing harmful content. Specifically, to balance semantic similarity with computational efficiency, MIST incorporates two key strategies: sequential synonym search, and its advanced version--order-determining optimization. Extensive experiments across two open-source models and four closed-source models demonstrate that MIST achieves competitive attack success rates and attack transferability compared with other state-of-the-art white-box and black-box jailbreak methods. Additionally, we conduct experiments on computational efficiency to validate the practical viability of MIST.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16792",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Hugging Face Embedding Container for Amazon SageMaker",
    "description": "",
    "summary": "Introducing the Hugging Face Embedding Container for Amazon SageMaker We are excited to announce tha...",
    "pubDate": "Fri, 07 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-huggingface-embedding",
    "thumbnail": "https://huggingface.co/blog/assets/sagemaker-huggingface-embedding/thumbnail.jpg"
  },
  {
    "title": "Disentangling Reasoning and Knowledge in Medical Large Language Models",
    "description": "arXiv:2505.11462v2 Announce Type: replace-cross Abstract: Medical reasoning in large language models (LLMs) aims to emulate clinicians' diagnostic thinking, but current benchmarks such as MedQA-USMLE, MedMCQA, and PubMedQA often mix reasoning with factual recall. We address this by separating 11 biomedical QA benchmarks into reasoning- and knowledge-focused subsets using a PubMedBERT classifier that reaches 81 percent accuracy, comparable to human performance. Our analysis shows that only 32.8 percent of questions require complex reasoning. We evaluate biomedical models (HuatuoGPT-o1, MedReason, m1) and general-domain models (DeepSeek-R1, o4-mini, Qwen3), finding consistent gaps between knowledge and reasoning performance. For example, HuatuoGPT-o1 scores 56.9 on knowledge but only 44.8 on reasoning. In adversarial tests where models are misled with incorrect initial reasoning, biomedical models degrade sharply, while larger or RL-trained general models show more robustness. To address this, we train BioMed-R1 using fine-tuning and reinforcement learning on reasoning-heavy examples. It achieves the strongest performance among similarly sized models. Further gains may come from incorporating clinical case reports and training with adversarial and backtracking scenarios.",
    "summary": "arXiv:2505.11462v2 Announce Type: replace-cross Abstract: Medical reasoning in large language models (LLMs) aims to emulate clinicians' diagnostic thinking, but current benchmarks such as MedQA-USMLE, MedMCQA, and PubMedQA often mix reasoning with factual recall. We address this by separating 11 biomedical QA benchmarks into reasoning- and knowledge-focused subsets using a PubMedBERT classifier that reaches 81 percent accuracy, comparable to human performance. Our analysis shows that only 32.8 percent of questions require complex reasoning. We evaluate biomedical models (HuatuoGPT-o1, MedReason, m1) and general-domain models (DeepSeek-R1, o4-mini, Qwen3), finding consistent gaps between knowledge and reasoning performance. For example, HuatuoGPT-o1 scores 56.9 on knowledge but only 44.8 on reasoning. In adversarial tests where models are misled with incorrect initial reasoning, biomedical models degrade sharply, while larger or RL-trained general models show more robustness. To address this, we train BioMed-R1 using fine-tuning and reinforcement learning on reasoning-heavy examples. It achieves the strongest performance among similarly sized models. Further gains may come from incorporating clinical case reports and training with adversarial and backtracking scenarios.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.11462",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Training and Finetuning Reranker Models with Sentence Transformers v4",
    "description": "",
    "summary": "Training and Finetuning Reranker Models with Sentence Transformers v4 Sentence Transformers is a Pyt...",
    "pubDate": "Wed, 26 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/train-reranker",
    "thumbnail": "https://huggingface.co/blog/assets/train-sentence-transformers/st-hf-thumbnail.png"
  },
  {
    "title": "Unlocking Insights Addressing Alcohol Inference Mismatch through Database-Narrative Alignment",
    "description": "arXiv:2506.19342v1 Announce Type: cross Abstract: Road traffic crashes are a significant global cause of fatalities, emphasizing the urgent need for accurate crash data to enhance prevention strategies and inform policy development. This study addresses the challenge of alcohol inference mismatch (AIM) by employing database narrative alignment to identify AIM in crash data. A framework was developed to improve data quality in crash management systems and reduce the percentage of AIM crashes. Utilizing the BERT model, the analysis of 371,062 crash records from Iowa (2016-2022) revealed 2,767 AIM incidents, resulting in an overall AIM percentage of 24.03%. Statistical tools, including the Probit Logit model, were used to explore the crash characteristics affecting AIM patterns. The findings indicate that alcohol-related fatal crashes and nighttime incidents have a lower percentage of the mismatch, while crashes involving unknown vehicle types and older drivers are more susceptible to mismatch. The geospatial cluster as part of this study can identify the regions which have an increased need for education and training. These insights highlight the necessity for targeted training programs and data management teams to improve the accuracy of crash reporting and support evidence-based policymaking.",
    "summary": "arXiv:2506.19342v1 Announce Type: cross Abstract: Road traffic crashes are a significant global cause of fatalities, emphasizing the urgent need for accurate crash data to enhance prevention strategies and inform policy development. This study addresses the challenge of alcohol inference mismatch (AIM) by employing database narrative alignment to identify AIM in crash data. A framework was developed to improve data quality in crash management systems and reduce the percentage of AIM crashes. Utilizing the BERT model, the analysis of 371,062 crash records from Iowa (2016-2022) revealed 2,767 AIM incidents, resulting in an overall AIM percentage of 24.03%. Statistical tools, including the Probit Logit model, were used to explore the crash characteristics affecting AIM patterns. The findings indicate that alcohol-related fatal crashes and nighttime incidents have a lower percentage of the mismatch, while crashes involving unknown vehicle types and older drivers are more susceptible to mismatch. The geospatial cluster as part of this study can identify the regions which have an increased need for education and training. These insights highlight the necessity for targeted training programs and data management teams to improve the accuracy of crash reporting and support evidence-based policymaking.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19342",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The MIT-Portugal Program enters Phase 4",
    "description": "New phase will support continued exploration of ideas and solutions in fields ranging from AI to nanotech to climate ‚Äî with emphasis on educational exchanges and entrepreneurship.",
    "summary": "New phase will support continued exploration of ideas and solutions in fields ranging from AI to nanotech to climate ‚Äî with emphasis on educational exchanges and entrepreneurship.",
    "pubDate": "Wed, 30 Apr 2025 16:20:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-portugal-program-enters-phase-4-0430",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/mit-portugal-2024-Conference.jpg"
  },
  {
    "title": "OpenAI Board Forms Safety and Security Committee",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 28 May 2024 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-board-forms-safety-and-security-committee",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "XetHub is joining Hugging Face!",
    "description": "",
    "summary": "XetHub is joining Hugging Face! We are super excited to officially announce that Hugging Face acquir...",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/xethub-joins-hf",
    "thumbnail": "https://huggingface.co/blog/assets/xethub-joins-hf/thumbnail.png"
  },
  {
    "title": "Introducing W√ºrstchen: Fast Diffusion for Image Generation",
    "description": "",
    "summary": "Introducing W√ºrstchen: Fast Diffusion for Image Generation What is W√ºrstchen? W√ºrstchen is a diffusi...",
    "pubDate": "Wed, 13 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/wuerstchen",
    "thumbnail": "https://huggingface.co/blog/assets/wuerstchen/thumbnail.jpg"
  },
  {
    "title": "Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search",
    "description": "arXiv:2503.04412v3 Announce Type: replace Abstract: Recent advances demonstrate that increasing inference-time computation can significantly boost the reasoning capabilities of large language models (LLMs). Although repeated sampling (i.e., generating multiple candidate outputs) is a highly effective strategy, it does not leverage external feedback signals for refinement, which are often available in tasks like coding. In this work, we propose Adaptive Branching Monte Carlo Tree Search (AB-MCTS), a novel inference-time framework that generalizes repeated sampling with principled multi-turn exploration and exploitation. At each node in the search tree, AB-MCTS dynamically decides whether to 'go wider' by expanding new candidate responses or 'go deeper' by revisiting existing ones based on external feedback signals. We evaluate our method on complex coding and engineering tasks using frontier models. Empirical results show that AB-MCTS consistently outperforms both repeated sampling and standard MCTS, underscoring the importance of combining the response diversity of LLMs with multi-turn solution refinement for effective inference-time scaling.",
    "summary": "arXiv:2503.04412v3 Announce Type: replace Abstract: Recent advances demonstrate that increasing inference-time computation can significantly boost the reasoning capabilities of large language models (LLMs). Although repeated sampling (i.e., generating multiple candidate outputs) is a highly effective strategy, it does not leverage external feedback signals for refinement, which are often available in tasks like coding. In this work, we propose Adaptive Branching Monte Carlo Tree Search (AB-MCTS), a novel inference-time framework that generalizes repeated sampling with principled multi-turn exploration and exploitation. At each node in the search tree, AB-MCTS dynamically decides whether to 'go wider' by expanding new candidate responses or 'go deeper' by revisiting existing ones based on external feedback signals. We evaluate our method on complex coding and engineering tasks using frontier models. Empirical results show that AB-MCTS consistently outperforms both repeated sampling and standard MCTS, underscoring the importance of combining the response diversity of LLMs with multi-turn solution refinement for effective inference-time scaling.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.04412",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A deep learning and machine learning approach to predict neonatal death in the context of S~ao Paulo",
    "description": "arXiv:2506.16929v1 Announce Type: cross Abstract: Neonatal death is still a concerning reality for underdeveloped and even some developed countries. Worldwide data indicate that 26.693 babies out of 1,000 births die, according to Macro Trades. To reduce this number, early prediction of endangered babies is crucial. Such prediction enables the opportunity to take ample care of the child and mother so that early child death can be avoided. In this context, machine learning was used to determine whether a newborn baby is at risk. To train the predictive model, historical data of 1.4 million newborns was used. Machine learning and deep learning techniques such as logical regression, K-nearest neighbor, random forest classifier, extreme gradient boosting (XGBoost), convolutional neural network, and long short-term memory (LSTM) were implemented using the dataset to identify the most accurate model for predicting neonatal mortality. Among the machine learning algorithms, XGBoost and random forest classifier achieved the best accuracy with 94%, while among the deep learning models, LSTM delivered the highest accuracy with 99%. Therefore, using LSTM appears to be the most suitable approach to predict whether precautionary measures for a child are necessary.",
    "summary": "arXiv:2506.16929v1 Announce Type: cross Abstract: Neonatal death is still a concerning reality for underdeveloped and even some developed countries. Worldwide data indicate that 26.693 babies out of 1,000 births die, according to Macro Trades. To reduce this number, early prediction of endangered babies is crucial. Such prediction enables the opportunity to take ample care of the child and mother so that early child death can be avoided. In this context, machine learning was used to determine whether a newborn baby is at risk. To train the predictive model, historical data of 1.4 million newborns was used. Machine learning and deep learning techniques such as logical regression, K-nearest neighbor, random forest classifier, extreme gradient boosting (XGBoost), convolutional neural network, and long short-term memory (LSTM) were implemented using the dataset to identify the most accurate model for predicting neonatal mortality. Among the machine learning algorithms, XGBoost and random forest classifier achieved the best accuracy with 94%, while among the deep learning models, LSTM delivered the highest accuracy with 99%. Therefore, using LSTM appears to be the most suitable approach to predict whether precautionary measures for a child are necessary.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16929",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "With AI, researchers predict the location of virtually any protein within a human cell",
    "description": "Trained with a joint understanding of protein and cell behavior, the model could help with diagnosing disease and developing new drugs.",
    "summary": "Trained with a joint understanding of protein and cell behavior, the model could help with diagnosing disease and developing new drugs.",
    "pubDate": "Thu, 15 May 2025 10:30:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/researchers-predict-protein-location-within-human-cell-using-ai-0515",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-ProteinLocalization-01-press.jpg"
  },
  {
    "title": "Rewriting SymCrypt in Rust to modernize Microsoft‚Äôs cryptographic library",
    "description": "<p>We're rewriting parts of Microsoft's SymCrypt cryptographic library in Rust to improve memory safety and defend against side-channel attacks, enabling formal verification while maintaining backward compatibility via a Rust-to-C compiler.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/'>Rewriting SymCrypt in Rust to modernize Microsoft‚Äôs cryptographic library¬†</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>We're rewriting parts of Microsoft's SymCrypt cryptographic library in Rust to improve memory safety and defend against side-channel attacks, enabling formal verification while maintaining backward compatibility via a Rust-to-C compiler.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/'>Rewriting SymCrypt in Rust to modernize Microsoft‚Äôs cryptographic library¬†</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Tue, 10 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Rationale engineering generates a compact new tool for gene therapy",
    "description": "Researchers redesign a compact RNA-guided enzyme from bacteria, making it an efficient editor of human DNA.",
    "summary": "Researchers redesign a compact RNA-guided enzyme from bacteria, making it an efficient editor of human DNA.",
    "pubDate": "Wed, 28 May 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/rationale-engineering-generates-compact-new-tool-gene-therapy-0528",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/phylogenetic-tree.jpg"
  },
  {
    "title": "Introducing the Hugging Face LLM Inference Container for Amazon SageMaker",
    "description": "",
    "summary": "Introducing the Hugging Face LLM Inference Container for Amazon SageMaker This is an example on how ...",
    "pubDate": "Wed, 31 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-huggingface-llm",
    "thumbnail": "https://huggingface.co/blog/assets/145_sagemaker-huggingface-llm/thumbnail.jpg"
  },
  {
    "title": "„ÄåÁîüÊàêAI„ÅÆÂ≠¶Áøí„Å´Êõ∏Á±ç„ÇíÁÑ°Êñ≠‰ΩøÁî®„Äç„ÅØÂêàÊ≥ï‚îÄ‚îÄ‚îÄÁ±≥Âú∞Ë£Å„Äå„Éï„Çß„Ç¢„É¶„Éº„Çπ„Äç„ÄÄAnthropic„Å∏„ÅÆË®¥Ë®üÂ∑°„Çä",
    "description": "Á±≥„Çµ„É≥„Éï„É©„É≥„Ç∑„Çπ„Ç≥„ÅÆÈÄ£ÈÇ¶Âú∞Ë£Å„ÅØ6Êúà23Êó•„ÄÅÁ±≥Êñ∞ËààAnthropic„ÅåAI„ÅÆÂ≠¶Áøí„Å´ËëóËÄÖ„ÅÆË®±ÂèØ„Å™„ÅèÊõ∏Á±ç„ÇíÂà©Áî®„Åó„Åü„Åì„Å®„ÅØÁ±≥Ëëó‰ΩúÊ®©Ê≥ï‰∏äÂêàÊ≥ï„Å®„ÅÆÂà§Êñ≠„ÇíÁ§∫„Åó„Åü„ÄÇÂêåÁ§æ„ÅÆË°åÁÇ∫„ÅØ„Äå„Éï„Çß„Ç¢„É¶„Éº„Çπ„ÄçÔºàÂÖ¨Ê≠£Âà©Áî®Ôºâ„Å´ÂΩì„Åü„Çã„Å®„Åó„Åü„ÄÇ",
    "summary": "Á±≥„Çµ„É≥„Éï„É©„É≥„Ç∑„Çπ„Ç≥„ÅÆÈÄ£ÈÇ¶Âú∞Ë£Å„ÅØ6Êúà23Êó•„ÄÅÁ±≥Êñ∞ËààAnthropic„ÅåAI„ÅÆÂ≠¶Áøí„Å´ËëóËÄÖ„ÅÆË®±ÂèØ„Å™„ÅèÊõ∏Á±ç„ÇíÂà©Áî®„Åó„Åü„Åì„Å®„ÅØÁ±≥Ëëó‰ΩúÊ®©Ê≥ï‰∏äÂêàÊ≥ï„Å®„ÅÆÂà§Êñ≠„ÇíÁ§∫„Åó„Åü„ÄÇÂêåÁ§æ„ÅÆË°åÁÇ∫„ÅØ„Äå„Éï„Çß„Ç¢„É¶„Éº„Çπ„ÄçÔºàÂÖ¨Ê≠£Âà©Áî®Ôºâ„Å´ÂΩì„Åü„Çã„Å®„Åó„Åü„ÄÇ",
    "pubDate": "Wed, 25 Jun 2025 14:03:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/25/news082.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/25/cover_news082.jpg"
  },
  {
    "title": "BEADs: Bias Evaluation Across Domains",
    "description": "arXiv:2406.04220v5 Announce Type: replace-cross Abstract: Recent advancements in large language models (LLMs) have significantly improved natural language processing (NLP) applications. However, these models often inherit biases from their training data. While several datasets exist for bias detection, most are limited to one or two NLP tasks, typically classification or evaluation, and lack comprehensive coverage across a broader range of tasks. To address this gap, we introduce the Bias Evaluations Across Domains (BEADs) dataset, designed to support a wide range of NLP tasks, including text classification, token classification, bias quantification, and benign language generation. A key contribution of this work is the gold-standard annotation provided by GPT-4 for scalability, with expert verification to ensure high reliability. BEADs can be used for both fine-tuning models (for classification and generation tasks) and evaluating LLM behavior. Our findings show that BEADs effectively surfaces various biases during model fine-tuning and helps reduce biases in language generation tasks while maintaining output quality. The dataset also highlights prevalent demographic biases in LLMs during evaluation. We release BEADs as a practical resource for detecting and mitigating bias across domains, supporting the development of responsible AI systems. Project: https://vectorinstitute.github.io/BEAD/ Data: https://huggingface.co/datasets/shainar/BEAD",
    "summary": "arXiv:2406.04220v5 Announce Type: replace-cross Abstract: Recent advancements in large language models (LLMs) have significantly improved natural language processing (NLP) applications. However, these models often inherit biases from their training data. While several datasets exist for bias detection, most are limited to one or two NLP tasks, typically classification or evaluation, and lack comprehensive coverage across a broader range of tasks. To address this gap, we introduce the Bias Evaluations Across Domains (BEADs) dataset, designed to support a wide range of NLP tasks, including text classification, token classification, bias quantification, and benign language generation. A key contribution of this work is the gold-standard annotation provided by GPT-4 for scalability, with expert verification to ensure high reliability. BEADs can be used for both fine-tuning models (for classification and generation tasks) and evaluating LLM behavior. Our findings show that BEADs effectively surfaces various biases during model fine-tuning and helps reduce biases in language generation tasks while maintaining output quality. The dataset also highlights prevalent demographic biases in LLMs during evaluation. We release BEADs as a practical resource for detecting and mitigating bias across domains, supporting the development of responsible AI systems. Project: https://vectorinstitute.github.io/BEAD/ Data: https://huggingface.co/datasets/shainar/BEAD",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.04220",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate",
    "description": "",
    "summary": "Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate This article shows how to get an incre...",
    "pubDate": "Fri, 16 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-inference-pytorch-scripts",
    "thumbnail": "https://huggingface.co/blog/assets/bloom-inference-pytorch-scripts/thumbnail.png"
  },
  {
    "title": "The Hugging Face Hub for Galleries, Libraries, Archives and Museums",
    "description": "",
    "summary": "The Hugging Face Hub for Galleries, Libraries, Archives and Museums The Hugging Face Hub for Galleri...",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hf-hub-glam-guide",
    "thumbnail": "https://huggingface.co/blog/assets/144_hf_hub_glam_guide/thumbnail.png"
  },
  {
    "title": "Autonomic Microservice Management via Agentic AI and MAPE-K Integration",
    "description": "arXiv:2506.22185v1 Announce Type: cross Abstract: While microservices are revolutionizing cloud computing by offering unparalleled scalability and independent deployment, their decentralized nature poses significant security and management challenges that can threaten system stability. We propose a framework based on MAPE-K, which leverages agentic AI, for autonomous anomaly detection and remediation to address the daunting task of highly distributed system management. Our framework offers practical, industry-ready solutions for maintaining robust and secure microservices. Practitioners and researchers can customize the framework to enhance system stability, reduce downtime, and monitor broader system quality attributes such as system performance level, resilience, security, and anomaly management, among others.",
    "summary": "arXiv:2506.22185v1 Announce Type: cross Abstract: While microservices are revolutionizing cloud computing by offering unparalleled scalability and independent deployment, their decentralized nature poses significant security and management challenges that can threaten system stability. We propose a framework based on MAPE-K, which leverages agentic AI, for autonomous anomaly detection and remediation to address the daunting task of highly distributed system management. Our framework offers practical, industry-ready solutions for maintaining robust and secure microservices. Practitioners and researchers can customize the framework to enhance system stability, reduce downtime, and monitor broader system quality attributes such as system performance level, resilience, security, and anomaly management, among others.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22185",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Announcing New Dataset Search Features",
    "description": "",
    "summary": "Announcing New Dataset Search Features The AI and ML community has shared more than 180,000 public d...",
    "pubDate": "Mon, 08 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/datasets-filters",
    "thumbnail": "https://huggingface.co/blog/assets/datasets-filters/thumbnail.png"
  },
  {
    "title": "Try new data visualizations and graphs for finance queries in AI Mode.",
    "description": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-600x600.format-webp.webp' />Today, we‚Äôre starting to roll out interactive chart visualizations in AI Mode in Labs to help bring financial data to life for questions on stocks and mutual funds.Now, ‚Ä¶",
    "summary": "<img src='https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-600x600.format-webp.webp' />Today, we‚Äôre starting to roll out interactive chart visualizations in AI Mode in Labs to help bring financial data to life for questions on stocks and mutual funds.Now, ‚Ä¶",
    "pubDate": "Thu, 05 Jun 2025 19:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/search/ai-mode-data-visualization/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/BlueChip_1920x1080.max-1440x810.png"
  },
  {
    "title": "AudioLDM 2, but faster ‚ö°Ô∏è",
    "description": "",
    "summary": "AudioLDM 2, but faster ‚ö°Ô∏è AudioLDM 2 was proposed in AudioLDM 2: Learning Holistic Audio Generation ...",
    "pubDate": "Wed, 30 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/audioldm2",
    "thumbnail": "https://huggingface.co/blog/assets/161_audioldm2/thumbnail.png"
  },
  {
    "title": "MTEB: Massive Text Embedding Benchmark",
    "description": "",
    "summary": "MTEB: Massive Text Embedding Benchmark MTEB is a massive benchmark for measuring the performance of ...",
    "pubDate": "Wed, 19 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mteb",
    "thumbnail": "https://huggingface.co/blog/assets/110_mteb/thumbnail.png"
  },
  {
    "title": "What's new in Diffusers? üé®",
    "description": "",
    "summary": "What's new in Diffusers? üé® A month and a half ago we released diffusers , a library that provides a ...",
    "pubDate": "Mon, 12 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-2nd-month",
    "thumbnail": "https://huggingface.co/blog/assets/102_diffusers_2nd_month/inpainting.png"
  },
  {
    "title": "BatteryBERT for Realistic Battery Fault Detection Using Point-Masked Signal Modeling",
    "description": "arXiv:2506.15712v1 Announce Type: cross Abstract: Accurate fault detection in lithium-ion batteries is essential for the safe and reliable operation of electric vehicles and energy storage systems. However, existing methods often struggle to capture complex temporal dependencies and cannot fully leverage abundant unlabeled data. Although large language models (LLMs) exhibit strong representation capabilities, their architectures are not directly suited to the numerical time-series data common in industrial settings. To address these challenges, we propose a novel framework that adapts BERT-style pretraining for battery fault detection by extending the standard BERT architecture with a customized time-series-to-token representation module and a point-level Masked Signal Modeling (point-MSM) pretraining task tailored to battery applications. This approach enables self-supervised learning on sequential current, voltage, and other charge-discharge cycle data, yielding distributionally robust, context-aware temporal embeddings. We then concatenate these embeddings with battery metadata and feed them into a downstream classifier for accurate fault classification. Experimental results on a large-scale real-world dataset show that models initialized with our pretrained parameters significantly improve both representation quality and classification accuracy, achieving an AUROC of 0.945 and substantially outperforming existing approaches. These findings validate the effectiveness of BERT-style pretraining for time-series fault detection.",
    "summary": "arXiv:2506.15712v1 Announce Type: cross Abstract: Accurate fault detection in lithium-ion batteries is essential for the safe and reliable operation of electric vehicles and energy storage systems. However, existing methods often struggle to capture complex temporal dependencies and cannot fully leverage abundant unlabeled data. Although large language models (LLMs) exhibit strong representation capabilities, their architectures are not directly suited to the numerical time-series data common in industrial settings. To address these challenges, we propose a novel framework that adapts BERT-style pretraining for battery fault detection by extending the standard BERT architecture with a customized time-series-to-token representation module and a point-level Masked Signal Modeling (point-MSM) pretraining task tailored to battery applications. This approach enables self-supervised learning on sequential current, voltage, and other charge-discharge cycle data, yielding distributionally robust, context-aware temporal embeddings. We then concatenate these embeddings with battery metadata and feed them into a downstream classifier for accurate fault classification. Experimental results on a large-scale real-world dataset show that models initialized with our pretrained parameters significantly improve both representation quality and classification accuracy, achieving an AUROC of 0.945 and substantially outperforming existing approaches. These findings validate the effectiveness of BERT-style pretraining for time-series fault detection.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15712",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Proximal Policy Optimization",
    "description": "We‚Äôre releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune. PPO has become the default reinforcement learning algorithm at OpenAI because of its ease of use and good performance.",
    "summary": "We‚Äôre releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune. PPO has become the default reinforcement learning algorithm at OpenAI because of its ease of use and good performance.",
    "pubDate": "Thu, 20 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-baselines-ppo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome spaCy to the ü§ó Hub",
    "description": "",
    "summary": "Welcome spaCy to the Hugging Face Hub spaCy is a popular library for advanced Natural Language Proce...",
    "pubDate": "Tue, 13 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spacy",
    "thumbnail": "https://huggingface.co/blog/assets/23_spacy/thumbnail.png"
  },
  {
    "title": "Introducing RWKV ‚Äî An RNN with the advantages of a transformer",
    "description": "",
    "summary": "Introducing RWKV - An RNN with the advantages of a transformer ChatGPT and chatbot-powered applicati...",
    "pubDate": "Mon, 15 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/rwkv",
    "thumbnail": "https://huggingface.co/blog/assets/142_rwkv/rwkv_thumbnail.png"
  },
  {
    "title": "Variational lossy autoencoder",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 08 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variational-lossy-autoencoder",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ÁîüÊàêAI„ÅÆ„Åì„Åì„ÅåÈõ£„Åó„ÅÑ„ÄÄ„Äå„Éó„É≠„É≥„Éó„ÉàË®≠Ë®à„Äç„ÇíË∂Ö„Åà„Åü1‰Ωç„ÅØÔºü„ÄÄ„Éï„É™„Éº„É©„É≥„Çπ„Å´ËÅû„Åè",
    "description": "„É™„É¢„É©„ÉúÔºàÊù±‰∫¨ÈÉΩÊ∏ãË∞∑Âå∫Ôºâ„Å´„Çà„Çã„Å®„ÄÅ„Éï„É™„Éº„É©„É≥„Çπ„ÅÆ3‰∫∫„Å´1‰∫∫„ÅåÁîüÊàêAI„ÅÆÊúâÊñôÁâà„ÇíÂà©Áî®„Åó„ÄÅAI„ÇíÊú¨Ê†ºÁöÑ„Å™Ê•≠Âãô„ÉÑ„Éº„É´„Å®„Åó„Å¶Âèñ„ÇäÂÖ•„Çå„Å¶„ÅÑ„ÇãÂÆüÊÖã„ÅåÊòé„Çâ„Åã„Å´„Å™„Å£„Åü„ÄÇÂÆüÈöõ„Å´‰Ωø„Å£„Å¶„Åø„Åü„Éï„É™„Éº„É©„É≥„Çπ„Åü„Å°„ÅØ„ÄÅÊúâÊñôÁâà„ÅÆÁîüÊàêAI„Çí„Å©„ÅÆ„Çà„ÅÜ„Å´Ë©ï‰æ°„Åó„Å¶„ÅÑ„Çã„ÅÆ„Åã„ÄÇ„Åæ„Åü„ÄÅ„Å©„ÅÆ„Çà„ÅÜ„Å™„Éù„Ç§„É≥„Éà„Åß„Å§„Åæ„Å•„ÅÑ„Å¶„ÅÑ„Çã„ÅÆ„ÅãÔºü",
    "summary": "„É™„É¢„É©„ÉúÔºàÊù±‰∫¨ÈÉΩÊ∏ãË∞∑Âå∫Ôºâ„Å´„Çà„Çã„Å®„ÄÅ„Éï„É™„Éº„É©„É≥„Çπ„ÅÆ3‰∫∫„Å´1‰∫∫„ÅåÁîüÊàêAI„ÅÆÊúâÊñôÁâà„ÇíÂà©Áî®„Åó„ÄÅAI„ÇíÊú¨Ê†ºÁöÑ„Å™Ê•≠Âãô„ÉÑ„Éº„É´„Å®„Åó„Å¶Âèñ„ÇäÂÖ•„Çå„Å¶„ÅÑ„ÇãÂÆüÊÖã„ÅåÊòé„Çâ„Åã„Å´„Å™„Å£„Åü„ÄÇÂÆüÈöõ„Å´‰Ωø„Å£„Å¶„Åø„Åü„Éï„É™„Éº„É©„É≥„Çπ„Åü„Å°„ÅØ„ÄÅÊúâÊñôÁâà„ÅÆÁîüÊàêAI„Çí„Å©„ÅÆ„Çà„ÅÜ„Å´Ë©ï‰æ°„Åó„Å¶„ÅÑ„Çã„ÅÆ„Åã„ÄÇ„Åæ„Åü„ÄÅ„Å©„ÅÆ„Çà„ÅÜ„Å™„Éù„Ç§„É≥„Éà„Åß„Å§„Åæ„Å•„ÅÑ„Å¶„ÅÑ„Çã„ÅÆ„ÅãÔºü",
    "pubDate": "Wed, 25 Jun 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2506/25/news020.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2506/25/cover_news020.jpg"
  },
  {
    "title": "Thought Anchors: Which LLM Reasoning Steps Matter?",
    "description": "arXiv:2506.19143v1 Announce Type: cross Abstract: Reasoning large language models have recently achieved state-of-the-art performance in many fields. However, their long-form chain-of-thought reasoning creates interpretability challenges as each generated token depends on all previous ones, making the computation harder to decompose. We argue that analyzing reasoning traces at the sentence level is a promising approach to understanding reasoning processes. We present three complementary attribution methods: (1) a black-box method measuring each sentence's counterfactual importance by comparing final answers across 100 rollouts conditioned on the model generating that sentence or one with a different meaning; (2) a white-box method of aggregating attention patterns between pairs of sentences, which identified ``broadcasting'' sentences that receive disproportionate attention from all future sentences via ``receiver'' attention heads; (3) a causal attribution method measuring logical connections between sentences by suppressing attention toward one sentence and measuring the effect on each future sentence's tokens. Each method provides evidence for the existence of thought anchors, reasoning steps that have outsized importance and that disproportionately influence the subsequent reasoning process. These thought anchors are typically planning or backtracking sentences. We provide an open-source tool (www.thought-anchors.com) for visualizing the outputs of our methods, and present a case study showing converging patterns across methods that map how a model performs multi-step reasoning. The consistency across methods demonstrates the potential of sentence-level analysis for a deeper understanding of reasoning models.",
    "summary": "arXiv:2506.19143v1 Announce Type: cross Abstract: Reasoning large language models have recently achieved state-of-the-art performance in many fields. However, their long-form chain-of-thought reasoning creates interpretability challenges as each generated token depends on all previous ones, making the computation harder to decompose. We argue that analyzing reasoning traces at the sentence level is a promising approach to understanding reasoning processes. We present three complementary attribution methods: (1) a black-box method measuring each sentence's counterfactual importance by comparing final answers across 100 rollouts conditioned on the model generating that sentence or one with a different meaning; (2) a white-box method of aggregating attention patterns between pairs of sentences, which identified ``broadcasting'' sentences that receive disproportionate attention from all future sentences via ``receiver'' attention heads; (3) a causal attribution method measuring logical connections between sentences by suppressing attention toward one sentence and measuring the effect on each future sentence's tokens. Each method provides evidence for the existence of thought anchors, reasoning steps that have outsized importance and that disproportionately influence the subsequent reasoning process. These thought anchors are typically planning or backtracking sentences. We provide an open-source tool (www.thought-anchors.com) for visualizing the outputs of our methods, and present a case study showing converging patterns across methods that map how a model performs multi-step reasoning. The consistency across methods demonstrates the potential of sentence-level analysis for a deeper understanding of reasoning models.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19143",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning complex goals with iterated amplification",
    "description": "We‚Äôre proposing an AI safety technique called iterated amplification that lets us specify complicated behaviors and goals that are beyond human scale, by demonstrating how to decompose a task into simpler sub-tasks, rather than by providing labeled data or a reward function. Although this idea is in its very early stages and we have only completed experiments on simple toy algorithmic domains, we‚Äôve decided to present it in its preliminary state because we think it could prove to be a scalable approach to AI¬†safety.",
    "summary": "We‚Äôre proposing an AI safety technique called iterated amplification that lets us specify complicated behaviors and goals that are beyond human scale, by demonstrating how to decompose a task into simpler sub-tasks, rather than by providing labeled data or a reward function. Although this idea is in its very early stages and we have only completed experiments on simple toy algorithmic domains, we‚Äôve decided to present it in its preliminary state because we think it could prove to be a scalable approach to AI¬†safety.",
    "pubDate": "Mon, 22 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-complex-goals-with-iterated-amplification",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Detecting misbehavior in frontier reasoning models",
    "description": "Frontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM to monitor their chains-of-thought. Penalizing their ‚Äúbad thoughts‚Äù doesn‚Äôt stop the majority of misbehavior‚Äîit makes them hide their intent.",
    "summary": "Frontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM to monitor their chains-of-thought. Penalizing their ‚Äúbad thoughts‚Äù doesn‚Äôt stop the majority of misbehavior‚Äîit makes them hide their intent.",
    "pubDate": "Mon, 10 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chain-of-thought-monitoring",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Community Tools on HuggingChat",
    "description": "",
    "summary": "Introducing Community Tools on HuggingChat Today we‚Äôre releasing our latest feature on HuggingChat: ...",
    "pubDate": "Mon, 16 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/community-tools",
    "thumbnail": "https://huggingface.co/blog/assets/community-tools/thumbnail.png"
  },
  {
    "title": "We‚Äôre expanding our Gemini 2.5 family of models",
    "description": "Gemini 2.5 Flash and Pro are now generally available, and we‚Äôre introducing 2.5 Flash-Lite, our most cost-efficient and fastest 2.5 model yet.",
    "summary": "Gemini 2.5 Flash and Pro are now generally available, and we‚Äôre introducing 2.5 Flash-Lite, our most cost-efficient and fastest 2.5 model yet.",
    "pubDate": "Tue, 17 Jun 2025 16:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/were-expanding-our-gemini-25-family-of-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_bundle_keyword_social-share_1920-1080.width-1300.png"
  },
  {
    "title": "Introducing Prodigy-HF: a direct integration with Hugging Face",
    "description": "",
    "summary": "Introducing Prodigy-HF Prodigy is an annotation tool made by Explosion, a company well known as the ...",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/prodigy-hf",
    "thumbnail": "https://huggingface.co/blog/assets/171_prodigy_hf/thumbnail.png"
  },
  {
    "title": "Learning from other domains to advance AI evaluation and testing",
    "description": "<p>As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the [&#8230;]</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/'>Learning from other domains to advance AI evaluation and testing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the [&#8230;]</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/'>Learning from other domains to advance AI evaluation and testing</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Mon, 23 Jun 2025 16:35:06 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Hybrid-NL2SVA: Integrating RAG and Finetuning for LLM-based NL2SVA",
    "description": "arXiv:2506.21569v1 Announce Type: cross Abstract: SystemVerilog Assertions (SVAs) are critical for verifying the correctness of hardware designs, but manually writing them from natural language property descriptions, i.e., NL2SVA, remains a labor-intensive and error-prone task. Recent advances in large language models (LLMs) offer opportunities to automate this translation. However, existing models still struggle with understanding domain-specific syntax and semantics. To enhance LLM performance in NL2SVA, we propose a customized retrieval-augmented generation (RAG) framework and a synthetic fine-tuning dataset that together improve LLM's performance. To further improve lightweight models over NL2SVA, our fine-tuning dataset provides prompt-guided explanations that teach LLMs the layer-by-layer construction process of concurrent SVAs, enabling supervised fine-tuning that greatly improves syntax and functionality accuracy. To evaluate the performance of LLMs over NL2SVA, we construct the largest evaluation dataset for NL2SVA, comprising 40 Verilog designs and 229 formally verified SVAs with detailed annotations. Experimental results show that our customized RAG framework increases the number of functionality matched SVAs by 58.42% over GPT-4o-mini, while Qwen2.5-Coder-7B-Instruct fine-tuned on our fine-tuning dataset and integrated with HybridRetrieval achieves a 59.05% over the base Qwen model.",
    "summary": "arXiv:2506.21569v1 Announce Type: cross Abstract: SystemVerilog Assertions (SVAs) are critical for verifying the correctness of hardware designs, but manually writing them from natural language property descriptions, i.e., NL2SVA, remains a labor-intensive and error-prone task. Recent advances in large language models (LLMs) offer opportunities to automate this translation. However, existing models still struggle with understanding domain-specific syntax and semantics. To enhance LLM performance in NL2SVA, we propose a customized retrieval-augmented generation (RAG) framework and a synthetic fine-tuning dataset that together improve LLM's performance. To further improve lightweight models over NL2SVA, our fine-tuning dataset provides prompt-guided explanations that teach LLMs the layer-by-layer construction process of concurrent SVAs, enabling supervised fine-tuning that greatly improves syntax and functionality accuracy. To evaluate the performance of LLMs over NL2SVA, we construct the largest evaluation dataset for NL2SVA, comprising 40 Verilog designs and 229 formally verified SVAs with detailed annotations. Experimental results show that our customized RAG framework increases the number of functionality matched SVAs by 58.42% over GPT-4o-mini, while Qwen2.5-Coder-7B-Instruct fine-tuned on our fine-tuning dataset and integrated with HybridRetrieval achieves a 59.05% over the base Qwen model.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21569",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Lemmanaid: Neuro-Symbolic Lemma Conjecturing",
    "description": "arXiv:2504.04942v3 Announce Type: replace Abstract: Automatically conjecturing useful, interesting and novel lemmas would greatly improve automated reasoning tools and lower the bar for formalizing mathematics in proof assistants. It is however a very challenging task for both neural and symbolic approaches. We present the first steps towards a practical neuro-symbolic lemma conjecturing tool, Lemmanaid, that combines Large Language Models (LLMs) and symbolic methods, and evaluate it on proof libraries for the Isabelle proof assistant. We train an LLM to generate lemma templates that describe the shape of a lemma, and use symbolic methods to fill in the details. We compare Lemmanaid against an LLM trained to generate complete lemma statements as well as previous fully symbolic conjecturing methods. Lemmanaid outperforms both neural and symbolic methods on test sets from Isabelle's HOL library and from its Archive of Formal Proofs, discovering between 29-39.5% of the gold standard human written lemmas. This is 8-15% more lemmas than the neural-only method. By leveraging the best of both symbolic and neural methods we can generate useful lemmas for a wide range of input domains, facilitating computer-assisted theory development and formalization.",
    "summary": "arXiv:2504.04942v3 Announce Type: replace Abstract: Automatically conjecturing useful, interesting and novel lemmas would greatly improve automated reasoning tools and lower the bar for formalizing mathematics in proof assistants. It is however a very challenging task for both neural and symbolic approaches. We present the first steps towards a practical neuro-symbolic lemma conjecturing tool, Lemmanaid, that combines Large Language Models (LLMs) and symbolic methods, and evaluate it on proof libraries for the Isabelle proof assistant. We train an LLM to generate lemma templates that describe the shape of a lemma, and use symbolic methods to fill in the details. We compare Lemmanaid against an LLM trained to generate complete lemma statements as well as previous fully symbolic conjecturing methods. Lemmanaid outperforms both neural and symbolic methods on test sets from Isabelle's HOL library and from its Archive of Formal Proofs, discovering between 29-39.5% of the gold standard human written lemmas. This is 8-15% more lemmas than the neural-only method. By leveraging the best of both symbolic and neural methods we can generate useful lemmas for a wide range of input domains, facilitating computer-assisted theory development and formalization.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.04942",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI o1 System Card External Testers Acknowledgements",
    "description": "OpenAI o1 system card external testers acknowledgements",
    "summary": "OpenAI o1 system card external testers acknowledgements",
    "pubDate": "Thu, 12 Sep 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-o1-system-card/external-testers-acknowledgements",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bringing the Artificial Analysis LLM Performance Leaderboard to Hugging Face",
    "description": "",
    "summary": "Bringing the Artificial Analysis LLM Performance Leaderboard to Hugging Face Building applications w...",
    "pubDate": "Fri, 03 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-artificial-analysis",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_artificialanalysis.png"
  },
  {
    "title": "Introducing the SWE-Lancer benchmark",
    "description": "Can frontier LLMs earn $1 million from real-world freelance software engineering?",
    "summary": "Can frontier LLMs earn $1 million from real-world freelance software engineering?",
    "pubDate": "Tue, 18 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/swe-lancer",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Scaling up learning across many different robot types",
    "description": "Robots are great specialists, but poor generalists. Typically, you have to train a model for each task, robot, and environment. Changing a single variable often requires starting from scratch. But what if we could combine the knowledge across robotics and create a way to train a general-purpose robot?",
    "summary": "Robots are great specialists, but poor generalists. Typically, you have to train a model for each task, robot, and environment. Changing a single variable often requires starting from scratch. But what if we could combine the knowledge across robotics and create a way to train a general-purpose robot?",
    "pubDate": "Tue, 03 Oct 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/scaling-up-learning-across-many-different-robot-types/",
    "thumbnail": "https://lh3.googleusercontent.com/KiNtKw6sX-3WmNln5pnEZjPMfM7VJLg0qe4VshEj_H_oXCI9hb6iGWl1DPx79WBb4EVds8mq2wUq_n9s2Lk8kkWazPtootwAUYBKxBEp64WTcEmXa6U=w1200-h630-n-nu"
  },
  {
    "title": "Lost in Translation? Converting RegExes for Log Parsing into Dynatrace Pattern Language",
    "description": "arXiv:2506.19539v1 Announce Type: cross Abstract: Log files provide valuable information for detecting and diagnosing problems in enterprise software applications and data centers. Several log analytics tools and platforms were developed to help filter and extract information from logs, typically using regular expressions (RegExes). Recent commercial log analytics platforms provide domain-specific languages specifically designed for log parsing, such as Grok or the Dynatrace Pattern Language (DPL). However, users who want to migrate to these platforms must manually convert their RegExes into the new pattern language, which is costly and error-prone. In this work, we present Reptile, which combines a rule-based approach for converting RegExes into DPL patterns with a best-effort approach for cases where a full conversion is impossible. Furthermore, it integrates GPT-4 to optimize the obtained DPL patterns. The evaluation with 946 RegExes collected from a large company shows that Reptile safely converted 73.7% of them. The evaluation of Reptile's pattern optimization with 23 real-world RegExes showed an F1-score and MCC above 0.91. These results are promising and have ample practical implications for companies that migrate to a modern log analytics platform, such as Dynatrace.",
    "summary": "arXiv:2506.19539v1 Announce Type: cross Abstract: Log files provide valuable information for detecting and diagnosing problems in enterprise software applications and data centers. Several log analytics tools and platforms were developed to help filter and extract information from logs, typically using regular expressions (RegExes). Recent commercial log analytics platforms provide domain-specific languages specifically designed for log parsing, such as Grok or the Dynatrace Pattern Language (DPL). However, users who want to migrate to these platforms must manually convert their RegExes into the new pattern language, which is costly and error-prone. In this work, we present Reptile, which combines a rule-based approach for converting RegExes into DPL patterns with a best-effort approach for cases where a full conversion is impossible. Furthermore, it integrates GPT-4 to optimize the obtained DPL patterns. The evaluation with 946 RegExes collected from a large company shows that Reptile safely converted 73.7% of them. The evaluation of Reptile's pattern optimization with 23 real-world RegExes showed an F1-score and MCC above 0.91. These results are promising and have ample practical implications for companies that migrate to a modern log analytics platform, such as Dynatrace.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19539",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Studying and Improving Graph Neural Network-based Motif Estimation",
    "description": "arXiv:2506.15709v1 Announce Type: cross Abstract: Graph Neural Networks (GNNs) are a predominant method for graph representation learning. However, beyond subgraph frequency estimation, their application to network motif significance-profile (SP) prediction remains under-explored, with no established benchmarks in the literature. We propose to address this problem, framing SP estimation as a task independent of subgraph frequency estimation. Our approach shifts from frequency counting to direct SP estimation and modulates the problem as multitarget regression. The reformulation is optimised for interpretability, stability and scalability on large graphs. We validate our method using a large synthetic dataset and further test it on real-world graphs. Our experiments reveal that 1-WL limited models struggle to make precise estimations of SPs. However, they can generalise to approximate the graph generation processes of networks by comparing their predicted SP with the ones originating from synthetic generators. This first study on GNN-based motif estimation also hints at how using direct SP estimation can help go past the theoretical limitations that motif estimation faces when performed through subgraph counting.",
    "summary": "arXiv:2506.15709v1 Announce Type: cross Abstract: Graph Neural Networks (GNNs) are a predominant method for graph representation learning. However, beyond subgraph frequency estimation, their application to network motif significance-profile (SP) prediction remains under-explored, with no established benchmarks in the literature. We propose to address this problem, framing SP estimation as a task independent of subgraph frequency estimation. Our approach shifts from frequency counting to direct SP estimation and modulates the problem as multitarget regression. The reformulation is optimised for interpretability, stability and scalability on large graphs. We validate our method using a large synthetic dataset and further test it on real-world graphs. Our experiments reveal that 1-WL limited models struggle to make precise estimations of SPs. However, they can generalise to approximate the graph generation processes of networks by comparing their predicted SP with the ones originating from synthetic generators. This first study on GNN-based motif estimation also hints at how using direct SP estimation can help go past the theoretical limitations that motif estimation faces when performed through subgraph counting.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15709",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "üá®üáø BenCzechMark - Can your LLM Understand Czech?",
    "description": "",
    "summary": "üá®üáø BenCzechMark - Can your LLM Understand Czech? The üá®üáø BenCzechMark is the first and most comprehen...",
    "pubDate": "Tue, 01 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/benczechmark",
    "thumbnail": "https://huggingface.co/blog/assets/187_benczechmark/thumbnail.png"
  },
  {
    "title": "OpenAI‚Äôs response to the Department of Energy on AI infrastructure",
    "description": "Why infrastructure is destiny and how the US can seize it.",
    "summary": "Why infrastructure is destiny and how the US can seize it.",
    "pubDate": "Wed, 07 May 2025 18:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-department-of-energy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Digital Gatekeepers: Exploring Large Language Model's Role in Immigration Decisions",
    "description": "arXiv:2506.21574v1 Announce Type: cross Abstract: With globalization and increasing immigrant populations, immigration departments face significant work-loads and the challenge of ensuring fairness in decision-making processes. Integrating artificial intelligence offers a promising solution to these challenges. This study investigates the potential of large language models (LLMs),such as GPT-3.5 and GPT-4, in supporting immigration decision-making. Utilizing a mixed-methods approach,this paper conducted discrete choice experiments and in-depth interviews to study LLM decision-making strategies and whether they are fair. Our findings demonstrate that LLMs can align their decision-making with human strategies, emphasizing utility maximization and procedural fairness. Meanwhile, this paper also reveals that while ChatGPT has safeguards to prevent unintentional discrimination, it still exhibits stereotypes and biases concerning nationality and shows preferences toward privileged group. This dual analysis highlights both the potential and limitations of LLMs in automating and enhancing immigration decisions.",
    "summary": "arXiv:2506.21574v1 Announce Type: cross Abstract: With globalization and increasing immigrant populations, immigration departments face significant work-loads and the challenge of ensuring fairness in decision-making processes. Integrating artificial intelligence offers a promising solution to these challenges. This study investigates the potential of large language models (LLMs),such as GPT-3.5 and GPT-4, in supporting immigration decision-making. Utilizing a mixed-methods approach,this paper conducted discrete choice experiments and in-depth interviews to study LLM decision-making strategies and whether they are fair. Our findings demonstrate that LLMs can align their decision-making with human strategies, emphasizing utility maximization and procedural fairness. Meanwhile, this paper also reveals that while ChatGPT has safeguards to prevent unintentional discrimination, it still exhibits stereotypes and biases concerning nationality and shows preferences toward privileged group. This dual analysis highlights both the potential and limitations of LLMs in automating and enhancing immigration decisions.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21574",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Getting Started with Transformers on Habana Gaudi",
    "description": "",
    "summary": "Getting Started with Transformers on Habana Gaudi A couple of weeks ago, we've had the pleasure to a...",
    "pubDate": "Tue, 26 Apr 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/getting-started-habana",
    "thumbnail": "https://huggingface.co/blog/assets/61_getting_started_habana/habana01.png"
  },
  {
    "title": "Solving complex problems with OpenAI o1 models",
    "description": "In this video, we share how the o1 reasoning models can help in domains like coding, strategy, and research.",
    "summary": "In this video, we share how the o1 reasoning models can help in domains like coding, strategy, and research.",
    "pubDate": "Thu, 17 Oct 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/solving-complex-problems-with-openai-o1-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding the capabilities, limitations, and societal impact of large language models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 04 Feb 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/understanding-the-capabilities-limitations-and-societal-impact-of-large-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interpretable and pedagogical examples",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 02 Nov 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/interpretable-and-pedagogical-examples",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Launching the Artificial Analysis Text to Image Leaderboard & Arena",
    "description": "",
    "summary": "Launching the Artificial Analysis Text to Image Leaderboard & Arena In two short years since the adv...",
    "pubDate": "Thu, 06 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-artificial-analysis2",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_artificialanalysis.png"
  },
  {
    "title": "Improving LLM Outputs Against Jailbreak Attacks with Expert Model Integration",
    "description": "arXiv:2505.17066v2 Announce Type: replace-cross Abstract: Using LLMs in a production environment presents security challenges that include vulnerabilities to jailbreaks and prompt injections, which can result in harmful outputs for humans or the enterprise. The challenge is amplified when working within a specific domain, as topics generally accepted for LLMs to address may be irrelevant to that field. These problems can be mitigated, for example, by fine-tuning large language models with domain-specific and security-focused data. However, these alone are insufficient, as jailbreak techniques evolve. Additionally, API-accessed models do not offer the flexibility needed to tailor behavior to industry-specific objectives, and in-context learning is not always sufficient or reliable. In response to these challenges, we introduce Archias, an expert model adept at distinguishing between in-domain and out-of-domain communications. Archias classifies user inquiries into several categories: in-domain (specifically for the automotive industry), malicious questions, price injections, prompt injections, and out-of-domain examples. Our methodology integrates outputs from the expert model (Archias) into prompts, which are then processed by the LLM to generate responses. This method increases the model's ability to understand the user's intention and give appropriate answers. Archias can be adjusted, fine-tuned, and used for many different purposes due to its small size. Therefore, it can be easily customized to the needs of any industry. To validate our approach, we created a benchmark dataset for the automotive industry. Furthermore, in the interest of advancing research and development, we release our benchmark dataset to the community.",
    "summary": "arXiv:2505.17066v2 Announce Type: replace-cross Abstract: Using LLMs in a production environment presents security challenges that include vulnerabilities to jailbreaks and prompt injections, which can result in harmful outputs for humans or the enterprise. The challenge is amplified when working within a specific domain, as topics generally accepted for LLMs to address may be irrelevant to that field. These problems can be mitigated, for example, by fine-tuning large language models with domain-specific and security-focused data. However, these alone are insufficient, as jailbreak techniques evolve. Additionally, API-accessed models do not offer the flexibility needed to tailor behavior to industry-specific objectives, and in-context learning is not always sufficient or reliable. In response to these challenges, we introduce Archias, an expert model adept at distinguishing between in-domain and out-of-domain communications. Archias classifies user inquiries into several categories: in-domain (specifically for the automotive industry), malicious questions, price injections, prompt injections, and out-of-domain examples. Our methodology integrates outputs from the expert model (Archias) into prompts, which are then processed by the LLM to generate responses. This method increases the model's ability to understand the user's intention and give appropriate answers. Archias can be adjusted, fine-tuned, and used for many different purposes due to its small size. Therefore, it can be easily customized to the needs of any industry. To validate our approach, we created a benchmark dataset for the automotive industry. Furthermore, in the interest of advancing research and development, we release our benchmark dataset to the community.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.17066",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Blazingly fast whisper transcriptions with Inference Endpoints",
    "description": "",
    "summary": "Blazingly fast whisper transcriptions with Inference Endpoints Today we are happy to introduce a new...",
    "pubDate": "Tue, 13 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-whisper-endpoints",
    "thumbnail": "https://huggingface.co/blog/assets/fast-whisper-endpoints/thumbnail.png"
  },
  {
    "title": "Optimizing your LLM in production",
    "description": "",
    "summary": "Optimizing your LLM in production Note: This blog post is also available as a documentation page on ...",
    "pubDate": "Fri, 15 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimize-llm",
    "thumbnail": "https://huggingface.co/blog/assets/163_optimize_llm/optimize_llm.png"
  },
  {
    "title": "YouTube: Enhancing the user experience",
    "description": "It‚Äôs all about using our technology and research to help enrich people‚Äôs lives. Like YouTube ‚Äî and its mission to give everyone a voice and show them the world.",
    "summary": "It‚Äôs all about using our technology and research to help enrich people‚Äôs lives. Like YouTube ‚Äî and its mission to give everyone a voice and show them the world.",
    "pubDate": "Fri, 16 Jun 2023 14:55:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/youtube-enhancing-the-user-experience/",
    "thumbnail": "https://lh3.googleusercontent.com/RAMu-2QAkfHieGDWkYFQOMiATW-wFi6jMLyC-YJ4f6Jj1H5BlhxQBmfQrb4RS6Sc6DFLFJqBahK3_1--XjoFPdGqYsCdSuTNr-pTcLkRO5SqvReblIQ=w1200-h630-n-nu"
  },
  {
    "title": "Ethics and Society Newsletter #1",
    "description": "",
    "summary": "Ethics and Society Newsletter #1 Hello, world! Originating as an open-source company, Hugging Face w...",
    "pubDate": "Thu, 22 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-1",
    "thumbnail": "https://huggingface.co/blog/assets/103_ethics-soc-1/thumbnail.png"
  },
  {
    "title": "Statistical Inference for Optimal Transport Maps: Recent Advances and Perspectives",
    "description": "arXiv:2506.19025v1 Announce Type: cross Abstract: In many applications of optimal transport (OT), the object of primary interest is the optimal transport map. This map rearranges mass from one probability distribution to another in the most efficient way possible by minimizing a specified cost. In this paper we review recent advances in estimating and developing limit theorems for the OT map, using samples from the underlying distributions. We also review parallel lines of work that establish similar results for special cases and variants of the basic OT setup. We conclude with a discussion of key directions for future research with the goal of providing practitioners with reliable inferential tools.",
    "summary": "arXiv:2506.19025v1 Announce Type: cross Abstract: In many applications of optimal transport (OT), the object of primary interest is the optimal transport map. This map rearranges mass from one probability distribution to another in the most efficient way possible by minimizing a specified cost. In this paper we review recent advances in estimating and developing limit theorems for the OT map, using samples from the underlying distributions. We also review parallel lines of work that establish similar results for special cases and variants of the basic OT setup. We conclude with a discussion of key directions for future research with the goal of providing practitioners with reliable inferential tools.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Instruction-tuning Stable Diffusion with InstructPix2Pix",
    "description": "",
    "summary": "Instruction-tuning Stable Diffusion with InstructPix2Pix This post explores instruction-tuning to te...",
    "pubDate": "Tue, 23 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/instruction-tuning-sd",
    "thumbnail": "https://huggingface.co/blog/instruction-tuning-sd/assets/instruction_tuning_sd/thumbnail.png"
  },
  {
    "title": "Mathematical Proof as a Litmus Test: Revealing Failure Modes of Advanced Large Reasoning Models",
    "description": "arXiv:2506.17114v1 Announce Type: new Abstract: Large reasoning models (e.g., R1, o3) have demonstrated remarkable mathematical problem-solving abilities. However, the high reported accuracy of these advanced models on popular datasets, reliance on purely numerical evaluation and potential benchmark leakage, often masks their true reasoning shortcomings. To address this, we propose leveraging the inherent rigor and methodological complexity of mathematical proofs as a diagnostic tool to expose these hidden failures. Specifically, we introduce the RFMDataset (Reveal Failure Modes), a collection of 200 diverse mathematical proof problems, and thoroughly evaluate advanced models' performance on it. Our in-depth analysis of their failures uncovers 10 fine-grained error types, which shows fundamental limitations in current large reasoning models: 1) large reasoning models grapple profoundly with mathematical proofs, with some generating entirely correct proofs for less than 20% of problems and failing even on basic ones; 2) models exhibit a diverse spectrum of reasoning failures, prominently demonstrating the lack of guarantees for the correctness and rigor of single-step reasoning; and 3) models show hallucination and incompleteness during the reasoning process. Our findings reveal that models' self-reflection is insufficient to resolve the current logical dilemmas, necessitating formalized and fine-grained logical training.",
    "summary": "arXiv:2506.17114v1 Announce Type: new Abstract: Large reasoning models (e.g., R1, o3) have demonstrated remarkable mathematical problem-solving abilities. However, the high reported accuracy of these advanced models on popular datasets, reliance on purely numerical evaluation and potential benchmark leakage, often masks their true reasoning shortcomings. To address this, we propose leveraging the inherent rigor and methodological complexity of mathematical proofs as a diagnostic tool to expose these hidden failures. Specifically, we introduce the RFMDataset (Reveal Failure Modes), a collection of 200 diverse mathematical proof problems, and thoroughly evaluate advanced models' performance on it. Our in-depth analysis of their failures uncovers 10 fine-grained error types, which shows fundamental limitations in current large reasoning models: 1) large reasoning models grapple profoundly with mathematical proofs, with some generating entirely correct proofs for less than 20% of problems and failing even on basic ones; 2) models exhibit a diverse spectrum of reasoning failures, prominently demonstrating the lack of guarantees for the correctness and rigor of single-step reasoning; and 3) models show hallucination and incompleteness during the reasoning process. Our findings reveal that models' self-reflection is insufficient to resolve the current logical dilemmas, necessitating formalized and fine-grained logical training.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17114",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GPT-2: 6-month follow-up",
    "description": "We‚Äôre releasing the 774 million parameter GPT-2 language model after the release of our small¬†124M model¬†in February, staged release of our medium¬†355M model¬†in May, and subsequent research with partners and the AI community into the model‚Äôs potential for misuse and societal benefit. We‚Äôre also releasing an open-source legal agreement to make it easier for organizations to initiate model-sharing partnerships with each other, and are publishing a technical report about our experience in coordinating with the wider AI research community on publication¬†norms.",
    "summary": "We‚Äôre releasing the 774 million parameter GPT-2 language model after the release of our small¬†124M model¬†in February, staged release of our medium¬†355M model¬†in May, and subsequent research with partners and the AI community into the model‚Äôs potential for misuse and societal benefit. We‚Äôre also releasing an open-source legal agreement to make it easier for organizations to initiate model-sharing partnerships with each other, and are publishing a technical report about our experience in coordinating with the wider AI research community on publication¬†norms.",
    "pubDate": "Tue, 20 Aug 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-2-6-month-follow-up",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Solving Rubik‚Äôs Cube with a robot hand",
    "description": "We‚Äôve trained a pair of neural networks to solve the Rubik‚Äôs Cube with a human-like robot hand. The neural networks are trained entirely in simulation, using the same reinforcement learning code as¬†OpenAI Five¬†paired with a new technique called Automatic Domain Randomization (ADR). The system can handle situations it never saw during training, such as being prodded by a¬†stuffed giraffe. This shows that reinforcement learning isn‚Äôt just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.",
    "summary": "We‚Äôve trained a pair of neural networks to solve the Rubik‚Äôs Cube with a human-like robot hand. The neural networks are trained entirely in simulation, using the same reinforcement learning code as¬†OpenAI Five¬†paired with a new technique called Automatic Domain Randomization (ADR). The system can handle situations it never saw during training, such as being prodded by a¬†stuffed giraffe. This shows that reinforcement learning isn‚Äôt just a tool for virtual tasks, but can solve physical-world problems requiring unprecedented dexterity.",
    "pubDate": "Tue, 15 Oct 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/solving-rubiks-cube",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A failed experiment: Infini-Attention, and why we should keep trying?",
    "description": "",
    "summary": "A failed experiment: Infini-Attention, and why we should keep trying? TLDR: Infini-attention's perfo...",
    "pubDate": "Wed, 14 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/infini-attention",
    "thumbnail": "https://huggingface.co/blog/infini-attention/assets/185_infini_attention/infini_attention_thumbnail.png"
  },
  {
    "title": "Announcing the ü§ó AI Research Residency Program",
    "description": "",
    "summary": "Announcing the ü§ó AI Research Residency Program üéâ üéâ üéâ The ü§ó Research Residency Program is a 9-month o...",
    "pubDate": "Tue, 22 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-residency",
    "thumbnail": "https://huggingface.co/blog/assets/57_ai_residency/residency-thumbnail.jpg"
  },
  {
    "title": "Best practices for data enrichment",
    "description": "Building a responsible approach to data collection with the Partnership on AI...",
    "summary": "Building a responsible approach to data collection with the Partnership on AI...",
    "pubDate": "Wed, 16 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/best-practices-for-data-enrichment/",
    "thumbnail": "https://lh3.googleusercontent.com/nYvgmCtFKpHCzKOzqvlm-YK_l5qbPvz570PQbWv2ZxKVIoZxraa7euQLCY65a7ecdDRzBQtbQY2jxAoYKO8PC90snL6QvwNAzhp5-8x31cL5cJV-_OY=w1200-h630-n-nu"
  },
  {
    "title": "Random Initialization Can't Catch Up: The Advantage of Language Model Transfer for Time Series Forecasting",
    "description": "arXiv:2506.21570v1 Announce Type: cross Abstract: Recent works have demonstrated the effectiveness of adapting pre-trained language models (LMs) for forecasting time series in the low-data regime. We build upon these findings by analyzing the effective transfer from language models to time series forecasting under various design choices including upstream post-training, time series tokenizer and language backbone size. In the low-data regime, these design choices have a significant impact on the validation loss, with clear-cut choices that outperform others. Contrary to Hernandez et al. (2021), we observe that the validation loss of the LMs continues to smoothly decrease long after the validation loss of the randomly initialized models has converged, leading to a non-vanishing transfer gap that holds across design choices. These findings not only help shed light on the effective use of compute-efficient training for time series, but also open the way for the study of modality-agnostic properties of data distributions leveraged by these models.",
    "summary": "arXiv:2506.21570v1 Announce Type: cross Abstract: Recent works have demonstrated the effectiveness of adapting pre-trained language models (LMs) for forecasting time series in the low-data regime. We build upon these findings by analyzing the effective transfer from language models to time series forecasting under various design choices including upstream post-training, time series tokenizer and language backbone size. In the low-data regime, these design choices have a significant impact on the validation loss, with clear-cut choices that outperform others. Contrary to Hernandez et al. (2021), we observe that the validation loss of the LMs continues to smoothly decrease long after the validation loss of the randomly initialized models has converged, leading to a non-vanishing transfer gap that holds across design choices. These findings not only help shed light on the effective use of compute-efficient training for time series, but also open the way for the study of modality-agnostic properties of data distributions leveraged by these models.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21570",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Graphics4Science: Computer Graphics for Scientific Impacts",
    "description": "arXiv:2506.15786v1 Announce Type: cross Abstract: Computer graphics, often associated with films, games, and visual effects, has long been a powerful tool for addressing scientific challenges--from its origins in 3D visualization for medical imaging to its role in modern computational modeling and simulation. This course explores the deep and evolving relationship between computer graphics and science, highlighting past achievements, ongoing contributions, and open questions that remain. We show how core methods, such as geometric reasoning and physical modeling, provide inductive biases that help address challenges in both fields, especially in data-scarce settings. To that end, we aim to reframe graphics as a modeling language for science by bridging vocabulary gaps between the two communities. Designed for both newcomers and experts, Graphics4Science invites the graphics community to engage with science, tackle high-impact problems where graphics expertise can make a difference, and contribute to the future of scientific discovery. Additional details are available on the course website: https://graphics4science.github.io",
    "summary": "arXiv:2506.15786v1 Announce Type: cross Abstract: Computer graphics, often associated with films, games, and visual effects, has long been a powerful tool for addressing scientific challenges--from its origins in 3D visualization for medical imaging to its role in modern computational modeling and simulation. This course explores the deep and evolving relationship between computer graphics and science, highlighting past achievements, ongoing contributions, and open questions that remain. We show how core methods, such as geometric reasoning and physical modeling, provide inductive biases that help address challenges in both fields, especially in data-scarce settings. To that end, we aim to reframe graphics as a modeling language for science by bridging vocabulary gaps between the two communities. Designed for both newcomers and experts, Graphics4Science invites the graphics community to engage with science, tackle high-impact problems where graphics expertise can make a difference, and contribute to the future of scientific discovery. Additional details are available on the course website: https://graphics4science.github.io",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15786",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Reformer - Pushing the limits of language modeling",
    "description": "",
    "summary": "The Reformer - Pushing the limits of language modeling How the Reformer uses less than 8GB of RAM to...",
    "pubDate": "Fri, 03 Jul 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/reformer",
    "thumbnail": "https://huggingface.co/blog/assets/03_reformer/thumbnail.png"
  },
  {
    "title": "A Certified Proof Checker for Deep Neural Network Verification in Imandra",
    "description": "arXiv:2405.10611v2 Announce Type: replace-cross Abstract: Recent advances in the verification of deep neural networks (DNNs) have opened the way for a broader usage of DNN verification technology in many application areas, including safety-critical ones. However, DNN verifiers are themselves complex programs that have been shown to be susceptible to errors and numerical imprecision; this, in turn, has raised the question of trust in DNN verifiers. One prominent attempt to address this issue is enhancing DNN verifiers with the capability of producing certificates of their results that are subject to independent algorithmic checking. While formulations of Marabou certificate checking already exist on top of the state-of-the-art DNN verifier Marabou, they are implemented in C++, and that code itself raises the question of trust (e.g., in the precision of floating point calculations or guarantees for implementation soundness). Here, we present an alternative implementation of the Marabou certificate checking in Imandra -- an industrial functional programming language and an interactive theorem prover (ITP) -- that allows us to obtain full proof of certificate correctness. The significance of the result is two-fold. Firstly, it gives stronger independent guarantees for Marabou proofs. Secondly, it opens the way for the wider adoption of DNN verifiers in interactive theorem proving in the same way as many ITPs already incorporate SMT solvers.",
    "summary": "arXiv:2405.10611v2 Announce Type: replace-cross Abstract: Recent advances in the verification of deep neural networks (DNNs) have opened the way for a broader usage of DNN verification technology in many application areas, including safety-critical ones. However, DNN verifiers are themselves complex programs that have been shown to be susceptible to errors and numerical imprecision; this, in turn, has raised the question of trust in DNN verifiers. One prominent attempt to address this issue is enhancing DNN verifiers with the capability of producing certificates of their results that are subject to independent algorithmic checking. While formulations of Marabou certificate checking already exist on top of the state-of-the-art DNN verifier Marabou, they are implemented in C++, and that code itself raises the question of trust (e.g., in the precision of floating point calculations or guarantees for implementation soundness). Here, we present an alternative implementation of the Marabou certificate checking in Imandra -- an industrial functional programming language and an interactive theorem prover (ITP) -- that allows us to obtain full proof of certificate correctness. The significance of the result is two-fold. Firstly, it gives stronger independent guarantees for Marabou proofs. Secondly, it opens the way for the wider adoption of DNN verifiers in interactive theorem proving in the same way as many ITPs already incorporate SMT solvers.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.10611",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Image Similarity with Hugging Face Datasets and Transformers",
    "description": "",
    "summary": "Image Similarity with Hugging Face Datasets and Transformers In this post, you'll learn to build an ...",
    "pubDate": "Mon, 16 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-similarity",
    "thumbnail": "https://huggingface.co/blog/assets/image_similarity/thumbnail.png"
  },
  {
    "title": "A Student‚Äôs Guide to Writing with ChatGPT",
    "description": "A Student‚Äôs Guide to Writing with ChatGPT",
    "summary": "A Student‚Äôs Guide to Writing with ChatGPT",
    "pubDate": "Wed, 13 Nov 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/chatgpt/use-cases/student-writing-guide",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Verdi, an AI dev platform powered by GPT-4o",
    "description": "Mercado Libre introduces Verdi, an AI developer platform powered by GPT-4o",
    "summary": "Mercado Libre introduces Verdi, an AI developer platform powered by GPT-4o",
    "pubDate": "Tue, 24 Sep 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mercado-libre",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "VesselSAM: Leveraging SAM for Aortic Vessel Segmentation with AtrousLoRA",
    "description": "arXiv:2502.18185v4 Announce Type: replace-cross Abstract: Medical image segmentation is crucial for clinical diagnosis and treatment planning, especially when dealing with complex anatomical structures such as vessels. However, accurately segmenting vessels remains challenging due to their small size, intricate edge structures, and susceptibility to artifacts and imaging noise. In this work, we propose VesselSAM, an enhanced version of the Segment Anything Model (SAM), specifically tailored for aortic vessel segmentation. VesselSAM incorporates AtrousLoRA, a novel module integrating Atrous Attention and Low-Rank Adaptation (LoRA), to enhance segmentation performance. Atrous Attention enables the model to capture multi-scale contextual information, preserving both fine-grained local details and broader global context. Additionally, LoRA facilitates efficient fine-tuning of the frozen SAM image encoder, reducing the number of trainable parameters and thereby enhancing computational efficiency. We evaluate VesselSAM using two challenging datasets: the Aortic Vessel Tree (AVT) dataset and the Type-B Aortic Dissection (TBAD) dataset. VesselSAM achieves state-of-the-art performance, attaining DSC scores of 93.50%, 93.25%, 93.02%, and 93.26% across multi-center datasets. Our results demonstrate that VesselSAM delivers high segmentation accuracy while significantly reducing computational overhead compared to existing large-scale models. This development paves the way for enhanced AI-based aortic vessel segmentation in clinical environments. The code and models will be released at https://github.com/Adnan-CAS/AtrousLora.",
    "summary": "arXiv:2502.18185v4 Announce Type: replace-cross Abstract: Medical image segmentation is crucial for clinical diagnosis and treatment planning, especially when dealing with complex anatomical structures such as vessels. However, accurately segmenting vessels remains challenging due to their small size, intricate edge structures, and susceptibility to artifacts and imaging noise. In this work, we propose VesselSAM, an enhanced version of the Segment Anything Model (SAM), specifically tailored for aortic vessel segmentation. VesselSAM incorporates AtrousLoRA, a novel module integrating Atrous Attention and Low-Rank Adaptation (LoRA), to enhance segmentation performance. Atrous Attention enables the model to capture multi-scale contextual information, preserving both fine-grained local details and broader global context. Additionally, LoRA facilitates efficient fine-tuning of the frozen SAM image encoder, reducing the number of trainable parameters and thereby enhancing computational efficiency. We evaluate VesselSAM using two challenging datasets: the Aortic Vessel Tree (AVT) dataset and the Type-B Aortic Dissection (TBAD) dataset. VesselSAM achieves state-of-the-art performance, attaining DSC scores of 93.50%, 93.25%, 93.02%, and 93.26% across multi-center datasets. Our results demonstrate that VesselSAM delivers high segmentation accuracy while significantly reducing computational overhead compared to existing large-scale models. This development paves the way for enhanced AI-based aortic vessel segmentation in clinical environments. The code and models will be released at https://github.com/Adnan-CAS/AtrousLora.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.18185",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Orthogonal Finetuning Made Scalable",
    "description": "arXiv:2506.19847v1 Announce Type: cross Abstract: Orthogonal finetuning (OFT) offers highly parameter-efficient adaptation while preventing catastrophic forgetting, but its high runtime and memory demands limit practical deployment. We identify the core computational bottleneck in OFT as its weight-centric implementation, which relies on costly matrix-matrix multiplications with cubic complexity. To overcome this, we propose OFTv2, an input-centric reformulation that instead uses matrix-vector multiplications (i.e., matrix-free computation), reducing the computational cost to quadratic. We further introduce the Cayley-Neumann parameterization, an efficient orthogonal parameterization that approximates the matrix inversion in Cayley transform via a truncated Neumann series. These modifications allow OFTv2 to achieve up to 10x faster training and 3x lower GPU memory usage without compromising performance. In addition, we extend OFTv2 to support finetuning quantized foundation models and show that it outperforms the popular QLoRA in training stability, efficiency, and memory usage.",
    "summary": "arXiv:2506.19847v1 Announce Type: cross Abstract: Orthogonal finetuning (OFT) offers highly parameter-efficient adaptation while preventing catastrophic forgetting, but its high runtime and memory demands limit practical deployment. We identify the core computational bottleneck in OFT as its weight-centric implementation, which relies on costly matrix-matrix multiplications with cubic complexity. To overcome this, we propose OFTv2, an input-centric reformulation that instead uses matrix-vector multiplications (i.e., matrix-free computation), reducing the computational cost to quadratic. We further introduce the Cayley-Neumann parameterization, an efficient orthogonal parameterization that approximates the matrix inversion in Cayley transform via a truncated Neumann series. These modifications allow OFTv2 to achieve up to 10x faster training and 3x lower GPU memory usage without compromising performance. In addition, we extend OFTv2 to support finetuning quantized foundation models and show that it outperforms the popular QLoRA in training stability, efficiency, and memory usage.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19847",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Animator Lyndon Barrois creates new worlds with Sora",
    "description": "Filmmaker Lyndon Barrois describes how to use Sora as a storytelling tool.",
    "summary": "Filmmaker Lyndon Barrois describes how to use Sora as a storytelling tool.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-lyndon-barrois",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing",
    "description": "arXiv:2506.20967v2 Announce Type: replace-cross Abstract: The advent of Video Diffusion Transformers (Video DiTs) marks a milestone in video generation. However, directly applying existing video editing methods to Video DiTs often incurs substantial computational overhead, due to resource-intensive attention modification or finetuning. To alleviate this problem, we present DFVEdit, an efficient zero-shot video editing method tailored for Video DiTs. DFVEdit eliminates the need for both attention modification and fine-tuning by directly operating on clean latents via flow transformation. To be more specific, we observe that editing and sampling can be unified under the continuous flow perspective. Building upon this foundation, we propose the Conditional Delta Flow Vector (CDFV) -- a theoretically unbiased estimation of DFV -- and integrate Implicit Cross Attention (ICA) guidance as well as Embedding Reinforcement (ER) to further enhance editing quality. DFVEdit excels in practical efficiency, offering at least 20x inference speed-up and 85% memory reduction on Video DiTs compared to attention-engineering-based editing methods. Extensive quantitative and qualitative experiments demonstrate that DFVEdit can be seamlessly applied to popular Video DiTs (e.g., CogVideoX and Wan2.1), attaining state-of-the-art performance on structural fidelity, spatial-temporal consistency, and editing quality.",
    "summary": "arXiv:2506.20967v2 Announce Type: replace-cross Abstract: The advent of Video Diffusion Transformers (Video DiTs) marks a milestone in video generation. However, directly applying existing video editing methods to Video DiTs often incurs substantial computational overhead, due to resource-intensive attention modification or finetuning. To alleviate this problem, we present DFVEdit, an efficient zero-shot video editing method tailored for Video DiTs. DFVEdit eliminates the need for both attention modification and fine-tuning by directly operating on clean latents via flow transformation. To be more specific, we observe that editing and sampling can be unified under the continuous flow perspective. Building upon this foundation, we propose the Conditional Delta Flow Vector (CDFV) -- a theoretically unbiased estimation of DFV -- and integrate Implicit Cross Attention (ICA) guidance as well as Embedding Reinforcement (ER) to further enhance editing quality. DFVEdit excels in practical efficiency, offering at least 20x inference speed-up and 85% memory reduction on Video DiTs compared to attention-engineering-based editing methods. Extensive quantitative and qualitative experiments demonstrate that DFVEdit can be seamlessly applied to popular Video DiTs (e.g., CogVideoX and Wan2.1), attaining state-of-the-art performance on structural fidelity, spatial-temporal consistency, and editing quality.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.20967",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Image search with ü§ó datasets",
    "description": "",
    "summary": "Image search with ü§ó datasets ü§ó datasets is a library that makes it easy to access and share datasets...",
    "pubDate": "Wed, 16 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/image-search-datasets",
    "thumbnail": "https://huggingface.co/blog/assets/54_image_search_datasets/spaces_image_search.jpg"
  },
  {
    "title": "Stargate Infrastructure",
    "description": "OpenAI, and our strategic partners, are thrilled about our shared vision for the Infrastructure of AGI. We are energized by the challenges we face and are excited by the prospect of partnering with firms across the industrial base to deliver against our ambitious mission. Specifically, we want to connect with firms across the built data center infrastructure landscape, from power and land to construction to equipment, and everything in between.",
    "summary": "OpenAI, and our strategic partners, are thrilled about our shared vision for the Infrastructure of AGI. We are energized by the challenges we face and are excited by the prospect of partnering with firms across the industrial base to deliver against our ambitious mission. Specifically, we want to connect with firms across the built data center infrastructure landscape, from power and land to construction to equipment, and everything in between.",
    "pubDate": "Tue, 21 Jan 2025 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/form/stargate-infrastructure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Third-person imitation learning",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 06 Mar 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/third-person-imitation-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Gradio's new Dataframe!",
    "description": "",
    "summary": "Introducing Gradio's new Dataframe! Gradio‚Äôs gr.Dataframe component is one of our most popular compo...",
    "pubDate": "Mon, 24 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-dataframe-upgrade",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-dataframe-upgrade/thumbnail.png"
  },
  {
    "title": "Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis",
    "description": "arXiv:2506.22393v1 Announce Type: cross Abstract: Adapting machine learning models to medical time series across different domains remains a challenge due to complex temporal dependencies and dynamic distribution shifts. Current approaches often focus on isolated feature representations, limiting their ability to fully capture the intricate temporal dynamics necessary for robust domain adaptation. In this work, we propose a novel framework leveraging multi-view contrastive learning to integrate temporal patterns, derivative-based dynamics, and frequency-domain features. Our method employs independent encoders and a hierarchical fusion mechanism to learn feature-invariant representations that are transferable across domains while preserving temporal coherence. Extensive experiments on diverse medical datasets, including electroencephalogram (EEG), electrocardiogram (ECG), and electromyography (EMG) demonstrate that our approach significantly outperforms state-of-the-art methods in transfer learning tasks. By advancing the robustness and generalizability of machine learning models, our framework offers a practical pathway for deploying reliable AI systems in diverse healthcare settings.",
    "summary": "arXiv:2506.22393v1 Announce Type: cross Abstract: Adapting machine learning models to medical time series across different domains remains a challenge due to complex temporal dependencies and dynamic distribution shifts. Current approaches often focus on isolated feature representations, limiting their ability to fully capture the intricate temporal dynamics necessary for robust domain adaptation. In this work, we propose a novel framework leveraging multi-view contrastive learning to integrate temporal patterns, derivative-based dynamics, and frequency-domain features. Our method employs independent encoders and a hierarchical fusion mechanism to learn feature-invariant representations that are transferable across domains while preserving temporal coherence. Extensive experiments on diverse medical datasets, including electroencephalogram (EEG), electrocardiogram (ECG), and electromyography (EMG) demonstrate that our approach significantly outperforms state-of-the-art methods in transfer learning tasks. By advancing the robustness and generalizability of machine learning models, our framework offers a practical pathway for deploying reliable AI systems in diverse healthcare settings.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22393",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Efficient Retail Video Annotation: A Robust Key Frame Generation Approach for Product and Customer Interaction Analysis",
    "description": "arXiv:2506.14854v2 Announce Type: replace-cross Abstract: Accurate video annotation plays a vital role in modern retail applications, including customer behavior analysis, product interaction detection, and in-store activity recognition. However, conventional annotation methods heavily rely on time-consuming manual labeling by human annotators, introducing non-robust frame selection and increasing operational costs. To address these challenges in the retail domain, we propose a deep learning-based approach that automates key-frame identification in retail videos and provides automatic annotations of products and customers. Our method leverages deep neural networks to learn discriminative features by embedding video frames and incorporating object detection-based techniques tailored for retail environments. Experimental results showcase the superiority of our approach over traditional methods, achieving accuracy comparable to human annotator labeling while enhancing the overall efficiency of retail video annotation. Remarkably, our approach leads to an average of 2 times cost savings in video annotation. By allowing human annotators to verify/adjust less than 5% of detected frames in the video dataset, while automating the annotation process for the remaining frames without reducing annotation quality, retailers can significantly reduce operational costs. The automation of key-frame detection enables substantial time and effort savings in retail video labeling tasks, proving highly valuable for diverse retail applications such as shopper journey analysis, product interaction detection, and in-store security monitoring.",
    "summary": "arXiv:2506.14854v2 Announce Type: replace-cross Abstract: Accurate video annotation plays a vital role in modern retail applications, including customer behavior analysis, product interaction detection, and in-store activity recognition. However, conventional annotation methods heavily rely on time-consuming manual labeling by human annotators, introducing non-robust frame selection and increasing operational costs. To address these challenges in the retail domain, we propose a deep learning-based approach that automates key-frame identification in retail videos and provides automatic annotations of products and customers. Our method leverages deep neural networks to learn discriminative features by embedding video frames and incorporating object detection-based techniques tailored for retail environments. Experimental results showcase the superiority of our approach over traditional methods, achieving accuracy comparable to human annotator labeling while enhancing the overall efficiency of retail video annotation. Remarkably, our approach leads to an average of 2 times cost savings in video annotation. By allowing human annotators to verify/adjust less than 5% of detected frames in the video dataset, while automating the annotation process for the remaining frames without reducing annotation quality, retailers can significantly reduce operational costs. The automation of key-frame detection enables substantial time and effort savings in retail video labeling tasks, proving highly valuable for diverse retail applications such as shopper journey analysis, product interaction detection, and in-store security monitoring.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14854",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "VideoPCDNet: Video Parsing and Prediction with Phase Correlation Networks",
    "description": "arXiv:2506.19621v1 Announce Type: cross Abstract: Understanding and predicting video content is essential for planning and reasoning in dynamic environments. Despite advancements, unsupervised learning of object representations and dynamics remains challenging. We present VideoPCDNet, an unsupervised framework for object-centric video decomposition and prediction. Our model uses frequency-domain phase correlation techniques to recursively parse videos into object components, which are represented as transformed versions of learned object prototypes, enabling accurate and interpretable tracking. By explicitly modeling object motion through a combination of frequency domain operations and lightweight learned modules, VideoPCDNet enables accurate unsupervised object tracking and prediction of future video frames. In our experiments, we demonstrate that VideoPCDNet outperforms multiple object-centric baseline models for unsupervised tracking and prediction on several synthetic datasets, while learning interpretable object and motion representations.",
    "summary": "arXiv:2506.19621v1 Announce Type: cross Abstract: Understanding and predicting video content is essential for planning and reasoning in dynamic environments. Despite advancements, unsupervised learning of object representations and dynamics remains challenging. We present VideoPCDNet, an unsupervised framework for object-centric video decomposition and prediction. Our model uses frequency-domain phase correlation techniques to recursively parse videos into object components, which are represented as transformed versions of learned object prototypes, enabling accurate and interpretable tracking. By explicitly modeling object motion through a combination of frequency domain operations and lightweight learned modules, VideoPCDNet enables accurate unsupervised object tracking and prediction of future video frames. In our experiments, we demonstrate that VideoPCDNet outperforms multiple object-centric baseline models for unsupervised tracking and prediction on several synthetic datasets, while learning interpretable object and motion representations.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19621",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Large Language Models as Psychological Simulators: A Methodological Guide",
    "description": "arXiv:2506.16702v1 Announce Type: cross Abstract: Large language models (LLMs) offer emerging opportunities for psychological and behavioral research, but methodological guidance is lacking. This article provides a framework for using LLMs as psychological simulators across two primary applications: simulating roles and personas to explore diverse contexts, and serving as computational models to investigate cognitive processes. For simulation, we present methods for developing psychologically grounded personas that move beyond demographic categories, with strategies for validation against human data and use cases ranging from studying inaccessible populations to prototyping research instruments. For cognitive modeling, we synthesize emerging approaches for probing internal representations, methodological advances in causal interventions, and strategies for relating model behavior to human cognition. We address overarching challenges including prompt sensitivity, temporal limitations from training data cutoffs, and ethical considerations that extend beyond traditional human subjects review. Throughout, we emphasize the need for transparency about model capabilities and constraints. Together, this framework integrates emerging empirical evidence about LLM performance--including systematic biases, cultural limitations, and prompt brittleness--to help researchers wrangle these challenges and leverage the unique capabilities of LLMs in psychological research.",
    "summary": "arXiv:2506.16702v1 Announce Type: cross Abstract: Large language models (LLMs) offer emerging opportunities for psychological and behavioral research, but methodological guidance is lacking. This article provides a framework for using LLMs as psychological simulators across two primary applications: simulating roles and personas to explore diverse contexts, and serving as computational models to investigate cognitive processes. For simulation, we present methods for developing psychologically grounded personas that move beyond demographic categories, with strategies for validation against human data and use cases ranging from studying inaccessible populations to prototyping research instruments. For cognitive modeling, we synthesize emerging approaches for probing internal representations, methodological advances in causal interventions, and strategies for relating model behavior to human cognition. We address overarching challenges including prompt sensitivity, temporal limitations from training data cutoffs, and ethical considerations that extend beyond traditional human subjects review. Throughout, we emphasize the need for transparency about model capabilities and constraints. Together, this framework integrates emerging empirical evidence about LLM performance--including systematic biases, cultural limitations, and prompt brittleness--to help researchers wrangle these challenges and leverage the unique capabilities of LLMs in psychological research.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16702",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation",
    "description": "arXiv:2506.21876v1 Announce Type: cross Abstract: Internal world models (WMs) enable agents to understand the world's state and predict transitions, serving as the basis for advanced deliberative reasoning. Recent large Vision-Language Models (VLMs), such as OpenAI o3, GPT-4o and Gemini, exhibit potential as general-purpose WMs. While the latest studies have evaluated and shown limitations in specific capabilities such as visual understanding, a systematic evaluation of VLMs' fundamental WM abilities remains absent. Drawing on comparative psychology and cognitive science, we propose a two-stage framework that assesses Perception (visual, spatial, temporal, quantitative, and motion) and Prediction (mechanistic simulation, transitive inference, compositional inference) to provide an atomic evaluation of VLMs as WMs. Guided by this framework, we introduce WM-ABench, a large-scale benchmark comprising 23 fine-grained evaluation dimensions across 6 diverse simulated environments with controlled counterfactual simulations. Through 660 experiments on 15 latest commercial and open-source VLMs, we find that these models exhibit striking limitations in basic world modeling abilities. For instance, almost all models perform at near-random accuracy when distinguishing motion trajectories. Additionally, they lack disentangled understanding -- e.g., some models tend to believe blue objects move faster than green ones. More rich results and analyses reveal significant gaps between VLMs and human-level world modeling.",
    "summary": "arXiv:2506.21876v1 Announce Type: cross Abstract: Internal world models (WMs) enable agents to understand the world's state and predict transitions, serving as the basis for advanced deliberative reasoning. Recent large Vision-Language Models (VLMs), such as OpenAI o3, GPT-4o and Gemini, exhibit potential as general-purpose WMs. While the latest studies have evaluated and shown limitations in specific capabilities such as visual understanding, a systematic evaluation of VLMs' fundamental WM abilities remains absent. Drawing on comparative psychology and cognitive science, we propose a two-stage framework that assesses Perception (visual, spatial, temporal, quantitative, and motion) and Prediction (mechanistic simulation, transitive inference, compositional inference) to provide an atomic evaluation of VLMs as WMs. Guided by this framework, we introduce WM-ABench, a large-scale benchmark comprising 23 fine-grained evaluation dimensions across 6 diverse simulated environments with controlled counterfactual simulations. Through 660 experiments on 15 latest commercial and open-source VLMs, we find that these models exhibit striking limitations in basic world modeling abilities. For instance, almost all models perform at near-random accuracy when distinguishing motion trajectories. Additionally, they lack disentangled understanding -- e.g., some models tend to believe blue objects move faster than green ones. More rich results and analyses reveal significant gaps between VLMs and human-level world modeling.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21876",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Computer-Using Agent",
    "description": "A universal interface for AI to interact with the digital world.",
    "summary": "A universal interface for AI to interact with the digital world.",
    "pubDate": "Thu, 23 Jan 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/computer-using-agent",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Minimalist Optimizer Design for LLM Pretraining",
    "description": "arXiv:2506.16659v1 Announce Type: cross Abstract: Training large language models (LLMs) typically relies on adaptive optimizers such as Adam, which require significant memory to maintain first- and second-moment matrices, known as optimizer states. While recent works such as GaLore, Fira, and APOLLO have proposed state-compressed variants to reduce memory consumption, a fundamental question remains: What is the minimal amount of optimizer state that is truly necessary to retain state-of-the-art performance in LLM pretraining? In this work, we systematically investigate this question using a bottom-up approach. We find that two memory- and compute-efficient optimization techniques are particularly effective: (1) column-wise gradient normalization significantly boosts the performance of plain SGD without requiring momentum; and (2) adding first-order momentum only to the output layer - where gradient variance is highest - yields performance competitive with fully adaptive methods such as Muon. Based on these insights, we propose SCALE (Stochastic Column-normalized Last-layer Momentum), a new optimizer that combines column-normalized SGD with last-layer momentum, where column normalization refers to normalizing the gradient along the output dimension. Across multiple LLaMA models (60M-1B), SCALE matches or exceeds the performance of Adam while using only 35-45% of the total memory. It also consistently outperforms memory-efficient optimizers such as GaLore, Fira, and APOLLO, making it a strong candidate for large-scale pretraining under memory constraints. For the LLaMA 7B model, SCALE outperforms the state-of-the-art method APOLLO in terms of both perplexity and memory consumption. In addition, our method serves as a minimalist baseline for more sophisticated optimizer design.",
    "summary": "arXiv:2506.16659v1 Announce Type: cross Abstract: Training large language models (LLMs) typically relies on adaptive optimizers such as Adam, which require significant memory to maintain first- and second-moment matrices, known as optimizer states. While recent works such as GaLore, Fira, and APOLLO have proposed state-compressed variants to reduce memory consumption, a fundamental question remains: What is the minimal amount of optimizer state that is truly necessary to retain state-of-the-art performance in LLM pretraining? In this work, we systematically investigate this question using a bottom-up approach. We find that two memory- and compute-efficient optimization techniques are particularly effective: (1) column-wise gradient normalization significantly boosts the performance of plain SGD without requiring momentum; and (2) adding first-order momentum only to the output layer - where gradient variance is highest - yields performance competitive with fully adaptive methods such as Muon. Based on these insights, we propose SCALE (Stochastic Column-normalized Last-layer Momentum), a new optimizer that combines column-normalized SGD with last-layer momentum, where column normalization refers to normalizing the gradient along the output dimension. Across multiple LLaMA models (60M-1B), SCALE matches or exceeds the performance of Adam while using only 35-45% of the total memory. It also consistently outperforms memory-efficient optimizers such as GaLore, Fira, and APOLLO, making it a strong candidate for large-scale pretraining under memory constraints. For the LLaMA 7B model, SCALE outperforms the state-of-the-art method APOLLO in terms of both perplexity and memory consumption. In addition, our method serves as a minimalist baseline for more sophisticated optimizer design.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16659",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Our Transformers Code Agent beats the GAIA benchmark!",
    "description": "",
    "summary": "Our Transformers Code Agent beats the GAIA benchmark! TL;DR After some experiments, we were impresse...",
    "pubDate": "Mon, 01 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/beating-gaia",
    "thumbnail": "https://huggingface.co/blog/assets/beating-gaia/thumbnail.jpeg"
  },
  {
    "title": "Introducing canvas, a new way to write and code with ChatGPT.",
    "description": "Introducing canvas",
    "summary": "Introducing canvas",
    "pubDate": "Thu, 03 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-canvas",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Rich Interoperable Metadata for Cultural Heritage Projects at Jagiellonian University",
    "description": "arXiv:2407.06976v3 Announce Type: replace-cross Abstract: The rich metadata created nowadays for objects stored in libraries has nowhere to be stored, because core standards, namely MARC 21 and Dublin Core, are not flexible enough. The aim of this paper is to summarize our work-in-progress on tackling this problem in research on cultural heritage objects at the Jagiellonian University (JU). We compared the objects' metadata currently being collected at the JU (with examples of manuscript, placard, and obituary) with five widespread metadata standards used by the cultural heritage community: Dublin Core, EAD, MODS, EDM and Digital Scriptorium. Our preliminary results showed that mapping between them is indeed problematic, but we identified requirements that should be followed in further work on the JU cultural heritage metadata schema in order to achieve maximum interoperability. As we move forward, based on the successive versions of the conceptual model, we will conduct experiments to validate the practical feasibility of these mappings and the degree to which the proposed model will actually enable integration with data in these various metadata formats.",
    "summary": "arXiv:2407.06976v3 Announce Type: replace-cross Abstract: The rich metadata created nowadays for objects stored in libraries has nowhere to be stored, because core standards, namely MARC 21 and Dublin Core, are not flexible enough. The aim of this paper is to summarize our work-in-progress on tackling this problem in research on cultural heritage objects at the Jagiellonian University (JU). We compared the objects' metadata currently being collected at the JU (with examples of manuscript, placard, and obituary) with five widespread metadata standards used by the cultural heritage community: Dublin Core, EAD, MODS, EDM and Digital Scriptorium. Our preliminary results showed that mapping between them is indeed problematic, but we identified requirements that should be followed in further work on the JU cultural heritage metadata schema in order to achieve maximum interoperability. As we move forward, based on the successive versions of the conceptual model, we will conduct experiments to validate the practical feasibility of these mappings and the degree to which the proposed model will actually enable integration with data in these various metadata formats.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.06976",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community",
    "description": "",
    "summary": "From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community The Elixir community is ...",
    "pubDate": "Fri, 09 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/elixir-bumblebee",
    "thumbnail": "https://huggingface.co/blog/assets/120_elixir-bumblebee/thumbnail.png"
  },
  {
    "title": "OpenAI acquires Rockset",
    "description": "OpenAI Acquires Rockset",
    "summary": "OpenAI Acquires Rockset",
    "pubDate": "Fri, 21 Jun 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-acquires-rockset",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Teaching models to express their uncertainty in words",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 28 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teaching-models-to-express-their-uncertainty-in-words",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Falcon 2: An 11B parameter pretrained language model and VLM, trained on over 5000B tokens tokens and 11 languages",
    "description": "",
    "summary": "Falcon 2: An 11B parameter pretrained language model and VLM, trained on over 5000B tokens and 11 la...",
    "pubDate": "Fri, 24 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon2-11b",
    "thumbnail": "https://huggingface.co/blog/assets/179_falcon2-11b/thumbnail.jpg"
  },
  {
    "title": "Web Archives Metadata Generation with GPT-4o: Challenges and Insights",
    "description": "arXiv:2411.05409v3 Announce Type: replace-cross Abstract: Current metadata creation for web archives is time consuming and costly due to reliance on human effort. This paper explores the use of gpt-4o for metadata generation within the Web Archive Singapore, focusing on scalability, efficiency, and cost effectiveness. We processed 112 Web ARChive (WARC) files using data reduction techniques, achieving a notable 99.9% reduction in metadata generation costs. By prompt engineering, we generated titles and abstracts, which were evaluated both intrinsically using Levenshtein Distance and BERTScore, and extrinsically with human cataloguers using McNemar's test. Results indicate that while our method offers significant cost savings and efficiency gains, human curated metadata maintains an edge in quality. The study identifies key challenges including content inaccuracies, hallucinations, and translation issues, suggesting that Large Language Models (LLMs) should serve as complements rather than replacements for human cataloguers. Future work will focus on refining prompts, improving content filtering, and addressing privacy concerns through experimentation with smaller models. This research advances the integration of LLMs in web archiving, offering valuable insights into their current capabilities and outlining directions for future enhancements. The code is available at https://github.com/masamune-prog/warc2summary for further development and use by institutions facing similar challenges.",
    "summary": "arXiv:2411.05409v3 Announce Type: replace-cross Abstract: Current metadata creation for web archives is time consuming and costly due to reliance on human effort. This paper explores the use of gpt-4o for metadata generation within the Web Archive Singapore, focusing on scalability, efficiency, and cost effectiveness. We processed 112 Web ARChive (WARC) files using data reduction techniques, achieving a notable 99.9% reduction in metadata generation costs. By prompt engineering, we generated titles and abstracts, which were evaluated both intrinsically using Levenshtein Distance and BERTScore, and extrinsically with human cataloguers using McNemar's test. Results indicate that while our method offers significant cost savings and efficiency gains, human curated metadata maintains an edge in quality. The study identifies key challenges including content inaccuracies, hallucinations, and translation issues, suggesting that Large Language Models (LLMs) should serve as complements rather than replacements for human cataloguers. Future work will focus on refining prompts, improving content filtering, and addressing privacy concerns through experimentation with smaller models. This research advances the integration of LLMs in web archiving, offering valuable insights into their current capabilities and outlining directions for future enhancements. The code is available at https://github.com/masamune-prog/warc2summary for further development and use by institutions facing similar challenges.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.05409",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Frontier Safety Framework",
    "description": "Our approach to analyzing and mitigating future risks posed by advanced AI models",
    "summary": "Our approach to analyzing and mitigating future risks posed by advanced AI models",
    "pubDate": "Fri, 17 May 2024 14:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-the-frontier-safety-framework/",
    "thumbnail": "https://lh3.googleusercontent.com/_NVnftxEp6r9O9gnZT2_jLPpIn_nGjYp9xgl8hFhg_-fX131_koFcj6znzflexf4-MdfkSTtA060-Hh7RcvVkNkY5kQ-QBulRYDCO1Li1R1jK71G=w1200-h630-n-nu"
  },
  {
    "title": "Introducing 4o Image Generation",
    "description": "At OpenAI, we have long believed image generation should be a primary capability of our language models. That‚Äôs why we‚Äôve built our most advanced image generator yet into GPT‚Äë4o. The result‚Äîimage generation that is not only beautiful, but useful.",
    "summary": "At OpenAI, we have long believed image generation should be a primary capability of our language models. That‚Äôs why we‚Äôve built our most advanced image generator yet into GPT‚Äë4o. The result‚Äîimage generation that is not only beautiful, but useful.",
    "pubDate": "Tue, 25 Mar 2025 11:05:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-4o-image-generation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Who Does What in Deep Learning? Multidimensional Game-Theoretic Attribution of Function of Neural Units",
    "description": "arXiv:2506.19732v1 Announce Type: cross Abstract: Neural networks now generate text, images, and speech with billions of parameters, producing a need to know how each neural unit contributes to these high-dimensional outputs. Existing explainable-AI methods, such as SHAP, attribute importance to inputs, but cannot quantify the contributions of neural units across thousands of output pixels, tokens, or logits. Here we close that gap with Multiperturbation Shapley-value Analysis (MSA), a model-agnostic game-theoretic framework. By systematically lesioning combinations of units, MSA yields Shapley Modes, unit-wise contribution maps that share the exact dimensionality of the model's output. We apply MSA across scales, from multi-layer perceptrons to the 56-billion-parameter Mixtral-8x7B and Generative Adversarial Networks (GAN). The approach demonstrates how regularisation concentrates computation in a few hubs, exposes language-specific experts inside the LLM, and reveals an inverted pixel-generation hierarchy in GANs. Together, these results showcase MSA as a powerful approach for interpreting, editing, and compressing deep neural networks.",
    "summary": "arXiv:2506.19732v1 Announce Type: cross Abstract: Neural networks now generate text, images, and speech with billions of parameters, producing a need to know how each neural unit contributes to these high-dimensional outputs. Existing explainable-AI methods, such as SHAP, attribute importance to inputs, but cannot quantify the contributions of neural units across thousands of output pixels, tokens, or logits. Here we close that gap with Multiperturbation Shapley-value Analysis (MSA), a model-agnostic game-theoretic framework. By systematically lesioning combinations of units, MSA yields Shapley Modes, unit-wise contribution maps that share the exact dimensionality of the model's output. We apply MSA across scales, from multi-layer perceptrons to the 56-billion-parameter Mixtral-8x7B and Generative Adversarial Networks (GAN). The approach demonstrates how regularisation concentrates computation in a few hubs, exposes language-specific experts inside the LLM, and reveals an inverted pixel-generation hierarchy in GANs. Together, these results showcase MSA as a powerful approach for interpreting, editing, and compressing deep neural networks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19732",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How Sempre Health is leveraging the Expert Acceleration Program to accelerate their ML roadmap",
    "description": "",
    "summary": "How Sempre Health is leveraging the Expert Acceleration Program to accelerate their ML roadmap üëã Hel...",
    "pubDate": "Thu, 19 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sempre-health-eap-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/70_sempre_health/thumbnail.jpg"
  },
  {
    "title": "Google„ÄÅÊïµ„Å´Â°©„ÇíÈÄÅ„ÇãÔºü„ÄÄOpenAI„Å®ÂçîÊ•≠‚îÄ‚îÄ‚ÄúÁ∑äÂºµÊÑü‚Äù„ÅÇ„Çã„Åù„ÅÆÂÜÖÂÆπ",
    "description": "Á±≥OpenAI„ÅØ„Åì„ÅÆ„Åª„Å©„ÄÅChatGPT„ÇÑ„Åù„ÅÆ‰ªñ„ÅÆ„Éó„É≠„ÉÄ„ÇØ„Éà„ÇíÁ®ºÂÉç„Åï„Åõ„Çã„Åü„ÇÅ„ÄÅÁ±≥Google„ÅåÈñãÁô∫„Åó„ÅüAIÁî®ÂçäÂ∞é‰Ωì„Çí„É¨„É≥„Çø„É´„ÅóÂßã„ÇÅ„Åü„ÄÇÈñ¢‰øÇËÄÖ„Åå„É≠„Ç§„Çø„ÉºÈÄö‰ø°„Å´Êòé„Åã„Åó„Åü„ÄÇ",
    "summary": "Á±≥OpenAI„ÅØ„Åì„ÅÆ„Åª„Å©„ÄÅChatGPT„ÇÑ„Åù„ÅÆ‰ªñ„ÅÆ„Éó„É≠„ÉÄ„ÇØ„Éà„ÇíÁ®ºÂÉç„Åï„Åõ„Çã„Åü„ÇÅ„ÄÅÁ±≥Google„ÅåÈñãÁô∫„Åó„ÅüAIÁî®ÂçäÂ∞é‰Ωì„Çí„É¨„É≥„Çø„É´„ÅóÂßã„ÇÅ„Åü„ÄÇÈñ¢‰øÇËÄÖ„Åå„É≠„Ç§„Çø„ÉºÈÄö‰ø°„Å´Êòé„Åã„Åó„Åü„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 14:50:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2506/30/news099.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2506/30/cover_news099.jpg"
  },
  {
    "title": "DALL¬∑E 2 research preview update",
    "description": "Early users have created over 3 million images to date and helped us improve our safety processes. We‚Äôre excited to begin adding up to 1,000 new users from our waitlist each week.",
    "summary": "Early users have created over 3 million images to date and helped us improve our safety processes. We‚Äôre excited to begin adding up to 1,000 new users from our waitlist each week.",
    "pubDate": "Wed, 18 May 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-update",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI‚Äôs approach to AI and national security",
    "description": "OpenAI‚Äôs approach to AI and national security",
    "summary": "OpenAI‚Äôs approach to AI and national security",
    "pubDate": "Thu, 24 Oct 2024 14:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-approach-to-ai-and-national-security",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Fellows Fall 2018: Final projects",
    "description": "Our second class of OpenAI Fellows has wrapped up, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship. We are currently reviewing applications on a rolling basis for our next round of OpenAI Fellows Summer 2019.",
    "summary": "Our second class of OpenAI Fellows has wrapped up, with each Fellow going from a machine learning beginner to core OpenAI contributor in the course of a 6-month apprenticeship. We are currently reviewing applications on a rolling basis for our next round of OpenAI Fellows Summer 2019.",
    "pubDate": "Fri, 17 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows-fall-2018",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ryght‚Äôs Journey to Empower Healthcare and Life Sciences with Expert Support from Hugging Face",
    "description": "",
    "summary": "Ryght‚Äôs Journey to Empower Healthcare and Life Sciences with Expert Support from Hugging Face This i...",
    "pubDate": "Tue, 16 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ryght-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/ryght-case-study/thumbnail.png"
  },
  {
    "title": "Latent Noise Injection for Private and Statistically Aligned Synthetic Data Generation",
    "description": "arXiv:2506.16636v1 Announce Type: cross Abstract: Synthetic Data Generation has become essential for scalable, privacy-preserving statistical analysis. While standard approaches based on generative models, such as Normalizing Flows, have been widely used, they often suffer from slow convergence in high-dimensional settings, frequently converging more slowly than the canonical $1/sqrt{n}$ rate when approximating the true data distribution. To overcome these limitations, we propose a Latent Noise Injection method using Masked Autoregressive Flows (MAF). Instead of directly sampling from the trained model, our method perturbs each data point in the latent space and maps it back to the data domain. This construction preserves a one to one correspondence between observed and synthetic data, enabling synthetic outputs that closely reflect the underlying distribution, particularly in challenging high-dimensional regimes where traditional sampling struggles. Our procedure satisfies local $(epsilon, delta)$-differential privacy and introduces a single perturbation parameter to control the privacy-utility trade-off. Although estimators based on individual synthetic datasets may converge slowly, we show both theoretically and empirically that aggregating across $K$ studies in a meta analysis framework restores classical efficiency and yields consistent, reliable inference. We demonstrate that with a well-calibrated perturbation parameter, Latent Noise Injection achieves strong statistical alignment with the original data and robustness against membership inference attacks. These results position our method as a compelling alternative to conventional flow-based sampling for synthetic data sharing in decentralized and privacy-sensitive domains, such as biomedical research.",
    "summary": "arXiv:2506.16636v1 Announce Type: cross Abstract: Synthetic Data Generation has become essential for scalable, privacy-preserving statistical analysis. While standard approaches based on generative models, such as Normalizing Flows, have been widely used, they often suffer from slow convergence in high-dimensional settings, frequently converging more slowly than the canonical $1/sqrt{n}$ rate when approximating the true data distribution. To overcome these limitations, we propose a Latent Noise Injection method using Masked Autoregressive Flows (MAF). Instead of directly sampling from the trained model, our method perturbs each data point in the latent space and maps it back to the data domain. This construction preserves a one to one correspondence between observed and synthetic data, enabling synthetic outputs that closely reflect the underlying distribution, particularly in challenging high-dimensional regimes where traditional sampling struggles. Our procedure satisfies local $(epsilon, delta)$-differential privacy and introduces a single perturbation parameter to control the privacy-utility trade-off. Although estimators based on individual synthetic datasets may converge slowly, we show both theoretically and empirically that aggregating across $K$ studies in a meta analysis framework restores classical efficiency and yields consistent, reliable inference. We demonstrate that with a well-calibrated perturbation parameter, Latent Noise Injection achieves strong statistical alignment with the original data and robustness against membership inference attacks. These results position our method as a compelling alternative to conventional flow-based sampling for synthetic data sharing in decentralized and privacy-sensitive domains, such as biomedical research.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16636",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome Llama 4 Maverick & Scout on Hugging Face!",
    "description": "",
    "summary": "Welcome Llama 4 Maverick & Scout on Hugging Face We are incredibly excited to welcome the next gener...",
    "pubDate": "Sat, 05 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama4-release",
    "thumbnail": "https://huggingface.co/blog/assets/llama_4.png"
  },
  {
    "title": "AI safety needs social scientists",
    "description": "We‚Äôve written a paper arguing that long-term AI safety research needs social scientists to ensure AI alignment algorithms succeed when actual humans are involved. Properly aligning advanced AI systems with human values requires resolving many uncertainties related to the psychology of human rationality, emotion, and biases. The aim of this paper is to spark further collaboration between machine learning and social science researchers, and we plan to¬†hire¬†social scientists to work on this full time at¬†OpenAI.",
    "summary": "We‚Äôve written a paper arguing that long-term AI safety research needs social scientists to ensure AI alignment algorithms succeed when actual humans are involved. Properly aligning advanced AI systems with human values requires resolving many uncertainties related to the psychology of human rationality, emotion, and biases. The aim of this paper is to spark further collaboration between machine learning and social science researchers, and we plan to¬†hire¬†social scientists to work on this full time at¬†OpenAI.",
    "pubDate": "Tue, 19 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-safety-needs-social-scientists",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "On the efficacy of old features for the detection of new bots",
    "description": "arXiv:2506.19635v1 Announce Type: new Abstract: For more than a decade now, academicians and online platform administrators have been studying solutions to the problem of bot detection. Bots are computer algorithms whose use is far from being benign: malicious bots are purposely created to distribute spam, sponsor public characters and, ultimately, induce a bias within the public opinion. To fight the bot invasion on our online ecosystem, several approaches have been implemented, mostly based on (supervised and unsupervised) classifiers, which adopt the most varied account features, from the simplest to the most expensive ones to be extracted from the raw data obtainable through the Twitter public APIs. In this exploratory study, using Twitter as a benchmark, we compare the performances of four state-of-art feature sets in detecting novel bots: one of the output scores of the popular bot detector Botometer, which considers more than 1,000 features of an account to take a decision; two feature sets based on the account profile and timeline; and the information about the Twitter client from which the user tweets. The results of our analysis, conducted on six recently released datasets of Twitter accounts, hint at the possible use of general-purpose classifiers and cheap-to-compute account features for the detection of evolved bots.",
    "summary": "arXiv:2506.19635v1 Announce Type: new Abstract: For more than a decade now, academicians and online platform administrators have been studying solutions to the problem of bot detection. Bots are computer algorithms whose use is far from being benign: malicious bots are purposely created to distribute spam, sponsor public characters and, ultimately, induce a bias within the public opinion. To fight the bot invasion on our online ecosystem, several approaches have been implemented, mostly based on (supervised and unsupervised) classifiers, which adopt the most varied account features, from the simplest to the most expensive ones to be extracted from the raw data obtainable through the Twitter public APIs. In this exploratory study, using Twitter as a benchmark, we compare the performances of four state-of-art feature sets in detecting novel bots: one of the output scores of the popular bot detector Botometer, which considers more than 1,000 features of an account to take a decision; two feature sets based on the account profile and timeline; and the information about the Twitter client from which the user tweets. The results of our analysis, conducted on six recently released datasets of Twitter accounts, hint at the possible use of general-purpose classifiers and cheap-to-compute account features for the detection of evolved bots.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19635",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RLSF: Fine-tuning LLMs via Symbolic Feedback",
    "description": "arXiv:2405.16661v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have transformed AI but often struggle with tasks that require domain-specific reasoning and logical alignment. Traditional fine-tuning methods do not leverage the vast amount of symbolic domain-knowledge available to us via symbolic reasoning tools (e.g., provers), and are further limited by sparse rewards and unreliable reward models. We introduce Reinforcement Learning via Symbolic Feedback (RLSF), a novel fine-tuning paradigm where symbolic reasoning tools (e.g., solvers, provers, and algebra systems) provide fine-grained feedback to LLMs. RLSF uses poly-sized certificates (e.g., proofs) generated by symbolic tools to identify and correct errors in model outputs, offering token-level guidance without requiring differentiable reasoning systems. This paradigm bridges the gap between symbolic reasoning and LLM fine-tuning, enabling precise alignment with domain-specific constraints while addressing key limitations of traditional reward signals. Via extensive evaluations, we show that our RLSF-based fine-tuning of LLMs outperforms traditional approaches on five different applications (that have some associated logical or domain constraints), namely, program synthesis from natural language pseudo-code to programming language, three chemistry tasks, and solving the Game of 24. A key takeaway is that fine-tuning via RLSF enables relatively smaller LLMs to significantly outperform closed-source models that are orders of magnitude larger.",
    "summary": "arXiv:2405.16661v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have transformed AI but often struggle with tasks that require domain-specific reasoning and logical alignment. Traditional fine-tuning methods do not leverage the vast amount of symbolic domain-knowledge available to us via symbolic reasoning tools (e.g., provers), and are further limited by sparse rewards and unreliable reward models. We introduce Reinforcement Learning via Symbolic Feedback (RLSF), a novel fine-tuning paradigm where symbolic reasoning tools (e.g., solvers, provers, and algebra systems) provide fine-grained feedback to LLMs. RLSF uses poly-sized certificates (e.g., proofs) generated by symbolic tools to identify and correct errors in model outputs, offering token-level guidance without requiring differentiable reasoning systems. This paradigm bridges the gap between symbolic reasoning and LLM fine-tuning, enabling precise alignment with domain-specific constraints while addressing key limitations of traditional reward signals. Via extensive evaluations, we show that our RLSF-based fine-tuning of LLMs outperforms traditional approaches on five different applications (that have some associated logical or domain constraints), namely, program synthesis from natural language pseudo-code to programming language, three chemistry tasks, and solving the Game of 24. A key takeaway is that fine-tuning via RLSF enables relatively smaller LLMs to significantly outperform closed-source models that are orders of magnitude larger.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.16661",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„Çµ„É†„Éª„Ç¢„É´„Éà„Éû„É≥Ê∞è„ÇÇË™ç„ÇÅ„Çã„ÄåÁ∑äÂºµÁä∂ÊÖã„Äç‚îÄ‚îÄMicrosoft„ÄÅOpenAI„Å∏„ÅÆÂá∫Ë≥áÊØîÁéáË¶ãÁõ¥„Åó„Åã",
    "description": "Á±≥OpenAI„ÅÆ„Çµ„É†„Éª„Ç¢„É´„Éà„Éû„É≥CEO„ÅØ„ÄÅÁ±≥Microsoft„ÅÆ„Çµ„ÉÜ„Ç£„Ç¢„Éª„Éä„Éá„É©CEO„Å®7Êúà23Êó•„Å´ÈõªË©±„Åß‰ºöË´á„Åó„ÄÅÂ∞ÜÊù•ÁöÑ„Å™ÂçîÊ•≠Èñ¢‰øÇ„Å´„Å§„ÅÑ„Å¶Ë©±„ÅóÂêà„Å£„Åü„Å®„ÄÅ24Êó•„Å´ÂÖ¨Èñã„Åï„Çå„Åü„Éã„É•„Éº„É®„Éº„ÇØ„Éª„Çø„Ç§„É†„Ç∫„ÅÆ„Éù„ÉÉ„Éâ„Ç≠„É£„Çπ„ÉàÁï™ÁµÑ„ÅßË™û„Å£„Åü„ÄÇ",
    "summary": "Á±≥OpenAI„ÅÆ„Çµ„É†„Éª„Ç¢„É´„Éà„Éû„É≥CEO„ÅØ„ÄÅÁ±≥Microsoft„ÅÆ„Çµ„ÉÜ„Ç£„Ç¢„Éª„Éä„Éá„É©CEO„Å®7Êúà23Êó•„Å´ÈõªË©±„Åß‰ºöË´á„Åó„ÄÅÂ∞ÜÊù•ÁöÑ„Å™ÂçîÊ•≠Èñ¢‰øÇ„Å´„Å§„ÅÑ„Å¶Ë©±„ÅóÂêà„Å£„Åü„Å®„ÄÅ24Êó•„Å´ÂÖ¨Èñã„Åï„Çå„Åü„Éã„É•„Éº„É®„Éº„ÇØ„Éª„Çø„Ç§„É†„Ç∫„ÅÆ„Éù„ÉÉ„Éâ„Ç≠„É£„Çπ„ÉàÁï™ÁµÑ„ÅßË™û„Å£„Åü„ÄÇ",
    "pubDate": "Thu, 26 Jun 2025 07:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2506/25/news114.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2506/25/cover_news114.jpg"
  },
  {
    "title": "AlphaDev discovers faster sorting algorithms",
    "description": "New algorithms will transform the foundations of computing",
    "summary": "New algorithms will transform the foundations of computing",
    "pubDate": "Wed, 07 Jun 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphadev-discovers-faster-sorting-algorithms/",
    "thumbnail": "https://lh3.googleusercontent.com/kYAs9KTHdhYZE0BeKMKlphVqU3eQS8oXP_GNrrWBjFbl8r4YFv2FWlRbe6x9L4Q_L-eKZeE7E__GtKVJTLXvW_zGTTzplSJCplN02n_8cz7No815L5M=w1200-h630-n-nu"
  },
  {
    "title": "Semantic Scene Graph for Ultrasound Image Explanation and Scanning Guidance",
    "description": "arXiv:2506.19683v1 Announce Type: cross Abstract: Understanding medical ultrasound imaging remains a long-standing challenge due to significant visual variability caused by differences in imaging and acquisition parameters. Recent advancements in large language models (LLMs) have been used to automatically generate terminology-rich summaries orientated to clinicians with sufficient physiological knowledge. Nevertheless, the increasing demand for improved ultrasound interpretability and basic scanning guidance among non-expert users, e.g., in point-of-care settings, has not yet been explored. In this study, we first introduce the scene graph (SG) for ultrasound images to explain image content to ordinary and provide guidance for ultrasound scanning. The ultrasound SG is first computed using a transformer-based one-stage method, eliminating the need for explicit object detection. To generate a graspable image explanation for ordinary, the user query is then used to further refine the abstract SG representation through LLMs. Additionally, the predicted SG is explored for its potential in guiding ultrasound scanning toward missing anatomies within the current imaging view, assisting ordinary users in achieving more standardized and complete anatomical exploration. The effectiveness of this SG-based image explanation and scanning guidance has been validated on images from the left and right neck regions, including the carotid and thyroid, across five volunteers. The results demonstrate the potential of the method to maximally democratize ultrasound by enhancing its interpretability and usability for ordinaries.",
    "summary": "arXiv:2506.19683v1 Announce Type: cross Abstract: Understanding medical ultrasound imaging remains a long-standing challenge due to significant visual variability caused by differences in imaging and acquisition parameters. Recent advancements in large language models (LLMs) have been used to automatically generate terminology-rich summaries orientated to clinicians with sufficient physiological knowledge. Nevertheless, the increasing demand for improved ultrasound interpretability and basic scanning guidance among non-expert users, e.g., in point-of-care settings, has not yet been explored. In this study, we first introduce the scene graph (SG) for ultrasound images to explain image content to ordinary and provide guidance for ultrasound scanning. The ultrasound SG is first computed using a transformer-based one-stage method, eliminating the need for explicit object detection. To generate a graspable image explanation for ordinary, the user query is then used to further refine the abstract SG representation through LLMs. Additionally, the predicted SG is explored for its potential in guiding ultrasound scanning toward missing anatomies within the current imaging view, assisting ordinary users in achieving more standardized and complete anatomical exploration. The effectiveness of this SG-based image explanation and scanning guidance has been validated on images from the left and right neck regions, including the carotid and thyroid, across five volunteers. The results demonstrate the potential of the method to maximally democratize ultrasound by enhancing its interpretability and usability for ordinaries.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19683",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Vana is letting users own a piece of the AI models trained on their data",
    "description": "More than 1 million people are contributing their data to Vana‚Äôs decentralized network, which started as an MIT class project.",
    "summary": "More than 1 million people are contributing their data to Vana‚Äôs decentralized network, which started as an MIT class project.",
    "pubDate": "Thu, 03 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/vana-lets-users-own-piece-ai-models-trained-on-their-data-0403",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Vana-01.jpg"
  },
  {
    "title": "AI powers Expedia‚Äôs marketing evolution",
    "description": "A conversation with Jochen Koedijk, Chief Marketing Officer of Expedia Group.",
    "summary": "A conversation with Jochen Koedijk, Chief Marketing Officer of Expedia Group.",
    "pubDate": "Wed, 14 May 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/expedia-jochen-koedijk",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learn from the Past: Fast Sparse Indexing for Large Language Model Decoding",
    "description": "arXiv:2506.15704v1 Announce Type: cross Abstract: As large language models (LLMs) continue to support increasingly longer contexts, the memory demand for key-value (KV) caches during decoding grows rapidly, becoming a critical bottleneck in both GPU memory capacity and PCIe bandwidth. Sparse attention mechanisms alleviate this issue by computing attention weights only for selected key-value pairs. However, their indexing computation typically requires traversing all key vectors, resulting in significant computational and data transfer overhead. To reduce the cost of index retrieval, existing methods often treat each decoding step as an independent process, failing to exploit the temporal correlations embedded in historical decoding information. To this end, we propose LFPS(Learn From the Past for Sparse Indexing), an acceleration method that dynamically constructs sparse indexing candidates based on historical attention patterns. LFPS captures two prevalent trends in decoder attention -vertical patterns (attending to fixed positions) and slash patterns (attending to relative positions) -and incorporates a positional expansion strategy to effectively predict the Top-k indices for the current step. We validate LFPS on challenging long-context benchmarks such as LongBench-RULER, using Llama-3.1-8B-Instruct as the base model. Experimental results show that LFPS achieves up to 22.8$times$ speedup over full attention and 9.6$times$ speedup over exact Top-k retrieval on an RTX 4090 GPU and a single CPU core of a Xeon Gold 6430, respectively, while preserving generation accuracy. These results demonstrate that LFPS offers a practical and efficient solution for decoding optimization in long-context LLM inference.",
    "summary": "arXiv:2506.15704v1 Announce Type: cross Abstract: As large language models (LLMs) continue to support increasingly longer contexts, the memory demand for key-value (KV) caches during decoding grows rapidly, becoming a critical bottleneck in both GPU memory capacity and PCIe bandwidth. Sparse attention mechanisms alleviate this issue by computing attention weights only for selected key-value pairs. However, their indexing computation typically requires traversing all key vectors, resulting in significant computational and data transfer overhead. To reduce the cost of index retrieval, existing methods often treat each decoding step as an independent process, failing to exploit the temporal correlations embedded in historical decoding information. To this end, we propose LFPS(Learn From the Past for Sparse Indexing), an acceleration method that dynamically constructs sparse indexing candidates based on historical attention patterns. LFPS captures two prevalent trends in decoder attention -vertical patterns (attending to fixed positions) and slash patterns (attending to relative positions) -and incorporates a positional expansion strategy to effectively predict the Top-k indices for the current step. We validate LFPS on challenging long-context benchmarks such as LongBench-RULER, using Llama-3.1-8B-Instruct as the base model. Experimental results show that LFPS achieves up to 22.8$times$ speedup over full attention and 9.6$times$ speedup over exact Top-k retrieval on an RTX 4090 GPU and a single CPU core of a Xeon Gold 6430, respectively, while preserving generation accuracy. These results demonstrate that LFPS offers a practical and efficient solution for decoding optimization in long-context LLM inference.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15704",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Teaching with AI",
    "description": "We‚Äôre releasing a guide for teachers using ChatGPT in their classroom‚Äîincluding suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.",
    "summary": "We‚Äôre releasing a guide for teachers using ChatGPT in their classroom‚Äîincluding suggested prompts, an explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.",
    "pubDate": "Thu, 31 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/teaching-with-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GraphRAG-Bench: Challenging Domain-Specific Reasoning for Evaluating Graph Retrieval-Augmented Generation",
    "description": "arXiv:2506.02404v3 Announce Type: replace-cross Abstract: Graph Retrieval Augmented Generation (GraphRAG) has garnered increasing recognition for its potential to enhance large language models (LLMs) by structurally organizing domain-specific corpora and facilitating complex reasoning. However, current evaluations of GraphRAG models predominantly rely on traditional question-answering datasets. Their limited scope in questions and evaluation metrics fails to comprehensively assess the reasoning capacity improvements enabled by GraphRAG models. To address this gap, we introduce GraphRAG-Bench, a large-scale, domain-specific benchmark designed to rigorously evaluate GraphRAG models. Our benchmark offers three key superiorities: ((i)) Challenging question design. Featuring college-level, domain-specific questions that demand multi-hop reasoning, the benchmark ensures that simple content retrieval is insufficient for problem-solving. For example, some questions require mathematical reasoning or programming. ((ii)) Diverse task coverage. The dataset includes a broad spectrum of reasoning tasks, multiple-choice, true/false, multi-select, open-ended, and fill-in-the-blank. It spans 16 disciplines in twenty core textbooks. ((iii)) Holistic evaluation framework. GraphRAG-Bench provides comprehensive assessment across the entire GraphRAG pipeline, including graph construction, knowledge retrieval, and answer generation. Beyond final-answer correctness, it evaluates the logical coherence of the reasoning process. By applying nine contemporary GraphRAG methods to GraphRAG-Bench, we demonstrate its utility in quantifying how graph-based structuring improves model reasoning capabilities. Our analysis reveals critical insights about graph architectures, retrieval efficacy, and reasoning capabilities, offering actionable guidance for the research community.",
    "summary": "arXiv:2506.02404v3 Announce Type: replace-cross Abstract: Graph Retrieval Augmented Generation (GraphRAG) has garnered increasing recognition for its potential to enhance large language models (LLMs) by structurally organizing domain-specific corpora and facilitating complex reasoning. However, current evaluations of GraphRAG models predominantly rely on traditional question-answering datasets. Their limited scope in questions and evaluation metrics fails to comprehensively assess the reasoning capacity improvements enabled by GraphRAG models. To address this gap, we introduce GraphRAG-Bench, a large-scale, domain-specific benchmark designed to rigorously evaluate GraphRAG models. Our benchmark offers three key superiorities: ((i)) Challenging question design. Featuring college-level, domain-specific questions that demand multi-hop reasoning, the benchmark ensures that simple content retrieval is insufficient for problem-solving. For example, some questions require mathematical reasoning or programming. ((ii)) Diverse task coverage. The dataset includes a broad spectrum of reasoning tasks, multiple-choice, true/false, multi-select, open-ended, and fill-in-the-blank. It spans 16 disciplines in twenty core textbooks. ((iii)) Holistic evaluation framework. GraphRAG-Bench provides comprehensive assessment across the entire GraphRAG pipeline, including graph construction, knowledge retrieval, and answer generation. Beyond final-answer correctness, it evaluates the logical coherence of the reasoning process. By applying nine contemporary GraphRAG methods to GraphRAG-Bench, we demonstrate its utility in quantifying how graph-based structuring improves model reasoning capabilities. Our analysis reveals critical insights about graph architectures, retrieval efficacy, and reasoning capabilities, offering actionable guidance for the research community.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.02404",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Promega‚Äôs top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "description": "Promega's top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "summary": "Promega's top-down adoption of ChatGPT accelerates manufacturing, sales, and marketing",
    "pubDate": "Thu, 31 Oct 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/promega",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Pushing the frontiers of audio generation",
    "description": "Our pioneering speech generation technologies are helping people around the world interact with more natural, conversational and intuitive digital assistants and AI tools.",
    "summary": "Our pioneering speech generation technologies are helping people around the world interact with more natural, conversational and intuitive digital assistants and AI tools.",
    "pubDate": "Wed, 30 Oct 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/pushing-the-frontiers-of-audio-generation/",
    "thumbnail": "https://lh3.googleusercontent.com/wyFc1lo4ByOJsbbSt1NEwBiSi3KpImyqA9ukx-mLxJROIakSxhPwk-kPtlIfFKX9Txm2J_lbpIvnrDhFnegrpN8ihlvYpBTsFNAmOlq0C2rm_gef=w1200-h630-n-nu"
  },
  {
    "title": "Discrepancy-Aware Graph Mask Auto-Encoder",
    "description": "arXiv:2506.19343v1 Announce Type: cross Abstract: Masked Graph Auto-Encoder, a powerful graph self-supervised training paradigm, has recently shown superior performance in graph representation learning. Existing works typically rely on node contextual information to recover the masked information. However, they fail to generalize well to heterophilic graphs where connected nodes may be not similar, because they focus only on capturing the neighborhood information and ignoring the discrepancy information between different nodes, resulting in indistinguishable node representations. In this paper, to address this issue, we propose a Discrepancy-Aware Graph Mask Auto-Encoder (DGMAE). It obtains more distinguishable node representations by reconstructing the discrepancy information of neighboring nodes during the masking process. We conduct extensive experiments on 17 widely-used benchmark datasets. The results show that our DGMAE can effectively preserve the discrepancies of nodes in low-dimensional space. Moreover, DGMAE significantly outperforms state-of-the-art graph self-supervised learning methods on three graph analytic including tasks node classification, node clustering, and graph classification, demonstrating its remarkable superiority. The code of DGMAE is available at https://github.com/zhengziyu77/DGMAE.",
    "summary": "arXiv:2506.19343v1 Announce Type: cross Abstract: Masked Graph Auto-Encoder, a powerful graph self-supervised training paradigm, has recently shown superior performance in graph representation learning. Existing works typically rely on node contextual information to recover the masked information. However, they fail to generalize well to heterophilic graphs where connected nodes may be not similar, because they focus only on capturing the neighborhood information and ignoring the discrepancy information between different nodes, resulting in indistinguishable node representations. In this paper, to address this issue, we propose a Discrepancy-Aware Graph Mask Auto-Encoder (DGMAE). It obtains more distinguishable node representations by reconstructing the discrepancy information of neighboring nodes during the masking process. We conduct extensive experiments on 17 widely-used benchmark datasets. The results show that our DGMAE can effectively preserve the discrepancies of nodes in low-dimensional space. Moreover, DGMAE significantly outperforms state-of-the-art graph self-supervised learning methods on three graph analytic including tasks node classification, node clustering, and graph classification, demonstrating its remarkable superiority. The code of DGMAE is available at https://github.com/zhengziyu77/DGMAE.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19343",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "End-to-End Long Document Summarization using Gradient Caching",
    "description": "arXiv:2501.01805v2 Announce Type: replace-cross Abstract: Training transformer-based encoder-decoder models for long document summarization poses a significant challenge due to the quadratic memory consumption during training. Several approaches have been proposed to extend the input length at test time, but training with these approaches is still difficult, requiring truncation of input documents and causing a mismatch between training and test conditions. In this work, we propose CachED (Gradient $textbf{Cach}$ing for $textbf{E}$ncoder-$textbf{D}$ecoder models), an approach that enables end-to-end training of existing transformer-based encoder-decoder models, using the entire document without truncation. Specifically, we apply non-overlapping sliding windows to input documents, followed by fusion in decoder. During backpropagation, the gradients are cached at the decoder and are passed through the encoder in chunks by re-computing the hidden vectors, similar to gradient checkpointing. In the experiments on long document summarization, we extend BART to CachED BART, processing more than 500K tokens during training and achieving superior performance without using any additional parameters.",
    "summary": "arXiv:2501.01805v2 Announce Type: replace-cross Abstract: Training transformer-based encoder-decoder models for long document summarization poses a significant challenge due to the quadratic memory consumption during training. Several approaches have been proposed to extend the input length at test time, but training with these approaches is still difficult, requiring truncation of input documents and causing a mismatch between training and test conditions. In this work, we propose CachED (Gradient $textbf{Cach}$ing for $textbf{E}$ncoder-$textbf{D}$ecoder models), an approach that enables end-to-end training of existing transformer-based encoder-decoder models, using the entire document without truncation. Specifically, we apply non-overlapping sliding windows to input documents, followed by fusion in decoder. During backpropagation, the gradients are cached at the decoder and are passed through the encoder in chunks by re-computing the hidden vectors, similar to gradient checkpointing. In the experiments on long document summarization, we extend BART to CachED BART, processing more than 500K tokens during training and achieving superior performance without using any additional parameters.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.01805",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Cybersecurity Grant Program",
    "description": "Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants and other support.",
    "summary": "Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants and other support.",
    "pubDate": "Thu, 01 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-cybersecurity-grant-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëAI„Ç®„É≥„Ç∏„Éã„Ç¢ÂøÖË¶ãÔºÅÁã¨Ëá™LLMÈñãÁô∫ÁßòË©±„Å®DevinÊ¥ªÁî®„ÅÆ„Çπ„Çπ„É° ÔΩûLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅGPU„ÅÆ„Ç≥„Çπ„ÉàÂâäÊ∏õ„Åæ„ÅßËß£Ë™¨„Åó„Åæ„ÅôÔΩû",
    "description": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà16Êó•ÔºàÊ∞¥Ôºâ12ÊôÇ„Åã„ÇâLLMÈñãÁô∫„Å´Èñ¢„Åô„Çã„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ Êú¨„Ç¶„Çß„Éì„Éä„Éº„Åß„ÅØ„ÄÅAI„Ç®„É≥„Ç∏„Éã„Ç¢/AIÈñãÁô∫ÈÉ®ÈñÄ„ÅÆÊñπÂêë„Åë„Å´Áã¨Ëá™LLM„ÅÆÈñãÁô∫ÁßòË©±„ÇÑDevin„ÅÆÊ¥ªÁî®‰∫ã [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250716webinar/'>„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëAI„Ç®„É≥„Ç∏„Éã„Ç¢ÂøÖË¶ãÔºÅÁã¨Ëá™LLMÈñãÁô∫ÁßòË©±„Å®DevinÊ¥ªÁî®„ÅÆ„Çπ„Çπ„É° ÔΩûLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅGPU„ÅÆ„Ç≥„Çπ„ÉàÂâäÊ∏õ„Åæ„ÅßËß£Ë™¨„Åó„Åæ„ÅôÔΩû</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢„ÄåAIsmiley„Äç„ÅØ„ÄÅ2025Âπ¥7Êúà16Êó•ÔºàÊ∞¥Ôºâ12ÊôÇ„Åã„ÇâLLMÈñãÁô∫„Å´Èñ¢„Åô„Çã„Ç¶„Çß„Éì„Éä„Éº„ÇíÈñãÂÇ¨„Åó„Åæ„Åô„ÄÇ Êú¨„Ç¶„Çß„Éì„Éä„Éº„Åß„ÅØ„ÄÅAI„Ç®„É≥„Ç∏„Éã„Ç¢/AIÈñãÁô∫ÈÉ®ÈñÄ„ÅÆÊñπÂêë„Åë„Å´Áã¨Ëá™LLM„ÅÆÈñãÁô∫ÁßòË©±„ÇÑDevin„ÅÆÊ¥ªÁî®‰∫ã [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/20250716webinar/'>„Äê7/16ÈñãÂÇ¨„Ç¶„Çß„Éì„Éä„Éº„ÄëAI„Ç®„É≥„Ç∏„Éã„Ç¢ÂøÖË¶ãÔºÅÁã¨Ëá™LLMÈñãÁô∫ÁßòË©±„Å®DevinÊ¥ªÁî®„ÅÆ„Çπ„Çπ„É° ÔΩûLLMÈñãÁô∫„Å´„Åä„Åë„ÇãGPU„ÇØ„É©„Ç¶„Éâ„Å®„Ç™„É≥„Éó„É¨„ÅÆÂæπÂ∫ïÊØîËºÉÔºÅGPU„ÅÆ„Ç≥„Çπ„ÉàÂâäÊ∏õ„Åæ„ÅßËß£Ë™¨„Åó„Åæ„ÅôÔΩû</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Fri, 27 Jun 2025 02:00:37 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/20250716webinar/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/700_1200x628.jpg"
  },
  {
    "title": "AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation",
    "description": "arXiv:2506.19269v1 Announce Type: cross Abstract: We present AnchorDP3, a diffusion policy framework for dual-arm robotic manipulation that achieves state-of-the-art performance in highly randomized environments. AnchorDP3 integrates three key innovations: (1) Simulator-Supervised Semantic Segmentation, using rendered ground truth to explicitly segment task-critical objects within the point cloud, which provides strong affordance priors; (2) Task-Conditioned Feature Encoders, lightweight modules processing augmented point clouds per task, enabling efficient multi-task learning through a shared diffusion-based action expert; (3) Affordance-Anchored Keypose Diffusion with Full State Supervision, replacing dense trajectory prediction with sparse, geometrically meaningful action anchors, i.e., keyposes such as pre-grasp pose, grasp pose directly anchored to affordances, drastically simplifying the prediction space; the action expert is forced to predict both robot joint angles and end-effector poses simultaneously, which exploits geometric consistency to accelerate convergence and boost accuracy. Trained on large-scale, procedurally generated simulation data, AnchorDP3 achieves a 98.7% average success rate in the RoboTwin benchmark across diverse tasks under extreme randomization of objects, clutter, table height, lighting, and backgrounds. This framework, when integrated with the RoboTwin real-to-sim pipeline, has the potential to enable fully autonomous generation of deployable visuomotor policies from only scene and instruction, totally eliminating human demonstrations from learning manipulation skills.",
    "summary": "arXiv:2506.19269v1 Announce Type: cross Abstract: We present AnchorDP3, a diffusion policy framework for dual-arm robotic manipulation that achieves state-of-the-art performance in highly randomized environments. AnchorDP3 integrates three key innovations: (1) Simulator-Supervised Semantic Segmentation, using rendered ground truth to explicitly segment task-critical objects within the point cloud, which provides strong affordance priors; (2) Task-Conditioned Feature Encoders, lightweight modules processing augmented point clouds per task, enabling efficient multi-task learning through a shared diffusion-based action expert; (3) Affordance-Anchored Keypose Diffusion with Full State Supervision, replacing dense trajectory prediction with sparse, geometrically meaningful action anchors, i.e., keyposes such as pre-grasp pose, grasp pose directly anchored to affordances, drastically simplifying the prediction space; the action expert is forced to predict both robot joint angles and end-effector poses simultaneously, which exploits geometric consistency to accelerate convergence and boost accuracy. Trained on large-scale, procedurally generated simulation data, AnchorDP3 achieves a 98.7% average success rate in the RoboTwin benchmark across diverse tasks under extreme randomization of objects, clutter, table height, lighting, and backgrounds. This framework, when integrated with the RoboTwin real-to-sim pipeline, has the potential to enable fully autonomous generation of deployable visuomotor policies from only scene and instruction, totally eliminating human demonstrations from learning manipulation skills.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19269",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improving health literacy and patient well-being",
    "description": "Lifespan uses GPT-4 to radically improve health literacy and patient outcomes.",
    "summary": "Lifespan uses GPT-4 to radically improve health literacy and patient outcomes.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/lifespan",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Safe Pruning LoRA: Robust Distance-Guided Pruning for Safety Alignment in Adaptation of LLMs",
    "description": "arXiv:2506.18931v1 Announce Type: cross Abstract: Fine-tuning Large Language Models (LLMs) with Low-Rank Adaptation (LoRA) enhances adaptability while reducing computational costs. However, fine-tuning can compromise safety alignment, even with benign data, increasing susceptibility to harmful outputs. Existing safety alignment methods struggle to capture complex parameter shifts, leading to suboptimal safety-utility trade-offs. To address this issue, we propose Safe Pruning LoRA (SPLoRA), a novel pruning-based approach that selectively removes LoRA layers that weaken safety alignment, improving safety while preserving performance. At its core, we introduce Empirical-DIEM (E-DIEM), a dimension-insensitive similarity metric that effectively detects safety misalignment in LoRA-adapted models. We conduct extensive experiments on LLMs fine-tuned with mixed of benign and malicious data, and purely benign datasets, evaluating SPLoRA across utility, safety, and reliability metrics. Results demonstrate that SPLoRA outperforms state-of-the-art safety alignment techniques, significantly reducing safety risks while maintaining or improving model performance and reliability. Additionally, SPLoRA reduces inference overhead, making it a scalable and efficient solution for deploying safer and more reliable LLMs. The code is available at https://github.com/AoShuang92/SPLoRA.",
    "summary": "arXiv:2506.18931v1 Announce Type: cross Abstract: Fine-tuning Large Language Models (LLMs) with Low-Rank Adaptation (LoRA) enhances adaptability while reducing computational costs. However, fine-tuning can compromise safety alignment, even with benign data, increasing susceptibility to harmful outputs. Existing safety alignment methods struggle to capture complex parameter shifts, leading to suboptimal safety-utility trade-offs. To address this issue, we propose Safe Pruning LoRA (SPLoRA), a novel pruning-based approach that selectively removes LoRA layers that weaken safety alignment, improving safety while preserving performance. At its core, we introduce Empirical-DIEM (E-DIEM), a dimension-insensitive similarity metric that effectively detects safety misalignment in LoRA-adapted models. We conduct extensive experiments on LLMs fine-tuned with mixed of benign and malicious data, and purely benign datasets, evaluating SPLoRA across utility, safety, and reliability metrics. Results demonstrate that SPLoRA outperforms state-of-the-art safety alignment techniques, significantly reducing safety risks while maintaining or improving model performance and reliability. Additionally, SPLoRA reduces inference overhead, making it a scalable and efficient solution for deploying safer and more reliable LLMs. The code is available at https://github.com/AoShuang92/SPLoRA.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18931",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From Rows to Yields: How Foundation Models for Tabular Data Simplify Crop Yield Prediction",
    "description": "arXiv:2506.19046v1 Announce Type: new Abstract: We present an application of a foundation model for small- to medium-sized tabular data (TabPFN), to sub-national yield forecasting task in South Africa. TabPFN has recently demonstrated superior performance compared to traditional machine learning (ML) models in various regression and classification tasks. We used the dekadal (10-days) time series of Earth Observation (EO; FAPAR and soil moisture) and gridded weather data (air temperature, precipitation and radiation) to forecast the yield of summer crops at the sub-national level. The crop yield data was available for 23 years and for up to 8 provinces. Covariate variables for TabPFN (i.e., EO and weather) were extracted by region and aggregated at a monthly scale. We benchmarked the results of the TabPFN against six ML models and three baseline models. Leave-one-year-out cross-validation experiment setting was used in order to ensure the assessment of the models capacity to forecast an unseen year. Results showed that TabPFN and ML models exhibit comparable accuracy, outperforming the baselines. Nonetheless, TabPFN demonstrated superior practical utility due to its significantly faster tuning time and reduced requirement for feature engineering. This renders TabPFN a more viable option for real-world operation yield forecasting applications, where efficiency and ease of implementation are paramount.",
    "summary": "arXiv:2506.19046v1 Announce Type: new Abstract: We present an application of a foundation model for small- to medium-sized tabular data (TabPFN), to sub-national yield forecasting task in South Africa. TabPFN has recently demonstrated superior performance compared to traditional machine learning (ML) models in various regression and classification tasks. We used the dekadal (10-days) time series of Earth Observation (EO; FAPAR and soil moisture) and gridded weather data (air temperature, precipitation and radiation) to forecast the yield of summer crops at the sub-national level. The crop yield data was available for 23 years and for up to 8 provinces. Covariate variables for TabPFN (i.e., EO and weather) were extracted by region and aggregated at a monthly scale. We benchmarked the results of the TabPFN against six ML models and three baseline models. Leave-one-year-out cross-validation experiment setting was used in order to ensure the assessment of the models capacity to forecast an unseen year. Results showed that TabPFN and ML models exhibit comparable accuracy, outperforming the baselines. Nonetheless, TabPFN demonstrated superior practical utility due to its significantly faster tuning time and reduced requirement for feature engineering. This renders TabPFN a more viable option for real-world operation yield forecasting applications, where efficiency and ease of implementation are paramount.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19046",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reducing health insurance costs and improving care",
    "description": "Oscar brings AI to health insurance, reducing costs and improving patient care.",
    "summary": "Oscar brings AI to health insurance, reducing costs and improving patient care.",
    "pubDate": "Mon, 01 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/oscar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ChatDBG: Augmenting Debugging with Large Language Models",
    "description": "arXiv:2403.16354v5 Announce Type: replace-cross Abstract: Debugging is a critical but challenging task for programmers. This paper proposes ChatDBG, an AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like 'why is x null?'. To handle these queries, ChatDBG grants the LLM autonomy to 'take the wheel': it can act as an independent agent capable of querying and controlling the debugger to navigate through stacks and inspect program state. It then reports its findings and yields back control to the programmer. By leveraging the real-world knowledge embedded in LLMs, ChatDBG can diagnose issues identifiable only through the use of domain-specific reasoning. Our ChatDBG prototype integrates with standard debuggers including LLDB and GDB for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code including standalone scripts and Jupyter notebooks, demonstrates that ChatDBG can successfully analyze root causes, explain bugs, and generate accurate fixes for a wide range of real-world errors. For the Python programs, a single query led to an actionable bug fix 67% of the time; one additional follow-up query increased the success rate to 85%. ChatDBG has seen rapid uptake; it has already been downloaded more than 75,000 times.",
    "summary": "arXiv:2403.16354v5 Announce Type: replace-cross Abstract: Debugging is a critical but challenging task for programmers. This paper proposes ChatDBG, an AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like 'why is x null?'. To handle these queries, ChatDBG grants the LLM autonomy to 'take the wheel': it can act as an independent agent capable of querying and controlling the debugger to navigate through stacks and inspect program state. It then reports its findings and yields back control to the programmer. By leveraging the real-world knowledge embedded in LLMs, ChatDBG can diagnose issues identifiable only through the use of domain-specific reasoning. Our ChatDBG prototype integrates with standard debuggers including LLDB and GDB for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code including standalone scripts and Jupyter notebooks, demonstrates that ChatDBG can successfully analyze root causes, explain bugs, and generate accurate fixes for a wide range of real-world errors. For the Python programs, a single query led to an actionable bug fix 67% of the time; one additional follow-up query increased the success rate to 85%. ChatDBG has seen rapid uptake; it has already been downloaded more than 75,000 times.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2403.16354",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Student Ambassador Program's call for applications is open!",
    "description": "",
    "summary": "Student Ambassador Program‚Äôs call for applications is open! As an open-source company democratizing ...",
    "pubDate": "Fri, 13 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ambassadors",
    "thumbnail": "https://huggingface.co/blog/assets/67_ambassadors/thumbnail.png"
  },
  {
    "title": "Moving AI governance forward",
    "description": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
    "summary": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
    "pubDate": "Fri, 21 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/moving-ai-governance-forward",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Advanced Sign Language Video Generation with Compressed and Quantized Multi-Condition Tokenization",
    "description": "arXiv:2506.15980v1 Announce Type: cross Abstract: Sign Language Video Generation (SLVG) seeks to generate identity-preserving sign language videos from spoken language texts. Existing methods primarily rely on the single coarse condition (eg, skeleton sequences) as the intermediary to bridge the translation model and the video generation model, which limits both the naturalness and expressiveness of the generated videos. To overcome these limitations, we propose SignViP, a novel SLVG framework that incorporates multiple fine-grained conditions for improved generation fidelity. Rather than directly translating error-prone high-dimensional conditions, SignViP adopts a discrete tokenization paradigm to integrate and represent fine-grained conditions (ie, fine-grained poses and 3D hands). SignViP contains three core components. (1) Sign Video Diffusion Model is jointly trained with a multi-condition encoder to learn continuous embeddings that encapsulate fine-grained motion and appearance. (2) Finite Scalar Quantization (FSQ) Autoencoder is further trained to compress and quantize these embeddings into discrete tokens for compact representation of the conditions. (3) Multi-Condition Token Translator is trained to translate spoken language text to discrete multi-condition tokens. During inference, Multi-Condition Token Translator first translates the spoken language text into discrete multi-condition tokens. These tokens are then decoded to continuous embeddings by FSQ Autoencoder, which are subsequently injected into Sign Video Diffusion Model to guide video generation. Experimental results show that SignViP achieves state-of-the-art performance across metrics, including video quality, temporal coherence, and semantic fidelity. The code is available at https://github.com/umnooob/signvip/.",
    "summary": "arXiv:2506.15980v1 Announce Type: cross Abstract: Sign Language Video Generation (SLVG) seeks to generate identity-preserving sign language videos from spoken language texts. Existing methods primarily rely on the single coarse condition (eg, skeleton sequences) as the intermediary to bridge the translation model and the video generation model, which limits both the naturalness and expressiveness of the generated videos. To overcome these limitations, we propose SignViP, a novel SLVG framework that incorporates multiple fine-grained conditions for improved generation fidelity. Rather than directly translating error-prone high-dimensional conditions, SignViP adopts a discrete tokenization paradigm to integrate and represent fine-grained conditions (ie, fine-grained poses and 3D hands). SignViP contains three core components. (1) Sign Video Diffusion Model is jointly trained with a multi-condition encoder to learn continuous embeddings that encapsulate fine-grained motion and appearance. (2) Finite Scalar Quantization (FSQ) Autoencoder is further trained to compress and quantize these embeddings into discrete tokens for compact representation of the conditions. (3) Multi-Condition Token Translator is trained to translate spoken language text to discrete multi-condition tokens. During inference, Multi-Condition Token Translator first translates the spoken language text into discrete multi-condition tokens. These tokens are then decoded to continuous embeddings by FSQ Autoencoder, which are subsequently injected into Sign Video Diffusion Model to guide video generation. Experimental results show that SignViP achieves state-of-the-art performance across metrics, including video quality, temporal coherence, and semantic fidelity. The code is available at https://github.com/umnooob/signvip/.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15980",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 1",
    "description": "",
    "summary": "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 1 About a year ago, we showed you...",
    "pubDate": "Mon, 02 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-sapphire-rapids",
    "thumbnail": "https://huggingface.co/blog/assets/124_intel_sapphire_rapids/02.png"
  },
  {
    "title": "Hugging Face partners with Wiz Research to Improve AI Security",
    "description": "",
    "summary": "Hugging Face partners with Wiz Research to Improve AI Security We are pleased to announce that we ar...",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugging-face-wiz-security-blog",
    "thumbnail": "https://huggingface.co/blog/assets/wiz_security/security.png"
  },
  {
    "title": "How do Probabilistic Graphical Models and Graph Neural Networks Look at Network Data?",
    "description": "arXiv:2506.11869v2 Announce Type: replace-cross Abstract: Graphs are a powerful data structure for representing relational data and are widely used to describe complex real-world systems. Probabilistic Graphical Models (PGMs) and Graph Neural Networks (GNNs) can both leverage graph-structured data, but their inherent functioning is different. The question is how do they compare in capturing the information contained in networked datasets? We address this objective by solving a link prediction task and we conduct three main experiments, on both synthetic and real networks: one focuses on how PGMs and GNNs handle input features, while the other two investigate their robustness to noisy features and increasing heterophily of the graph. PGMs do not necessarily require features on nodes, while GNNs cannot exploit the network edges alone, and the choice of input features matters. We find that GNNs are outperformed by PGMs when input features are low-dimensional or noisy, mimicking many real scenarios where node attributes might be scalar or noisy. Then, we find that PGMs are more robust than GNNs when the heterophily of the graph is increased. Finally, to assess performance beyond prediction tasks, we also compare the two frameworks in terms of their computational complexity and interpretability.",
    "summary": "arXiv:2506.11869v2 Announce Type: replace-cross Abstract: Graphs are a powerful data structure for representing relational data and are widely used to describe complex real-world systems. Probabilistic Graphical Models (PGMs) and Graph Neural Networks (GNNs) can both leverage graph-structured data, but their inherent functioning is different. The question is how do they compare in capturing the information contained in networked datasets? We address this objective by solving a link prediction task and we conduct three main experiments, on both synthetic and real networks: one focuses on how PGMs and GNNs handle input features, while the other two investigate their robustness to noisy features and increasing heterophily of the graph. PGMs do not necessarily require features on nodes, while GNNs cannot exploit the network edges alone, and the choice of input features matters. We find that GNNs are outperformed by PGMs when input features are low-dimensional or noisy, mimicking many real scenarios where node attributes might be scalar or noisy. Then, we find that PGMs are more robust than GNNs when the heterophily of the graph is increased. Finally, to assess performance beyond prediction tasks, we also compare the two frameworks in terms of their computational complexity and interpretability.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11869",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Agents.js: Give tools to your LLMs using JavaScript",
    "description": "",
    "summary": "Introducing Agents.js: Give tools to your LLMs using JavaScript We have recently been working on Age...",
    "pubDate": "Mon, 24 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/agents-js",
    "thumbnail": "https://huggingface.co/blog/assets/agents-js/thumbnail.png"
  },
  {
    "title": "Simplifying contract reviews with AI",
    "description": "Ironclad uses GPT-4 to simplify the contract review process.",
    "summary": "Ironclad uses GPT-4 to simplify the contract review process.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ironclad",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Efficient and Flexible Neural Network Training through Layer-wise Feedback Propagation",
    "description": "arXiv:2308.12053v3 Announce Type: replace-cross Abstract: Gradient-based optimization has been a cornerstone of machine learning that enabled the vast advances of Artificial Intelligence (AI) development over the past decades. However, this type of optimization requires differentiation, and with recent evidence of the benefits of non-differentiable (e.g. neuromorphic) architectures over classical models w.r.t. efficiency, such constraints can become limiting in the future. We present Layer-wise Feedback Propagation (LFP), a novel training principle for neural network-like predictors that utilizes methods from the domain of explainability to decompose a reward to individual neurons based on their respective contributions. Leveraging these neuron-wise rewards, our method then implements a greedy approach reinforcing helpful parts of the network and weakening harmful ones. While having comparable computational complexity to gradient descent, LFP does not require gradient computation and generates sparse and thereby memory- and energy-efficient parameter updates and models. We establish the convergence of LFP theoretically and empirically, demonstrating its effectiveness on various models and datasets. Via two applications - neural network pruning and the approximation-free training of Spiking Neural Networks (SNNs) - we demonstrate that LFP combines increased efficiency in terms of computation and representation with flexibility w.r.t. choice of model architecture and objective function. Our code is available at https://github.com/leanderweber/layerwise-feedback-propagation.",
    "summary": "arXiv:2308.12053v3 Announce Type: replace-cross Abstract: Gradient-based optimization has been a cornerstone of machine learning that enabled the vast advances of Artificial Intelligence (AI) development over the past decades. However, this type of optimization requires differentiation, and with recent evidence of the benefits of non-differentiable (e.g. neuromorphic) architectures over classical models w.r.t. efficiency, such constraints can become limiting in the future. We present Layer-wise Feedback Propagation (LFP), a novel training principle for neural network-like predictors that utilizes methods from the domain of explainability to decompose a reward to individual neurons based on their respective contributions. Leveraging these neuron-wise rewards, our method then implements a greedy approach reinforcing helpful parts of the network and weakening harmful ones. While having comparable computational complexity to gradient descent, LFP does not require gradient computation and generates sparse and thereby memory- and energy-efficient parameter updates and models. We establish the convergence of LFP theoretically and empirically, demonstrating its effectiveness on various models and datasets. Via two applications - neural network pruning and the approximation-free training of Spiking Neural Networks (SNNs) - we demonstrate that LFP combines increased efficiency in terms of computation and representation with flexibility w.r.t. choice of model architecture and objective function. Our code is available at https://github.com/leanderweber/layerwise-feedback-propagation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2308.12053",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing multi-backends (TRT-LLM, vLLM) support for Text Generation Inference",
    "description": "",
    "summary": "Introducing multi-backends (TRT-LLM, vLLM) support for Text Generation Inference Introduction Since ...",
    "pubDate": "Thu, 16 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tgi-multi-backend",
    "thumbnail": "https://huggingface.co/blog/assets/tgi-multi-backend/thumbnail.png"
  },
  {
    "title": "GPT-4",
    "description": "We‚Äôve created GPT-4, the latest milestone in OpenAI‚Äôs effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.",
    "summary": "We‚Äôve created GPT-4, the latest milestone in OpenAI‚Äôs effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Point-E: A system for generating 3D point clouds from complex prompts",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 16 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/point-e",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Solving math word problems",
    "description": "We‚Äôve trained¬†a system that solves grade school math problems with nearly twice the accuracy of a fine-tuned GPT-3 model. It solves about 90% as many problems as real kids: a small sample of 9-12 year olds scored 60% on a test from our dataset, while our system scored 55% on those same problems.",
    "summary": "We‚Äôve trained¬†a system that solves grade school math problems with nearly twice the accuracy of a fine-tuned GPT-3 model. It solves about 90% as many problems as real kids: a small sample of 9-12 year olds scored 60% on a test from our dataset, while our system scored 55% on those same problems.",
    "pubDate": "Fri, 29 Oct 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/solving-math-word-problems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Simple considerations for simple people building fancy neural networks",
    "description": "",
    "summary": "üöß Simple considerations for simple people building fancy neural networks Photo by Henry & Co. on Uns...",
    "pubDate": "Thu, 25 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/simple-considerations",
    "thumbnail": "https://huggingface.co/blog/assets/13_simple-considerations/henry-co-3coKbdfnAFg-unsplash.jpg"
  },
  {
    "title": "Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series",
    "description": "arXiv:2506.10412v2 Announce Type: replace-cross Abstract: Time series data in real-world applications such as healthcare, climate modeling, and finance are often irregular, multimodal, and messy, with varying sampling rates, asynchronous modalities, and pervasive missingness. However, existing benchmarks typically assume clean, regularly sampled, unimodal data, creating a significant gap between research and real-world deployment. We introduce Time-IMM, a dataset specifically designed to capture cause-driven irregularity in multimodal multivariate time series. Time-IMM represents nine distinct types of time series irregularity, categorized into trigger-based, constraint-based, and artifact-based mechanisms. Complementing the dataset, we introduce IMM-TSF, a benchmark library for forecasting on irregular multimodal time series, enabling asynchronous integration and realistic evaluation. IMM-TSF includes specialized fusion modules, including a timestamp-to-text fusion module and a multimodality fusion module, which support both recency-aware averaging and attention-based integration strategies. Empirical results demonstrate that explicitly modeling multimodality on irregular time series data leads to substantial gains in forecasting performance. Time-IMM and IMM-TSF provide a foundation for advancing time series analysis under real-world conditions. The dataset is publicly available at https://www.kaggle.com/datasets/blacksnail789521/time-imm/data, and the benchmark library can be accessed at https://anonymous.4open.science/r/IMMTSF_NeurIPS2025.",
    "summary": "arXiv:2506.10412v2 Announce Type: replace-cross Abstract: Time series data in real-world applications such as healthcare, climate modeling, and finance are often irregular, multimodal, and messy, with varying sampling rates, asynchronous modalities, and pervasive missingness. However, existing benchmarks typically assume clean, regularly sampled, unimodal data, creating a significant gap between research and real-world deployment. We introduce Time-IMM, a dataset specifically designed to capture cause-driven irregularity in multimodal multivariate time series. Time-IMM represents nine distinct types of time series irregularity, categorized into trigger-based, constraint-based, and artifact-based mechanisms. Complementing the dataset, we introduce IMM-TSF, a benchmark library for forecasting on irregular multimodal time series, enabling asynchronous integration and realistic evaluation. IMM-TSF includes specialized fusion modules, including a timestamp-to-text fusion module and a multimodality fusion module, which support both recency-aware averaging and attention-based integration strategies. Empirical results demonstrate that explicitly modeling multimodality on irregular time series data leads to substantial gains in forecasting performance. Time-IMM and IMM-TSF provide a foundation for advancing time series analysis under real-world conditions. The dataset is publicly available at https://www.kaggle.com/datasets/blacksnail789521/time-imm/data, and the benchmark library can be accessed at https://anonymous.4open.science/r/IMMTSF_NeurIPS2025.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.10412",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "5 things from I/O to try right now",
    "description": "Collage on a dark background showing AI-generated media including humpback whales jumping from the water and the very detailed face of a chameleon",
    "summary": "Collage on a dark background showing AI-generated media including humpback whales jumping from the water and the very detailed face of a chameleon",
    "pubDate": "Thu, 12 Jun 2025 16:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/io-2025-tools-to-try-globally/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5_I_O_tools_ss.width-1300.png"
  },
  {
    "title": "Reinforcing Spatial Reasoning in Vision-Language Models with Interwoven Thinking and Visual Drawing",
    "description": "arXiv:2506.09965v2 Announce Type: replace-cross Abstract: As textual reasoning with large language models (LLMs) has advanced significantly, there has been growing interest in enhancing the multimodal reasoning capabilities of large vision-language models (LVLMs). However, existing methods primarily approach multimodal reasoning in a straightforward, text-centric manner, where both reasoning and answer derivation are conducted purely through text, with the only difference being the presence of multimodal input. As a result, these methods often encounter fundamental limitations in spatial reasoning tasks that demand precise geometric understanding and continuous spatial tracking-capabilities that humans achieve through mental visualization and manipulation. To address the limitations, we propose drawing to reason in space, a novel paradigm that enables LVLMs to reason through elementary drawing operations in the visual space. By equipping models with basic drawing operations, including annotating bounding boxes and drawing auxiliary lines, we empower them to express and analyze spatial relationships through direct visual manipulation, meanwhile avoiding the performance ceiling imposed by specialized perception tools in previous tool-integrated reasoning approaches. To cultivate this capability, we develop a three-stage training framework: cold-start training with synthetic data to establish basic drawing abilities, reflective rejection sampling to enhance self-reflection behaviors, and reinforcement learning to directly optimize for target rewards. Extensive experiments demonstrate that our model, named VILASR, consistently outperforms existing methods across diverse spatial reasoning benchmarks, involving maze navigation, static spatial reasoning, video-based reasoning, and multi-view-based reasoning tasks, with an average improvement of 18.4%.",
    "summary": "arXiv:2506.09965v2 Announce Type: replace-cross Abstract: As textual reasoning with large language models (LLMs) has advanced significantly, there has been growing interest in enhancing the multimodal reasoning capabilities of large vision-language models (LVLMs). However, existing methods primarily approach multimodal reasoning in a straightforward, text-centric manner, where both reasoning and answer derivation are conducted purely through text, with the only difference being the presence of multimodal input. As a result, these methods often encounter fundamental limitations in spatial reasoning tasks that demand precise geometric understanding and continuous spatial tracking-capabilities that humans achieve through mental visualization and manipulation. To address the limitations, we propose drawing to reason in space, a novel paradigm that enables LVLMs to reason through elementary drawing operations in the visual space. By equipping models with basic drawing operations, including annotating bounding boxes and drawing auxiliary lines, we empower them to express and analyze spatial relationships through direct visual manipulation, meanwhile avoiding the performance ceiling imposed by specialized perception tools in previous tool-integrated reasoning approaches. To cultivate this capability, we develop a three-stage training framework: cold-start training with synthetic data to establish basic drawing abilities, reflective rejection sampling to enhance self-reflection behaviors, and reinforcement learning to directly optimize for target rewards. Extensive experiments demonstrate that our model, named VILASR, consistently outperforms existing methods across diverse spatial reasoning benchmarks, involving maze navigation, static spatial reasoning, video-based reasoning, and multi-view-based reasoning tasks, with an average improvement of 18.4%.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.09965",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Plan for Speed -- Dilated Scheduling for Masked Diffusion Language Models",
    "description": "arXiv:2506.19037v1 Announce Type: cross Abstract: Masked diffusion language models (MDLM) have shown strong promise for non-autoregressive text generation, yet existing samplers act as implicit planners, selecting tokens to unmask via denoiser confidence or entropy scores. Such heuristics falter under parallel unmasking - they ignore pairwise interactions between tokens and cannot account for dependencies when unmasking multiple positions at once, limiting their inference time to traditional auto-regressive (AR) models. We introduce the Dilated-scheduled Unmasking Strategy (DUS), an inference-only, planner-model-free method that requires no additional training. DUS leverages a first-order Markov assumption to partition sequence positions into dilation-based groups of non-adjacent tokens, enabling independent, parallel unmasking steps that respect local context that minimizes the joint entropy of each iteration step. Unlike semi-AR block approaches (e.g., LLADA and Dream) that still invoke the denoiser per block, DUS reduces the number of denoiser calls to O(log B) per generation block - yielding substantial speedup over the O(B) run time of state-of-the-art diffusion models, where B is the block size in the semi-AR inference process. In experiments on math (GSM8K) and code completion (Humaneval, MBPP) benchmarks - domains suited to non-ordinal generation - DUS improves scores over parallel confidence-based planner, without modifying the underlying denoiser. DUS offers a lightweight, budget-aware approach to efficient, high-quality text generation, paving the way to unlock the true capabilities of MDLMs.",
    "summary": "arXiv:2506.19037v1 Announce Type: cross Abstract: Masked diffusion language models (MDLM) have shown strong promise for non-autoregressive text generation, yet existing samplers act as implicit planners, selecting tokens to unmask via denoiser confidence or entropy scores. Such heuristics falter under parallel unmasking - they ignore pairwise interactions between tokens and cannot account for dependencies when unmasking multiple positions at once, limiting their inference time to traditional auto-regressive (AR) models. We introduce the Dilated-scheduled Unmasking Strategy (DUS), an inference-only, planner-model-free method that requires no additional training. DUS leverages a first-order Markov assumption to partition sequence positions into dilation-based groups of non-adjacent tokens, enabling independent, parallel unmasking steps that respect local context that minimizes the joint entropy of each iteration step. Unlike semi-AR block approaches (e.g., LLADA and Dream) that still invoke the denoiser per block, DUS reduces the number of denoiser calls to O(log B) per generation block - yielding substantial speedup over the O(B) run time of state-of-the-art diffusion models, where B is the block size in the semi-AR inference process. In experiments on math (GSM8K) and code completion (Humaneval, MBPP) benchmarks - domains suited to non-ordinal generation - DUS improves scores over parallel confidence-based planner, without modifying the underlying denoiser. DUS offers a lightweight, budget-aware approach to efficient, high-quality text generation, paving the way to unlock the true capabilities of MDLMs.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19037",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Can foundation models label data like humans?",
    "description": "",
    "summary": "Can foundation models label data like humans? Since the advent of ChatGPT, we have seen unprecedente...",
    "pubDate": "Mon, 12 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-rlhf",
    "thumbnail": "https://huggingface.co/blog/assets/llm-leaderboard/leaderboard-thumbnail.png"
  },
  {
    "title": "Accelerate your models with ü§ó Optimum Intel and OpenVINO",
    "description": "",
    "summary": "Accelerate your models with ü§ó Optimum Intel and OpenVINO Last July, we announced that Intel and Hugg...",
    "pubDate": "Wed, 02 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/openvino",
    "thumbnail": "https://huggingface.co/blog/assets/113_openvino/thumbnail.png"
  },
  {
    "title": "Introducing BERTopic Integration with Hugging Face Hub",
    "description": "",
    "summary": "Introducing BERTopic Integration with the Hugging Face Hub We are thrilled to announce a significant...",
    "pubDate": "Wed, 31 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bertopic",
    "thumbnail": "https://huggingface.co/blog/assets/145_bertopic/logo.png"
  },
  {
    "title": "Director of Machine Learning Insights [Part 4]",
    "description": "",
    "summary": "Director of Machine Learning Insights [Part 4] If you're interested in building ML solutions faster ...",
    "pubDate": "Wed, 23 Nov 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-director-insights-4",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/part4.png"
  },
  {
    "title": "How to train a new language model from scratch using Transformers and Tokenizers",
    "description": "",
    "summary": "How to train a new language model from scratch using Transformers and Tokenizers Over the past few m...",
    "pubDate": "Fri, 14 Feb 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-train",
    "thumbnail": "https://huggingface.co/blog/assets/01_how-to-train/how-to-train_blogpost.png"
  },
  {
    "title": "FloorPlan-DeepSeek (FPDS): A multimodal approach to floorplan generation using vector-based next room prediction",
    "description": "arXiv:2506.21562v1 Announce Type: cross Abstract: In the architectural design process, floor plan generation is inherently progressive and iterative. However, existing generative models for floor plans are predominantly end-to-end generation that produce an entire pixel-based layout in a single pass. This paradigm is often incompatible with the incremental workflows observed in real-world architectural practice. To address this issue, we draw inspiration from the autoregressive 'next token prediction' mechanism commonly used in large language models, and propose a novel 'next room prediction' paradigm tailored to architectural floor plan modeling. Experimental evaluation indicates that FPDS demonstrates competitive performance in comparison to diffusion models and Tell2Design in the text-to-floorplan task, indicating its potential applicability in supporting future intelligent architectural design.",
    "summary": "arXiv:2506.21562v1 Announce Type: cross Abstract: In the architectural design process, floor plan generation is inherently progressive and iterative. However, existing generative models for floor plans are predominantly end-to-end generation that produce an entire pixel-based layout in a single pass. This paradigm is often incompatible with the incremental workflows observed in real-world architectural practice. To address this issue, we draw inspiration from the autoregressive 'next token prediction' mechanism commonly used in large language models, and propose a novel 'next room prediction' paradigm tailored to architectural floor plan modeling. Experimental evaluation indicates that FPDS demonstrates competitive performance in comparison to diffusion models and Tell2Design in the text-to-floorplan task, indicating its potential applicability in supporting future intelligent architectural design.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21562",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Transformers backend integration in SGLang",
    "description": "",
    "summary": "Transformers backend integration in SGLang Hugging Face transformers library is the standard for wor...",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/transformers-backend-sglang",
    "thumbnail": "https://huggingface.co/blog/assets/196_transformers_backend_sglang/thumbnail.jpg"
  },
  {
    "title": "New in ChatGPT for Business: April 2025",
    "description": "Watch hands-on demos of the lastest in ChatGPT for Business: o3, image generation, enhanced memory, and internal knowledge.",
    "summary": "Watch hands-on demos of the lastest in ChatGPT for Business: o3, image generation, enhanced memory, and internal knowledge.",
    "pubDate": "Thu, 24 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/new-in-chatgpt-for-business-april-updates-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Understanding BigBird's Block Sparse Attention",
    "description": "",
    "summary": "Understanding BigBird's Block Sparse Attention Introduction Transformer-based models have shown to b...",
    "pubDate": "Wed, 31 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/big-bird",
    "thumbnail": "https://huggingface.co/blog/assets/18_big_bird/attn.png"
  },
  {
    "title": "PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models",
    "description": "arXiv:2506.17667v3 Announce Type: replace Abstract: Physics problem-solving is a challenging domain for large AI models, requiring integration of conceptual understanding, mathematical reasoning, and interpretation of physical diagrams. Current evaluation methodologies show notable limitations in capturing the breadth and complexity of undergraduate-level physics, underscoring the need for more rigorous assessments. To this end, we present PhysUniBench, a large-scale multimodal benchmark designed to evaluate and improve the reasoning capabilities of multimodal large language models (MLLMs) specifically on undergraduate-level physics problems. PhysUniBench consists of 3,304 physics questions spanning 8 major sub-disciplines of physics, each accompanied by one visual diagrams. The benchmark includes both open-ended and multiple-choice questions, systematically curated and difficulty-rated through an iterative model-in-the-loop process. The benchmark's construction involved a rigorous multi-stage process, including multiple roll-outs, expert-level evaluation, automated filtering of easily solved problems, and a nuanced difficulty grading system with five levels. Through extensive experiments, we observe that current state-of-the-art models encounter substantial challenges in physics reasoning. For example, GPT-4o mini achieves only about 34.2% accuracy in the proposed PhysUniBench. These results highlight that current MLLMs struggle with advanced physics reasoning, especially on multi-step problems and those requiring precise diagram interpretation. By providing a broad and rigorous assessment tool, PhysUniBench aims to drive progress in AI for Science, encouraging the development of models with stronger physical reasoning, problem-solving skills, and multimodal understanding. The benchmark and evaluation scripts are available at https://prismax-team.github.io/PhysUniBenchmark/.",
    "summary": "arXiv:2506.17667v3 Announce Type: replace Abstract: Physics problem-solving is a challenging domain for large AI models, requiring integration of conceptual understanding, mathematical reasoning, and interpretation of physical diagrams. Current evaluation methodologies show notable limitations in capturing the breadth and complexity of undergraduate-level physics, underscoring the need for more rigorous assessments. To this end, we present PhysUniBench, a large-scale multimodal benchmark designed to evaluate and improve the reasoning capabilities of multimodal large language models (MLLMs) specifically on undergraduate-level physics problems. PhysUniBench consists of 3,304 physics questions spanning 8 major sub-disciplines of physics, each accompanied by one visual diagrams. The benchmark includes both open-ended and multiple-choice questions, systematically curated and difficulty-rated through an iterative model-in-the-loop process. The benchmark's construction involved a rigorous multi-stage process, including multiple roll-outs, expert-level evaluation, automated filtering of easily solved problems, and a nuanced difficulty grading system with five levels. Through extensive experiments, we observe that current state-of-the-art models encounter substantial challenges in physics reasoning. For example, GPT-4o mini achieves only about 34.2% accuracy in the proposed PhysUniBench. These results highlight that current MLLMs struggle with advanced physics reasoning, especially on multi-step problems and those requiring precise diagram interpretation. By providing a broad and rigorous assessment tool, PhysUniBench aims to drive progress in AI for Science, encouraging the development of models with stronger physical reasoning, problem-solving skills, and multimodal understanding. The benchmark and evaluation scripts are available at https://prismax-team.github.io/PhysUniBenchmark/.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17667",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Genmab launches ‚ÄúAI Everywhere‚Äù",
    "description": "Genmab embraces ChatGPT Enterprise, supported by OpenAI‚Äôs commitment to security and privacy",
    "summary": "Genmab embraces ChatGPT Enterprise, supported by OpenAI‚Äôs commitment to security and privacy",
    "pubDate": "Thu, 19 Sep 2024 04:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/genmab",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Exploring the Collaborative Co-Creation Process with AI: A Case Study in Novice Music Production",
    "description": "arXiv:2501.15276v2 Announce Type: replace-cross Abstract: Artificial intelligence is reshaping creative domains, yet its co-creative processes, especially in group settings with novice users, remain under explored. To bridge this gap, we conducted a case study in a college-level course where nine undergraduate students were tasked with creating three original music tracks using AI tools over 10 weeks. The study spanned the entire creative journey from ideation to releasing these songs on Spotify. Participants leveraged AI for music and lyric production, cover art, and distribution. Our findings highlight how AI transforms creative workflows: accelerating ideation but compressing the traditional preparation stage, and requiring novices to navigate a challenging idea selection and validation phase. We also identified a new 'collaging and refinement' stage, where participants creatively combined diverse AI-generated outputs into cohesive works. Furthermore, AI influenced group social dynamics and role division among human creators. Based on these insights, we propose the Human-AI Co-Creation Stage Model and the Human-AI Agency Model, offering new perspectives on collaborative co-creation with AI.",
    "summary": "arXiv:2501.15276v2 Announce Type: replace-cross Abstract: Artificial intelligence is reshaping creative domains, yet its co-creative processes, especially in group settings with novice users, remain under explored. To bridge this gap, we conducted a case study in a college-level course where nine undergraduate students were tasked with creating three original music tracks using AI tools over 10 weeks. The study spanned the entire creative journey from ideation to releasing these songs on Spotify. Participants leveraged AI for music and lyric production, cover art, and distribution. Our findings highlight how AI transforms creative workflows: accelerating ideation but compressing the traditional preparation stage, and requiring novices to navigate a challenging idea selection and validation phase. We also identified a new 'collaging and refinement' stage, where participants creatively combined diverse AI-generated outputs into cohesive works. Furthermore, AI influenced group social dynamics and role division among human creators. Based on these insights, we propose the Human-AI Co-Creation Stage Model and the Human-AI Agency Model, offering new perspectives on collaborative co-creation with AI.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.15276",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How AI is reshaping the future of healthcare and medical research",
    "description": "<p>Technologists Bill Gates and S√©bastien Bubeck discuss the state of generative AI in medicine, how access to ‚Äúmedical intelligence‚Äù might help empower people across healthcare, and how AI‚Äôs accelerating improvements are likely to affect both delivery and discovery.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/'>How AI is reshaping the future of healthcare and medical research</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>Technologists Bill Gates and S√©bastien Bubeck discuss the state of generative AI in medicine, how access to ‚Äúmedical intelligence‚Äù might help empower people across healthcare, and how AI‚Äôs accelerating improvements are likely to affect both delivery and discovery.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/'>How AI is reshaping the future of healthcare and medical research</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 12 Jun 2025 16:17:04 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "OSWorld-Human: Benchmarking the Efficiency of Computer-Use Agents",
    "description": "arXiv:2506.16042v1 Announce Type: new Abstract: Generative AI is being leveraged to solve a variety of computer-use tasks involving desktop applications. State-of-the-art systems have focused solely on improving accuracy on leading benchmarks. However, these systems are practically unusable due to extremely high end-to-end latency (e.g., tens of minutes) for tasks that typically take humans just a few minutes to complete. To understand the cause behind this and to guide future developments of computer agents, we conduct the first study on the temporal performance of computer-use agents on OSWorld, the flagship benchmark in computer-use AI. We find that large model calls for planning and reflection account for the majority of the overall latency, and as an agent uses more steps to complete a task, each successive step can take 3x longer than steps at the beginning of a task. We then construct OSWorld-Human, a manually annotated version of the original OSWorld dataset that contains a human-determined trajectory for each task. We evaluate 16 agents on their efficiency using OSWorld-Human and found that even the highest-scoring agents on OSWorld take 1.4-2.7x more steps than necessary.",
    "summary": "arXiv:2506.16042v1 Announce Type: new Abstract: Generative AI is being leveraged to solve a variety of computer-use tasks involving desktop applications. State-of-the-art systems have focused solely on improving accuracy on leading benchmarks. However, these systems are practically unusable due to extremely high end-to-end latency (e.g., tens of minutes) for tasks that typically take humans just a few minutes to complete. To understand the cause behind this and to guide future developments of computer agents, we conduct the first study on the temporal performance of computer-use agents on OSWorld, the flagship benchmark in computer-use AI. We find that large model calls for planning and reflection account for the majority of the overall latency, and as an agent uses more steps to complete a task, each successive step can take 3x longer than steps at the beginning of a task. We then construct OSWorld-Human, a manually annotated version of the original OSWorld dataset that contains a human-determined trajectory for each task. We evaluate 16 agents on their efficiency using OSWorld-Human and found that even the highest-scoring agents on OSWorld take 1.4-2.7x more steps than necessary.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16042",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Improvements to data analysis in ChatGPT",
    "description": "Improvements to data analysis in ChatGPT Interact with tables and charts and add files directly from Google Drive and Microsoft OneDrive.",
    "summary": "Improvements to data analysis in ChatGPT Interact with tables and charts and add files directly from Google Drive and Microsoft OneDrive.",
    "pubDate": "Thu, 16 May 2024 15:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improvements-to-data-analysis-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Idefics2: A Powerful 8B Vision-Language Model for the community",
    "description": "",
    "summary": "Introducing Idefics2: A Powerful 8B Vision-Language Model for the community We are excited to releas...",
    "pubDate": "Mon, 15 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/idefics2",
    "thumbnail": "https://huggingface.co/blog/assets/idefics/thumbnail.png"
  },
  {
    "title": "The Consistency Hypothesis in Uncertainty Quantification for Large Language Models",
    "description": "arXiv:2506.21849v1 Announce Type: cross Abstract: Estimating the confidence of large language model (LLM) outputs is essential for real-world applications requiring high user trust. Black-box uncertainty quantification (UQ) methods, relying solely on model API access, have gained popularity due to their practical benefits. In this paper, we examine the implicit assumption behind several UQ methods, which use generation consistency as a proxy for confidence, an idea we formalize as the consistency hypothesis. We introduce three mathematical statements with corresponding statistical tests to capture variations of this hypothesis and metrics to evaluate LLM output conformity across tasks. Our empirical investigation, spanning 8 benchmark datasets and 3 tasks (question answering, text summarization, and text-to-SQL), highlights the prevalence of the hypothesis under different settings. Among the statements, we highlight the `Sim-Any' hypothesis as the most actionable, and demonstrate how it can be leveraged by proposing data-free black-box UQ methods that aggregate similarities between generations for confidence estimation. These approaches can outperform the closest baselines, showcasing the practical value of the empirically observed consistency hypothesis.",
    "summary": "arXiv:2506.21849v1 Announce Type: cross Abstract: Estimating the confidence of large language model (LLM) outputs is essential for real-world applications requiring high user trust. Black-box uncertainty quantification (UQ) methods, relying solely on model API access, have gained popularity due to their practical benefits. In this paper, we examine the implicit assumption behind several UQ methods, which use generation consistency as a proxy for confidence, an idea we formalize as the consistency hypothesis. We introduce three mathematical statements with corresponding statistical tests to capture variations of this hypothesis and metrics to evaluate LLM output conformity across tasks. Our empirical investigation, spanning 8 benchmark datasets and 3 tasks (question answering, text summarization, and text-to-SQL), highlights the prevalence of the hypothesis under different settings. Among the statements, we highlight the `Sim-Any' hypothesis as the most actionable, and demonstrate how it can be leveraged by proposing data-free black-box UQ methods that aggregate similarities between generations for confidence estimation. These approaches can outperform the closest baselines, showcasing the practical value of the empirically observed consistency hypothesis.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21849",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gotta Learn Fast: A new benchmark for generalization in RL",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 10 Apr 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gotta-learn-fast",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing Triton: Open-source GPU programming for neural networks",
    "description": "We‚Äôre releasing Triton 1.0, an open-source Python-like programming language which enables researchers with no CUDA experience to write highly efficient GPU code‚Äîmost of the time on par with what an expert would be able to produce.",
    "summary": "We‚Äôre releasing Triton 1.0, an open-source Python-like programming language which enables researchers with no CUDA experience to write highly efficient GPU code‚Äîmost of the time on par with what an expert would be able to produce.",
    "pubDate": "Wed, 28 Jul 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/triton",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Five Benchmark: Results",
    "description": "Yesterday,¬†OpenAI Five¬†won a best-of-three against a team of 99.95th percentile Dota players:¬†Blitz,¬†Cap,¬†Fogged,¬†Merlini, and¬†MoonMeander‚Äîfour of whom have played Dota professionally‚Äîin front of a live audience and 100,000 concurrent livestream¬†viewers.",
    "summary": "Yesterday,¬†OpenAI Five¬†won a best-of-three against a team of 99.95th percentile Dota players:¬†Blitz,¬†Cap,¬†Fogged,¬†Merlini, and¬†MoonMeander‚Äîfour of whom have played Dota professionally‚Äîin front of a live audience and 100,000 concurrent livestream¬†viewers.",
    "pubDate": "Mon, 06 Aug 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-benchmark-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Behind ‚ÄúANCESTRA‚Äù: combining Veo with live-action filmmaking",
    "description": "We partnered with Darren Aronofsky, Eliza McNitt and a team of more than 200 people to make a film using Veo and live-action filmmaking.",
    "summary": "We partnered with Darren Aronofsky, Eliza McNitt and a team of more than 200 people to make a film using Veo and live-action filmmaking.",
    "pubDate": "Fri, 13 Jun 2025 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/behind-ancestra-combining-veo-with-live-action-filmmaking/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ancestra-YTThumbnail.width-1300.png"
  },
  {
    "title": "AlphaProteo generates novel proteins for biology and health research",
    "description": "New AI system designs proteins that successfully bind to target molecules, with potential for advancing drug design, disease understanding and more.",
    "summary": "New AI system designs proteins that successfully bind to target molecules, with potential for advancing drug design, disease understanding and more.",
    "pubDate": "Thu, 05 Sep 2024 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/",
    "thumbnail": "https://lh3.googleusercontent.com/7RKd6r-Wc8JfMau5x9knRq9DrOKGDwS3ye4YxY0jjWGntf74y8WL0lOlktJefxwkJYw33UEf2Ph_BhQ51TIufCxPkmtCPOpakekMpnOUwVI-3R6RzQ=w1200-h630-n-nu"
  },
  {
    "title": "HAWAII: Hierarchical Visual Knowledge Transfer for Efficient Vision-Language Models",
    "description": "arXiv:2506.19072v1 Announce Type: cross Abstract: Improving the visual understanding ability of vision-language models (VLMs) is crucial for enhancing their performance across various tasks. While using multiple pretrained visual experts has shown great promise, it often incurs significant computational costs during training and inference. To address this challenge, we propose HAWAII, a novel framework that distills knowledge from multiple visual experts into a single vision encoder, enabling it to inherit the complementary strengths of several experts with minimal computational overhead. To mitigate conflicts among different teachers and switch between different teacher-specific knowledge, instead of using a fixed set of adapters for multiple teachers, we propose to use teacher-specific Low-Rank Adaptation (LoRA) adapters with a corresponding router. Each adapter is aligned with a specific teacher, avoiding noisy guidance during distillation. To enable efficient knowledge distillation, we propose fine-grained and coarse-grained distillation. At the fine-grained level, token importance scores are employed to emphasize the most informative tokens from each teacher adaptively. At the coarse-grained level, we summarize the knowledge from multiple teachers and transfer it to the student using a set of general-knowledge LoRA adapters with a router. Extensive experiments on various vision-language tasks demonstrate the superiority of HAWAII, compared to the popular open-source VLMs.",
    "summary": "arXiv:2506.19072v1 Announce Type: cross Abstract: Improving the visual understanding ability of vision-language models (VLMs) is crucial for enhancing their performance across various tasks. While using multiple pretrained visual experts has shown great promise, it often incurs significant computational costs during training and inference. To address this challenge, we propose HAWAII, a novel framework that distills knowledge from multiple visual experts into a single vision encoder, enabling it to inherit the complementary strengths of several experts with minimal computational overhead. To mitigate conflicts among different teachers and switch between different teacher-specific knowledge, instead of using a fixed set of adapters for multiple teachers, we propose to use teacher-specific Low-Rank Adaptation (LoRA) adapters with a corresponding router. Each adapter is aligned with a specific teacher, avoiding noisy guidance during distillation. To enable efficient knowledge distillation, we propose fine-grained and coarse-grained distillation. At the fine-grained level, token importance scores are employed to emphasize the most informative tokens from each teacher adaptively. At the coarse-grained level, we summarize the knowledge from multiple teachers and transfer it to the student using a set of general-knowledge LoRA adapters with a router. Extensive experiments on various vision-language tasks demonstrate the superiority of HAWAII, compared to the popular open-source VLMs.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19072",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Alleviating User-Sensitive bias with Fair Generative Sequential Recommendation Model",
    "description": "arXiv:2506.19777v1 Announce Type: cross Abstract: Recommendation fairness has recently attracted much attention. In the real world, recommendation systems are driven by user behavior, and since users with the same sensitive feature (e.g., gender and age) tend to have the same patterns, recommendation models can easily capture the strong correlation preference of sensitive features and thus cause recommendation unfairness. Diffusion model (DM) as a new generative model paradigm has achieved great success in recommendation systems. DM's ability to model uncertainty and represent diversity, and its modeling mechanism has a high degree of adaptability with the real-world recommendation process with bias. Therefore, we use DM to effectively model the fairness of recommendation and enhance the diversity. This paper proposes a FairGENerative sequential Recommendation model based on DM, FairGENRec. In the training phase, we inject random noise into the original distribution under the guidance of the sensitive feature recognition model, and a sequential denoise model is designed for the reverse reconstruction of items. Simultaneously, recommendation fairness modeling is completed by injecting multi-interests representational information that eliminates the bias of sensitive user features into the generated results. In the inference phase, the model obtains the noise in the form of noise addition by using the history interactions which is followed by reverse iteration to reconstruct the target item representation. Finally, our extensive experiments on three datasets demonstrate the dual enhancement effect of FairGENRec on accuracy and fairness, while the statistical analysis of the cases visualizes the degree of improvement on the fairness of the recommendation.",
    "summary": "arXiv:2506.19777v1 Announce Type: cross Abstract: Recommendation fairness has recently attracted much attention. In the real world, recommendation systems are driven by user behavior, and since users with the same sensitive feature (e.g., gender and age) tend to have the same patterns, recommendation models can easily capture the strong correlation preference of sensitive features and thus cause recommendation unfairness. Diffusion model (DM) as a new generative model paradigm has achieved great success in recommendation systems. DM's ability to model uncertainty and represent diversity, and its modeling mechanism has a high degree of adaptability with the real-world recommendation process with bias. Therefore, we use DM to effectively model the fairness of recommendation and enhance the diversity. This paper proposes a FairGENerative sequential Recommendation model based on DM, FairGENRec. In the training phase, we inject random noise into the original distribution under the guidance of the sensitive feature recognition model, and a sequential denoise model is designed for the reverse reconstruction of items. Simultaneously, recommendation fairness modeling is completed by injecting multi-interests representational information that eliminates the bias of sensitive user features into the generated results. In the inference phase, the model obtains the noise in the form of noise addition by using the history interactions which is followed by reverse iteration to reconstruct the target item representation. Finally, our extensive experiments on three datasets demonstrate the dual enhancement effect of FairGENRec on accuracy and fairness, while the statistical analysis of the cases visualizes the degree of improvement on the fairness of the recommendation.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19777",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Language Models can perform Single-Utterance Self-Correction of Perturbed Reasoning",
    "description": "arXiv:2506.15894v1 Announce Type: cross Abstract: Large Language Models (LLMs) have demonstrated impressive mathematical reasoning capabilities, yet their performance remains brittle to minor variations in problem description and prompting strategy. Furthermore, reasoning is vulnerable to sampling-induced errors which autoregressive models must primarily address using self-correction via additionally-generated tokens. To better understand self-correction capabilities of recent models, we conduct experiments measuring models' ability to self-correct synthetic perturbations introduced into their Chain of Thought (CoT) reasoning. We observe robust single-utterance intrinsic self-correction behavior across a range of open-weight models and datasets, ranging from subtle, implicit corrections to explicit acknowledgments and corrections of errors. Our findings suggest that LLMs, including those not finetuned for long CoT, may possess stronger intrinsic self-correction capabilities than commonly shown in the literature. The presence of this ability suggests that recent 'reasoning' model work involves amplification of traits already meaningfully present in models.",
    "summary": "arXiv:2506.15894v1 Announce Type: cross Abstract: Large Language Models (LLMs) have demonstrated impressive mathematical reasoning capabilities, yet their performance remains brittle to minor variations in problem description and prompting strategy. Furthermore, reasoning is vulnerable to sampling-induced errors which autoregressive models must primarily address using self-correction via additionally-generated tokens. To better understand self-correction capabilities of recent models, we conduct experiments measuring models' ability to self-correct synthetic perturbations introduced into their Chain of Thought (CoT) reasoning. We observe robust single-utterance intrinsic self-correction behavior across a range of open-weight models and datasets, ranging from subtle, implicit corrections to explicit acknowledgments and corrections of errors. Our findings suggest that LLMs, including those not finetuned for long CoT, may possess stronger intrinsic self-correction capabilities than commonly shown in the literature. The presence of this ability suggests that recent 'reasoning' model work involves amplification of traits already meaningfully present in models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15894",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "College students and ChatGPT adoption in the US",
    "description": "A look into state-by-state adoption and how gaps might impact workforce readiness.",
    "summary": "A look into state-by-state adoption and how gaps might impact workforce readiness.",
    "pubDate": "Thu, 20 Feb 2025 06:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/college-students-and-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Perspective-Shifted Neuro-Symbolic World Models: A Framework for Socially-Aware Robot Navigation",
    "description": "arXiv:2503.20425v2 Announce Type: replace Abstract: Navigating in environments alongside humans requires agents to reason under uncertainty and account for the beliefs and intentions of those around them. Under a sequential decision-making framework, egocentric navigation can naturally be represented as a Markov Decision Process (MDP). However, social navigation additionally requires reasoning about the hidden beliefs of others, inherently leading to a Partially Observable Markov Decision Process (POMDP), where agents lack direct access to others' mental states. Inspired by Theory of Mind and Epistemic Planning, we propose (1) a neuro-symbolic model-based reinforcement learning architecture for social navigation, addressing the challenge of belief tracking in partially observable environments; and (2) a perspective-shift operator for belief estimation, leveraging recent work on Influence-based Abstractions (IBA) in structured multi-agent settings.",
    "summary": "arXiv:2503.20425v2 Announce Type: replace Abstract: Navigating in environments alongside humans requires agents to reason under uncertainty and account for the beliefs and intentions of those around them. Under a sequential decision-making framework, egocentric navigation can naturally be represented as a Markov Decision Process (MDP). However, social navigation additionally requires reasoning about the hidden beliefs of others, inherently leading to a Partially Observable Markov Decision Process (POMDP), where agents lack direct access to others' mental states. Inspired by Theory of Mind and Epistemic Planning, we propose (1) a neuro-symbolic model-based reinforcement learning architecture for social navigation, addressing the challenge of belief tracking in partially observable environments; and (2) a perspective-shift operator for belief estimation, leveraging recent work on Influence-based Abstractions (IBA) in structured multi-agent settings.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.20425",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sparking a more productive company with ChatGPT Enterprise",
    "description": "Match Group uses ChatGPT Enterprise to spark creativity and impact.",
    "summary": "Match Group uses ChatGPT Enterprise to spark creativity and impact.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/match-group",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "From Token to Rhythm: A Multi-Scale Approach for ECG-Language Pretraining",
    "description": "arXiv:2506.21803v1 Announce Type: cross Abstract: Electrocardiograms (ECGs) play a vital role in monitoring cardiac health and diagnosing heart diseases. However, traditional deep learning approaches for ECG analysis rely heavily on large-scale manual annotations, which are both time-consuming and resource-intensive to obtain. To overcome this limitation, self-supervised learning (SSL) has emerged as a promising alternative, enabling the extraction of robust ECG representations that can be efficiently transferred to various downstream tasks. While previous studies have explored SSL for ECG pretraining and multi-modal ECG-language alignment, they often fail to capture the multi-scale nature of ECG signals. As a result, these methods struggle to learn generalized representations due to their inability to model the hierarchical structure of ECG data. To address this gap, we introduce MELP, a novel Multi-scale ECG-Language Pretraining (MELP) model that fully leverages hierarchical supervision from ECG-text pairs. MELP first pretrains a cardiology-specific language model to enhance its understanding of clinical text. It then applies three levels of cross-modal supervision-at the token, beat, and rhythm levels-to align ECG signals with textual reports, capturing structured information across different time scales. We evaluate MELP on three public ECG datasets across multiple tasks, including zero-shot ECG classification, linear probing, and transfer learning. Experimental results demonstrate that MELP outperforms existing SSL methods, underscoring its effectiveness and adaptability across diverse clinical applications. Our code is available at https://github.com/HKU-MedAI/MELP.",
    "summary": "arXiv:2506.21803v1 Announce Type: cross Abstract: Electrocardiograms (ECGs) play a vital role in monitoring cardiac health and diagnosing heart diseases. However, traditional deep learning approaches for ECG analysis rely heavily on large-scale manual annotations, which are both time-consuming and resource-intensive to obtain. To overcome this limitation, self-supervised learning (SSL) has emerged as a promising alternative, enabling the extraction of robust ECG representations that can be efficiently transferred to various downstream tasks. While previous studies have explored SSL for ECG pretraining and multi-modal ECG-language alignment, they often fail to capture the multi-scale nature of ECG signals. As a result, these methods struggle to learn generalized representations due to their inability to model the hierarchical structure of ECG data. To address this gap, we introduce MELP, a novel Multi-scale ECG-Language Pretraining (MELP) model that fully leverages hierarchical supervision from ECG-text pairs. MELP first pretrains a cardiology-specific language model to enhance its understanding of clinical text. It then applies three levels of cross-modal supervision-at the token, beat, and rhythm levels-to align ECG signals with textual reports, capturing structured information across different time scales. We evaluate MELP on three public ECG datasets across multiple tasks, including zero-shot ECG classification, linear probing, and transfer learning. Experimental results demonstrate that MELP outperforms existing SSL methods, underscoring its effectiveness and adaptability across diverse clinical applications. Our code is available at https://github.com/HKU-MedAI/MELP.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21803",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How the voices for ChatGPT were chosen",
    "description": "How the voices for ChatGPT were chosen We worked with industry-leading casting and directing professionals to narrow down over 400 submissions before selecting the 5 voices.",
    "summary": "How the voices for ChatGPT were chosen We worked with industry-leading casting and directing professionals to narrow down over 400 submissions before selecting the 5 voices.",
    "pubDate": "Sun, 19 May 2024 23:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/how-the-voices-for-chatgpt-were-chosen",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Putting RL back in RLHF",
    "description": "",
    "summary": "Putting RL back in RLHF We are excited to introduce the RLOO (REINFORCE Leave One-Out) Trainer in TR...",
    "pubDate": "Wed, 12 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/putting_rl_back_in_rlhf_with_rloo",
    "thumbnail": "https://huggingface.co/blog/assets/putting_rl_back_in_rlhf_with_rloo/thumbnail.png"
  },
  {
    "title": "Scaling the OpenAI Academy",
    "description": "Online resource hub will support AI literacy and help people from all backgrounds access tools, best practices, and peer insights to use AI.",
    "summary": "Online resource hub will support AI literacy and help people from all backgrounds access tools, best practices, and peer insights to use AI.",
    "pubDate": "Tue, 25 Mar 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/scaling-the-openai-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety",
    "description": "arXiv:2506.22183v1 Announce Type: new Abstract: The rapid rise of open-weight and open-source foundation models is intensifying the obligation and reshaping the opportunity to make AI systems safe. This paper reports outcomes from the Columbia Convening on AI Openness and Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme involving more than forty-five researchers, engineers, and policy leaders from academia, industry, civil society, and government. Using a participatory, solutions-oriented process, the working groups produced (i) a research agenda at the intersection of safety and open source AI; (ii) a mapping of existing and needed technical interventions and open source tools to safely and responsibly deploy open foundation models across the AI development workflow; and (iii) a mapping of the content safety filter ecosystem with a proposed roadmap for future research and development. We find that openness -- understood as transparent weights, interoperable tooling, and public governance -- can enhance safety by enabling independent scrutiny, decentralized mitigation, and culturally plural oversight. However, significant gaps persist: scarce multimodal and multilingual benchmarks, limited defenses against prompt-injection and compositional attacks in agentic systems, and insufficient participatory mechanisms for communities most affected by AI harms. The paper concludes with a roadmap of five priority research directions, emphasizing participatory inputs, future-proof content filters, ecosystem-wide safety infrastructure, rigorous agentic safeguards, and expanded harm taxonomies. These recommendations informed the February 2025 French AI Action Summit and lay groundwork for an open, plural, and accountable AI safety discipline.",
    "summary": "arXiv:2506.22183v1 Announce Type: new Abstract: The rapid rise of open-weight and open-source foundation models is intensifying the obligation and reshaping the opportunity to make AI systems safe. This paper reports outcomes from the Columbia Convening on AI Openness and Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme involving more than forty-five researchers, engineers, and policy leaders from academia, industry, civil society, and government. Using a participatory, solutions-oriented process, the working groups produced (i) a research agenda at the intersection of safety and open source AI; (ii) a mapping of existing and needed technical interventions and open source tools to safely and responsibly deploy open foundation models across the AI development workflow; and (iii) a mapping of the content safety filter ecosystem with a proposed roadmap for future research and development. We find that openness -- understood as transparent weights, interoperable tooling, and public governance -- can enhance safety by enabling independent scrutiny, decentralized mitigation, and culturally plural oversight. However, significant gaps persist: scarce multimodal and multilingual benchmarks, limited defenses against prompt-injection and compositional attacks in agentic systems, and insufficient participatory mechanisms for communities most affected by AI harms. The paper concludes with a roadmap of five priority research directions, emphasizing participatory inputs, future-proof content filters, ecosystem-wide safety infrastructure, rigorous agentic safeguards, and expanded harm taxonomies. These recommendations informed the February 2025 French AI Action Summit and lay groundwork for an open, plural, and accountable AI safety discipline.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22183",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Preparing for malicious uses of AI",
    "description": "We‚Äôve co-authored a paper that forecasts how malicious actors could misuse AI technology, and potential ways we can prevent and mitigate these threats. This paper is the outcome of almost a year of sustained work with our colleagues at the Future of Humanity Institute, the Centre for the Study of Existential Risk, the Center for a New American Security, the Electronic Frontier Foundation, and others.",
    "summary": "We‚Äôve co-authored a paper that forecasts how malicious actors could misuse AI technology, and potential ways we can prevent and mitigate these threats. This paper is the outcome of almost a year of sustained work with our colleagues at the Future of Humanity Institute, the Centre for the Study of Existential Risk, the Center for a New American Security, the Electronic Frontier Foundation, and others.",
    "pubDate": "Tue, 20 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/preparing-for-malicious-uses-of-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2018: Final projects",
    "description": "Our first cohort of¬†OpenAI Scholars¬†has now completed the program.",
    "summary": "Our first cohort of¬†OpenAI Scholars¬†has now completed the program.",
    "pubDate": "Mon, 10 Sep 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2018-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "On the Feasibility of Poisoning Text-to-Image AI Models via Adversarial Mislabeling",
    "description": "arXiv:2506.21874v1 Announce Type: cross Abstract: Today's text-to-image generative models are trained on millions of images sourced from the Internet, each paired with a detailed caption produced by Vision-Language Models (VLMs). This part of the training pipeline is critical for supplying the models with large volumes of high-quality image-caption pairs during training. However, recent work suggests that VLMs are vulnerable to stealthy adversarial attacks, where adversarial perturbations are added to images to mislead the VLMs into producing incorrect captions. In this paper, we explore the feasibility of adversarial mislabeling attacks on VLMs as a mechanism to poisoning training pipelines for text-to-image models. Our experiments demonstrate that VLMs are highly vulnerable to adversarial perturbations, allowing attackers to produce benign-looking images that are consistently miscaptioned by the VLM models. This has the effect of injecting strong 'dirty-label' poison samples into the training pipeline for text-to-image models, successfully altering their behavior with a small number of poisoned samples. We find that while potential defenses can be effective, they can be targeted and circumvented by adaptive attackers. This suggests a cat-and-mouse game that is likely to reduce the quality of training data and increase the cost of text-to-image model development. Finally, we demonstrate the real-world effectiveness of these attacks, achieving high attack success (over 73%) even in black-box scenarios against commercial VLMs (Google Vertex AI and Microsoft Azure).",
    "summary": "arXiv:2506.21874v1 Announce Type: cross Abstract: Today's text-to-image generative models are trained on millions of images sourced from the Internet, each paired with a detailed caption produced by Vision-Language Models (VLMs). This part of the training pipeline is critical for supplying the models with large volumes of high-quality image-caption pairs during training. However, recent work suggests that VLMs are vulnerable to stealthy adversarial attacks, where adversarial perturbations are added to images to mislead the VLMs into producing incorrect captions. In this paper, we explore the feasibility of adversarial mislabeling attacks on VLMs as a mechanism to poisoning training pipelines for text-to-image models. Our experiments demonstrate that VLMs are highly vulnerable to adversarial perturbations, allowing attackers to produce benign-looking images that are consistently miscaptioned by the VLM models. This has the effect of injecting strong 'dirty-label' poison samples into the training pipeline for text-to-image models, successfully altering their behavior with a small number of poisoned samples. We find that while potential defenses can be effective, they can be targeted and circumvented by adaptive attackers. This suggests a cat-and-mouse game that is likely to reduce the quality of training data and increase the cost of text-to-image model development. Finally, we demonstrate the real-world effectiveness of these attacks, achieving high attack success (over 73%) even in black-box scenarios against commercial VLMs (Google Vertex AI and Microsoft Azure).",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21874",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Team update",
    "description": "We‚Äôve hired more great people to help us achieve our goals. Welcome, everyone!",
    "summary": "We‚Äôve hired more great people to help us achieve our goals. Welcome, everyone!",
    "pubDate": "Tue, 16 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update-august",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning to summarize with human feedback",
    "description": "We‚Äôve applied reinforcement learning from human feedback to train language models that are better at summarization.",
    "summary": "We‚Äôve applied reinforcement learning from human feedback to train language models that are better at summarization.",
    "pubDate": "Fri, 04 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-summarize-with-human-feedback",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Simplifying, stabilizing, and scaling continuous-time consistency models",
    "description": "We‚Äôve simplified, stabilized, and scaled continuous-time consistency models, achieving comparable sample quality to leading diffusion models, while using only two sampling steps.",
    "summary": "We‚Äôve simplified, stabilized, and scaled continuous-time consistency models, achieving comparable sample quality to leading diffusion models, while using only two sampling steps.",
    "pubDate": "Wed, 23 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/simplifying-stabilizing-and-scaling-continuous-time-consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Adaptive Experimental Design for Policy Learning",
    "description": "arXiv:2401.03756v4 Announce Type: replace-cross Abstract: This study investigates the contextual best arm identification (BAI) problem, aiming to design an adaptive experiment to identify the best treatment arm conditioned on contextual information (covariates). We consider a decision-maker who assigns treatment arms to experimental units during an experiment and recommends the estimated best treatment arm based on the contexts at the end of the experiment. The decision-maker uses a policy for recommendations, which is a function that provides the estimated best treatment arm given the contexts. In our evaluation, we focus on the worst-case expected regret, a relative measure between the expected outcomes of an optimal policy and our proposed policy. We derive a lower bound for the expected simple regret and then propose a strategy called Adaptive Sampling-Policy Learning (PLAS). We prove that this strategy is minimax rate-optimal in the sense that its leading factor in the regret upper bound matches the lower bound as the number of experimental units increases.",
    "summary": "arXiv:2401.03756v4 Announce Type: replace-cross Abstract: This study investigates the contextual best arm identification (BAI) problem, aiming to design an adaptive experiment to identify the best treatment arm conditioned on contextual information (covariates). We consider a decision-maker who assigns treatment arms to experimental units during an experiment and recommends the estimated best treatment arm based on the contexts at the end of the experiment. The decision-maker uses a policy for recommendations, which is a function that provides the estimated best treatment arm given the contexts. In our evaluation, we focus on the worst-case expected regret, a relative measure between the expected outcomes of an optimal policy and our proposed policy. We derive a lower bound for the expected simple regret and then propose a strategy called Adaptive Sampling-Policy Learning (PLAS). We prove that this strategy is minimax rate-optimal in the sense that its leading factor in the regret upper bound matches the lower bound as the number of experimental units increases.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2401.03756",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ChordPrompt: Orchestrating Cross-Modal Prompt Synergy for Multi-Domain Incremental Learning in CLIP",
    "description": "arXiv:2506.19608v1 Announce Type: new Abstract: Continual learning (CL) empowers pre-trained vision-language models to adapt effectively to novel or previously underrepresented data distributions without comprehensive retraining, enhancing their adaptability and efficiency. While vision-language models like CLIP show great promise, they struggle to maintain performance across domains in incremental learning scenarios. Existing prompt learning methods face two main limitations: 1) they primarily focus on class-incremental learning scenarios, lacking specific strategies for multi-domain task incremental learning; 2) most current approaches employ single-modal prompts, neglecting the potential benefits of cross-modal information exchange. To address these challenges, we propose the ChordPrompt framework, which facilitates a harmonious interplay between visual and textual prompts. ChordPrompt introduces cross-modal prompts to leverage interactions between visual and textual information. Our approach also employs domain-adaptive text prompts to select appropriate prompts for continual adaptation across multiple domains. Comprehensive experiments on multi-domain incremental learning benchmarks demonstrate that ChordPrompt outperforms state-of-the-art methods in zero-shot generalization and downstream task performance.",
    "summary": "arXiv:2506.19608v1 Announce Type: new Abstract: Continual learning (CL) empowers pre-trained vision-language models to adapt effectively to novel or previously underrepresented data distributions without comprehensive retraining, enhancing their adaptability and efficiency. While vision-language models like CLIP show great promise, they struggle to maintain performance across domains in incremental learning scenarios. Existing prompt learning methods face two main limitations: 1) they primarily focus on class-incremental learning scenarios, lacking specific strategies for multi-domain task incremental learning; 2) most current approaches employ single-modal prompts, neglecting the potential benefits of cross-modal information exchange. To address these challenges, we propose the ChordPrompt framework, which facilitates a harmonious interplay between visual and textual prompts. ChordPrompt introduces cross-modal prompts to leverage interactions between visual and textual information. Our approach also employs domain-adaptive text prompts to select appropriate prompts for continual adaptation across multiple domains. Comprehensive experiments on multi-domain incremental learning benchmarks demonstrate that ChordPrompt outperforms state-of-the-art methods in zero-shot generalization and downstream task performance.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19608",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Dual-Objective Reinforcement Learning with Novel Hamilton-Jacobi-Bellman Formulations",
    "description": "arXiv:2506.16016v1 Announce Type: new Abstract: Hard constraints in reinforcement learning (RL), whether imposed via the reward function or the model architecture, often degrade policy performance. Lagrangian methods offer a way to blend objectives with constraints, but often require intricate reward engineering and parameter tuning. In this work, we extend recent advances that connect Hamilton-Jacobi (HJ) equations with RL to propose two novel value functions for dual-objective satisfaction. Namely, we address: (1) the Reach-Always-Avoid problem - of achieving distinct reward and penalty thresholds - and (2) the Reach-Reach problem - of achieving thresholds of two distinct rewards. In contrast with temporal logic approaches, which typically involve representing an automaton, we derive explicit, tractable Bellman forms in this context by decomposing our problem into reach, avoid, and reach-avoid problems, as to leverage these aforementioned recent advances. From a mathematical perspective, the Reach-Always-Avoid and Reach-Reach problems are complementary and fundamentally different from standard sum-of-rewards problems and temporal logic problems, providing a new perspective on constrained decision-making. We leverage our analysis to propose a variation of Proximal Policy Optimization (DO-HJ-PPO), which solves these problems. Across a range of tasks for safe-arrival and multi-target achievement, we demonstrate that DO-HJ-PPO produces qualitatively distinct behaviors from previous approaches and out-competes a number of baselines in various metrics.",
    "summary": "arXiv:2506.16016v1 Announce Type: new Abstract: Hard constraints in reinforcement learning (RL), whether imposed via the reward function or the model architecture, often degrade policy performance. Lagrangian methods offer a way to blend objectives with constraints, but often require intricate reward engineering and parameter tuning. In this work, we extend recent advances that connect Hamilton-Jacobi (HJ) equations with RL to propose two novel value functions for dual-objective satisfaction. Namely, we address: (1) the Reach-Always-Avoid problem - of achieving distinct reward and penalty thresholds - and (2) the Reach-Reach problem - of achieving thresholds of two distinct rewards. In contrast with temporal logic approaches, which typically involve representing an automaton, we derive explicit, tractable Bellman forms in this context by decomposing our problem into reach, avoid, and reach-avoid problems, as to leverage these aforementioned recent advances. From a mathematical perspective, the Reach-Always-Avoid and Reach-Reach problems are complementary and fundamentally different from standard sum-of-rewards problems and temporal logic problems, providing a new perspective on constrained decision-making. We leverage our analysis to propose a variation of Proximal Policy Optimization (DO-HJ-PPO), which solves these problems. Across a range of tasks for safe-arrival and multi-target achievement, we demonstrate that DO-HJ-PPO produces qualitatively distinct behaviors from previous approaches and out-competes a number of baselines in various metrics.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16016",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fast and Distributed Equivariant Graph Neural Networks by Virtual Node Learning",
    "description": "arXiv:2506.19482v1 Announce Type: cross Abstract: Equivariant Graph Neural Networks (GNNs) have achieved remarkable success across diverse scientific applications. However, existing approaches face critical efficiency challenges when scaling to large geometric graphs and suffer significant performance degradation when the input graphs are sparsified for computational tractability. To address these limitations, we introduce FastEGNN and DistEGNN, two novel enhancements to equivariant GNNs for large-scale geometric graphs. FastEGNN employs a key innovation: a small ordered set of virtual nodes that effectively approximates the large unordered graph of real nodes. Specifically, we implement distinct message passing and aggregation mechanisms for different virtual nodes to ensure mutual distinctiveness, and minimize Maximum Mean Discrepancy (MMD) between virtual and real coordinates to achieve global distributedness. This design enables FastEGNN to maintain high accuracy while efficiently processing large-scale sparse graphs. For extremely large-scale geometric graphs, we present DistEGNN, a distributed extension where virtual nodes act as global bridges between subgraphs in different devices, maintaining consistency while dramatically reducing memory and computational overhead. We comprehensively evaluate our models across four challenging domains: N-body systems (100 nodes), protein dynamics (800 nodes), Water-3D (8,000 nodes), and our new Fluid113K benchmark (113,000 nodes). Results demonstrate superior efficiency and performance, establishing new capabilities in large-scale equivariant graph learning. Code is available at https://github.com/GLAD-RUC/DistEGNN.",
    "summary": "arXiv:2506.19482v1 Announce Type: cross Abstract: Equivariant Graph Neural Networks (GNNs) have achieved remarkable success across diverse scientific applications. However, existing approaches face critical efficiency challenges when scaling to large geometric graphs and suffer significant performance degradation when the input graphs are sparsified for computational tractability. To address these limitations, we introduce FastEGNN and DistEGNN, two novel enhancements to equivariant GNNs for large-scale geometric graphs. FastEGNN employs a key innovation: a small ordered set of virtual nodes that effectively approximates the large unordered graph of real nodes. Specifically, we implement distinct message passing and aggregation mechanisms for different virtual nodes to ensure mutual distinctiveness, and minimize Maximum Mean Discrepancy (MMD) between virtual and real coordinates to achieve global distributedness. This design enables FastEGNN to maintain high accuracy while efficiently processing large-scale sparse graphs. For extremely large-scale geometric graphs, we present DistEGNN, a distributed extension where virtual nodes act as global bridges between subgraphs in different devices, maintaining consistency while dramatically reducing memory and computational overhead. We comprehensively evaluate our models across four challenging domains: N-body systems (100 nodes), protein dynamics (800 nodes), Water-3D (8,000 nodes), and our new Fluid113K benchmark (113,000 nodes). Results demonstrate superior efficiency and performance, establishing new capabilities in large-scale equivariant graph learning. Code is available at https://github.com/GLAD-RUC/DistEGNN.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19482",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BLUR: A Benchmark for LLM Unlearning Robust to Forget-Retain Overlap",
    "description": "arXiv:2506.15699v1 Announce Type: cross Abstract: Machine unlearning has the potential to improve the safety of large language models (LLMs) by removing sensitive or harmful information post hoc. A key challenge in unlearning involves balancing between forget quality (effectively unlearning undesirable information) and retain quality (maintaining good performance on other, general tasks). Unfortunately, as we show, current LLM unlearning benchmarks contain highly disparate forget and retain sets -- painting a false picture of the effectiveness of LLM unlearning methods. This can be particularly problematic because it opens the door for benign perturbations, such as relearning attacks, to easily reveal supposedly unlearned knowledge once models are deployed. To address this, we present $texttt{BLUR}$: a benchmark for LLM unlearning that provides more realistic scenarios of forget-retain overlap. $texttt{BLUR}$ significantly expands on existing unlearning benchmarks by providing extended evaluation tasks, combined forget/retain queries, and relearning datasets of varying degrees of difficulty. Despite the benign nature of the queries considered, we find that the performance of existing methods drops significantly when evaluated on $texttt{BLUR}$, with simple approaches performing better on average than more recent methods. These results highlight the importance of robust evaluation and suggest several important directions of future study. Our benchmark is publicly available at: https://huggingface.co/datasets/forgelab/BLUR",
    "summary": "arXiv:2506.15699v1 Announce Type: cross Abstract: Machine unlearning has the potential to improve the safety of large language models (LLMs) by removing sensitive or harmful information post hoc. A key challenge in unlearning involves balancing between forget quality (effectively unlearning undesirable information) and retain quality (maintaining good performance on other, general tasks). Unfortunately, as we show, current LLM unlearning benchmarks contain highly disparate forget and retain sets -- painting a false picture of the effectiveness of LLM unlearning methods. This can be particularly problematic because it opens the door for benign perturbations, such as relearning attacks, to easily reveal supposedly unlearned knowledge once models are deployed. To address this, we present $texttt{BLUR}$: a benchmark for LLM unlearning that provides more realistic scenarios of forget-retain overlap. $texttt{BLUR}$ significantly expands on existing unlearning benchmarks by providing extended evaluation tasks, combined forget/retain queries, and relearning datasets of varying degrees of difficulty. Despite the benign nature of the queries considered, we find that the performance of existing methods drops significantly when evaluated on $texttt{BLUR}$, with simple approaches performing better on average than more recent methods. These results highlight the importance of robust evaluation and suggest several important directions of future study. Our benchmark is publicly available at: https://huggingface.co/datasets/forgelab/BLUR",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15699",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Voices of Her: Analyzing Gender Differences in the AI Publication World",
    "description": "arXiv:2305.14597v2 Announce Type: replace-cross Abstract: While several previous studies have analyzed gender bias in research, we are still missing a comprehensive analysis of gender differences in the AI community, covering diverse topics and different development trends. Using the AI Scholar dataset of 78K researchers in the field of AI, we identify several gender differences: (1) Although female researchers tend to have fewer overall citations than males, this citation difference does not hold for all academic-age groups; (2) There exist large gender homophily in co-authorship on AI papers; (3) Female first-authored papers show distinct linguistic styles, such as longer text, more positive emotion words, and more catchy titles than male first-authored papers. Our analysis provides a window into the current demographic trends in our AI community, and encourages more gender equality and diversity in the future. Our code and data are at https://github.com/causalNLP/ai-scholar-gender.",
    "summary": "arXiv:2305.14597v2 Announce Type: replace-cross Abstract: While several previous studies have analyzed gender bias in research, we are still missing a comprehensive analysis of gender differences in the AI community, covering diverse topics and different development trends. Using the AI Scholar dataset of 78K researchers in the field of AI, we identify several gender differences: (1) Although female researchers tend to have fewer overall citations than males, this citation difference does not hold for all academic-age groups; (2) There exist large gender homophily in co-authorship on AI papers; (3) Female first-authored papers show distinct linguistic styles, such as longer text, more positive emotion words, and more catchy titles than male first-authored papers. Our analysis provides a window into the current demographic trends in our AI community, and encourages more gender equality and diversity in the future. Our code and data are at https://github.com/causalNLP/ai-scholar-gender.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2305.14597",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Democratic inputs to AI",
    "description": "Our nonprofit organization, OpenAI, Inc., is launching a program to award ten $100,000 grants to fund experiments in setting up a democratic process for deciding what rules AI systems should follow, within the bounds defined by the law.",
    "summary": "Our nonprofit organization, OpenAI, Inc., is launching a program to award ten $100,000 grants to fund experiments in setting up a democratic process for deciding what rules AI systems should follow, within the bounds defined by the law.",
    "pubDate": "Thu, 25 May 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/democratic-inputs-to-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Journey to 1 Million Gradio Users!",
    "description": "",
    "summary": "Journey to 1 Million Gradio Users! 5 years ago, we launched Gradio as a simple Python library to let...",
    "pubDate": "Fri, 04 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradio-1m",
    "thumbnail": "https://huggingface.co/blog/assets/gradio-1m/thumbnail.png"
  },
  {
    "title": "Vision Language Models Explained",
    "description": "",
    "summary": "Vision Language Models Explained This blog post was written on April 2024 and provides a great intro...",
    "pubDate": "Thu, 11 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vlms",
    "thumbnail": "https://huggingface.co/blog/assets/vlms_explained/thumbnail.png"
  },
  {
    "title": "On CNF formulas irredundant with respect to unit clause propagation",
    "description": "arXiv:2309.01750v5 Announce Type: replace-cross Abstract: Two CNF formulas are called ucp-equivalent, if they behave in the same way with respect to the unit clause propagation (UCP). A formula is called ucp-irredundant, if removing any clause leads to a formula which is not ucp-equivalent to the original one. As a consequence of known results, the ratio of the size of a ucp-irredundant formula and the size of a smallest ucp-equivalent formula is at most $n^2$, where $n$ is the number of the variables. We demonstrate an example of a ucp-irredundant formula for a symmetric definite Horn function which is larger than a smallest ucp-equivalent formula by a factor $Omega(n/ln n)$. Consequently, a general upper bound on the above ratio cannot be smaller than this.",
    "summary": "arXiv:2309.01750v5 Announce Type: replace-cross Abstract: Two CNF formulas are called ucp-equivalent, if they behave in the same way with respect to the unit clause propagation (UCP). A formula is called ucp-irredundant, if removing any clause leads to a formula which is not ucp-equivalent to the original one. As a consequence of known results, the ratio of the size of a ucp-irredundant formula and the size of a smallest ucp-equivalent formula is at most $n^2$, where $n$ is the number of the variables. We demonstrate an example of a ucp-irredundant formula for a symmetric definite Horn function which is larger than a smallest ucp-equivalent formula by a factor $Omega(n/ln n)$. Consequently, a general upper bound on the above ratio cannot be smaller than this.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2309.01750",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„Éá„Ç£„Ç∫„Éã„Éº„Çâ„Å®‰øÇ‰∫â‰∏≠„ÅÆMidjourney„ÄÅÂãïÁîªÁîüÊàêAI„ÄåV1„ÄçÁô∫Ë°®„ÄÄÊúà10„Éâ„É´„Åã„Çâ„ÄÄ„Å©„Çì„Å™ÂãïÁîª„Åå‰Ωú„Çå„ÇãÔºü",
    "description": "ÁîªÂÉèÁîüÊàêAI„Çµ„Éº„Éì„Çπ„ÄåMidjourney„Äç„ÇíÊèê‰æõ„Åô„ÇãÁ±≥MidjourneyÁ§æ„ÅØ„ÄÅÂêåÁ§æÂàù„ÅÆÂãïÁîªÁîüÊàêAI„ÄåV1„Äç„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÁîªÂÉè„ÇíÂÖ•Âäõ„Åô„Çã„Å®„ÄÅ5Áßí„ÅÆÂãïÁîª„ÇíÁîüÊàê„Åô„Çã„ÄÇ„Åæ„Åö„ÅØÊúâÊñô„É¶„Éº„Ç∂„ÉºÂêë„Åë„Å´„ÄÅMidjourney„ÅÆWebÁâà„ÅßÊèê‰æõ„ÇíÂßã„ÇÅ„Çã„ÄÇ",
    "summary": "ÁîªÂÉèÁîüÊàêAI„Çµ„Éº„Éì„Çπ„ÄåMidjourney„Äç„ÇíÊèê‰æõ„Åô„ÇãÁ±≥MidjourneyÁ§æ„ÅØ„ÄÅÂêåÁ§æÂàù„ÅÆÂãïÁîªÁîüÊàêAI„ÄåV1„Äç„ÇíÁô∫Ë°®„Åó„Åü„ÄÇÁîªÂÉè„ÇíÂÖ•Âäõ„Åô„Çã„Å®„ÄÅ5Áßí„ÅÆÂãïÁîª„ÇíÁîüÊàê„Åô„Çã„ÄÇ„Åæ„Åö„ÅØÊúâÊñô„É¶„Éº„Ç∂„ÉºÂêë„Åë„Å´„ÄÅMidjourney„ÅÆWebÁâà„ÅßÊèê‰æõ„ÇíÂßã„ÇÅ„Çã„ÄÇ",
    "pubDate": "Thu, 19 Jun 2025 15:38:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/19/news073.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/19/cover_news073.jpg"
  },
  {
    "title": "Introducing ChatGPT Team",
    "description": "We‚Äôre launching a new ChatGPT plan for teams of all sizes, which provides a secure, collaborative workspace to get the most out of ChatGPT at work.",
    "summary": "We‚Äôre launching a new ChatGPT plan for teams of all sizes, which provides a secure, collaborative workspace to get the most out of ChatGPT at work.",
    "pubDate": "Wed, 10 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-team",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Summer at Hugging Face ‚òÄÔ∏è",
    "description": "",
    "summary": "Summer At Hugging Face üòé Summer is now officially over and these last few months have been quite bus...",
    "pubDate": "Fri, 24 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/summer-at-huggingface",
    "thumbnail": "https://huggingface.co/blog/assets/27_summer_at_huggingface/summer_intro.gif"
  },
  {
    "title": "DF2: Distribution-Free Decision-Focused Learning",
    "description": "arXiv:2308.05889v2 Announce Type: replace-cross Abstract: Decision-focused learning (DFL), which differentiates through the KKT conditions, has recently emerged as a powerful approach for predict-then-optimize problems. However, under probabilistic settings, DFL faces three major bottlenecks: model mismatch error, sample average approximation error, and gradient approximation error. Model mismatch error stems from the misalignment between the model's parameterized predictive distribution and the true probability distribution. Sample average approximation error arises when using finite samples to approximate the expected optimization objective. Gradient approximation error occurs when the objectives are non-convex and KKT conditions cannot be directly applied. In this paper, we present DF2, the first distribution-free decision-focused learning method designed to mitigate these three bottlenecks. Rather than depending on a task-specific forecaster that requires precise model assumptions, our method directly learns the expected optimization function during training. To efficiently learn this function in a data-driven manner, we devise an attention-based model architecture inspired by the distribution-based parameterization of the expected objective. We evaluate DF2 on two synthetic problems and three real-world problems, demonstrating the effectiveness of DF2. Our code is available at: https://github.com/Lingkai-Kong/DF2.",
    "summary": "arXiv:2308.05889v2 Announce Type: replace-cross Abstract: Decision-focused learning (DFL), which differentiates through the KKT conditions, has recently emerged as a powerful approach for predict-then-optimize problems. However, under probabilistic settings, DFL faces three major bottlenecks: model mismatch error, sample average approximation error, and gradient approximation error. Model mismatch error stems from the misalignment between the model's parameterized predictive distribution and the true probability distribution. Sample average approximation error arises when using finite samples to approximate the expected optimization objective. Gradient approximation error occurs when the objectives are non-convex and KKT conditions cannot be directly applied. In this paper, we present DF2, the first distribution-free decision-focused learning method designed to mitigate these three bottlenecks. Rather than depending on a task-specific forecaster that requires precise model assumptions, our method directly learns the expected optimization function during training. To efficiently learn this function in a data-driven manner, we devise an attention-based model architecture inspired by the distribution-based parameterization of the expected objective. We evaluate DF2 on two synthetic problems and three real-world problems, demonstrating the effectiveness of DF2. Our code is available at: https://github.com/Lingkai-Kong/DF2.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2308.05889",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI‚Äôs Economic Blueprint",
    "description": "OpenAI‚Äôs Economic Blueprint",
    "summary": "OpenAI‚Äôs Economic Blueprint",
    "pubDate": "Mon, 13 Jan 2025 03:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openais-economic-blueprint",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Autonomous Computer Vision Development with Agentic AI",
    "description": "arXiv:2506.11140v3 Announce Type: replace-cross Abstract: Agentic Artificial Intelligence (AI) systems leveraging Large Language Models (LLMs) exhibit significant potential for complex reasoning, planning, and tool utilization. We demonstrate that a specialized computer vision system can be built autonomously from a natural language prompt using Agentic AI methods. This involved extending SimpleMind (SM), an open-source Cognitive AI environment with configurable tools for medical image analysis, with an LLM-based agent, implemented using OpenManus, to automate the planning (tool configuration) for a particular computer vision task. We provide a proof-of-concept demonstration that an agentic system can interpret a computer vision task prompt, plan a corresponding SimpleMind workflow by decomposing the task and configuring appropriate tools. From the user input prompt, 'provide sm (SimpleMind) config for lungs, heart, and ribs segmentation for cxr (chest x-ray)'), the agent LLM was able to generate the plan (tool configuration file in YAML format), and execute SM-Learn (training) and SM-Think (inference) scripts autonomously. The computer vision agent automatically configured, trained, and tested itself on 50 chest x-ray images, achieving mean dice scores of 0.96, 0.82, 0.83, for lungs, heart, and ribs, respectively. This work shows the potential for autonomous planning and tool configuration that has traditionally been performed by a data scientist in the development of computer vision applications.",
    "summary": "arXiv:2506.11140v3 Announce Type: replace-cross Abstract: Agentic Artificial Intelligence (AI) systems leveraging Large Language Models (LLMs) exhibit significant potential for complex reasoning, planning, and tool utilization. We demonstrate that a specialized computer vision system can be built autonomously from a natural language prompt using Agentic AI methods. This involved extending SimpleMind (SM), an open-source Cognitive AI environment with configurable tools for medical image analysis, with an LLM-based agent, implemented using OpenManus, to automate the planning (tool configuration) for a particular computer vision task. We provide a proof-of-concept demonstration that an agentic system can interpret a computer vision task prompt, plan a corresponding SimpleMind workflow by decomposing the task and configuring appropriate tools. From the user input prompt, 'provide sm (SimpleMind) config for lungs, heart, and ribs segmentation for cxr (chest x-ray)'), the agent LLM was able to generate the plan (tool configuration file in YAML format), and execute SM-Learn (training) and SM-Think (inference) scripts autonomously. The computer vision agent automatically configured, trained, and tested itself on 50 chest x-ray images, achieving mean dice scores of 0.96, 0.82, 0.83, for lungs, heart, and ribs, respectively. This work shows the potential for autonomous planning and tool configuration that has traditionally been performed by a data scientist in the development of computer vision applications.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.11140",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Docmatix - a huge dataset for Document Visual Question Answering",
    "description": "",
    "summary": "Docmatix - A huge dataset for Document Visual Question Answering With this blog we are releasing Doc...",
    "pubDate": "Thu, 18 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/docmatix",
    "thumbnail": "https://huggingface.co/blog/assets/183_docmatix/thumbnail_new.png"
  },
  {
    "title": "REMOR: Automated Peer Review Generation with LLM Reasoning and Multi-Objective Reinforcement Learning",
    "description": "arXiv:2505.11718v2 Announce Type: replace Abstract: AI-based peer review systems tend to produce shallow and overpraising suggestions compared to human feedback. Here, we evaluate how well a reasoning LLM trained with multi-objective reinforcement learning (REMOR) can overcome these limitations. We start by designing a multi-aspect reward function that aligns with human evaluation of reviews. The aspects are related to the review itself (e.g., criticisms, novelty) and the relationship between the review and the manuscript (i.e., relevance). First, we perform supervised fine-tuning of DeepSeek-R1-Distill-Qwen-7B using LoRA on PeerRT, a new dataset of high-quality top AI conference reviews enriched with reasoning traces. We then apply Group Relative Policy Optimization (GRPO) to train two models: REMOR-H (with the human-aligned reward) and REMOR-U (with a uniform reward). Interestingly, the human-aligned reward penalizes aspects typically associated with strong reviews, leading REMOR-U to produce qualitatively more substantive feedback. Our results show that REMOR-U and REMOR-H achieve more than twice the average rewards of human reviews, non-reasoning state-of-the-art agentic multi-modal AI review systems, and general commercial LLM baselines. We found that while the best AI and human reviews are comparable in quality, REMOR avoids the long tail of low-quality human reviews. We discuss how reasoning is key to achieving these improvements and release the Human-aligned Peer Review Reward (HPRR) function, the Peer Review Reasoning-enriched Traces (PeerRT) dataset, and the REMOR models, which we believe can help spur progress in the area.",
    "summary": "arXiv:2505.11718v2 Announce Type: replace Abstract: AI-based peer review systems tend to produce shallow and overpraising suggestions compared to human feedback. Here, we evaluate how well a reasoning LLM trained with multi-objective reinforcement learning (REMOR) can overcome these limitations. We start by designing a multi-aspect reward function that aligns with human evaluation of reviews. The aspects are related to the review itself (e.g., criticisms, novelty) and the relationship between the review and the manuscript (i.e., relevance). First, we perform supervised fine-tuning of DeepSeek-R1-Distill-Qwen-7B using LoRA on PeerRT, a new dataset of high-quality top AI conference reviews enriched with reasoning traces. We then apply Group Relative Policy Optimization (GRPO) to train two models: REMOR-H (with the human-aligned reward) and REMOR-U (with a uniform reward). Interestingly, the human-aligned reward penalizes aspects typically associated with strong reviews, leading REMOR-U to produce qualitatively more substantive feedback. Our results show that REMOR-U and REMOR-H achieve more than twice the average rewards of human reviews, non-reasoning state-of-the-art agentic multi-modal AI review systems, and general commercial LLM baselines. We found that while the best AI and human reviews are comparable in quality, REMOR avoids the long tail of low-quality human reviews. We discuss how reasoning is key to achieving these improvements and release the Human-aligned Peer Review Reward (HPRR) function, the Peer Review Reasoning-enriched Traces (PeerRT) dataset, and the REMOR models, which we believe can help spur progress in the area.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.11718",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments",
    "description": "arXiv:2506.13205v2 Announce Type: replace-cross Abstract: With the growing integration of vision-language models (VLMs), mobile agents are now widely used for tasks like UI automation and camera-based user assistance. These agents are often fine-tuned on limited user-generated datasets, leaving them vulnerable to covert threats during the training process. In this work we present GHOST, the first clean-label backdoor attack specifically designed for mobile agents built upon VLMs. Our method manipulates only the visual inputs of a portion of the training samples - without altering their corresponding labels or instructions - thereby injecting malicious behaviors into the model. Once fine-tuned with this tampered data, the agent will exhibit attacker-controlled responses when a specific visual trigger is introduced at inference time. The core of our approach lies in aligning the gradients of poisoned samples with those of a chosen target instance, embedding backdoor-relevant features into the poisoned training data. To maintain stealth and enhance robustness, we develop three realistic visual triggers: static visual patches, dynamic motion cues, and subtle low-opacity overlays. We evaluate our method across six real-world Android apps and three VLM architectures adapted for mobile use. Results show that our attack achieves high attack success rates (up to 94.67 percent) while maintaining high clean-task performance (FSR up to 95.85 percent). Additionally, ablation studies shed light on how various design choices affect the efficacy and concealment of the attack. Overall, this work is the first to expose critical security flaws in VLM-based mobile agents, highlighting their susceptibility to clean-label backdoor attacks and the urgent need for effective defense mechanisms in their training pipelines.",
    "summary": "arXiv:2506.13205v2 Announce Type: replace-cross Abstract: With the growing integration of vision-language models (VLMs), mobile agents are now widely used for tasks like UI automation and camera-based user assistance. These agents are often fine-tuned on limited user-generated datasets, leaving them vulnerable to covert threats during the training process. In this work we present GHOST, the first clean-label backdoor attack specifically designed for mobile agents built upon VLMs. Our method manipulates only the visual inputs of a portion of the training samples - without altering their corresponding labels or instructions - thereby injecting malicious behaviors into the model. Once fine-tuned with this tampered data, the agent will exhibit attacker-controlled responses when a specific visual trigger is introduced at inference time. The core of our approach lies in aligning the gradients of poisoned samples with those of a chosen target instance, embedding backdoor-relevant features into the poisoned training data. To maintain stealth and enhance robustness, we develop three realistic visual triggers: static visual patches, dynamic motion cues, and subtle low-opacity overlays. We evaluate our method across six real-world Android apps and three VLM architectures adapted for mobile use. Results show that our attack achieves high attack success rates (up to 94.67 percent) while maintaining high clean-task performance (FSR up to 95.85 percent). Additionally, ablation studies shed light on how various design choices affect the efficacy and concealment of the attack. Overall, this work is the first to expose critical security flaws in VLM-based mobile agents, highlighting their susceptibility to clean-label backdoor attacks and the urgent need for effective defense mechanisms in their training pipelines.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.13205",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CodeAgents + Structure: A Better Way to Execute Actions",
    "description": "",
    "summary": "CodeAgents + Structure: A Better Way to Execute Actions Today we're sharing research that bridges tw...",
    "pubDate": "Wed, 28 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/structured-codeagent",
    "thumbnail": "https://huggingface.co/blog/assets/structured-codeagent/thumbnail-codeagent.png"
  },
  {
    "title": "Portraits: personalized AI coaching built alongside real experts",
    "description": "Kim Scott Portrait chat example",
    "summary": "Kim Scott Portrait chat example",
    "pubDate": "Thu, 05 Jun 2025 18:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/google-labs/portraits/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/portraits-hero.width-1300.png"
  },
  {
    "title": "AI for the board game Diplomacy",
    "description": "Successful communication and cooperation have been crucial for helping societies advance throughout history. The closed environments of board games can serve as a sandbox for modelling and investigating interaction and communication ‚Äì and we can learn a lot from playing them. In our recent paper, published today in Nature Communications, we show how artificial agents can use communication to better cooperate in the board game Diplomacy, a vibrant domain in artificial intelligence (AI) research, known for its focus on alliance building.",
    "summary": "Successful communication and cooperation have been crucial for helping societies advance throughout history. The closed environments of board games can serve as a sandbox for modelling and investigating interaction and communication ‚Äì and we can learn a lot from playing them. In our recent paper, published today in Nature Communications, we show how artificial agents can use communication to better cooperate in the board game Diplomacy, a vibrant domain in artificial intelligence (AI) research, known for its focus on alliance building.",
    "pubDate": "Tue, 06 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ai-for-the-board-game-diplomacy/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "Grammar and Gameplay-aligned RL for Game Description Generation with LLMs",
    "description": "arXiv:2503.15783v2 Announce Type: replace-cross Abstract: Game Description Generation (GDG) is the task of generating a game description written in a Game Description Language (GDL) from natural language text. Previous studies have explored generation methods leveraging the contextual understanding capabilities of Large Language Models (LLMs); however, accurately reproducing the game features of the game descriptions remains a challenge. In this paper, we propose reinforcement learning-based fine-tuning of LLMs for GDG (RLGDG). Our training method simultaneously improves grammatical correctness and fidelity to game concepts by introducing both grammar rewards and concept rewards. Furthermore, we adopt a two-stage training strategy where Reinforcement Learning (RL) is applied following Supervised Fine-Tuning (SFT). Experimental results demonstrate that our proposed method significantly outperforms baseline methods using SFT alone. Our code is available at https://github.com/tsunehiko/rlgdg",
    "summary": "arXiv:2503.15783v2 Announce Type: replace-cross Abstract: Game Description Generation (GDG) is the task of generating a game description written in a Game Description Language (GDL) from natural language text. Previous studies have explored generation methods leveraging the contextual understanding capabilities of Large Language Models (LLMs); however, accurately reproducing the game features of the game descriptions remains a challenge. In this paper, we propose reinforcement learning-based fine-tuning of LLMs for GDG (RLGDG). Our training method simultaneously improves grammatical correctness and fidelity to game concepts by introducing both grammar rewards and concept rewards. Furthermore, we adopt a two-stage training strategy where Reinforcement Learning (RL) is applied following Supervised Fine-Tuning (SFT). Experimental results demonstrate that our proposed method significantly outperforms baseline methods using SFT alone. Our code is available at https://github.com/tsunehiko/rlgdg",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.15783",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Fellows Fall 2018",
    "description": "We‚Äôre now accepting applications for the next cohort of OpenAI Fellows, a program which offers a compensated 6-month apprenticeship in AI research at OpenAI.",
    "summary": "We‚Äôre now accepting applications for the next cohort of OpenAI Fellows, a program which offers a compensated 6-month apprenticeship in AI research at OpenAI.",
    "pubDate": "Wed, 30 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-fellows",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Scholars 2018: Meet our Scholars",
    "description": "Our first class of¬†OpenAI Scholars¬†is underway, and¬†you can now follow along as this group¬†of experienced software developers becomes machine learning practitioners.",
    "summary": "Our first class of¬†OpenAI Scholars¬†is underway, and¬†you can now follow along as this group¬†of experienced software developers becomes machine learning practitioners.",
    "pubDate": "Wed, 25 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2018-meet-our-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Llama 2 on Amazon SageMaker a Benchmark",
    "description": "",
    "summary": "Llama 2 on Amazon SageMaker a Benchmark Deploying large language models (LLMs) and other generative ...",
    "pubDate": "Tue, 26 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama-sagemaker-benchmark",
    "thumbnail": "https://huggingface.co/blog/assets/llama_sagemaker_benchmark/thumbnail.jpg"
  },
  {
    "title": "OpenAI Scholars 2019: Meet our Scholars",
    "description": "Our class of eight¬†scholars¬†(out of 550 applicants) brings together collective expertise in literature, philosophy, cell biology, statistics, economics, quantum physics, and business innovation.",
    "summary": "Our class of eight¬†scholars¬†(out of 550 applicants) brings together collective expertise in literature, philosophy, cell biology, statistics, economics, quantum physics, and business innovation.",
    "pubDate": "Wed, 13 Mar 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019-meet-our-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SRFT: A Single-Stage Method with Supervised and Reinforcement Fine-Tuning for Reasoning",
    "description": "arXiv:2506.19767v1 Announce Type: cross Abstract: Large language models (LLMs) have achieved remarkable progress in reasoning tasks, yet the optimal integration of Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) remains a fundamental challenge. Through comprehensive analysis of token distributions, learning dynamics, and integration mechanisms from entropy-based perspectives, we reveal key differences between these paradigms: SFT induces coarse-grained global changes to LLM policy distributions, while RL performs fine-grained selective optimizations, with entropy serving as a critical indicator of training effectiveness. Building on these observations, we propose Supervised Reinforcement Fine-Tuning (SRFT), a single-stage method that unifies both fine-tuning paradigms through entropy-aware weighting mechanisms. Our approach simultaneously applies SFT and RL to directly optimize the LLM using demonstrations and self-exploration rollouts rather than through two-stage sequential methods. Extensive experiments show that SRFT achieves 59.1% average accuracy, outperforming zero-RL methods by 9.0% on five mathematical reasoning benchmarks and 10.9% on three out-of-distribution benchmarks.",
    "summary": "arXiv:2506.19767v1 Announce Type: cross Abstract: Large language models (LLMs) have achieved remarkable progress in reasoning tasks, yet the optimal integration of Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) remains a fundamental challenge. Through comprehensive analysis of token distributions, learning dynamics, and integration mechanisms from entropy-based perspectives, we reveal key differences between these paradigms: SFT induces coarse-grained global changes to LLM policy distributions, while RL performs fine-grained selective optimizations, with entropy serving as a critical indicator of training effectiveness. Building on these observations, we propose Supervised Reinforcement Fine-Tuning (SRFT), a single-stage method that unifies both fine-tuning paradigms through entropy-aware weighting mechanisms. Our approach simultaneously applies SFT and RL to directly optimize the LLM using demonstrations and self-exploration rollouts rather than through two-stage sequential methods. Extensive experiments show that SRFT achieves 59.1% average accuracy, outperforming zero-RL methods by 9.0% on five mathematical reasoning benchmarks and 10.9% on three out-of-distribution benchmarks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19767",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robust Behavior Cloning Via Global Lipschitz Regularization",
    "description": "arXiv:2506.19250v1 Announce Type: cross Abstract: Behavior Cloning (BC) is an effective imitation learning technique and has even been adopted in some safety-critical domains such as autonomous vehicles. BC trains a policy to mimic the behavior of an expert by using a dataset composed of only state-action pairs demonstrated by the expert, without any additional interaction with the environment. However, During deployment, the policy observations may contain measurement errors or adversarial disturbances. Since the observations may deviate from the true states, they can mislead the agent into making sub-optimal actions. In this work, we use a global Lipschitz regularization approach to enhance the robustness of the learned policy network. We then show that the resulting global Lipschitz property provides a robustness certificate to the policy with respect to different bounded norm perturbations. Then, we propose a way to construct a Lipschitz neural network that ensures the policy robustness. We empirically validate our theory across various environments in Gymnasium. Keywords: Robust Reinforcement Learning; Behavior Cloning; Lipschitz Neural Network",
    "summary": "arXiv:2506.19250v1 Announce Type: cross Abstract: Behavior Cloning (BC) is an effective imitation learning technique and has even been adopted in some safety-critical domains such as autonomous vehicles. BC trains a policy to mimic the behavior of an expert by using a dataset composed of only state-action pairs demonstrated by the expert, without any additional interaction with the environment. However, During deployment, the policy observations may contain measurement errors or adversarial disturbances. Since the observations may deviate from the true states, they can mislead the agent into making sub-optimal actions. In this work, we use a global Lipschitz regularization approach to enhance the robustness of the learned policy network. We then show that the resulting global Lipschitz property provides a robustness certificate to the policy with respect to different bounded norm perturbations. Then, we propose a way to construct a Lipschitz neural network that ensures the policy robustness. We empirically validate our theory across various environments in Gymnasium. Keywords: Robust Reinforcement Learning; Behavior Cloning; Lipschitz Neural Network",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19250",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evolving online forms into dynamic data",
    "description": "Typeform evolves online forms into dynamic and conversational data collection experiences with GPT-3.5 and GPT-4.",
    "summary": "Typeform evolves online forms into dynamic and conversational data collection experiences with GPT-3.5 and GPT-4.",
    "pubDate": "Wed, 11 Oct 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/typeform",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The AI tools for Art Newsletter - Issue 1",
    "description": "",
    "summary": "The AI tools for Art Newsletter First issue üéâ The AI space is moving so fast it‚Äôs hard to believe th...",
    "pubDate": "Fri, 31 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-art-newsletter-jan-25",
    "thumbnail": "https://huggingface.co/blog/assets/ai_art_newsletter_1/thumbnail.png"
  },
  {
    "title": "New and improved embedding model",
    "description": "We are excited to announce a new embedding model which is significantly more capable, cost effective, and simpler to use.",
    "summary": "We are excited to announce a new embedding model which is significantly more capable, cost effective, and simpler to use.",
    "pubDate": "Thu, 15 Dec 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-and-improved-embedding-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Reinforcement Fine-Tuned Large Language Models for Next POI Recommendation",
    "description": "arXiv:2506.21599v1 Announce Type: cross Abstract: Large language models (LLMs) have been adopted for next point-of-interest (POI) recommendation tasks. Typical LLM-based recommenders fall into two categories: prompt-based and supervised fine-tuning (SFT)-based models. Prompt-based models generally offer greater output flexibility but deliver lower accuracy, whereas SFT-based models achieve higher performance yet face a fundamental mismatch: next POI recommendation data does not naturally suit supervised fine-tuning. In SFT, the model is trained to reproduce the exact ground truth, but each training example provides only a single target POI, so there is no ground truth for producing a top-k list. To address this, we propose Refine-POI, a reinforcement fine-tuning framework for next POI recommendation. We introduce recommendation-driven rewards that enable LLMs to learn to generate top-k recommendation lists using only one ground-truth POI per example. Experiments on real-world datasets demonstrate that Refine-POI achieves state-of-the-art top-k recommendation performance.",
    "summary": "arXiv:2506.21599v1 Announce Type: cross Abstract: Large language models (LLMs) have been adopted for next point-of-interest (POI) recommendation tasks. Typical LLM-based recommenders fall into two categories: prompt-based and supervised fine-tuning (SFT)-based models. Prompt-based models generally offer greater output flexibility but deliver lower accuracy, whereas SFT-based models achieve higher performance yet face a fundamental mismatch: next POI recommendation data does not naturally suit supervised fine-tuning. In SFT, the model is trained to reproduce the exact ground truth, but each training example provides only a single target POI, so there is no ground truth for producing a top-k list. To address this, we propose Refine-POI, a reinforcement fine-tuning framework for next POI recommendation. We introduce recommendation-driven rewards that enable LLMs to learn to generate top-k recommendation lists using only one ground-truth POI per example. Experiments on real-world datasets demonstrate that Refine-POI achieves state-of-the-art top-k recommendation performance.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21599",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PaperBench: Evaluating AI‚Äôs Ability to Replicate AI Research",
    "description": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research.",
    "summary": "We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI research.",
    "pubDate": "Wed, 02 Apr 2025 10:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paperbench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Automated Skill Discovery for Language Agents through Exploration and Iterative Feedback",
    "description": "arXiv:2506.04287v2 Announce Type: replace Abstract: Training large language model (LLM) agents to acquire necessary skills and perform diverse tasks within an environment is gaining interest as a means to enable open-endedness. However, creating the training dataset for their skill acquisition faces several challenges. Manual trajectory collection requires significant human effort. Another approach, where LLMs directly propose tasks to learn, is often invalid, as the LLMs lack knowledge of which tasks are actually feasible. Moreover, the generated data may not provide a meaningful learning signal, as agents often already perform well on the proposed tasks. To address this, we propose a novel automatic skill discovery framework EXIF for LLM-powered agents, designed to improve the feasibility of generated target behaviors while accounting for the agents' capabilities. Our method adopts an exploration-first strategy by employing an exploration agent (Alice) to train the target agent (Bob) to learn essential skills in the environment. Specifically, Alice first interacts with the environment to retrospectively generate a feasible, environment-grounded skill dataset, which is then used to train Bob. Crucially, we incorporate an iterative feedback loop, where Alice evaluates Bob's performance to identify areas for improvement. This feedback then guides Alice's next round of exploration, forming a closed-loop data generation process. Experiments on Webshop and Crafter demonstrate EXIF's ability to effectively discover meaningful skills and iteratively expand the capabilities of the trained agent without any human intervention, achieving substantial performance improvements. Interestingly, we observe that setting Alice to the same model as Bob also notably improves performance, demonstrating EXIF's potential for building a self-evolving system.",
    "summary": "arXiv:2506.04287v2 Announce Type: replace Abstract: Training large language model (LLM) agents to acquire necessary skills and perform diverse tasks within an environment is gaining interest as a means to enable open-endedness. However, creating the training dataset for their skill acquisition faces several challenges. Manual trajectory collection requires significant human effort. Another approach, where LLMs directly propose tasks to learn, is often invalid, as the LLMs lack knowledge of which tasks are actually feasible. Moreover, the generated data may not provide a meaningful learning signal, as agents often already perform well on the proposed tasks. To address this, we propose a novel automatic skill discovery framework EXIF for LLM-powered agents, designed to improve the feasibility of generated target behaviors while accounting for the agents' capabilities. Our method adopts an exploration-first strategy by employing an exploration agent (Alice) to train the target agent (Bob) to learn essential skills in the environment. Specifically, Alice first interacts with the environment to retrospectively generate a feasible, environment-grounded skill dataset, which is then used to train Bob. Crucially, we incorporate an iterative feedback loop, where Alice evaluates Bob's performance to identify areas for improvement. This feedback then guides Alice's next round of exploration, forming a closed-loop data generation process. Experiments on Webshop and Crafter demonstrate EXIF's ability to effectively discover meaningful skills and iteratively expand the capabilities of the trained agent without any human intervention, achieving substantial performance improvements. Interestingly, we observe that setting Alice to the same model as Bob also notably improves performance, demonstrating EXIF's potential for building a self-evolving system.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.04287",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemini 2.5: Updates to our family of thinking models",
    "description": "Explore the latest Gemini 2.5 model updates with enhanced performance and accuracy: Gemini 2.5 Pro now stable, Flash generally available, and the new Flash-Lite in preview.",
    "summary": "Explore the latest Gemini 2.5 model updates with enhanced performance and accuracy: Gemini 2.5 Pro now stable, Flash generally available, and the new Flash-Lite in preview.",
    "pubDate": "Tue, 17 Jun 2025 16:03:39 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-25-updates-to-our-family-of-thinking-models/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-2-5-pro-meta_1.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Deploy MusicGen in no time with Inference Endpoints",
    "description": "",
    "summary": "Deploy MusicGen in no time with Inference Endpoints MusicGen is a powerful music generation model th...",
    "pubDate": "Fri, 04 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/run-musicgen-as-an-api",
    "thumbnail": "https://huggingface.co/blog/assets/run-musicgen-as-an-api/thumbnail.png"
  },
  {
    "title": "Assisted Generation: a new direction toward low-latency text generation",
    "description": "",
    "summary": "Assisted Generation: a new direction toward low-latency text generation Large language models are al...",
    "pubDate": "Thu, 11 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/assisted-generation",
    "thumbnail": "https://huggingface.co/blog/assets/assisted-generation/thumbnail.png"
  },
  {
    "title": "Custom instructions for ChatGPT",
    "description": "We‚Äôre rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
    "summary": "We‚Äôre rolling out custom instructions to give you more control over how ChatGPT responds. Set your preferences, and ChatGPT will keep them in mind for all future conversations.",
    "pubDate": "Thu, 20 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/custom-instructions-for-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "3Description: An Intuitive Human-AI Collaborative 3D Modeling Approach",
    "description": "arXiv:2506.21845v1 Announce Type: cross Abstract: This paper presents 3Description, an experimental human-AI collaborative approach for intuitive 3D modeling. 3Description aims to address accessibility and usability challenges in traditional 3D modeling by enabling non-professional individuals to co-create 3D models using verbal and gesture descriptions. Through a combination of qualitative research, product analysis, and user testing, 3Description integrates AI technologies such as Natural Language Processing and Computer Vision, powered by OpenAI and MediaPipe. Recognizing the web has wide cross-platform capabilities, 3Description is web-based, allowing users to describe the desired model and subsequently adjust its components using verbal and gestural inputs. In the era of AI and emerging media, 3Description not only contributes to a more inclusive and user-friendly design process, empowering more people to participate in the construction of the future 3D world, but also strives to increase human engagement in co-creation with AI, thereby avoiding undue surrender to technology and preserving human creativity.",
    "summary": "arXiv:2506.21845v1 Announce Type: cross Abstract: This paper presents 3Description, an experimental human-AI collaborative approach for intuitive 3D modeling. 3Description aims to address accessibility and usability challenges in traditional 3D modeling by enabling non-professional individuals to co-create 3D models using verbal and gesture descriptions. Through a combination of qualitative research, product analysis, and user testing, 3Description integrates AI technologies such as Natural Language Processing and Computer Vision, powered by OpenAI and MediaPipe. Recognizing the web has wide cross-platform capabilities, 3Description is web-based, allowing users to describe the desired model and subsequently adjust its components using verbal and gestural inputs. In the era of AI and emerging media, 3Description not only contributes to a more inclusive and user-friendly design process, empowering more people to participate in the construction of the future 3D world, but also strives to increase human engagement in co-creation with AI, thereby avoiding undue surrender to technology and preserving human creativity.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21845",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face and Google partner for open AI collaboration",
    "description": "",
    "summary": "Hugging Face and Google partner for open AI collaboration At Hugging Face, we want to enable all com...",
    "pubDate": "Thu, 25 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gcp-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/173_gcp-partnership/thumbnail.jpg"
  },
  {
    "title": "Multivariate Probabilistic Time Series Forecasting with Informer",
    "description": "",
    "summary": "Multivariate Probabilistic Time Series Forecasting with Informer Introduction A few months ago we in...",
    "pubDate": "Fri, 10 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/informer",
    "thumbnail": "https://huggingface.co/blog/assets/134_informer/thumbnail.png"
  },
  {
    "title": "The next chapter of our Gemini era",
    "description": "We're bringing Gemini to more Google products",
    "summary": "We're bringing Gemini to more Google products",
    "pubDate": "Thu, 08 Feb 2024 13:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-gemini-update-sundar-pichai-2024/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Keyword_Social_-_1920x1080.width-1300.png"
  },
  {
    "title": "New methods boost reasoning in small and large language models",
    "description": "<p>New techniques are reimagining how LLMs reason. By combining symbolic logic, mathematical rigor, and adaptive planning, these methods enable models to tackle complex, real-world problems across a variety of fields.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/'>New methods boost reasoning in small and large language models</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>New techniques are reimagining how LLMs reason. By combining symbolic logic, mathematical rigor, and adaptive planning, these methods enable models to tackle complex, real-world problems across a variety of fields.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/'>New methods boost reasoning in small and large language models</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Music AI Sandbox, now with new features and broader access",
    "description": "Helping music professionals explore the potential of generative AI",
    "summary": "Helping music professionals explore the potential of generative AI",
    "pubDate": "Thu, 24 Apr 2025 15:01:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/music-ai-sandbox-now-with-new-features-and-broader-access/",
    "thumbnail": "https://lh3.googleusercontent.com/t_n_87B373tBNlvzgBy7RuJXb5hoPdLtBBgWjzfJnVuauI0JFwiYAyGM_LMl-yeJ3zNWO782VBE8m6ByaxDJoIvIbWoQ_DQPMdxszprk5Tbh2xQx5Q=w1200-h630-n-nu"
  },
  {
    "title": "Welcome fastText to the ü§ó Hub",
    "description": "",
    "summary": "Welcome fastText to the Hugging Face Hub fastText is a library for efficient learning of text repres...",
    "pubDate": "Tue, 06 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fasttext",
    "thumbnail": "https://huggingface.co/blog/assets/147_fasttext/thumbnail.png"
  },
  {
    "title": "New Credit Facility Enhances Financial Flexibility",
    "description": "In addition to securing $6.6 billion in new funding from leading investors, we have established a new $4 billion credit facility with leading banks, including JPMorgan Chase, Citi, Goldman Sachs, Morgan Stanley, Santander, Wells Fargo, SMBC, UBS, and HSBC.",
    "summary": "In addition to securing $6.6 billion in new funding from leading investors, we have established a new $4 billion credit facility with leading banks, including JPMorgan Chase, Citi, Goldman Sachs, Morgan Stanley, Santander, Wells Fargo, SMBC, UBS, and HSBC.",
    "pubDate": "Thu, 03 Oct 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-credit-facility-enhances-financial-flexibility",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI achieves silver-medal standard solving International Mathematical Olympiad problems",
    "description": "Breakthrough models AlphaProof and AlphaGeometry 2 solve advanced reasoning problems in mathematics",
    "summary": "Breakthrough models AlphaProof and AlphaGeometry 2 solve advanced reasoning problems in mathematics",
    "pubDate": "Thu, 25 Jul 2024 15:29:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/",
    "thumbnail": "https://lh3.googleusercontent.com/2A21eFt7wdDrmMzzkenrCTuioLWGFdzU5Ao5dPH9yPtAw6QNHxZcDmoQA2_ZriU2gMjX8mzEOtfPbMCRuL5kVzLoz6efLgqT_foBXU3pxKBXTTOXXpc=w1200-h630-n-nu"
  },
  {
    "title": "Evaluating Language Model Bias with ü§ó Evaluate",
    "description": "",
    "summary": "Evaluating Language Model Bias with ü§ó Evaluate While the size and capabilities of large language mod...",
    "pubDate": "Mon, 24 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/evaluating-llm-bias",
    "thumbnail": "https://huggingface.co/blog/assets/112_evaluating-llm-bias/thumbnail.png"
  },
  {
    "title": "Deploying Speech-to-Speech on Hugging Face",
    "description": "",
    "summary": "Deploying Speech-to-Speech on Hugging Face Introduction Speech-to-Speech (S2S) is an exciting new pr...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/s2s_endpoint",
    "thumbnail": "https://huggingface.co/blog/assets/s2s_endpoint/thumbnail.png"
  },
  {
    "title": "Less Greedy Equivalence Search",
    "description": "arXiv:2506.22331v1 Announce Type: cross Abstract: Greedy Equivalence Search (GES) is a classic score-based algorithm for causal discovery from observational data. In the sample limit, it recovers the Markov equivalence class of graphs that describe the data. Still, it faces two challenges in practice: computational cost and finite-sample accuracy. In this paper, we develop Less Greedy Equivalence Search (LGES), a variant of GES that retains its theoretical guarantees while partially addressing these limitations. LGES modifies the greedy step: rather than always applying the highest-scoring insertion, it avoids edge insertions between variables for which the score implies some conditional independence. This more targeted search yields up to a (10)-fold speed-up and a substantial reduction in structural error relative to GES. Moreover, LGES can guide the search using prior assumptions, while correcting these assumptions when contradicted by the data. Finally, LGES can exploit interventional data to refine the learned observational equivalence class. We prove that LGES recovers the true equivalence class in the sample limit from observational and interventional data, even with misspecified prior assumptions. Experiments demonstrate that LGES outperforms GES and other baselines in speed, accuracy, and robustness to misspecified assumptions. Our code is available at https://github.com/CausalAILab/lges.",
    "summary": "arXiv:2506.22331v1 Announce Type: cross Abstract: Greedy Equivalence Search (GES) is a classic score-based algorithm for causal discovery from observational data. In the sample limit, it recovers the Markov equivalence class of graphs that describe the data. Still, it faces two challenges in practice: computational cost and finite-sample accuracy. In this paper, we develop Less Greedy Equivalence Search (LGES), a variant of GES that retains its theoretical guarantees while partially addressing these limitations. LGES modifies the greedy step: rather than always applying the highest-scoring insertion, it avoids edge insertions between variables for which the score implies some conditional independence. This more targeted search yields up to a (10)-fold speed-up and a substantial reduction in structural error relative to GES. Moreover, LGES can guide the search using prior assumptions, while correcting these assumptions when contradicted by the data. Finally, LGES can exploit interventional data to refine the learned observational equivalence class. We prove that LGES recovers the true equivalence class in the sample limit from observational and interventional data, even with misspecified prior assumptions. Experiments demonstrate that LGES outperforms GES and other baselines in speed, accuracy, and robustness to misspecified assumptions. Our code is available at https://github.com/CausalAILab/lges.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22331",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using generative AI to help robots jump higher and land safely",
    "description": "MIT CSAIL researchers combined GenAI and a physics simulation engine to refine robot designs. The result: a machine that out-jumped a robot designed by humans.",
    "summary": "MIT CSAIL researchers combined GenAI and a physics simulation engine to refine robot designs. The result: a machine that out-jumped a robot designed by humans.",
    "pubDate": "Fri, 27 Jun 2025 13:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/using-generative-ai-help-robots-jump-higher-land-safely-0627",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Jumping_Robot%20%285%29.png"
  },
  {
    "title": "Automated Detection of Pre-training Text in Black-box LLMs",
    "description": "arXiv:2506.19399v1 Announce Type: cross Abstract: Detecting whether a given text is a member of the pre-training data of Large Language Models (LLMs) is crucial for ensuring data privacy and copyright protection. Most existing methods rely on the LLM's hidden information (e.g., model parameters or token probabilities), making them ineffective in the black-box setting, where only input and output texts are accessible. Although some methods have been proposed for the black-box setting, they rely on massive manual efforts such as designing complicated questions or instructions. To address these issues, we propose VeilProbe, the first framework for automatically detecting LLMs' pre-training texts in a black-box setting without human intervention. VeilProbe utilizes a sequence-to-sequence mapping model to infer the latent mapping feature between the input text and the corresponding output suffix generated by the LLM. Then it performs the key token perturbations to obtain more distinguishable membership features. Additionally, considering real-world scenarios where the ground-truth training text samples are limited, a prototype-based membership classifier is introduced to alleviate the overfitting issue. Extensive evaluations on three widely used datasets demonstrate that our framework is effective and superior in the black-box setting.",
    "summary": "arXiv:2506.19399v1 Announce Type: cross Abstract: Detecting whether a given text is a member of the pre-training data of Large Language Models (LLMs) is crucial for ensuring data privacy and copyright protection. Most existing methods rely on the LLM's hidden information (e.g., model parameters or token probabilities), making them ineffective in the black-box setting, where only input and output texts are accessible. Although some methods have been proposed for the black-box setting, they rely on massive manual efforts such as designing complicated questions or instructions. To address these issues, we propose VeilProbe, the first framework for automatically detecting LLMs' pre-training texts in a black-box setting without human intervention. VeilProbe utilizes a sequence-to-sequence mapping model to infer the latent mapping feature between the input text and the corresponding output suffix generated by the LLM. Then it performs the key token perturbations to obtain more distinguishable membership features. Additionally, considering real-world scenarios where the ground-truth training text samples are limited, a prototype-based membership classifier is introduced to alleviate the overfitting issue. Extensive evaluations on three widely used datasets demonstrate that our framework is effective and superior in the black-box setting.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19399",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hope Speech Detection in code-mixed Roman Urdu tweets: A Positive Turn in Natural Language Processing",
    "description": "arXiv:2506.21583v1 Announce Type: cross Abstract: Hope is a positive emotional state involving the expectation of favorable future outcomes, while hope speech refers to communication that promotes optimism, resilience, and support, particularly in adverse contexts. Although hope speech detection has gained attention in Natural Language Processing (NLP), existing research mainly focuses on high-resource languages and standardized scripts, often overlooking informal and underrepresented forms such as Roman Urdu. To the best of our knowledge, this is the first study to address hope speech detection in code-mixed Roman Urdu by introducing a carefully annotated dataset, thereby filling a critical gap in inclusive NLP research for low-resource, informal language varieties. This study makes four key contributions: (1) it introduces the first multi-class annotated dataset for Roman Urdu hope speech, comprising Generalized Hope, Realistic Hope, Unrealistic Hope, and Not Hope categories; (2) it explores the psychological foundations of hope and analyzes its linguistic patterns in code-mixed Roman Urdu to inform dataset development; (3) it proposes a custom attention-based transformer model optimized for the syntactic and semantic variability of Roman Urdu, evaluated using 5-fold cross-validation; and (4) it verifies the statistical significance of performance gains using a t-test. The proposed model, XLM-R, achieves the best performance with a cross-validation score of 0.78, outperforming the baseline SVM (0.75) and BiLSTM (0.76), with gains of 4% and 2.63% respectively.",
    "summary": "arXiv:2506.21583v1 Announce Type: cross Abstract: Hope is a positive emotional state involving the expectation of favorable future outcomes, while hope speech refers to communication that promotes optimism, resilience, and support, particularly in adverse contexts. Although hope speech detection has gained attention in Natural Language Processing (NLP), existing research mainly focuses on high-resource languages and standardized scripts, often overlooking informal and underrepresented forms such as Roman Urdu. To the best of our knowledge, this is the first study to address hope speech detection in code-mixed Roman Urdu by introducing a carefully annotated dataset, thereby filling a critical gap in inclusive NLP research for low-resource, informal language varieties. This study makes four key contributions: (1) it introduces the first multi-class annotated dataset for Roman Urdu hope speech, comprising Generalized Hope, Realistic Hope, Unrealistic Hope, and Not Hope categories; (2) it explores the psychological foundations of hope and analyzes its linguistic patterns in code-mixed Roman Urdu to inform dataset development; (3) it proposes a custom attention-based transformer model optimized for the syntactic and semantic variability of Roman Urdu, evaluated using 5-fold cross-validation; and (4) it verifies the statistical significance of performance gains using a t-test. The proposed model, XLM-R, achieves the best performance with a cross-validation score of 0.78, outperforming the baseline SVM (0.75) and BiLSTM (0.76), with gains of 4% and 2.63% respectively.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21583",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Elucidating and Endowing the Diffusion Training Paradigm for General Image Restoration",
    "description": "arXiv:2506.21722v1 Announce Type: cross Abstract: While diffusion models demonstrate strong generative capabilities in image restoration (IR) tasks, their complex architectures and iterative processes limit their practical application compared to mainstream reconstruction-based general ordinary IR networks. Existing approaches primarily focus on optimizing network architecture and diffusion paths but overlook the integration of the diffusion training paradigm within general ordinary IR frameworks. To address these challenges, this paper elucidates key principles for adapting the diffusion training paradigm to general IR training through systematic analysis of time-step dependencies, network hierarchies, noise-level relationships, and multi-restoration task correlations, proposing a new IR framework supported by diffusion-based training. To enable IR networks to simultaneously restore images and model generative representations, we introduce a series of regularization strategies that align diffusion objectives with IR tasks, improving generalization in single-task scenarios. Furthermore, recognizing that diffusion-based generation exerts varying influences across different IR tasks, we develop an incremental training paradigm and task-specific adaptors, further enhancing performance in multi-task unified IR. Experiments demonstrate that our method significantly improves the generalization of IR networks in single-task IR and achieves superior performance in multi-task unified IR. Notably, the proposed framework can be seamlessly integrated into existing general IR architectures.",
    "summary": "arXiv:2506.21722v1 Announce Type: cross Abstract: While diffusion models demonstrate strong generative capabilities in image restoration (IR) tasks, their complex architectures and iterative processes limit their practical application compared to mainstream reconstruction-based general ordinary IR networks. Existing approaches primarily focus on optimizing network architecture and diffusion paths but overlook the integration of the diffusion training paradigm within general ordinary IR frameworks. To address these challenges, this paper elucidates key principles for adapting the diffusion training paradigm to general IR training through systematic analysis of time-step dependencies, network hierarchies, noise-level relationships, and multi-restoration task correlations, proposing a new IR framework supported by diffusion-based training. To enable IR networks to simultaneously restore images and model generative representations, we introduce a series of regularization strategies that align diffusion objectives with IR tasks, improving generalization in single-task scenarios. Furthermore, recognizing that diffusion-based generation exerts varying influences across different IR tasks, we develop an incremental training paradigm and task-specific adaptors, further enhancing performance in multi-task unified IR. Experiments demonstrate that our method significantly improves the generalization of IR networks in single-task IR and achieves superior performance in multi-task unified IR. Notably, the proposed framework can be seamlessly integrated into existing general IR architectures.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21722",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Conversational Intent-Driven GraphRAG: Enhancing Multi-Turn Dialogue Systems through Adaptive Dual-Retrieval of Flow Patterns and Context Semantics",
    "description": "arXiv:2506.19385v1 Announce Type: new Abstract: We present CID-GraphRAG (Conversational Intent-Driven Graph Retrieval Augmented Generation), a novel framework that addresses the limitations of existing dialogue systems in maintaining both contextual coherence and goal-oriented progression in multi-turn customer service conversations. Unlike traditional RAG systems that rely solely on semantic similarity (Conversation RAG) or standard knowledge graphs (GraphRAG), CID-GraphRAG constructs dynamic intent transition graphs from goal achieved historical dialogues and implements a dual-retrieval mechanism that adaptively balances intent-based graph traversal with semantic search. This approach enables the system to simultaneously leverage both conversional intent flow patterns and contextual semantics, significantly improving retrieval quality and response quality. In extensive experiments on real-world customer service dialogues, we employ both automatic metrics and LLM-as-judge assessments, demonstrating that CID-GraphRAG significantly outperforms both semantic-based Conversation RAG and intent-based GraphRAG baselines across all evaluation criteria. Quantitatively, CID-GraphRAG demonstrates substantial improvements over Conversation RAG across automatic metrics, with relative gains of 11% in BLEU, 5% in ROUGE-L, 6% in METEOR, and most notably, a 58% improvement in response quality according to LLM-as-judge evaluations. These results demonstrate that the integration of intent transition structures with semantic retrieval creates a synergistic effect that neither approach achieves independently, establishing CID-GraphRAG as an effective framework for addressing the challenges of maintaining contextual coherence and goal-oriented progression in knowledge-intensive multi-turn dialogues.",
    "summary": "arXiv:2506.19385v1 Announce Type: new Abstract: We present CID-GraphRAG (Conversational Intent-Driven Graph Retrieval Augmented Generation), a novel framework that addresses the limitations of existing dialogue systems in maintaining both contextual coherence and goal-oriented progression in multi-turn customer service conversations. Unlike traditional RAG systems that rely solely on semantic similarity (Conversation RAG) or standard knowledge graphs (GraphRAG), CID-GraphRAG constructs dynamic intent transition graphs from goal achieved historical dialogues and implements a dual-retrieval mechanism that adaptively balances intent-based graph traversal with semantic search. This approach enables the system to simultaneously leverage both conversional intent flow patterns and contextual semantics, significantly improving retrieval quality and response quality. In extensive experiments on real-world customer service dialogues, we employ both automatic metrics and LLM-as-judge assessments, demonstrating that CID-GraphRAG significantly outperforms both semantic-based Conversation RAG and intent-based GraphRAG baselines across all evaluation criteria. Quantitatively, CID-GraphRAG demonstrates substantial improvements over Conversation RAG across automatic metrics, with relative gains of 11% in BLEU, 5% in ROUGE-L, 6% in METEOR, and most notably, a 58% improvement in response quality according to LLM-as-judge evaluations. These results demonstrate that the integration of intent transition structures with semantic retrieval creates a synergistic effect that neither approach achieves independently, establishing CID-GraphRAG as an effective framework for addressing the challenges of maintaining contextual coherence and goal-oriented progression in knowledge-intensive multi-turn dialogues.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19385",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A hazard analysis framework for code synthesis large language models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-hazard-analysis-framework-for-code-synthesis-large-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy Embedding Models with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Deploy Embedding Models with Hugging Face Inference Endpoints The rise of Generative AI and LLMs lik...",
    "pubDate": "Tue, 24 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/168_inference_endpoints_embeddings/thumbnail.jpg"
  },
  {
    "title": "Introducing Gemini: our largest and most capable AI model",
    "description": "Making AI more helpful for everyone",
    "summary": "Making AI more helpful for everyone",
    "pubDate": "Wed, 06 Dec 2023 15:13:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-our-largest-and-most-capable-ai-model/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini_SS.width-1300.jpg"
  },
  {
    "title": "Fine-Tune ViT for Image Classification with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune ViT for Image Classification with ü§ó Transformers Just as transformers-based models have re...",
    "pubDate": "Fri, 11 Feb 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-vit",
    "thumbnail": "https://huggingface.co/blog/assets/51_fine_tune_vit/vit-thumbnail.jpg"
  },
  {
    "title": "Introducing the Enterprise Scenarios Leaderboard: a Leaderboard for Real World Use Cases",
    "description": "",
    "summary": "Introducing the Enterprise Scenarios Leaderboard: a Leaderboard for Real World Use Cases Today, the ...",
    "pubDate": "Wed, 31 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-patronus",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_patronus.png"
  },
  {
    "title": "MOST: MR reconstruction Optimization for multiple downStream Tasks via continual learning",
    "description": "arXiv:2409.10394v3 Announce Type: replace-cross Abstract: Deep learning-based Magnetic Resonance (MR) reconstruction methods have focused on generating high-quality images but often overlook the impact on downstream tasks (e.g., segmentation) that utilize the reconstructed images. Cascading separately trained reconstruction network and downstream task network has been shown to introduce performance degradation due to error propagation and domain gaps between training datasets. To mitigate this issue, downstream task-oriented reconstruction optimization has been proposed for a single downstream task. Expanding this optimization to multi-task scenarios is not straightforward. In this work, we extended this optimization to sequentially introduced multiple downstream tasks and demonstrated that a single MR reconstruction network can be optimized for multiple downstream tasks by deploying continual learning (MOST). MOST integrated techniques from replay-based continual learning and image-guided loss to overcome catastrophic forgetting. Comparative experiments demonstrated that MOST outperformed a reconstruction network without finetuning, a reconstruction network with na'ive finetuning, and conventional continual learning methods. The source code is available at: https://github.com/SNU-LIST/MOST.",
    "summary": "arXiv:2409.10394v3 Announce Type: replace-cross Abstract: Deep learning-based Magnetic Resonance (MR) reconstruction methods have focused on generating high-quality images but often overlook the impact on downstream tasks (e.g., segmentation) that utilize the reconstructed images. Cascading separately trained reconstruction network and downstream task network has been shown to introduce performance degradation due to error propagation and domain gaps between training datasets. To mitigate this issue, downstream task-oriented reconstruction optimization has been proposed for a single downstream task. Expanding this optimization to multi-task scenarios is not straightforward. In this work, we extended this optimization to sequentially introduced multiple downstream tasks and demonstrated that a single MR reconstruction network can be optimized for multiple downstream tasks by deploying continual learning (MOST). MOST integrated techniques from replay-based continual learning and image-guided loss to overcome catastrophic forgetting. Comparative experiments demonstrated that MOST outperformed a reconstruction network without finetuning, a reconstruction network with na'ive finetuning, and conventional continual learning methods. The source code is available at: https://github.com/SNU-LIST/MOST.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2409.10394",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI o3-mini System Card",
    "description": "This report outlines the safety work carried out for the OpenAI o3-mini model, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
    "summary": "This report outlines the safety work carried out for the OpenAI o3-mini model, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
    "pubDate": "Fri, 31 Jan 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-mini-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Red-Teaming Resistance Leaderboard",
    "description": "",
    "summary": "Introducing the Red-Teaming Resistance Leaderboard Content warning: since this blog post is about a ...",
    "pubDate": "Fri, 23 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-haizelab",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_haizelab.png"
  },
  {
    "title": "ECG-SMART-NET: A Deep Learning Architecture for Precise ECG Diagnosis of Occlusion Myocardial Infarction",
    "description": "arXiv:2405.09567v2 Announce Type: replace-cross Abstract: Objective: In this paper we develop and evaluate ECG-SMART-NET for occlusion myocardial infarction (OMI) identification. OMI is a severe form of heart attack characterized by complete blockage of one or more coronary arteries requiring immediate referral for cardiac catheterization to restore blood flow to the heart. Two thirds of OMI cases are difficult to visually identify from a 12-lead electrocardiogram (ECG) and can be potentially fatal if not identified quickly. Previous works on this topic are scarce, and current state-of-the-art evidence suggests both feature-based random forests and convolutional neural networks (CNNs) are promising approaches to improve ECG detection of OMI. Methods: While the ResNet architecture has been adapted for use with ECG recordings, it is not ideally suited to capture informative temporal features within each lead and the spatial concordance or discordance across leads. We propose a clinically informed modification of the ResNet-18 architecture. The model first learns temporal features through temporal convolutional layers with 1xk kernels followed by a spatial convolutional layer, after the residual blocks, with 12x1 kernels to learn spatial features. Results: ECG-SMART-NET was benchmarked against the original ResNet-18 and other state-of-the-art models on a multisite real-word clinical dataset that consists of 10,393 ECGs from 7,397 unique patients (rate of OMI =7.2%). ECG-SMART-NET outperformed other models in the classification of OMI with a test AUC of 0.953 [0.921, 0.978]. Conclusion and Significance: ECG-SMART-NET can outperform the state-of-the-art random forest for OMI prediction and is better suited for this task than the original ResNet-18 architecture.",
    "summary": "arXiv:2405.09567v2 Announce Type: replace-cross Abstract: Objective: In this paper we develop and evaluate ECG-SMART-NET for occlusion myocardial infarction (OMI) identification. OMI is a severe form of heart attack characterized by complete blockage of one or more coronary arteries requiring immediate referral for cardiac catheterization to restore blood flow to the heart. Two thirds of OMI cases are difficult to visually identify from a 12-lead electrocardiogram (ECG) and can be potentially fatal if not identified quickly. Previous works on this topic are scarce, and current state-of-the-art evidence suggests both feature-based random forests and convolutional neural networks (CNNs) are promising approaches to improve ECG detection of OMI. Methods: While the ResNet architecture has been adapted for use with ECG recordings, it is not ideally suited to capture informative temporal features within each lead and the spatial concordance or discordance across leads. We propose a clinically informed modification of the ResNet-18 architecture. The model first learns temporal features through temporal convolutional layers with 1xk kernels followed by a spatial convolutional layer, after the residual blocks, with 12x1 kernels to learn spatial features. Results: ECG-SMART-NET was benchmarked against the original ResNet-18 and other state-of-the-art models on a multisite real-word clinical dataset that consists of 10,393 ECGs from 7,397 unique patients (rate of OMI =7.2%). ECG-SMART-NET outperformed other models in the classification of OMI with a test AUC of 0.953 [0.921, 0.978]. Conclusion and Significance: ECG-SMART-NET can outperform the state-of-the-art random forest for OMI prediction and is better suited for this task than the original ResNet-18 architecture.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.09567",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Hallucinations Leaderboard, an Open Effort to Measure Hallucinations in Large Language Models",
    "description": "",
    "summary": "The Hallucinations Leaderboard, an Open Effort to Measure Hallucinations in Large Language Models In...",
    "pubDate": "Mon, 29 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-hallucinations",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail.png"
  },
  {
    "title": "Best practices for deploying language models",
    "description": "Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models.",
    "summary": "Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models.",
    "pubDate": "Thu, 02 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/best-practices-for-deploying-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Reads, Feb. 2021 - Long-range Transformers",
    "description": "",
    "summary": "Hugging Face Reads, Feb. 2021 - Long-range Transformers Co-written by Teven Le Scao, Patrick Von Pla...",
    "pubDate": "Tue, 09 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/long-range-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/14_long_range_transformers/EfficientTransformerTaxonomy.png"
  },
  {
    "title": "Optimize and deploy models with Optimum-Intel and OpenVINO GenAI",
    "description": "",
    "summary": "Optimize and deploy models with Optimum-Intel and OpenVINO GenAI Deploying Transformers models at th...",
    "pubDate": "Fri, 20 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-with-openvino",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Empowering YouTube creators with generative AI",
    "description": "New video generation technology in YouTube Shorts will help millions of people realize their creative vision",
    "summary": "New video generation technology in YouTube Shorts will help millions of people realize their creative vision",
    "pubDate": "Wed, 18 Sep 2024 14:30:06 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/empowering-youtube-creators-with-generative-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/Q8qBc1kzbYeksHRjsSuR7HEvezKsw3n1fxYlOqLf2sslqDOqYXJOhxyjznZ4cyq1fwNhpyMTMXW0RRrgHweVg6NaCEPnt3ujcFAIe0bVXK_sHka7cLo=w1200-h630-n-nu"
  },
  {
    "title": "Using AI to improve patient access to clinical trials",
    "description": "Paradigm uses OpenAI‚Äôs API to improve patient access to clinical trials.",
    "summary": "Paradigm uses OpenAI‚Äôs API to improve patient access to clinical trials.",
    "pubDate": "Wed, 06 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/paradigm",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LLM-Driven Medical Document Analysis: Enhancing Trustworthy Pathology and Differential Diagnosis",
    "description": "arXiv:2506.19702v1 Announce Type: new Abstract: Medical document analysis plays a crucial role in extracting essential clinical insights from unstructured healthcare records, supporting critical tasks such as differential diagnosis. Determining the most probable condition among overlapping symptoms requires precise evaluation and deep medical expertise. While recent advancements in large language models (LLMs) have significantly enhanced performance in medical document analysis, privacy concerns related to sensitive patient data limit the use of online LLMs services in clinical settings. To address these challenges, we propose a trustworthy medical document analysis platform that fine-tunes a LLaMA-v3 using low-rank adaptation, specifically optimized for differential diagnosis tasks. Our approach utilizes DDXPlus, the largest benchmark dataset for differential diagnosis, and demonstrates superior performance in pathology prediction and variable-length differential diagnosis compared to existing methods. The developed web-based platform allows users to submit their own unstructured medical documents and receive accurate, explainable diagnostic results. By incorporating advanced explainability techniques, the system ensures transparent and reliable predictions, fostering user trust and confidence. Extensive evaluations confirm that the proposed method surpasses current state-of-the-art models in predictive accuracy while offering practical utility in clinical settings. This work addresses the urgent need for reliable, explainable, and privacy-preserving artificial intelligence solutions, representing a significant advancement in intelligent medical document analysis for real-world healthcare applications. The code can be found at href{https://github.com/leitro/Differential-Diagnosis-LoRA}{https://github.com/leitro/Differential-Diagnosis-LoRA}.",
    "summary": "arXiv:2506.19702v1 Announce Type: new Abstract: Medical document analysis plays a crucial role in extracting essential clinical insights from unstructured healthcare records, supporting critical tasks such as differential diagnosis. Determining the most probable condition among overlapping symptoms requires precise evaluation and deep medical expertise. While recent advancements in large language models (LLMs) have significantly enhanced performance in medical document analysis, privacy concerns related to sensitive patient data limit the use of online LLMs services in clinical settings. To address these challenges, we propose a trustworthy medical document analysis platform that fine-tunes a LLaMA-v3 using low-rank adaptation, specifically optimized for differential diagnosis tasks. Our approach utilizes DDXPlus, the largest benchmark dataset for differential diagnosis, and demonstrates superior performance in pathology prediction and variable-length differential diagnosis compared to existing methods. The developed web-based platform allows users to submit their own unstructured medical documents and receive accurate, explainable diagnostic results. By incorporating advanced explainability techniques, the system ensures transparent and reliable predictions, fostering user trust and confidence. Extensive evaluations confirm that the proposed method surpasses current state-of-the-art models in predictive accuracy while offering practical utility in clinical settings. This work addresses the urgent need for reliable, explainable, and privacy-preserving artificial intelligence solutions, representing a significant advancement in intelligent medical document analysis for real-world healthcare applications. The code can be found at href{https://github.com/leitro/Differential-Diagnosis-LoRA}{https://github.com/leitro/Differential-Diagnosis-LoRA}.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19702",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ICASSP2025 Áô∫Ë°®Â†±Âëä @Hyderabad, India",
    "description": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ 2025Âπ¥4Êúà6Êó•(Êó•)„Äú4Êúà11Êó•(Èáë)„Å´„Ç§„É≥„Éâ„Éª„Éè„Ç§„Éá„É©„Éê„Éº„Éâ„ÄÅHyderabad International Convention Centre„Å´„Å¶ÈñãÂÇ¨„Åï„Çå„Åü„ÄÅÈü≥Èüø„ÉªÈü≥ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5728' rel='nofollow'>ICASSP2025 Áô∫Ë°®Â†±Âëä @Hyderabad, India</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„ÅØ„Åò„ÇÅ„Å´ „Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÂ§ßÁ´π„Åß„Åô„ÄÇ 2025Âπ¥4Êúà6Êó•(Êó•)„Äú4Êúà11Êó•(Èáë)„Å´„Ç§„É≥„Éâ„Éª„Éè„Ç§„Éá„É©„Éê„Éº„Éâ„ÄÅHyderabad International Convention Centre„Å´„Å¶ÈñãÂÇ¨„Åï„Çå„Åü„ÄÅÈü≥Èüø„ÉªÈü≥ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5728' rel='nofollow'>ICASSP2025 Áô∫Ë°®Â†±Âëä @Hyderabad, India</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Tue, 15 Apr 2025 01:50:49 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5728",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/IMG_20250406_091623-1.jpg"
  },
  {
    "title": "With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You",
    "description": "arXiv:2506.16895v1 Announce Type: cross Abstract: Multimodal models have demonstrated powerful capabilities in complex tasks requiring multimodal alignment including zero-shot classification and cross-modal retrieval. However, existing models typically rely on millions of paired multimodal samples, which are prohibitively expensive or infeasible to obtain in many domains. In this work, we explore the feasibility of building multimodal models with limited amount of paired data by aligning pretrained unimodal foundation models. We show that high-quality alignment is possible with as few as tens of thousands of paired samples$unicode{x2013}$less than $1%$ of the data typically used in the field. To achieve this, we introduce STRUCTURE, an effective regularization technique that preserves the neighborhood geometry of the latent space of unimodal encoders. Additionally, we show that aligning last layers is often suboptimal and demonstrate the benefits of aligning the layers with the highest representational similarity across modalities. These two components can be readily incorporated into existing alignment methods, yielding substantial gains across 24 zero-shot image classification and retrieval benchmarks, with average relative improvement of $51.6%$ in classification and $91.8%$ in retrieval tasks. Our results highlight the effectiveness and broad applicability of our framework for limited-sample multimodal learning and offer a promising path forward for resource-constrained domains.",
    "summary": "arXiv:2506.16895v1 Announce Type: cross Abstract: Multimodal models have demonstrated powerful capabilities in complex tasks requiring multimodal alignment including zero-shot classification and cross-modal retrieval. However, existing models typically rely on millions of paired multimodal samples, which are prohibitively expensive or infeasible to obtain in many domains. In this work, we explore the feasibility of building multimodal models with limited amount of paired data by aligning pretrained unimodal foundation models. We show that high-quality alignment is possible with as few as tens of thousands of paired samples$unicode{x2013}$less than $1%$ of the data typically used in the field. To achieve this, we introduce STRUCTURE, an effective regularization technique that preserves the neighborhood geometry of the latent space of unimodal encoders. Additionally, we show that aligning last layers is often suboptimal and demonstrate the benefits of aligning the layers with the highest representational similarity across modalities. These two components can be readily incorporated into existing alignment methods, yielding substantial gains across 24 zero-shot image classification and retrieval benchmarks, with average relative improvement of $51.6%$ in classification and $91.8%$ in retrieval tasks. Our results highlight the effectiveness and broad applicability of our framework for limited-sample multimodal learning and offer a promising path forward for resource-constrained domains.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16895",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The Partnership: Amazon SageMaker and Hugging Face",
    "description": "",
    "summary": "The Partnership: Amazon SageMaker and Hugging Face Look at these smiles! Today, we announce a strate...",
    "pubDate": "Tue, 23 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face",
    "thumbnail": "https://huggingface.co/blog/assets/17_the_partnership_amazon_sagemaker_and_hugging_face/thumbnail.png"
  },
  {
    "title": "Nubank elevates customer experiences with OpenAI",
    "description": "Nubank elevates customer experiences with OpenAI",
    "summary": "Nubank elevates customer experiences with OpenAI",
    "pubDate": "Fri, 07 Mar 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nubank",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Multi-task parallelism for robust pre-training of graph foundation models on multi-source, multi-fidelity atomistic modeling data",
    "description": "arXiv:2506.21788v1 Announce Type: cross Abstract: Graph foundation models using graph neural networks promise sustainable, efficient atomistic modeling. To tackle challenges of processing multi-source, multi-fidelity data during pre-training, recent studies employ multi-task learning, in which shared message passing layers initially process input atomistic structures regardless of source, then route them to multiple decoding heads that predict data-specific outputs. This approach stabilizes pre-training and enhances a model's transferability to unexplored chemical regions. Preliminary results on approximately four million structures are encouraging, yet questions remain about generalizability to larger, more diverse datasets and scalability on supercomputers. We propose a multi-task parallelism method that distributes each head across computing resources with GPU acceleration. Implemented in the open-source HydraGNN architecture, our method was trained on over 24 million structures from five datasets and tested on the Perlmutter, Aurora, and Frontier supercomputers, demonstrating efficient scaling on all three highly heterogeneous super-computing architectures.",
    "summary": "arXiv:2506.21788v1 Announce Type: cross Abstract: Graph foundation models using graph neural networks promise sustainable, efficient atomistic modeling. To tackle challenges of processing multi-source, multi-fidelity data during pre-training, recent studies employ multi-task learning, in which shared message passing layers initially process input atomistic structures regardless of source, then route them to multiple decoding heads that predict data-specific outputs. This approach stabilizes pre-training and enhances a model's transferability to unexplored chemical regions. Preliminary results on approximately four million structures are encouraging, yet questions remain about generalizability to larger, more diverse datasets and scalability on supercomputers. We propose a multi-task parallelism method that distributes each head across computing resources with GPU acceleration. Implemented in the open-source HydraGNN architecture, our method was trained on over 24 million structures from five datasets and tested on the Perlmutter, Aurora, and Frontier supercomputers, demonstrating efficient scaling on all three highly heterogeneous super-computing architectures.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21788",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "New ViT and ALIGN Models From Kakao Brain",
    "description": "",
    "summary": "Kakao Brain‚Äôs Open Source ViT, ALIGN, and the New COYO Text-Image Dataset Kakao Brain and Hugging Fa...",
    "pubDate": "Mon, 06 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vit-align",
    "thumbnail": "https://huggingface.co/blog//assets/132_vit_align/thumbnail.png"
  },
  {
    "title": "License to Call: Introducing Transformers Agents 2.0",
    "description": "",
    "summary": "License to Call: Introducing Transformers Agents 2.0 TL;DR We are releasing Transformers Agents 2.0!...",
    "pubDate": "Mon, 13 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/agents",
    "thumbnail": "https://huggingface.co/blog/assets/agents/thumbnail.png"
  },
  {
    "title": "VEIGAR: View-consistent Explicit Inpainting and Geometry Alignment for 3D object Removal",
    "description": "arXiv:2506.15821v1 Announce Type: cross Abstract: Recent advances in Novel View Synthesis (NVS) and 3D generation have significantly improved editing tasks, with a primary emphasis on maintaining cross-view consistency throughout the generative process. Contemporary methods typically address this challenge using a dual-strategy framework: performing consistent 2D inpainting across all views guided by embedded priors either explicitly in pixel space or implicitly in latent space; and conducting 3D reconstruction with additional consistency guidance. Previous strategies, in particular, often require an initial 3D reconstruction phase to establish geometric structure, introducing considerable computational overhead. Even with the added cost, the resulting reconstruction quality often remains suboptimal. In this paper, we present VEIGAR, a computationally efficient framework that outperforms existing methods without relying on an initial reconstruction phase. VEIGAR leverages a lightweight foundation model to reliably align priors explicitly in the pixel space. In addition, we introduce a novel supervision strategy based on scale-invariant depth loss, which removes the need for traditional scale-and-shift operations in monocular depth regularization. Through extensive experimentation, VEIGAR establishes a new state-of-the-art benchmark in reconstruction quality and cross-view consistency, while achieving a threefold reduction in training time compared to the fastest existing method, highlighting its superior balance of efficiency and effectiveness.",
    "summary": "arXiv:2506.15821v1 Announce Type: cross Abstract: Recent advances in Novel View Synthesis (NVS) and 3D generation have significantly improved editing tasks, with a primary emphasis on maintaining cross-view consistency throughout the generative process. Contemporary methods typically address this challenge using a dual-strategy framework: performing consistent 2D inpainting across all views guided by embedded priors either explicitly in pixel space or implicitly in latent space; and conducting 3D reconstruction with additional consistency guidance. Previous strategies, in particular, often require an initial 3D reconstruction phase to establish geometric structure, introducing considerable computational overhead. Even with the added cost, the resulting reconstruction quality often remains suboptimal. In this paper, we present VEIGAR, a computationally efficient framework that outperforms existing methods without relying on an initial reconstruction phase. VEIGAR leverages a lightweight foundation model to reliably align priors explicitly in the pixel space. In addition, we introduce a novel supervision strategy based on scale-invariant depth loss, which removes the need for traditional scale-and-shift operations in monocular depth regularization. Through extensive experimentation, VEIGAR establishes a new state-of-the-art benchmark in reconstruction quality and cross-view consistency, while achieving a threefold reduction in training time compared to the fastest existing method, highlighting its superior balance of efficiency and effectiveness.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15821",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Stopping malaria in its tracks",
    "description": "Developing a vaccine that could save hundreds of thousands of lives",
    "summary": "Developing a vaccine that could save hundreds of thousands of lives",
    "pubDate": "Thu, 13 Oct 2022 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/stopping-malaria-in-its-tracks/",
    "thumbnail": "https://lh3.googleusercontent.com/8EXA5jqukU4EEWDHB9rJG25ir12WetmJlMuErPLe7hJUaGdIjXIA51D-PcxCMjNf9IVu3QxaZRbs4isgJsBsVpaHZjbgK4XM3MCc-8XOgcQ9-sqYWQ=w1200-h630-n-nu"
  },
  {
    "title": "Faster Training and Inference: Habana Gaudi¬Æ2 vs Nvidia A100 80GB",
    "description": "",
    "summary": "Faster Training and Inference: Habana Gaudi¬Æ-2 vs Nvidia A100 80GB In this article, you will learn h...",
    "pubDate": "Wed, 14 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/habana-gaudi-2-benchmark",
    "thumbnail": "https://huggingface.co/blog/assets/habana-gaudi-2-benchmark/thumbnail.png"
  },
  {
    "title": "USM-VC: Mitigating Timbre Leakage with Universal Semantic Mapping Residual Block for Voice Conversion",
    "description": "arXiv:2504.08524v3 Announce Type: replace-cross Abstract: Voice conversion (VC) transforms source speech into a target voice by preserving the content. However, timbre information from the source speaker is inherently embedded in the content representations, causing significant timbre leakage and reducing similarity to the target speaker. To address this, we introduce a Universal Semantic Matching (USM) residual block to a content extractor. The residual block consists of two weighted branches: 1) universal semantic dictionary based Content Feature Re-expression (CFR) module, supplying timbre-free content representation. 2) skip connection to the original content layer, providing complementary fine-grained information. In the CFR module, each dictionary entry in the universal semantic dictionary represents a phoneme class, computed statistically using speech from multiple speakers, creating a stable, speaker-independent semantic set. We introduce a CFR method to obtain timbre-free content representations by expressing each content frame as a weighted linear combination of dictionary entries using corresponding phoneme posteriors as weights. Extensive experiments across various VC frameworks demonstrate that our approach effectively mitigates timbre leakage and significantly improves similarity to the target speaker.",
    "summary": "arXiv:2504.08524v3 Announce Type: replace-cross Abstract: Voice conversion (VC) transforms source speech into a target voice by preserving the content. However, timbre information from the source speaker is inherently embedded in the content representations, causing significant timbre leakage and reducing similarity to the target speaker. To address this, we introduce a Universal Semantic Matching (USM) residual block to a content extractor. The residual block consists of two weighted branches: 1) universal semantic dictionary based Content Feature Re-expression (CFR) module, supplying timbre-free content representation. 2) skip connection to the original content layer, providing complementary fine-grained information. In the CFR module, each dictionary entry in the universal semantic dictionary represents a phoneme class, computed statistically using speech from multiple speakers, creating a stable, speaker-independent semantic set. We introduce a CFR method to obtain timbre-free content representations by expressing each content frame as a weighted linear combination of dictionary entries using corresponding phoneme posteriors as weights. Extensive experiments across various VC frameworks demonstrate that our approach effectively mitigates timbre leakage and significantly improves similarity to the target speaker.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.08524",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Addendum to OpenAI o3 and o4-mini system card: OpenAI o3 Operator",
    "description": "We are replacing the existing GPT-4o-based model for Operator with a version based on OpenAI o3. The API version will remain based on 4o.",
    "summary": "We are replacing the existing GPT-4o-based model for Operator with a version based on OpenAI o3. The API version will remain based on 4o.",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-system-card-addendum-operator-o3",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Model Distillation in the API",
    "description": "Fine-tune a cost-efficient model with the outputs of a large frontier model‚Äìall on the OpenAI platform",
    "summary": "Fine-tune a cost-efficient model with the outputs of a large frontier model‚Äìall on the OpenAI platform",
    "pubDate": "Tue, 01 Oct 2024 10:02:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-model-distillation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our vision for building a universal AI assistant",
    "description": "We‚Äôre extending Gemini to become a world model that can make plans and imagine new experiences by simulating aspects of the world.",
    "summary": "We‚Äôre extending Gemini to become a world model that can make plans and imagine new experiences by simulating aspects of the world.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/our-vision-for-building-a-universal-ai-assistant/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO25_GeminiVision_SocialShare.width-1300.png"
  },
  {
    "title": "AMD Pervasive AI Developer Contest!",
    "description": "",
    "summary": "AMD Pervasive AI Developer Contest AMD and Hugging Face are actively engaged in helping developers s...",
    "pubDate": "Wed, 14 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/amd_pervasive_developer_ai_contest",
    "thumbnail": "https://huggingface.co/blog/amd_pervasive_developer_ai_contest/assets/amd_pervasive_developer_ai_contest/amd_developer_general_abstract.jpg"
  },
  {
    "title": "Mixture of Experts Explained",
    "description": "",
    "summary": "Mixture of Experts Explained With the release of Mixtral 8x7B (announcement, model card), a class of...",
    "pubDate": "Mon, 11 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/moe",
    "thumbnail": "https://huggingface.co/blog/assets/moe/thumbnail.png"
  },
  {
    "title": "Spam detection in the physical world",
    "description": "We‚Äôve created the world‚Äôs first Spam-detecting AI trained entirely in simulation and deployed on a physical robot.",
    "summary": "We‚Äôve created the world‚Äôs first Spam-detecting AI trained entirely in simulation and deployed on a physical robot.",
    "pubDate": "Sat, 01 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spam-detection-in-the-physical-world",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Demis Hassabis & John Jumper awarded Nobel Prize in Chemistry",
    "description": "The award recognizes their work developing AlphaFold, a groundbreaking AI system that predicts the 3D structure of proteins from their amino acid sequences.",
    "summary": "The award recognizes their work developing AlphaFold, a groundbreaking AI system that predicts the 3D structure of proteins from their amino acid sequences.",
    "pubDate": "Wed, 09 Oct 2024 11:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/demis-hassabis-john-jumper-awarded-nobel-prize-in-chemistry/",
    "thumbnail": "https://lh3.googleusercontent.com/7ZdZh5xhoD5NnykRBJHACxkxc3VubCdJLGHty2nYdJ36pBLVxRWO3Keu9C2Tum4OHCyGbJ5K5mB8R_oR94JG700qenuZ2rhq2sKjN4IkjIoU9Chv=w1200-h630-n-nu"
  },
  {
    "title": "OpenAI Red Teaming Network",
    "description": "We‚Äôre announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in improving the safety of OpenAI‚Äôs models to join our efforts.",
    "summary": "We‚Äôre announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in improving the safety of OpenAI‚Äôs models to join our efforts.",
    "pubDate": "Tue, 19 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/red-teaming-network",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "„ÉÜ„Çπ„É©„ÅÆ„É≠„Éú„Çø„ÇØ„Ç∑„Éº„ÄÅ‰∫àÂÆöÈÄö„ÇäËµ∞Ë°åÈñãÂßã„ÄÄ„ÉÜ„Ç≠„Çµ„ÇπÂ∑û„Åß",
    "description": "Á±≥ÂçóÈÉ®„ÉÜ„Ç≠„Çµ„ÇπÂ∑û„Ç™„Éº„Çπ„ÉÜ„Ç£„É≥„Åß6Êúà22Êó•„ÄÅÈõªÊ∞óËá™ÂãïËªäÂ§ßÊâãTesla„Å´„Çà„Çã„É≠„Éú„Çø„ÇØ„Ç∑„ÉºÔºàËá™ÂãïÈÅãËª¢„Çø„ÇØ„Ç∑„ÉºÔºâËµ∞Ë°å„Åå‰∫àÂÆöÈÄö„ÇäÂßã„Åæ„Å£„Åü„ÄÇ",
    "summary": "Á±≥ÂçóÈÉ®„ÉÜ„Ç≠„Çµ„ÇπÂ∑û„Ç™„Éº„Çπ„ÉÜ„Ç£„É≥„Åß6Êúà22Êó•„ÄÅÈõªÊ∞óËá™ÂãïËªäÂ§ßÊâãTesla„Å´„Çà„Çã„É≠„Éú„Çø„ÇØ„Ç∑„ÉºÔºàËá™ÂãïÈÅãËª¢„Çø„ÇØ„Ç∑„ÉºÔºâËµ∞Ë°å„Åå‰∫àÂÆöÈÄö„ÇäÂßã„Åæ„Å£„Åü„ÄÇ",
    "pubDate": "Mon, 23 Jun 2025 11:20:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/23/news054.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/23/cover_news054.jpg"
  },
  {
    "title": "Leveraging Online Olympiad-Level Math Problems for LLMs Training and Contamination-Resistant Evaluation",
    "description": "arXiv:2501.14275v2 Announce Type: replace-cross Abstract: Advances in Large Language Models (LLMs) have sparked interest in their ability to solve Olympiad-level math problems. However, the training and evaluation of these models are constrained by the limited size and quality of available datasets, as creating large-scale data for such advanced problems requires extensive effort from human experts. In addition, current benchmarks are prone to contamination, leading to unreliable evaluations. In this paper, we present an automated pipeline that leverages the rich resources of the Art of Problem Solving (AoPS) forum, which predominantly features Olympiad-level problems and community-driven solutions. Using open-source LLMs, we develop a method to extract question-answer pairs from the forum, resulting in AoPS-Instruct, a dataset of more than 600,000 high-quality QA pairs. Our experiments demonstrate that fine-tuning LLMs on AoPS-Instruct improves their reasoning abilities across various benchmarks. Moreover, we build an automatic pipeline that introduces LiveAoPSBench, an evolving evaluation set with timestamps, derived from the latest forum data, providing a contamination-resistant benchmark for assessing LLM performance. Notably, we observe a significant decline in LLM performance over time, suggesting their success on older examples may stem from pre-training exposure rather than true reasoning ability. Our work presents a scalable approach to creating and maintaining large-scale, high-quality datasets for advanced math reasoning, offering valuable insights into the capabilities and limitations of LLMs in this domain. Our benchmark and code is available at https://github.com/DSL-Lab/aops",
    "summary": "arXiv:2501.14275v2 Announce Type: replace-cross Abstract: Advances in Large Language Models (LLMs) have sparked interest in their ability to solve Olympiad-level math problems. However, the training and evaluation of these models are constrained by the limited size and quality of available datasets, as creating large-scale data for such advanced problems requires extensive effort from human experts. In addition, current benchmarks are prone to contamination, leading to unreliable evaluations. In this paper, we present an automated pipeline that leverages the rich resources of the Art of Problem Solving (AoPS) forum, which predominantly features Olympiad-level problems and community-driven solutions. Using open-source LLMs, we develop a method to extract question-answer pairs from the forum, resulting in AoPS-Instruct, a dataset of more than 600,000 high-quality QA pairs. Our experiments demonstrate that fine-tuning LLMs on AoPS-Instruct improves their reasoning abilities across various benchmarks. Moreover, we build an automatic pipeline that introduces LiveAoPSBench, an evolving evaluation set with timestamps, derived from the latest forum data, providing a contamination-resistant benchmark for assessing LLM performance. Notably, we observe a significant decline in LLM performance over time, suggesting their success on older examples may stem from pre-training exposure rather than true reasoning ability. Our work presents a scalable approach to creating and maintaining large-scale, high-quality datasets for advanced math reasoning, offering valuable insights into the capabilities and limitations of LLMs in this domain. Our benchmark and code is available at https://github.com/DSL-Lab/aops",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.14275",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI announces nonprofit commission advisors",
    "description": "OpenAI is appointing four new advisors to help inform OpenAI‚Äôs philanthropic efforts.",
    "summary": "OpenAI is appointing four new advisors to help inform OpenAI‚Äôs philanthropic efforts.",
    "pubDate": "Tue, 15 Apr 2025 13:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonprofit-commission-advisors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware",
    "description": "",
    "summary": "(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware In our previous post, Exploring Quantization Back...",
    "pubDate": "Thu, 19 Jun 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/flux-qlora",
    "thumbnail": "https://huggingface.co/blog/assets/flux-qlora/thumbnail.png"
  },
  {
    "title": "Welcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM",
    "description": "",
    "summary": "Welcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM TL;DR Today Google...",
    "pubDate": "Wed, 12 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gemma3",
    "thumbnail": "https://huggingface.co/blog/assets/gemma3/thumbnail.png"
  },
  {
    "title": "BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining",
    "description": "arXiv:2506.21567v1 Announce Type: cross Abstract: Large Language Models (LLMs) have recently gained attention in the life sciences due to their capacity to model, extract, and apply complex biological information. Beyond their classical use as chatbots, these systems are increasingly used for complex analysis and problem-solving in specialized fields, including bioinformatics. First, we introduce BIOPARS-BENCH, a dataset from over 10,000 scientific articles, textbooks, and medical websites. BioParsQA was also introduced to evaluate the proposed model, which consists of 5,231 Persian medical questions and answers. This study then introduces BioPars, a simple but accurate measure designed to assess LLMs for three main abilities: acquiring subject-specific knowledge, interpreting and synthesizing such knowledge, and demonstrating proper evidence. Comparing ChatGPT, Llama, and Galactica, our study highlights their ability to remember and retrieve learned knowledge but also reveals shortcomings in addressing higher-level, real-world questions and fine-grained inferences. These findings indicate the need for further fine-tuning to address the capabilities of LLM in bioinformatics tasks. To our knowledge, BioPars is the first application of LLM in Persian medical QA, especially for generating long answers. Evaluation of four selected medical QA datasets shows that BioPars has achieved remarkable results compared to comparative approaches. The model on BioParsQA achieved a ROUGE-L score of 29.99, which is an improvement over GPT-4 1.0. The model achieved a BERTScore of 90.87 with the MMR method. The MoverScore and BLEURT values were also higher in this model than the other three models. In addition, the reported scores for the model are MoverScore=60.43 and BLEURT=50.78. BioPars is an ongoing project and all resources related to its development will be made available via the following GitHub repository: https://github.com/amirap80/BioPars.",
    "summary": "arXiv:2506.21567v1 Announce Type: cross Abstract: Large Language Models (LLMs) have recently gained attention in the life sciences due to their capacity to model, extract, and apply complex biological information. Beyond their classical use as chatbots, these systems are increasingly used for complex analysis and problem-solving in specialized fields, including bioinformatics. First, we introduce BIOPARS-BENCH, a dataset from over 10,000 scientific articles, textbooks, and medical websites. BioParsQA was also introduced to evaluate the proposed model, which consists of 5,231 Persian medical questions and answers. This study then introduces BioPars, a simple but accurate measure designed to assess LLMs for three main abilities: acquiring subject-specific knowledge, interpreting and synthesizing such knowledge, and demonstrating proper evidence. Comparing ChatGPT, Llama, and Galactica, our study highlights their ability to remember and retrieve learned knowledge but also reveals shortcomings in addressing higher-level, real-world questions and fine-grained inferences. These findings indicate the need for further fine-tuning to address the capabilities of LLM in bioinformatics tasks. To our knowledge, BioPars is the first application of LLM in Persian medical QA, especially for generating long answers. Evaluation of four selected medical QA datasets shows that BioPars has achieved remarkable results compared to comparative approaches. The model on BioParsQA achieved a ROUGE-L score of 29.99, which is an improvement over GPT-4 1.0. The model achieved a BERTScore of 90.87 with the MMR method. The MoverScore and BLEURT values were also higher in this model than the other three models. In addition, the reported scores for the model are MoverScore=60.43 and BLEURT=50.78. BioPars is an ongoing project and all resources related to its development will be made available via the following GitHub repository: https://github.com/amirap80/BioPars.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21567",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI announces new members to board of directors",
    "description": "Dr. Sue Desmond-Hellmann, Nicole Seligman, Fidji Simo join; Sam Altman rejoins board",
    "summary": "Dr. Sue Desmond-Hellmann, Nicole Seligman, Fidji Simo join; Sam Altman rejoins board",
    "pubDate": "Fri, 08 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-announces-new-members-to-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Refining Salience-Aware Sparse Fine-Tuning Strategies for Language Models",
    "description": "arXiv:2412.13488v2 Announce Type: replace-cross Abstract: Parameter-Efficient Fine-Tuning (PEFT) has gained prominence through low-rank adaptation methods like LoRA. In this paper, we focus on sparsity-based PEFT (SPEFT), which introduces trainable sparse adaptations to the weight matrices in the model, offering greater flexibility in selecting fine-tuned parameters compared to low-rank methods. We conduct the first systematic evaluation of salience metrics for SPEFT, inspired by zero-cost NAS proxies, and identify simple gradient-based metrics is reliable, and results are on par with the best alternatives, offering both computational efficiency and robust performance. Additionally, we compare static and dynamic masking strategies, finding that static masking, which predetermines non-zero entries before training, delivers efficiency without sacrificing performance, while dynamic masking offers no substantial benefits. Across NLP tasks, a simple gradient-based, static SPEFT consistently outperforms other fine-tuning methods for LLMs, providing a simple yet effective baseline for SPEFT. Our work challenges the notion that complexity is necessary for effective PEFT, while our open-source framework establishes a reproducible benchmark for future research, which is available at [https://github.com/0-ml/speft].",
    "summary": "arXiv:2412.13488v2 Announce Type: replace-cross Abstract: Parameter-Efficient Fine-Tuning (PEFT) has gained prominence through low-rank adaptation methods like LoRA. In this paper, we focus on sparsity-based PEFT (SPEFT), which introduces trainable sparse adaptations to the weight matrices in the model, offering greater flexibility in selecting fine-tuned parameters compared to low-rank methods. We conduct the first systematic evaluation of salience metrics for SPEFT, inspired by zero-cost NAS proxies, and identify simple gradient-based metrics is reliable, and results are on par with the best alternatives, offering both computational efficiency and robust performance. Additionally, we compare static and dynamic masking strategies, finding that static masking, which predetermines non-zero entries before training, delivers efficiency without sacrificing performance, while dynamic masking offers no substantial benefits. Across NLP tasks, a simple gradient-based, static SPEFT consistently outperforms other fine-tuning methods for LLMs, providing a simple yet effective baseline for SPEFT. Our work challenges the notion that complexity is necessary for effective PEFT, while our open-source framework establishes a reproducible benchmark for future research, which is available at [https://github.com/0-ml/speft].",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.13488",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Instruction Learning Paradigms: A Dual Perspective on White-box and Black-box LLMs",
    "description": "arXiv:2506.21573v1 Announce Type: cross Abstract: Optimizing instructions for large language models (LLMs) is critical for harnessing their full potential in complex and diverse tasks. However, relying solely on white-box approaches demands extensive computational resources and offers limited representational capacity, while black-box models can incur prohibitive financial costs. To address these challenges, we introduce a novel framework that seamlessly merges the strengths of both paradigms. Black-box models provide high-quality, diverse instruction initializations, and white-box models supply fine-grained interpretability through hidden states and output features. By enforcing a semantic similarity constraint, these components fuse into a unified high-dimensional representation that captures deep semantic and structural nuances, enabling an iterative optimization process to refine instruction quality and adaptability. Extensive evaluations across a broad spectrum of tasks-ranging from complex reasoning to cross-lingual generalization-demonstrate that our approach consistently outperforms state-of-the-art baselines. This fusion of black-box initialization with advanced semantic refinement yields a scalable and efficient solution, paving the way for next-generation LLM-driven applications in diverse real-world scenarios. The source code will be released soon.",
    "summary": "arXiv:2506.21573v1 Announce Type: cross Abstract: Optimizing instructions for large language models (LLMs) is critical for harnessing their full potential in complex and diverse tasks. However, relying solely on white-box approaches demands extensive computational resources and offers limited representational capacity, while black-box models can incur prohibitive financial costs. To address these challenges, we introduce a novel framework that seamlessly merges the strengths of both paradigms. Black-box models provide high-quality, diverse instruction initializations, and white-box models supply fine-grained interpretability through hidden states and output features. By enforcing a semantic similarity constraint, these components fuse into a unified high-dimensional representation that captures deep semantic and structural nuances, enabling an iterative optimization process to refine instruction quality and adaptability. Extensive evaluations across a broad spectrum of tasks-ranging from complex reasoning to cross-lingual generalization-demonstrate that our approach consistently outperforms state-of-the-art baselines. This fusion of black-box initialization with advanced semantic refinement yields a scalable and efficient solution, paving the way for next-generation LLM-driven applications in diverse real-world scenarios. The source code will be released soon.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21573",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Teaching AI models the broad strokes to sketch more like humans do",
    "description": "SketchAgent, a drawing system developed by MIT CSAIL researchers, sketches up concepts stroke-by-stroke, teaching language models to visually express concepts on their own and collaborate with humans.",
    "summary": "SketchAgent, a drawing system developed by MIT CSAIL researchers, sketches up concepts stroke-by-stroke, teaching language models to visually express concepts on their own and collaborate with humans.",
    "pubDate": "Mon, 02 Jun 2025 14:50:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/teaching-ai-models-to-sketch-more-like-humans-0602",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-SketchAgent.jpg"
  },
  {
    "title": "Deep Dive: Vision Transformers On Hugging Face Optimum Graphcore",
    "description": "",
    "summary": "Deep Dive: Vision Transformers On Hugging Face Optimum Graphcore This blog post will show how easy i...",
    "pubDate": "Thu, 18 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vision-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/97_vision_transformers/thumbnail.png"
  },
  {
    "title": "Techniques for training large neural networks",
    "description": "Large neural networks are at the core of many recent advances in AI, but training them is a difficult engineering and research challenge which requires orchestrating a cluster of GPUs to perform a single synchronized calculation.",
    "summary": "Large neural networks are at the core of many recent advances in AI, but training them is a difficult engineering and research challenge which requires orchestrating a cluster of GPUs to perform a single synchronized calculation.",
    "pubDate": "Thu, 09 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/techniques-for-training-large-neural-networks",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ask a Techspert: What is inference?",
    "description": "Illustration of a computer chip surrounded by elements representing AI and data, including a cat's head, a wireframe cat, puzzle pieces, a bar graph, gears, and text bubbles.",
    "summary": "Illustration of a computer chip surrounded by elements representing AI and data, including a cat's head, a wireframe cat, puzzle pieces, a bar graph, gears, and text bubbles.",
    "pubDate": "Mon, 23 Jun 2025 17:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/ask-a-techspert-what-is-inference/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/InferenceHero_v3.width-1300.png"
  },
  {
    "title": "Scaling laws for neural language models",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 23 Jan 2020 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-laws-for-neural-language-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Glow: Better reversible generative models",
    "description": "We introduce¬†Glow, a reversible generative model which uses invertible 1x1 convolutions. It extends¬†previous¬†work¬†on reversible generative models and simplifies the architecture. Our model can generate realistic high resolution images, supports efficient sampling, and discovers features that can be used to manipulate attributes of data. We‚Äôre releasing code for the model and an online visualization tool so people can explore and build on these¬†results.",
    "summary": "We introduce¬†Glow, a reversible generative model which uses invertible 1x1 convolutions. It extends¬†previous¬†work¬†on reversible generative models and simplifies the architecture. Our model can generate realistic high resolution images, supports efficient sampling, and discovers features that can be used to manipulate attributes of data. We‚Äôre releasing code for the model and an online visualization tool so people can explore and build on these¬†results.",
    "pubDate": "Mon, 09 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/glow",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "POV Learning: Individual Alignment of Multimodal Models using Human Perception",
    "description": "arXiv:2405.04443v2 Announce Type: replace Abstract: Aligning machine learning systems with human expectations is mostly attempted by training with manually vetted human behavioral samples, typically explicit feedback. This is done on a population level since the context that is capturing the subjective Point-Of-View (POV) of a concrete person in a specific situational context is not retained in the data. However, we argue that alignment on an individual level can boost the subjective predictive performance for the individual user interacting with the system considerably. Since perception differs for each person, the same situation is observed differently. Consequently, the basis for decision making and the subsequent reasoning processes and observable reactions differ. We hypothesize that individual perception patterns can be used for improving the alignment on an individual level. We test this, by integrating perception information into machine learning systems and measuring their predictive performance wrt.~individual subjective assessments. For our empirical study, we collect a novel data set of multimodal stimuli and corresponding eye tracking sequences for the novel task of Perception-Guided Crossmodal Entailment and tackle it with our Perception-Guided Multimodal Transformer. Our findings suggest that exploiting individual perception signals for the machine learning of subjective human assessments provides a valuable cue for individual alignment. It does not only improve the overall predictive performance from the point-of-view of the individual user but might also contribute to steering AI systems towards every person's individual expectations and values.",
    "summary": "arXiv:2405.04443v2 Announce Type: replace Abstract: Aligning machine learning systems with human expectations is mostly attempted by training with manually vetted human behavioral samples, typically explicit feedback. This is done on a population level since the context that is capturing the subjective Point-Of-View (POV) of a concrete person in a specific situational context is not retained in the data. However, we argue that alignment on an individual level can boost the subjective predictive performance for the individual user interacting with the system considerably. Since perception differs for each person, the same situation is observed differently. Consequently, the basis for decision making and the subsequent reasoning processes and observable reactions differ. We hypothesize that individual perception patterns can be used for improving the alignment on an individual level. We test this, by integrating perception information into machine learning systems and measuring their predictive performance wrt.~individual subjective assessments. For our empirical study, we collect a novel data set of multimodal stimuli and corresponding eye tracking sequences for the novel task of Perception-Guided Crossmodal Entailment and tackle it with our Perception-Guided Multimodal Transformer. Our findings suggest that exploiting individual perception signals for the machine learning of subjective human assessments provides a valuable cue for individual alignment. It does not only improve the overall predictive performance from the point-of-view of the individual user but might also contribute to steering AI systems towards every person's individual expectations and values.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.04443",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Variational option discovery algorithms",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 26 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/variational-option-discovery-algorithms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AMD + ü§ó: Large Language Models Out-of-the-Box Acceleration with AMD GPU",
    "description": "",
    "summary": "AMD + ü§ó: Large Language Models Out-of-the-Box Acceleration with AMD GPU Earlier this year, AMD and H...",
    "pubDate": "Tue, 05 Dec 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-optimum-amd",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_amd/amd_hf_logo_fixed.png"
  },
  {
    "title": "RiOSWorld: Benchmarking the Risk of Multimodal Computer-Use Agents",
    "description": "arXiv:2506.00618v3 Announce Type: replace Abstract: With the rapid development of multimodal large language models (MLLMs), they are increasingly deployed as autonomous computer-use agents capable of accomplishing complex computer tasks. However, a pressing issue arises: Can the safety risk principles designed and aligned for general MLLMs in dialogue scenarios be effectively transferred to real-world computer-use scenarios? Existing research on evaluating the safety risks of MLLM-based computer-use agents suffers from several limitations: it either lacks realistic interactive environments, or narrowly focuses on one or a few specific risk types. These limitations ignore the complexity, variability, and diversity of real-world environments, thereby restricting comprehensive risk evaluation for computer-use agents. To this end, we introduce textbf{RiOSWorld}, a benchmark designed to evaluate the potential risks of MLLM-based agents during real-world computer manipulations. Our benchmark includes 492 risky tasks spanning various computer applications, involving web, social media, multimedia, os, email, and office software. We categorize these risks into two major classes based on their risk source: (i) User-originated risks and (ii) Environmental risks. For the evaluation, we evaluate safety risks from two perspectives: (i) Risk goal intention and (ii) Risk goal completion. Extensive experiments with multimodal agents on textbf{RiOSWorld} demonstrate that current computer-use agents confront significant safety risks in real-world scenarios. Our findings highlight the necessity and urgency of safety alignment for computer-use agents in real-world computer manipulation, providing valuable insights for developing trustworthy computer-use agents. Our benchmark is publicly available at https://yjyddq.github.io/RiOSWorld.github.io/.",
    "summary": "arXiv:2506.00618v3 Announce Type: replace Abstract: With the rapid development of multimodal large language models (MLLMs), they are increasingly deployed as autonomous computer-use agents capable of accomplishing complex computer tasks. However, a pressing issue arises: Can the safety risk principles designed and aligned for general MLLMs in dialogue scenarios be effectively transferred to real-world computer-use scenarios? Existing research on evaluating the safety risks of MLLM-based computer-use agents suffers from several limitations: it either lacks realistic interactive environments, or narrowly focuses on one or a few specific risk types. These limitations ignore the complexity, variability, and diversity of real-world environments, thereby restricting comprehensive risk evaluation for computer-use agents. To this end, we introduce textbf{RiOSWorld}, a benchmark designed to evaluate the potential risks of MLLM-based agents during real-world computer manipulations. Our benchmark includes 492 risky tasks spanning various computer applications, involving web, social media, multimedia, os, email, and office software. We categorize these risks into two major classes based on their risk source: (i) User-originated risks and (ii) Environmental risks. For the evaluation, we evaluate safety risks from two perspectives: (i) Risk goal intention and (ii) Risk goal completion. Extensive experiments with multimodal agents on textbf{RiOSWorld} demonstrate that current computer-use agents confront significant safety risks in real-world scenarios. Our findings highlight the necessity and urgency of safety alignment for computer-use agents in real-world computer manipulation, providing valuable insights for developing trustworthy computer-use agents. Our benchmark is publicly available at https://yjyddq.github.io/RiOSWorld.github.io/.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.00618",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LangGraph CodeAct„ÇíE2B„ÅÆÂÆâÂÖ®„Å™‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åô",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØÂÖàÊó•LangChain„Åã„ÇâÁô∫Ë°®„Åï„Çå„ÅüLangGraph CodeAct„ÇíE2B„ÅÆ‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åó„Å¶„Åø„Çà„ÅÜ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇCodeAct„ÅØÊúÄËøëÊ≥®ÁõÆ„ÇíÈõÜ„ÇÅ„Å¶„ÅÑ„ÇãAI Agent„ÅÆTool [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5652' rel='nofollow'>LangGraph CodeAct„ÇíE2B„ÅÆÂÆâÂÖ®„Å™‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åô</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô ‰ªäÂõû„ÅØÂÖàÊó•LangChain„Åã„ÇâÁô∫Ë°®„Åï„Çå„ÅüLangGraph CodeAct„ÇíE2B„ÅÆ‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åó„Å¶„Åø„Çà„ÅÜ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇCodeAct„ÅØÊúÄËøëÊ≥®ÁõÆ„ÇíÈõÜ„ÇÅ„Å¶„ÅÑ„ÇãAI Agent„ÅÆTool [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5652' rel='nofollow'>LangGraph CodeAct„ÇíE2B„ÅÆÂÆâÂÖ®„Å™‰ªÆÊÉ≥Áí∞Â¢É„ÅßÂãï„Åã„Åô</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Thu, 17 Apr 2025 01:11:36 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5652",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "Deploy LLMs with Hugging Face Inference Endpoints",
    "description": "",
    "summary": "Deploy LLMs with Hugging Face Inference Endpoints Open-source LLMs like Falcon, (Open-)LLaMA, X-Gen,...",
    "pubDate": "Tue, 04 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-endpoints-llm",
    "thumbnail": "https://huggingface.co/blog/assets/155_inference_endpoints_llm/thumbnail.jpg"
  },
  {
    "title": "SmolVLM Grows Smaller ‚Äì Introducing the 250M & 500M Models!",
    "description": "",
    "summary": "SmolVLM Grows Smaller ‚Äì Introducing the 250M & 500M Models! TLDR We‚Äôre excited to announce two new a...",
    "pubDate": "Thu, 23 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smolervlm",
    "thumbnail": "https://huggingface.co/blog/assets/smolervlm/banner.png"
  },
  {
    "title": "UniMate: A Unified Model for Mechanical Metamaterial Generation, Property Prediction, and Condition Confirmation",
    "description": "arXiv:2506.15722v1 Announce Type: cross Abstract: Metamaterials are artificial materials that are designed to meet unseen properties in nature, such as ultra-stiffness and negative materials indices. In mechanical metamaterial design, three key modalities are typically involved, i.e., 3D topology, density condition, and mechanical property. Real-world complex application scenarios place the demanding requirements on machine learning models to consider all three modalities together. However, a comprehensive literature review indicates that most existing works only consider two modalities, e.g., predicting mechanical properties given the 3D topology or generating 3D topology given the required properties. Therefore, there is still a significant gap for the state-of-the-art machine learning models capturing the whole. Hence, we propose a unified model named UNIMATE, which consists of a modality alignment module and a synergetic diffusion generation module. Experiments indicate that UNIMATE outperforms the other baseline models in topology generation task, property prediction task, and condition confirmation task by up to 80.2%, 5.1%, and 50.2%, respectively. We opensource our proposed UNIMATE model and corresponding results at https://github.com/wzhan24/UniMate.",
    "summary": "arXiv:2506.15722v1 Announce Type: cross Abstract: Metamaterials are artificial materials that are designed to meet unseen properties in nature, such as ultra-stiffness and negative materials indices. In mechanical metamaterial design, three key modalities are typically involved, i.e., 3D topology, density condition, and mechanical property. Real-world complex application scenarios place the demanding requirements on machine learning models to consider all three modalities together. However, a comprehensive literature review indicates that most existing works only consider two modalities, e.g., predicting mechanical properties given the 3D topology or generating 3D topology given the required properties. Therefore, there is still a significant gap for the state-of-the-art machine learning models capturing the whole. Hence, we propose a unified model named UNIMATE, which consists of a modality alignment module and a synergetic diffusion generation module. Experiments indicate that UNIMATE outperforms the other baseline models in topology generation task, property prediction task, and condition confirmation task by up to 80.2%, 5.1%, and 50.2%, respectively. We opensource our proposed UNIMATE model and corresponding results at https://github.com/wzhan24/UniMate.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15722",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How we're supporting better tropical cyclone prediction with AI",
    "description": "We‚Äôre launching Weather Lab, featuring our experimental cyclone predictions, and we‚Äôre partnering with the U.S. National Hurricane Center to support their forecasts and warnings this cyclone season.",
    "summary": "We‚Äôre launching Weather Lab, featuring our experimental cyclone predictions, and we‚Äôre partnering with the U.S. National Hurricane Center to support their forecasts and warnings this cyclone season.",
    "pubDate": "Thu, 12 Jun 2025 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/weather-lab-cyclone-predictions-with-ai/",
    "thumbnail": "https://lh3.googleusercontent.com/4emGMNrEdaydebppYDiyQMNhXtgUFr8VvrKhVItMHENrxeWmWO9yqhteSj2fe25lxkiZAu7vOZZcsXPDLg0O-LPSvk6CS1I8E2-GdjtoN_2ViJOY=w1200-h630-n-nu"
  },
  {
    "title": "CUPID: Curating Data your Robot Loves with Influence Functions",
    "description": "arXiv:2506.19121v1 Announce Type: cross Abstract: In robot imitation learning, policy performance is tightly coupled with the quality and composition of the demonstration data. Yet, developing a precise understanding of how individual demonstrations contribute to downstream outcomes - such as closed-loop task success or failure - remains a persistent challenge. We propose CUPID, a robot data curation method based on a novel influence function-theoretic formulation for imitation learning policies. Given a set of evaluation rollouts, CUPID estimates the influence of each training demonstration on the policy's expected return. This enables ranking and selection of demonstrations according to their impact on the policy's closed-loop performance. We use CUPID to curate data by 1) filtering out training demonstrations that harm policy performance and 2) subselecting newly collected trajectories that will most improve the policy. Extensive simulated and hardware experiments show that our approach consistently identifies which data drives test-time performance. For example, training with less than 33% of curated data can yield state-of-the-art diffusion policies on the simulated RoboMimic benchmark, with similar gains observed in hardware. Furthermore, hardware experiments show that our method can identify robust strategies under distribution shift, isolate spurious correlations, and even enhance the post-training of generalist robot policies. Additional materials are made available at: https://cupid-curation.github.io.",
    "summary": "arXiv:2506.19121v1 Announce Type: cross Abstract: In robot imitation learning, policy performance is tightly coupled with the quality and composition of the demonstration data. Yet, developing a precise understanding of how individual demonstrations contribute to downstream outcomes - such as closed-loop task success or failure - remains a persistent challenge. We propose CUPID, a robot data curation method based on a novel influence function-theoretic formulation for imitation learning policies. Given a set of evaluation rollouts, CUPID estimates the influence of each training demonstration on the policy's expected return. This enables ranking and selection of demonstrations according to their impact on the policy's closed-loop performance. We use CUPID to curate data by 1) filtering out training demonstrations that harm policy performance and 2) subselecting newly collected trajectories that will most improve the policy. Extensive simulated and hardware experiments show that our approach consistently identifies which data drives test-time performance. For example, training with less than 33% of curated data can yield state-of-the-art diffusion policies on the simulated RoboMimic benchmark, with similar gains observed in hardware. Furthermore, hardware experiments show that our method can identify robust strategies under distribution shift, isolate spurious correlations, and even enhance the post-training of generalist robot policies. Additional materials are made available at: https://cupid-curation.github.io.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19121",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI‚Äôs comment to the NTIA on open model weights",
    "description": "OpenAI‚Äôs comment to the NTIA on open model weights This comment was submitted by OpenAI in response to NTIA‚Äôs March 2024 Request for Information on Dual-Use Foundation Models with Widely Available Weights.",
    "summary": "OpenAI‚Äôs comment to the NTIA on open model weights This comment was submitted by OpenAI in response to NTIA‚Äôs March 2024 Request for Information on Dual-Use Foundation Models with Widely Available Weights.",
    "pubDate": "Wed, 27 Mar 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-s-comment-to-the-ntia-on-open-model-weights",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Platform on the AWS Marketplace: Pay with your AWS Account",
    "description": "",
    "summary": "Hugging Face Hub on the AWS Marketplace: Pay with your AWS Account The Hugging Face Hub has landed o...",
    "pubDate": "Thu, 10 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/aws-marketplace",
    "thumbnail": "https://huggingface.co/blog/assets/158_aws_marketplace/thumbnail.jpg"
  },
  {
    "title": "Selective Use of Yannakakis' Algorithm to Improve Query Performance: Machine Learning to the Rescue",
    "description": "arXiv:2502.20233v2 Announce Type: replace-cross Abstract: Query optimization has played a central role in database research for decades. However, more often than not, the proposed optimization techniques lead to a performance improvement in some, but not in all, situations. Therefore, we urgently need a methodology for designing a decision procedure that decides for a given query whether the optimization technique should be applied or not. In this work, we propose such a methodology with a focus on Yannakakis-style query evaluation as our optimization technique of interest. More specifically, we formulate this decision problem as an algorithm selection problem and we present a Machine Learning based approach for its solution. Empirical results with several benchmarks on a variety of database systems show that our approach indeed leads to a statistically significant performance improvement.",
    "summary": "arXiv:2502.20233v2 Announce Type: replace-cross Abstract: Query optimization has played a central role in database research for decades. However, more often than not, the proposed optimization techniques lead to a performance improvement in some, but not in all, situations. Therefore, we urgently need a methodology for designing a decision procedure that decides for a given query whether the optimization technique should be applied or not. In this work, we propose such a methodology with a focus on Yannakakis-style query evaluation as our optimization technique of interest. More specifically, we formulate this decision problem as an algorithm selection problem and we present a Machine Learning based approach for its solution. Empirical results with several benchmarks on a variety of database systems show that our approach indeed leads to a statistically significant performance improvement.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.20233",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Faster Stable Diffusion with Core ML on iPhone, iPad, and Mac",
    "description": "",
    "summary": "Faster Stable Diffusion with Core ML on iPhone, iPad, and Mac WWDC‚Äô23 (Apple Worldwide Developers Co...",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fast-diffusers-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/149_fast_diffusers_coreml/thumbnail.png"
  },
  {
    "title": "Fine-tuning MMS Adapter Models for Multi-Lingual ASR",
    "description": "",
    "summary": "Fine-tuning MMS Adapter Models for Multi-Lingual ASR New (06/2023): This blog post is strongly inspi...",
    "pubDate": "Mon, 19 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/mms_adapters",
    "thumbnail": "https://huggingface.co/blog/assets/151_mms/mms_map.png"
  },
  {
    "title": "Making AI-generated code more accurate in any language",
    "description": "A new technique automatically guides an LLM toward outputs that adhere to the rules of whatever programming language or other format is being used.",
    "summary": "A new technique automatically guides an LLM toward outputs that adhere to the rules of whatever programming language or other format is being used.",
    "pubDate": "Fri, 18 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/making-ai-generated-code-more-accurate-0418",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Probalistic-Control-compressed.gif"
  },
  {
    "title": "Introducing vision to the fine-tuning API",
    "description": "Developers can now fine-tune GPT-4o with images and text to improve vision capabilities",
    "summary": "Developers can now fine-tune GPT-4o with images and text to improve vision capabilities",
    "pubDate": "Tue, 01 Oct 2024 10:04:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-vision-to-the-fine-tuning-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fine-Tune Wav2Vec2 for English ASR with ü§ó Transformers",
    "description": "",
    "summary": "Fine-Tune Wav2Vec2 for English ASR with ü§ó Transformers Wav2Vec2 is a pretrained model for Automatic ...",
    "pubDate": "Fri, 12 Mar 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-wav2vec2-english",
    "thumbnail": "https://huggingface.co/blog/assets/15_fine_tune_wav2vec2/wav2vec2.png"
  },
  {
    "title": "Robust Finite-Memory Policy Gradients for Hidden-Model POMDPs",
    "description": "arXiv:2505.09518v2 Announce Type: replace Abstract: Partially observable Markov decision processes (POMDPs) model specific environments in sequential decision-making under uncertainty. Critically, optimal policies for POMDPs may not be robust against perturbations in the environment. Hidden-model POMDPs (HM-POMDPs) capture sets of different environment models, that is, POMDPs with a shared action and observation space. The intuition is that the true model is hidden among a set of potential models, and it is unknown which model will be the environment at execution time. A policy is robust for a given HM-POMDP if it achieves sufficient performance for each of its POMDPs.We compute such robust policies by combining two orthogonal techniques: (1) a deductive formal verification technique that supports tractable robust policy evaluation by computing a worst-case POMDP within the HM-POMDP, and (2) subgradient ascent to optimize the candidate policy for a worst-case POMDP. The empirical evaluation shows that, compared to various baselines, our approach (1) produces policies that are more robust and generalize better to unseen POMDPs, and (2) scales to HM-POMDPs that consist of over a hundred thousand environments.",
    "summary": "arXiv:2505.09518v2 Announce Type: replace Abstract: Partially observable Markov decision processes (POMDPs) model specific environments in sequential decision-making under uncertainty. Critically, optimal policies for POMDPs may not be robust against perturbations in the environment. Hidden-model POMDPs (HM-POMDPs) capture sets of different environment models, that is, POMDPs with a shared action and observation space. The intuition is that the true model is hidden among a set of potential models, and it is unknown which model will be the environment at execution time. A policy is robust for a given HM-POMDP if it achieves sufficient performance for each of its POMDPs.We compute such robust policies by combining two orthogonal techniques: (1) a deductive formal verification technique that supports tractable robust policy evaluation by computing a worst-case POMDP within the HM-POMDP, and (2) subgradient ascent to optimize the candidate policy for a worst-case POMDP. The empirical evaluation shows that, compared to various baselines, our approach (1) produces policies that are more robust and generalize better to unseen POMDPs, and (2) scales to HM-POMDPs that consist of over a hundred thousand environments.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.09518",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FALCON: Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization system",
    "description": "arXiv:2410.21349v5 Announce Type: replace-cross Abstract: Recently, large language models (LLMs) have achieved significant progress in automated code generation. Despite their strong instruction-following capabilities, these models frequently struggled to align with user intent in coding scenarios. In particular, they were hampered by datasets that lacked diversity and failed to address specialized tasks or edge cases. Furthermore, challenges in supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) led to failures in generating precise, human-intent-aligned code. To tackle these challenges and improve the code generation performance for automated programming systems, we propose Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization (i.e., FALCON). FALCON is structured into two hierarchical levels. From the global level, long-term memory improves code quality by retaining and applying learned knowledge. At the local level, short-term memory allows for the incorporation of immediate feedback from compilers and AI systems. Additionally, we introduce meta-reinforcement learning with feedback rewards to solve the global-local bi-level optimization problem and enhance the model's adaptability across diverse code generation tasks. Extensive experiments demonstrate that our technique achieves state-of-the-art performance, leading other reinforcement learning methods by more than 4.5 percentage points on the MBPP benchmark and 6.1 percentage points on the Humaneval benchmark. The open-sourced code is publicly available at https://github.com/titurte/FALCON.",
    "summary": "arXiv:2410.21349v5 Announce Type: replace-cross Abstract: Recently, large language models (LLMs) have achieved significant progress in automated code generation. Despite their strong instruction-following capabilities, these models frequently struggled to align with user intent in coding scenarios. In particular, they were hampered by datasets that lacked diversity and failed to address specialized tasks or edge cases. Furthermore, challenges in supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) led to failures in generating precise, human-intent-aligned code. To tackle these challenges and improve the code generation performance for automated programming systems, we propose Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization (i.e., FALCON). FALCON is structured into two hierarchical levels. From the global level, long-term memory improves code quality by retaining and applying learned knowledge. At the local level, short-term memory allows for the incorporation of immediate feedback from compilers and AI systems. Additionally, we introduce meta-reinforcement learning with feedback rewards to solve the global-local bi-level optimization problem and enhance the model's adaptability across diverse code generation tasks. Extensive experiments demonstrate that our technique achieves state-of-the-art performance, leading other reinforcement learning methods by more than 4.5 percentage points on the MBPP benchmark and 6.1 percentage points on the Humaneval benchmark. The open-sourced code is publicly available at https://github.com/titurte/FALCON.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.21349",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases",
    "description": "arXiv:2506.17336v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used as personal agents, accessing sensitive user data such as calendars, emails, and medical records. Users currently face a trade-off: They can send private records, many of which are stored in remote databases, to powerful but untrusted LLM providers, increasing their exposure risk. Alternatively, they can run less powerful models locally on trusted devices. We bridge this gap. Our Socratic Chain-of-Thought Reasoning first sends a generic, non-private user query to a powerful, untrusted LLM, which generates a Chain-of-Thought (CoT) prompt and detailed sub-queries without accessing user data. Next, we embed these sub-queries and perform encrypted sub-second semantic search using our Homomorphically Encrypted Vector Database across one million entries of a single user's private data. This represents a realistic scale of personal documents, emails, and records accumulated over years of digital activity. Finally, we feed the CoT prompt and the decrypted records to a local language model and generate the final response. On the LoCoMo long-context QA benchmark, our hybrid framework, combining GPT-4o with a local Llama-3.2-1B model, outperforms using GPT-4o alone by up to 7.1 percentage points. This demonstrates a first step toward systems where tasks are decomposed and split between untrusted strong LLMs and weak local ones, preserving user privacy.",
    "summary": "arXiv:2506.17336v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used as personal agents, accessing sensitive user data such as calendars, emails, and medical records. Users currently face a trade-off: They can send private records, many of which are stored in remote databases, to powerful but untrusted LLM providers, increasing their exposure risk. Alternatively, they can run less powerful models locally on trusted devices. We bridge this gap. Our Socratic Chain-of-Thought Reasoning first sends a generic, non-private user query to a powerful, untrusted LLM, which generates a Chain-of-Thought (CoT) prompt and detailed sub-queries without accessing user data. Next, we embed these sub-queries and perform encrypted sub-second semantic search using our Homomorphically Encrypted Vector Database across one million entries of a single user's private data. This represents a realistic scale of personal documents, emails, and records accumulated over years of digital activity. Finally, we feed the CoT prompt and the decrypted records to a local language model and generate the final response. On the LoCoMo long-context QA benchmark, our hybrid framework, combining GPT-4o with a local Llama-3.2-1B model, outperforms using GPT-4o alone by up to 7.1 percentage points. This demonstrates a first step toward systems where tasks are decomposed and split between untrusted strong LLMs and weak local ones, preserving user privacy.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17336",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ReDit: Reward Dithering for Improved LLM Policy Optimization",
    "description": "arXiv:2506.18631v2 Announce Type: replace-cross Abstract: DeepSeek-R1 has successfully enhanced Large Language Model (LLM) reasoning capabilities through its rule-based reward system. While it's a ''perfect'' reward system that effectively mitigates reward hacking, such reward functions are often discrete. Our experimental observations suggest that discrete rewards can lead to gradient anomaly, unstable optimization, and slow convergence. To address this issue, we propose ReDit (Reward Dithering), a method that dithers the discrete reward signal by adding simple random noise. With this perturbed reward, exploratory gradients are continuously provided throughout the learning process, enabling smoother gradient updates and accelerating convergence. The injected noise also introduces stochasticity into flat reward regions, encouraging the model to explore novel policies and escape local optima. Experiments across diverse tasks demonstrate the effectiveness and efficiency of ReDit. On average, ReDit achieves performance comparable to vanilla GRPO with only approximately 10% the training steps, and furthermore, still exhibits a 4% performance improvement over vanilla GRPO when trained for a similar duration. Visualizations confirm significant mitigation of gradient issues with ReDit. Moreover, theoretical analyses are provided to further validate these advantages.",
    "summary": "arXiv:2506.18631v2 Announce Type: replace-cross Abstract: DeepSeek-R1 has successfully enhanced Large Language Model (LLM) reasoning capabilities through its rule-based reward system. While it's a ''perfect'' reward system that effectively mitigates reward hacking, such reward functions are often discrete. Our experimental observations suggest that discrete rewards can lead to gradient anomaly, unstable optimization, and slow convergence. To address this issue, we propose ReDit (Reward Dithering), a method that dithers the discrete reward signal by adding simple random noise. With this perturbed reward, exploratory gradients are continuously provided throughout the learning process, enabling smoother gradient updates and accelerating convergence. The injected noise also introduces stochasticity into flat reward regions, encouraging the model to explore novel policies and escape local optima. Experiments across diverse tasks demonstrate the effectiveness and efficiency of ReDit. On average, ReDit achieves performance comparable to vanilla GRPO with only approximately 10% the training steps, and furthermore, still exhibits a 4% performance improvement over vanilla GRPO when trained for a similar duration. Visualizations confirm significant mitigation of gradient issues with ReDit. Moreover, theoretical analyses are provided to further validate these advantages.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18631",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "CP$^2$: Leveraging Geometry for Conformal Prediction via Canonicalization",
    "description": "arXiv:2506.16189v1 Announce Type: cross Abstract: We study the problem of conformal prediction (CP) under geometric data shifts, where data samples are susceptible to transformations such as rotations or flips. While CP endows prediction models with post-hoc uncertainty quantification and formal coverage guarantees, their practicality breaks under distribution shifts that deteriorate model performance. To address this issue, we propose integrating geometric information--such as geometric pose--into the conformal procedure to reinstate its guarantees and ensure robustness under geometric shifts. In particular, we explore recent advancements on pose canonicalization as a suitable information extractor for this purpose. Evaluating the combined approach across discrete and continuous shifts and against equivariant and augmentation-based baselines, we find that integrating geometric information with CP yields a principled way to address geometric shifts while maintaining broad applicability to black-box predictors.",
    "summary": "arXiv:2506.16189v1 Announce Type: cross Abstract: We study the problem of conformal prediction (CP) under geometric data shifts, where data samples are susceptible to transformations such as rotations or flips. While CP endows prediction models with post-hoc uncertainty quantification and formal coverage guarantees, their practicality breaks under distribution shifts that deteriorate model performance. To address this issue, we propose integrating geometric information--such as geometric pose--into the conformal procedure to reinstate its guarantees and ensure robustness under geometric shifts. In particular, we explore recent advancements on pose canonicalization as a suitable information extractor for this purpose. Evaluating the combined approach across discrete and continuous shifts and against equivariant and augmentation-based baselines, we find that integrating geometric information with CP yields a principled way to address geometric shifts while maintaining broad applicability to black-box predictors.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16189",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Building an AI WebTV",
    "description": "",
    "summary": "Building an AI WebTV The AI WebTV is an experimental demo to showcase the latest advancements in aut...",
    "pubDate": "Mon, 17 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ai-webtv",
    "thumbnail": "https://huggingface.co/blog/assets/156_ai_webtv/thumbnail.gif"
  },
  {
    "title": "Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards",
    "description": "arXiv:2506.20332v2 Announce Type: replace Abstract: Vision-language model-based mobile agents have gained the ability to not only understand complex instructions and mobile screenshots, but also optimize their action outputs via thinking and reasoning, benefiting from reinforcement learning, such as Group Relative Policy Optimization (GRPO). However, existing research centers on offline reinforcement learning training or online optimization using action-level rewards, which limits the agent's dynamic interaction with the environment. This often results in agents settling into local optima, thereby weakening their ability for exploration and error action correction. To address these challenges, we introduce an approach called Mobile-R1, which employs interactive multi-turn reinforcement learning with task-level rewards for mobile agents. Our training framework consists of three stages: initial format finetuning, single-step online training via action-level reward, followed by online training via task-level reward based on multi-turn trajectories. This strategy is designed to enhance the exploration and error correction capabilities of Mobile-R1, leading to significant performance improvements. Moreover, we have collected a dataset covering 28 Chinese applications with 24,521 high-quality manual annotations and established a new benchmark with 500 trajectories. We will open source all resources, including the dataset, benchmark, model weight, and codes: https://mobile-r1.github.io/Mobile-R1/.",
    "summary": "arXiv:2506.20332v2 Announce Type: replace Abstract: Vision-language model-based mobile agents have gained the ability to not only understand complex instructions and mobile screenshots, but also optimize their action outputs via thinking and reasoning, benefiting from reinforcement learning, such as Group Relative Policy Optimization (GRPO). However, existing research centers on offline reinforcement learning training or online optimization using action-level rewards, which limits the agent's dynamic interaction with the environment. This often results in agents settling into local optima, thereby weakening their ability for exploration and error action correction. To address these challenges, we introduce an approach called Mobile-R1, which employs interactive multi-turn reinforcement learning with task-level rewards for mobile agents. Our training framework consists of three stages: initial format finetuning, single-step online training via action-level reward, followed by online training via task-level reward based on multi-turn trajectories. This strategy is designed to enhance the exploration and error correction capabilities of Mobile-R1, leading to significant performance improvements. Moreover, we have collected a dataset covering 28 Chinese applications with 24,521 high-quality manual annotations and established a new benchmark with 500 trajectories. We will open source all resources, including the dataset, benchmark, model weight, and codes: https://mobile-r1.github.io/Mobile-R1/.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.20332",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LaunchDarkly's approach to AI-powered product management",
    "description": "A conversation with Claire Vo, Chief Product Officer of LaunchDarkly, about the changing role of product managers, her anti-to-do list, and building AI-native teams.",
    "summary": "A conversation with Claire Vo, Chief Product Officer of LaunchDarkly, about the changing role of product managers, her anti-to-do list, and building AI-native teams.",
    "pubDate": "Tue, 04 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/launchdarkly-claire-vo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions",
    "description": "Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model's original instructions with their own malicious prompts.",
    "summary": "Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to overwrite a model's original instructions with their own malicious prompts.",
    "pubDate": "Fri, 19 Apr 2024 19:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/the-instruction-hierarchy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Robust Optimization with Diffusion Models for Green Security",
    "description": "arXiv:2503.05730v2 Announce Type: replace-cross Abstract: In green security, defenders must forecast adversarial behavior, such as poaching, illegal logging, and illegal fishing, to plan effective patrols. These behavior are often highly uncertain and complex. Prior work has leveraged game theory to design robust patrol strategies to handle uncertainty, but existing adversarial behavior models primarily rely on Gaussian processes or linear models, which lack the expressiveness needed to capture intricate behavioral patterns. To address this limitation, we propose a conditional diffusion model for adversary behavior modeling, leveraging its strong distribution-fitting capabilities. To the best of our knowledge, this is the first application of diffusion models in the green security domain. Integrating diffusion models into game-theoretic optimization, however, presents new challenges, including a constrained mixed strategy space and the need to sample from an unnormalized distribution to estimate utilities. To tackle these challenges, we introduce a mixed strategy of mixed strategies and employ a twisted Sequential Monte Carlo (SMC) sampler for accurate sampling. Theoretically, our algorithm is guaranteed to converge to an epsilon equilibrium with high probability using a finite number of iterations and samples. Empirically, we evaluate our approach on both synthetic and real-world poaching datasets, demonstrating its effectiveness.",
    "summary": "arXiv:2503.05730v2 Announce Type: replace-cross Abstract: In green security, defenders must forecast adversarial behavior, such as poaching, illegal logging, and illegal fishing, to plan effective patrols. These behavior are often highly uncertain and complex. Prior work has leveraged game theory to design robust patrol strategies to handle uncertainty, but existing adversarial behavior models primarily rely on Gaussian processes or linear models, which lack the expressiveness needed to capture intricate behavioral patterns. To address this limitation, we propose a conditional diffusion model for adversary behavior modeling, leveraging its strong distribution-fitting capabilities. To the best of our knowledge, this is the first application of diffusion models in the green security domain. Integrating diffusion models into game-theoretic optimization, however, presents new challenges, including a constrained mixed strategy space and the need to sample from an unnormalized distribution to estimate utilities. To tackle these challenges, we introduce a mixed strategy of mixed strategies and employ a twisted Sequential Monte Carlo (SMC) sampler for accurate sampling. Theoretically, our algorithm is guaranteed to converge to an epsilon equilibrium with high probability using a finite number of iterations and samples. Empirically, we evaluate our approach on both synthetic and real-world poaching datasets, demonstrating its effectiveness.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.05730",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability",
    "description": "arXiv:2402.09404v2 Announce Type: replace-cross Abstract: This paper introduces AQA-Bench, a novel benchmark to assess the sequential reasoning capabilities of large language models (LLMs) in algorithmic contexts, such as depth-first search (DFS). The key feature of our evaluation benchmark lies in its interactive evaluation protocol - for example, in DFS, the availability of each node's connected edge is contingent upon the model's traversal to that node, thereby necessitating the LLM's ability to effectively remember visited nodes and strategize subsequent moves considering the possible environmental feedback in the future steps. We comprehensively build AQA-Bench with three different algorithms, namely binary search, depth-first search, and breadth-first search, and to evaluate the sequential reasoning ability of 14 different LLMs. Our investigations reveal several interesting findings: (1) Closed-source models like GPT-4 and Gemini generally show much stronger sequential reasoning ability, significantly outperforming open-source LLMs. (2) Naively providing in-context examples may inadvertently hurt few-shot performance in an interactive environment due to over-fitting to examples. (3) Instead of using optimal steps from another test case as the in-context example, a very limited number of predecessor steps in the current test case following the optimal policy can substantially boost small models' performance. (4) The performance gap between weak models and strong models is greatly due to the incapability of weak models to start well. (5) The scaling correlation between performance and model size is not always significant, sometimes even showcasing an inverse trend. We hope our study can catalyze future work on advancing the understanding and enhancement of LLMs' capabilities in sequential reasoning. The code is available at https://github.com/UCSC-VLAA/AQA-Bench.",
    "summary": "arXiv:2402.09404v2 Announce Type: replace-cross Abstract: This paper introduces AQA-Bench, a novel benchmark to assess the sequential reasoning capabilities of large language models (LLMs) in algorithmic contexts, such as depth-first search (DFS). The key feature of our evaluation benchmark lies in its interactive evaluation protocol - for example, in DFS, the availability of each node's connected edge is contingent upon the model's traversal to that node, thereby necessitating the LLM's ability to effectively remember visited nodes and strategize subsequent moves considering the possible environmental feedback in the future steps. We comprehensively build AQA-Bench with three different algorithms, namely binary search, depth-first search, and breadth-first search, and to evaluate the sequential reasoning ability of 14 different LLMs. Our investigations reveal several interesting findings: (1) Closed-source models like GPT-4 and Gemini generally show much stronger sequential reasoning ability, significantly outperforming open-source LLMs. (2) Naively providing in-context examples may inadvertently hurt few-shot performance in an interactive environment due to over-fitting to examples. (3) Instead of using optimal steps from another test case as the in-context example, a very limited number of predecessor steps in the current test case following the optimal policy can substantially boost small models' performance. (4) The performance gap between weak models and strong models is greatly due to the incapability of weak models to start well. (5) The scaling correlation between performance and model size is not always significant, sometimes even showcasing an inverse trend. We hope our study can catalyze future work on advancing the understanding and enhancement of LLMs' capabilities in sequential reasoning. The code is available at https://github.com/UCSC-VLAA/AQA-Bench.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2402.09404",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Universal Assisted Generation: Faster Decoding with Any Assistant Model",
    "description": "",
    "summary": "Universal Assisted Generation: Faster Decoding with Any Assistant Model TL;DR: Many LLMs such as gem...",
    "pubDate": "Tue, 29 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/universal_assisted_generation",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Faulty reward functions in the wild",
    "description": "Reinforcement learning algorithms can break in surprising, counterintuitive ways. In this post we‚Äôll explore one failure mode, which is where you misspecify your reward function.",
    "summary": "Reinforcement learning algorithms can break in surprising, counterintuitive ways. In this post we‚Äôll explore one failure mode, which is where you misspecify your reward function.",
    "pubDate": "Wed, 21 Dec 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/faulty-reward-functions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How to train a Language Model with Megatron-LM",
    "description": "",
    "summary": "How to train a Language Model with Megatron-LM Training large language models in Pytorch requires mo...",
    "pubDate": "Wed, 07 Sep 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/megatron-training",
    "thumbnail": "https://huggingface.co/blog/assets/100_megatron_training/thumbnail.png"
  },
  {
    "title": "Summarizing books with human feedback",
    "description": "Scaling human oversight of AI systems for tasks that are difficult to¬†evaluate.",
    "summary": "Scaling human oversight of AI systems for tasks that are difficult to¬†evaluate.",
    "pubDate": "Thu, 23 Sep 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/summarizing-books",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds",
    "description": "arXiv:2506.21887v1 Announce Type: new Abstract: High-stakes decision-making involves navigating multiple competing objectives with expensive evaluations. For instance, in brachytherapy, clinicians must balance maximizing tumor coverage (e.g., an aspirational target or soft bound of >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard bound of <601 cGy to the bladder), with each plan evaluation being resource-intensive. Selecting Pareto-optimal solutions that match implicit preferences is challenging, as exhaustive Pareto frontier exploration is computationally and cognitively prohibitive, necessitating interactive frameworks to guide users. While decision-makers (DMs) often possess domain knowledge to narrow the search via such soft-hard bounds, current methods often lack systematic approaches to iteratively refine these multi-faceted preference structures. Critically, DMs must trust their final decision, confident they haven't missed superior alternatives; this trust is paramount in high-consequence scenarios. We present Active-MoSH, an interactive local-global framework designed for this process. Its local component integrates soft-hard bounds with probabilistic preference learning, maintaining distributions over DM preferences and bounds for adaptive Pareto subset refinement. This is guided by an active sampling strategy optimizing exploration-exploitation while minimizing cognitive burden. To build DM trust, Active-MoSH's global component, T-MoSH, leverages multi-objective sensitivity analysis to identify potentially overlooked, high-value points beyond immediate feedback. We demonstrate Active-MoSH's performance benefits through diverse synthetic and real-world applications. A user study on AI-generated image selection further validates our hypotheses regarding the framework's ability to improve convergence, enhance DM trust, and provide expressive preference articulation, enabling more effective DMs.",
    "summary": "arXiv:2506.21887v1 Announce Type: new Abstract: High-stakes decision-making involves navigating multiple competing objectives with expensive evaluations. For instance, in brachytherapy, clinicians must balance maximizing tumor coverage (e.g., an aspirational target or soft bound of >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard bound of <601 cGy to the bladder), with each plan evaluation being resource-intensive. Selecting Pareto-optimal solutions that match implicit preferences is challenging, as exhaustive Pareto frontier exploration is computationally and cognitively prohibitive, necessitating interactive frameworks to guide users. While decision-makers (DMs) often possess domain knowledge to narrow the search via such soft-hard bounds, current methods often lack systematic approaches to iteratively refine these multi-faceted preference structures. Critically, DMs must trust their final decision, confident they haven't missed superior alternatives; this trust is paramount in high-consequence scenarios. We present Active-MoSH, an interactive local-global framework designed for this process. Its local component integrates soft-hard bounds with probabilistic preference learning, maintaining distributions over DM preferences and bounds for adaptive Pareto subset refinement. This is guided by an active sampling strategy optimizing exploration-exploitation while minimizing cognitive burden. To build DM trust, Active-MoSH's global component, T-MoSH, leverages multi-objective sensitivity analysis to identify potentially overlooked, high-value points beyond immediate feedback. We demonstrate Active-MoSH's performance benefits through diverse synthetic and real-world applications. A user study on AI-generated image selection further validates our hypotheses regarding the framework's ability to improve convergence, enhance DM trust, and provide expressive preference articulation, enabling more effective DMs.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21887",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "When Can We Reuse a Calibration Set for Multiple Conformal Predictions?",
    "description": "arXiv:2506.19689v1 Announce Type: cross Abstract: Reliable uncertainty quantification is crucial for the trustworthiness of machine learning applications. Inductive Conformal Prediction (ICP) offers a distribution-free framework for generating prediction sets or intervals with user-specified confidence. However, standard ICP guarantees are marginal and typically require a fresh calibration set for each new prediction to maintain their validity. This paper addresses this practical limitation by demonstrating how e-conformal prediction, in conjunction with Hoeffding's inequality, can enable the repeated use of a single calibration set with a high probability of preserving the desired coverage. Through a case study on the CIFAR-10 dataset, we train a deep neural network and utilise a calibration set to estimate a Hoeffding correction. This correction allows us to apply a modified Markov's inequality, leading to the construction of prediction sets with quantifiable confidence. Our results illustrate the feasibility of maintaining provable performance in conformal prediction while enhancing its practicality by reducing the need for repeated calibration. The code for this work is publicly available.",
    "summary": "arXiv:2506.19689v1 Announce Type: cross Abstract: Reliable uncertainty quantification is crucial for the trustworthiness of machine learning applications. Inductive Conformal Prediction (ICP) offers a distribution-free framework for generating prediction sets or intervals with user-specified confidence. However, standard ICP guarantees are marginal and typically require a fresh calibration set for each new prediction to maintain their validity. This paper addresses this practical limitation by demonstrating how e-conformal prediction, in conjunction with Hoeffding's inequality, can enable the repeated use of a single calibration set with a high probability of preserving the desired coverage. Through a case study on the CIFAR-10 dataset, we train a deep neural network and utilise a calibration set to estimate a Hoeffding correction. This correction allows us to apply a modified Markov's inequality, leading to the construction of prediction sets with quantifiable confidence. Our results illustrate the feasibility of maintaining provable performance in conformal prediction while enhancing its practicality by reducing the need for repeated calibration. The code for this work is publicly available.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19689",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "KAG-Thinker: Interactive Thinking and Deep Reasoning in LLMs via Knowledge-Augmented Generation",
    "description": "arXiv:2506.17728v2 Announce Type: replace-cross Abstract: In this paper, we introduce KAG-Thinker, which upgrade KAG to a multi-turn interactive thinking and deep reasoning framework powered by a dedicated parameter-light large language model (LLM). Our approach constructs a structured thinking process for solving complex problems, enhancing the the logical coherence and contextual consistency of the reasoning process in question-answering (Q&amp;A) tasks on domain-specific knowledge bases (KBs) within LLMs. Following the textbf{Logical Form} guided retrieval and reasoning technology route of KAG, this framework first decomposes complex questions into independently solvable sub-problems (which are also referred to as logical forms) through textbf{breadth decomposition}. Each such logical form is represented in two equivalent forms-natural language and logical function-and subsequently classified as either a Knowledge Retrieval or Reasoning Analysis task. Dependencies and parameter passing between these tasks are explicitly modeled via logical function interfaces. In the solving process, the Retrieval function performs retrieval tasks. It retrieves one-hop structured and unstructured information of specified knowledge unit. While the Math and Deduce functions are used to perform reasoning analysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval sub-problem tasks, LLMs and external knowledge sources are regarded as equivalent KBs. We use the textbf{knowledge boundary} module to determine the optimal source using self-regulatory mechanisms such as confidence calibration and reflective reasoning, and use the textbf{depth solving} module to enhance the comprehensiveness of knowledge acquisition...",
    "summary": "arXiv:2506.17728v2 Announce Type: replace-cross Abstract: In this paper, we introduce KAG-Thinker, which upgrade KAG to a multi-turn interactive thinking and deep reasoning framework powered by a dedicated parameter-light large language model (LLM). Our approach constructs a structured thinking process for solving complex problems, enhancing the the logical coherence and contextual consistency of the reasoning process in question-answering (Q&amp;A) tasks on domain-specific knowledge bases (KBs) within LLMs. Following the textbf{Logical Form} guided retrieval and reasoning technology route of KAG, this framework first decomposes complex questions into independently solvable sub-problems (which are also referred to as logical forms) through textbf{breadth decomposition}. Each such logical form is represented in two equivalent forms-natural language and logical function-and subsequently classified as either a Knowledge Retrieval or Reasoning Analysis task. Dependencies and parameter passing between these tasks are explicitly modeled via logical function interfaces. In the solving process, the Retrieval function performs retrieval tasks. It retrieves one-hop structured and unstructured information of specified knowledge unit. While the Math and Deduce functions are used to perform reasoning analysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval sub-problem tasks, LLMs and external knowledge sources are regarded as equivalent KBs. We use the textbf{knowledge boundary} module to determine the optimal source using self-regulatory mechanisms such as confidence calibration and reflective reasoning, and use the textbf{depth solving} module to enhance the comprehensiveness of knowledge acquisition...",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17728",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "GPT-3 powers the next generation of apps",
    "description": "Over 300 applications are delivering GPT-3‚Äìpowered search, conversation, text completion, and other advanced AI features through our¬†API.",
    "summary": "Over 300 applications are delivering GPT-3‚Äìpowered search, conversation, text completion, and other advanced AI features through our¬†API.",
    "pubDate": "Thu, 25 Mar 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-apps",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improved Exploration in GFlownets via Enhanced Epistemic Neural Networks",
    "description": "arXiv:2506.16313v1 Announce Type: cross Abstract: Efficiently identifying the right trajectories for training remains an open problem in GFlowNets. To address this, it is essential to prioritize exploration in regions of the state space where the reward distribution has not been sufficiently learned. This calls for uncertainty-driven exploration, in other words, the agent should be aware of what it does not know. This attribute can be measured by joint predictions, which are particularly important for combinatorial and sequential decision problems. In this research, we integrate epistemic neural networks (ENN) with the conventional architecture of GFlowNets to enable more efficient joint predictions and better uncertainty quantification, thereby improving exploration and the identification of optimal trajectories. Our proposed algorithm, ENN-GFN-Enhanced, is compared to the baseline method in GFlownets and evaluated in grid environments and structured sequence generation in various settings, demonstrating both its efficacy and efficiency.",
    "summary": "arXiv:2506.16313v1 Announce Type: cross Abstract: Efficiently identifying the right trajectories for training remains an open problem in GFlowNets. To address this, it is essential to prioritize exploration in regions of the state space where the reward distribution has not been sufficiently learned. This calls for uncertainty-driven exploration, in other words, the agent should be aware of what it does not know. This attribute can be measured by joint predictions, which are particularly important for combinatorial and sequential decision problems. In this research, we integrate epistemic neural networks (ENN) with the conventional architecture of GFlowNets to enable more efficient joint predictions and better uncertainty quantification, thereby improving exploration and the identification of optimal trajectories. Our proposed algorithm, ENN-GFN-Enhanced, is compared to the baseline method in GFlownets and evaluated in grid environments and structured sequence generation in various settings, demonstrating both its efficacy and efficiency.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16313",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Demonstrating Interoperable Channel State Feedback Compression with Machine Learning",
    "description": "arXiv:2506.21796v1 Announce Type: cross Abstract: Neural network-based compression and decompression of channel state feedback has been one of the most widely studied applications of machine learning (ML) in wireless networks. Various simulation-based studies have shown that ML-based feedback compression can result in reduced overhead and more accurate channel information. However, to the best of our knowledge, there are no real-life proofs of concepts demonstrating the benefits of ML-based channel feedback compression in a practical setting, where the user equipment (UE) and base station have no access to each others' ML models. In this paper, we present a novel approach for training interoperable compression and decompression ML models in a confidential manner, and demonstrate the accuracy of the ensuing models using prototype UEs and base stations. The performance of the ML-based channel feedback is measured both in terms of the accuracy of the reconstructed channel information and achieved downlink throughput gains when using the channel information for beamforming. The reported measurement results demonstrate that it is possible to develop an accurate ML-based channel feedback link without having to share ML models between device and network vendors. These results pave the way for a practical implementation of ML-based channel feedback in commercial 6G networks.",
    "summary": "arXiv:2506.21796v1 Announce Type: cross Abstract: Neural network-based compression and decompression of channel state feedback has been one of the most widely studied applications of machine learning (ML) in wireless networks. Various simulation-based studies have shown that ML-based feedback compression can result in reduced overhead and more accurate channel information. However, to the best of our knowledge, there are no real-life proofs of concepts demonstrating the benefits of ML-based channel feedback compression in a practical setting, where the user equipment (UE) and base station have no access to each others' ML models. In this paper, we present a novel approach for training interoperable compression and decompression ML models in a confidential manner, and demonstrate the accuracy of the ensuing models using prototype UEs and base stations. The performance of the ML-based channel feedback is measured both in terms of the accuracy of the reconstructed channel information and achieved downlink throughput gains when using the channel information for beamforming. The reported measurement results demonstrate that it is possible to develop an accurate ML-based channel feedback link without having to share ML models between device and network vendors. These results pave the way for a practical implementation of ML-based channel feedback in commercial 6G networks.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21796",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerated Inference with Optimum and Transformers Pipelines",
    "description": "",
    "summary": "Accelerated Inference with Optimum and Transformers Pipelines Inference has landed in Optimum with s...",
    "pubDate": "Tue, 10 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-inference",
    "thumbnail": "https://huggingface.co/blog/assets/66_optimum_inference/thumbnail.png"
  },
  {
    "title": "Facial Landmark Visualization and Emotion Recognition Through Neural Networks",
    "description": "arXiv:2506.17191v1 Announce Type: cross Abstract: Emotion recognition from facial images is a crucial task in human-computer interaction, enabling machines to learn human emotions through facial expressions. Previous studies have shown that facial images can be used to train deep learning models; however, most of these studies do not include a through dataset analysis. Visualizing facial landmarks can be challenging when extracting meaningful dataset insights; to address this issue, we propose facial landmark box plots, a visualization technique designed to identify outliers in facial datasets. Additionally, we compare two sets of facial landmark features: (i) the landmarks' absolute positions and (ii) their displacements from a neutral expression to the peak of an emotional expression. Our results indicate that a neural network achieves better performance than a random forest classifier.",
    "summary": "arXiv:2506.17191v1 Announce Type: cross Abstract: Emotion recognition from facial images is a crucial task in human-computer interaction, enabling machines to learn human emotions through facial expressions. Previous studies have shown that facial images can be used to train deep learning models; however, most of these studies do not include a through dataset analysis. Visualizing facial landmarks can be challenging when extracting meaningful dataset insights; to address this issue, we propose facial landmark box plots, a visualization technique designed to identify outliers in facial datasets. Additionally, we compare two sets of facial landmark features: (i) the landmarks' absolute positions and (ii) their displacements from a neutral expression to the peak of an emotional expression. Our results indicate that a neural network achieves better performance than a random forest classifier.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17191",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?",
    "description": "arXiv:2506.21763v1 Announce Type: new Abstract: Large Language Models (LLMs) are accelerating scientific idea generation, but rigorously evaluating these numerous, often superficial, AI-generated propositions for novelty and factual accuracy is a critical bottleneck; manual verification is too slow.Existing validation methods are inadequate: LLMs as standalone verifiers may hallucinate and lack domain knowledge (our findings show ~60% unawareness of relevant papers in specific domains), while traditional citation networks lack explicit causality and narrative surveys are unstructured.This underscores a core challenge: the absence of structured, verifiable, and causally-linked historical data of scientific evolution.To address this,we introduce textbf{THE-Tree} (textbf{T}echnology textbf{H}istory textbf{E}volution Tree), a computational framework that constructs such domain-specific evolution trees from scientific literature.THE-Tree employs a search algorithm to explore evolutionary paths. During its node expansion, it utilizes a novel 'Think-Verbalize-Cite-Verify' process: an LLM proposes potential advancements and cites supporting literature. Critically, each proposed evolutionary link is then validated for logical coherence and evidential support by a recovered natural language inference mechanism that interrogates the cited literature, ensuring that each step is grounded.We construct and validate 88 THE-Trees across diverse domains and release a benchmark dataset including up to 71k fact verifications covering 27k papers to foster further research.Experiments demonstrate that i) in graph completion, our THE-Tree improves hit@1 by 8% to 14% across multiple models compared to traditional citation networks; ii) for predicting future scientific developments, it improves hit@1 metric by nearly 10%; and iii) when combined with other methods, it boosts the performance of evaluating important scientific papers by almost 100%.",
    "summary": "arXiv:2506.21763v1 Announce Type: new Abstract: Large Language Models (LLMs) are accelerating scientific idea generation, but rigorously evaluating these numerous, often superficial, AI-generated propositions for novelty and factual accuracy is a critical bottleneck; manual verification is too slow.Existing validation methods are inadequate: LLMs as standalone verifiers may hallucinate and lack domain knowledge (our findings show ~60% unawareness of relevant papers in specific domains), while traditional citation networks lack explicit causality and narrative surveys are unstructured.This underscores a core challenge: the absence of structured, verifiable, and causally-linked historical data of scientific evolution.To address this,we introduce textbf{THE-Tree} (textbf{T}echnology textbf{H}istory textbf{E}volution Tree), a computational framework that constructs such domain-specific evolution trees from scientific literature.THE-Tree employs a search algorithm to explore evolutionary paths. During its node expansion, it utilizes a novel 'Think-Verbalize-Cite-Verify' process: an LLM proposes potential advancements and cites supporting literature. Critically, each proposed evolutionary link is then validated for logical coherence and evidential support by a recovered natural language inference mechanism that interrogates the cited literature, ensuring that each step is grounded.We construct and validate 88 THE-Trees across diverse domains and release a benchmark dataset including up to 71k fact verifications covering 27k papers to foster further research.Experiments demonstrate that i) in graph completion, our THE-Tree improves hit@1 by 8% to 14% across multiple models compared to traditional citation networks; ii) for predicting future scientific developments, it improves hit@1 metric by nearly 10%; and iii) when combined with other methods, it boosts the performance of evaluating important scientific papers by almost 100%.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21763",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs",
    "description": "arXiv:2506.16962v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) have begun to demonstrate robust reasoning capabilities on general tasks, yet their application in the medical domain remains in its early stages. Constructing chain-of-thought (CoT) training data is essential for bolstering the reasoning abilities of medical MLLMs. However, existing approaches exhibit a deficiency in offering a comprehensive framework for searching and evaluating effective reasoning paths towards critical diagnosis. To address this challenge, we propose Mentor-Intern Collaborative Search (MICS), a novel reasoning-path searching scheme to generate rigorous and effective medical CoT data. MICS first leverages mentor models to initialize the reasoning, one step at a time, then prompts each intern model to continue the thinking along those initiated paths, and finally selects the optimal reasoning path according to the overall reasoning performance of multiple intern models. The reasoning performance is determined by an MICS-Score, which assesses the quality of generated reasoning paths. Eventually, we construct MMRP, a multi-task medical reasoning dataset with ranked difficulty, and Chiron-o1, a new medical MLLM devised via a curriculum learning strategy, with robust visual question-answering and generalizable reasoning capabilities. Extensive experiments demonstrate that Chiron-o1, trained on our CoT dataset constructed using MICS, achieves state-of-the-art performance across a list of medical visual question answering and reasoning benchmarks. Codes are available at GitHub - manglu097/Chiron-o1: Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs",
    "summary": "arXiv:2506.16962v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) have begun to demonstrate robust reasoning capabilities on general tasks, yet their application in the medical domain remains in its early stages. Constructing chain-of-thought (CoT) training data is essential for bolstering the reasoning abilities of medical MLLMs. However, existing approaches exhibit a deficiency in offering a comprehensive framework for searching and evaluating effective reasoning paths towards critical diagnosis. To address this challenge, we propose Mentor-Intern Collaborative Search (MICS), a novel reasoning-path searching scheme to generate rigorous and effective medical CoT data. MICS first leverages mentor models to initialize the reasoning, one step at a time, then prompts each intern model to continue the thinking along those initiated paths, and finally selects the optimal reasoning path according to the overall reasoning performance of multiple intern models. The reasoning performance is determined by an MICS-Score, which assesses the quality of generated reasoning paths. Eventually, we construct MMRP, a multi-task medical reasoning dataset with ranked difficulty, and Chiron-o1, a new medical MLLM devised via a curriculum learning strategy, with robust visual question-answering and generalizable reasoning capabilities. Extensive experiments demonstrate that Chiron-o1, trained on our CoT dataset constructed using MICS, achieves state-of-the-art performance across a list of medical visual question answering and reasoning benchmarks. Codes are available at GitHub - manglu097/Chiron-o1: Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16962",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Problem Solving Through Human-AI Preference-Based Cooperation",
    "description": "arXiv:2408.07461v5 Announce Type: replace Abstract: While there is a widespread belief that artificial general intelligence (AGI) -- or even superhuman AI -- is imminent, complex problems in expert domains are far from being solved. We argue that such problems require human-AI cooperation and that the current state of the art in generative AI is unable to play the role of a reliable partner due to a multitude of shortcomings, including difficulty to keep track of a complex solution artifact (e.g., a software program), limited support for versatile human preference expression and lack of adapting to human preference in an interactive setting. To address these challenges, we propose HAICo2, a novel human-AI co-construction framework. We take first steps towards a formalization of HAICo2 and discuss the difficult open research problems that it faces.",
    "summary": "arXiv:2408.07461v5 Announce Type: replace Abstract: While there is a widespread belief that artificial general intelligence (AGI) -- or even superhuman AI -- is imminent, complex problems in expert domains are far from being solved. We argue that such problems require human-AI cooperation and that the current state of the art in generative AI is unable to play the role of a reliable partner due to a multitude of shortcomings, including difficulty to keep track of a complex solution artifact (e.g., a software program), limited support for versatile human preference expression and lack of adapting to human preference in an interactive setting. To address these challenges, we propose HAICo2, a novel human-AI co-construction framework. We take first steps towards a formalization of HAICo2 and discuss the difficult open research problems that it faces.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.07461",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "1 Billion Classifications",
    "description": "",
    "summary": "1 Billion Classifications You‚Äôve optimized your model. Your pipeline is running smoothly. But now, y...",
    "pubDate": "Thu, 13 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/billion-classifications",
    "thumbnail": "https://huggingface.co/blog/assets/billion-classifications/billion-classifications-thumbnail.png"
  },
  {
    "title": "Few-shot learning in practice: GPT-NEO and the ü§ó Accelerated Inference API",
    "description": "",
    "summary": "Few-shot learning in practice: GPT-Neo and the ü§ó Accelerated Inference API In many Machine Learning ...",
    "pubDate": "Thu, 03 Jun 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning",
    "description": "arXiv:2506.16141v1 Announce Type: cross Abstract: Recent reinforcement learning approaches, such as outcome-supervised GRPO, have advanced Chain-of-Thought reasoning in large language models (LLMs), yet their adaptation to multimodal LLMs (MLLMs) is unexplored. To address the lack of rigorous evaluation for MLLM post-training methods, we introduce SEED-Bench-R1, a benchmark with complex real-world videos requiring balanced perception and reasoning. It offers a large training set and evaluates generalization across three escalating challenges: in-distribution, cross-environment, and cross-environment-task scenarios. Using SEED-Bench-R1, we find that standard GRPO, while improving answer accuracy, often reduces logical coherence between reasoning steps and answers, with only a 57.9% consistency rate. This stems from reward signals focusing solely on final answers, encouraging shortcuts, and strict KL penalties limiting exploration.To address this, we propose GRPO-CARE, a consistency-aware RL framework optimizing both answer correctness and reasoning coherence without explicit supervision. GRPO-CARE introduces a two-tiered reward: (1) a base reward for answer correctness, and (2) an adaptive consistency bonus, computed by comparing the model's reasoning-to-answer likelihood (via a slowly-evolving reference model) against group peers.This dual mechanism amplifies rewards for reasoning paths that are both correct and logically consistent. Replacing KL penalties with this adaptive bonus, GRPO-CARE outperforms standard GRPO on SEED-Bench-R1, achieving a 6.7% performance gain on the hardest evaluation level and a 24.5% improvement in consistency. It also shows strong transferability, improving model performance across diverse video understanding benchmarks. Our work contributes a systematically designed benchmark and a generalizable post-training framework, advancing the development of more interpretable and robust MLLMs.",
    "summary": "arXiv:2506.16141v1 Announce Type: cross Abstract: Recent reinforcement learning approaches, such as outcome-supervised GRPO, have advanced Chain-of-Thought reasoning in large language models (LLMs), yet their adaptation to multimodal LLMs (MLLMs) is unexplored. To address the lack of rigorous evaluation for MLLM post-training methods, we introduce SEED-Bench-R1, a benchmark with complex real-world videos requiring balanced perception and reasoning. It offers a large training set and evaluates generalization across three escalating challenges: in-distribution, cross-environment, and cross-environment-task scenarios. Using SEED-Bench-R1, we find that standard GRPO, while improving answer accuracy, often reduces logical coherence between reasoning steps and answers, with only a 57.9% consistency rate. This stems from reward signals focusing solely on final answers, encouraging shortcuts, and strict KL penalties limiting exploration.To address this, we propose GRPO-CARE, a consistency-aware RL framework optimizing both answer correctness and reasoning coherence without explicit supervision. GRPO-CARE introduces a two-tiered reward: (1) a base reward for answer correctness, and (2) an adaptive consistency bonus, computed by comparing the model's reasoning-to-answer likelihood (via a slowly-evolving reference model) against group peers.This dual mechanism amplifies rewards for reasoning paths that are both correct and logically consistent. Replacing KL penalties with this adaptive bonus, GRPO-CARE outperforms standard GRPO on SEED-Bench-R1, achieving a 6.7% performance gain on the hardest evaluation level and a 24.5% improvement in consistency. It also shows strong transferability, improving model performance across diverse video understanding benchmarks. Our work contributes a systematically designed benchmark and a generalizable post-training framework, advancing the development of more interpretable and robust MLLMs.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16141",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gemini 2.0 is now available to everyone",
    "description": "We‚Äôre announcing new updates to Gemini 2.0 Flash, plus introducing Gemini 2.0 Flash-Lite and Gemini 2.0 Pro Experimental.",
    "summary": "We‚Äôre announcing new updates to Gemini 2.0 Flash, plus introducing Gemini 2.0 Flash-Lite and Gemini 2.0 Pro Experimental.",
    "pubDate": "Wed, 05 Feb 2025 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gemini-2-0-is-now-available-to-everyone/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemini_28.01.25_keyword_social.width-1300.png"
  },
  {
    "title": "AI-based Multimodal Biometrics for Detecting Smartphone Distractions: Application to Online Learning",
    "description": "arXiv:2506.17364v2 Announce Type: replace-cross Abstract: This work investigates the use of multimodal biometrics to detect distractions caused by smartphone use during tasks that require sustained attention, with a focus on computer-based online learning. Although the methods are applicable to various domains, such as autonomous driving, we concentrate on the challenges learners face in maintaining engagement amid internal (e.g., motivation), system-related (e.g., course design) and contextual (e.g., smartphone use) factors. Traditional learning platforms often lack detailed behavioral data, but Multimodal Learning Analytics (MMLA) and biosensors provide new insights into learner attention. We propose an AI-based approach that leverages physiological signals and head pose data to detect phone use. Our results show that single biometric signals, such as brain waves or heart rate, offer limited accuracy, while head pose alone achieves 87%. A multimodal model combining all signals reaches 91% accuracy, highlighting the benefits of integration. We conclude by discussing the implications and limitations of deploying these models for real-time support in online learning environments.",
    "summary": "arXiv:2506.17364v2 Announce Type: replace-cross Abstract: This work investigates the use of multimodal biometrics to detect distractions caused by smartphone use during tasks that require sustained attention, with a focus on computer-based online learning. Although the methods are applicable to various domains, such as autonomous driving, we concentrate on the challenges learners face in maintaining engagement amid internal (e.g., motivation), system-related (e.g., course design) and contextual (e.g., smartphone use) factors. Traditional learning platforms often lack detailed behavioral data, but Multimodal Learning Analytics (MMLA) and biosensors provide new insights into learner attention. We propose an AI-based approach that leverages physiological signals and head pose data to detect phone use. Our results show that single biometric signals, such as brain waves or heart rate, offer limited accuracy, while head pose alone achieves 87%. A multimodal model combining all signals reaches 91% accuracy, highlighting the benefits of integration. We conclude by discussing the implications and limitations of deploying these models for real-time support in online learning environments.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17364",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Content and Product Partnership with Vox Media",
    "description": "In a multi-faceted agreement, Vox Media‚Äôs content will enhance the output of OpenAI‚Äôs ChatGPT, and the company will build on OpenAI‚Äôs technology to develop products to better serve its audiences and advertisers.",
    "summary": "In a multi-faceted agreement, Vox Media‚Äôs content will enhance the output of OpenAI‚Äôs ChatGPT, and the company will build on OpenAI‚Äôs technology to develop products to better serve its audiences and advertisers.",
    "pubDate": "Wed, 29 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-content-and-product-partnership-with-vox-media",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MCP-Zero: Active Tool Discovery for Autonomous LLM Agents",
    "description": "arXiv:2506.01056v4 Announce Type: replace Abstract: True intelligence requires active capability acquisition, yet current LLM agents inject pre-defined tool schemas into prompts, reducing models to passive selectors and falling short of robust general-purpose agency. We introduce MCP-Zero, an active agent framework that restores tool discovery autonomy to LLMs themselves. Instead of overwhelming models with all available tools, MCP-Zero enables agents to actively identify capability gaps, and request specific tools on-demand, transforming them from large-scale retrievers into genuine autonomous agents. The framework operates through three core mechanisms: (1) Active Tool Request, where models autonomously generate structured requests specifying their exact tool requirements; (2) Hierarchical Semantic Routing, a two-stage algorithm that matches requests to relevant servers and tools through improved semantic alignment; (3) Iterative Capability Extension, enabling agents to progressively build cross-domain toolchains while maintaining minimal context footprint. We construct MCP-tools, a comprehensive dataset of 308 MCP servers and 2,797 tools from the official Model-Context-Protocol repository. Experiments demonstrate that MCP-Zero preserves agent autonomy while achieving substantial efficiency gains: (i) accurate tool selection from nearly 3k candidates across 248.1k tokens; (ii) 98% reduction in token consumption on APIBank while maintaining high accuracy; and (iii) consistent multi-turn performance that scales with tool ecosystem growth. This work establishes active tool discovery as a fundamental design pattern for scalable autonomous agent systems.",
    "summary": "arXiv:2506.01056v4 Announce Type: replace Abstract: True intelligence requires active capability acquisition, yet current LLM agents inject pre-defined tool schemas into prompts, reducing models to passive selectors and falling short of robust general-purpose agency. We introduce MCP-Zero, an active agent framework that restores tool discovery autonomy to LLMs themselves. Instead of overwhelming models with all available tools, MCP-Zero enables agents to actively identify capability gaps, and request specific tools on-demand, transforming them from large-scale retrievers into genuine autonomous agents. The framework operates through three core mechanisms: (1) Active Tool Request, where models autonomously generate structured requests specifying their exact tool requirements; (2) Hierarchical Semantic Routing, a two-stage algorithm that matches requests to relevant servers and tools through improved semantic alignment; (3) Iterative Capability Extension, enabling agents to progressively build cross-domain toolchains while maintaining minimal context footprint. We construct MCP-tools, a comprehensive dataset of 308 MCP servers and 2,797 tools from the official Model-Context-Protocol repository. Experiments demonstrate that MCP-Zero preserves agent autonomy while achieving substantial efficiency gains: (i) accurate tool selection from nearly 3k candidates across 248.1k tokens; (ii) 98% reduction in token consumption on APIBank while maintaining high accuracy; and (iii) consistent multi-turn performance that scales with tool ecosystem growth. This work establishes active tool discovery as a fundamental design pattern for scalable autonomous agent systems.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.01056",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Building a Playlist Generator with Sentence Transformers",
    "description": "",
    "summary": "Building a Playlist Generator with Sentence Transformers A short while ago I published a playlist ge...",
    "pubDate": "Wed, 13 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/playlist-generator",
    "thumbnail": "https://huggingface.co/blog/assets/87_playlist_generator/thumbnail.png"
  },
  {
    "title": "VRAIL: Vectorized Reward-based Attribution for Interpretable Learning",
    "description": "arXiv:2506.16014v1 Announce Type: cross Abstract: We propose VRAIL (Vectorized Reward-based Attribution for Interpretable Learning), a bi-level framework for value-based reinforcement learning (RL) that learns interpretable weight representations from state features. VRAIL consists of two stages: a deep learning (DL) stage that fits an estimated value function using state features, and an RL stage that uses this to shape learning via potential-based reward transformations. The estimator is modeled in either linear or quadratic form, allowing attribution of importance to individual features and their interactions. Empirical results on the Taxi-v3 environment demonstrate that VRAIL improves training stability and convergence compared to standard DQN, without requiring environment modifications. Further analysis shows that VRAIL uncovers semantically meaningful subgoals, such as passenger possession, highlighting its ability to produce human-interpretable behavior. Our findings suggest that VRAIL serves as a general, model-agnostic framework for reward shaping that enhances both learning and interpretability.",
    "summary": "arXiv:2506.16014v1 Announce Type: cross Abstract: We propose VRAIL (Vectorized Reward-based Attribution for Interpretable Learning), a bi-level framework for value-based reinforcement learning (RL) that learns interpretable weight representations from state features. VRAIL consists of two stages: a deep learning (DL) stage that fits an estimated value function using state features, and an RL stage that uses this to shape learning via potential-based reward transformations. The estimator is modeled in either linear or quadratic form, allowing attribution of importance to individual features and their interactions. Empirical results on the Taxi-v3 environment demonstrate that VRAIL improves training stability and convergence compared to standard DQN, without requiring environment modifications. Further analysis shows that VRAIL uncovers semantically meaningful subgoals, such as passenger possession, highlighting its ability to produce human-interpretable behavior. Our findings suggest that VRAIL serves as a general, model-agnostic framework for reward shaping that enhances both learning and interpretability.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16014",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Announcing Google DeepMind",
    "description": "DeepMind and the Brain team from Google Research will join forces to accelerate progress towards a world in which AI helps solve the biggest challenges facing humanity.",
    "summary": "DeepMind and the Brain team from Google Research will join forces to accelerate progress towards a world in which AI helps solve the biggest challenges facing humanity.",
    "pubDate": "Thu, 20 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/announcing-google-deepmind/",
    "thumbnail": "https://lh3.googleusercontent.com/MNdJdEO1VpepmU25h9OTpnMr9hxe6NScc1ZWlerWf5WtOYMnHETsPEWKqvG36zQv5CGflTOHAKG_JbADpmLrh8Mrpa91B95U6bs0isMSbTUerT-qT38=w1200-h630-n-nu"
  },
  {
    "title": "Introducing Skops",
    "description": "",
    "summary": "Introducing Skops Introducing Skops At Hugging Face, we are working on tackling various problems in ...",
    "pubDate": "Fri, 12 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/skops",
    "thumbnail": "https://huggingface.co/blog/assets/94_skops/introducing_skops.png"
  },
  {
    "title": "Learning Multi-Branch Cooperation for Enhanced Click-Through Rate Prediction at Taobao",
    "description": "arXiv:2411.13057v2 Announce Type: replace-cross Abstract: Existing click-through rate (CTR) prediction works have studied the role of feature interaction through a variety of techniques. Each interaction technique exhibits its own strength, and solely using one type usually constrains the model's capability to capture the complex feature relationships, especially for industrial data with enormous input feature fields. Recent research shows that effective CTR models often combine an MLP network with a dedicated feature interaction network in a two-parallel structure. However, the interplay and cooperative dynamics between different streams or branches remain under-researched. In this work, we introduce a novel Multi-Branch Cooperation Network (MBCnet) which enables multiple branch networks to collaborate with each other for better complex feature interaction modeling. Specifically, MBCnet consists of three branches: the Extensible Feature Grouping and Crossing (EFGC) branch that promotes the model's memorization ability of specific feature fields, the low rank Cross Net branch and Deep branch to enhance explicit and implicit feature crossing for improved generalization. Among these branches, a novel cooperation scheme is proposed based on two principles: Branch co-teaching and moderate differentiation. Branch co-teaching encourages well-learned branches to support poorly-learned ones on specific training samples. Moderate differentiation advocates branches to maintain a reasonable level of difference in their feature representations on the same inputs. This cooperation strategy improves learning through mutual knowledge sharing and boosts the discovery of diverse feature interactions across branches. Experiments on large-scale industrial datasets and online A/B test at Taobao app demonstrate MBCnet's superior performance, delivering a 0.09 point increase in CTR, 1.49% growth in deals, and 1.62% rise in GMV. Core codes are available online.",
    "summary": "arXiv:2411.13057v2 Announce Type: replace-cross Abstract: Existing click-through rate (CTR) prediction works have studied the role of feature interaction through a variety of techniques. Each interaction technique exhibits its own strength, and solely using one type usually constrains the model's capability to capture the complex feature relationships, especially for industrial data with enormous input feature fields. Recent research shows that effective CTR models often combine an MLP network with a dedicated feature interaction network in a two-parallel structure. However, the interplay and cooperative dynamics between different streams or branches remain under-researched. In this work, we introduce a novel Multi-Branch Cooperation Network (MBCnet) which enables multiple branch networks to collaborate with each other for better complex feature interaction modeling. Specifically, MBCnet consists of three branches: the Extensible Feature Grouping and Crossing (EFGC) branch that promotes the model's memorization ability of specific feature fields, the low rank Cross Net branch and Deep branch to enhance explicit and implicit feature crossing for improved generalization. Among these branches, a novel cooperation scheme is proposed based on two principles: Branch co-teaching and moderate differentiation. Branch co-teaching encourages well-learned branches to support poorly-learned ones on specific training samples. Moderate differentiation advocates branches to maintain a reasonable level of difference in their feature representations on the same inputs. This cooperation strategy improves learning through mutual knowledge sharing and boosts the discovery of diverse feature interactions across branches. Experiments on large-scale industrial datasets and online A/B test at Taobao app demonstrate MBCnet's superior performance, delivering a 0.09 point increase in CTR, 1.49% growth in deals, and 1.62% rise in GMV. Core codes are available online.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.13057",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Announcing the Open Source AI Game Jam üéÆ",
    "description": "",
    "summary": "Announcing the Open Source AI Game Jam üéÆ Unleash Your Creativity with AI Tools and make a game in a ...",
    "pubDate": "Thu, 01 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/game-jam",
    "thumbnail": "https://huggingface.co/blog/assets/145_gamejam/thumbnail.png"
  },
  {
    "title": "Efficient Mixture-of-Expert for Video-based Driver State and Physiological Multi-task Estimation in Conditional Autonomous Driving",
    "description": "arXiv:2410.21086v2 Announce Type: replace-cross Abstract: Road safety remains a critical challenge worldwide, with approximately 1.35 million fatalities annually attributed to traffic accidents, often due to human errors. As we advance towards higher levels of vehicle automation, challenges still exist, as driving with automation can cognitively over-demand drivers if they engage in non-driving-related tasks (NDRTs), or lead to drowsiness if driving was the sole task. This calls for the urgent need for an effective Driver Monitoring System (DMS) that can evaluate cognitive load and drowsiness in SAE Level-2/3 autonomous driving contexts. In this study, we propose a novel multi-task DMS, termed VDMoE, which leverages RGB video input to monitor driver states non-invasively. By utilizing key facial features to minimize computational load and integrating remote Photoplethysmography (rPPG) for physiological insights, our approach enhances detection accuracy while maintaining efficiency. Additionally, we optimize the Mixture-of-Experts (MoE) framework to accommodate multi-modal inputs and improve performance across different tasks. A novel prior-inclusive regularization method is introduced to align model outputs with statistical priors, thus accelerating convergence and mitigating overfitting risks. We validate our method with the creation of a new dataset (MCDD), which comprises RGB video and physiological indicators from 42 participants, and two public datasets. Our findings demonstrate the effectiveness of VDMoE in monitoring driver states, contributing to safer autonomous driving systems. The code and data will be released.",
    "summary": "arXiv:2410.21086v2 Announce Type: replace-cross Abstract: Road safety remains a critical challenge worldwide, with approximately 1.35 million fatalities annually attributed to traffic accidents, often due to human errors. As we advance towards higher levels of vehicle automation, challenges still exist, as driving with automation can cognitively over-demand drivers if they engage in non-driving-related tasks (NDRTs), or lead to drowsiness if driving was the sole task. This calls for the urgent need for an effective Driver Monitoring System (DMS) that can evaluate cognitive load and drowsiness in SAE Level-2/3 autonomous driving contexts. In this study, we propose a novel multi-task DMS, termed VDMoE, which leverages RGB video input to monitor driver states non-invasively. By utilizing key facial features to minimize computational load and integrating remote Photoplethysmography (rPPG) for physiological insights, our approach enhances detection accuracy while maintaining efficiency. Additionally, we optimize the Mixture-of-Experts (MoE) framework to accommodate multi-modal inputs and improve performance across different tasks. A novel prior-inclusive regularization method is introduced to align model outputs with statistical priors, thus accelerating convergence and mitigating overfitting risks. We validate our method with the creation of a new dataset (MCDD), which comprises RGB video and physiological indicators from 42 participants, and two public datasets. Our findings demonstrate the effectiveness of VDMoE in monitoring driver states, contributing to safer autonomous driving systems. The code and data will be released.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.21086",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Every Rollout Counts: Optimal Resource Allocation for Efficient Test-Time Scaling",
    "description": "arXiv:2506.15707v1 Announce Type: cross Abstract: Test-Time Scaling (TTS) improves the performance of Large Language Models (LLMs) by using additional inference-time computation to explore multiple reasoning paths through search. Yet how to allocate a fixed rollout budget most effectively during search remains underexplored, often resulting in inefficient use of compute at test time. To bridge this gap, we formulate test-time search as a resource allocation problem and derive the optimal allocation strategy that maximizes the probability of obtaining a correct solution under a fixed rollout budget. Within this formulation, we reveal a core limitation of existing search methods: solution-level allocation tends to favor reasoning directions with more candidates, leading to theoretically suboptimal and inefficient use of compute. To address this, we propose Direction-Oriented Resource Allocation (DORA), a provably optimal method that mitigates this bias by decoupling direction quality from candidate count and allocating resources at the direction level. To demonstrate DORA's effectiveness, we conduct extensive experiments on challenging mathematical reasoning benchmarks including MATH500, AIME2024, and AIME2025. The empirical results show that DORA consistently outperforms strong baselines with comparable computational cost, achieving state-of-the-art accuracy. We hope our findings contribute to a broader understanding of optimal TTS for LLMs.",
    "summary": "arXiv:2506.15707v1 Announce Type: cross Abstract: Test-Time Scaling (TTS) improves the performance of Large Language Models (LLMs) by using additional inference-time computation to explore multiple reasoning paths through search. Yet how to allocate a fixed rollout budget most effectively during search remains underexplored, often resulting in inefficient use of compute at test time. To bridge this gap, we formulate test-time search as a resource allocation problem and derive the optimal allocation strategy that maximizes the probability of obtaining a correct solution under a fixed rollout budget. Within this formulation, we reveal a core limitation of existing search methods: solution-level allocation tends to favor reasoning directions with more candidates, leading to theoretically suboptimal and inefficient use of compute. To address this, we propose Direction-Oriented Resource Allocation (DORA), a provably optimal method that mitigates this bias by decoupling direction quality from candidate count and allocating resources at the direction level. To demonstrate DORA's effectiveness, we conduct extensive experiments on challenging mathematical reasoning benchmarks including MATH500, AIME2024, and AIME2025. The empirical results show that DORA consistently outperforms strong baselines with comparable computational cost, achieving state-of-the-art accuracy. We hope our findings contribute to a broader understanding of optimal TTS for LLMs.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15707",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "New in ChatGPT for Business: March 2025",
    "description": "Join us as we share our latest releases and how ChatGPT is becoming more interactive, customized to the way your teams work, and agentic.",
    "summary": "Join us as we share our latest releases and how ChatGPT is becoming more interactive, customized to the way your teams work, and agentic.",
    "pubDate": "Tue, 18 Mar 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/new-in-chatgpt-for-work-march-updates-2025",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generating Stories: AI for Game Development #5",
    "description": "",
    "summary": "Generating Stories: AI for Game Development #5 Welcome to AI for Game Development! In this series, w...",
    "pubDate": "Tue, 07 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-5",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail5.png"
  },
  {
    "title": "Cellular Traffic Prediction via Deep State Space Models with Attention Mechanism",
    "description": "arXiv:2506.15688v1 Announce Type: cross Abstract: Cellular traffic prediction is of great importance for operators to manage network resources and make decisions. Traffic is highly dynamic and influenced by many exogenous factors, which would lead to the degradation of traffic prediction accuracy. This paper proposes an end-to-end framework with two variants to explicitly characterize the spatiotemporal patterns of cellular traffic among neighboring cells. It uses convolutional neural networks with an attention mechanism to capture the spatial dynamics and Kalman filter for temporal modelling. Besides, we can fully exploit the auxiliary information such as social activities to improve prediction performance. We conduct extensive experiments on three real-world datasets. The results show that our proposed models outperform the state-of-the-art machine learning techniques in terms of prediction accuracy.",
    "summary": "arXiv:2506.15688v1 Announce Type: cross Abstract: Cellular traffic prediction is of great importance for operators to manage network resources and make decisions. Traffic is highly dynamic and influenced by many exogenous factors, which would lead to the degradation of traffic prediction accuracy. This paper proposes an end-to-end framework with two variants to explicitly characterize the spatiotemporal patterns of cellular traffic among neighboring cells. It uses convolutional neural networks with an attention mechanism to capture the spatial dynamics and Kalman filter for temporal modelling. Besides, we can fully exploit the auxiliary information such as social activities to improve prediction performance. We conduct extensive experiments on three real-world datasets. The results show that our proposed models outperform the state-of-the-art machine learning techniques in terms of prediction accuracy.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15688",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response",
    "description": "arXiv:2502.18452v2 Announce Type: replace-cross Abstract: During Human Robot Interactions in disaster relief scenarios, Large Language Models (LLMs) have the potential for substantial physical reasoning to assist in mission objectives. However, these capabilities are often found only in larger models, which are frequently not reasonable to deploy on robotic systems. To meet our problem space requirements, we introduce a dataset and pipeline to create Field Reasoning and Instruction Decoding Agent (FRIDA) models. In our pipeline, domain experts and linguists combine their knowledge to make high-quality few-shot prompts used to generate synthetic data for fine-tuning. We hand-curate datasets for this few-shot prompting and for evaluation to improve LLM reasoning on both general and disaster-specific objects. We concurrently run an ablation study to understand which kinds of synthetic data most affect performance. We fine-tune several small instruction-tuned models and find that ablated FRIDA models only trained on objects' physical state and function data outperformed both the FRIDA models trained on all synthetic data and the base models in our customized evaluation. We demonstrate that the FRIDA pipeline is capable of instilling physical common sense with minimal data.",
    "summary": "arXiv:2502.18452v2 Announce Type: replace-cross Abstract: During Human Robot Interactions in disaster relief scenarios, Large Language Models (LLMs) have the potential for substantial physical reasoning to assist in mission objectives. However, these capabilities are often found only in larger models, which are frequently not reasonable to deploy on robotic systems. To meet our problem space requirements, we introduce a dataset and pipeline to create Field Reasoning and Instruction Decoding Agent (FRIDA) models. In our pipeline, domain experts and linguists combine their knowledge to make high-quality few-shot prompts used to generate synthetic data for fine-tuning. We hand-curate datasets for this few-shot prompting and for evaluation to improve LLM reasoning on both general and disaster-specific objects. We concurrently run an ablation study to understand which kinds of synthetic data most affect performance. We fine-tune several small instruction-tuned models and find that ablated FRIDA models only trained on objects' physical state and function data outperformed both the FRIDA models trained on all synthetic data and the base models in our customized evaluation. We demonstrate that the FRIDA pipeline is capable of instilling physical common sense with minimal data.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.18452",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Argilla 2.4: Easily Build Fine-Tuning and Evaluation datasets on the Hub ‚Äî No Code Required",
    "description": "",
    "summary": "Argilla 2.4: Easily Build Fine-Tuning and Evaluation Datasets on the Hub ‚Äî No Code Required We are i...",
    "pubDate": "Mon, 04 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/argilla-ui-hub",
    "thumbnail": "https://huggingface.co/blog/assets/argilla-ui-hub/thumbnail.png"
  },
  {
    "title": "AI's Blind Spots: Geographic Knowledge and Diversity Deficit in Generated Urban Scenario",
    "description": "arXiv:2506.16898v1 Announce Type: new Abstract: Image generation models are revolutionizing many domains, and urban analysis and design is no exception. While such models are widely adopted, there is a limited literature exploring their geographic knowledge, along with the biases they embed. In this work, we generated 150 synthetic images for each state in the USA and related capitals using FLUX 1 and Stable Diffusion 3.5, two state-of-the-art models for image generation. We embed each image using DINO-v2 ViT-S/14 and the Fr'echet Inception Distances to measure the similarity between the generated images. We found that while these models have implicitly learned aspects of USA geography, if we prompt the models to generate an image for 'United States' instead of specific cities or states, the models exhibit a strong representative bias toward metropolis-like areas, excluding rural states and smaller cities. {color{black} In addition, we found that models systematically exhibit some entity-disambiguation issues with European-sounding names like Frankfort or Devon.",
    "summary": "arXiv:2506.16898v1 Announce Type: new Abstract: Image generation models are revolutionizing many domains, and urban analysis and design is no exception. While such models are widely adopted, there is a limited literature exploring their geographic knowledge, along with the biases they embed. In this work, we generated 150 synthetic images for each state in the USA and related capitals using FLUX 1 and Stable Diffusion 3.5, two state-of-the-art models for image generation. We embed each image using DINO-v2 ViT-S/14 and the Fr'echet Inception Distances to measure the similarity between the generated images. We found that while these models have implicitly learned aspects of USA geography, if we prompt the models to generate an image for 'United States' instead of specific cities or states, the models exhibit a strong representative bias toward metropolis-like areas, excluding rural states and smaller cities. {color{black} In addition, we found that models systematically exhibit some entity-disambiguation issues with European-sounding names like Frankfort or Devon.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16898",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Envisioning a future where health care tech leaves some behind",
    "description": "The winning essay of the Envisioning the Future of Computing Prize puts health care disparities at the forefront.",
    "summary": "The winning essay of the Envisioning the Future of Computing Prize puts health care disparities at the forefront.",
    "pubDate": "Mon, 09 Jun 2025 16:10:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/envisioning-future-where-health-care-tech-leaves-some-behind-0609",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/Annaliese%20statue%20crop_v2.jpg"
  },
  {
    "title": "Stylized Structural Patterns for Improved Neural Network Pre-training",
    "description": "arXiv:2506.19465v1 Announce Type: cross Abstract: Modern deep learning models in computer vision require large datasets of real images, which are difficult to curate and pose privacy and legal concerns, limiting their commercial use. Recent works suggest synthetic data as an alternative, yet models trained with it often underperform. This paper proposes a two-step approach to bridge this gap. First, we propose an improved neural fractal formulation through which we introduce a new class of synthetic data. Second, we propose reverse stylization, a technique that transfers visual features from a small, license-free set of real images onto synthetic datasets, enhancing their effectiveness. We analyze the domain gap between our synthetic datasets and real images using Kernel Inception Distance (KID) and show that our method achieves a significantly lower distributional gap compared to existing synthetic datasets. Furthermore, our experiments across different tasks demonstrate the practical impact of this reduced gap. We show that pretraining the EDM2 diffusion model on our synthetic dataset leads to an 11% reduction in FID during image generation, compared to models trained on existing synthetic datasets, and a 20% decrease in autoencoder reconstruction error, indicating improved performance in data representation. Furthermore, a ViT-S model trained for classification on this synthetic data achieves over a 10% improvement in ImageNet-100 accuracy. Our work opens up exciting possibilities for training practical models when sufficiently large real training sets are not available.",
    "summary": "arXiv:2506.19465v1 Announce Type: cross Abstract: Modern deep learning models in computer vision require large datasets of real images, which are difficult to curate and pose privacy and legal concerns, limiting their commercial use. Recent works suggest synthetic data as an alternative, yet models trained with it often underperform. This paper proposes a two-step approach to bridge this gap. First, we propose an improved neural fractal formulation through which we introduce a new class of synthetic data. Second, we propose reverse stylization, a technique that transfers visual features from a small, license-free set of real images onto synthetic datasets, enhancing their effectiveness. We analyze the domain gap between our synthetic datasets and real images using Kernel Inception Distance (KID) and show that our method achieves a significantly lower distributional gap compared to existing synthetic datasets. Furthermore, our experiments across different tasks demonstrate the practical impact of this reduced gap. We show that pretraining the EDM2 diffusion model on our synthetic dataset leads to an 11% reduction in FID during image generation, compared to models trained on existing synthetic datasets, and a 20% decrease in autoencoder reconstruction error, indicating improved performance in data representation. Furthermore, a ViT-S model trained for classification on this synthetic data achieves over a 10% improvement in ImageNet-100 accuracy. Our work opens up exciting possibilities for training practical models when sufficiently large real training sets are not available.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19465",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI en France",
    "description": "Our first office in continental Europe",
    "summary": "Our first office in continental Europe",
    "pubDate": "Fri, 15 Nov 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-en-france",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Dynamic Adaptive Optimization for Effective Sentiment Analysis Fine-Tuning on Large Language Models",
    "description": "arXiv:2408.11856v3 Announce Type: replace-cross Abstract: Sentiment analysis plays a crucial role in various domains, such as business intelligence and financial forecasting. Large language models (LLMs) have become a popular paradigm for sentiment analysis, leveraging multi-task learning to address specific tasks concurrently. However, LLMs with fine-tuning for sentiment analysis often underperforms due to the inherent challenges in managing diverse task complexities. Moreover, constant-weight approaches in multi-task learning struggle to adapt to variations in data characteristics, further complicating model effectiveness. To address these issues, we propose a novel multi-task learning framework with a dynamic adaptive optimization (DAO) module. This module is designed as a plug-and-play component that can be seamlessly integrated into existing models, providing an effective and flexible solution for multi-task learning. The key component of the DAO module is dynamic adaptive loss, which dynamically adjusts the weights assigned to different tasks based on their relative importance and data characteristics during training. Sentiment analyses on a standard and customized financial text dataset demonstrate that the proposed framework achieves superior performance. Specifically, this work improves the Mean Squared Error (MSE) and Accuracy (ACC) by 15.58% and 1.24% respectively, compared with previous work.",
    "summary": "arXiv:2408.11856v3 Announce Type: replace-cross Abstract: Sentiment analysis plays a crucial role in various domains, such as business intelligence and financial forecasting. Large language models (LLMs) have become a popular paradigm for sentiment analysis, leveraging multi-task learning to address specific tasks concurrently. However, LLMs with fine-tuning for sentiment analysis often underperforms due to the inherent challenges in managing diverse task complexities. Moreover, constant-weight approaches in multi-task learning struggle to adapt to variations in data characteristics, further complicating model effectiveness. To address these issues, we propose a novel multi-task learning framework with a dynamic adaptive optimization (DAO) module. This module is designed as a plug-and-play component that can be seamlessly integrated into existing models, providing an effective and flexible solution for multi-task learning. The key component of the DAO module is dynamic adaptive loss, which dynamically adjusts the weights assigned to different tasks based on their relative importance and data characteristics during training. Sentiment analyses on a standard and customized financial text dataset demonstrate that the proposed framework achieves superior performance. Specifically, this work improves the Mean Squared Error (MSE) and Accuracy (ACC) by 15.58% and 1.24% respectively, compared with previous work.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.11856",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face on PyTorch / XLA TPUs",
    "description": "",
    "summary": "Hugging Face on PyTorch / XLA TPUs: Faster and cheaper training Training Your Favorite Transformers ...",
    "pubDate": "Tue, 09 Feb 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-xla",
    "thumbnail": "https://huggingface.co/blog/assets/13_pytorch_xla/pytorch_xla_thumbnail.png"
  },
  {
    "title": "OpenAI and Reddit Partnership",
    "description": "OpenAI and Reddit Partnership We‚Äôre bringing Reddit‚Äôs unique content to ChatGPT and our products.",
    "summary": "OpenAI and Reddit Partnership We‚Äôre bringing Reddit‚Äôs unique content to ChatGPT and our products.",
    "pubDate": "Thu, 16 May 2024 13:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-and-reddit-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face x LangChain : A new partner package in LangChain",
    "description": "",
    "summary": "Hugging Face x LangChain : A new partner package in LangChain We are thrilled to announce the launch...",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/langchain",
    "thumbnail": "https://huggingface.co/blog/assets/langchain_huggingface/thumbnail.png"
  },
  {
    "title": "Image GPT",
    "description": "We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image¬†completions¬†and¬†samples. By establishing a correlation between sample quality and image classification accuracy, we show that our best generative model also contains features competitive with top convolutional nets in the unsupervised¬†setting.",
    "summary": "We find that, just as a large transformer model trained on language can generate coherent text, the same exact model trained on pixel sequences can generate coherent image¬†completions¬†and¬†samples. By establishing a correlation between sample quality and image classification accuracy, we show that our best generative model also contains features competitive with top convolutional nets in the unsupervised¬†setting.",
    "pubDate": "Wed, 17 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/image-gpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Our response to the UK‚Äôs copyright consultation",
    "description": "Recommendations for pro-innovation policies that can help make the UK the AI capital of Europe.",
    "summary": "Recommendations for pro-innovation policies that can help make the UK the AI capital of Europe.",
    "pubDate": "Wed, 02 Apr 2025 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/response-to-uk-copyright-consultation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "KVCache Cache in the Wild: Characterizing and Optimizing KVCache Cache at a Large Cloud Provider",
    "description": "arXiv:2506.02634v3 Announce Type: replace-cross Abstract: Serving large language models (LLMs) is important for cloud providers, and caching intermediate results (KV$) after processing each request substantially improves serving throughput and latency. However, there is limited understanding of how LLM serving benefits from KV$ caching, where system design decisions like cache eviction policies are highly workload-dependent. In this paper, we present the first systematic characterization of the KV$ workload patterns from one of the leading LLM service providers. We draw observations that were not covered by previous studies focusing on synthetic workloads, including: KV$ reuses are skewed across requests, where reuses between single-turn requests are equally important as multi-turn requests; the reuse time and probability are diverse considering all requests, but for a specific request category, the pattern tends to be predictable; and the overall cache size required for an ideal cache hit ratio is moderate. Based on the characterization, we further propose a workload-aware cache eviction policy that improves the serving performance under real-world traces, especially with limited cache capacity.",
    "summary": "arXiv:2506.02634v3 Announce Type: replace-cross Abstract: Serving large language models (LLMs) is important for cloud providers, and caching intermediate results (KV$) after processing each request substantially improves serving throughput and latency. However, there is limited understanding of how LLM serving benefits from KV$ caching, where system design decisions like cache eviction policies are highly workload-dependent. In this paper, we present the first systematic characterization of the KV$ workload patterns from one of the leading LLM service providers. We draw observations that were not covered by previous studies focusing on synthetic workloads, including: KV$ reuses are skewed across requests, where reuses between single-turn requests are equally important as multi-turn requests; the reuse time and probability are diverse considering all requests, but for a specific request category, the pattern tends to be predictable; and the overall cache size required for an ideal cache hit ratio is moderate. Based on the characterization, we further propose a workload-aware cache eviction policy that improves the serving performance under real-world traces, especially with limited cache capacity.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.02634",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AerialVG: A Challenging Benchmark for Aerial Visual Grounding by Exploring Positional Relations",
    "description": "arXiv:2504.07836v3 Announce Type: replace-cross Abstract: Visual grounding (VG) aims to localize target objects in an image based on natural language descriptions. In this paper, we propose AerialVG, a new task focusing on visual grounding from aerial views. Compared to traditional VG, AerialVG poses new challenges, emph{e.g.}, appearance-based grounding is insufficient to distinguish among multiple visually similar objects, and positional relations should be emphasized. Besides, existing VG models struggle when applied to aerial imagery, where high-resolution images cause significant difficulties. To address these challenges, we introduce the first AerialVG dataset, consisting of 5K real-world aerial images, 50K manually annotated descriptions, and 103K objects. Particularly, each annotation in AerialVG dataset contains multiple target objects annotated with relative spatial relations, requiring models to perform comprehensive spatial reasoning. Furthermore, we propose an innovative model especially for the AerialVG task, where a Hierarchical Cross-Attention is devised to focus on target regions, and a Relation-Aware Grounding module is designed to infer positional relations. Experimental results validate the effectiveness of our dataset and method, highlighting the importance of spatial reasoning in aerial visual grounding. The code and dataset will be released.",
    "summary": "arXiv:2504.07836v3 Announce Type: replace-cross Abstract: Visual grounding (VG) aims to localize target objects in an image based on natural language descriptions. In this paper, we propose AerialVG, a new task focusing on visual grounding from aerial views. Compared to traditional VG, AerialVG poses new challenges, emph{e.g.}, appearance-based grounding is insufficient to distinguish among multiple visually similar objects, and positional relations should be emphasized. Besides, existing VG models struggle when applied to aerial imagery, where high-resolution images cause significant difficulties. To address these challenges, we introduce the first AerialVG dataset, consisting of 5K real-world aerial images, 50K manually annotated descriptions, and 103K objects. Particularly, each annotation in AerialVG dataset contains multiple target objects annotated with relative spatial relations, requiring models to perform comprehensive spatial reasoning. Furthermore, we propose an innovative model especially for the AerialVG task, where a Hierarchical Cross-Attention is devised to focus on target regions, and a Relation-Aware Grounding module is designed to infer positional relations. Experimental results validate the effectiveness of our dataset and method, highlighting the importance of spatial reasoning in aerial visual grounding. The code and dataset will be released.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.07836",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Temporal-IRL: Modeling Port Congestion and Berth Scheduling with Inverse Reinforcement Learning",
    "description": "arXiv:2506.19843v1 Announce Type: new Abstract: Predicting port congestion is crucial for maintaining reliable global supply chains. Accurate forecasts enableimprovedshipment planning, reducedelaysand costs, and optimizeinventoryanddistributionstrategies, thereby ensuring timely deliveries and enhancing supply chain resilience. To achieve accurate predictions, analyzing vessel behavior and their stay times at specific port terminals is essential, focusing particularly on berth scheduling under various conditions. Crucially, the model must capture and learn the underlying priorities and patterns of berth scheduling. Berth scheduling and planning are influenced by a range of factors, including incoming vessel size, waiting times, and the status of vessels within the port terminal. By observing historical Automatic Identification System (AIS) positions of vessels, we reconstruct berth schedules, which are subsequently utilized to determine the reward function via Inverse Reinforcement Learning (IRL). For this purpose, we modeled a specific terminal at the Port of New York/New Jersey and developed Temporal-IRL. This Temporal-IRL model learns berth scheduling to predict vessel sequencing at the terminal and estimate vessel port stay, encompassing both waiting and berthing times, to forecast port congestion. Utilizing data from Maher Terminal spanning January 2015 to September 2023, we trained and tested the model, achieving demonstrably excellent results.",
    "summary": "arXiv:2506.19843v1 Announce Type: new Abstract: Predicting port congestion is crucial for maintaining reliable global supply chains. Accurate forecasts enableimprovedshipment planning, reducedelaysand costs, and optimizeinventoryanddistributionstrategies, thereby ensuring timely deliveries and enhancing supply chain resilience. To achieve accurate predictions, analyzing vessel behavior and their stay times at specific port terminals is essential, focusing particularly on berth scheduling under various conditions. Crucially, the model must capture and learn the underlying priorities and patterns of berth scheduling. Berth scheduling and planning are influenced by a range of factors, including incoming vessel size, waiting times, and the status of vessels within the port terminal. By observing historical Automatic Identification System (AIS) positions of vessels, we reconstruct berth schedules, which are subsequently utilized to determine the reward function via Inverse Reinforcement Learning (IRL). For this purpose, we modeled a specific terminal at the Port of New York/New Jersey and developed Temporal-IRL. This Temporal-IRL model learns berth scheduling to predict vessel sequencing at the terminal and estimate vessel port stay, encompassing both waiting and berthing times, to forecast port congestion. Utilizing data from Maher Terminal spanning January 2015 to September 2023, we trained and tested the model, achieving demonstrably excellent results.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19843",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How to Install and Use the Hugging Face Unity API",
    "description": "",
    "summary": "How to Install and Use the Hugging Face Unity API The Hugging Face Unity API is an easy-to-use integ...",
    "pubDate": "Mon, 01 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-api",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-api-thumbnail.png"
  },
  {
    "title": "Uncovering Conceptual Blindspots in Generative Image Models Using Sparse Autoencoders",
    "description": "arXiv:2506.19708v1 Announce Type: cross Abstract: Despite their impressive performance, generative image models trained on large-scale datasets frequently fail to produce images with seemingly simple concepts -- e.g., human hands or objects appearing in groups of four -- that are reasonably expected to appear in the training data. These failure modes have largely been documented anecdotally, leaving open the question of whether they reflect idiosyncratic anomalies or more structural limitations of these models. To address this, we introduce a systematic approach for identifying and characterizing 'conceptual blindspots' -- concepts present in the training data but absent or misrepresented in a model's generations. Our method leverages sparse autoencoders (SAEs) to extract interpretable concept embeddings, enabling a quantitative comparison of concept prevalence between real and generated images. We train an archetypal SAE (RA-SAE) on DINOv2 features with 32,000 concepts -- the largest such SAE to date -- enabling fine-grained analysis of conceptual disparities. Applied to four popular generative models (Stable Diffusion 1.5/2.1, PixArt, and Kandinsky), our approach reveals specific suppressed blindspots (e.g., bird feeders, DVD discs, and whitespaces on documents) and exaggerated blindspots (e.g., wood background texture and palm trees). At the individual datapoint level, we further isolate memorization artifacts -- instances where models reproduce highly specific visual templates seen during training. Overall, we propose a theoretically grounded framework for systematically identifying conceptual blindspots in generative models by assessing their conceptual fidelity with respect to the underlying data-generating process.",
    "summary": "arXiv:2506.19708v1 Announce Type: cross Abstract: Despite their impressive performance, generative image models trained on large-scale datasets frequently fail to produce images with seemingly simple concepts -- e.g., human hands or objects appearing in groups of four -- that are reasonably expected to appear in the training data. These failure modes have largely been documented anecdotally, leaving open the question of whether they reflect idiosyncratic anomalies or more structural limitations of these models. To address this, we introduce a systematic approach for identifying and characterizing 'conceptual blindspots' -- concepts present in the training data but absent or misrepresented in a model's generations. Our method leverages sparse autoencoders (SAEs) to extract interpretable concept embeddings, enabling a quantitative comparison of concept prevalence between real and generated images. We train an archetypal SAE (RA-SAE) on DINOv2 features with 32,000 concepts -- the largest such SAE to date -- enabling fine-grained analysis of conceptual disparities. Applied to four popular generative models (Stable Diffusion 1.5/2.1, PixArt, and Kandinsky), our approach reveals specific suppressed blindspots (e.g., bird feeders, DVD discs, and whitespaces on documents) and exaggerated blindspots (e.g., wood background texture and palm trees). At the individual datapoint level, we further isolate memorization artifacts -- instances where models reproduce highly specific visual templates seen during training. Overall, we propose a theoretically grounded framework for systematically identifying conceptual blindspots in generative models by assessing their conceptual fidelity with respect to the underlying data-generating process.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19708",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MimicMotion: High-Quality Human Motion Video Generation with Confidence-aware Pose Guidance",
    "description": "arXiv:2406.19680v2 Announce Type: replace-cross Abstract: In recent years, generative artificial intelligence has achieved significant advancements in the field of image generation, spawning a variety of applications. However, video generation still faces considerable challenges in various aspects, such as controllability, video length, and richness of details, which hinder the application and popularization of this technology. In this work, we propose a controllable video generation framework, dubbed MimicMotion, which can generate high-quality videos of arbitrary length mimicking specific motion guidance. Compared with previous methods, our approach has several highlights. Firstly, we introduce confidence-aware pose guidance that ensures high frame quality and temporal smoothness. Secondly, we introduce regional loss amplification based on pose confidence, which significantly reduces image distortion. Lastly, for generating long and smooth videos, we propose a progressive latent fusion strategy. By this means, we can produce videos of arbitrary length with acceptable resource consumption. With extensive experiments and user studies, MimicMotion demonstrates significant improvements over previous approaches in various aspects. Detailed results and comparisons are available on our project page: https://tencent.github.io/MimicMotion .",
    "summary": "arXiv:2406.19680v2 Announce Type: replace-cross Abstract: In recent years, generative artificial intelligence has achieved significant advancements in the field of image generation, spawning a variety of applications. However, video generation still faces considerable challenges in various aspects, such as controllability, video length, and richness of details, which hinder the application and popularization of this technology. In this work, we propose a controllable video generation framework, dubbed MimicMotion, which can generate high-quality videos of arbitrary length mimicking specific motion guidance. Compared with previous methods, our approach has several highlights. Firstly, we introduce confidence-aware pose guidance that ensures high frame quality and temporal smoothness. Secondly, we introduce regional loss amplification based on pose confidence, which significantly reduces image distortion. Lastly, for generating long and smooth videos, we propose a progressive latent fusion strategy. By this means, we can produce videos of arbitrary length with acceptable resource consumption. With extensive experiments and user studies, MimicMotion demonstrates significant improvements over previous approaches in various aspects. Detailed results and comparisons are available on our project page: https://tencent.github.io/MimicMotion .",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.19680",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robust adversarial inputs",
    "description": "We‚Äôve created images that reliably fool neural network classifiers when viewed from varied scales and perspectives. This challenges a claim from last week that self-driving cars would be hard to trick maliciously since they capture images from multiple scales, angles, perspectives, and the like.",
    "summary": "We‚Äôve created images that reliably fool neural network classifiers when viewed from varied scales and perspectives. This challenges a claim from last week that self-driving cars would be hard to trick maliciously since they capture images from multiple scales, angles, perspectives, and the like.",
    "pubDate": "Mon, 17 Jul 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/robust-adversarial-inputs",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interpretable Hybrid Machine Learning Models Using FOLD-R++ and Answer Set Programming",
    "description": "arXiv:2506.19573v1 Announce Type: new Abstract: Machine learning (ML) techniques play a pivotal role in high-stakes domains such as healthcare, where accurate predictions can greatly enhance decision-making. However, most high-performing methods such as neural networks and ensemble methods are often opaque, limiting trust and broader adoption. In parallel, symbolic methods like Answer Set Programming (ASP) offer the possibility of interpretable logical rules but do not always match the predictive power of ML models. This paper proposes a hybrid approach that integrates ASP-derived rules from the FOLD-R++ algorithm with black-box ML classifiers to selectively correct uncertain predictions and provide human-readable explanations. Experiments on five medical datasets reveal statistically significant performance gains in accuracy and F1 score. This study underscores the potential of combining symbolic reasoning with conventional ML to achieve high interpretability without sacrificing accuracy.",
    "summary": "arXiv:2506.19573v1 Announce Type: new Abstract: Machine learning (ML) techniques play a pivotal role in high-stakes domains such as healthcare, where accurate predictions can greatly enhance decision-making. However, most high-performing methods such as neural networks and ensemble methods are often opaque, limiting trust and broader adoption. In parallel, symbolic methods like Answer Set Programming (ASP) offer the possibility of interpretable logical rules but do not always match the predictive power of ML models. This paper proposes a hybrid approach that integrates ASP-derived rules from the FOLD-R++ algorithm with black-box ML classifiers to selectively correct uncertain predictions and provide human-readable explanations. Experiments on five medical datasets reveal statistically significant performance gains in accuracy and F1 score. This study underscores the potential of combining symbolic reasoning with conventional ML to achieve high interpretability without sacrificing accuracy.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19573",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LAECIPS: Large Vision Model Assisted Adaptive Edge-Cloud Collaboration for IoT-based Embodied Intelligence System",
    "description": "arXiv:2404.10498v2 Announce Type: replace Abstract: Embodied intelligence (EI) enables manufacturing systems to flexibly perceive, reason, adapt, and operate within dynamic shop floor environments. In smart manufacturing, a representative EI scenario is robotic visual inspection, where industrial robots must accurately inspect components on rapidly changing, heterogeneous production lines. This task requires both high inference accuracy especially for uncommon defects and low latency to match production speeds, despite evolving lighting, part geometries, and surface conditions. To meet these needs, we propose LAECIPS, a large vision model-assisted adaptive edge-cloud collaboration framework for IoT-based embodied intelligence systems. LAECIPS decouples large vision models in the cloud from lightweight models on the edge, enabling plug-and-play model adaptation and continual learning. Through a hard input mining-based inference strategy, LAECIPS routes complex and uncertain inspection cases to the cloud while handling routine tasks at the edge, achieving both high accuracy and low latency. Experiments conducted on a real-world robotic semantic segmentation system for visual inspection demonstrate significant improvements in accuracy, processing latency, and communication overhead compared to state-of-the-art methods. LAECIPS provides a practical and scalable foundation for embodied intelligence in smart manufacturing, especially in adaptive robotic inspection and quality control scenarios.",
    "summary": "arXiv:2404.10498v2 Announce Type: replace Abstract: Embodied intelligence (EI) enables manufacturing systems to flexibly perceive, reason, adapt, and operate within dynamic shop floor environments. In smart manufacturing, a representative EI scenario is robotic visual inspection, where industrial robots must accurately inspect components on rapidly changing, heterogeneous production lines. This task requires both high inference accuracy especially for uncommon defects and low latency to match production speeds, despite evolving lighting, part geometries, and surface conditions. To meet these needs, we propose LAECIPS, a large vision model-assisted adaptive edge-cloud collaboration framework for IoT-based embodied intelligence systems. LAECIPS decouples large vision models in the cloud from lightweight models on the edge, enabling plug-and-play model adaptation and continual learning. Through a hard input mining-based inference strategy, LAECIPS routes complex and uncertain inspection cases to the cloud while handling routine tasks at the edge, achieving both high accuracy and low latency. Experiments conducted on a real-world robotic semantic segmentation system for visual inspection demonstrate significant improvements in accuracy, processing latency, and communication overhead compared to state-of-the-art methods. LAECIPS provides a practical and scalable foundation for embodied intelligence in smart manufacturing, especially in adaptive robotic inspection and quality control scenarios.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2404.10498",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Google„ÅÆAI„ÇÇ‰ø°„Åò„Çã„Äå‰∏áÂçö80Ê≠≥‰ª•‰∏äÁÑ°Êñô„Äç„ÅÆÂÅΩÊÉÖÂ†±„ÄÄË™§ÂõûÁ≠î„ÅÆÊñ∞Ê©üËÉΩ„Äå„Åï„Çâ„Å™„ÇãÊîπÂñÑ„Äç",
    "description": "Â§ßÈò™„ÉªÈñ¢Ë•ø‰∏áÂçö„ÅÆÂÖ•Â†¥Êñô„ÇíÂ∑°„Çä„ÄÅ80Ê≠≥‰ª•‰∏ä„ÅØ„ÄåÁÑ°Êñô„Äç„Å®„Åô„ÇãË™§„Å£„ÅüÊÉÖÂ†±„Åå„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà‰∏ä„Å´Â∫É„Åå„Å£„Å¶„ÅÑ„Çã„ÄÇÁ±≥ITÂ§ßÊâãGoogle„ÅÆÊ§úÁ¥¢„Çµ„Ç§„Éà„Åß„ÇÇ„Äå‰∏áÂçö„Äç„ÄåÈ´òÈΩ¢ËÄÖ„Äç„Å®Êâì„Å°Ëæº„ÇÄ„Å®„ÄÅAI„ÅÆÂõûÁ≠î„Åß80Ê≠≥‰ª•‰∏ä„ÅØÁÑ°Êñô„Å®Á§∫„Åï„Çå„ÇãÁä∂Ê≥Å„Å†„ÄÇÊó•Êú¨ÂõΩÈöõÂçöË¶ß‰ºöÂçî‰ºöÔºà‰∏áÂçöÂçî‰ºöÔºâ„ÅÆÁõ∏Ë´áÁ™ìÂè£„Å´„ÇÇ„Äå80Ê≠≥‰ª•‰∏ä„ÅØÁÑ°Êñô„Å™„ÅÆ„Åã„Äç„Å®„ÅÆÂïè„ÅÑÂêà„Çè„Åõ„ÅåË§áÊï∞„ÅÇ„Çä„ÄÅGoogle„ÅØ„Äå„Åï„Çâ„Å™„ÇãÊîπÂñÑ„ÇíÁ∂ö„Åë„Çã„Äç„Å®„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "Â§ßÈò™„ÉªÈñ¢Ë•ø‰∏áÂçö„ÅÆÂÖ•Â†¥Êñô„ÇíÂ∑°„Çä„ÄÅ80Ê≠≥‰ª•‰∏ä„ÅØ„ÄåÁÑ°Êñô„Äç„Å®„Åô„ÇãË™§„Å£„ÅüÊÉÖÂ†±„Åå„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà‰∏ä„Å´Â∫É„Åå„Å£„Å¶„ÅÑ„Çã„ÄÇÁ±≥ITÂ§ßÊâãGoogle„ÅÆÊ§úÁ¥¢„Çµ„Ç§„Éà„Åß„ÇÇ„Äå‰∏áÂçö„Äç„ÄåÈ´òÈΩ¢ËÄÖ„Äç„Å®Êâì„Å°Ëæº„ÇÄ„Å®„ÄÅAI„ÅÆÂõûÁ≠î„Åß80Ê≠≥‰ª•‰∏ä„ÅØÁÑ°Êñô„Å®Á§∫„Åï„Çå„ÇãÁä∂Ê≥Å„Å†„ÄÇÊó•Êú¨ÂõΩÈöõÂçöË¶ß‰ºöÂçî‰ºöÔºà‰∏áÂçöÂçî‰ºöÔºâ„ÅÆÁõ∏Ë´áÁ™ìÂè£„Å´„ÇÇ„Äå80Ê≠≥‰ª•‰∏ä„ÅØÁÑ°Êñô„Å™„ÅÆ„Åã„Äç„Å®„ÅÆÂïè„ÅÑÂêà„Çè„Åõ„ÅåË§áÊï∞„ÅÇ„Çä„ÄÅGoogle„ÅØ„Äå„Åï„Çâ„Å™„ÇãÊîπÂñÑ„ÇíÁ∂ö„Åë„Çã„Äç„Å®„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Tue, 24 Jun 2025 13:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/24/news082.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/24/cover_news082.jpg"
  },
  {
    "title": "AI Agents Are Here. What Now?",
    "description": "",
    "summary": "AI Agents Are Here. What Now? Introduction The sudden, rapid advancement of LLM capabilities ‚Äì such ...",
    "pubDate": "Mon, 13 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-7",
    "thumbnail": "https://huggingface.co/blog/assets/190_ethics-soc-7/thumbnail.png"
  },
  {
    "title": "General Methods Make Great Domain-specific Foundation Models: A Case-study on Fetal Ultrasound",
    "description": "arXiv:2506.19552v1 Announce Type: cross Abstract: With access to large-scale, unlabeled medical datasets, researchers are confronted with two questions: Should they attempt to pretrain a custom foundation model on this medical data, or use transfer-learning from an existing generalist model? And, if a custom model is pretrained, are novel methods required? In this paper we explore these questions by conducting a case-study, in which we train a foundation model on a large regional fetal ultrasound dataset of 2M images. By selecting the well-established DINOv2 method for pretraining, we achieve state-of-the-art results on three fetal ultrasound datasets, covering data from different countries, classification, segmentation, and few-shot tasks. We compare against a series of models pretrained on natural images, ultrasound images, and supervised baselines. Our results demonstrate two key insights: (i) Pretraining on custom data is worth it, even if smaller models are trained on less data, as scaling in natural image pretraining does not translate to ultrasound performance. (ii) Well-tuned methods from computer vision are making it feasible to train custom foundation models for a given medical domain, requiring no hyperparameter tuning and little methodological adaptation. Given these findings, we argue that a bias towards methodological innovation should be avoided when developing domain specific foundation models under common computational resource constraints.",
    "summary": "arXiv:2506.19552v1 Announce Type: cross Abstract: With access to large-scale, unlabeled medical datasets, researchers are confronted with two questions: Should they attempt to pretrain a custom foundation model on this medical data, or use transfer-learning from an existing generalist model? And, if a custom model is pretrained, are novel methods required? In this paper we explore these questions by conducting a case-study, in which we train a foundation model on a large regional fetal ultrasound dataset of 2M images. By selecting the well-established DINOv2 method for pretraining, we achieve state-of-the-art results on three fetal ultrasound datasets, covering data from different countries, classification, segmentation, and few-shot tasks. We compare against a series of models pretrained on natural images, ultrasound images, and supervised baselines. Our results demonstrate two key insights: (i) Pretraining on custom data is worth it, even if smaller models are trained on less data, as scaling in natural image pretraining does not translate to ultrasound performance. (ii) Well-tuned methods from computer vision are making it feasible to train custom foundation models for a given medical domain, requiring no hyperparameter tuning and little methodological adaptation. Given these findings, we argue that a bias towards methodological innovation should be avoided when developing domain specific foundation models under common computational resource constraints.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19552",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SSPS: Self-Supervised Positive Sampling for Robust Self-Supervised Speaker Verification",
    "description": "arXiv:2505.14561v2 Announce Type: replace-cross Abstract: Self-Supervised Learning (SSL) has led to considerable progress in Speaker Verification (SV). The standard framework uses same-utterance positive sampling and data-augmentation to generate anchor-positive pairs of the same speaker. This is a major limitation, as this strategy primarily encodes channel information from the recording condition, shared by the anchor and positive. We propose a new positive sampling technique to address this bottleneck: Self-Supervised Positive Sampling (SSPS). For a given anchor, SSPS aims to find an appropriate positive, i.e., of the same speaker identity but a different recording condition, in the latent space using clustering assignments and a memory queue of positive embeddings. SSPS improves SV performance for both SimCLR and DINO, reaching 2.57% and 2.53% EER, outperforming SOTA SSL methods on VoxCeleb1-O. In particular, SimCLR-SSPS achieves a 58% EER reduction by lowering intra-speaker variance, providing comparable performance to DINO-SSPS.",
    "summary": "arXiv:2505.14561v2 Announce Type: replace-cross Abstract: Self-Supervised Learning (SSL) has led to considerable progress in Speaker Verification (SV). The standard framework uses same-utterance positive sampling and data-augmentation to generate anchor-positive pairs of the same speaker. This is a major limitation, as this strategy primarily encodes channel information from the recording condition, shared by the anchor and positive. We propose a new positive sampling technique to address this bottleneck: Self-Supervised Positive Sampling (SSPS). For a given anchor, SSPS aims to find an appropriate positive, i.e., of the same speaker identity but a different recording condition, in the latent space using clustering assignments and a memory queue of positive embeddings. SSPS improves SV performance for both SimCLR and DINO, reaching 2.57% and 2.53% EER, outperforming SOTA SSL methods on VoxCeleb1-O. In particular, SimCLR-SSPS achieves a 58% EER reduction by lowering intra-speaker variance, providing comparable performance to DINO-SSPS.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.14561",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "RareSpot: Spotting Small and Rare Wildlife in Aerial Imagery with Multi-Scale Consistency and Context-Aware Augmentation",
    "description": "arXiv:2506.19087v1 Announce Type: cross Abstract: Automated detection of small and rare wildlife in aerial imagery is crucial for effective conservation, yet remains a significant technical challenge. Prairie dogs exemplify this issue: their ecological importance as keystone species contrasts sharply with their elusive presence--marked by small size, sparse distribution, and subtle visual features--which undermines existing detection approaches. To address these challenges, we propose RareSpot, a robust detection framework integrating multi-scale consistency learning and context-aware augmentation. Our multi-scale consistency approach leverages structured alignment across feature pyramids, enhancing fine-grained object representation and mitigating scale-related feature loss. Complementarily, context-aware augmentation strategically synthesizes challenging training instances by embedding difficult-to-detect samples into realistic environmental contexts, significantly boosting model precision and recall. Evaluated on an expert-annotated prairie dog drone imagery benchmark, our method achieves state-of-the-art performance, improving detection accuracy by over 35% compared to baseline methods. Importantly, it generalizes effectively across additional wildlife datasets, demonstrating broad applicability. The RareSpot benchmark and approach not only support critical ecological monitoring but also establish a new foundation for detecting small, rare species in complex aerial scenes.",
    "summary": "arXiv:2506.19087v1 Announce Type: cross Abstract: Automated detection of small and rare wildlife in aerial imagery is crucial for effective conservation, yet remains a significant technical challenge. Prairie dogs exemplify this issue: their ecological importance as keystone species contrasts sharply with their elusive presence--marked by small size, sparse distribution, and subtle visual features--which undermines existing detection approaches. To address these challenges, we propose RareSpot, a robust detection framework integrating multi-scale consistency learning and context-aware augmentation. Our multi-scale consistency approach leverages structured alignment across feature pyramids, enhancing fine-grained object representation and mitigating scale-related feature loss. Complementarily, context-aware augmentation strategically synthesizes challenging training instances by embedding difficult-to-detect samples into realistic environmental contexts, significantly boosting model precision and recall. Evaluated on an expert-annotated prairie dog drone imagery benchmark, our method achieves state-of-the-art performance, improving detection accuracy by over 35% compared to baseline methods. Importantly, it generalizes effectively across additional wildlife datasets, demonstrating broad applicability. The RareSpot benchmark and approach not only support critical ecological monitoring but also establish a new foundation for detecting small, rare species in complex aerial scenes.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19087",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BrowseComp: a benchmark for browsing agents",
    "description": "BrowseComp: a benchmark for browsing agents.",
    "summary": "BrowseComp: a benchmark for browsing agents.",
    "pubDate": "Thu, 10 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/browsecomp",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "RCStat: A Statistical Framework for using Relative Contextualization in Transformers",
    "description": "arXiv:2506.19549v1 Announce Type: cross Abstract: Prior work on input-token importance in auto-regressive transformers has relied on Softmax-normalized attention weights, which obscure the richer structure of pre-Softmax query-key logits. We introduce RCStat, a statistical framework that harnesses raw attention logits via Relative Contextualization (RC), a random variable measuring contextual alignment between token segments, and derive an efficient upper bound for RC. We demonstrate two applications: (i) Key-Value compression, where RC-based thresholds drive adaptive key-value eviction for substantial cache reduction with minimal quality loss; and (ii) Attribution, where RC yields higher-fidelity token-, sentence-, and chunk-level explanations than post-Softmax methods. Across question answering, summarization, and attribution benchmarks, RCStat achieves significant empirical gains, delivering state-of-the-art compression and attribution performance without any model retraining.",
    "summary": "arXiv:2506.19549v1 Announce Type: cross Abstract: Prior work on input-token importance in auto-regressive transformers has relied on Softmax-normalized attention weights, which obscure the richer structure of pre-Softmax query-key logits. We introduce RCStat, a statistical framework that harnesses raw attention logits via Relative Contextualization (RC), a random variable measuring contextual alignment between token segments, and derive an efficient upper bound for RC. We demonstrate two applications: (i) Key-Value compression, where RC-based thresholds drive adaptive key-value eviction for substantial cache reduction with minimal quality loss; and (ii) Attribution, where RC yields higher-fidelity token-, sentence-, and chunk-level explanations than post-Softmax methods. Across question answering, summarization, and attribution benchmarks, RCStat achieves significant empirical gains, delivering state-of-the-art compression and attribution performance without any model retraining.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19549",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robust Dynamic Material Handling via Adaptive Constrained Evolutionary Reinforcement Learning",
    "description": "arXiv:2506.16795v1 Announce Type: cross Abstract: Dynamic material handling (DMH) involves the assignment of dynamically arriving material transporting tasks to suitable vehicles in real time for minimising makespan and tardiness. In real-world scenarios, historical task records are usually available, which enables the training of a decision policy on multiple instances consisting of historical records. Recently, reinforcement learning has been applied to solve DMH. Due to the occurrence of dynamic events such as new tasks, adaptability is highly required. Solving DMH is challenging since constraints including task delay should be satisfied. A feedback is received only when all tasks are served, which leads to sparse reward. Besides, making the best use of limited computational resources and historical records for training a robust policy is crucial. The time allocated to different problem instances would highly impact the learning process. To tackle those challenges, this paper proposes a novel adaptive constrained evolutionary reinforcement learning (ACERL) approach, which maintains a population of actors for diverse exploration. ACERL accesses each actor for tackling sparse rewards and constraint violation to restrict the behaviour of the policy. Moreover, ACERL adaptively selects the most beneficial training instances for improving the policy. Extensive experiments on eight training and eight unseen test instances demonstrate the outstanding performance of ACERL compared with several state-of-the-art algorithms. Policies trained by ACERL can schedule the vehicles while fully satisfying the constraints. Additional experiments on 40 unseen noised instances show the robust performance of ACERL. Cross-validation further presents the overall effectiveness of ACREL. Besides, a rigorous ablation study highlights the coordination and benefits of each ingredient of ACERL.",
    "summary": "arXiv:2506.16795v1 Announce Type: cross Abstract: Dynamic material handling (DMH) involves the assignment of dynamically arriving material transporting tasks to suitable vehicles in real time for minimising makespan and tardiness. In real-world scenarios, historical task records are usually available, which enables the training of a decision policy on multiple instances consisting of historical records. Recently, reinforcement learning has been applied to solve DMH. Due to the occurrence of dynamic events such as new tasks, adaptability is highly required. Solving DMH is challenging since constraints including task delay should be satisfied. A feedback is received only when all tasks are served, which leads to sparse reward. Besides, making the best use of limited computational resources and historical records for training a robust policy is crucial. The time allocated to different problem instances would highly impact the learning process. To tackle those challenges, this paper proposes a novel adaptive constrained evolutionary reinforcement learning (ACERL) approach, which maintains a population of actors for diverse exploration. ACERL accesses each actor for tackling sparse rewards and constraint violation to restrict the behaviour of the policy. Moreover, ACERL adaptively selects the most beneficial training instances for improving the policy. Extensive experiments on eight training and eight unseen test instances demonstrate the outstanding performance of ACERL compared with several state-of-the-art algorithms. Policies trained by ACERL can schedule the vehicles while fully satisfying the constraints. Additional experiments on 40 unseen noised instances show the robust performance of ACERL. Cross-validation further presents the overall effectiveness of ACREL. Besides, a rigorous ablation study highlights the coordination and benefits of each ingredient of ACERL.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16795",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI‰ΩúÊàê„ÅÆÂÅΩ„Çµ„Ç§„Éà„ÇíAIÁî®„ÅÑ„Å¶ÊçúÊüª„ÄÅ„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Çµ„Ç§„Éà‰ΩúÊàê„ÅÆÁî∑2‰∫∫„ÇíÈÄÆÊçï„ÄÄÂ§ßÈò™Â∫úË≠¶",
    "description": "EC„Çµ„Ç§„Éà„Å´„Å™„Çä„Åô„Åæ„Åó„Åü„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Çµ„Ç§„Éà„Çí‰ΩúÊàê„Åó„ÄÅ„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà„Å´ÂÖ¨Èñã„Åó„Åü„Å™„Å©„Å®„Åó„Å¶„ÄÅÂ§ßÈò™Â∫úË≠¶„Çµ„Ç§„Éê„ÉºÁäØÁΩ™ÊçúÊüªË™≤„ÅØ‰∏çÊ≠£„Ç¢„ÇØ„Çª„ÇπÁ¶ÅÊ≠¢Ê≥ïÈÅïÂèç„ÅÆÁñë„ÅÑ„Åß2‰∫∫„ÇíÈÄÆÊçï„Åó„Åü„Å®Áô∫Ë°®„Åó„Åü„ÄÇ",
    "summary": "EC„Çµ„Ç§„Éà„Å´„Å™„Çä„Åô„Åæ„Åó„Åü„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Çµ„Ç§„Éà„Çí‰ΩúÊàê„Åó„ÄÅ„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà„Å´ÂÖ¨Èñã„Åó„Åü„Å™„Å©„Å®„Åó„Å¶„ÄÅÂ§ßÈò™Â∫úË≠¶„Çµ„Ç§„Éê„ÉºÁäØÁΩ™ÊçúÊüªË™≤„ÅØ‰∏çÊ≠£„Ç¢„ÇØ„Çª„ÇπÁ¶ÅÊ≠¢Ê≥ïÈÅïÂèç„ÅÆÁñë„ÅÑ„Åß2‰∫∫„ÇíÈÄÆÊçï„Åó„Åü„Å®Áô∫Ë°®„Åó„Åü„ÄÇ",
    "pubDate": "Mon, 23 Jun 2025 17:27:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/23/news093.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/23/cover_news093.jpg"
  },
  {
    "title": "Getting Started With Embeddings",
    "description": "",
    "summary": "Getting Started With Embeddings Check out this tutorial with the Notebook Companion: Understanding e...",
    "pubDate": "Thu, 23 Jun 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/getting-started-with-embeddings",
    "thumbnail": "https://huggingface.co/blog/assets/80_getting_started_with_embeddings/thumbnail.png"
  },
  {
    "title": "Exploring institutions for global AI governance",
    "description": "New white paper investigates models and functions of international institutions that could help manage opportunities and mitigate risks of advanced AI.",
    "summary": "New white paper investigates models and functions of international institutions that could help manage opportunities and mitigate risks of advanced AI.",
    "pubDate": "Tue, 11 Jul 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/exploring-institutions-for-global-ai-governance/",
    "thumbnail": "https://lh3.googleusercontent.com/Y9dCJWt3ky1gjizSCHb17S3iHZ_Q2v6hoC8SaBgq9f7e5yW15pzg7BGNoCIaklP6f34uioxwHY0gbzehAMe5HhXBvBBKBKNIcOo7ugjFeLENTWMqNQ=w1200-h630-n-nu"
  },
  {
    "title": "AI breakthroughs are bringing hope to cancer research and treatment",
    "description": "A presentation slide displays 'Why not?' in multiple languages, representing global communication. Smaller images show Ruth Porat on stage, medical professionals, and 3D virus models, connecting technology with healthcare.",
    "summary": "A presentation slide displays 'Why not?' in multiple languages, representing global communication. Smaller images show Ruth Porat on stage, medical professionals, and 3D virus models, connecting technology with healthcare.",
    "pubDate": "Wed, 04 Jun 2025 18:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/health/ruth-porat-remarks-asco/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/RuthAsco_Hero_2097x1182.width-1300.png"
  },
  {
    "title": "Reading Smiles: Proxy Bias in Foundation Models for Facial Emotion Recognition",
    "description": "arXiv:2506.19079v1 Announce Type: cross Abstract: Foundation Models (FMs) are rapidly transforming Affective Computing (AC), with Vision Language Models (VLMs) now capable of recognising emotions in zero shot settings. This paper probes a critical but underexplored question: what visual cues do these models rely on to infer affect, and are these cues psychologically grounded or superficially learnt? We benchmark varying scale VLMs on a teeth annotated subset of AffectNet dataset and find consistent performance shifts depending on the presence of visible teeth. Through structured introspection of, the best-performing model, i.e., GPT-4o, we show that facial attributes like eyebrow position drive much of its affective reasoning, revealing a high degree of internal consistency in its valence-arousal predictions. These patterns highlight the emergent nature of FMs behaviour, but also reveal risks: shortcut learning, bias, and fairness issues especially in sensitive domains like mental health and education.",
    "summary": "arXiv:2506.19079v1 Announce Type: cross Abstract: Foundation Models (FMs) are rapidly transforming Affective Computing (AC), with Vision Language Models (VLMs) now capable of recognising emotions in zero shot settings. This paper probes a critical but underexplored question: what visual cues do these models rely on to infer affect, and are these cues psychologically grounded or superficially learnt? We benchmark varying scale VLMs on a teeth annotated subset of AffectNet dataset and find consistent performance shifts depending on the presence of visible teeth. Through structured introspection of, the best-performing model, i.e., GPT-4o, we show that facial attributes like eyebrow position drive much of its affective reasoning, revealing a high degree of internal consistency in its valence-arousal predictions. These patterns highlight the emergent nature of FMs behaviour, but also reveal risks: shortcut learning, bias, and fairness issues especially in sensitive domains like mental health and education.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19079",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Transfer from simulation to real world through learning deep inverse dynamics model",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 11 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/transfer-from-simulation-to-real-world-through-learning-deep-inverse-dynamics-model",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CLoVE: Personalized Federated Learning through Clustering of Loss Vector Embeddings",
    "description": "arXiv:2506.22427v1 Announce Type: cross Abstract: We propose CLoVE (Clustering of Loss Vector Embeddings), a novel algorithm for Clustered Federated Learning (CFL). In CFL, clients are naturally grouped into clusters based on their data distribution. However, identifying these clusters is challenging, as client assignments are unknown. CLoVE utilizes client embeddings derived from model losses on client data, and leverages the insight that clients in the same cluster share similar loss values, while those in different clusters exhibit distinct loss patterns. Based on these embeddings, CLoVE is able to iteratively identify and separate clients from different clusters and optimize cluster-specific models through federated aggregation. Key advantages of CLoVE over existing CFL algorithms are (1) its simplicity, (2) its applicability to both supervised and unsupervised settings, and (3) the fact that it eliminates the need for near-optimal model initialization, which makes it more robust and better suited for real-world applications. We establish theoretical convergence bounds, showing that CLoVE can recover clusters accurately with high probability in a single round and converges exponentially fast to optimal models in a linear setting. Our comprehensive experiments comparing with a variety of both CFL and generic Personalized Federated Learning (PFL) algorithms on different types of datasets and an extensive array of non-IID settings demonstrate that CLoVE achieves highly accurate cluster recovery in just a few rounds of training, along with state-of-the-art model accuracy, across a variety of both supervised and unsupervised PFL tasks.",
    "summary": "arXiv:2506.22427v1 Announce Type: cross Abstract: We propose CLoVE (Clustering of Loss Vector Embeddings), a novel algorithm for Clustered Federated Learning (CFL). In CFL, clients are naturally grouped into clusters based on their data distribution. However, identifying these clusters is challenging, as client assignments are unknown. CLoVE utilizes client embeddings derived from model losses on client data, and leverages the insight that clients in the same cluster share similar loss values, while those in different clusters exhibit distinct loss patterns. Based on these embeddings, CLoVE is able to iteratively identify and separate clients from different clusters and optimize cluster-specific models through federated aggregation. Key advantages of CLoVE over existing CFL algorithms are (1) its simplicity, (2) its applicability to both supervised and unsupervised settings, and (3) the fact that it eliminates the need for near-optimal model initialization, which makes it more robust and better suited for real-world applications. We establish theoretical convergence bounds, showing that CLoVE can recover clusters accurately with high probability in a single round and converges exponentially fast to optimal models in a linear setting. Our comprehensive experiments comparing with a variety of both CFL and generic Personalized Federated Learning (PFL) algorithms on different types of datasets and an extensive array of non-IID settings demonstrate that CLoVE achieves highly accurate cluster recovery in just a few rounds of training, along with state-of-the-art model accuracy, across a variety of both supervised and unsupervised PFL tasks.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22427",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Empowering a global org with ChatGPT",
    "description": "Empowering a global org with ChatGPT",
    "summary": "Empowering a global org with ChatGPT",
    "pubDate": "Thu, 21 Nov 2024 05:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/bbva",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Ilya Sutskever to leave OpenAI, Jakub Pachocki announced as Chief Scientist",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 14 May 2024 18:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jakub-pachocki-announced-as-chief-scientist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Breaking Rank Bottlenecks in Knowledge Graph Completion",
    "description": "arXiv:2506.22271v1 Announce Type: new Abstract: Many Knowledge Graph Completion (KGC) models, despite using powerful encoders, rely on a simple vector-matrix multiplication to score queries against candidate object entities. When the number of entities is larger than the model's embedding dimension, which in practical scenarios is often by several orders of magnitude, we have a linear output layer with a rank bottleneck. Such bottlenecked layers limit model expressivity. We investigate both theoretically and empirically how rank bottlenecks affect KGC models. We find that, by limiting the set of feasible predictions, rank bottlenecks hurt ranking accuracy and the distribution fidelity of scores. Inspired by the language modelling literature, we propose KGE-MoS, a mixture-based output layer to break rank bottlenecks in many KGC models. Our experiments on four datasets show that KGE-MoS improves performance and probabilistic fit of KGC models for a low parameter cost.",
    "summary": "arXiv:2506.22271v1 Announce Type: new Abstract: Many Knowledge Graph Completion (KGC) models, despite using powerful encoders, rely on a simple vector-matrix multiplication to score queries against candidate object entities. When the number of entities is larger than the model's embedding dimension, which in practical scenarios is often by several orders of magnitude, we have a linear output layer with a rank bottleneck. Such bottlenecked layers limit model expressivity. We investigate both theoretically and empirically how rank bottlenecks affect KGC models. We find that, by limiting the set of feasible predictions, rank bottlenecks hurt ranking accuracy and the distribution fidelity of scores. Inspired by the language modelling literature, we propose KGE-MoS, a mixture-based output layer to break rank bottlenecks in many KGC models. Our experiments on four datasets show that KGE-MoS improves performance and probabilistic fit of KGC models for a low parameter cost.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22271",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Generalizable Agent Modeling for Agent Collaboration-Competition Adaptation with Multi-Retrieval and Dynamic Generation",
    "description": "arXiv:2506.16718v1 Announce Type: cross Abstract: Adapting a single agent to a new multi-agent system brings challenges, necessitating adjustments across various tasks, environments, and interactions with unknown teammates and opponents. Addressing this challenge is highly complex, and researchers have proposed two simplified scenarios, Multi-agent reinforcement learning for zero-shot learning and Ad-Hoc Teamwork. Building on these foundations, we propose a more comprehensive setting, Agent Collaborative-Competitive Adaptation (ACCA), which evaluates an agent to generalize across diverse scenarios, tasks, and interactions with both unfamiliar opponents and teammates. In ACCA, agents adjust to task and environmental changes, collaborate with unseen teammates, and compete against unknown opponents. We introduce a new modeling approach, Multi-Retrieval and Dynamic Generation (MRDG), that effectively models both teammates and opponents using their behavioral trajectories. This method incorporates a positional encoder for varying team sizes and a hypernetwork module to boost agents' learning and adaptive capabilities. Additionally, a viewpoint alignment module harmonizes the observational perspectives of retrieved teammates and opponents with the learning agent. Extensive tests in benchmark scenarios like SMAC, Overcooked-AI, and Melting Pot show that MRDG significantly improves robust collaboration and competition with unseen teammates and opponents, surpassing established baselines. Our code is available at: https://github.com/vcis-wangchenxu/MRDG.git",
    "summary": "arXiv:2506.16718v1 Announce Type: cross Abstract: Adapting a single agent to a new multi-agent system brings challenges, necessitating adjustments across various tasks, environments, and interactions with unknown teammates and opponents. Addressing this challenge is highly complex, and researchers have proposed two simplified scenarios, Multi-agent reinforcement learning for zero-shot learning and Ad-Hoc Teamwork. Building on these foundations, we propose a more comprehensive setting, Agent Collaborative-Competitive Adaptation (ACCA), which evaluates an agent to generalize across diverse scenarios, tasks, and interactions with both unfamiliar opponents and teammates. In ACCA, agents adjust to task and environmental changes, collaborate with unseen teammates, and compete against unknown opponents. We introduce a new modeling approach, Multi-Retrieval and Dynamic Generation (MRDG), that effectively models both teammates and opponents using their behavioral trajectories. This method incorporates a positional encoder for varying team sizes and a hypernetwork module to boost agents' learning and adaptive capabilities. Additionally, a viewpoint alignment module harmonizes the observational perspectives of retrieved teammates and opponents with the learning agent. Extensive tests in benchmark scenarios like SMAC, Overcooked-AI, and Melting Pot show that MRDG significantly improves robust collaboration and competition with unseen teammates and opponents, surpassing established baselines. Our code is available at: https://github.com/vcis-wangchenxu/MRDG.git",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16718",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Spread Your Wings: Falcon 180B is here",
    "description": "",
    "summary": "Spread Your Wings: Falcon 180B is here Introduction Today, we're excited to welcome TII's Falcon 180...",
    "pubDate": "Wed, 06 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon-180b",
    "thumbnail": "https://huggingface.co/blog/assets/162_falcon_180b/thumbnail.jpg"
  },
  {
    "title": "Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC",
    "description": "",
    "summary": "Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC We're e...",
    "pubDate": "Wed, 09 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastrtc-cloudflare",
    "thumbnail": "https://huggingface.co/blog/assets/fastrtc-cloudflare/fastrtc_cloudflare.png"
  },
  {
    "title": "Vall√©e Duhamel & Sora",
    "description": "Filmmaking duo Vall√©e Duhamel explains how Sora helps build new worlds.",
    "summary": "Filmmaking duo Vall√©e Duhamel explains how Sora helps build new worlds.",
    "pubDate": "Mon, 09 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sora-vallee-duhamel",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Personal Copilot: Train Your Own Coding Assistant",
    "description": "",
    "summary": "Personal Copilot: Train Your Own Coding Assistant In the ever-evolving landscape of programming and ...",
    "pubDate": "Fri, 27 Oct 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/personal-copilot",
    "thumbnail": "https://huggingface.co/blog/assets/170_personal_copilot/thumbnail.png"
  },
  {
    "title": "Hugging Face and Graphcore partner for IPU-optimized Transformers",
    "description": "",
    "summary": "Hugging Face and Graphcore partner for IPU-optimized Transformers Speaking at the 2021 AI Hardware S...",
    "pubDate": "Tue, 14 Sep 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/graphcore",
    "thumbnail": "https://huggingface.co/blog/assets/26_graphcore-ipu/thumbnail.png"
  },
  {
    "title": "Letting Large Models Debate: The First Multilingual LLM Debate Competition",
    "description": "",
    "summary": "Letting Large Models Debate: The First Multilingual LLM Debate Competition Current static evaluation...",
    "pubDate": "Wed, 20 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/debate",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "From RAG to Memory: Non-Parametric Continual Learning for Large Language Models",
    "description": "arXiv:2502.14802v2 Announce Type: replace-cross Abstract: Our ability to continuously acquire, organize, and leverage knowledge is a key feature of human intelligence that AI systems must approximate to unlock their full potential. Given the challenges in continual learning with large language models (LLMs), retrieval-augmented generation (RAG) has become the dominant way to introduce new information. However, its reliance on vector retrieval hinders its ability to mimic the dynamic and interconnected nature of human long-term memory. Recent RAG approaches augment vector embeddings with various structures like knowledge graphs to address some of these gaps, namely sense-making and associativity. However, their performance on more basic factual memory tasks drops considerably below standard RAG. We address this unintended deterioration and propose HippoRAG 2, a framework that outperforms standard RAG comprehensively on factual, sense-making, and associative memory tasks. HippoRAG 2 builds upon the Personalized PageRank algorithm used in HippoRAG and enhances it with deeper passage integration and more effective online use of an LLM. This combination pushes this RAG system closer to the effectiveness of human long-term memory, achieving a 7% improvement in associative memory tasks over the state-of-the-art embedding model while also exhibiting superior factual knowledge and sense-making memory capabilities. This work paves the way for non-parametric continual learning for LLMs. Code and data are available at https://github.com/OSU-NLP-Group/HippoRAG.",
    "summary": "arXiv:2502.14802v2 Announce Type: replace-cross Abstract: Our ability to continuously acquire, organize, and leverage knowledge is a key feature of human intelligence that AI systems must approximate to unlock their full potential. Given the challenges in continual learning with large language models (LLMs), retrieval-augmented generation (RAG) has become the dominant way to introduce new information. However, its reliance on vector retrieval hinders its ability to mimic the dynamic and interconnected nature of human long-term memory. Recent RAG approaches augment vector embeddings with various structures like knowledge graphs to address some of these gaps, namely sense-making and associativity. However, their performance on more basic factual memory tasks drops considerably below standard RAG. We address this unintended deterioration and propose HippoRAG 2, a framework that outperforms standard RAG comprehensively on factual, sense-making, and associative memory tasks. HippoRAG 2 builds upon the Personalized PageRank algorithm used in HippoRAG and enhances it with deeper passage integration and more effective online use of an LLM. This combination pushes this RAG system closer to the effectiveness of human long-term memory, achieving a 7% improvement in associative memory tasks over the state-of-the-art embedding model while also exhibiting superior factual knowledge and sense-making memory capabilities. This work paves the way for non-parametric continual learning for LLMs. Code and data are available at https://github.com/OSU-NLP-Group/HippoRAG.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.14802",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "When Can Model-Free Reinforcement Learning be Enough for Thinking?",
    "description": "arXiv:2506.17124v1 Announce Type: new Abstract: Recent work on large language models has demonstrated the use of model-free reinforcement learning (RL) to train reasoning-like capabilities. The emergence of 'thinking' through model-free RL is interesting as thinking actions neither produce reward nor change the external world state to one where the agent is more likely to get reward. This paper seeks to build a domain-independent understanding of when model-free RL will lead to 'thinking' as a strategy for reward maximization. To build this understanding, we first introduce a theoretical model which we call a textit{thought Markov decision process} (MDP). Thought MDPs minimally extend the classical MDP model to include an abstract notion of thought state and thought action. Using the thought MDP model, we prove the importance of policy initialization in determining whether or not thinking emerges and show formally that thought actions are equivalent to the agent choosing to perform a step of policy improvement before continuing to act. We then show that open-source LLMs satisfy the conditions that our theory predicts are necessary for model-free RL to produce thinking-like behavior. Finally, we hypothesize sufficient conditions that would enable thinking to be learned outside of language generation and introduce a toy domain where a combination of multi-task pre-training and designated thought actions enable more data-efficient RL compared to non-thinking agents.",
    "summary": "arXiv:2506.17124v1 Announce Type: new Abstract: Recent work on large language models has demonstrated the use of model-free reinforcement learning (RL) to train reasoning-like capabilities. The emergence of 'thinking' through model-free RL is interesting as thinking actions neither produce reward nor change the external world state to one where the agent is more likely to get reward. This paper seeks to build a domain-independent understanding of when model-free RL will lead to 'thinking' as a strategy for reward maximization. To build this understanding, we first introduce a theoretical model which we call a textit{thought Markov decision process} (MDP). Thought MDPs minimally extend the classical MDP model to include an abstract notion of thought state and thought action. Using the thought MDP model, we prove the importance of policy initialization in determining whether or not thinking emerges and show formally that thought actions are equivalent to the agent choosing to perform a step of policy improvement before continuing to act. We then show that open-source LLMs satisfy the conditions that our theory predicts are necessary for model-free RL to produce thinking-like behavior. Finally, we hypothesize sufficient conditions that would enable thinking to be learned outside of language generation and introduce a toy domain where a combination of multi-task pre-training and designated thought actions enable more data-efficient RL compared to non-thinking agents.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17124",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Anthropic„ÄÅAI„ÅÆ„ÄåÊÑüÊÉÖÁöÑÂà©Áî®„ÄçË™øÊüªÁµêÊûú„ÇíÂÖ¨Èñã„ÄÄÂØæÁ≠ñ„ÇÇÊèêÁ§∫",
    "description": "Anthropic„ÅØ„ÄÅAI„ÄåClaude„Äç„ÅÆÊÑüÊÉÖÁöÑ„Å™Âà©Áî®„Å´Èñ¢„Åô„ÇãË™øÊüªÁµêÊûú„ÇíÂÖ¨Èñã„Åó„Åü„ÄÇÊÑüÊÉÖÁöÑ„Å™‰ºöË©±„ÅØÂÖ®‰Ωì„ÅÆÁ¥Ñ3ÔºÖ„Å®Á®Ä„Å†„Åå„ÄÅÂÜÖÂÆπ„ÅØÂ§öÂ≤ê„Å´„Çè„Åü„Çã„ÄÇ‰ºöË©±„ÇíÈÄö„Åò„Å¶„É¶„Éº„Ç∂„Éº„ÅÆÊÑüÊÉÖ„ÅåËÇØÂÆöÁöÑ„Å´„Å™„ÇãÂÇæÂêë„ÅåË¶ã„Çâ„Çå„Çã„Åå„ÄÅAI„ÇíÂ∞ÇÈñÄÂÆ∂„ÅÆ‰ª£Êõø„Å®„ÅØ„Åõ„Åö„ÄÅÂÆâÂÖ®ÂØæÁ≠ñ„ÇíÈÄ≤„ÇÅ„Çã„ÄÇ",
    "summary": "Anthropic„ÅØ„ÄÅAI„ÄåClaude„Äç„ÅÆÊÑüÊÉÖÁöÑ„Å™Âà©Áî®„Å´Èñ¢„Åô„ÇãË™øÊüªÁµêÊûú„ÇíÂÖ¨Èñã„Åó„Åü„ÄÇÊÑüÊÉÖÁöÑ„Å™‰ºöË©±„ÅØÂÖ®‰Ωì„ÅÆÁ¥Ñ3ÔºÖ„Å®Á®Ä„Å†„Åå„ÄÅÂÜÖÂÆπ„ÅØÂ§öÂ≤ê„Å´„Çè„Åü„Çã„ÄÇ‰ºöË©±„ÇíÈÄö„Åò„Å¶„É¶„Éº„Ç∂„Éº„ÅÆÊÑüÊÉÖ„ÅåËÇØÂÆöÁöÑ„Å´„Å™„ÇãÂÇæÂêë„ÅåË¶ã„Çâ„Çå„Çã„Åå„ÄÅAI„ÇíÂ∞ÇÈñÄÂÆ∂„ÅÆ‰ª£Êõø„Å®„ÅØ„Åõ„Åö„ÄÅÂÆâÂÖ®ÂØæÁ≠ñ„ÇíÈÄ≤„ÇÅ„Çã„ÄÇ",
    "pubDate": "Fri, 27 Jun 2025 08:49:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/27/news057.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/27/cover_news057.jpg"
  },
  {
    "title": "Judge Arena: Benchmarking LLMs as Evaluators",
    "description": "",
    "summary": "Judge Arena: Benchmarking LLMs as Evaluators LLM-as-a-Judge has emerged as a popular way to grade na...",
    "pubDate": "Tue, 19 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-atla",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail_atla.png"
  },
  {
    "title": "MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot",
    "description": "arXiv:2502.04413v2 Announce Type: replace-cross Abstract: Retrieval-augmented generation (RAG) is a well-suited technique for retrieving privacy-sensitive Electronic Health Records (EHR). It can serve as a key module of the healthcare copilot, helping reduce misdiagnosis for healthcare practitioners and patients. However, the diagnostic accuracy and specificity of existing heuristic-based RAG models used in the medical domain are inadequate, particularly for diseases with similar manifestations. This paper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicited reasoning for the medical domain that retrieves diagnosis and treatment recommendations based on manifestations. MedRAG systematically constructs a comprehensive four-tier hierarchical diagnostic KG encompassing critical diagnostic differences of various diseases. These differences are dynamically integrated with similar EHRs retrieved from an EHR database, and reasoned within a large language model. This process enables more accurate and specific decision support, while also proactively providing follow-up questions to enhance personalized medical decision-making. MedRAG is evaluated on both a public dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD) collected from Tan Tock Seng Hospital, and its performance is compared against various existing RAG methods. Experimental results show that, leveraging the information integration and relational abilities of the KG, our MedRAG provides more specific diagnostic insights and outperforms state-of-the-art models in reducing misdiagnosis rates. Our code will be available at https://github.com/SNOWTEAM2023/MedRAG",
    "summary": "arXiv:2502.04413v2 Announce Type: replace-cross Abstract: Retrieval-augmented generation (RAG) is a well-suited technique for retrieving privacy-sensitive Electronic Health Records (EHR). It can serve as a key module of the healthcare copilot, helping reduce misdiagnosis for healthcare practitioners and patients. However, the diagnostic accuracy and specificity of existing heuristic-based RAG models used in the medical domain are inadequate, particularly for diseases with similar manifestations. This paper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicited reasoning for the medical domain that retrieves diagnosis and treatment recommendations based on manifestations. MedRAG systematically constructs a comprehensive four-tier hierarchical diagnostic KG encompassing critical diagnostic differences of various diseases. These differences are dynamically integrated with similar EHRs retrieved from an EHR database, and reasoned within a large language model. This process enables more accurate and specific decision support, while also proactively providing follow-up questions to enhance personalized medical decision-making. MedRAG is evaluated on both a public dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD) collected from Tan Tock Seng Hospital, and its performance is compared against various existing RAG methods. Experimental results show that, leveraging the information integration and relational abilities of the KG, our MedRAG provides more specific diagnostic insights and outperforms state-of-the-art models in reducing misdiagnosis rates. Our code will be available at https://github.com/SNOWTEAM2023/MedRAG",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.04413",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DeepTalk: Towards Seamless and Smart Speech Interaction with Adaptive Modality-Specific MoE",
    "description": "arXiv:2506.21864v1 Announce Type: cross Abstract: Native multimodal large language models (MLLMs) restructure a single large language model (LLM) into a spoken language model (SLM) capable of both speech and text generation. Compared to modular and aligned MLLMs, native MLLMs preserve richer paralinguistic features such as emotion and prosody, and generate speech responses directly within the backbone LLM rather than using a separate speech decoder. This integration also results in lower response latency and smoother interaction. However, native MLLMs suffer from catastrophic forgetting and performance degradation because the available paired speech-text data is insufficient to support the pretraining of MLLMs compared to the vast amount of text data required to pretrain text LLMs. To address this issue, we propose DeepTalk, a framework for adaptive modality expert learning based on a Mixture of Experts (MoE) architecture. DeepTalk first adaptively distinguishes modality experts according to their modality load within the LLM. Each modality expert then undergoes specialized single-modality training, followed by joint multimodal collaborative training. As a result, DeepTalk incurs only a 5.5% performance drop compared to the original LLM, which is significantly lower than the average performance drop of over 20% typically seen in native MLLMs (such as GLM-4-Voice), and is on par with modular MLLMs. Meanwhile, the end-to-end dialogue latency remains within 0.5 seconds, ensuring a seamless and intelligent speech interaction experience. Code and models are released at https://github.com/talkking/DeepTalk.",
    "summary": "arXiv:2506.21864v1 Announce Type: cross Abstract: Native multimodal large language models (MLLMs) restructure a single large language model (LLM) into a spoken language model (SLM) capable of both speech and text generation. Compared to modular and aligned MLLMs, native MLLMs preserve richer paralinguistic features such as emotion and prosody, and generate speech responses directly within the backbone LLM rather than using a separate speech decoder. This integration also results in lower response latency and smoother interaction. However, native MLLMs suffer from catastrophic forgetting and performance degradation because the available paired speech-text data is insufficient to support the pretraining of MLLMs compared to the vast amount of text data required to pretrain text LLMs. To address this issue, we propose DeepTalk, a framework for adaptive modality expert learning based on a Mixture of Experts (MoE) architecture. DeepTalk first adaptively distinguishes modality experts according to their modality load within the LLM. Each modality expert then undergoes specialized single-modality training, followed by joint multimodal collaborative training. As a result, DeepTalk incurs only a 5.5% performance drop compared to the original LLM, which is significantly lower than the average performance drop of over 20% typically seen in native MLLMs (such as GLM-4-Voice), and is on par with modular MLLMs. Meanwhile, the end-to-end dialogue latency remains within 0.5 seconds, ensuring a seamless and intelligent speech interaction experience. Code and models are released at https://github.com/talkking/DeepTalk.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21864",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "TrainVerify: Equivalence-Based Verification for Distributed LLM Training",
    "description": "arXiv:2506.15961v1 Announce Type: cross Abstract: Training large language models (LLMs) at scale requires parallel execution across thousands of devices, incurring enormous computational costs. Yet, these costly distributed trainings are rarely verified, leaving them prone to silent errors and potentially wasting millions of GPU hours. We introduce TrainVerify, a system for verifiable distributed training of LLMs. Given a deep learning model's logical specification as the ground truth, TrainVerify formally verifies that a distributed parallel execution plan is mathematically equivalent to it. Direct verification is notoriously difficult due to the sheer scale of LLMs which often involves billions of variables and highly intricate computation graphs. Therefore, TrainVerify introduces shape-reduction techniques and a stage-wise parallel verification algorithm that significantly reduces complexity while preserving formal correctness. TrainVerify scales to frontier LLMs, including the successful verification of the Llama3 (405B) and DeepSeek-V3 (671B) training plans.",
    "summary": "arXiv:2506.15961v1 Announce Type: cross Abstract: Training large language models (LLMs) at scale requires parallel execution across thousands of devices, incurring enormous computational costs. Yet, these costly distributed trainings are rarely verified, leaving them prone to silent errors and potentially wasting millions of GPU hours. We introduce TrainVerify, a system for verifiable distributed training of LLMs. Given a deep learning model's logical specification as the ground truth, TrainVerify formally verifies that a distributed parallel execution plan is mathematically equivalent to it. Direct verification is notoriously difficult due to the sheer scale of LLMs which often involves billions of variables and highly intricate computation graphs. Therefore, TrainVerify introduces shape-reduction techniques and a stage-wise parallel verification algorithm that significantly reduces complexity while preserving formal correctness. TrainVerify scales to frontier LLMs, including the successful verification of the Llama3 (405B) and DeepSeek-V3 (671B) training plans.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15961",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Distributed Training: Train BART/T5 for Summarization using ü§ó Transformers and Amazon SageMaker",
    "description": "",
    "summary": "Distributed Training: Train BART/T5 for Summarization using ü§ó Transformers and Amazon SageMaker In c...",
    "pubDate": "Thu, 08 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sagemaker-distributed-training-seq2seq",
    "thumbnail": "https://huggingface.co/blog/assets/19_sagemaker_distributed_training_seq2seq/thumbnail.png"
  },
  {
    "title": "New GPT-3 capabilities: Edit & insert",
    "description": "We‚Äôve released new versions of GPT-3 and Codex¬†which can edit or insert content into existing text, rather than just completing existing text.",
    "summary": "We‚Äôve released new versions of GPT-3 and Codex¬†which can edit or insert content into existing text, rather than just completing existing text.",
    "pubDate": "Tue, 15 Mar 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-3-edit-insert",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Learning sparse neural networks through L‚ÇÄ regularization",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 04 Dec 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-sparse-neural-networks-through-l0-regularization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome Stable-baselines3 to the Hugging Face Hub ü§ó",
    "description": "",
    "summary": "Welcome Stable-baselines3 to the Hugging Face Hub ü§ó At Hugging Face, we are contributing to the ecos...",
    "pubDate": "Fri, 21 Jan 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sb3",
    "thumbnail": "https://huggingface.co/blog/assets/47_sb3/thumbnail.png"
  },
  {
    "title": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study",
    "description": "arXiv:2506.19794v1 Announce Type: cross Abstract: Large Language Models (LLMs) hold promise in automating data analysis tasks, yet open-source models face significant limitations in these kinds of reasoning-intensive scenarios. In this work, we investigate strategies to enhance the data analysis capabilities of open-source LLMs. By curating a seed dataset of diverse, realistic scenarios, we evaluate models across three dimensions: data understanding, code generation, and strategic planning. Our analysis reveals three key findings: (1) Strategic planning quality serves as the primary determinant of model performance; (2) Interaction design and task complexity significantly influence reasoning capabilities; (3) Data quality demonstrates a greater impact than diversity in achieving optimal performance. We leverage these insights to develop a data synthesis methodology, demonstrating significant improvements in open-source LLMs' analytical reasoning capabilities.",
    "summary": "arXiv:2506.19794v1 Announce Type: cross Abstract: Large Language Models (LLMs) hold promise in automating data analysis tasks, yet open-source models face significant limitations in these kinds of reasoning-intensive scenarios. In this work, we investigate strategies to enhance the data analysis capabilities of open-source LLMs. By curating a seed dataset of diverse, realistic scenarios, we evaluate models across three dimensions: data understanding, code generation, and strategic planning. Our analysis reveals three key findings: (1) Strategic planning quality serves as the primary determinant of model performance; (2) Interaction design and task complexity significantly influence reasoning capabilities; (3) Data quality demonstrates a greater impact than diversity in achieving optimal performance. We leverage these insights to develop a data synthesis methodology, demonstrating significant improvements in open-source LLMs' analytical reasoning capabilities.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19794",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PromptDSI: Prompt-based Rehearsal-free Instance-wise Incremental Learning for Document Retrieval",
    "description": "arXiv:2406.12593v3 Announce Type: replace-cross Abstract: Differentiable Search Index (DSI) utilizes pre-trained language models to perform indexing and document retrieval via end-to-end learning without relying on external indexes. However, DSI requires full re-training to index new documents, causing significant computational inefficiencies. Continual learning (CL) offers a solution by enabling the model to incrementally update without full re-training. Existing CL solutions in document retrieval rely on memory buffers or generative models for rehearsal, which is infeasible when accessing previous training data is restricted due to privacy concerns. To this end, we introduce PromptDSI, a prompt-based, rehearsal-free continual learning approach for document retrieval. PromptDSI follows the Prompt-based Continual Learning (PCL) framework, using learnable prompts to efficiently index new documents without accessing previous documents or queries. To improve retrieval latency, we remove the initial forward pass of PCL, which otherwise greatly increases training and inference time, with a negligible trade-off in performance. Additionally, we introduce a novel topic-aware prompt pool that employs neural topic embeddings as fixed keys, eliminating the instability of prompt key optimization while maintaining competitive performance with existing PCL prompt pools. In a challenging rehearsal-free continual learning setup, we demonstrate that PromptDSI variants outperform rehearsal-based baselines, match the strong cache-based baseline in mitigating forgetting, and significantly improving retrieval performance on new corpora.",
    "summary": "arXiv:2406.12593v3 Announce Type: replace-cross Abstract: Differentiable Search Index (DSI) utilizes pre-trained language models to perform indexing and document retrieval via end-to-end learning without relying on external indexes. However, DSI requires full re-training to index new documents, causing significant computational inefficiencies. Continual learning (CL) offers a solution by enabling the model to incrementally update without full re-training. Existing CL solutions in document retrieval rely on memory buffers or generative models for rehearsal, which is infeasible when accessing previous training data is restricted due to privacy concerns. To this end, we introduce PromptDSI, a prompt-based, rehearsal-free continual learning approach for document retrieval. PromptDSI follows the Prompt-based Continual Learning (PCL) framework, using learnable prompts to efficiently index new documents without accessing previous documents or queries. To improve retrieval latency, we remove the initial forward pass of PCL, which otherwise greatly increases training and inference time, with a negligible trade-off in performance. Additionally, we introduce a novel topic-aware prompt pool that employs neural topic embeddings as fixed keys, eliminating the instability of prompt key optimization while maintaining competitive performance with existing PCL prompt pools. In a challenging rehearsal-free continual learning setup, we demonstrate that PromptDSI variants outperform rehearsal-based baselines, match the strong cache-based baseline in mitigating forgetting, and significantly improving retrieval performance on new corpora.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.12593",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ÈäÖÁ∑öÊ≥•Ê£í„ÇíË®±„Åï„Å™„ÅÑ„ÄÄKDDIÁ≥ª‰ºÅÊ•≠„ÅåAWS„Åß‰∏ÄË®àÊ°à„Åò„Çã",
    "description": "KDDI„Çπ„Éû„Éº„Éà„Éâ„É≠„Éº„É≥„ÅØ„ÄåAmazon SageMaker„Äç„Å®ÈÄ£Êê∫„Åó„ÅüAIËß£Êûê„Éâ„É≠„Éº„É≥„Ç∑„Çπ„ÉÜ„É†„ÇíÈñãÁô∫„Åó„ÄÅÂ§™ÈôΩÂÖâÁô∫ÈõªÊñΩË®≠„ÅÆÂ§úÈñìË≠¶ÂÇô„Å´ÂÆüË£Ö„Åó„Åü„ÄÇÈÅ†ÈöîÈÅãËà™„Å®„É™„Ç¢„É´„Çø„Ç§„É†Ëß£Êûê„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„ÄÅ‰∫∫ÁöÑË≤†ÊãÖ„ÇíËªΩÊ∏õ„Åó„Å§„Å§ÁõóÈõ£ÂØæÁ≠ñ„ÇíÂº∑Âåñ„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "summary": "KDDI„Çπ„Éû„Éº„Éà„Éâ„É≠„Éº„É≥„ÅØ„ÄåAmazon SageMaker„Äç„Å®ÈÄ£Êê∫„Åó„ÅüAIËß£Êûê„Éâ„É≠„Éº„É≥„Ç∑„Çπ„ÉÜ„É†„ÇíÈñãÁô∫„Åó„ÄÅÂ§™ÈôΩÂÖâÁô∫ÈõªÊñΩË®≠„ÅÆÂ§úÈñìË≠¶ÂÇô„Å´ÂÆüË£Ö„Åó„Åü„ÄÇÈÅ†ÈöîÈÅãËà™„Å®„É™„Ç¢„É´„Çø„Ç§„É†Ëß£Êûê„ÇíÁµÑ„ÅøÂêà„Çè„Åõ„ÄÅ‰∫∫ÁöÑË≤†ÊãÖ„ÇíËªΩÊ∏õ„Åó„Å§„Å§ÁõóÈõ£ÂØæÁ≠ñ„ÇíÂº∑Âåñ„Åó„Å¶„ÅÑ„Çã„ÄÇ",
    "pubDate": "Thu, 19 Jun 2025 10:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://kn.itmedia.co.jp/kn/articles/2506/19/news033.html",
    "thumbnail": "https://image.itmedia.co.jp/kn/articles/2506/19/cover_news033.png"
  },
  {
    "title": "Advanced audio dialog and generation with Gemini 2.5",
    "description": "Gemini 2.5 has new capabilities in AI-powered audio dialog and generation.",
    "summary": "Gemini 2.5 has new capabilities in AI-powered audio dialog and generation.",
    "pubDate": "Tue, 03 Jun 2025 17:15:47 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/advanced-audio-dialog-and-generation-with-gemini-25/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/capability__native-audio_16-9_121.width-1300.jpg"
  },
  {
    "title": "DX„ÅÆÊú¨Ë≥™„ÅØÊäÄË°ìÂ∞éÂÖ•„Å´„ÅÇ„Çâ„Åö„ÄÄ„Ç§„É≥„Éâ„Éç„Ç∑„Ç¢Â∞èÂ£≤Â§ßÊâã„Å´Â≠¶„Å∂„ÄÅÈ°ßÂÆ¢„Éá„Éº„Çø„ÅÆÂæπÂ∫ïÊ¥ªÁî®",
    "description": "„Ç§„É≥„Éâ„Éç„Ç∑„Ç¢„ÅÆÂ§ßÊâãÂ∞èÂ£≤Ê•≠„Ç¢„É´„Éï„Ç°„Éû„Éº„Éà„ÅØ„ÄÅ25Âπ¥Èñì„Åß1‰∏á2000Â∫óËàó„Åã„Çâ2‰∏á2000Â∫óËàó„Å∏„Å®Êã°Â§ß„Åó„ÄÅÂõΩÂÜÖË™çÁü•Â∫¶98%„ÇíË™á„Çã„ÄÇÂêåÁ§æ„ÅÆÊà¶Áï•„Å®„Éì„Ç∏„Éç„Çπ„É¢„Éá„É´„Åã„Çâ„ÄÅÊó•Êú¨‰ºÅÊ•≠„ÅåÂ≠¶„Å∂„Åπ„Åç„Åì„Å®„Å®„ÅØ„ÄÇ",
    "summary": "„Ç§„É≥„Éâ„Éç„Ç∑„Ç¢„ÅÆÂ§ßÊâãÂ∞èÂ£≤Ê•≠„Ç¢„É´„Éï„Ç°„Éû„Éº„Éà„ÅØ„ÄÅ25Âπ¥Èñì„Åß1‰∏á2000Â∫óËàó„Åã„Çâ2‰∏á2000Â∫óËàó„Å∏„Å®Êã°Â§ß„Åó„ÄÅÂõΩÂÜÖË™çÁü•Â∫¶98%„ÇíË™á„Çã„ÄÇÂêåÁ§æ„ÅÆÊà¶Áï•„Å®„Éì„Ç∏„Éç„Çπ„É¢„Éá„É´„Åã„Çâ„ÄÅÊó•Êú¨‰ºÅÊ•≠„ÅåÂ≠¶„Å∂„Åπ„Åç„Åì„Å®„Å®„ÅØ„ÄÇ",
    "pubDate": "Mon, 23 Jun 2025 07:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2506/23/news010.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2506/23/cover_news010.jpg"
  },
  {
    "title": "Robo2VLM: Visual Question Answering from Large-Scale In-the-Wild Robot Manipulation Datasets",
    "description": "arXiv:2505.15517v2 Announce Type: replace-cross Abstract: Vision-Language Models (VLMs) acquire real-world knowledge and general reasoning ability through Internet-scale image-text corpora. They can augment robotic systems with scene understanding and task planning, and assist visuomotor policies that are trained on robot trajectory data. We explore the reverse paradigm - using rich, real, multi-modal robot trajectory data to enhance and evaluate VLMs. In this paper, we present Robo2VLM, a Visual Question Answering (VQA) dataset generation framework for VLMs. Given a human tele-operated robot trajectory, Robo2VLM derives ground-truth from non-visual and non-descriptive sensory modalities, such as end-effector pose, gripper aperture, and force sensing. Based on these modalities, it segments the robot trajectory into a sequence of manipulation phases. At each phase, Robo2VLM uses scene and interaction understanding to identify 3D properties of the robot, task goal, and the target object. The properties are used to generate representative VQA queries - images with textural multiple-choice questions - based on spatial, goal-conditioned, and interaction reasoning question templates. We curate Robo2VLM-1, a large-scale in-the-wild dataset with 684,710 questions covering 463 distinct scenes and 3,396 robotic manipulation tasks from 176k real robot trajectories. Results suggest that Robo2VLM-1 can benchmark and improve VLM capabilities in spatial and interaction reasoning.",
    "summary": "arXiv:2505.15517v2 Announce Type: replace-cross Abstract: Vision-Language Models (VLMs) acquire real-world knowledge and general reasoning ability through Internet-scale image-text corpora. They can augment robotic systems with scene understanding and task planning, and assist visuomotor policies that are trained on robot trajectory data. We explore the reverse paradigm - using rich, real, multi-modal robot trajectory data to enhance and evaluate VLMs. In this paper, we present Robo2VLM, a Visual Question Answering (VQA) dataset generation framework for VLMs. Given a human tele-operated robot trajectory, Robo2VLM derives ground-truth from non-visual and non-descriptive sensory modalities, such as end-effector pose, gripper aperture, and force sensing. Based on these modalities, it segments the robot trajectory into a sequence of manipulation phases. At each phase, Robo2VLM uses scene and interaction understanding to identify 3D properties of the robot, task goal, and the target object. The properties are used to generate representative VQA queries - images with textural multiple-choice questions - based on spatial, goal-conditioned, and interaction reasoning question templates. We curate Robo2VLM-1, a large-scale in-the-wild dataset with 684,710 questions covering 463 distinct scenes and 3,396 robotic manipulation tasks from 176k real robot trajectories. Results suggest that Robo2VLM-1 can benchmark and improve VLM capabilities in spatial and interaction reasoning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.15517",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Filling crucial language learning gaps",
    "description": "GPT-4 deepens the conversation on Duolingo.",
    "summary": "GPT-4 deepens the conversation on Duolingo.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/duolingo",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Shadow defense against gradient inversion attack in federated learning",
    "description": "arXiv:2506.15711v1 Announce Type: cross Abstract: Federated learning (FL) has emerged as a transformative framework for privacy-preserving distributed training, allowing clients to collaboratively train a global model without sharing their local data. This is especially crucial in sensitive fields like healthcare, where protecting patient data is paramount. However, privacy leakage remains a critical challenge, as the communication of model updates can be exploited by potential adversaries. Gradient inversion attacks (GIAs), for instance, allow adversaries to approximate the gradients used for training and reconstruct training images, thus stealing patient privacy. Existing defense mechanisms obscure gradients, yet lack a nuanced understanding of which gradients or types of image information are most vulnerable to such attacks. These indiscriminate calibrated perturbations result in either excessive privacy protection degrading model accuracy, or insufficient one failing to safeguard sensitive information. Therefore, we introduce a framework that addresses these challenges by leveraging a shadow model with interpretability for identifying sensitive areas. This enables a more targeted and sample-specific noise injection. Specially, our defensive strategy achieves discrepancies of 3.73 in PSNR and 0.2 in SSIM compared to the circumstance without defense on the ChestXRay dataset, and 2.78 in PSNR and 0.166 in the EyePACS dataset. Moreover, it minimizes adverse effects on model performance, with less than 1% F1 reduction compared to SOTA methods. Our extensive experiments, conducted across diverse types of medical images, validate the generalization of the proposed framework. The stable defense improvements for FedAvg are consistently over 1.5% times in LPIPS and SSIM. It also offers a universal defense against various GIA types, especially for these sensitive areas in images.",
    "summary": "arXiv:2506.15711v1 Announce Type: cross Abstract: Federated learning (FL) has emerged as a transformative framework for privacy-preserving distributed training, allowing clients to collaboratively train a global model without sharing their local data. This is especially crucial in sensitive fields like healthcare, where protecting patient data is paramount. However, privacy leakage remains a critical challenge, as the communication of model updates can be exploited by potential adversaries. Gradient inversion attacks (GIAs), for instance, allow adversaries to approximate the gradients used for training and reconstruct training images, thus stealing patient privacy. Existing defense mechanisms obscure gradients, yet lack a nuanced understanding of which gradients or types of image information are most vulnerable to such attacks. These indiscriminate calibrated perturbations result in either excessive privacy protection degrading model accuracy, or insufficient one failing to safeguard sensitive information. Therefore, we introduce a framework that addresses these challenges by leveraging a shadow model with interpretability for identifying sensitive areas. This enables a more targeted and sample-specific noise injection. Specially, our defensive strategy achieves discrepancies of 3.73 in PSNR and 0.2 in SSIM compared to the circumstance without defense on the ChestXRay dataset, and 2.78 in PSNR and 0.166 in the EyePACS dataset. Moreover, it minimizes adverse effects on model performance, with less than 1% F1 reduction compared to SOTA methods. Our extensive experiments, conducted across diverse types of medical images, validate the generalization of the proposed framework. The stable defense improvements for FedAvg are consistently over 1.5% times in LPIPS and SSIM. It also offers a universal defense against various GIA types, especially for these sensitive areas in images.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15711",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Scholars 2021: Final projects",
    "description": "We‚Äôre proud to announce that the 2021 class of¬†OpenAI Scholars¬†has completed our six-month mentorship program and have produced an open-source research project with stipends and support from¬†OpenAI.",
    "summary": "We‚Äôre proud to announce that the 2021 class of¬†OpenAI Scholars¬†has completed our six-month mentorship program and have produced an open-source research project with stipends and support from¬†OpenAI.",
    "pubDate": "Mon, 10 May 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2021-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New models and developer products announced at DevDay",
    "description": "GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL¬∑E 3 API, and more.",
    "summary": "GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL¬∑E 3 API, and more.",
    "pubDate": "Mon, 06 Nov 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-models-and-developer-products-announced-at-devday",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI London",
    "description": "We are excited to announce OpenAI‚Äôs first international expansion with a new office in London, United Kingdom.",
    "summary": "We are excited to announce OpenAI‚Äôs first international expansion with a new office in London, United Kingdom.",
    "pubDate": "Wed, 28 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-london",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fetch Cuts ML Processing Latency by 50% Using Amazon SageMaker & Hugging Face",
    "description": "",
    "summary": "Fetch Cuts ML Processing Latency by 50% Using Amazon SageMaker & Hugging Face This article is a cros...",
    "pubDate": "Fri, 01 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fetch-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/78_ml_director_insights/fetch.png"
  },
  {
    "title": "Empowering the next generation for an AI-enabled world",
    "description": "Experience AI's course and resources are expanding on a global scale",
    "summary": "Experience AI's course and resources are expanding on a global scale",
    "pubDate": "Wed, 15 Nov 2023 10:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/empowering-the-next-generation-for-an-ai-enabled-world/",
    "thumbnail": "https://lh3.googleusercontent.com/XJ10IR5bv5MmygxoFC0hrepTZtjq_Bwz69bL7d7jBy06fnEFodAa0tbIWKOwV7gW2Im3JY2GGda-xZKtVQhqcaozz6r_vdHXsgVu0CzyIhIz4VGs=w1200-h630-n-nu"
  },
  {
    "title": "KMS„ÄÅÊ•≠ÂãôÂäπÁéáÂåñ„Çµ„Éº„Éì„Çπ„ÄåDAIVERSE„Äç„Å´GPT-4.1„Å®WebÊÉÖÂ†±ÁôªÈå≤Ê©üËÉΩ„ÇíÂÆüË£Ö",
    "description": "<p>KMS„ÅØ„ÄÅÊ•≠ÂãôÂäπÁéáÂåñ„Çµ„Éº„Éì„Çπ„ÄåDAIVERSE„Äç„Å´„ÄÅAzure OpenAI Service„ÅÆGPT-4.1„É¢„Éá„É´„Å®Web„Çµ„Ç§„ÉàÊÉÖÂ†±ÁôªÈå≤Ê©üËÉΩ„ÇíÂÆüË£Ö„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà „ÄåDAIVERSE„Äç„Å´GPT-4.1„É¢ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/kms-azure-openai-service/'>KMS„ÄÅÊ•≠ÂãôÂäπÁéáÂåñ„Çµ„Éº„Éì„Çπ„ÄåDAIVERSE„Äç„Å´GPT-4.1„Å®WebÊÉÖÂ†±ÁôªÈå≤Ê©üËÉΩ„ÇíÂÆüË£Ö</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>KMS„ÅØ„ÄÅÊ•≠ÂãôÂäπÁéáÂåñ„Çµ„Éº„Éì„Çπ„ÄåDAIVERSE„Äç„Å´„ÄÅAzure OpenAI Service„ÅÆGPT-4.1„É¢„Éá„É´„Å®Web„Çµ„Ç§„ÉàÊÉÖÂ†±ÁôªÈå≤Ê©üËÉΩ„ÇíÂÆüË£Ö„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà „ÄåDAIVERSE„Äç„Å´GPT-4.1„É¢ [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/kms-azure-openai-service/'>KMS„ÄÅÊ•≠ÂãôÂäπÁéáÂåñ„Çµ„Éº„Éì„Çπ„ÄåDAIVERSE„Äç„Å´GPT-4.1„Å®WebÊÉÖÂ†±ÁôªÈå≤Ê©üËÉΩ„ÇíÂÆüË£Ö</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Fri, 13 Jun 2025 02:00:38 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/kms-azure-openai-service/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/kms-azure-openai-service1.png"
  },
  {
    "title": "Evolving OpenAI‚Äôs structure",
    "description": "An update from the OpenAI board on transitioning its for-profit entity to a Public Benefit Corporation, reinforcing its mission-driven structure under nonprofit oversight while enabling greater impact and long-term alignment with the public good.",
    "summary": "An update from the OpenAI board on transitioning its for-profit entity to a Public Benefit Corporation, reinforcing its mission-driven structure under nonprofit oversight while enabling greater impact and long-term alignment with the public good.",
    "pubDate": "Mon, 05 May 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evolving-our-structure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI Residency",
    "description": "As part of our effort to support and develop AI talent, we‚Äôre excited to announce the OpenAI Residency.",
    "summary": "As part of our effort to support and develop AI talent, we‚Äôre excited to announce the OpenAI Residency.",
    "pubDate": "Tue, 30 Nov 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-residency",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Sheaf-Based Decentralized Multimodal Learning for Next-Generation Wireless Communication Systems",
    "description": "arXiv:2506.22374v1 Announce Type: cross Abstract: In large-scale communication systems, increasingly complex scenarios require more intelligent collaboration among edge devices collecting various multimodal sensory data to achieve a more comprehensive understanding of the environment and improve decision-making accuracy. However, conventional federated learning (FL) algorithms typically consider unimodal datasets, require identical model architectures, and fail to leverage the rich information embedded in multimodal data, limiting their applicability to real-world scenarios with diverse modalities and varying client capabilities. To address this issue, we propose Sheaf-DMFL, a novel decentralized multimodal learning framework leveraging sheaf theory to enhance collaboration among devices with diverse modalities. Specifically, each client has a set of local feature encoders for its different modalities, whose outputs are concatenated before passing through a task-specific layer. While encoders for the same modality are trained collaboratively across clients, we capture the intrinsic correlations among clients' task-specific layers using a sheaf-based structure. To further enhance learning capability, we propose an enhanced algorithm named Sheaf-DMFL-Att, which tailors the attention mechanism within each client to capture correlations among different modalities. A rigorous convergence analysis of Sheaf-DMFL-Att is provided, establishing its theoretical guarantees. Extensive simulations are conducted on real-world link blockage prediction and mmWave beamforming scenarios, demonstrate the superiority of the proposed algorithms in such heterogeneous wireless communication systems.",
    "summary": "arXiv:2506.22374v1 Announce Type: cross Abstract: In large-scale communication systems, increasingly complex scenarios require more intelligent collaboration among edge devices collecting various multimodal sensory data to achieve a more comprehensive understanding of the environment and improve decision-making accuracy. However, conventional federated learning (FL) algorithms typically consider unimodal datasets, require identical model architectures, and fail to leverage the rich information embedded in multimodal data, limiting their applicability to real-world scenarios with diverse modalities and varying client capabilities. To address this issue, we propose Sheaf-DMFL, a novel decentralized multimodal learning framework leveraging sheaf theory to enhance collaboration among devices with diverse modalities. Specifically, each client has a set of local feature encoders for its different modalities, whose outputs are concatenated before passing through a task-specific layer. While encoders for the same modality are trained collaboratively across clients, we capture the intrinsic correlations among clients' task-specific layers using a sheaf-based structure. To further enhance learning capability, we propose an enhanced algorithm named Sheaf-DMFL-Att, which tailors the attention mechanism within each client to capture correlations among different modalities. A rigorous convergence analysis of Sheaf-DMFL-Att is provided, establishing its theoretical guarantees. Extensive simulations are conducted on real-world link blockage prediction and mmWave beamforming scenarios, demonstrate the superiority of the proposed algorithms in such heterogeneous wireless communication systems.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22374",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deep Learning over the Internet: Training Language Models Collaboratively",
    "description": "",
    "summary": "Deep Learning over the Internet: Training Language Models Collaboratively Modern language models oft...",
    "pubDate": "Thu, 15 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/collaborative-training",
    "thumbnail": "https://huggingface.co/blog/assets/24_sahajBERT/thumbnail.png"
  },
  {
    "title": "Understanding Human-AI Trust in Education",
    "description": "arXiv:2506.09160v3 Announce Type: replace-cross Abstract: As AI chatbots become increasingly integrated in education, students are turning to these systems for guidance, feedback, and information. However, the anthropomorphic characteristics of these chatbots create ambiguity regarding whether students develop trust toward them as they would a human peer or instructor, based in interpersonal trust, or as they would any other piece of technology, based in technology trust. This ambiguity presents theoretical challenges, as interpersonal trust models may inappropriately ascribe human intentionality and morality to AI, while technology trust models were developed for non-social technologies, leaving their applicability to anthropomorphic systems unclear. To address this gap, we investigate how human-like and system-like trusting beliefs comparatively influence students' perceived enjoyment, trusting intention, behavioral intention to use, and perceived usefulness of an AI chatbot - factors associated with students' engagement and learning outcomes. Through partial least squares structural equation modeling, we found that human-like and system-like trust significantly influenced student perceptions, with varied effects. Human-like trust more strongly predicted trusting intention, while system-like trust better predicted behavioral intention and perceived usefulness. Both had similar effects on perceived enjoyment. Given the partial explanatory power of each type of trust, we propose that students develop a distinct form of trust with AI chatbots (human-AI trust) that differs from human-human and human-technology models of trust. Our findings highlight the need for new theoretical frameworks specific to human-AI trust and offer practical insights for fostering appropriately calibrated trust, which is critical for the effective adoption and pedagogical impact of AI in education.",
    "summary": "arXiv:2506.09160v3 Announce Type: replace-cross Abstract: As AI chatbots become increasingly integrated in education, students are turning to these systems for guidance, feedback, and information. However, the anthropomorphic characteristics of these chatbots create ambiguity regarding whether students develop trust toward them as they would a human peer or instructor, based in interpersonal trust, or as they would any other piece of technology, based in technology trust. This ambiguity presents theoretical challenges, as interpersonal trust models may inappropriately ascribe human intentionality and morality to AI, while technology trust models were developed for non-social technologies, leaving their applicability to anthropomorphic systems unclear. To address this gap, we investigate how human-like and system-like trusting beliefs comparatively influence students' perceived enjoyment, trusting intention, behavioral intention to use, and perceived usefulness of an AI chatbot - factors associated with students' engagement and learning outcomes. Through partial least squares structural equation modeling, we found that human-like and system-like trust significantly influenced student perceptions, with varied effects. Human-like trust more strongly predicted trusting intention, while system-like trust better predicted behavioral intention and perceived usefulness. Both had similar effects on perceived enjoyment. Given the partial explanatory power of each type of trust, we propose that students develop a distinct form of trust with AI chatbots (human-AI trust) that differs from human-human and human-technology models of trust. Our findings highlight the need for new theoretical frameworks specific to human-AI trust and offer practical insights for fostering appropriately calibrated trust, which is critical for the effective adoption and pedagogical impact of AI in education.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.09160",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling",
    "description": "arXiv:2506.16043v1 Announce Type: cross Abstract: Inference-time scaling has proven effective in boosting large language model (LLM) performance through increased test-time computation. Yet, its practical application is often hindered by reliance on external verifiers or a lack of optimization for realistic computational constraints. We propose DynScaling, which addresses these limitations through two primary innovations: an integrated parallel-sequential sampling strategy and a bandit-based dynamic budget allocation framework. The integrated sampling strategy unifies parallel and sequential sampling by constructing synthetic sequential reasoning chains from initially independent parallel responses, promoting diverse and coherent reasoning trajectories. The dynamic budget allocation framework formulates the allocation of computational resources as a multi-armed bandit problem, adaptively distributing the inference budget across queries based on the uncertainty of previously sampled responses, thereby maximizing computational efficiency. By combining these components, DynScaling effectively improves LLM performance under practical resource constraints without the need for external verifiers. Experimental results demonstrate that DynScaling consistently surpasses existing verifier-free inference scaling baselines in both task performance and computational cost.",
    "summary": "arXiv:2506.16043v1 Announce Type: cross Abstract: Inference-time scaling has proven effective in boosting large language model (LLM) performance through increased test-time computation. Yet, its practical application is often hindered by reliance on external verifiers or a lack of optimization for realistic computational constraints. We propose DynScaling, which addresses these limitations through two primary innovations: an integrated parallel-sequential sampling strategy and a bandit-based dynamic budget allocation framework. The integrated sampling strategy unifies parallel and sequential sampling by constructing synthetic sequential reasoning chains from initially independent parallel responses, promoting diverse and coherent reasoning trajectories. The dynamic budget allocation framework formulates the allocation of computational resources as a multi-armed bandit problem, adaptively distributing the inference budget across queries based on the uncertainty of previously sampled responses, thereby maximizing computational efficiency. By combining these components, DynScaling effectively improves LLM performance under practical resource constraints without the need for external verifiers. Experimental results demonstrate that DynScaling consistently surpasses existing verifier-free inference scaling baselines in both task performance and computational cost.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16043",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Jukebox",
    "description": "We‚Äôre introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. We‚Äôre releasing the model weights and code, along with a tool to explore the generated¬†samples.",
    "summary": "We‚Äôre introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a variety of genres and artist styles. We‚Äôre releasing the model weights and code, along with a tool to explore the generated¬†samples.",
    "pubDate": "Thu, 30 Apr 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/jukebox",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face Teams Up with Protect AI: Enhancing Model Security for the Community",
    "description": "",
    "summary": "Hugging Face Teams Up with Protect AI: Enhancing Model Security for the Community We are pleased to ...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/protectai",
    "thumbnail": "https://huggingface.co/blog/assets/protectai/thumbnail.png"
  },
  {
    "title": "PrivacyXray: Detecting Privacy Breaches in LLMs through Semantic Consistency and Probability Certainty",
    "description": "arXiv:2506.19563v1 Announce Type: cross Abstract: Large Language Models (LLMs) are widely used in sensitive domains, including healthcare, finance, and legal services, raising concerns about potential private information leaks during inference. Privacy extraction attacks, such as jailbreaking, expose vulnerabilities in LLMs by crafting inputs that force the models to output sensitive information. However, these attacks cannot verify whether the extracted private information is accurate, as no public datasets exist for cross-validation, leaving a critical gap in private information detection during inference. To address this, we propose PrivacyXray, a novel framework detecting privacy breaches by analyzing LLM inner states. Our analysis reveals that LLMs exhibit higher semantic coherence and probabilistic certainty when generating correct private outputs. Based on this, PrivacyXray detects privacy breaches using four metrics: intra-layer and inter-layer semantic similarity, token-level and sentence-level probability distributions. PrivacyXray addresses critical challenges in private information detection by overcoming the lack of open-source private datasets and eliminating reliance on external data for validation. It achieves this through the synthesis of realistic private data and a detection mechanism based on the inner states of LLMs. Experiments show that PrivacyXray achieves consistent performance, with an average accuracy of 92.69% across five LLMs. Compared to state-of-the-art methods, PrivacyXray achieves significant improvements, with an average accuracy increase of 20.06%, highlighting its stability and practical utility in real-world applications.",
    "summary": "arXiv:2506.19563v1 Announce Type: cross Abstract: Large Language Models (LLMs) are widely used in sensitive domains, including healthcare, finance, and legal services, raising concerns about potential private information leaks during inference. Privacy extraction attacks, such as jailbreaking, expose vulnerabilities in LLMs by crafting inputs that force the models to output sensitive information. However, these attacks cannot verify whether the extracted private information is accurate, as no public datasets exist for cross-validation, leaving a critical gap in private information detection during inference. To address this, we propose PrivacyXray, a novel framework detecting privacy breaches by analyzing LLM inner states. Our analysis reveals that LLMs exhibit higher semantic coherence and probabilistic certainty when generating correct private outputs. Based on this, PrivacyXray detects privacy breaches using four metrics: intra-layer and inter-layer semantic similarity, token-level and sentence-level probability distributions. PrivacyXray addresses critical challenges in private information detection by overcoming the lack of open-source private datasets and eliminating reliance on external data for validation. It achieves this through the synthesis of realistic private data and a detection mechanism based on the inner states of LLMs. Experiments show that PrivacyXray achieves consistent performance, with an average accuracy of 92.69% across five LLMs. Compared to state-of-the-art methods, PrivacyXray achieves significant improvements, with an average accuracy increase of 20.06%, highlighting its stability and practical utility in real-world applications.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19563",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "On the quantitative analysis of decoder-based generative models",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 14 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/on-the-quantitative-analysis-of-decoder-based-generative-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Shaping the future of financial services",
    "description": "Morgan Stanley uses AI evals to shape the future of financial services",
    "summary": "Morgan Stanley uses AI evals to shape the future of financial services",
    "pubDate": "Wed, 04 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/morgan-stanley",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Interrogating AI: Characterizing Emergent Playful Interactions with ChatGPT",
    "description": "arXiv:2401.08405v4 Announce Type: replace-cross Abstract: In an era of AI's growing capabilities and influences, recent advancements are reshaping HCI and CSCW's view of AI. Playful interactions emerged as an important way for users to make sense of the ever-changing AI technologies, yet remained underexamined. We target this gap by investigating playful interactions exhibited by users of a popular AI technology, ChatGPT. Through a thematic analysis of 372 user-generated posts on the ChatGPT subreddit, we found that more than half (54%) of user discourse revolved around playful interactions. The analysis further allowed us to construct a preliminary framework to describe these interactions, categorizing them into six types: reflecting, jesting, imitating, challenging, tricking, and contriving; each included sub-categories. This study contributes to HCI and CSCW by identifying the diverse ways users engage in playful interactions with AI. It examines how these interactions can help users understand AI's agency, shape human-AI relationships, and provide insights for designing AI systems.",
    "summary": "arXiv:2401.08405v4 Announce Type: replace-cross Abstract: In an era of AI's growing capabilities and influences, recent advancements are reshaping HCI and CSCW's view of AI. Playful interactions emerged as an important way for users to make sense of the ever-changing AI technologies, yet remained underexamined. We target this gap by investigating playful interactions exhibited by users of a popular AI technology, ChatGPT. Through a thematic analysis of 372 user-generated posts on the ChatGPT subreddit, we found that more than half (54%) of user discourse revolved around playful interactions. The analysis further allowed us to construct a preliminary framework to describe these interactions, categorizing them into six types: reflecting, jesting, imitating, challenging, tricking, and contriving; each included sub-categories. This study contributes to HCI and CSCW by identifying the diverse ways users engage in playful interactions with AI. It examines how these interactions can help users understand AI's agency, shape human-AI relationships, and provide insights for designing AI systems.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2401.08405",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the GPT Store",
    "description": "We‚Äôre launching the GPT Store to help you find useful and popular custom versions of ChatGPT.",
    "summary": "We‚Äôre launching the GPT Store to help you find useful and popular custom versions of ChatGPT.",
    "pubDate": "Wed, 10 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-the-gpt-store",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Have a damaged painting? Restore it in just hours with an AI-generated ‚Äúmask‚Äù",
    "description": "A new method can physically restore original paintings using digitally constructed films, which can be removed if desired.",
    "summary": "A new method can physically restore original paintings using digitally constructed films, which can be removed if desired.",
    "pubDate": "Wed, 11 Jun 2025 11:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/restoring-damaged-paintings-using-ai-generated-mask-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-Restoring-Paintings-01-press.jpg"
  },
  {
    "title": "RoomCraft: Controllable and Complete 3D Indoor Scene Generation",
    "description": "arXiv:2506.22291v1 Announce Type: cross Abstract: Generating realistic 3D indoor scenes from user inputs remains a challenging problem in computer vision and graphics, requiring careful balance of geometric consistency, spatial relationships, and visual realism. While neural generation methods often produce repetitive elements due to limited global spatial reasoning, procedural approaches can leverage constraints for controllable generation but struggle with multi-constraint scenarios. When constraints become numerous, object collisions frequently occur, forcing the removal of furniture items and compromising layout completeness. To address these limitations, we propose RoomCraft, a multi-stage pipeline that converts real images, sketches, or text descriptions into coherent 3D indoor scenes. Our approach combines a scene generation pipeline with a constraint-driven optimization framework. The pipeline first extracts high-level scene information from user inputs and organizes it into a structured format containing room type, furniture items, and spatial relations. It then constructs a spatial relationship network to represent furniture arrangements and generates an optimized placement sequence using a heuristic-based depth-first search (HDFS) algorithm to ensure layout coherence. To handle complex multi-constraint scenarios, we introduce a unified constraint representation that processes both formal specifications and natural language inputs, enabling flexible constraint-oriented adjustments through a comprehensive action space design. Additionally, we propose a Conflict-Aware Positioning Strategy (CAPS) that dynamically adjusts placement weights to minimize furniture collisions and ensure layout completeness. Extensive experiments demonstrate that RoomCraft significantly outperforms existing methods in generating realistic, semantically coherent, and visually appealing room layouts across diverse input modalities.",
    "summary": "arXiv:2506.22291v1 Announce Type: cross Abstract: Generating realistic 3D indoor scenes from user inputs remains a challenging problem in computer vision and graphics, requiring careful balance of geometric consistency, spatial relationships, and visual realism. While neural generation methods often produce repetitive elements due to limited global spatial reasoning, procedural approaches can leverage constraints for controllable generation but struggle with multi-constraint scenarios. When constraints become numerous, object collisions frequently occur, forcing the removal of furniture items and compromising layout completeness. To address these limitations, we propose RoomCraft, a multi-stage pipeline that converts real images, sketches, or text descriptions into coherent 3D indoor scenes. Our approach combines a scene generation pipeline with a constraint-driven optimization framework. The pipeline first extracts high-level scene information from user inputs and organizes it into a structured format containing room type, furniture items, and spatial relations. It then constructs a spatial relationship network to represent furniture arrangements and generates an optimized placement sequence using a heuristic-based depth-first search (HDFS) algorithm to ensure layout coherence. To handle complex multi-constraint scenarios, we introduce a unified constraint representation that processes both formal specifications and natural language inputs, enabling flexible constraint-oriented adjustments through a comprehensive action space design. Additionally, we propose a Conflict-Aware Positioning Strategy (CAPS) that dynamically adjusts placement weights to minimize furniture collisions and ensure layout completeness. Extensive experiments demonstrate that RoomCraft significantly outperforms existing methods in generating realistic, semantically coherent, and visually appealing room layouts across diverse input modalities.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22291",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Evaluating large language models trained on code",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 07 Jul 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evaluating-large-language-models-trained-on-code",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Towards Understanding the Cognitive Habits of Large Reasoning Models",
    "description": "arXiv:2506.21571v1 Announce Type: cross Abstract: Large Reasoning Models (LRMs), which autonomously produce a reasoning Chain of Thought (CoT) before producing final responses, offer a promising approach to interpreting and monitoring model behaviors. Inspired by the observation that certain CoT patterns -- e.g., ``Wait, did I miss anything?'' -- consistently emerge across tasks, we explore whether LRMs exhibit human-like cognitive habits. Building on Habits of Mind, a well-established framework of cognitive habits associated with successful human problem-solving, we introduce CogTest, a principled benchmark designed to evaluate LRMs' cognitive habits. CogTest includes 16 cognitive habits, each instantiated with 25 diverse tasks, and employs an evidence-first extraction method to ensure reliable habit identification. With CogTest, we conduct a comprehensive evaluation of 16 widely used LLMs (13 LRMs and 3 non-reasoning ones). Our findings reveal that LRMs, unlike conventional LLMs, not only exhibit human-like habits but also adaptively deploy them according to different tasks. Finer-grained analyses further uncover patterns of similarity and difference in LRMs' cognitive habit profiles, particularly certain inter-family similarity (e.g., Qwen-3 models and DeepSeek-R1). Extending the study to safety-related tasks, we observe that certain habits, such as Taking Responsible Risks, are strongly associated with the generation of harmful responses. These findings suggest that studying persistent behavioral patterns in LRMs' CoTs is a valuable step toward deeper understanding of LLM misbehavior. The code is available at: https://github.com/jianshuod/CogTest.",
    "summary": "arXiv:2506.21571v1 Announce Type: cross Abstract: Large Reasoning Models (LRMs), which autonomously produce a reasoning Chain of Thought (CoT) before producing final responses, offer a promising approach to interpreting and monitoring model behaviors. Inspired by the observation that certain CoT patterns -- e.g., ``Wait, did I miss anything?'' -- consistently emerge across tasks, we explore whether LRMs exhibit human-like cognitive habits. Building on Habits of Mind, a well-established framework of cognitive habits associated with successful human problem-solving, we introduce CogTest, a principled benchmark designed to evaluate LRMs' cognitive habits. CogTest includes 16 cognitive habits, each instantiated with 25 diverse tasks, and employs an evidence-first extraction method to ensure reliable habit identification. With CogTest, we conduct a comprehensive evaluation of 16 widely used LLMs (13 LRMs and 3 non-reasoning ones). Our findings reveal that LRMs, unlike conventional LLMs, not only exhibit human-like habits but also adaptively deploy them according to different tasks. Finer-grained analyses further uncover patterns of similarity and difference in LRMs' cognitive habit profiles, particularly certain inter-family similarity (e.g., Qwen-3 models and DeepSeek-R1). Extending the study to safety-related tasks, we observe that certain habits, such as Taking Responsible Risks, are strongly associated with the generation of harmful responses. These findings suggest that studying persistent behavioral patterns in LRMs' CoTs is a valuable step toward deeper understanding of LLM misbehavior. The code is available at: https://github.com/jianshuod/CogTest.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21571",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome the Falcon 3 Family of Open Models!",
    "description": "",
    "summary": "Welcome to the Falcon 3 Family of Open Models! We introduce Falcon3, a family of decoder-only large ...",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/falcon3",
    "thumbnail": "https://huggingface.co/blog/assets/falcon3/thumbnail.png"
  },
  {
    "title": "QuickSilver -- Speeding up LLM Inference through Dynamic Token Halting, KV Skipping, Contextual Token Fusion, and Adaptive Matryoshka Quantization",
    "description": "arXiv:2506.22396v1 Announce Type: cross Abstract: Inference accounts for the majority of latency and energy consumption in large language model (LLM) deployments, often exceeding 90% of total cost. While training-time efficiency has seen extensive progress, runtime optimization remains a key bottleneck, particularly under autoregressive decoding. Existing approaches -- such as pruning, quantization, early exits, and speculative decoding -- often require retraining, architectural changes, or disrupt decoding compatibility. We introduce QuickSilver, a modular, token-level framework that enables semantic adaptivity at inference time without altering model weights or structure. QuickSilver integrates four synergistic mechanisms: (i) Dynamic Token Halting, which halts computation for tokens with converged representations; (ii) KV Cache Skipping, which selectively suppresses memory writes to reduce attention overhead; and (iii) Contextual Token Fusion, which collapses redundant tokens into shared paths to shrink sequence length. Unlike speculative decoding or MoE routing, QuickSilver operates entirely on frozen, dense models and requires no auxiliary networks. Applied to GPT-2 and Llama-2 across WikiText-103 and C4, QuickSilver achieves up to 39.6% FLOP reduction with negligible perplexity degradation (<=0.2).",
    "summary": "arXiv:2506.22396v1 Announce Type: cross Abstract: Inference accounts for the majority of latency and energy consumption in large language model (LLM) deployments, often exceeding 90% of total cost. While training-time efficiency has seen extensive progress, runtime optimization remains a key bottleneck, particularly under autoregressive decoding. Existing approaches -- such as pruning, quantization, early exits, and speculative decoding -- often require retraining, architectural changes, or disrupt decoding compatibility. We introduce QuickSilver, a modular, token-level framework that enables semantic adaptivity at inference time without altering model weights or structure. QuickSilver integrates four synergistic mechanisms: (i) Dynamic Token Halting, which halts computation for tokens with converged representations; (ii) KV Cache Skipping, which selectively suppresses memory writes to reduce attention overhead; and (iii) Contextual Token Fusion, which collapses redundant tokens into shared paths to shrink sequence length. Unlike speculative decoding or MoE routing, QuickSilver operates entirely on frozen, dense models and requires no auxiliary networks. Applied to GPT-2 and Llama-2 across WikiText-103 and C4, QuickSilver achieves up to 39.6% FLOP reduction with negligible perplexity degradation (<=0.2).",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22396",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sparse-Reg: Improving Sample Complexity in Offline Reinforcement Learning using Sparsity",
    "description": "arXiv:2506.17155v1 Announce Type: cross Abstract: In this paper, we investigate the use of small datasets in the context of offline reinforcement learning (RL). While many common offline RL benchmarks employ datasets with over a million data points, many offline RL applications rely on considerably smaller datasets. We show that offline RL algorithms can overfit on small datasets, resulting in poor performance. To address this challenge, we introduce 'Sparse-Reg': a regularization technique based on sparsity to mitigate overfitting in offline reinforcement learning, enabling effective learning in limited data settings and outperforming state-of-the-art baselines in continuous control.",
    "summary": "arXiv:2506.17155v1 Announce Type: cross Abstract: In this paper, we investigate the use of small datasets in the context of offline reinforcement learning (RL). While many common offline RL benchmarks employ datasets with over a million data points, many offline RL applications rely on considerably smaller datasets. We show that offline RL algorithms can overfit on small datasets, resulting in poor performance. To address this challenge, we introduce 'Sparse-Reg': a regularization technique based on sparsity to mitigate overfitting in offline reinforcement learning, enabling effective learning in limited data settings and outperforming state-of-the-art baselines in continuous control.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17155",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„ÄåSaaS„ÅåÁµÇ„Çè„ÇãÔºü„ÄÄËààÂë≥„Å™„ÅÑ„Äç„ÄÄ„É©„ÇØ„ÇπÁ§æÈï∑„ÅåË™û„ÇãAI„ÅÆ„ÄåÁúü„ÅÆËÑÖÂ®Å„Äç",
    "description": "ÂõΩÂÜÖSaaSÊ•≠Áïå„Éà„ÉÉ„Éó„É©„É≥„Éä„Éº„ÅÆ„É©„ÇØ„Çπ„ÄÇ„ÄåSaaS„ÅåÊ≠ª„Å¨„Åã„Å©„ÅÜ„Åã„Å£„Å¶„Åù„Çì„Å™„Å´ËààÂë≥„Å™„ÅÑ„Äç„Å®Êòé„Åã„Åô‰∏≠ÊùëÂ¥áÂâáÁ§æÈï∑„Åå„ÄÅÊú¨ÂΩì„Å´ÊÅê„Çå„Å¶„ÅÑ„Çã„ÇÇ„ÅÆ„Å®„ÅØ‰Ωï„Å™„ÅÆ„Åã„ÄÇÊ•≠Áïå„Éà„ÉÉ„Éó„ÅåÊòé„Åã„ÅôAIÊôÇ‰ª£„ÅÆÁîüÂ≠òÊà¶Áï•„ÇíËÅû„ÅÑ„Åü„ÄÇ",
    "summary": "ÂõΩÂÜÖSaaSÊ•≠Áïå„Éà„ÉÉ„Éó„É©„É≥„Éä„Éº„ÅÆ„É©„ÇØ„Çπ„ÄÇ„ÄåSaaS„ÅåÊ≠ª„Å¨„Åã„Å©„ÅÜ„Åã„Å£„Å¶„Åù„Çì„Å™„Å´ËààÂë≥„Å™„ÅÑ„Äç„Å®Êòé„Åã„Åô‰∏≠ÊùëÂ¥áÂâáÁ§æÈï∑„Åå„ÄÅÊú¨ÂΩì„Å´ÊÅê„Çå„Å¶„ÅÑ„Çã„ÇÇ„ÅÆ„Å®„ÅØ‰Ωï„Å™„ÅÆ„Åã„ÄÇÊ•≠Áïå„Éà„ÉÉ„Éó„ÅåÊòé„Åã„ÅôAIÊôÇ‰ª£„ÅÆÁîüÂ≠òÊà¶Áï•„ÇíËÅû„ÅÑ„Åü„ÄÇ",
    "pubDate": "Wed, 25 Jun 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/business/articles/2506/25/news038.html",
    "thumbnail": "https://image.itmedia.co.jp/business/articles/2506/25/cover_news038.jpg"
  },
  {
    "title": "MuZero, AlphaZero, and AlphaDev: Optimizing computer systems",
    "description": "How MuZero, AlphaZero, and AlphaDev are optimizing the computing ecosystem that powers our world of devices.",
    "summary": "How MuZero, AlphaZero, and AlphaDev are optimizing the computing ecosystem that powers our world of devices.",
    "pubDate": "Mon, 12 Jun 2023 14:41:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/muzero-alphazero-and-alphadev-optimizing-computer-systems/",
    "thumbnail": "https://lh3.googleusercontent.com/6tSxHgEgSLR8FSELf3If1M1QBbXTtpsfH6w2ocuruWGnFDTdogbyNA8sHOyKpFYCja4hT7fGCVwl2xyI9biVB1bFNcnTxvYptuVdcT0XHMjn-TzG=w1200-h630-n-nu"
  },
  {
    "title": "Weight normalization: A simple reparameterization to accelerate training of deep neural networks",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 25 Feb 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/weight-normalization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PatchTSMixer in HuggingFace",
    "description": "",
    "summary": "PatchTSMixer in HuggingFace - Getting Started PatchTSMixer is a lightweight time-series modeling app...",
    "pubDate": "Fri, 19 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/patchtsmixer",
    "thumbnail": "https://huggingface.co/blog/assets/patchtsmixer/thumbnail.jpeg"
  },
  {
    "title": "Introducing SimpleQA",
    "description": "A factuality benchmark called SimpleQA that measures the ability for language models to answer short, fact-seeking questions.",
    "summary": "A factuality benchmark called SimpleQA that measures the ability for language models to answer short, fact-seeking questions.",
    "pubDate": "Wed, 30 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-simpleqa",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PR-Attack: Coordinated Prompt-RAG Attacks on Retrieval-Augmented Generation in Large Language Models via Bilevel Optimization",
    "description": "arXiv:2504.07717v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of applications, e.g., medical question-answering, mathematical sciences, and code generation. However, they also exhibit inherent limitations, such as outdated knowledge and susceptibility to hallucinations. Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to address these issues, but it also introduces new vulnerabilities. Recent efforts have focused on the security of RAG-based LLMs, yet existing attack methods face three critical challenges: (1) their effectiveness declines sharply when only a limited number of poisoned texts can be injected into the knowledge database, (2) they lack sufficient stealth, as the attacks are often detectable by anomaly detection systems, which compromises their effectiveness, and (3) they rely on heuristic approaches to generate poisoned texts, lacking formal optimization frameworks and theoretic guarantees, which limits their effectiveness and applicability. To address these issues, we propose coordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack that introduces a small number of poisoned texts into the knowledge database while embedding a backdoor trigger within the prompt. When activated, the trigger causes the LLM to generate pre-designed responses to targeted queries, while maintaining normal behavior in other contexts. This ensures both high effectiveness and stealth. We formulate the attack generation process as a bilevel optimization problem leveraging a principled optimization framework to develop optimal poisoned texts and triggers. Extensive experiments across diverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving a high attack success rate even with a limited number of poisoned texts and significantly improved stealth compared to existing methods.",
    "summary": "arXiv:2504.07717v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of applications, e.g., medical question-answering, mathematical sciences, and code generation. However, they also exhibit inherent limitations, such as outdated knowledge and susceptibility to hallucinations. Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to address these issues, but it also introduces new vulnerabilities. Recent efforts have focused on the security of RAG-based LLMs, yet existing attack methods face three critical challenges: (1) their effectiveness declines sharply when only a limited number of poisoned texts can be injected into the knowledge database, (2) they lack sufficient stealth, as the attacks are often detectable by anomaly detection systems, which compromises their effectiveness, and (3) they rely on heuristic approaches to generate poisoned texts, lacking formal optimization frameworks and theoretic guarantees, which limits their effectiveness and applicability. To address these issues, we propose coordinated Prompt-RAG attack (PR-attack), a novel optimization-driven attack that introduces a small number of poisoned texts into the knowledge database while embedding a backdoor trigger within the prompt. When activated, the trigger causes the LLM to generate pre-designed responses to targeted queries, while maintaining normal behavior in other contexts. This ensures both high effectiveness and stealth. We formulate the attack generation process as a bilevel optimization problem leveraging a principled optimization framework to develop optimal poisoned texts and triggers. Extensive experiments across diverse LLMs and datasets demonstrate the effectiveness of PR-Attack, achieving a high attack success rate even with a limited number of poisoned texts and significantly improved stealth compared to existing methods.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.07717",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deploy Hugging Face models easily with Amazon SageMaker",
    "description": "",
    "summary": "Deploy Hugging Face models easily with Amazon SageMaker üèé Earlier this year we announced a strategic...",
    "pubDate": "Thu, 08 Jul 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deploy-hugging-face-models-easily-with-amazon-sagemaker",
    "thumbnail": "https://huggingface.co/blog/assets/17_the_partnership_amazon_sagemaker_and_hugging_face/thumbnail.png"
  },
  {
    "title": "Google DeepMind at ICLR 2024",
    "description": "Developing next-gen AI agents, exploring new modalities, and pioneering foundational learning",
    "summary": "Developing next-gen AI agents, exploring new modalities, and pioneering foundational learning",
    "pubDate": "Fri, 03 May 2024 13:39:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/google-deepmind-at-iclr-2024/",
    "thumbnail": "https://lh3.googleusercontent.com/8PzKGooudBtamqh9keU_q7O0ex5XxGgIIK3BKQNAVEV6WDzIkfadsbNPhU0QCg5PurFGnAOSOClrM9dQHIGvOEe9MPluA5uhyFcun3FvNMBfPI63mWk=w1200-h630-n-nu"
  },
  {
    "title": "Consistency Models",
    "description": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation.",
    "summary": "Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation.",
    "pubDate": "Thu, 20 Jun 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/consistency-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New and improved content moderation tooling",
    "description": "We are introducing a new and improved content moderation tool. The¬†Moderation endpoint¬†improves upon our previous content filter, and is available for free today to OpenAI API¬†developers.",
    "summary": "We are introducing a new and improved content moderation tool. The¬†Moderation endpoint¬†improves upon our previous content filter, and is available for free today to OpenAI API¬†developers.",
    "pubDate": "Wed, 10 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-and-improved-content-moderation-tooling",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Running IF with üß® diffusers on a Free Tier Google Colab",
    "description": "",
    "summary": "Running IF with üß® diffusers on a Free Tier Google Colab TL;DR: We show how to run one of the most po...",
    "pubDate": "Wed, 26 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/if",
    "thumbnail": "https://huggingface.co/blog/assets/if/thumbnail.jpg"
  },
  {
    "title": "Off-Policy Actor-Critic for Adversarial Observation Robustness: Virtual Alternative Training via Symmetric Policy Evaluation",
    "description": "arXiv:2506.16753v1 Announce Type: cross Abstract: Recently, robust reinforcement learning (RL) methods designed to handle adversarial input observations have received significant attention, motivated by RL's inherent vulnerabilities. While existing approaches have demonstrated reasonable success, addressing worst-case scenarios over long time horizons requires both minimizing the agent's cumulative rewards for adversaries and training agents to counteract them through alternating learning. However, this process introduces mutual dependencies between the agent and the adversary, making interactions with the environment inefficient and hindering the development of off-policy methods. In this work, we propose a novel off-policy method that eliminates the need for additional environmental interactions by reformulating adversarial learning as a soft-constrained optimization problem. Our approach is theoretically supported by the symmetric property of policy evaluation between the agent and the adversary. The implementation is available at https://github.com/nakanakakosuke/VALT_SAC.",
    "summary": "arXiv:2506.16753v1 Announce Type: cross Abstract: Recently, robust reinforcement learning (RL) methods designed to handle adversarial input observations have received significant attention, motivated by RL's inherent vulnerabilities. While existing approaches have demonstrated reasonable success, addressing worst-case scenarios over long time horizons requires both minimizing the agent's cumulative rewards for adversaries and training agents to counteract them through alternating learning. However, this process introduces mutual dependencies between the agent and the adversary, making interactions with the environment inefficient and hindering the development of off-policy methods. In this work, we propose a novel off-policy method that eliminates the need for additional environmental interactions by reformulating adversarial learning as a soft-constrained optimization problem. Our approach is theoretically supported by the symmetric property of policy evaluation between the agent and the adversary. The implementation is available at https://github.com/nakanakakosuke/VALT_SAC.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16753",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Moir'eXNet: Adaptive Multi-Scale Demoir'eing with Linear Attention Test-Time Training and Truncated Flow Matching Prior",
    "description": "arXiv:2506.15929v1 Announce Type: cross Abstract: This paper introduces a novel framework for image and video demoir'eing by integrating Maximum A Posteriori (MAP) estimation with advanced deep learning techniques. Demoir'eing addresses inherently nonlinear degradation processes, which pose significant challenges for existing methods. Traditional supervised learning approaches either fail to remove moir'e patterns completely or produce overly smooth results. This stems from constrained model capacity and scarce training data, which inadequately represent the clean image distribution and hinder accurate reconstruction of ground-truth images. While generative models excel in image restoration for linear degradations, they struggle with nonlinear cases such as demoir'eing and often introduce artifacts. To address these limitations, we propose a hybrid MAP-based framework that integrates two complementary components. The first is a supervised learning model enhanced with efficient linear attention Test-Time Training (TTT) modules, which directly learn nonlinear mappings for RAW-to-sRGB demoir'eing. The second is a Truncated Flow Matching Prior (TFMP) that further refines the outputs by aligning them with the clean image distribution, effectively restoring high-frequency details and suppressing artifacts. These two components combine the computational efficiency of linear attention with the refinement abilities of generative models, resulting in improved restoration performance.",
    "summary": "arXiv:2506.15929v1 Announce Type: cross Abstract: This paper introduces a novel framework for image and video demoir'eing by integrating Maximum A Posteriori (MAP) estimation with advanced deep learning techniques. Demoir'eing addresses inherently nonlinear degradation processes, which pose significant challenges for existing methods. Traditional supervised learning approaches either fail to remove moir'e patterns completely or produce overly smooth results. This stems from constrained model capacity and scarce training data, which inadequately represent the clean image distribution and hinder accurate reconstruction of ground-truth images. While generative models excel in image restoration for linear degradations, they struggle with nonlinear cases such as demoir'eing and often introduce artifacts. To address these limitations, we propose a hybrid MAP-based framework that integrates two complementary components. The first is a supervised learning model enhanced with efficient linear attention Test-Time Training (TTT) modules, which directly learn nonlinear mappings for RAW-to-sRGB demoir'eing. The second is a Truncated Flow Matching Prior (TFMP) that further refines the outputs by aligning them with the clean image distribution, effectively restoring high-frequency details and suppressing artifacts. These two components combine the computational efficiency of linear attention with the refinement abilities of generative models, resulting in improved restoration performance.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15929",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing HUGS - Scale your AI with Open Models",
    "description": "",
    "summary": "Introducing HUGS - Scale your AI with Open Models Today, we are thrilled to announce the launch of H...",
    "pubDate": "Wed, 23 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hugs",
    "thumbnail": "https://huggingface.co/blog/assets/hugs/thumbnail.jpg"
  },
  {
    "title": "Researchers present bold ideas for AI at MIT Generative AI Impact Consortium kickoff event",
    "description": "Presentations targeted high-impact intersections of AI and other areas, such as health care, business, and education.",
    "summary": "Presentations targeted high-impact intersections of AI and other areas, such as health care, business, and education.",
    "pubDate": "Fri, 20 Jun 2025 16:45:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/researchers-present-bold-ideas-ai-mit-generative-ai-impact-consortium-event-0620",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-Anantha.jpg"
  },
  {
    "title": "Hugging Face + PyCharm",
    "description": "",
    "summary": "Hugging Face + PyCharm It‚Äôs a Tuesday morning. As a Transformers maintainer, I‚Äôm doing the same thin...",
    "pubDate": "Tue, 05 Nov 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pycharm-integration",
    "thumbnail": "https://huggingface.co/blog/assets/pycharm-integration/thumbnail.png"
  },
  {
    "title": "Scaling-up BERT Inference on CPU (Part 1)",
    "description": "",
    "summary": "Scaling up BERT-like model Inference on modern CPU - Part 1 1. Context and Motivations Back in Octob...",
    "pubDate": "Tue, 20 Apr 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-cpu-scaling-part-1",
    "thumbnail": "https://huggingface.co/blog/assets/21_bert_cpu_scaling_part_1/imgs/numa_set.png"
  },
  {
    "title": "Med-U1: Incentivizing Unified Medical Reasoning in LLMs via Large-scale Reinforcement Learning",
    "description": "arXiv:2506.12307v2 Announce Type: replace-cross Abstract: Medical Question-Answering (QA) encompasses a broad spectrum of tasks, including multiple choice questions (MCQ), open-ended text generation, and complex computational reasoning. Despite this variety, a unified framework for delivering high-quality medical QA has yet to emerge. Although recent progress in reasoning-augmented large language models (LLMs) has shown promise, their ability to achieve comprehensive medical understanding is still largely unexplored. In this paper, we present Med-U1, a unified framework for robust reasoning across medical QA tasks with diverse output formats, ranging from MCQs to complex generation and computation tasks. Med-U1 employs pure large-scale reinforcement learning with mixed rule-based binary reward functions, incorporating a length penalty to manage output verbosity. With multi-objective reward optimization, Med-U1 directs LLMs to produce concise and verifiable reasoning chains. Empirical results reveal that Med-U1 significantly improves performance across multiple challenging Med-QA benchmarks, surpassing even larger specialized and proprietary models. Furthermore, Med-U1 demonstrates robust generalization to out-of-distribution (OOD) tasks. Extensive analysis presents insights into training strategies, reasoning chain length control, and reward design for medical LLMs. Our code is available here.",
    "summary": "arXiv:2506.12307v2 Announce Type: replace-cross Abstract: Medical Question-Answering (QA) encompasses a broad spectrum of tasks, including multiple choice questions (MCQ), open-ended text generation, and complex computational reasoning. Despite this variety, a unified framework for delivering high-quality medical QA has yet to emerge. Although recent progress in reasoning-augmented large language models (LLMs) has shown promise, their ability to achieve comprehensive medical understanding is still largely unexplored. In this paper, we present Med-U1, a unified framework for robust reasoning across medical QA tasks with diverse output formats, ranging from MCQs to complex generation and computation tasks. Med-U1 employs pure large-scale reinforcement learning with mixed rule-based binary reward functions, incorporating a length penalty to manage output verbosity. With multi-objective reward optimization, Med-U1 directs LLMs to produce concise and verifiable reasoning chains. Empirical results reveal that Med-U1 significantly improves performance across multiple challenging Med-QA benchmarks, surpassing even larger specialized and proprietary models. Furthermore, Med-U1 demonstrates robust generalization to out-of-distribution (OOD) tasks. Extensive analysis presents insights into training strategies, reasoning chain length control, and reward design for medical LLMs. Our code is available here.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12307",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing OpenAI for Government",
    "description": "We‚Äôre launching OpenAI for Government, a new initiative focused on bringing our most advanced AI tools to public servants across the United States. We're supporting the U.S. government's efforts in adopting best-in-class technology and deploying these tools in service of the public good.",
    "summary": "We‚Äôre launching OpenAI for Government, a new initiative focused on bringing our most advanced AI tools to public servants across the United States. We're supporting the U.S. government's efforts in adopting best-in-class technology and deploying these tools in service of the public good.",
    "pubDate": "Mon, 16 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/introducing-openai-for-government",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing NPC-Playground, a 3D playground to interact with LLM-powered NPCs",
    "description": "",
    "summary": "Introducing NPC-Playground, a 3D playground to interact with LLM-powered NPCs AI-powered NPCs (Non-P...",
    "pubDate": "Wed, 05 Jun 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/npc-gigax-cubzh",
    "thumbnail": "https://huggingface.co/blog/assets/181_npc-gigax-cubzh/thumbnail.png"
  },
  {
    "title": "ECCoT: A Framework for Enhancing Effective Cognition via Chain of Thought in Large Language Model",
    "description": "arXiv:2506.19599v1 Announce Type: cross Abstract: In the era of large-scale artificial intelligence, Large Language Models (LLMs) have made significant strides in natural language processing. However, they often lack transparency and generate unreliable outputs, raising concerns about their interpretability. To address this, the Chain of Thought (CoT) prompting method structures reasoning into step-by-step deductions. Yet, not all reasoning chains are valid, and errors can lead to unreliable conclusions. We propose ECCoT, an End-to-End Cognitive Chain of Thought Validation Framework, to evaluate and refine reasoning chains in LLMs. ECCoT integrates the Markov Random Field-Embedded Topic Model (MRF-ETM) for topic-aware CoT generation and Causal Sentence-BERT (CSBert) for causal reasoning alignment. By filtering ineffective chains using structured ordering statistics, ECCoT improves interpretability, reduces biases, and enhances the trustworthiness of LLM-based decision-making. Key contributions include the introduction of ECCoT, MRF-ETM for topic-driven CoT generation, and CSBert for causal reasoning enhancement. Code is released at: https://github.com/erwinmsmith/ECCoT.git.",
    "summary": "arXiv:2506.19599v1 Announce Type: cross Abstract: In the era of large-scale artificial intelligence, Large Language Models (LLMs) have made significant strides in natural language processing. However, they often lack transparency and generate unreliable outputs, raising concerns about their interpretability. To address this, the Chain of Thought (CoT) prompting method structures reasoning into step-by-step deductions. Yet, not all reasoning chains are valid, and errors can lead to unreliable conclusions. We propose ECCoT, an End-to-End Cognitive Chain of Thought Validation Framework, to evaluate and refine reasoning chains in LLMs. ECCoT integrates the Markov Random Field-Embedded Topic Model (MRF-ETM) for topic-aware CoT generation and Causal Sentence-BERT (CSBert) for causal reasoning alignment. By filtering ineffective chains using structured ordering statistics, ECCoT improves interpretability, reduces biases, and enhances the trustworthiness of LLM-based decision-making. Key contributions include the introduction of ECCoT, MRF-ETM for topic-driven CoT generation, and CSBert for causal reasoning enhancement. Code is released at: https://github.com/erwinmsmith/ECCoT.git.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19599",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Personalizing education with ChatGPT",
    "description": "Arizona State University embraces ChatGPT campus-wide to personalize learning, advance research, and prepare students for the future",
    "summary": "Arizona State University embraces ChatGPT campus-wide to personalize learning, advance research, and prepare students for the future",
    "pubDate": "Mon, 26 Aug 2024 04:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/asu",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring",
    "description": "arXiv:2506.19325v2 Announce Type: replace Abstract: In English education tutoring, teacher feedback is essential for guiding students. Recently, AI-based tutoring systems have emerged to assist teachers; however, these systems require high-quality and large-scale teacher feedback data, which is both time-consuming and costly to generate manually. In this study, we propose FEAT, a cost-effective framework for generating teacher feedback, and have constructed three complementary datasets: (1) DIRECT-Manual (DM), where both humans and large language models (LLMs) collaboratively generate high-quality teacher feedback, albeit at a higher cost; (2) DIRECT-Generated (DG), an LLM-only generated, cost-effective dataset with lower quality;, and (3) DIRECT-Augmented (DA), primarily based on DG with a small portion of DM added to enhance quality while maintaining cost-efficiency. Experimental results showed that incorporating a small portion of DM (5-10%) into DG leads to superior performance compared to using 100% DM alone.",
    "summary": "arXiv:2506.19325v2 Announce Type: replace Abstract: In English education tutoring, teacher feedback is essential for guiding students. Recently, AI-based tutoring systems have emerged to assist teachers; however, these systems require high-quality and large-scale teacher feedback data, which is both time-consuming and costly to generate manually. In this study, we propose FEAT, a cost-effective framework for generating teacher feedback, and have constructed three complementary datasets: (1) DIRECT-Manual (DM), where both humans and large language models (LLMs) collaboratively generate high-quality teacher feedback, albeit at a higher cost; (2) DIRECT-Generated (DG), an LLM-only generated, cost-effective dataset with lower quality;, and (3) DIRECT-Augmented (DA), primarily based on DG with a small portion of DM added to enhance quality while maintaining cost-efficiency. Experimental results showed that incorporating a small portion of DM (5-10%) into DG leads to superior performance compared to using 100% DM alone.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19325",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Function calling and other API updates",
    "description": "We‚Äôre announcing updates including more steerable API models, function calling capabilities, longer context, and lower prices.",
    "summary": "We‚Äôre announcing updates including more steerable API models, function calling capabilities, longer context, and lower prices.",
    "pubDate": "Tue, 13 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/function-calling-and-other-api-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "EQUES„ÄÅË£ΩËñ¨ÁâπÂåñLLM„ÄåJPharmatron-7B„Äç„ÇíÈñãÁô∫„ÄÇËñ¨ÊñáÊõ∏‰ΩúÊàê„Å™„Å©„ÄÅË£ΩËñ¨Ê•≠Âãô„Å´„Åä„Åë„ÇãÊ¥ªÁî®„ÇíÁõÆÊåá„Åô",
    "description": "<p>EQUES„ÅØ„ÄÅÁµåÊ∏àÁî£Ê•≠ÁúÅ/NEDO„Å´„Çà„ÇãÁîüÊàêAIÁ†îÁ©∂ÊîØÊè¥„Éó„É≠„Ç∞„É©„É†„ÄåGENIAC„Äç„ÅÆ‰∏ÄÁí∞„Å®„Åó„Å¶„ÄÅË£ΩËñ¨Ê•≠ÁïåÂêë„Åë„ÅÆÊñ∞„Åó„ÅÑLLM„ÄåJPharmatron-7B„Äç„ÇíÁô∫Ë°®„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Ë£ΩËñ¨Ê•≠ÁïåÂêë„ÅëLLM„ÄåJP [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/eques-develops-pharmaceutical-specific-llm/'>EQUES„ÄÅË£ΩËñ¨ÁâπÂåñLLM„ÄåJPharmatron-7B„Äç„ÇíÈñãÁô∫„ÄÇËñ¨ÊñáÊõ∏‰ΩúÊàê„Å™„Å©„ÄÅË£ΩËñ¨Ê•≠Âãô„Å´„Åä„Åë„ÇãÊ¥ªÁî®„ÇíÁõÆÊåá„Åô</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>EQUES„ÅØ„ÄÅÁµåÊ∏àÁî£Ê•≠ÁúÅ/NEDO„Å´„Çà„ÇãÁîüÊàêAIÁ†îÁ©∂ÊîØÊè¥„Éó„É≠„Ç∞„É©„É†„ÄåGENIAC„Äç„ÅÆ‰∏ÄÁí∞„Å®„Åó„Å¶„ÄÅË£ΩËñ¨Ê•≠ÁïåÂêë„Åë„ÅÆÊñ∞„Åó„ÅÑLLM„ÄåJPharmatron-7B„Äç„ÇíÁô∫Ë°®„Åó„Åæ„Åó„Åü„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Ë£ΩËñ¨Ê•≠ÁïåÂêë„ÅëLLM„ÄåJP [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/eques-develops-pharmaceutical-specific-llm/'>EQUES„ÄÅË£ΩËñ¨ÁâπÂåñLLM„ÄåJPharmatron-7B„Äç„ÇíÈñãÁô∫„ÄÇËñ¨ÊñáÊõ∏‰ΩúÊàê„Å™„Å©„ÄÅË£ΩËñ¨Ê•≠Âãô„Å´„Åä„Åë„ÇãÊ¥ªÁî®„ÇíÁõÆÊåá„Åô</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Thu, 12 Jun 2025 09:25:20 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/eques-develops-pharmaceutical-specific-llm/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/eques-develops-pharmaceutical-specific-llm1.png"
  },
  {
    "title": "Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details",
    "description": "arXiv:2506.16504v1 Announce Type: cross Abstract: In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion models aimed at generating high-fidelity and detailed textured 3D assets. Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D 2.0, while demonstrating substantial advancements in both shape and texture generation. In terms of shape generation, we introduce a new shape foundation model -- LATTICE, which is trained with scaled high-quality datasets, model-size, and compute. Our largest model reaches 10B parameters and generates sharp and detailed 3D shape with precise image-3D following while keeping mesh surface clean and smooth, significantly closing the gap between generated and handcrafted 3D shapes. In terms of texture generation, it is upgraded with phyiscal-based rendering (PBR) via a novel multi-view architecture extended from Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D 2.5 significantly outperforms previous methods in both shape and end-to-end texture generation.",
    "summary": "arXiv:2506.16504v1 Announce Type: cross Abstract: In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion models aimed at generating high-fidelity and detailed textured 3D assets. Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D 2.0, while demonstrating substantial advancements in both shape and texture generation. In terms of shape generation, we introduce a new shape foundation model -- LATTICE, which is trained with scaled high-quality datasets, model-size, and compute. Our largest model reaches 10B parameters and generates sharp and detailed 3D shape with precise image-3D following while keeping mesh surface clean and smooth, significantly closing the gap between generated and handcrafted 3D shapes. In terms of texture generation, it is upgraded with phyiscal-based rendering (PBR) via a novel multi-view architecture extended from Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D 2.5 significantly outperforms previous methods in both shape and end-to-end texture generation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16504",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SegMoE: Segmind Mixture of Diffusion Experts",
    "description": "",
    "summary": "SegMoE: Segmind Mixture of Diffusion Experts SegMoE is an exciting framework for creating Mixture-of...",
    "pubDate": "Sat, 03 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/segmoe",
    "thumbnail": "https://huggingface.co/blog/assets/segmoe/thumbnail.png"
  },
  {
    "title": "Under the Shadow of Babel: How Language Shapes Reasoning in LLMs",
    "description": "arXiv:2506.16151v1 Announce Type: cross Abstract: Language is not only a tool for communication but also a medium for human cognition and reasoning. If, as linguistic relativity suggests, the structure of language shapes cognitive patterns, then large language models (LLMs) trained on human language may also internalize the habitual logical structures embedded in different languages. To examine this hypothesis, we introduce BICAUSE, a structured bilingual dataset for causal reasoning, which includes semantically aligned Chinese and English samples in both forward and reversed causal forms. Our study reveals three key findings: (1) LLMs exhibit typologically aligned attention patterns, focusing more on causes and sentence-initial connectives in Chinese, while showing a more balanced distribution in English. (2) Models internalize language-specific preferences for causal word order and often rigidly apply them to atypical inputs, leading to degraded performance, especially in Chinese. (3) When causal reasoning succeeds, model representations converge toward semantically aligned abstractions across languages, indicating a shared understanding beyond surface form. Overall, these results suggest that LLMs not only mimic surface linguistic forms but also internalize the reasoning biases shaped by language. Rooted in cognitive linguistic theory, this phenomenon is for the first time empirically verified through structural analysis of model internals.",
    "summary": "arXiv:2506.16151v1 Announce Type: cross Abstract: Language is not only a tool for communication but also a medium for human cognition and reasoning. If, as linguistic relativity suggests, the structure of language shapes cognitive patterns, then large language models (LLMs) trained on human language may also internalize the habitual logical structures embedded in different languages. To examine this hypothesis, we introduce BICAUSE, a structured bilingual dataset for causal reasoning, which includes semantically aligned Chinese and English samples in both forward and reversed causal forms. Our study reveals three key findings: (1) LLMs exhibit typologically aligned attention patterns, focusing more on causes and sentence-initial connectives in Chinese, while showing a more balanced distribution in English. (2) Models internalize language-specific preferences for causal word order and often rigidly apply them to atypical inputs, leading to degraded performance, especially in Chinese. (3) When causal reasoning succeeds, model representations converge toward semantically aligned abstractions across languages, indicating a shared understanding beyond surface form. Overall, these results suggest that LLMs not only mimic surface linguistic forms but also internalize the reasoning biases shaped by language. Rooted in cognitive linguistic theory, this phenomenon is for the first time empirically verified through structural analysis of model internals.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16151",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning to Solve Multi-Objective Routing Problems on Multigraphs",
    "description": "arXiv:2506.22095v1 Announce Type: cross Abstract: Learning-based methods for routing have gained significant attention in recent years, both in single-objective and multi-objective contexts. However, the multigraph setting, where multiple paths with distinct attributes can exist between destinations, has largely been overlooked, despite its high practical relevancy. In this paper, we introduce two neural approaches to address multi-objective routing on multigraphs. Our first approach works directly on the multigraph, by autoregressively selecting edges until a tour is completed. On the other hand, our second model first prunes the multigraph into a simple graph and then builds routes. We validate both models experimentally and find that they demonstrate strong performance across a variety of problems, including the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP).",
    "summary": "arXiv:2506.22095v1 Announce Type: cross Abstract: Learning-based methods for routing have gained significant attention in recent years, both in single-objective and multi-objective contexts. However, the multigraph setting, where multiple paths with distinct attributes can exist between destinations, has largely been overlooked, despite its high practical relevancy. In this paper, we introduce two neural approaches to address multi-objective routing on multigraphs. Our first approach works directly on the multigraph, by autoregressively selecting edges until a tour is completed. On the other hand, our second model first prunes the multigraph into a simple graph and then builds routes. We validate both models experimentally and find that they demonstrate strong performance across a variety of problems, including the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP).",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22095",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Space secrets security update",
    "description": "",
    "summary": "Space secrets leak disclosure Earlier this week our team detected unauthorized access to our Spaces ...",
    "pubDate": "Fri, 31 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/space-secrets-disclosure",
    "thumbnail": "https://huggingface.co/blog/assets/space-secrets-security-update/space-secrets-security-update.png"
  },
  {
    "title": "Universe",
    "description": "We‚Äôre releasing Universe, a software platform for measuring and training an AI‚Äôs general intelligence across the world‚Äôs supply of games, websites and other applications.",
    "summary": "We‚Äôre releasing Universe, a software platform for measuring and training an AI‚Äôs general intelligence across the world‚Äôs supply of games, websites and other applications.",
    "pubDate": "Mon, 05 Dec 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/universe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building Cost-Efficient Enterprise RAG applications with Intel Gaudi 2 and Intel Xeon",
    "description": "",
    "summary": "Building Cost-Efficient Enterprise RAG applications with Intel Gaudi 2 and Intel Xeon Retrieval-augm...",
    "pubDate": "Thu, 09 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cost-efficient-rag-applications-with-intel",
    "thumbnail": "https://huggingface.co/blog/assets/cost_efficient_rag_applications_with_intel/main.jpg"
  },
  {
    "title": "LAuReL: Learned Augmented Residual Layer",
    "description": "arXiv:2411.07501v4 Announce Type: replace-cross Abstract: One of the core pillars of efficient deep learning methods is architectural improvements such as the residual/skip connection, which has led to significantly better model convergence and quality. Since then the residual connection has become ubiquitous in not just convolutional neural networks but also transformer-based architectures, the backbone of LLMs. In this paper we introduce Learned Augmented Residual Layer (LAuReL) -- a novel generalization of the canonical residual connection -- with the goal to be an in-situ replacement of the latter while outperforming on both model quality and footprint metrics. Our experiments show that using LAuReL can help boost performance for both vision and language models. For example, on the ResNet-50, ImageNet 1K task, it achieves 60% of the gains from adding an extra layer, while only adding 0.003% more parameters, and matches it while adding 2.6 times fewer parameters. Similarly, when pre-training 1B and 4B parameter LLMs, LAuReL improves performance on a variety of challenging downstream evaluation tasks by 2.54% to 20.05%, while adding only 0.012% and 0.1% additional parameters, respectively.",
    "summary": "arXiv:2411.07501v4 Announce Type: replace-cross Abstract: One of the core pillars of efficient deep learning methods is architectural improvements such as the residual/skip connection, which has led to significantly better model convergence and quality. Since then the residual connection has become ubiquitous in not just convolutional neural networks but also transformer-based architectures, the backbone of LLMs. In this paper we introduce Learned Augmented Residual Layer (LAuReL) -- a novel generalization of the canonical residual connection -- with the goal to be an in-situ replacement of the latter while outperforming on both model quality and footprint metrics. Our experiments show that using LAuReL can help boost performance for both vision and language models. For example, on the ResNet-50, ImageNet 1K task, it achieves 60% of the gains from adding an extra layer, while only adding 0.003% more parameters, and matches it while adding 2.6 times fewer parameters. Similarly, when pre-training 1B and 4B parameter LLMs, LAuReL improves performance on a variety of challenging downstream evaluation tasks by 2.54% to 20.05%, while adding only 0.012% and 0.1% additional parameters, respectively.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.07501",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Is an object-centric representation beneficial for robotic manipulation ?",
    "description": "arXiv:2506.19408v1 Announce Type: new Abstract: Object-centric representation (OCR) has recently become a subject of interest in the computer vision community for learning a structured representation of images and videos. It has been several times presented as a potential way to improve data-efficiency and generalization capabilities to learn an agent on downstream tasks. However, most existing work only evaluates such models on scene decomposition, without any notion of reasoning over the learned representation. Robotic manipulation tasks generally involve multi-object environments with potential inter-object interaction. We thus argue that they are a very interesting playground to really evaluate the potential of existing object-centric work. To do so, we create several robotic manipulation tasks in simulated environments involving multiple objects (several distractors, the robot, etc.) and a high-level of randomization (object positions, colors, shapes, background, initial positions, etc.). We then evaluate one classical object-centric method across several generalization scenarios and compare its results against several state-of-the-art hollistic representations. Our results exhibit that existing methods are prone to failure in difficult scenarios involving complex scene structures, whereas object-centric methods help overcome these challenges.",
    "summary": "arXiv:2506.19408v1 Announce Type: new Abstract: Object-centric representation (OCR) has recently become a subject of interest in the computer vision community for learning a structured representation of images and videos. It has been several times presented as a potential way to improve data-efficiency and generalization capabilities to learn an agent on downstream tasks. However, most existing work only evaluates such models on scene decomposition, without any notion of reasoning over the learned representation. Robotic manipulation tasks generally involve multi-object environments with potential inter-object interaction. We thus argue that they are a very interesting playground to really evaluate the potential of existing object-centric work. To do so, we create several robotic manipulation tasks in simulated environments involving multiple objects (several distractors, the robot, etc.) and a high-level of randomization (object positions, colors, shapes, background, initial positions, etc.). We then evaluate one classical object-centric method across several generalization scenarios and compare its results against several state-of-the-art hollistic representations. Our results exhibit that existing methods are prone to failure in difficult scenarios involving complex scene structures, whereas object-centric methods help overcome these challenges.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19408",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A landmark multi-year global partnership with News Corp",
    "description": "Companies Join Forces to Enrich OpenAI‚Äôs Generative AI Products and Platforms with Premium Journalism",
    "summary": "Companies Join Forces to Enrich OpenAI‚Äôs Generative AI Products and Platforms with Premium Journalism",
    "pubDate": "Wed, 22 May 2024 13:15:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/news-corp-and-openai-sign-landmark-multi-year-global-partnership",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Unpacking the bias of large language models",
    "description": "In a new study, researchers discover the root cause of a type of bias in LLMs, paving the way for more accurate and reliable AI systems.",
    "summary": "In a new study, researchers discover the root cause of a type of bias in LLMs, paving the way for more accurate and reliable AI systems.",
    "pubDate": "Tue, 17 Jun 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/unpacking-large-language-model-bias-0617",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT-transform-bias-01-press.jpg"
  },
  {
    "title": "DeepMind‚Äôs latest research at ICLR 2023",
    "description": "Next week marks the start of the 11th International Conference on Learning Representations (ICLR), taking place 1-5 May in Kigali, Rwanda. This will be the first major artificial intelligence (AI) conference to be hosted in Africa and the first in-person event since the start of the pandemic. Researchers from around the world will gather to share their cutting-edge work in deep learning spanning the fields of AI, statistics and data science, and applications including machine vision, gaming and robotics. We‚Äôre proud to support the conference as a Diamond sponsor and DEI champion.",
    "summary": "Next week marks the start of the 11th International Conference on Learning Representations (ICLR), taking place 1-5 May in Kigali, Rwanda. This will be the first major artificial intelligence (AI) conference to be hosted in Africa and the first in-person event since the start of the pandemic. Researchers from around the world will gather to share their cutting-edge work in deep learning spanning the fields of AI, statistics and data science, and applications including machine vision, gaming and robotics. We‚Äôre proud to support the conference as a Diamond sponsor and DEI champion.",
    "pubDate": "Thu, 27 Apr 2023 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/deepminds-latest-research-at-iclr-2023/",
    "thumbnail": "https://lh3.googleusercontent.com/PH30vPBZLwZXlSFrALk6AT507Qn70LSPLW5a89vsRhDdkje_xaPGvNE2UrhOBy8Gkaasn-FVRuDWlPhEPntzw02gxSAEPygt7djS4URtQZJuaLPw3w=w1200-h630-n-nu"
  },
  {
    "title": "AlphaGeometry: An Olympiad-level AI system for geometry",
    "description": "Advancing AI reasoning in mathematics",
    "summary": "Advancing AI reasoning in mathematics",
    "pubDate": "Wed, 17 Jan 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/",
    "thumbnail": "https://lh3.googleusercontent.com/tVTh_ZCW5Qozy4vOCpMH06B7Ac_eF7fmEULMMTwDellOh6hnOMUtf28toD68N527IHQTlBWfBCHcZykYPMdrS48yvuEcJKMJG8rU3YRM3u5Ojn3JXnc=w1200-h630-n-nu"
  },
  {
    "title": "A Survey of Automatic Hallucination Evaluation on Natural Language Generation",
    "description": "arXiv:2404.12041v3 Announce Type: replace-cross Abstract: The proliferation of Large Language Models (LLMs) has introduced a critical challenge: accurate hallucination evaluation that ensures model reliability. While Automatic Hallucination Evaluation (AHE) has emerged as essential, the field suffers from methodological fragmentation, hindering both theoretical understanding and practical advancement. This survey addresses this critical gap through a comprehensive analysis of 74 evaluation methods, revealing that 74% specifically target LLMs, a paradigm shift that demands new evaluation frameworks. We formulate a unified evaluation pipeline encompassing datasets and benchmarks, evidence collection strategies, and comparison mechanisms, systematically documenting the evolution from pre-LLM to post-LLM methodologies. Beyond taxonomical organization, we identify fundamental limitations in current approaches and their implications for real-world deployment. To guide future research, we delineate key challenges and propose strategic directions, including enhanced interpretability mechanisms and integration of application-specific evaluation criteria, ultimately providing a roadmap for developing more robust and practical hallucination evaluation systems.",
    "summary": "arXiv:2404.12041v3 Announce Type: replace-cross Abstract: The proliferation of Large Language Models (LLMs) has introduced a critical challenge: accurate hallucination evaluation that ensures model reliability. While Automatic Hallucination Evaluation (AHE) has emerged as essential, the field suffers from methodological fragmentation, hindering both theoretical understanding and practical advancement. This survey addresses this critical gap through a comprehensive analysis of 74 evaluation methods, revealing that 74% specifically target LLMs, a paradigm shift that demands new evaluation frameworks. We formulate a unified evaluation pipeline encompassing datasets and benchmarks, evidence collection strategies, and comparison mechanisms, systematically documenting the evolution from pre-LLM to post-LLM methodologies. Beyond taxonomical organization, we identify fundamental limitations in current approaches and their implications for real-world deployment. To guide future research, we delineate key challenges and propose strategic directions, including enhanced interpretability mechanisms and integration of application-specific evaluation criteria, ultimately providing a roadmap for developing more robust and practical hallucination evaluation systems.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2404.12041",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Damba-ST: Domain-Adaptive Mamba for Efficient Urban Spatio-Temporal Prediction",
    "description": "arXiv:2506.18939v1 Announce Type: cross Abstract: Training urban spatio-temporal foundation models that generalize well across diverse regions and cities is critical for deploying urban services in unseen or data-scarce regions. Recent studies have typically focused on fusing cross-domain spatio-temporal data to train unified Transformer-based models. However, these models suffer from quadratic computational complexity and high memory overhead, limiting their scalability and practical deployment. Inspired by the efficiency of Mamba, a state space model with linear time complexity, we explore its potential for efficient urban spatio-temporal prediction. However, directly applying Mamba as a spatio-temporal backbone leads to negative transfer and severe performance degradation. This is primarily due to spatio-temporal heterogeneity and the recursive mechanism of Mamba's hidden state updates, which limit cross-domain generalization. To overcome these challenges, we propose Damba-ST, a novel domain-adaptive Mamba-based model for efficient urban spatio-temporal prediction. Damba-ST retains Mamba's linear complexity advantage while significantly enhancing its adaptability to heterogeneous domains. Specifically, we introduce two core innovations: (1) a domain-adaptive state space model that partitions the latent representation space into a shared subspace for learning cross-domain commonalities and independent, domain-specific subspaces for capturing intra-domain discriminative features; (2) three distinct Domain Adapters, which serve as domain-aware proxies to bridge disparate domain distributions and facilitate the alignment of cross-domain commonalities. Extensive experiments demonstrate the generalization and efficiency of Damba-ST. It achieves state-of-the-art performance on prediction tasks and demonstrates strong zero-shot generalization, enabling seamless deployment in new urban environments without extensive retraining or fine-tuning.",
    "summary": "arXiv:2506.18939v1 Announce Type: cross Abstract: Training urban spatio-temporal foundation models that generalize well across diverse regions and cities is critical for deploying urban services in unseen or data-scarce regions. Recent studies have typically focused on fusing cross-domain spatio-temporal data to train unified Transformer-based models. However, these models suffer from quadratic computational complexity and high memory overhead, limiting their scalability and practical deployment. Inspired by the efficiency of Mamba, a state space model with linear time complexity, we explore its potential for efficient urban spatio-temporal prediction. However, directly applying Mamba as a spatio-temporal backbone leads to negative transfer and severe performance degradation. This is primarily due to spatio-temporal heterogeneity and the recursive mechanism of Mamba's hidden state updates, which limit cross-domain generalization. To overcome these challenges, we propose Damba-ST, a novel domain-adaptive Mamba-based model for efficient urban spatio-temporal prediction. Damba-ST retains Mamba's linear complexity advantage while significantly enhancing its adaptability to heterogeneous domains. Specifically, we introduce two core innovations: (1) a domain-adaptive state space model that partitions the latent representation space into a shared subspace for learning cross-domain commonalities and independent, domain-specific subspaces for capturing intra-domain discriminative features; (2) three distinct Domain Adapters, which serve as domain-aware proxies to bridge disparate domain distributions and facilitate the alignment of cross-domain commonalities. Extensive experiments demonstrate the generalization and efficiency of Damba-ST. It achieves state-of-the-art performance on prediction tasks and demonstrates strong zero-shot generalization, enabling seamless deployment in new urban environments without extensive retraining or fine-tuning.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18939",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Arize Phoenix „ÅßÂÆüÁèæ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Éà„É¨„Éº„Çπ",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI „ÉÅ„Éº„É†„ÅÆÈï∑Êæ§(@sp_1999N)„Åß„Åô„ÄÇ ‰ªäÂõû„ÅØ Arize AI Á§æ„ÅåÈñãÁô∫„ÉªÊèê‰æõ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥Âêë„Åë„ÅÆÁõ£Ë¶ñ„ÉÑ„Éº„É´ Phoenix „ÅÆÁ¥π‰ªã„Åä„Çà„Å≥Á∞°Âçò„Å™„Éá„É¢ÊßãÁØâ„ÇíË°å„ÅÑ„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ „Éá„É¢„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5608' rel='nofollow'>Arize Phoenix „ÅßÂÆüÁèæ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Éà„É¨„Éº„Çπ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI „ÉÅ„Éº„É†„ÅÆÈï∑Êæ§(@sp_1999N)„Åß„Åô„ÄÇ ‰ªäÂõû„ÅØ Arize AI Á§æ„ÅåÈñãÁô∫„ÉªÊèê‰æõ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥Âêë„Åë„ÅÆÁõ£Ë¶ñ„ÉÑ„Éº„É´ Phoenix „ÅÆÁ¥π‰ªã„Åä„Çà„Å≥Á∞°Âçò„Å™„Éá„É¢ÊßãÁØâ„ÇíË°å„ÅÑ„Åü„ÅÑ„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇ „Éá„É¢„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5608' rel='nofollow'>Arize Phoenix „ÅßÂÆüÁèæ„Åô„Çã LLM „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅÆ„Éà„É¨„Éº„Çπ</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Tue, 25 Mar 2025 10:22:46 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5608",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/image-4.png"
  },
  {
    "title": "Ethics and Society Newsletter #5: Hugging Face Goes To Washington and Other Summer 2023 Musings",
    "description": "",
    "summary": "Ethics and Society Newsletter #5: Hugging Face Goes To Washington and Other Summer 2023 Musings One ...",
    "pubDate": "Fri, 29 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-5",
    "thumbnail": "https://huggingface.co/blog/assets/164_ethics-soc-5/thumbnail.png"
  },
  {
    "title": "The New and Fresh analytics in Inference Endpoints",
    "description": "",
    "summary": "Analytics is important Analytics and metrics are the cornerstone of understanding what's happening w...",
    "pubDate": "Fri, 21 Mar 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/endpoint-analytics",
    "thumbnail": "https://huggingface.co/blog/assets/endpoint-analytics/thumbnail.png"
  },
  {
    "title": "Advantage Actor Critic (A2C)",
    "description": "",
    "summary": "Advantage Actor Critic (A2C) Deep Reinforcement Learning Class with Hugging Face ü§ó Unit 7, of the‚ö†Ô∏è ...",
    "pubDate": "Fri, 22 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/deep-rl-a2c",
    "thumbnail": "https://huggingface.co/blog/assets/89_deep_rl_a2c/thumbnail.gif"
  },
  {
    "title": "A Survey of Continual Reinforcement Learning",
    "description": "arXiv:2506.21872v1 Announce Type: cross Abstract: Reinforcement Learning (RL) is an important machine learning paradigm for solving sequential decision-making problems. Recent years have witnessed remarkable progress in this field due to the rapid development of deep neural networks. However, the success of RL currently relies on extensive training data and computational resources. In addition, RL's limited ability to generalize across tasks restricts its applicability in dynamic and real-world environments. With the arisen of Continual Learning (CL), Continual Reinforcement Learning (CRL) has emerged as a promising research direction to address these limitations by enabling agents to learn continuously, adapt to new tasks, and retain previously acquired knowledge. In this survey, we provide a comprehensive examination of CRL, focusing on its core concepts, challenges, and methodologies. Firstly, we conduct a detailed review of existing works, organizing and analyzing their metrics, tasks, benchmarks, and scenario settings. Secondly, we propose a new taxonomy of CRL methods, categorizing them into four types from the perspective of knowledge storage and/or transfer. Finally, our analysis highlights the unique challenges of CRL and provides practical insights into future directions.",
    "summary": "arXiv:2506.21872v1 Announce Type: cross Abstract: Reinforcement Learning (RL) is an important machine learning paradigm for solving sequential decision-making problems. Recent years have witnessed remarkable progress in this field due to the rapid development of deep neural networks. However, the success of RL currently relies on extensive training data and computational resources. In addition, RL's limited ability to generalize across tasks restricts its applicability in dynamic and real-world environments. With the arisen of Continual Learning (CL), Continual Reinforcement Learning (CRL) has emerged as a promising research direction to address these limitations by enabling agents to learn continuously, adapt to new tasks, and retain previously acquired knowledge. In this survey, we provide a comprehensive examination of CRL, focusing on its core concepts, challenges, and methodologies. Firstly, we conduct a detailed review of existing works, organizing and analyzing their metrics, tasks, benchmarks, and scenario settings. Secondly, we propose a new taxonomy of CRL methods, categorizing them into four types from the perspective of knowledge storage and/or transfer. Finally, our analysis highlights the unique challenges of CRL and provides practical insights into future directions.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21872",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SciMantify -- A Hybrid Approach for the Evolving Semantification of Scientific Knowledge",
    "description": "arXiv:2506.21819v1 Announce Type: cross Abstract: Scientific publications, primarily digitized as PDFs, remain static and unstructured, limiting the accessibility and reusability of the contained knowledge. At best, scientific knowledge from publications is provided in tabular formats, which lack semantic context. A more flexible, structured, and semantic representation is needed to make scientific knowledge understandable and processable by both humans and machines. We propose an evolution model of knowledge representation, inspired by the 5-star Linked Open Data (LOD) model, with five stages and defined criteria to guide the stepwise transition from a digital artifact, such as a PDF, to a semantic representation integrated in a knowledge graph (KG). Based on an exemplary workflow implementing the entire model, we developed a hybrid approach, called SciMantify, leveraging tabular formats of scientific knowledge, e.g., results from secondary studies, to support its evolving semantification. In the approach, humans and machines collaborate closely by performing semantic annotation tasks (SATs) and refining the results to progressively improve the semantic representation of scientific knowledge. We implemented the approach in the Open Research Knowledge Graph (ORKG), an established platform for improving the findability, accessibility, interoperability, and reusability of scientific knowledge. A preliminary user experiment showed that the approach simplifies the preprocessing of scientific knowledge, reduces the effort for the evolving semantification, and enhances the knowledge representation through better alignment with the KG structures.",
    "summary": "arXiv:2506.21819v1 Announce Type: cross Abstract: Scientific publications, primarily digitized as PDFs, remain static and unstructured, limiting the accessibility and reusability of the contained knowledge. At best, scientific knowledge from publications is provided in tabular formats, which lack semantic context. A more flexible, structured, and semantic representation is needed to make scientific knowledge understandable and processable by both humans and machines. We propose an evolution model of knowledge representation, inspired by the 5-star Linked Open Data (LOD) model, with five stages and defined criteria to guide the stepwise transition from a digital artifact, such as a PDF, to a semantic representation integrated in a knowledge graph (KG). Based on an exemplary workflow implementing the entire model, we developed a hybrid approach, called SciMantify, leveraging tabular formats of scientific knowledge, e.g., results from secondary studies, to support its evolving semantification. In the approach, humans and machines collaborate closely by performing semantic annotation tasks (SATs) and refining the results to progressively improve the semantic representation of scientific knowledge. We implemented the approach in the Open Research Knowledge Graph (ORKG), an established platform for improving the findability, accessibility, interoperability, and reusability of scientific knowledge. A preliminary user experiment showed that the approach simplifies the preprocessing of scientific knowledge, reduces the effort for the evolving semantification, and enhances the knowledge representation through better alignment with the KG structures.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21819",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Text2SQL using Hugging Face Dataset Viewer API and Motherduck DuckDB-NSQL-7B",
    "description": "",
    "summary": "Text2SQL using Hugging Face Dataset Viewer API and Motherduck DuckDB-NSQL-7B Today, integrating AI-p...",
    "pubDate": "Thu, 04 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/duckdb-nsql-7b",
    "thumbnail": "https://huggingface.co/blog/assets/duckdb-nsql-7b/thumbnail.png"
  },
  {
    "title": "AirV2X: Unified Air-Ground Vehicle-to-Everything Collaboration",
    "description": "arXiv:2506.19283v1 Announce Type: cross Abstract: While multi-vehicular collaborative driving demonstrates clear advantages over single-vehicle autonomy, traditional infrastructure-based V2X systems remain constrained by substantial deployment costs and the creation of 'uncovered danger zones' in rural and suburban areas. We present AirV2X-Perception, a large-scale dataset that leverages Unmanned Aerial Vehicles (UAVs) as a flexible alternative or complement to fixed Road-Side Units (RSUs). Drones offer unique advantages over ground-based perception: complementary bird's-eye-views that reduce occlusions, dynamic positioning capabilities that enable hovering, patrolling, and escorting navigation rules, and significantly lower deployment costs compared to fixed infrastructure. Our dataset comprises 6.73 hours of drone-assisted driving scenarios across urban, suburban, and rural environments with varied weather and lighting conditions. The AirV2X-Perception dataset facilitates the development and standardized evaluation of Vehicle-to-Drone (V2D) algorithms, addressing a critical gap in the rapidly expanding field of aerial-assisted autonomous driving systems. The dataset and development kits are open-sourced at https://github.com/taco-group/AirV2X-Perception.",
    "summary": "arXiv:2506.19283v1 Announce Type: cross Abstract: While multi-vehicular collaborative driving demonstrates clear advantages over single-vehicle autonomy, traditional infrastructure-based V2X systems remain constrained by substantial deployment costs and the creation of 'uncovered danger zones' in rural and suburban areas. We present AirV2X-Perception, a large-scale dataset that leverages Unmanned Aerial Vehicles (UAVs) as a flexible alternative or complement to fixed Road-Side Units (RSUs). Drones offer unique advantages over ground-based perception: complementary bird's-eye-views that reduce occlusions, dynamic positioning capabilities that enable hovering, patrolling, and escorting navigation rules, and significantly lower deployment costs compared to fixed infrastructure. Our dataset comprises 6.73 hours of drone-assisted driving scenarios across urban, suburban, and rural environments with varied weather and lighting conditions. The AirV2X-Perception dataset facilitates the development and standardized evaluation of Vehicle-to-Drone (V2D) algorithms, addressing a critical gap in the rapidly expanding field of aerial-assisted autonomous driving systems. The dataset and development kits are open-sourced at https://github.com/taco-group/AirV2X-Perception.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19283",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face Text Generation Inference available for AWS Inferentia2",
    "description": "",
    "summary": "Hugging Face Text Generation Inference available for AWS Inferentia2 We are excited to announce the ...",
    "pubDate": "Thu, 01 Feb 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-generation-inference-on-inferentia2",
    "thumbnail": "https://huggingface.co/blog/assets/175_text_generation_inference_on_inferentia2/thumbnail.jpg"
  },
  {
    "title": "Compiler-R1: Towards Agentic Compiler Auto-tuning with Reinforcement Learning",
    "description": "arXiv:2506.15701v1 Announce Type: cross Abstract: Compiler auto-tuning optimizes pass sequences to improve performance metrics such as Intermediate Representation (IR) instruction count. Although recent advances leveraging Large Language Models (LLMs) have shown promise in automating compiler tuning, two significant challenges still remain: the absence of high-quality reasoning datasets for agents training, and limited effective interactions with the compilation environment. In this work, we introduce Compiler-R1, the first reinforcement learning (RL)-driven framework specifically augmenting LLM capabilities for compiler auto-tuning. Compiler-R1 features a curated, high-quality reasoning dataset and a novel two-stage end-to-end RL training pipeline, enabling efficient environment exploration and learning through an outcome-based reward. Extensive experiments across seven datasets demonstrate Compiler-R1 achieving an average 8.46% IR instruction count reduction compared to opt -Oz, showcasing the strong potential of RL-trained LLMs for compiler optimization. Our code and datasets are publicly available at https://github.com/Panhaolin2001/Compiler-R1.",
    "summary": "arXiv:2506.15701v1 Announce Type: cross Abstract: Compiler auto-tuning optimizes pass sequences to improve performance metrics such as Intermediate Representation (IR) instruction count. Although recent advances leveraging Large Language Models (LLMs) have shown promise in automating compiler tuning, two significant challenges still remain: the absence of high-quality reasoning datasets for agents training, and limited effective interactions with the compilation environment. In this work, we introduce Compiler-R1, the first reinforcement learning (RL)-driven framework specifically augmenting LLM capabilities for compiler auto-tuning. Compiler-R1 features a curated, high-quality reasoning dataset and a novel two-stage end-to-end RL training pipeline, enabling efficient environment exploration and learning through an outcome-based reward. Extensive experiments across seven datasets demonstrate Compiler-R1 achieving an average 8.46% IR instruction count reduction compared to opt -Oz, showcasing the strong potential of RL-trained LLMs for compiler optimization. Our code and datasets are publicly available at https://github.com/Panhaolin2001/Compiler-R1.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15701",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome Llama 3 - Meta's new open LLM",
    "description": "",
    "summary": "Welcome Llama 3 - Meta‚Äôs new open LLM Introduction Meta‚Äôs Llama 3, the next iteration of the open-ac...",
    "pubDate": "Thu, 18 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama3",
    "thumbnail": "https://huggingface.co/blog/assets/llama3/thumbnail.jpg"
  },
  {
    "title": "OpenAI Five Benchmark",
    "description": "The OpenAI Five Benchmark match is now over!",
    "summary": "The OpenAI Five Benchmark match is now over!",
    "pubDate": "Wed, 18 Jul 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-five-benchmark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion Model",
    "description": "arXiv:2408.16767v3 Announce Type: replace-cross Abstract: Advancements in 3D scene reconstruction have transformed 2D images from the real world into 3D models, producing realistic 3D results from hundreds of input photos. Despite great success in dense-view reconstruction scenarios, rendering a detailed scene from insufficient captured views is still an ill-posed optimization problem, often resulting in artifacts and distortions in unseen areas. In this paper, we propose ReconX, a novel 3D scene reconstruction paradigm that reframes the ambiguous reconstruction challenge as a temporal generation task. The key insight is to unleash the strong generative prior of large pre-trained video diffusion models for sparse-view reconstruction. However, 3D view consistency struggles to be accurately preserved in directly generated video frames from pre-trained models. To address this, given limited input views, the proposed ReconX first constructs a global point cloud and encodes it into a contextual space as the 3D structure condition. Guided by the condition, the video diffusion model then synthesizes video frames that are both detail-preserved and exhibit a high degree of 3D consistency, ensuring the coherence of the scene from various perspectives. Finally, we recover the 3D scene from the generated video through a confidence-aware 3D Gaussian Splatting optimization scheme. Extensive experiments on various real-world datasets show the superiority of our ReconX over state-of-the-art methods in terms of quality and generalizability.",
    "summary": "arXiv:2408.16767v3 Announce Type: replace-cross Abstract: Advancements in 3D scene reconstruction have transformed 2D images from the real world into 3D models, producing realistic 3D results from hundreds of input photos. Despite great success in dense-view reconstruction scenarios, rendering a detailed scene from insufficient captured views is still an ill-posed optimization problem, often resulting in artifacts and distortions in unseen areas. In this paper, we propose ReconX, a novel 3D scene reconstruction paradigm that reframes the ambiguous reconstruction challenge as a temporal generation task. The key insight is to unleash the strong generative prior of large pre-trained video diffusion models for sparse-view reconstruction. However, 3D view consistency struggles to be accurately preserved in directly generated video frames from pre-trained models. To address this, given limited input views, the proposed ReconX first constructs a global point cloud and encodes it into a contextual space as the 3D structure condition. Guided by the condition, the video diffusion model then synthesizes video frames that are both detail-preserved and exhibit a high degree of 3D consistency, ensuring the coherence of the scene from various perspectives. Finally, we recover the 3D scene from the generated video through a confidence-aware 3D Gaussian Splatting optimization scheme. Extensive experiments on various real-world datasets show the superiority of our ReconX over state-of-the-art methods in terms of quality and generalizability.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2408.16767",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Tiny Agents: a MCP-powered agent in 50 lines of code",
    "description": "",
    "summary": "Tiny Agents: an MCP-powered agent in 50 lines of code New! (May 23, '25) If you prefer Python, check...",
    "pubDate": "Fri, 25 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tiny-agents",
    "thumbnail": "https://huggingface.co/blog/assets/tiny-agents/thumbnail.jpg"
  },
  {
    "title": "Efficient but Vulnerable: Benchmarking and Defending LLM Batch Prompting Attack",
    "description": "arXiv:2503.15551v2 Announce Type: replace-cross Abstract: Batch prompting, which combines a batch of multiple queries sharing the same context in one inference, has emerged as a promising solution to reduce inference costs. However, our study reveals a significant security vulnerability in batch prompting: malicious users can inject attack instructions into a batch, leading to unwanted interference across all queries, which can result in the inclusion of harmful content, such as phishing links, or the disruption of logical reasoning. In this paper, we construct BATCHSAFEBENCH, a comprehensive benchmark comprising 150 attack instructions of two types and 8k batch instances, to study the batch prompting vulnerability systematically. Our evaluation of both closed-source and open-weight LLMs demonstrates that all LLMs are susceptible to batch-prompting attacks. We then explore multiple defending approaches. While the prompting-based defense shows limited effectiveness for smaller LLMs, the probing-based approach achieves about 95% accuracy in detecting attacks. Additionally, we perform a mechanistic analysis to understand the attack and identify attention heads that are responsible for it.",
    "summary": "arXiv:2503.15551v2 Announce Type: replace-cross Abstract: Batch prompting, which combines a batch of multiple queries sharing the same context in one inference, has emerged as a promising solution to reduce inference costs. However, our study reveals a significant security vulnerability in batch prompting: malicious users can inject attack instructions into a batch, leading to unwanted interference across all queries, which can result in the inclusion of harmful content, such as phishing links, or the disruption of logical reasoning. In this paper, we construct BATCHSAFEBENCH, a comprehensive benchmark comprising 150 attack instructions of two types and 8k batch instances, to study the batch prompting vulnerability systematically. Our evaluation of both closed-source and open-weight LLMs demonstrates that all LLMs are susceptible to batch-prompting attacks. We then explore multiple defending approaches. While the prompting-based defense shows limited effectiveness for smaller LLMs, the probing-based approach achieves about 95% accuracy in detecting attacks. Additionally, we perform a mechanistic analysis to understand the attack and identify attention heads that are responsible for it.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.15551",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SwarmThinkers: Learning Physically Consistent Atomic KMC Transitions at Scale",
    "description": "arXiv:2505.20094v2 Announce Type: replace Abstract: Can a scientific simulation system be physically consistent, interpretable by design, and scalable across regimes--all at once? Despite decades of progress, this trifecta remains elusive. Classical methods like Kinetic Monte Carlo ensure thermodynamic accuracy but scale poorly; learning-based methods offer efficiency but often sacrifice physical consistency and interpretability. We present SwarmThinkers, a reinforcement learning framework that recasts atomic-scale simulation as a physically grounded swarm intelligence system. Each diffusing particle is modeled as a local decision-making agent that selects transitions via a shared policy network trained under thermodynamic constraints. A reweighting mechanism fuses learned preferences with transition rates, preserving statistical fidelity while enabling interpretable, step-wise decision making. Training follows a centralized-training, decentralized-execution paradigm, allowing the policy to generalize across system sizes, concentrations, and temperatures without retraining. On a benchmark simulating radiation-induced Fe-Cu alloy precipitation, SwarmThinkers is the first system to achieve full-scale, physically consistent simulation on a single A100 GPU, previously attainable only via OpenKMC on a supercomputer. It delivers up to 4963x (3185x on average) faster computation with 485x lower memory usage. By treating particles as decision-makers, not passive samplers, SwarmThinkers marks a paradigm shift in scientific simulation--one that unifies physical consistency, interpretability, and scalability through agent-driven intelligence.",
    "summary": "arXiv:2505.20094v2 Announce Type: replace Abstract: Can a scientific simulation system be physically consistent, interpretable by design, and scalable across regimes--all at once? Despite decades of progress, this trifecta remains elusive. Classical methods like Kinetic Monte Carlo ensure thermodynamic accuracy but scale poorly; learning-based methods offer efficiency but often sacrifice physical consistency and interpretability. We present SwarmThinkers, a reinforcement learning framework that recasts atomic-scale simulation as a physically grounded swarm intelligence system. Each diffusing particle is modeled as a local decision-making agent that selects transitions via a shared policy network trained under thermodynamic constraints. A reweighting mechanism fuses learned preferences with transition rates, preserving statistical fidelity while enabling interpretable, step-wise decision making. Training follows a centralized-training, decentralized-execution paradigm, allowing the policy to generalize across system sizes, concentrations, and temperatures without retraining. On a benchmark simulating radiation-induced Fe-Cu alloy precipitation, SwarmThinkers is the first system to achieve full-scale, physically consistent simulation on a single A100 GPU, previously attainable only via OpenKMC on a supercomputer. It delivers up to 4963x (3185x on average) faster computation with 485x lower memory usage. By treating particles as decision-makers, not passive samplers, SwarmThinkers marks a paradigm shift in scientific simulation--one that unifies physical consistency, interpretability, and scalability through agent-driven intelligence.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.20094",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "EUR/USD Exchange Rate Forecasting incorporating Text Mining Based on Pre-trained Language Models and Deep Learning Methods",
    "description": "arXiv:2411.07560v2 Announce Type: replace-cross Abstract: This study introduces a novel approach for EUR/USD exchange rate forecasting that integrates deep learning, textual analysis, and particle swarm optimization (PSO). By incorporating online news and analysis texts as qualitative data, the proposed PSO-LSTM model demonstrates superior performance compared to traditional econometric and machine learning models. The research employs advanced text mining techniques, including sentiment analysis using the RoBERTa-Large model and topic modeling with LDA. Empirical findings underscore the significant advantage of incorporating textual data, with the PSO-LSTM model outperforming benchmark models such as SVM, SVR, ARIMA, and GARCH. Ablation experiments reveal the contribution of each textual data category to the overall forecasting performance. The study highlights the transformative potential of artificial intelligence in finance and paves the way for future research in real-time forecasting and the integration of alternative data sources.",
    "summary": "arXiv:2411.07560v2 Announce Type: replace-cross Abstract: This study introduces a novel approach for EUR/USD exchange rate forecasting that integrates deep learning, textual analysis, and particle swarm optimization (PSO). By incorporating online news and analysis texts as qualitative data, the proposed PSO-LSTM model demonstrates superior performance compared to traditional econometric and machine learning models. The research employs advanced text mining techniques, including sentiment analysis using the RoBERTa-Large model and topic modeling with LDA. Empirical findings underscore the significant advantage of incorporating textual data, with the PSO-LSTM model outperforming benchmark models such as SVM, SVR, ARIMA, and GARCH. Ablation experiments reveal the contribution of each textual data category to the overall forecasting performance. The study highlights the transformative potential of artificial intelligence in finance and paves the way for future research in real-time forecasting and the integration of alternative data sources.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2411.07560",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "IndexTTS2: A Breakthrough in Emotionally Expressive and Duration-Controlled Auto-Regressive Zero-Shot Text-to-Speech",
    "description": "arXiv:2506.21619v1 Announce Type: cross Abstract: Large-scale text-to-speech (TTS) models are typically categorized into autoregressive and non-autoregressive systems. Although autoregressive systems exhibit certain advantages in speech naturalness, their token-by-token generation mechanism makes it difficult to precisely control the duration of synthesized speech. This is a key limitation in applications such as video dubbing that require strict audio-visual synchronization. This paper introduces IndexTTS2, which proposes a novel and autoregressive-model-friendly method for speech duration control. The method supports two generation modes: one allows explicit specification of the number of generated tokens for precise duration control; the other does not require manual input and lets the model freely generate speech while preserving prosodic characteristics from the input prompt. Furthermore, IndexTTS2 achieves disentanglement between emotional expression and speaker identity, enabling independent control of timbre and emotion. In the zero-shot setting, the model can perfectly reproduce the emotional characteristics of the input prompt. Users may also provide a separate emotion prompt, even from a different speaker, allowing the model to reconstruct the target timbre while conveying the desired emotion. To enhance clarity during strong emotional expressions, we incorporate GPT latent representations to improve speech stability. Meanwhile, to lower the barrier for emotion control, we design a soft instruction mechanism based on textual descriptions by fine-tuning Qwen3. This enables effective guidance of speech generation with desired emotional tendencies using natural language input. Experimental results demonstrate that IndexTTS2 outperforms existing state-of-the-art zero-shot TTS models in word error rate, speaker similarity, and emotional fidelity.",
    "summary": "arXiv:2506.21619v1 Announce Type: cross Abstract: Large-scale text-to-speech (TTS) models are typically categorized into autoregressive and non-autoregressive systems. Although autoregressive systems exhibit certain advantages in speech naturalness, their token-by-token generation mechanism makes it difficult to precisely control the duration of synthesized speech. This is a key limitation in applications such as video dubbing that require strict audio-visual synchronization. This paper introduces IndexTTS2, which proposes a novel and autoregressive-model-friendly method for speech duration control. The method supports two generation modes: one allows explicit specification of the number of generated tokens for precise duration control; the other does not require manual input and lets the model freely generate speech while preserving prosodic characteristics from the input prompt. Furthermore, IndexTTS2 achieves disentanglement between emotional expression and speaker identity, enabling independent control of timbre and emotion. In the zero-shot setting, the model can perfectly reproduce the emotional characteristics of the input prompt. Users may also provide a separate emotion prompt, even from a different speaker, allowing the model to reconstruct the target timbre while conveying the desired emotion. To enhance clarity during strong emotional expressions, we incorporate GPT latent representations to improve speech stability. Meanwhile, to lower the barrier for emotion control, we design a soft instruction mechanism based on textual descriptions by fine-tuning Qwen3. This enables effective guidance of speech generation with desired emotional tendencies using natural language input. Experimental results demonstrate that IndexTTS2 outperforms existing state-of-the-art zero-shot TTS models in word error rate, speaker similarity, and emotional fidelity.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21619",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Canva enables creativity with AI",
    "description": "A conversation with Cameron Adams, Chief Product Officer and Co-founder of Canva.",
    "summary": "A conversation with Cameron Adams, Chief Product Officer and Co-founder of Canva.",
    "pubDate": "Mon, 07 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/canva-cam-adams",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays",
    "description": "<p>The world‚Äôs first multimodal, bilingual radiology dataset could reshape the way radiologists and AI systems make sense of X-rays. PadChest-GR, developed by the University of Alicante with Microsoft Research, has the potential to advance research across the field for years to come.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/'>PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>The world‚Äôs first multimodal, bilingual radiology dataset could reshape the way radiologists and AI systems make sense of X-rays. PadChest-GR, developed by the University of Alicante with Microsoft Research, has the potential to advance research across the field for years to come.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/'>PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 26 Jun 2025 16:08:25 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/ai-icon.png"
  },
  {
    "title": "Uber enables outstanding on-demand experiences with AI",
    "description": "A conversation with Jai Malkani, Head of AI and Product, Customer Obsession at Uber.",
    "summary": "A conversation with Jai Malkani, Head of AI and Product, Customer Obsession at Uber.",
    "pubDate": "Thu, 20 Feb 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/uber-enables-outstanding-experiences",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Metapath-based Hyperbolic Contrastive Learning for Heterogeneous Graph Embedding",
    "description": "arXiv:2506.16754v1 Announce Type: cross Abstract: The hyperbolic space, characterized by a constant negative curvature and exponentially expanding space, aligns well with the structural properties of heterogeneous graphs. However, although heterogeneous graphs inherently possess diverse power-law structures, most hyperbolic heterogeneous graph embedding models rely on a single hyperbolic space. This approach may fail to effectively capture the diverse power-law structures within heterogeneous graphs. To address this limitation, we propose a Metapath-based Hyperbolic Contrastive Learning framework (MHCL), which uses multiple hyperbolic spaces to capture diverse complex structures within heterogeneous graphs. Specifically, by learning each hyperbolic space to describe the distribution of complex structures corresponding to each metapath, it is possible to capture semantic information effectively. Since metapath embeddings represent distinct semantic information, preserving their discriminability is important when aggregating them to obtain node representations. Therefore, we use a contrastive learning approach to optimize MHCL and improve the discriminability of metapath embeddings. In particular, our contrastive learning method minimizes the distance between embeddings of the same metapath and maximizes the distance between those of different metapaths in hyperbolic space, thereby improving the separability of metapath embeddings with distinct semantic information. We conduct comprehensive experiments to evaluate the effectiveness of MHCL. The experimental results demonstrate that MHCL outperforms state-of-the-art baselines in various graph machine learning tasks, effectively capturing the complex structures of heterogeneous graphs.",
    "summary": "arXiv:2506.16754v1 Announce Type: cross Abstract: The hyperbolic space, characterized by a constant negative curvature and exponentially expanding space, aligns well with the structural properties of heterogeneous graphs. However, although heterogeneous graphs inherently possess diverse power-law structures, most hyperbolic heterogeneous graph embedding models rely on a single hyperbolic space. This approach may fail to effectively capture the diverse power-law structures within heterogeneous graphs. To address this limitation, we propose a Metapath-based Hyperbolic Contrastive Learning framework (MHCL), which uses multiple hyperbolic spaces to capture diverse complex structures within heterogeneous graphs. Specifically, by learning each hyperbolic space to describe the distribution of complex structures corresponding to each metapath, it is possible to capture semantic information effectively. Since metapath embeddings represent distinct semantic information, preserving their discriminability is important when aggregating them to obtain node representations. Therefore, we use a contrastive learning approach to optimize MHCL and improve the discriminability of metapath embeddings. In particular, our contrastive learning method minimizes the distance between embeddings of the same metapath and maximizes the distance between those of different metapaths in hyperbolic space, thereby improving the separability of metapath embeddings with distinct semantic information. We conduct comprehensive experiments to evaluate the effectiveness of MHCL. The experimental results demonstrate that MHCL outperforms state-of-the-art baselines in various graph machine learning tasks, effectively capturing the complex structures of heterogeneous graphs.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16754",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Our updated Preparedness Framework",
    "description": "Sharing our updated framework for measuring and protecting against severe harm from frontier AI capabilities.",
    "summary": "Sharing our updated framework for measuring and protecting against severe harm from frontier AI capabilities.",
    "pubDate": "Tue, 15 Apr 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/updating-our-preparedness-framework",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Panel on Hugging Face",
    "description": "",
    "summary": "Panel on Hugging Face We are thrilled to announce the collaboration between Panel and Hugging Face! ...",
    "pubDate": "Thu, 22 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/panel-on-hugging-face",
    "thumbnail": "https://huggingface.co/blog/assets/panel-on-hugging-face/thumbnail.png"
  },
  {
    "title": "OpenAI‚Äôs API now available with no waitlist",
    "description": "Wider availability made possible by safety¬†progress.",
    "summary": "Wider availability made possible by safety¬†progress.",
    "pubDate": "Thu, 18 Nov 2021 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-no-waitlist",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing AI stories: daily benefits shine a light on bigger opportunities",
    "description": "Sam Altman has written that we are entering the Intelligence Age, a time when AI will help people become dramatically more capable. The biggest problems of today‚Äîacross science, medicine, education, national defense‚Äîwill no longer seem intractable, but will in fact be solvable. New horizons of possibility and prosperity will open up.",
    "summary": "Sam Altman has written that we are entering the Intelligence Age, a time when AI will help people become dramatically more capable. The biggest problems of today‚Äîacross science, medicine, education, national defense‚Äîwill no longer seem intractable, but will in fact be solvable. New horizons of possibility and prosperity will open up.",
    "pubDate": "Tue, 06 May 2025 10:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/ai-stories-daily-benefits-bigger-opportunities",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating Hugging Face Transformers with AWS Inferentia2",
    "description": "",
    "summary": "Accelerating Hugging Face Transformers with AWS Inferentia2 In the last five years, Transformer mode...",
    "pubDate": "Mon, 17 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerate-transformers-with-inferentia2",
    "thumbnail": "https://huggingface.co/blog/assets/140_accelerate_transformers_with_inferentia2/thumbnail.png"
  },
  {
    "title": "Adebayo Ogunlesi joins OpenAI‚Äôs Board of Directors",
    "description": "Adebayo Ogunlesi Joins OpenAI‚Äôs Board of Directors",
    "summary": "Adebayo Ogunlesi Joins OpenAI‚Äôs Board of Directors",
    "pubDate": "Tue, 14 Jan 2025 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/adebayo-ogunlesi-joins-openais-board-of-directors",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Emergent tool use from multi-agent interaction",
    "description": "We‚Äôve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek. Through training in our new simulated hide-and-seek environment, agents build a series of six distinct strategies and counterstrategies, some of which we did not know our environment supported. The self-supervised emergent complexity in this simple environment further suggests that multi-agent co-adaptation may one day produce extremely complex and intelligent behavior.",
    "summary": "We‚Äôve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek. Through training in our new simulated hide-and-seek environment, agents build a series of six distinct strategies and counterstrategies, some of which we did not know our environment supported. The self-supervised emergent complexity in this simple environment further suggests that multi-agent co-adaptation may one day produce extremely complex and intelligent behavior.",
    "pubDate": "Tue, 17 Sep 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergent-tool-use",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-4 API general availability and deprecation of older models in the Completions API",
    "description": "GPT-3.5 Turbo, DALL¬∑E and Whisper APIs are also generally available, and we are releasing a deprecation plan for older models of the Completions API, which will retire at the beginning of 2024.",
    "summary": "GPT-3.5 Turbo, DALL¬∑E and Whisper APIs are also generally available, and we are releasing a deprecation plan for older models of the Completions API, which will retire at the beginning of 2024.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4-api-general-availability",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Customizable, no-code voice agent automation with GPT-4o",
    "description": "Retell AI is transforming the call center with AI voice automation powered by GPT-4o and GPT-4.1. Its no-code platform enables businesses to launch natural, real-time voice agents that cut call costs, boost CSAT, and automate customer conversations‚Äîwithout scripts or hold times.",
    "summary": "Retell AI is transforming the call center with AI voice automation powered by GPT-4o and GPT-4.1. Its no-code platform enables businesses to launch natural, real-time voice agents that cut call costs, boost CSAT, and automate customer conversations‚Äîwithout scripts or hold times.",
    "pubDate": "Thu, 26 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/retell-ai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Happy 1st anniversary ü§ó Diffusers!",
    "description": "",
    "summary": "Happy 1st anniversary ü§ó Diffusers! ü§ó Diffusers is happy to celebrate its first anniversary! It has b...",
    "pubDate": "Thu, 20 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-turns-1",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers-turns-1/diffusers-turns-1.png"
  },
  {
    "title": "Public Policy at Hugging Face",
    "description": "",
    "summary": "Public Policy at Hugging Face Published April 8, 2024 Update on GitHubAI Policy at Hugging Face is a...",
    "pubDate": "Mon, 08 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/policy-blog",
    "thumbnail": "https://huggingface.co/blog/assets/policy_docs/policy_blog_thumbnail.png"
  },
  {
    "title": "Driving scalable growth with OpenAI o3, GPT-4.1, and CUA",
    "description": "Unify, an AI-powered GTM platform, uses OpenAI‚Äôs o3, GPT-4.1, and CUA to automate prospecting, research, and outreach. With hyper-personalized messaging and an always-on workflow, Unify helps teams generate pipeline at scale while focusing on high-impact customer interactions.",
    "summary": "Unify, an AI-powered GTM platform, uses OpenAI‚Äôs o3, GPT-4.1, and CUA to automate prospecting, research, and outreach. With hyper-personalized messaging and an always-on workflow, Unify helps teams generate pipeline at scale while focusing on high-impact customer interactions.",
    "pubDate": "Tue, 24 Jun 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/unify",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bench to the Future: A Pastcasting Benchmark for Forecasting Agents",
    "description": "arXiv:2506.21558v1 Announce Type: cross Abstract: Forecasting is a challenging task that offers a clearly measurable way to study AI systems. Forecasting requires a large amount of research on the internet, and evaluations require time for events to happen, making the development of forecasting benchmarks challenging. To date, no forecasting benchmark provides a realistic, hermetic, and repeatable environment for LLM forecasters. We introduce Bench To the Future (BTF), a 'pastcasting' benchmark with hundreds of high-quality questions for which the resolution is already known. Each question is accompanied by a large offline corpus of tens of thousands of relevant web pages, enabling a way to elicit realistic 'forecasts' on past events from LLMs. Results suggest that our pastcasting environment can produce results comparable to those based on forecasts using the internet on at-the-time unresolved questions. We show results benchmarking agent and chain-of-thought forecasting approaches using several LLMs, including the recently-released Claude 4 models, and demonstrate BTF's ability to track steady forecasting capability progress over time. We intend this to be a living benchmark, with new questions added continually to account for increasing training data cutoff dates. We invite researchers to contact us at hello@futuresearch.ai to utilize our benchmark or tooling for their own research.",
    "summary": "arXiv:2506.21558v1 Announce Type: cross Abstract: Forecasting is a challenging task that offers a clearly measurable way to study AI systems. Forecasting requires a large amount of research on the internet, and evaluations require time for events to happen, making the development of forecasting benchmarks challenging. To date, no forecasting benchmark provides a realistic, hermetic, and repeatable environment for LLM forecasters. We introduce Bench To the Future (BTF), a 'pastcasting' benchmark with hundreds of high-quality questions for which the resolution is already known. Each question is accompanied by a large offline corpus of tens of thousands of relevant web pages, enabling a way to elicit realistic 'forecasts' on past events from LLMs. Results suggest that our pastcasting environment can produce results comparable to those based on forecasts using the internet on at-the-time unresolved questions. We show results benchmarking agent and chain-of-thought forecasting approaches using several LLMs, including the recently-released Claude 4 models, and demonstrate BTF's ability to track steady forecasting capability progress over time. We intend this to be a living benchmark, with new questions added continually to account for increasing training data cutoff dates. We invite researchers to contact us at hello@futuresearch.ai to utilize our benchmark or tooling for their own research.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21558",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Meta-learning for wrestling",
    "description": "We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to physical malfunction.",
    "summary": "We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to physical malfunction.",
    "pubDate": "Wed, 11 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/meta-learning-for-wrestling",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Optimum+ONNX Runtime - Easier, Faster training for your Hugging Face models",
    "description": "",
    "summary": "Optimum + ONNX Runtime: Easier, Faster training for your Hugging Face models Introduction Transforme...",
    "pubDate": "Tue, 24 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/optimum-onnxruntime-training",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_onnxruntime-training/thumbnail.png"
  },
  {
    "title": "Fine-tuning GPT-2 from human preferences",
    "description": "We‚Äôve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we‚Äôd only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required only 5k. Our motivation is to move safety techniques closer to the general task of ‚Äúmachines talking to humans,‚Äù which we believe is key to extracting information about human¬†values.",
    "summary": "We‚Äôve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully matching the preferences of the external human labelers, though those preferences did not always match our own. Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we‚Äôd only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels; simpler tasks which continue text in various styles required only 5k. Our motivation is to move safety techniques closer to the general task of ‚Äúmachines talking to humans,‚Äù which we believe is key to extracting information about human¬†values.",
    "pubDate": "Thu, 19 Sep 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fine-tuning-gpt-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the Open Leaderboard for Hebrew LLMs!",
    "description": "",
    "summary": "Introducing the Open Leaderboard for Hebrew LLMs! This project addresses the critical need for advan...",
    "pubDate": "Sun, 05 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/leaderboard-hebrew",
    "thumbnail": "https://huggingface.co/blog/assets/leaderboards-on-the-hub/thumbnail_hebrew.png"
  },
  {
    "title": "Requests for Research 2.0",
    "description": "We‚Äôre releasing a new batch of¬†seven unsolved problems¬†which have come up in the course of our research at OpenAI.",
    "summary": "We‚Äôre releasing a new batch of¬†seven unsolved problems¬†which have come up in the course of our research at OpenAI.",
    "pubDate": "Wed, 31 Jan 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/requests-for-research-2",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ÁîªÂÉèÁîüÊàêAIÊ¥ªÁî®„ÅßË≥õÂê¶„ÄÅ„Ç≤„Éº„É†„ÄåÁ•ûÈ≠îÁã©„Çä„ÅÆ„ÉÑ„ÇØ„É®„Éü„Äç„ÅØ‚ÄúÊàêÂäü‚Äù„Åó„Åü„ÅÆ„Åã‚îÄ‚îÄÈáëÂ≠ê‰∏ÄÈ¶¨Ê∞èÔºÜÈñãÁô∫P„Å´ÊâãÂøú„Åà„ÇíËÅû„ÅÑ„Åü",
    "description": "„ÄåÂÆü„ÅØ„ÄÅÔºàÈñãÁô∫„ÇíÂßã„ÇÅ„ÅüÔºâÊúÄÂàù„ÅÆÊñπ„ÅØAI„ÅÆÂà©Áî®„Å´ÂèçÂØæ„Åô„Çã‰∏ñÈñì„ÅÆÂãï„Åç„ÇÇ„ÅÇ„Çä„ÄÅÁµêÊßã„Éì„ÇØ„Éì„ÇØ„Åó„Å¶„ÅÑ„Åæ„Åó„Åü„Äç‚îÄ‚îÄÁîüÊàêAI„ÇíÂèñ„ÇäÂÖ•„Çå„Åü„Ç≥„É≠„Éó„É©„ÅÆ„Ç≤„Éº„É†„ÄåÁ•ûÈ≠îÁã©„Çä„ÅÆ„ÉÑ„ÇØ„É®„Éü„ÄçÔºà„Åò„Çì„Åæ„Åå„Çä„ÅÆ„Å§„Åè„Çà„ÅøÔºâ„Å´„Å§„ÅÑ„Å¶„ÄÅÂêå‰Ωú„ÇíÊâãÊéõ„Åë„Çã„Ç≤„Éº„É†„ÇØ„É™„Ç®„Ç§„Çø„Éº„Åß„Ç§„É©„Çπ„Éà„É¨„Éº„Çø„Éº„ÅÆÈáëÂ≠ê‰∏ÄÈ¶¨„Åï„Çì„Å®„ÄÅÈñãÁô∫„Éó„É≠„Éá„É•„Éº„Çµ„Éº„ÅÆÈΩãËó§„Ç±„Éì„É≥ÈõÑËºî„Åï„Çì„ÅØ„Åì„ÅÜË™û„Çã„ÄÇ",
    "summary": "„ÄåÂÆü„ÅØ„ÄÅÔºàÈñãÁô∫„ÇíÂßã„ÇÅ„ÅüÔºâÊúÄÂàù„ÅÆÊñπ„ÅØAI„ÅÆÂà©Áî®„Å´ÂèçÂØæ„Åô„Çã‰∏ñÈñì„ÅÆÂãï„Åç„ÇÇ„ÅÇ„Çä„ÄÅÁµêÊßã„Éì„ÇØ„Éì„ÇØ„Åó„Å¶„ÅÑ„Åæ„Åó„Åü„Äç‚îÄ‚îÄÁîüÊàêAI„ÇíÂèñ„ÇäÂÖ•„Çå„Åü„Ç≥„É≠„Éó„É©„ÅÆ„Ç≤„Éº„É†„ÄåÁ•ûÈ≠îÁã©„Çä„ÅÆ„ÉÑ„ÇØ„É®„Éü„ÄçÔºà„Åò„Çì„Åæ„Åå„Çä„ÅÆ„Å§„Åè„Çà„ÅøÔºâ„Å´„Å§„ÅÑ„Å¶„ÄÅÂêå‰Ωú„ÇíÊâãÊéõ„Åë„Çã„Ç≤„Éº„É†„ÇØ„É™„Ç®„Ç§„Çø„Éº„Åß„Ç§„É©„Çπ„Éà„É¨„Éº„Çø„Éº„ÅÆÈáëÂ≠ê‰∏ÄÈ¶¨„Åï„Çì„Å®„ÄÅÈñãÁô∫„Éó„É≠„Éá„É•„Éº„Çµ„Éº„ÅÆÈΩãËó§„Ç±„Éì„É≥ÈõÑËºî„Åï„Çì„ÅØ„Åì„ÅÜË™û„Çã„ÄÇ",
    "pubDate": "Sun, 29 Jun 2025 12:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/29/news013.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/29/cover_news013.jpg"
  },
  {
    "title": "Identifying Macro Causal Effects in C-DMGs over DMGs",
    "description": "arXiv:2506.19650v1 Announce Type: new Abstract: The do-calculus is a sound and complete tool for identifying causal effects in acyclic directed mixed graphs (ADMGs) induced by structural causal models (SCMs). However, in many real-world applications, especially in high-dimensional setting, constructing a fully specified ADMG is often infeasible. This limitation has led to growing interest in partially specified causal representations, particularly through cluster-directed mixed graphs (C-DMGs), which group variables into clusters and offer a more abstract yet practical view of causal dependencies. While these representations can include cycles, recent work has shown that the do-calculus remains sound and complete for identifying macro-level causal effects in C-DMGs over ADMGs under the assumption that all clusters size are greater than 1. Nevertheless, real-world systems often exhibit cyclic causal dynamics at the structural level. To account for this, input-output structural causal models (ioSCMs) have been introduced as a generalization of SCMs that allow for cycles. ioSCMs induce another type of graph structure known as a directed mixed graph (DMG). Analogous to the ADMG setting, one can define C-DMGs over DMGs as high-level representations of causal relations among clusters of variables. In this paper, we prove that, unlike in the ADMG setting, the do-calculus is unconditionally sound and complete for identifying macro causal effects in C-DMGs over DMGs. Furthermore, we show that the graphical criteria for non-identifiability of macro causal effects previously established C-DMGs over ADMGs naturally extends to a subset of C-DMGs over DMGs.",
    "summary": "arXiv:2506.19650v1 Announce Type: new Abstract: The do-calculus is a sound and complete tool for identifying causal effects in acyclic directed mixed graphs (ADMGs) induced by structural causal models (SCMs). However, in many real-world applications, especially in high-dimensional setting, constructing a fully specified ADMG is often infeasible. This limitation has led to growing interest in partially specified causal representations, particularly through cluster-directed mixed graphs (C-DMGs), which group variables into clusters and offer a more abstract yet practical view of causal dependencies. While these representations can include cycles, recent work has shown that the do-calculus remains sound and complete for identifying macro-level causal effects in C-DMGs over ADMGs under the assumption that all clusters size are greater than 1. Nevertheless, real-world systems often exhibit cyclic causal dynamics at the structural level. To account for this, input-output structural causal models (ioSCMs) have been introduced as a generalization of SCMs that allow for cycles. ioSCMs induce another type of graph structure known as a directed mixed graph (DMG). Analogous to the ADMG setting, one can define C-DMGs over DMGs as high-level representations of causal relations among clusters of variables. In this paper, we prove that, unlike in the ADMG setting, the do-calculus is unconditionally sound and complete for identifying macro causal effects in C-DMGs over DMGs. Furthermore, we show that the graphical criteria for non-identifiability of macro causal effects previously established C-DMGs over ADMGs naturally extends to a subset of C-DMGs over DMGs.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19650",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Insights from global conversations",
    "description": "We are sharing what we learned from our conversations across 22 countries, and how we will be incorporating those insights moving forward.",
    "summary": "We are sharing what we learned from our conversations across 22 countries, and how we will be incorporating those insights moving forward.",
    "pubDate": "Thu, 29 Jun 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/insights-from-global-conversations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Investing in Performance: Fine-tune small models with LLM insights  - a CFM case study",
    "description": "",
    "summary": "Investing in Performance: Fine-tune small models with LLM insights - a CFM case study Overview: This...",
    "pubDate": "Tue, 03 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/cfm-case-study",
    "thumbnail": "https://huggingface.co/blog/assets/cfm-case-study/blogpost_cfm.png"
  },
  {
    "title": "Evaluating Multimodal Large Language Models on Educational Textbook Question Answering",
    "description": "arXiv:2506.21596v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) have recently achieved significant success in vision--language tasks. However, their capacity to reason over complex, long lessons and intricate educational diagrams that cannot be represented as a single natural image remains largely untested. In this work, we present the first evaluation of state-of-the-art MLLMs on the textbook question answering (TQA) task using the CK12-QA dataset. We assess the performance of recent vision-language models, including LLaVA and LLaMA 3.2-Vision, across various input configurations. Additionally, we introduce a lightweight multimodal retrieval-augmented generation (RAG) pipeline that integrates both paragraphs and diagrams from the lesson into the prompt. Our results demonstrate the influence of retrieved educational context on model accuracy and reasoning, while also revealing current limitations in handling question-context relationships and the potential for noise, pointing to key directions for future research in multimodal AI-driven learning.",
    "summary": "arXiv:2506.21596v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) have recently achieved significant success in vision--language tasks. However, their capacity to reason over complex, long lessons and intricate educational diagrams that cannot be represented as a single natural image remains largely untested. In this work, we present the first evaluation of state-of-the-art MLLMs on the textbook question answering (TQA) task using the CK12-QA dataset. We assess the performance of recent vision-language models, including LLaVA and LLaMA 3.2-Vision, across various input configurations. Additionally, we introduce a lightweight multimodal retrieval-augmented generation (RAG) pipeline that integrates both paragraphs and diagrams from the lesson into the prompt. Our results demonstrate the influence of retrieved educational context on model accuracy and reasoning, while also revealing current limitations in handling question-context relationships and the potential for noise, pointing to key directions for future research in multimodal AI-driven learning.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21596",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Persona Features Control Emergent Misalignment",
    "description": "arXiv:2506.19823v1 Announce Type: cross Abstract: Understanding how language models generalize behaviors from their training to a broader deployment distribution is an important problem in AI safety. Betley et al. discovered that fine-tuning GPT-4o on intentionally insecure code causes 'emergent misalignment,' where models give stereotypically malicious responses to unrelated prompts. We extend this work, demonstrating emergent misalignment across diverse conditions, including reinforcement learning on reasoning models, fine-tuning on various synthetic datasets, and in models without safety training. To investigate the mechanisms behind this generalized misalignment, we apply a 'model diffing' approach using sparse autoencoders to compare internal model representations before and after fine-tuning. This approach reveals several 'misaligned persona' features in activation space, including a toxic persona feature which most strongly controls emergent misalignment and can be used to predict whether a model will exhibit such behavior. Additionally, we investigate mitigation strategies, discovering that fine-tuning an emergently misaligned model on just a few hundred benign samples efficiently restores alignment.",
    "summary": "arXiv:2506.19823v1 Announce Type: cross Abstract: Understanding how language models generalize behaviors from their training to a broader deployment distribution is an important problem in AI safety. Betley et al. discovered that fine-tuning GPT-4o on intentionally insecure code causes 'emergent misalignment,' where models give stereotypically malicious responses to unrelated prompts. We extend this work, demonstrating emergent misalignment across diverse conditions, including reinforcement learning on reasoning models, fine-tuning on various synthetic datasets, and in models without safety training. To investigate the mechanisms behind this generalized misalignment, we apply a 'model diffing' approach using sparse autoencoders to compare internal model representations before and after fine-tuning. This approach reveals several 'misaligned persona' features in activation space, including a toxic persona feature which most strongly controls emergent misalignment and can be used to predict whether a model will exhibit such behavior. Additionally, we investigate mitigation strategies, discovering that fine-tuning an emergently misaligned model on just a few hundred benign samples efficiently restores alignment.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19823",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How we sped up transformer inference 100x for ü§ó API customers",
    "description": "",
    "summary": "How we sped up transformer inference 100x for ü§ó API customers ü§ó Transformers has become the default ...",
    "pubDate": "Mon, 18 Jan 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerated-inference",
    "thumbnail": "https://huggingface.co/blog/assets/09_accelerated_inference/thumbnail.png"
  },
  {
    "title": "Instituto de Telecomunicac{c}~oes at IWSLT 2025: Aligning Small-Scale Speech and Language Models for Speech-to-Text Learning",
    "description": "arXiv:2506.17019v1 Announce Type: cross Abstract: This paper presents the IT-IST submission to the IWSLT 2025 Shared Task on Instruction Following Speech Processing. We submit results for the Short Track, i.e., speech recognition, translation, and spoken question answering. Our model is a unified speech-to-text model that integrates a pre-trained continuous speech encoder and text decoder through a first phase of modality alignment and a second phase of instruction fine-tuning. Crucially, we focus on using small-scale language model backbones (< 2B) and restrict to high-quality, CC-BY data along with synthetic data generation to supplement existing resources.",
    "summary": "arXiv:2506.17019v1 Announce Type: cross Abstract: This paper presents the IT-IST submission to the IWSLT 2025 Shared Task on Instruction Following Speech Processing. We submit results for the Short Track, i.e., speech recognition, translation, and spoken question answering. Our model is a unified speech-to-text model that integrates a pre-trained continuous speech encoder and text decoder through a first phase of modality alignment and a second phase of instruction fine-tuning. Crucially, we focus on using small-scale language model backbones (< 2B) and restrict to high-quality, CC-BY data along with synthetic data generation to supplement existing resources.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tuning Llama 2 70B using PyTorch FSDP",
    "description": "",
    "summary": "Fine-tuning Llama 2 70B using PyTorch FSDP Introduction In this blog post, we will look at how to fi...",
    "pubDate": "Wed, 13 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ram-efficient-pytorch-fsdp",
    "thumbnail": "https://huggingface.co/blog/assets/160_fsdp_llama/thumbnail.jpg"
  },
  {
    "title": "Hyperparameter Search with Transformers and Ray Tune",
    "description": "",
    "summary": "Hyperparameter Search with Transformers and Ray Tune A guest blog post by Richard Liaw from the Anys...",
    "pubDate": "Mon, 02 Nov 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ray-tune",
    "thumbnail": "https://huggingface.co/blog/assets/06_ray_tune/ray-hf.jpg"
  },
  {
    "title": "A Dive into Text-to-Video Models",
    "description": "",
    "summary": "Text-to-Video: The Task, Challenges and the Current State Video samples generated with ModelScope. T...",
    "pubDate": "Mon, 08 May 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/text-to-video",
    "thumbnail": "https://huggingface.co/blog/assets/140_text-to-video/thumbnail.png"
  },
  {
    "title": "2023: A Year of Groundbreaking Advances in AI and Computing",
    "description": "This has been a year of incredible progress in the field of Artificial Intelligence (AI) research and its practical applications.",
    "summary": "This has been a year of incredible progress in the field of Artificial Intelligence (AI) research and its practical applications.",
    "pubDate": "Fri, 22 Dec 2023 13:30:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/2023-a-year-of-groundbreaking-advances-in-ai-and-computing/",
    "thumbnail": "https://lh3.googleusercontent.com/fkZqqqpfLKvV2E6ebVmYJjR9q9XnczvWtiui5uU-yPkHCQb5mLAB4kBmh3opGqOJLhtaC58td96UtvULI8uGpbB9TmejR82GZ2vWOqTyWZ6HSItIpHg=w1200-h630-n-nu"
  },
  {
    "title": "Perceiver IO: a scalable, fully-attentional model that works on any modality",
    "description": "",
    "summary": "Perceiver IO: a scalable, fully-attentional model that works on any modality TLDR We've added Percei...",
    "pubDate": "Wed, 15 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/perceiver",
    "thumbnail": "https://huggingface.co/blog/assets/41_perceiver/thumbnail.png"
  },
  {
    "title": "Introducing HELMET",
    "description": "",
    "summary": "Introducing HELMET: Holistically Evaluating Long-context Language Models Contact: hyen@cs.princeton....",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/helmet",
    "thumbnail": "https://huggingface.co/blog/assets/helmet/thumbnail.png"
  },
  {
    "title": "Eau De $Q$-Network: Adaptive Distillation of Neural Networks in Deep Reinforcement Learning",
    "description": "arXiv:2503.01437v2 Announce Type: replace-cross Abstract: Recent works have successfully demonstrated that sparse deep reinforcement learning agents can be competitive against their dense counterparts. This opens up opportunities for reinforcement learning applications in fields where inference time and memory requirements are cost-sensitive or limited by hardware. Until now, dense-to-sparse methods have relied on hand-designed sparsity schedules that are not synchronized with the agent's learning pace. Crucially, the final sparsity level is chosen as a hyperparameter, which requires careful tuning as setting it too high might lead to poor performances. In this work, we address these shortcomings by crafting a dense-to-sparse algorithm that we name Eau De $Q$-Network (EauDeQN). To increase sparsity at the agent's learning pace, we consider multiple online networks with different sparsity levels, where each online network is trained from a shared target network. At each target update, the online network with the smallest loss is chosen as the next target network, while the other networks are replaced by a pruned version of the chosen network. We evaluate the proposed approach on the Atari $2600$ benchmark and the MuJoCo physics simulator, showing that EauDeQN reaches high sparsity levels while keeping performances high.",
    "summary": "arXiv:2503.01437v2 Announce Type: replace-cross Abstract: Recent works have successfully demonstrated that sparse deep reinforcement learning agents can be competitive against their dense counterparts. This opens up opportunities for reinforcement learning applications in fields where inference time and memory requirements are cost-sensitive or limited by hardware. Until now, dense-to-sparse methods have relied on hand-designed sparsity schedules that are not synchronized with the agent's learning pace. Crucially, the final sparsity level is chosen as a hyperparameter, which requires careful tuning as setting it too high might lead to poor performances. In this work, we address these shortcomings by crafting a dense-to-sparse algorithm that we name Eau De $Q$-Network (EauDeQN). To increase sparsity at the agent's learning pace, we consider multiple online networks with different sparsity levels, where each online network is trained from a shared target network. At each target update, the online network with the smallest loss is chosen as the next target network, while the other networks are replaced by a pruned version of the chosen network. We evaluate the proposed approach on the Atari $2600$ benchmark and the MuJoCo physics simulator, showing that EauDeQN reaches high sparsity levels while keeping performances high.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.01437",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Exclusive Style Removal for Cross Domain Novel Class Discovery",
    "description": "arXiv:2406.18140v4 Announce Type: replace-cross Abstract: As a promising field in open-world learning, textit{Novel Class Discovery} (NCD) is usually a task to cluster unseen novel classes in an unlabeled set based on the prior knowledge of labeled data within the same domain. However, the performance of existing NCD methods could be severely compromised when novel classes are sampled from a different distribution with the labeled ones. In this paper, we explore and establish the solvability of NCD with cross domain setting under the necessary condition that the style information needs to be removed. Based on the theoretical analysis, we introduce an exclusive style removal module for extracting style information that is distinctive from the baseline features, thereby facilitating inference. Moreover, this module is easy to integrate with other NCD methods, acting as a plug-in to improve performance on novel classes with different distributions compared to the labeled set. Additionally, recognizing the non-negligible influence of different backbones and pre-training strategies on the performance of the NCD methods, we build a fair benchmark for future NCD research. Extensive experiments on three common datasets demonstrate the effectiveness of our proposed style removal strategy.",
    "summary": "arXiv:2406.18140v4 Announce Type: replace-cross Abstract: As a promising field in open-world learning, textit{Novel Class Discovery} (NCD) is usually a task to cluster unseen novel classes in an unlabeled set based on the prior knowledge of labeled data within the same domain. However, the performance of existing NCD methods could be severely compromised when novel classes are sampled from a different distribution with the labeled ones. In this paper, we explore and establish the solvability of NCD with cross domain setting under the necessary condition that the style information needs to be removed. Based on the theoretical analysis, we introduce an exclusive style removal module for extracting style information that is distinctive from the baseline features, thereby facilitating inference. Moreover, this module is easy to integrate with other NCD methods, acting as a plug-in to improve performance on novel classes with different distributions compared to the labeled set. Additionally, recognizing the non-negligible influence of different backbones and pre-training strategies on the performance of the NCD methods, we build a fair benchmark for future NCD research. Extensive experiments on three common datasets demonstrate the effectiveness of our proposed style removal strategy.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.18140",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "„ÄåÁßÅ„ÅÆÈ°îÂûã„Å´Âêà„ÅÜ„Éï„É¨„Éº„É†„ÅØÔºü„ÄçAI„ÅåÊèêÊ°à„ÄÄÁã¨Ëá™ÈñãÁô∫„ÄåJINS AI„ÄçÂÆüË®ºÂÆüÈ®ìÊã°Â§ß",
    "description": "ÁîüÊàêAI„ÇíÊ¥ªÁî®„Åó„ÄÅÈ°ßÂÆ¢„ÅÆ„É°„Ç¨„ÉçË≥ºÂÖ•„Å´Èñ¢„Åô„ÇãÁñëÂïè„ÇÑÊÇ©„Åø„Å´Áû¨ÊôÇ„Å´ÂõûÁ≠î„ÉªÊèêÊ°à„Çí„Åô„Çã„Çµ„Éº„Éì„Çπ„ÄåJINS AI„Äç„ÅÆÂÆüË®ºÂÆüÈ®ì„ÅÆÂØæË±°Â∫óËàó„ÅåÊã°Â§ß„Å∏„ÄÇ",
    "summary": "ÁîüÊàêAI„ÇíÊ¥ªÁî®„Åó„ÄÅÈ°ßÂÆ¢„ÅÆ„É°„Ç¨„ÉçË≥ºÂÖ•„Å´Èñ¢„Åô„ÇãÁñëÂïè„ÇÑÊÇ©„Åø„Å´Áû¨ÊôÇ„Å´ÂõûÁ≠î„ÉªÊèêÊ°à„Çí„Åô„Çã„Çµ„Éº„Éì„Çπ„ÄåJINS AI„Äç„ÅÆÂÆüË®ºÂÆüÈ®ì„ÅÆÂØæË±°Â∫óËàó„ÅåÊã°Â§ß„Å∏„ÄÇ",
    "pubDate": "Wed, 25 Jun 2025 16:58:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/25/news104.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/25/cover_news104.jpg"
  },
  {
    "title": "CRIA: A Cross-View Interaction and Instance-Adapted Pre-training Framework for Generalizable EEG Representations",
    "description": "arXiv:2506.16056v1 Announce Type: cross Abstract: The difficulty of extracting deep features from EEG data and effectively integrating information from multiple views presents significant challenges for developing a generalizable pretraining framework for EEG representation learning. However, most existing pre-training methods rely solely on the contextual semantics of a single view, failing to capture the complex and synergistic interactions among different perspectives, limiting the expressiveness and generalization of learned representations. To address these issues, this paper proposes CRIA, an adaptive framework that utilizes variable-length and variable-channel coding to achieve a unified representation of EEG data across different datasets. In this work, we define cross-view information as the integrated representation that emerges from the interaction among temporal, spectral, and spatial views of EEG signals. The model employs a cross-attention mechanism to fuse temporal, spectral, and spatial features effectively, and combines an attention matrix masking strategy based on the information bottleneck principle with a novel viewpoint masking pre-training scheme. Experimental results on the Temple University EEG corpus and the CHB-MIT dataset show that CRIA outperforms existing methods with the same pre-training conditions, achieving a balanced accuracy of 57.02% for multi-class event classification and 80.03% for anomaly detection, highlighting its strong generalization ability.",
    "summary": "arXiv:2506.16056v1 Announce Type: cross Abstract: The difficulty of extracting deep features from EEG data and effectively integrating information from multiple views presents significant challenges for developing a generalizable pretraining framework for EEG representation learning. However, most existing pre-training methods rely solely on the contextual semantics of a single view, failing to capture the complex and synergistic interactions among different perspectives, limiting the expressiveness and generalization of learned representations. To address these issues, this paper proposes CRIA, an adaptive framework that utilizes variable-length and variable-channel coding to achieve a unified representation of EEG data across different datasets. In this work, we define cross-view information as the integrated representation that emerges from the interaction among temporal, spectral, and spatial views of EEG signals. The model employs a cross-attention mechanism to fuse temporal, spectral, and spatial features effectively, and combines an attention matrix masking strategy based on the information bottleneck principle with a novel viewpoint masking pre-training scheme. Experimental results on the Temple University EEG corpus and the CHB-MIT dataset show that CRIA outperforms existing methods with the same pre-training conditions, achieving a balanced accuracy of 57.02% for multi-class event classification and 80.03% for anomaly detection, highlighting its strong generalization ability.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16056",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Unified Neural Backdoor Removal with Only Few Clean Samples through Unlearning and Relearning",
    "description": "arXiv:2405.14781v2 Announce Type: replace-cross Abstract: Deep neural networks have achieved remarkable success across various applications; however, their vulnerability to backdoor attacks poses severe security risks -- especially in situations where only a limited set of clean samples is available for defense. In this work, we address this critical challenge by proposing ULRL (UnLearn and ReLearn for backdoor removal), a novel two-phase approach for comprehensive backdoor removal. Our method first employs an unlearning phase, in which the network's loss is intentionally maximized on a small clean dataset to expose neurons that are excessively sensitive to backdoor triggers. Subsequently, in the relearning phase, these suspicious neurons are recalibrated using targeted reinitialization and cosine similarity regularization, effectively neutralizing backdoor influences while preserving the model's performance on benign data. Extensive experiments with 12 backdoor types on multiple datasets (CIFAR-10, CIFAR-100, GTSRB, and Tiny-ImageNet) and architectures (PreAct-ResNet18, VGG19-BN, and ViT-B-16) demonstrate that ULRL significantly reduces the attack success rate without compromising clean accuracy -- even when only 1% of clean data is used for defense.",
    "summary": "arXiv:2405.14781v2 Announce Type: replace-cross Abstract: Deep neural networks have achieved remarkable success across various applications; however, their vulnerability to backdoor attacks poses severe security risks -- especially in situations where only a limited set of clean samples is available for defense. In this work, we address this critical challenge by proposing ULRL (UnLearn and ReLearn for backdoor removal), a novel two-phase approach for comprehensive backdoor removal. Our method first employs an unlearning phase, in which the network's loss is intentionally maximized on a small clean dataset to expose neurons that are excessively sensitive to backdoor triggers. Subsequently, in the relearning phase, these suspicious neurons are recalibrated using targeted reinitialization and cosine similarity regularization, effectively neutralizing backdoor influences while preserving the model's performance on benign data. Extensive experiments with 12 backdoor types on multiple datasets (CIFAR-10, CIFAR-100, GTSRB, and Tiny-ImageNet) and architectures (PreAct-ResNet18, VGG19-BN, and ViT-B-16) demonstrate that ULRL significantly reduces the attack success rate without compromising clean accuracy -- even when only 1% of clean data is used for defense.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2405.14781",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Using GPT-4 to deliver a new customer service standard",
    "description": "Ada uses GPT-4 to deliver a new customer service standard",
    "summary": "Ada uses GPT-4 to deliver a new customer service standard",
    "pubDate": "Thu, 05 Sep 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ada",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Generative modeling with sparse transformers",
    "description": "We‚Äôve developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence‚Äîwhether text, images, or sound. It uses an algorithmic improvement of the¬†attention¬†mechanism to extract patterns from sequences 30x longer than possible¬†previously.",
    "summary": "We‚Äôve developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes next in a sequence‚Äîwhether text, images, or sound. It uses an algorithmic improvement of the¬†attention¬†mechanism to extract patterns from sequences 30x longer than possible¬†previously.",
    "pubDate": "Tue, 23 Apr 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/sparse-transformer",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents",
    "description": "arXiv:2407.01511v3 Announce Type: replace Abstract: The development of autonomous agents increasingly relies on Multimodal Language Models (MLMs) to perform tasks described in natural language with GUI environments, such as websites, desktop computers, or mobile phones. Existing benchmarks for MLM agents in interactive environments are limited by their focus on a single environment, lack of detailed and generalized evaluation methods, and the complexities of constructing tasks and evaluators. To overcome these limitations, we introduce Crab, the first agent benchmark framework designed to support cross-environment tasks, incorporating a graph-based fine-grained evaluation method and an efficient mechanism for task and evaluator construction. Our framework supports multiple devices and can be easily extended to any environment with a Python interface. Leveraging Crab, we developed a cross-platform Crab Benchmark-v0 comprising 120 tasks in computer desktop and mobile phone environments. We evaluated four advanced MLMs using different single and multi-agent system configurations on this benchmark. The experimental results demonstrate that the single agent with GPT-4o achieves the best completion ratio of 38.01%. All framework code, agent code, and task datasets are publicly available at https://github.com/camel-ai/crab.",
    "summary": "arXiv:2407.01511v3 Announce Type: replace Abstract: The development of autonomous agents increasingly relies on Multimodal Language Models (MLMs) to perform tasks described in natural language with GUI environments, such as websites, desktop computers, or mobile phones. Existing benchmarks for MLM agents in interactive environments are limited by their focus on a single environment, lack of detailed and generalized evaluation methods, and the complexities of constructing tasks and evaluators. To overcome these limitations, we introduce Crab, the first agent benchmark framework designed to support cross-environment tasks, incorporating a graph-based fine-grained evaluation method and an efficient mechanism for task and evaluator construction. Our framework supports multiple devices and can be easily extended to any environment with a Python interface. Leveraging Crab, we developed a cross-platform Crab Benchmark-v0 comprising 120 tasks in computer desktop and mobile phone environments. We evaluated four advanced MLMs using different single and multi-agent system configurations on this benchmark. The experimental results demonstrate that the single agent with GPT-4o achieves the best completion ratio of 38.01%. All framework code, agent code, and task datasets are publicly available at https://github.com/camel-ai/crab.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.01511",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "10 tips for 10 years of Google Photos",
    "description": "Google Photos logo with the number ten and colorful confetti shapes.",
    "summary": "Google Photos logo with the number ten and colorful confetti shapes.",
    "pubDate": "Wed, 28 May 2025 17:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/products/photos/google-photos-10-years-tips-tricks/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GooglePhotos-10year-Blog-header.width-1300.png"
  },
  {
    "title": "Creating nail art with ChatGPT",
    "description": "Using ChatGPT to find inspiration for nail art",
    "summary": "Using ChatGPT to find inspiration for nail art",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ten-tiny-canvases",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Start using ChatGPT instantly",
    "description": "We‚Äôre making it easier for people to experience the benefits of AI without needing to sign up",
    "summary": "We‚Äôre making it easier for people to experience the benefits of AI without needing to sign up",
    "pubDate": "Mon, 01 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/start-using-chatgpt-instantly",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "What's going on with the Open LLM Leaderboard?",
    "description": "",
    "summary": "What's going on with the Open LLM Leaderboard? Recently an interesting discussion arose on Twitter f...",
    "pubDate": "Fri, 23 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-mmlu",
    "thumbnail": "https://huggingface.co/blog/assets/evaluating-mmlu-leaderboard/thumbnail.png"
  },
  {
    "title": "Addendum to o3 and o4-mini system card: Codex",
    "description": "Codex is a cloud-based coding agent. Codex is powered by codex-1, a version of OpenAI o3 optimized for software engineering. codex-1 was trained using reinforcement learning on real-world coding tasks in a variety of environments to generate code that closely mirrors human style and PR preferences, adheres precisely to instructions, and iteratively runs tests until passing results are achieved.",
    "summary": "Codex is a cloud-based coding agent. Codex is powered by codex-1, a version of OpenAI o3 optimized for software engineering. codex-1 was trained using reinforcement learning on real-world coding tasks in a variety of environments to generate code that closely mirrors human style and PR preferences, adheres precisely to instructions, and iteratively runs tests until passing results are achieved.",
    "pubDate": "Fri, 16 May 2025 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o3-o4-mini-codex-system-card-addendum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "GPT-4V(ision) system card",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 25 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gpt-4v-system-card",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Signal Use and Emergent Cooperation",
    "description": "arXiv:2506.18920v1 Announce Type: new Abstract: In this work, we investigate how autonomous agents, organized into tribes, learn to use communication signals to coordinate their activities and enhance their collective efficiency. Using the NEC-DAC (Neurally Encoded Culture - Distributed Autonomous Communicators) system, where each agent is equipped with its own neural network for decision-making, we demonstrate how these agents develop a shared behavioral system -- akin to a culture -- through learning and signalling. Our research focuses on the self-organization of culture within these tribes of agents and how varying communication strategies impact their fitness and cooperation. By analyzing different social structures, such as authority hierarchies, we show that the culture of cooperation significantly influences the tribe's performance. Furthermore, we explore how signals not only facilitate the emergence of culture but also enable its transmission across generations of agents. Additionally, we examine the benefits of coordinating behavior and signaling within individual agents' neural networks.",
    "summary": "arXiv:2506.18920v1 Announce Type: new Abstract: In this work, we investigate how autonomous agents, organized into tribes, learn to use communication signals to coordinate their activities and enhance their collective efficiency. Using the NEC-DAC (Neurally Encoded Culture - Distributed Autonomous Communicators) system, where each agent is equipped with its own neural network for decision-making, we demonstrate how these agents develop a shared behavioral system -- akin to a culture -- through learning and signalling. Our research focuses on the self-organization of culture within these tribes of agents and how varying communication strategies impact their fitness and cooperation. By analyzing different social structures, such as authority hierarchies, we show that the culture of cooperation significantly influences the tribe's performance. Furthermore, we explore how signals not only facilitate the emergence of culture but also enable its transmission across generations of agents. Additionally, we examine the benefits of coordinating behavior and signaling within individual agents' neural networks.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18920",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Minifinetuning: Low-Data Generation Domain Adaptation through Corrective Self-Distillation",
    "description": "arXiv:2506.15702v1 Announce Type: cross Abstract: Finetuning language models for a new domain inevitably leads to the deterioration of their general performance. This becomes more pronounced the more limited the finetuning data resource. We introduce minifinetuning (MFT), a method for language model domain adaptation that considerably reduces the effects of overfitting-induced degeneralization in low-data settings and which does so in the absence of any pre-training data for replay. MFT demonstrates 2-10x more favourable specialization-to-degeneralization ratios than standard finetuning across a wide range of models and domains and exhibits an intrinsic robustness to overfitting when data in the new domain is scarce and down to as little as 500 samples. Employing corrective self-distillation that is individualized on the sample level, MFT outperforms parameter-efficient finetuning methods, demonstrates replay-like degeneralization mitigation properties, and is composable with either for a combined effect.",
    "summary": "arXiv:2506.15702v1 Announce Type: cross Abstract: Finetuning language models for a new domain inevitably leads to the deterioration of their general performance. This becomes more pronounced the more limited the finetuning data resource. We introduce minifinetuning (MFT), a method for language model domain adaptation that considerably reduces the effects of overfitting-induced degeneralization in low-data settings and which does so in the absence of any pre-training data for replay. MFT demonstrates 2-10x more favourable specialization-to-degeneralization ratios than standard finetuning across a wide range of models and domains and exhibits an intrinsic robustness to overfitting when data in the new domain is scarce and down to as little as 500 samples. Employing corrective self-distillation that is individualized on the sample level, MFT outperforms parameter-efficient finetuning methods, demonstrates replay-like degeneralization mitigation properties, and is composable with either for a combined effect.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15702",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Grounding-Aware Token Pruning: Recovering from Drastic Performance Drops in Visual Grounding Caused by Pruning",
    "description": "arXiv:2506.21873v1 Announce Type: cross Abstract: Recent Multimodal Large Language Models (MLLMs) have demonstrated strong performance in visual grounding, establishing themselves as a general interface for various vision-language applications. This progress has driven the development of token pruning methods to mitigate the high computational costs associated with processing numerous visual tokens. However, we observe that pruning significantly weakens the model's grounding ability, leading to incorrect predictions and drastic performance degradation. In Referring Expression Comprehension (REC), for instance, pruning causes the accuracy of LLaVA on the RefCOCO validation set to drop from 56.14% to 15.34%. Our analysis identifies misaligned position IDs after pruning as the primary cause of this degradation, as both the order and value of these IDs are crucial for maintaining performance in grounding tasks. To address this issue, we propose Grounding-Aware Token Pruning (GAP), a simple yet effective adjustment to position IDs that recovers REC accuracy back to 51.42%, which is 90% of the original performance in the without pruning setting, all while requiring no additional training, memory, or computational overhead. Applied to models such as Shikra, MiniGPTv2, and the LLaVA series, our method consistently improves performance across various token pruning strategies.",
    "summary": "arXiv:2506.21873v1 Announce Type: cross Abstract: Recent Multimodal Large Language Models (MLLMs) have demonstrated strong performance in visual grounding, establishing themselves as a general interface for various vision-language applications. This progress has driven the development of token pruning methods to mitigate the high computational costs associated with processing numerous visual tokens. However, we observe that pruning significantly weakens the model's grounding ability, leading to incorrect predictions and drastic performance degradation. In Referring Expression Comprehension (REC), for instance, pruning causes the accuracy of LLaVA on the RefCOCO validation set to drop from 56.14% to 15.34%. Our analysis identifies misaligned position IDs after pruning as the primary cause of this degradation, as both the order and value of these IDs are crucial for maintaining performance in grounding tasks. To address this issue, we propose Grounding-Aware Token Pruning (GAP), a simple yet effective adjustment to position IDs that recovers REC accuracy back to 51.42%, which is 90% of the original performance in the without pruning setting, all while requiring no additional training, memory, or computational overhead. Applied to models such as Shikra, MiniGPTv2, and the LLaVA series, our method consistently improves performance across various token pruning strategies.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21873",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Hugging Face and FriendliAI partner to supercharge model deployment on the Hub",
    "description": "",
    "summary": "Hugging Face and FriendliAI partner to supercharge model deployment on the Hub FriendliAI‚Äôs inferenc...",
    "pubDate": "Wed, 22 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/friendliai-partnership",
    "thumbnail": "https://huggingface.co/blog/assets/friendliai-partnership/thumbnail.png"
  },
  {
    "title": "Introducing deep research",
    "description": "An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.",
    "summary": "An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next.",
    "pubDate": "Sun, 02 Feb 2025 16:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-deep-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hugging Face and AMD partner on accelerating state-of-the-art models for CPU and GPU platforms",
    "description": "",
    "summary": "Hugging Face and AMD partner on accelerating state-of-the-art models for CPU and GPU platforms Wheth...",
    "pubDate": "Tue, 13 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/huggingface-and-amd",
    "thumbnail": "https://huggingface.co/blog/assets/148_huggingface_amd/01.png"
  },
  {
    "title": "Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX",
    "description": "arXiv:2505.24616v3 Announce Type: replace-cross Abstract: We introduce POLLUX, a comprehensive open-source benchmark designed to evaluate the generative capabilities of large language models (LLMs) in Russian. Our main contribution is a novel evaluation methodology that enhances the interpretability of LLM assessment. For each task type, we define a set of detailed criteria and develop a scoring protocol where models evaluate responses and provide justifications for their ratings. This enables transparent, criteria-driven evaluation beyond traditional resource-consuming, side-by-side human comparisons. POLLUX includes a detailed, fine-grained taxonomy of 35 task types covering diverse generative domains such as code generation, creative writing, and practical assistant use cases, totaling 2,100 manually crafted and professionally authored prompts. Each task is categorized by difficulty (easy/medium/hard), with experts constructing the dataset entirely from scratch. We also release a family of LLM-as-a-Judge (7B and 32B) evaluators trained for nuanced assessment of generative outputs. This approach provides scalable, interpretable evaluation and annotation tools for model development, effectively replacing costly and less precise human judgments.",
    "summary": "arXiv:2505.24616v3 Announce Type: replace-cross Abstract: We introduce POLLUX, a comprehensive open-source benchmark designed to evaluate the generative capabilities of large language models (LLMs) in Russian. Our main contribution is a novel evaluation methodology that enhances the interpretability of LLM assessment. For each task type, we define a set of detailed criteria and develop a scoring protocol where models evaluate responses and provide justifications for their ratings. This enables transparent, criteria-driven evaluation beyond traditional resource-consuming, side-by-side human comparisons. POLLUX includes a detailed, fine-grained taxonomy of 35 task types covering diverse generative domains such as code generation, creative writing, and practical assistant use cases, totaling 2,100 manually crafted and professionally authored prompts. Each task is categorized by difficulty (easy/medium/hard), with experts constructing the dataset entirely from scratch. We also release a family of LLM-as-a-Judge (7B and 32B) evaluators trained for nuanced assessment of generative outputs. This approach provides scalable, interpretable evaluation and annotation tools for model development, effectively replacing costly and less precise human judgments.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.24616",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "$texttt{SPECS}$: Faster Test-Time Scaling through Speculative Drafts",
    "description": "arXiv:2506.15733v1 Announce Type: new Abstract: Scaling test-time compute has driven the recent advances in the reasoning capabilities of large language models (LLMs), typically by allocating additional computation for more thorough exploration. However, increased compute often comes at the expense of higher user-facing latency, directly impacting user experience. Current test-time scaling methods primarily optimize for accuracy based on total compute resources (FLOPS), often overlooking latency constraints. To address this gap, we propose $texttt{SPECS}$, a latency-aware test-time scaling method inspired by speculative decoding. $texttt{SPECS}$~uses a smaller, faster model to generate candidate sequences efficiently, and evaluates these candidates using signals from both a larger target model and a dedicated reward model. We introduce new integration strategies, including reward-guided soft verification and a reward-based deferral mechanism. Empirical results on MATH500, AMC23 and OlympiadBench datasets show that $texttt{SPECS}$~matches or surpasses beam search accuracy while reducing latency by up to $sim$19.1%. Our theoretical analysis shows that our algorithm converges to the solution of a KL-regularized reinforcement learning objective with increasing beam width.",
    "summary": "arXiv:2506.15733v1 Announce Type: new Abstract: Scaling test-time compute has driven the recent advances in the reasoning capabilities of large language models (LLMs), typically by allocating additional computation for more thorough exploration. However, increased compute often comes at the expense of higher user-facing latency, directly impacting user experience. Current test-time scaling methods primarily optimize for accuracy based on total compute resources (FLOPS), often overlooking latency constraints. To address this gap, we propose $texttt{SPECS}$, a latency-aware test-time scaling method inspired by speculative decoding. $texttt{SPECS}$~uses a smaller, faster model to generate candidate sequences efficiently, and evaluates these candidates using signals from both a larger target model and a dedicated reward model. We introduce new integration strategies, including reward-guided soft verification and a reward-based deferral mechanism. Empirical results on MATH500, AMC23 and OlympiadBench datasets show that $texttt{SPECS}$~matches or surpasses beam search accuracy while reducing latency by up to $sim$19.1%. Our theoretical analysis shows that our algorithm converges to the solution of a KL-regularized reinforcement learning objective with increasing beam width.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15733",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Preference Tuning LLMs with Direct Preference Optimization Methods",
    "description": "",
    "summary": "Preference Tuning LLMs with Direct Preference Optimization Methods Addendum After consulting with th...",
    "pubDate": "Thu, 18 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pref-tuning",
    "thumbnail": "https://huggingface.co/blog/assets/pref-tuning/thumbnail.jpg"
  },
  {
    "title": "HealthQA-BR: A System-Wide Benchmark Reveals Critical Knowledge Gaps in Large Language Models",
    "description": "arXiv:2506.21578v1 Announce Type: cross Abstract: The evaluation of Large Language Models (LLMs) in healthcare has been dominated by physician-centric, English-language benchmarks, creating a dangerous illusion of competence that ignores the interprofessional nature of patient care. To provide a more holistic and realistic assessment, we introduce HealthQA-BR, the first large-scale, system-wide benchmark for Portuguese-speaking healthcare. Comprising 5,632 questions from Brazil's national licensing and residency exams, it uniquely assesses knowledge not only in medicine and its specialties but also in nursing, dentistry, psychology, social work, and other allied health professions. We conducted a rigorous zero-shot evaluation of over 20 leading LLMs. Our results reveal that while state-of-the-art models like GPT 4.1 achieve high overall accuracy (86.6%), this top-line score masks alarming, previously unmeasured deficiencies. A granular analysis shows performance plummets from near-perfect in specialties like Ophthalmology (98.7%) to barely passing in Neurosurgery (60.0%) and, most notably, Social Work (68.4%). This 'spiky' knowledge profile is a systemic issue observed across all models, demonstrating that high-level scores are insufficient for safety validation. By publicly releasing HealthQA-BR and our evaluation suite, we provide a crucial tool to move beyond single-score evaluations and toward a more honest, granular audit of AI readiness for the entire healthcare team.",
    "summary": "arXiv:2506.21578v1 Announce Type: cross Abstract: The evaluation of Large Language Models (LLMs) in healthcare has been dominated by physician-centric, English-language benchmarks, creating a dangerous illusion of competence that ignores the interprofessional nature of patient care. To provide a more holistic and realistic assessment, we introduce HealthQA-BR, the first large-scale, system-wide benchmark for Portuguese-speaking healthcare. Comprising 5,632 questions from Brazil's national licensing and residency exams, it uniquely assesses knowledge not only in medicine and its specialties but also in nursing, dentistry, psychology, social work, and other allied health professions. We conducted a rigorous zero-shot evaluation of over 20 leading LLMs. Our results reveal that while state-of-the-art models like GPT 4.1 achieve high overall accuracy (86.6%), this top-line score masks alarming, previously unmeasured deficiencies. A granular analysis shows performance plummets from near-perfect in specialties like Ophthalmology (98.7%) to barely passing in Neurosurgery (60.0%) and, most notably, Social Work (68.4%). This 'spiky' knowledge profile is a systemic issue observed across all models, demonstrating that high-level scores are insufficient for safety validation. By publicly releasing HealthQA-BR and our evaluation suite, we provide a crucial tool to move beyond single-score evaluations and toward a more honest, granular audit of AI readiness for the entire healthcare team.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21578",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Do LLMs Know When to Flip a Coin? Strategic Randomization through Reasoning and Experience",
    "description": "arXiv:2506.18928v1 Announce Type: new Abstract: Strategic randomization is a key principle in game theory, yet it remains underexplored in large language models (LLMs). Prior work often conflates the cognitive decision to randomize with the mechanical generation of randomness, leading to incomplete evaluations. To address this, we propose a novel zero-sum game inspired by the Tian Ji Horse Race, where the Nash equilibrium corresponds to a maximal entropy strategy. The game's complexity masks this property from untrained humans and underdeveloped LLMs. We evaluate five LLMs across prompt styles -- framed, neutral, and hinted -- using competitive multi-tournament gameplay with system-provided random choices, isolating the decision to randomize. Results show that weaker models remain deterministic regardless of prompts, while stronger models exhibit increased randomization under explicit hints. When facing weaker models, strong LLMs adopt deterministic strategies to exploit biases, but converge toward equilibrium play when facing peers. Through win/loss outcomes and Bayes factor analysis, we demonstrate meaningful variation in LLMs' strategic reasoning capabilities, highlighting opportunities for improvement in abstract reasoning and adaptive learning. We make our implementation publicly available at https://github.com/ocelopus/llm-when-to-throw-coin to ensure full reproducibility.",
    "summary": "arXiv:2506.18928v1 Announce Type: new Abstract: Strategic randomization is a key principle in game theory, yet it remains underexplored in large language models (LLMs). Prior work often conflates the cognitive decision to randomize with the mechanical generation of randomness, leading to incomplete evaluations. To address this, we propose a novel zero-sum game inspired by the Tian Ji Horse Race, where the Nash equilibrium corresponds to a maximal entropy strategy. The game's complexity masks this property from untrained humans and underdeveloped LLMs. We evaluate five LLMs across prompt styles -- framed, neutral, and hinted -- using competitive multi-tournament gameplay with system-provided random choices, isolating the decision to randomize. Results show that weaker models remain deterministic regardless of prompts, while stronger models exhibit increased randomization under explicit hints. When facing weaker models, strong LLMs adopt deterministic strategies to exploit biases, but converge toward equilibrium play when facing peers. Through win/loss outcomes and Bayes factor analysis, we demonstrate meaningful variation in LLMs' strategic reasoning capabilities, highlighting opportunities for improvement in abstract reasoning and adaptive learning. We make our implementation publicly available at https://github.com/ocelopus/llm-when-to-throw-coin to ensure full reproducibility.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18928",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Controlling Language Model Generation with NVIDIA's LogitsProcessorZoo",
    "description": "",
    "summary": "Controlling Language Model Generation with NVIDIA's LogitsProcessorZoo Generating text with language...",
    "pubDate": "Mon, 23 Dec 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/logits-processor-zoo",
    "thumbnail": "https://huggingface.co/blog/assets/logits-processor-zoo/thumbnail.png"
  },
  {
    "title": "Optimization story: Bloom inference",
    "description": "",
    "summary": "Optimization story: Bloom inference This article gives you the behind-the-scenes of how we made an e...",
    "pubDate": "Wed, 12 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bloom-inference-optimization",
    "thumbnail": "https://huggingface.co/blog/assets/bloom-inference-pytorch-scripts/thumbnail.png"
  },
  {
    "title": "TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs",
    "description": "arXiv:2506.16990v1 Announce Type: cross Abstract: LaTeX's precision and flexibility in typesetting have made it the gold standard for the preparation of scientific documentation. Large Language Models (LLMs) present a promising opportunity for researchers to produce publication-ready material using LaTeX with natural language instructions, yet current benchmarks completely lack evaluation of this ability. By introducing TeXpert, our benchmark dataset with natural language prompts for generating LaTeX code focused on components of scientific documents across multiple difficulty levels, we conduct an in-depth analysis of LLM performance in this regard and identify frequent error types. Our evaluation across open and closed-source LLMs highlights multiple key findings: LLMs excelling on standard benchmarks perform poorly in LaTeX generation with a significant accuracy drop-off as the complexity of tasks increases; open-source models like DeepSeek v3 and DeepSeek Coder strongly rival closed-source counterparts in LaTeX tasks; and formatting and package errors are unexpectedly prevalent, suggesting a lack of diverse LaTeX examples in the training datasets of most LLMs. Our dataset, code, and model evaluations are available at https://github.com/knowledge-verse-ai/TeXpert.",
    "summary": "arXiv:2506.16990v1 Announce Type: cross Abstract: LaTeX's precision and flexibility in typesetting have made it the gold standard for the preparation of scientific documentation. Large Language Models (LLMs) present a promising opportunity for researchers to produce publication-ready material using LaTeX with natural language instructions, yet current benchmarks completely lack evaluation of this ability. By introducing TeXpert, our benchmark dataset with natural language prompts for generating LaTeX code focused on components of scientific documents across multiple difficulty levels, we conduct an in-depth analysis of LLM performance in this regard and identify frequent error types. Our evaluation across open and closed-source LLMs highlights multiple key findings: LLMs excelling on standard benchmarks perform poorly in LaTeX generation with a significant accuracy drop-off as the complexity of tasks increases; open-source models like DeepSeek v3 and DeepSeek Coder strongly rival closed-source counterparts in LaTeX tasks; and formatting and package errors are unexpectedly prevalent, suggesting a lack of diverse LaTeX examples in the training datasets of most LLMs. Our dataset, code, and model evaluations are available at https://github.com/knowledge-verse-ai/TeXpert.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16990",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Guaranteed prediction sets for functional surrogate models",
    "description": "arXiv:2501.18426v2 Announce Type: replace-cross Abstract: We propose a method for obtaining statistically guaranteed prediction sets for functional machine learning methods: surrogate models which map between function spaces, motivated by the need to build reliable PDE emulators. The method constructs nested prediction sets on a low-dimensional representation (an SVD) of the surrogate model's error, and then maps these sets to the prediction space using set-propagation techniques. This results in prediction sets for functional surrogate models with conformal prediction coverage guarantees. We use zonotopes as basis of the set construction, which allow an exact linear propagation and are closed under Cartesian products, making them well-suited to this high-dimensional problem. The method is model agnostic and can thus be applied to complex Sci-ML models, including Neural Operators, but also in simpler settings. We also introduce a technique to capture the truncation error of the SVD, preserving the guarantees of the method.",
    "summary": "arXiv:2501.18426v2 Announce Type: replace-cross Abstract: We propose a method for obtaining statistically guaranteed prediction sets for functional machine learning methods: surrogate models which map between function spaces, motivated by the need to build reliable PDE emulators. The method constructs nested prediction sets on a low-dimensional representation (an SVD) of the surrogate model's error, and then maps these sets to the prediction space using set-propagation techniques. This results in prediction sets for functional surrogate models with conformal prediction coverage guarantees. We use zonotopes as basis of the set construction, which allow an exact linear propagation and are closed under Cartesian products, making them well-suited to this high-dimensional problem. The method is model agnostic and can thus be applied to complex Sci-ML models, including Neural Operators, but also in simpler settings. We also introduce a technique to capture the truncation error of the SVD, preserving the guarantees of the method.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.18426",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DALL¬∑E 2 pre-training mitigations",
    "description": "In order to share the magic of¬†DALL¬∑E 2¬†with a broad audience, we needed to reduce the risks associated with powerful image generation models. To this end, we put various¬†guardrails¬†in place to prevent generated images from violating our¬†content policy.",
    "summary": "In order to share the magic of¬†DALL¬∑E 2¬†with a broad audience, we needed to reduce the risks associated with powerful image generation models. To this end, we put various¬†guardrails¬†in place to prevent generated images from violating our¬†content policy.",
    "pubDate": "Tue, 28 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-pre-training-mitigations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree",
    "description": "arXiv:2506.15655v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) has become essential for large-scale code generation, grounding predictions in external code corpora to improve actuality. However, a critical yet underexplored aspect of RAG pipelines is chunking -- the process of dividing documents into retrievable units. Existing line-based chunking heuristics often break semantic structures, splitting functions or merging unrelated code, which can degrade generation quality. We propose chunking via Abstract Syntax Trees (ourwork), a structure-aware method that recursively breaks large AST nodes into smaller chunks and merges sibling nodes while respecting size limits. This approach generates self-contained, semantically coherent units across programming languages and tasks, improving performance on diverse code generation tasks, e.g., boosting Recall@5 by 4.3 points on RepoEval retrieval and Pass@1 by 2.67 points on SWE-bench generation. Our work highlights the importance of structure-aware chunking for scaling retrieval-enhanced code intelligence.",
    "summary": "arXiv:2506.15655v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) has become essential for large-scale code generation, grounding predictions in external code corpora to improve actuality. However, a critical yet underexplored aspect of RAG pipelines is chunking -- the process of dividing documents into retrievable units. Existing line-based chunking heuristics often break semantic structures, splitting functions or merging unrelated code, which can degrade generation quality. We propose chunking via Abstract Syntax Trees (ourwork), a structure-aware method that recursively breaks large AST nodes into smaller chunks and merges sibling nodes while respecting size limits. This approach generates self-contained, semantically coherent units across programming languages and tasks, improving performance on diverse code generation tasks, e.g., boosting Recall@5 by 4.3 points on RepoEval retrieval and Pass@1 by 2.67 points on SWE-bench generation. Our work highlights the importance of structure-aware chunking for scaling retrieval-enhanced code intelligence.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15655",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Stable Diffusion in JAX/Flax üöÄ",
    "description": "",
    "summary": "üß® Stable Diffusion in JAX / Flax ! ü§ó Hugging Face Diffusers supports Flax since version 0.5.1 ! This...",
    "pubDate": "Thu, 13 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/stable_diffusion_jax",
    "thumbnail": "https://huggingface.co/blog/assets/108_stable_diffusion_jax/thumbnail.png"
  },
  {
    "title": "Creating agent and human collaboration with GPT 4o",
    "description": "Altera uses GPT-4o to build a new area of human collaboration",
    "summary": "Altera uses GPT-4o to build a new area of human collaboration",
    "pubDate": "Tue, 01 Oct 2024 09:59:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/altera",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Using LoRA for Efficient Stable Diffusion Fine-Tuning",
    "description": "",
    "summary": "Using LoRA for Efficient Stable Diffusion Fine-Tuning LoRA: Low-Rank Adaptation of Large Language Mo...",
    "pubDate": "Thu, 26 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/lora",
    "thumbnail": "https://huggingface.co/blog/assets/lora/thumbnail.png"
  },
  {
    "title": "Efficient Transformations in Deep Learning Convolutional Neural Networks",
    "description": "arXiv:2506.16418v1 Announce Type: cross Abstract: This study investigates the integration of signal processing transformations -- Fast Fourier Transform (FFT), Walsh-Hadamard Transform (WHT), and Discrete Cosine Transform (DCT) -- within the ResNet50 convolutional neural network (CNN) model for image classification. The primary objective is to assess the trade-offs between computational efficiency, energy consumption, and classification accuracy during training and inference. Using the CIFAR-100 dataset (100 classes, 60,000 images), experiments demonstrated that incorporating WHT significantly reduced energy consumption while improving accuracy. Specifically, a baseline ResNet50 model achieved a testing accuracy of 66%, consuming an average of 25,606 kJ per model. In contrast, a modified ResNet50 incorporating WHT in the early convolutional layers achieved 74% accuracy, and an enhanced version with WHT applied to both early and late layers achieved 79% accuracy, with an average energy consumption of only 39 kJ per model. These results demonstrate the potential of WHT as a highly efficient and effective approach for energy-constrained CNN applications.",
    "summary": "arXiv:2506.16418v1 Announce Type: cross Abstract: This study investigates the integration of signal processing transformations -- Fast Fourier Transform (FFT), Walsh-Hadamard Transform (WHT), and Discrete Cosine Transform (DCT) -- within the ResNet50 convolutional neural network (CNN) model for image classification. The primary objective is to assess the trade-offs between computational efficiency, energy consumption, and classification accuracy during training and inference. Using the CIFAR-100 dataset (100 classes, 60,000 images), experiments demonstrated that incorporating WHT significantly reduced energy consumption while improving accuracy. Specifically, a baseline ResNet50 model achieved a testing accuracy of 66%, consuming an average of 25,606 kJ per model. In contrast, a modified ResNet50 incorporating WHT in the early convolutional layers achieved 74% accuracy, and an enhanced version with WHT applied to both early and late layers achieved 79% accuracy, with an average energy consumption of only 39 kJ per model. These results demonstrate the potential of WHT as a highly efficient and effective approach for energy-constrained CNN applications.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16418",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "2024 Security Feature Highlights",
    "description": "",
    "summary": "2024 Security Feature Highlights Security is a top priority at Hugging Face, and we're committed to ...",
    "pubDate": "Tue, 06 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/2024-security-features",
    "thumbnail": "https://huggingface.co/blog/assets/2024-security-features/thumbnail.png"
  },
  {
    "title": "Learning from human preferences",
    "description": "One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind‚Äôs safety team, we‚Äôve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better.",
    "summary": "One step towards building safe AI systems is to remove the need for humans to write goal functions, since using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even dangerous behavior. In collaboration with DeepMind‚Äôs safety team, we‚Äôve developed an algorithm which can infer what humans want by being told which of two proposed behaviors is better.",
    "pubDate": "Tue, 13 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-from-human-preferences",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Put AI to work: Automate and Scale Financial Operations",
    "description": "Put AI to work: Automate and Scale Financial Operations",
    "summary": "Put AI to work: Automate and Scale Financial Operations",
    "pubDate": "Mon, 30 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/put-ai-to-work-automate-and-scale-financial-operations",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Taking a responsible path to AGI",
    "description": "We‚Äôre exploring the frontiers of AGI, prioritizing technical safety, proactive risk assessment, and collaboration with the AI community.",
    "summary": "We‚Äôre exploring the frontiers of AGI, prioritizing technical safety, proactive risk assessment, and collaboration with the AI community.",
    "pubDate": "Wed, 02 Apr 2025 13:31:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/taking-a-responsible-path-to-agi/",
    "thumbnail": "https://lh3.googleusercontent.com/0sOE0EshCImNhSW7FRZvw-v_eyJJt_WUEh9evgRbhB4tl0o7qY2VAJdAloF5q3Q6CKTCiXdEvv1kUfsyZz8h6rR7Rl9jUhH02ADOyl7A7w-0QDWWr1Y=w1200-h630-n-nu"
  },
  {
    "title": "Hybrid Attention Network for Accurate Breast Tumor Segmentation in Ultrasound Images",
    "description": "arXiv:2506.16592v1 Announce Type: cross Abstract: Breast ultrasound imaging is a valuable tool for early breast cancer detection, but automated tumor segmentation is challenging due to inherent noise, variations in scale of lesions, and fuzzy boundaries. To address these challenges, we propose a novel hybrid attention-based network for lesion segmentation. Our proposed architecture integrates a pre-trained DenseNet121 in the encoder part for robust feature extraction with a multi-branch attention-enhanced decoder tailored for breast ultrasound images. The bottleneck incorporates Global Spatial Attention (GSA), Position Encoding (PE), and Scaled Dot-Product Attention (SDPA) to learn global context, spatial relationships, and relative positional features. The Spatial Feature Enhancement Block (SFEB) is embedded at skip connections to refine and enhance spatial features, enabling the network to focus more effectively on tumor regions. A hybrid loss function combining Binary Cross-Entropy (BCE) and Jaccard Index loss optimizes both pixel-level accuracy and region-level overlap metrics, enhancing robustness to class imbalance and irregular tumor shapes. Experiments on public datasets demonstrate that our method outperforms existing approaches, highlighting its potential to assist radiologists in early and accurate breast cancer diagnosis.",
    "summary": "arXiv:2506.16592v1 Announce Type: cross Abstract: Breast ultrasound imaging is a valuable tool for early breast cancer detection, but automated tumor segmentation is challenging due to inherent noise, variations in scale of lesions, and fuzzy boundaries. To address these challenges, we propose a novel hybrid attention-based network for lesion segmentation. Our proposed architecture integrates a pre-trained DenseNet121 in the encoder part for robust feature extraction with a multi-branch attention-enhanced decoder tailored for breast ultrasound images. The bottleneck incorporates Global Spatial Attention (GSA), Position Encoding (PE), and Scaled Dot-Product Attention (SDPA) to learn global context, spatial relationships, and relative positional features. The Spatial Feature Enhancement Block (SFEB) is embedded at skip connections to refine and enhance spatial features, enabling the network to focus more effectively on tumor regions. A hybrid loss function combining Binary Cross-Entropy (BCE) and Jaccard Index loss optimizes both pixel-level accuracy and region-level overlap metrics, enhancing robustness to class imbalance and irregular tumor shapes. Experiments on public datasets demonstrate that our method outperforms existing approaches, highlighting its potential to assist radiologists in early and accurate breast cancer diagnosis.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16592",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing more enterprise-grade features for API customers",
    "description": "Increasing enterprise support with more security features and controls, updates to our Assistants API, and tools to better manage costs.",
    "summary": "Increasing enterprise support with more security features and controls, updates to our Assistants API, and tools to better manage costs.",
    "pubDate": "Tue, 23 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/more-enterprise-grade-features-for-api-customers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Spinning Up in Deep RL",
    "description": "We‚Äôre releasing Spinning Up in Deep RL, an educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning. Spinning Up consists of crystal-clear examples of RL code, educational exercises, documentation, and¬†tutorials.",
    "summary": "We‚Äôre releasing Spinning Up in Deep RL, an educational resource designed to let anyone learn to become a skilled practitioner in deep reinforcement learning. Spinning Up consists of crystal-clear examples of RL code, educational exercises, documentation, and¬†tutorials.",
    "pubDate": "Thu, 08 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/spinning-up-in-deep-rl",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How to generate text: using different decoding methods for language generation with Transformers",
    "description": "",
    "summary": "How to generate text: using different decoding methods for language generation with Transformers Not...",
    "pubDate": "Sun, 01 Mar 2020 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-generate",
    "thumbnail": "https://huggingface.co/blog/assets/02_how-to-generate/thumbnail.png"
  },
  {
    "title": "Ignition Phase : Standard Training for Fast Adversarial Robustness",
    "description": "arXiv:2506.15685v1 Announce Type: cross Abstract: Adversarial Training (AT) is a cornerstone defense, but many variants overlook foundational feature representations by primarily focusing on stronger attack generation. We introduce Adversarial Evolution Training (AET), a simple yet powerful framework that strategically prepends an Empirical Risk Minimization (ERM) phase to conventional AT. We hypothesize this initial ERM phase cultivates a favorable feature manifold, enabling more efficient and effective robustness acquisition. Empirically, AET achieves comparable or superior robustness more rapidly, improves clean accuracy, and cuts training costs by 8-25%. Its effectiveness is shown across multiple datasets, architectures, and when augmenting established AT methods. Our findings underscore the impact of feature pre-conditioning via standard training for developing more efficient, principled robust defenses. Code is available in the supplementary material.",
    "summary": "arXiv:2506.15685v1 Announce Type: cross Abstract: Adversarial Training (AT) is a cornerstone defense, but many variants overlook foundational feature representations by primarily focusing on stronger attack generation. We introduce Adversarial Evolution Training (AET), a simple yet powerful framework that strategically prepends an Empirical Risk Minimization (ERM) phase to conventional AT. We hypothesize this initial ERM phase cultivates a favorable feature manifold, enabling more efficient and effective robustness acquisition. Empirically, AET achieves comparable or superior robustness more rapidly, improves clean accuracy, and cuts training costs by 8-25%. Its effectiveness is shown across multiple datasets, architectures, and when augmenting established AT methods. Our findings underscore the impact of feature pre-conditioning via standard training for developing more efficient, principled robust defenses. Code is available in the supplementary material.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15685",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Saving lives with AI health coaching",
    "description": "Healthify collaborates with OpenAI to improve millions of lives with sustainable weight loss.",
    "summary": "Healthify collaborates with OpenAI to improve millions of lives with sustainable weight loss.",
    "pubDate": "Wed, 13 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/healthify",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "How we used generative media at I/O 2025",
    "description": "Video showing the I/O opening film.",
    "summary": "Video showing the I/O opening film.",
    "pubDate": "Tue, 10 Jun 2025 17:00:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/generative-ai-io-keynote-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/thumbnail_opener_hero.width-1300.png"
  },
  {
    "title": "Grounding Language Models with Semantic Digital Twins for Robotic Planning",
    "description": "arXiv:2506.16493v1 Announce Type: cross Abstract: We introduce a novel framework that integrates Semantic Digital Twins (SDTs) with Large Language Models (LLMs) to enable adaptive and goal-driven robotic task execution in dynamic environments. The system decomposes natural language instructions into structured action triplets, which are grounded in contextual environmental data provided by the SDT. This semantic grounding allows the robot to interpret object affordances and interaction rules, enabling action planning and real-time adaptability. In case of execution failures, the LLM utilizes error feedback and SDT insights to generate recovery strategies and iteratively revise the action plan. We evaluate our approach using tasks from the ALFRED benchmark, demonstrating robust performance across various household scenarios. The proposed framework effectively combines high-level reasoning with semantic environment understanding, achieving reliable task completion in the face of uncertainty and failure.",
    "summary": "arXiv:2506.16493v1 Announce Type: cross Abstract: We introduce a novel framework that integrates Semantic Digital Twins (SDTs) with Large Language Models (LLMs) to enable adaptive and goal-driven robotic task execution in dynamic environments. The system decomposes natural language instructions into structured action triplets, which are grounded in contextual environmental data provided by the SDT. This semantic grounding allows the robot to interpret object affordances and interaction rules, enabling action planning and real-time adaptability. In case of execution failures, the LLM utilizes error feedback and SDT insights to generate recovery strategies and iteratively revise the action plan. We evaluate our approach using tasks from the ALFRED benchmark, demonstrating robust performance across various household scenarios. The proposed framework effectively combines high-level reasoning with semantic environment understanding, achieving reliable task completion in the face of uncertainty and failure.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16493",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Generalizing from simulation",
    "description": "Our latest robotics techniques allow robot controllers, trained entirely in simulation and deployed on physical robots, to react to unplanned changes in the environment as they solve simple tasks. That is, we‚Äôve used these techniques to build closed-loop systems rather than open-loop ones as before.",
    "summary": "Our latest robotics techniques allow robot controllers, trained entirely in simulation and deployed on physical robots, to react to unplanned changes in the environment as they solve simple tasks. That is, we‚Äôve used these techniques to build closed-loop systems rather than open-loop ones as before.",
    "pubDate": "Thu, 19 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generalizing-from-simulation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FuzzAug: Data Augmentation by Coverage-guided Fuzzing for Neural Test Generation",
    "description": "arXiv:2406.08665v3 Announce Type: replace-cross Abstract: Testing is essential to modern software engineering for building reliable software. Given the high costs of manually creating test cases, automated test case generation, particularly methods utilizing large language models, has become increasingly popular. These neural approaches generate semantically meaningful tests that are more maintainable compared with traditional automatic testing methods like fuzzing. However, the diversity and volume of unit tests in current datasets are limited, especially for newer but important languages. In this paper, we present a novel data augmentation technique, FuzzAug, that introduces the benefits of fuzzing to large language models by introducing valid testing semantics and providing diverse coverage-guided inputs. Doubling the size of training datasets, FuzzAug improves the performance from the baselines significantly. This technique demonstrates the potential of introducing prior knowledge from dynamic software analysis to improve neural test generation, offering significant enhancements in neural test generation.",
    "summary": "arXiv:2406.08665v3 Announce Type: replace-cross Abstract: Testing is essential to modern software engineering for building reliable software. Given the high costs of manually creating test cases, automated test case generation, particularly methods utilizing large language models, has become increasingly popular. These neural approaches generate semantically meaningful tests that are more maintainable compared with traditional automatic testing methods like fuzzing. However, the diversity and volume of unit tests in current datasets are limited, especially for newer but important languages. In this paper, we present a novel data augmentation technique, FuzzAug, that introduces the benefits of fuzzing to large language models by introducing valid testing semantics and providing diverse coverage-guided inputs. Doubling the size of training datasets, FuzzAug improves the performance from the baselines significantly. This technique demonstrates the potential of introducing prior knowledge from dynamic software analysis to improve neural test generation, offering significant enhancements in neural test generation.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.08665",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Mastering Stratego, the classic game of imperfect information",
    "description": "Game-playing artificial intelligence (AI) systems have advanced to a new frontier.",
    "summary": "Game-playing artificial intelligence (AI) systems have advanced to a new frontier.",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/mastering-stratego-the-classic-game-of-imperfect-information/",
    "thumbnail": "https://lh3.googleusercontent.com/nvWTaah_1s2OEAt4CsxX5gKok_0V6-Q5eH3aW3GF6YyZdEVM0OBdgFxNa4DAbmUCXpvTqTfslfUB7_3ZBYr6kIQuk2u46khXH41IU16EZghstwt72Mk=w1200-h630-n-nu"
  },
  {
    "title": "Announcing Gemma 3n preview: Powerful, efficient, mobile-first AI",
    "description": "Gemma 3n is a cutting-edge open model designed for fast, multimodal AI on devices, featuring optimized performance, unique flexibility with a 2-in-1 model, and expanded multimodal understanding with audio, empowering developers to build live, interactive applications and sophisticated audio-centric experiences.",
    "summary": "Gemma 3n is a cutting-edge open model designed for fast, multimodal AI on devices, featuring optimized performance, unique flexibility with a 2-in-1 model, and expanded multimodal understanding with audio, empowering developers to build live, interactive applications and sophisticated audio-centric experiences.",
    "pubDate": "Tue, 20 May 2025 09:45:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/announcing-gemma-3n-preview-powerful-efficient-mobile-first-ai/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemma3n_Metadatal_RD2-V01.2e16d0ba.fill-1200x600.jpg"
  },
  {
    "title": "Consistent Sampling and Simulation: Molecular Dynamics with Energy-Based Diffusion Models",
    "description": "arXiv:2506.17139v1 Announce Type: cross Abstract: Diffusion models have recently gained significant attention due to their effectiveness in various scientific domains, including biochemistry. When trained on equilibrium molecular distributions, diffusion models provide both: a generative procedure to sample equilibrium conformations and associated forces derived from the model's scores. However, using the forces for coarse-grained molecular dynamics simulations uncovers inconsistencies in the samples generated via classical diffusion inference and simulation, despite both originating from the same model. Particularly at the small diffusion timesteps required for simulations, diffusion models fail to satisfy the Fokker-Planck equation, which governs how the score should evolve over time. We interpret this deviation as an indication of the observed inconsistencies and propose an energy-based diffusion model with a Fokker-Planck-derived regularization term enforcing consistency. We demonstrate the effectiveness of our approach on toy systems, alanine dipeptide, and introduce a state-of-the-art transferable Boltzmann emulator for dipeptides that supports simulation and demonstrates enhanced consistency and efficient sampling.",
    "summary": "arXiv:2506.17139v1 Announce Type: cross Abstract: Diffusion models have recently gained significant attention due to their effectiveness in various scientific domains, including biochemistry. When trained on equilibrium molecular distributions, diffusion models provide both: a generative procedure to sample equilibrium conformations and associated forces derived from the model's scores. However, using the forces for coarse-grained molecular dynamics simulations uncovers inconsistencies in the samples generated via classical diffusion inference and simulation, despite both originating from the same model. Particularly at the small diffusion timesteps required for simulations, diffusion models fail to satisfy the Fokker-Planck equation, which governs how the score should evolve over time. We interpret this deviation as an indication of the observed inconsistencies and propose an energy-based diffusion model with a Fokker-Planck-derived regularization term enforcing consistency. We demonstrate the effectiveness of our approach on toy systems, alanine dipeptide, and introduce a state-of-the-art transferable Boltzmann emulator for dipeptides that supports simulation and demonstrates enhanced consistency and efficient sampling.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17139",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "One Sample is Enough to Make Conformal Prediction Robust",
    "description": "arXiv:2506.16553v1 Announce Type: cross Abstract: Given any model, conformal prediction (CP) returns prediction sets guaranteed to include the true label with high adjustable probability. Robust CP (RCP) extends this to inputs with worst-case noise. A well-established approach is to use randomized smoothing for RCP since it is applicable to any black-box model and provides smaller sets compared to deterministic methods. However, current smoothing-based RCP requires many model forward passes per each input which is computationally expensive. We show that conformal prediction attains some robustness even with a forward pass on a single randomly perturbed input. Using any binary certificate we propose a single sample robust CP (RCP1). Our approach returns robust sets with smaller average set size compared to SOTA methods which use many (e.g. around 100) passes per input. Our key insight is to certify the conformal prediction procedure itself rather than individual scores. Our approach is agnostic to the setup (classification and regression). We further extend our approach to smoothing-based robust conformal risk control.",
    "summary": "arXiv:2506.16553v1 Announce Type: cross Abstract: Given any model, conformal prediction (CP) returns prediction sets guaranteed to include the true label with high adjustable probability. Robust CP (RCP) extends this to inputs with worst-case noise. A well-established approach is to use randomized smoothing for RCP since it is applicable to any black-box model and provides smaller sets compared to deterministic methods. However, current smoothing-based RCP requires many model forward passes per each input which is computationally expensive. We show that conformal prediction attains some robustness even with a forward pass on a single randomly perturbed input. Using any binary certificate we propose a single sample robust CP (RCP1). Our approach returns robust sets with smaller average set size compared to SOTA methods which use many (e.g. around 100) passes per input. Our key insight is to certify the conformal prediction procedure itself rather than individual scores. Our approach is agnostic to the setup (classification and regression). We further extend our approach to smoothing-based robust conformal risk control.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16553",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing IDEFICS: An Open Reproduction of State-of-the-art Visual Language Model",
    "description": "",
    "summary": "Introducing IDEFICS: An Open Reproduction of State-of-the-Art Visual Language Model We are excited t...",
    "pubDate": "Tue, 22 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/idefics",
    "thumbnail": "https://huggingface.co/blog/assets/idefics/thumbnail.png"
  },
  {
    "title": "SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications",
    "description": "arXiv:2506.18951v1 Announce Type: cross Abstract: Resolution of complex SQL issues persists as a significant bottleneck in real-world database applications. Current Large Language Models (LLMs), while adept at text-to-SQL translation, have not been rigorously evaluated on the more challenging task of debugging SQL issues. To address this gap, we introduce BIRD-CRITIC, a new SQL issue debugging benchmark comprising 530 PostgreSQL tasks (BIRD-CRITIC-PG) and 570 multi-dialect tasks (BIRD-CRITIC-Multi), distilled from authentic user issues and replayed within new environments to facilitate rigorous evaluation. Baseline evaluations underscore the task's complexity, with the leading reasoning model O3-Mini achieving only 38.87% success rate on BIRD-CRITIC-PG and 33.33% on BIRD-CRITIC-Multi. Meanwhile, advancing open-source models for database tasks is crucial for empowering local development while safeguarding data privacy. Therefore, we present Six-Gym (Sql-fIX-Gym), a training environment for elevating open-source model capabilities for SQL issue debugging. This environment leverages SQL-Rewind strategy, which automatically generates executable issue-solution datasets by reverse-engineering issues from verified SQLs. However, popular trajectory-based fine-tuning methods do not explore substantial supervisory signals. We further propose f-Plan Boosting, which extracts high-level debugging plans from SQL solutions, enabling teacher LLMs to produce 73.7% more successful trajectories for training. We integrate these components into an open-source agent, Bird-Fixer. Based on Qwen-2.5-Coder-14B, Bird-Fixer achieves 38.11% success rate on BIRD-CRITIC-PG and 29.65% on BIRD-CRITIC-Multi, surpassing leading proprietary models such as Claude-3.7-Sonnet and GPT-4.1, marking a significant step toward democratizing sophisticated SQL-debugging capabilities. The leaderboard and source code are available: https://bird-critic.github.io/",
    "summary": "arXiv:2506.18951v1 Announce Type: cross Abstract: Resolution of complex SQL issues persists as a significant bottleneck in real-world database applications. Current Large Language Models (LLMs), while adept at text-to-SQL translation, have not been rigorously evaluated on the more challenging task of debugging SQL issues. To address this gap, we introduce BIRD-CRITIC, a new SQL issue debugging benchmark comprising 530 PostgreSQL tasks (BIRD-CRITIC-PG) and 570 multi-dialect tasks (BIRD-CRITIC-Multi), distilled from authentic user issues and replayed within new environments to facilitate rigorous evaluation. Baseline evaluations underscore the task's complexity, with the leading reasoning model O3-Mini achieving only 38.87% success rate on BIRD-CRITIC-PG and 33.33% on BIRD-CRITIC-Multi. Meanwhile, advancing open-source models for database tasks is crucial for empowering local development while safeguarding data privacy. Therefore, we present Six-Gym (Sql-fIX-Gym), a training environment for elevating open-source model capabilities for SQL issue debugging. This environment leverages SQL-Rewind strategy, which automatically generates executable issue-solution datasets by reverse-engineering issues from verified SQLs. However, popular trajectory-based fine-tuning methods do not explore substantial supervisory signals. We further propose f-Plan Boosting, which extracts high-level debugging plans from SQL solutions, enabling teacher LLMs to produce 73.7% more successful trajectories for training. We integrate these components into an open-source agent, Bird-Fixer. Based on Qwen-2.5-Coder-14B, Bird-Fixer achieves 38.11% success rate on BIRD-CRITIC-PG and 29.65% on BIRD-CRITIC-Multi, surpassing leading proprietary models such as Claude-3.7-Sonnet and GPT-4.1, marking a significant step toward democratizing sophisticated SQL-debugging capabilities. The leaderboard and source code are available: https://bird-critic.github.io/",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18951",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Enhancing Security in LLM Applications: A Performance Evaluation of Early Detection Systems",
    "description": "arXiv:2506.19109v1 Announce Type: cross Abstract: Prompt injection threatens novel applications that emerge from adapting LLMs for various user tasks. The newly developed LLM-based software applications become more ubiquitous and diverse. However, the threat of prompt injection attacks undermines the security of these systems as the mitigation and defenses against them, proposed so far, are insufficient. We investigated the capabilities of early prompt injection detection systems, focusing specifically on the detection performance of techniques implemented in various open-source solutions. These solutions are supposed to detect certain types of prompt injection attacks, including the prompt leak. In prompt leakage attacks, an attacker maliciously manipulates the LLM into outputting its system instructions, violating the system's confidentiality. Our study presents analyzes of distinct prompt leakage detection techniques, and a comparative analysis of several detection solutions, which implement those techniques. We identify the strengths and weaknesses of these techniques and elaborate on their optimal configuration and usage in high-stake deployments. In one of the first studies on existing prompt leak detection solutions, we compared the performances of LLM Guard, Vigil, and Rebuff. We concluded that the implementations of canary word checks in Vigil and Rebuff were not effective at detecting prompt leak attacks, and we proposed improvements for them. We also found an evasion weakness in Rebuff's secondary model-based technique and proposed a mitigation. Then, the result of the comparison of LLM Guard, Vigil, and Rebuff at their peak performance revealed that Vigil is optimal for cases when minimal false positive rate is required, and Rebuff is the most optimal for average needs.",
    "summary": "arXiv:2506.19109v1 Announce Type: cross Abstract: Prompt injection threatens novel applications that emerge from adapting LLMs for various user tasks. The newly developed LLM-based software applications become more ubiquitous and diverse. However, the threat of prompt injection attacks undermines the security of these systems as the mitigation and defenses against them, proposed so far, are insufficient. We investigated the capabilities of early prompt injection detection systems, focusing specifically on the detection performance of techniques implemented in various open-source solutions. These solutions are supposed to detect certain types of prompt injection attacks, including the prompt leak. In prompt leakage attacks, an attacker maliciously manipulates the LLM into outputting its system instructions, violating the system's confidentiality. Our study presents analyzes of distinct prompt leakage detection techniques, and a comparative analysis of several detection solutions, which implement those techniques. We identify the strengths and weaknesses of these techniques and elaborate on their optimal configuration and usage in high-stake deployments. In one of the first studies on existing prompt leak detection solutions, we compared the performances of LLM Guard, Vigil, and Rebuff. We concluded that the implementations of canary word checks in Vigil and Rebuff were not effective at detecting prompt leak attacks, and we proposed improvements for them. We also found an evasion weakness in Rebuff's secondary model-based technique and proposed a mitigation. Then, the result of the comparison of LLM Guard, Vigil, and Rebuff at their peak performance revealed that Vigil is optimal for cases when minimal false positive rate is required, and Rebuff is the most optimal for average needs.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19109",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Ethics and Society Newsletter #2: Let's talk about bias!",
    "description": "",
    "summary": "Machine Learning in development: Let's talk about bias! Bias in ML is ubiquitous, and Bias in ML is ...",
    "pubDate": "Thu, 15 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ethics-soc-2",
    "thumbnail": "https://huggingface.co/blog/assets/122_ethics_soc_2/thumbnail-solstice.png"
  },
  {
    "title": "SmolLM - blazingly fast and remarkably powerful",
    "description": "",
    "summary": "SmolLM - blazingly fast and remarkably powerful TL;DR This blog post introduces SmolLM, a family of ...",
    "pubDate": "Tue, 16 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/smollm",
    "thumbnail": "https://huggingface.co/blog/assets/smollm/banner.png"
  },
  {
    "title": "Researchers teach LLMs to solve complex planning challenges",
    "description": "This new framework leverages a model‚Äôs reasoning abilities to create a ‚Äúsmart assistant‚Äù that finds the optimal solution to multistep problems.",
    "summary": "This new framework leverages a model‚Äôs reasoning abilities to create a ‚Äúsmart assistant‚Äù that finds the optimal solution to multistep problems.",
    "pubDate": "Wed, 02 Apr 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/researchers-teach-llms-to-solve-complex-planning-challenges-0402",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/MIT-Formalized-Programming-01-press.jpg"
  },
  {
    "title": "Deep double descent",
    "description": "We show that the¬†double¬†descent¬†phenomenon¬†occurs in CNNs, ResNets, and transformers: performance first improves, then gets worse, and then improves again with increasing model size, data size, or training time. This effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we don‚Äôt yet fully understand why it happens, and view further study of this phenomenon as an important research¬†direction.",
    "summary": "We show that the¬†double¬†descent¬†phenomenon¬†occurs in CNNs, ResNets, and transformers: performance first improves, then gets worse, and then improves again with increasing model size, data size, or training time. This effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we don‚Äôt yet fully understand why it happens, and view further study of this phenomenon as an important research¬†direction.",
    "pubDate": "Thu, 05 Dec 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deep-double-descent",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms",
    "description": "New AI agent evolves algorithms for math and practical applications in computing by combining the creativity of large language models with automated evaluators",
    "summary": "New AI agent evolves algorithms for math and practical applications in computing by combining the creativity of large language models with automated evaluators",
    "pubDate": "Wed, 14 May 2025 14:59:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/",
    "thumbnail": "https://lh3.googleusercontent.com/tG6-MqdlvhQ-z7ENzGxR-kpGPPdPHbJ8UZtbTP66Rxi0UftTFU1yAvaBCVuigYuKvESMeEFf4jqNBVENFcZXEUnj8SSqj8zsop8UHAl0eD9A-hUCvQ=w1200-h630-n-nu"
  },
  {
    "title": "Datadog„Åå„ÄåAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÊÑèÂøóÊ±∫ÂÆö„Éó„É≠„Çª„Çπ„Äç„ÇíÂèØË¶ñÂåñ„Åô„Çã„ÉÑ„Éº„É´„ÇíÁô∫Ë°®",
    "description": "DataDog„ÅØ„ÄÅ„ÄåLLM Observability„Äç„ÅÆÊñ∞Ê©üËÉΩ„ÇíÁô∫Ë°®„Åó„Åü„ÄÇAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÂãï‰ΩúÂÖ®‰Ωì„ÇíÂèØË¶ñÂåñ„Åô„Çã„Å®„Å®„ÇÇ„Å´„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÁÆ°ÁêÜ„Çí‰∏ÄÂÖÉÂåñ„Åô„Çã„Åü„ÇÅ„ÅÆ„Ç¨„Éê„Éä„É≥„Çπ‰ΩìÂà∂„ÅÆÊßãÁØâ„ÇÇÊîØÊè¥„Åô„Çã„Å®„ÅÑ„ÅÜ„ÄÇ",
    "summary": "DataDog„ÅØ„ÄÅ„ÄåLLM Observability„Äç„ÅÆÊñ∞Ê©üËÉΩ„ÇíÁô∫Ë°®„Åó„Åü„ÄÇAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÂãï‰ΩúÂÖ®‰Ωì„ÇíÂèØË¶ñÂåñ„Åô„Çã„Å®„Å®„ÇÇ„Å´„ÄÅAI„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÁÆ°ÁêÜ„Çí‰∏ÄÂÖÉÂåñ„Åô„Çã„Åü„ÇÅ„ÅÆ„Ç¨„Éê„Éä„É≥„Çπ‰ΩìÂà∂„ÅÆÊßãÁØâ„ÇÇÊîØÊè¥„Åô„Çã„Å®„ÅÑ„ÅÜ„ÄÇ",
    "pubDate": "Mon, 30 Jun 2025 08:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://atmarkit.itmedia.co.jp/ait/articles/2506/30/news042.html",
    "thumbnail": "https://image.itmedia.co.jp/ait/articles/2506/30/cover_news042.jpg"
  },
  {
    "title": "Using Stable Diffusion with Core ML on Apple Silicon",
    "description": "",
    "summary": "Using Stable Diffusion with Core ML on Apple Silicon Thanks to Apple engineers, you can now run Stab...",
    "pubDate": "Thu, 01 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/diffusers-coreml",
    "thumbnail": "https://huggingface.co/blog/assets/diffusers_coreml/thumbnail.png"
  },
  {
    "title": "OpenAI Pioneers Program",
    "description": "Advancing model performance and real world evaluation in applied domains.",
    "summary": "Advancing model performance and real world evaluation in applied domains.",
    "pubDate": "Wed, 09 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-pioneers-program",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Hugging Face Training Efficiency Through Packing with Flash Attention",
    "description": "",
    "summary": "Improving Hugging Face Training Efficiency Through Packing with Flash Attention TL;DR Training with ...",
    "pubDate": "Wed, 21 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/packing-with-FA2",
    "thumbnail": "https://huggingface.co/blog/assets/packing-with-FA2/thumbnail.png"
  },
  {
    "title": "daDPO: Distribution-Aware DPO for Distilling Conversational Abilities",
    "description": "arXiv:2506.15717v1 Announce Type: cross Abstract: Large language models (LLMs) have demonstrated exceptional performance across various applications, but their conversational abilities decline sharply as model size decreases, presenting a barrier to their deployment in resource-constrained environments. Knowledge distillation with Direct Preference Optimization (dDPO) has emerged as a promising approach to enhancing the conversational abilities of smaller models using a larger teacher model. However, current methods primarily focus on 'black-box' KD, which only uses the teacher's responses, overlooking the output distribution offered by the teacher. This paper addresses this gap by introducing daDPO (Distribution-Aware DPO), a unified method for preference optimization and distribution-based distillation. We provide rigorous theoretical analysis and empirical validation, showing that daDPO outperforms existing methods in restoring performance for pruned models and enhancing smaller LLM models. Notably, in in-domain evaluation, our method enables a 20% pruned Vicuna1.5-7B to achieve near-teacher performance (-7.3% preference rate compared to that of dDPO's -31%), and allows Qwen2.5-1.5B to occasionally outperform its 7B teacher model (14.0% win rate).",
    "summary": "arXiv:2506.15717v1 Announce Type: cross Abstract: Large language models (LLMs) have demonstrated exceptional performance across various applications, but their conversational abilities decline sharply as model size decreases, presenting a barrier to their deployment in resource-constrained environments. Knowledge distillation with Direct Preference Optimization (dDPO) has emerged as a promising approach to enhancing the conversational abilities of smaller models using a larger teacher model. However, current methods primarily focus on 'black-box' KD, which only uses the teacher's responses, overlooking the output distribution offered by the teacher. This paper addresses this gap by introducing daDPO (Distribution-Aware DPO), a unified method for preference optimization and distribution-based distillation. We provide rigorous theoretical analysis and empirical validation, showing that daDPO outperforms existing methods in restoring performance for pruned models and enhancing smaller LLM models. Notably, in in-domain evaluation, our method enables a 20% pruned Vicuna1.5-7B to achieve near-teacher performance (-7.3% preference rate compared to that of dDPO's -31%), and allows Qwen2.5-1.5B to occasionally outperform its 7B teacher model (14.0% win rate).",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15717",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Make your llama generation time fly with AWS Inferentia2",
    "description": "",
    "summary": "Make your llama generation time fly with AWS Inferentia2 Update (02/2024): Performance has improved ...",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inferentia-llama2",
    "thumbnail": "https://huggingface.co/blog/assets/inferentia-llama2/thumbnail.png"
  },
  {
    "title": "AlphaFold 3 predicts the structure and interactions of all of life‚Äôs molecules",
    "description": "Introducing a new AI model developed by Google DeepMind and Isomorphic Labs.",
    "summary": "Introducing a new AI model developed by Google DeepMind and Isomorphic Labs.",
    "pubDate": "Wed, 08 May 2024 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/alphafold-3-predicts-the-structure-and-interactions-of-all-lifes-molecules/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AF_social_share.width-1300.jpg"
  },
  {
    "title": "Plan online, learn offline: Efficient learning and exploration via model-based control",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 05 Nov 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/plan-online-learn-offline",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Human2LocoMan: Learning Versatile Quadrupedal Manipulation with Human Pretraining",
    "description": "arXiv:2506.16475v1 Announce Type: cross Abstract: Quadrupedal robots have demonstrated impressive locomotion capabilities in complex environments, but equipping them with autonomous versatile manipulation skills in a scalable way remains a significant challenge. In this work, we introduce a cross-embodiment imitation learning system for quadrupedal manipulation, leveraging data collected from both humans and LocoMan, a quadruped equipped with multiple manipulation modes. Specifically, we develop a teleoperation and data collection pipeline, which unifies and modularizes the observation and action spaces of the human and the robot. To effectively leverage the collected data, we propose an efficient modularized architecture that supports co-training and pretraining on structured modality-aligned data across different embodiments. Additionally, we construct the first manipulation dataset for the LocoMan robot, covering various household tasks in both unimanual and bimanual modes, supplemented by a corresponding human dataset. We validate our system on six real-world manipulation tasks, where it achieves an average success rate improvement of 41.9% overall and 79.7% under out-of-distribution (OOD) settings compared to the baseline. Pretraining with human data contributes a 38.6% success rate improvement overall and 82.7% under OOD settings, enabling consistently better performance with only half the amount of robot data. Our code, hardware, and data are open-sourced at: https://human2bots.github.io.",
    "summary": "arXiv:2506.16475v1 Announce Type: cross Abstract: Quadrupedal robots have demonstrated impressive locomotion capabilities in complex environments, but equipping them with autonomous versatile manipulation skills in a scalable way remains a significant challenge. In this work, we introduce a cross-embodiment imitation learning system for quadrupedal manipulation, leveraging data collected from both humans and LocoMan, a quadruped equipped with multiple manipulation modes. Specifically, we develop a teleoperation and data collection pipeline, which unifies and modularizes the observation and action spaces of the human and the robot. To effectively leverage the collected data, we propose an efficient modularized architecture that supports co-training and pretraining on structured modality-aligned data across different embodiments. Additionally, we construct the first manipulation dataset for the LocoMan robot, covering various household tasks in both unimanual and bimanual modes, supplemented by a corresponding human dataset. We validate our system on six real-world manipulation tasks, where it achieves an average success rate improvement of 41.9% overall and 79.7% under out-of-distribution (OOD) settings compared to the baseline. Pretraining with human data contributes a 38.6% success rate improvement overall and 82.7% under OOD settings, enabling consistently better performance with only half the amount of robot data. Our code, hardware, and data are open-sourced at: https://human2bots.github.io.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16475",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Robotics Under Construction: Challenges on Job Sites",
    "description": "arXiv:2506.19597v1 Announce Type: cross Abstract: As labor shortages and productivity stagnation increasingly challenge the construction industry, automation has become essential for sustainable infrastructure development. This paper presents an autonomous payload transportation system as an initial step toward fully unmanned construction sites. Our system, based on the CD110R-3 crawler carrier, integrates autonomous navigation, fleet management, and GNSS-based localization to facilitate material transport in construction site environments. While the current system does not yet incorporate dynamic environment adaptation algorithms, we have begun fundamental investigations into external-sensor based perception and mapping system. Preliminary results highlight the potential challenges, including navigation in evolving terrain, environmental perception under construction-specific conditions, and sensor placement optimization for improving autonomy and efficiency. Looking forward, we envision a construction ecosystem where collaborative autonomous agents dynamically adapt to site conditions, optimizing workflow and reducing human intervention. This paper provides foundational insights into the future of robotics-driven construction automation and identifies critical areas for further technological development.",
    "summary": "arXiv:2506.19597v1 Announce Type: cross Abstract: As labor shortages and productivity stagnation increasingly challenge the construction industry, automation has become essential for sustainable infrastructure development. This paper presents an autonomous payload transportation system as an initial step toward fully unmanned construction sites. Our system, based on the CD110R-3 crawler carrier, integrates autonomous navigation, fleet management, and GNSS-based localization to facilitate material transport in construction site environments. While the current system does not yet incorporate dynamic environment adaptation algorithms, we have begun fundamental investigations into external-sensor based perception and mapping system. Preliminary results highlight the potential challenges, including navigation in evolving terrain, environmental perception under construction-specific conditions, and sensor placement optimization for improving autonomy and efficiency. Looking forward, we envision a construction ecosystem where collaborative autonomous agents dynamically adapt to site conditions, optimizing workflow and reducing human intervention. This paper provides foundational insights into the future of robotics-driven construction automation and identifies critical areas for further technological development.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19597",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sum-of-Parts: Self-Attributing Neural Networks with End-to-End Learning of Feature Groups",
    "description": "arXiv:2310.16316v4 Announce Type: replace-cross Abstract: Self-attributing neural networks (SANNs) present a potential path towards interpretable models for high-dimensional problems, but often face significant trade-offs in performance. In this work, we formally prove a lower bound on errors of per-feature SANNs, whereas group-based SANNs can achieve zero error and thus high performance. Motivated by these insights, we propose Sum-of-Parts (SOP), a framework that transforms any differentiable model into a group-based SANN, where feature groups are learned end-to-end without group supervision. SOP achieves state-of-the-art performance for SANNs on vision and language tasks, and we validate that the groups are interpretable on a range of quantitative and semantic metrics. We further validate the utility of SOP explanations in model debugging and cosmological scientific discovery. Our code is available at https://github.com/BrachioLab/sop",
    "summary": "arXiv:2310.16316v4 Announce Type: replace-cross Abstract: Self-attributing neural networks (SANNs) present a potential path towards interpretable models for high-dimensional problems, but often face significant trade-offs in performance. In this work, we formally prove a lower bound on errors of per-feature SANNs, whereas group-based SANNs can achieve zero error and thus high performance. Motivated by these insights, we propose Sum-of-Parts (SOP), a framework that transforms any differentiable model into a group-based SANN, where feature groups are learned end-to-end without group supervision. SOP achieves state-of-the-art performance for SANNs on vision and language tasks, and we validate that the groups are interpretable on a range of quantitative and semantic metrics. We further validate the utility of SOP explanations in model debugging and cosmological scientific discovery. Our code is available at https://github.com/BrachioLab/sop",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2310.16316",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval",
    "description": "",
    "summary": "Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval We introduce t...",
    "pubDate": "Fri, 22 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/embedding-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/embedding-quantization/thumbnail.png"
  },
  {
    "title": "AdaptGOT: A Pre-trained Model for Adaptive Contextual POI Representation Learning",
    "description": "arXiv:2506.21612v1 Announce Type: cross Abstract: Currently, considerable strides have been achieved in Point-of-Interest (POI) embedding methodologies, driven by the emergence of novel POI tasks like recommendation and classification. Despite the success of task-specific, end-to-end models in POI embedding, several challenges remain. These include the need for more effective multi-context sampling strategies, insufficient exploration of multiple POI contexts, limited versatility, and inadequate generalization. To address these issues, we propose the AdaptGOT model, which integrates both the (Adapt)ive representation learning technique and the Geographical-Co-Occurrence-Text (GOT) representation with a particular emphasis on Geographical location, Co-Occurrence and Textual information. The AdaptGOT model comprises three key components: (1) contextual neighborhood generation, which integrates advanced mixed sampling techniques such as KNN, density-based, importance-based, and category-aware strategies to capture complex contextual neighborhoods; (2) an advanced GOT representation enhanced by an attention mechanism, designed to derive high-quality, customized representations and efficiently capture complex interrelations between POIs; and (3) the MoE-based adaptive encoder-decoder architecture, which ensures topological consistency and enriches contextual representation by minimizing Jensen-Shannon divergence across varying contexts. Experiments on two real-world datasets and multiple POI tasks substantiate the superior performance of the proposed AdaptGOT model.",
    "summary": "arXiv:2506.21612v1 Announce Type: cross Abstract: Currently, considerable strides have been achieved in Point-of-Interest (POI) embedding methodologies, driven by the emergence of novel POI tasks like recommendation and classification. Despite the success of task-specific, end-to-end models in POI embedding, several challenges remain. These include the need for more effective multi-context sampling strategies, insufficient exploration of multiple POI contexts, limited versatility, and inadequate generalization. To address these issues, we propose the AdaptGOT model, which integrates both the (Adapt)ive representation learning technique and the Geographical-Co-Occurrence-Text (GOT) representation with a particular emphasis on Geographical location, Co-Occurrence and Textual information. The AdaptGOT model comprises three key components: (1) contextual neighborhood generation, which integrates advanced mixed sampling techniques such as KNN, density-based, importance-based, and category-aware strategies to capture complex contextual neighborhoods; (2) an advanced GOT representation enhanced by an attention mechanism, designed to derive high-quality, customized representations and efficiently capture complex interrelations between POIs; and (3) the MoE-based adaptive encoder-decoder architecture, which ensures topological consistency and enriches contextual representation by minimizing Jensen-Shannon divergence across varying contexts. Experiments on two real-world datasets and multiple POI tasks substantiate the superior performance of the proposed AdaptGOT model.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21612",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Practices for Governing Agentic AI Systems",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/practices-for-governing-agentic-ai-systems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LLMs and Stack Overflow Discussions: Reliability, Impact, and Challenges",
    "description": "arXiv:2402.08801v2 Announce Type: replace-cross Abstract: Since its release in November 2022, ChatGPT has shaken up Stack Overflow, the premier platform for developers queries on programming and software development. Demonstrating an ability to generate instant, human-like responses to technical questions, ChatGPT has ignited debates within the developer community about the evolving role of human-driven platforms in the age of generative AI. Two months after ChatGPT release, Meta released its answer with its own Large Language Model (LLM) called LLaMA: the race was on. We conducted an empirical study analyzing questions from Stack Overflow and using these LLMs to address them. This way, we aim to (i) quantify the reliability of LLMs answers and their potential to replace Stack Overflow in the long term; (ii) identify and understand why LLMs fail; (iii) measure users activity evolution with Stack Overflow over time; and (iv) compare LLMs together. Our empirical results are unequivocal: ChatGPT and LLaMA challenge human expertise, yet do not outperform it for some domains, while a significant decline in user posting activity has been observed. Furthermore, we also discuss the impact of our findings regarding the usage and development of new LLMs and provide guidelines for future challenges faced by users and researchers.",
    "summary": "arXiv:2402.08801v2 Announce Type: replace-cross Abstract: Since its release in November 2022, ChatGPT has shaken up Stack Overflow, the premier platform for developers queries on programming and software development. Demonstrating an ability to generate instant, human-like responses to technical questions, ChatGPT has ignited debates within the developer community about the evolving role of human-driven platforms in the age of generative AI. Two months after ChatGPT release, Meta released its answer with its own Large Language Model (LLM) called LLaMA: the race was on. We conducted an empirical study analyzing questions from Stack Overflow and using these LLMs to address them. This way, we aim to (i) quantify the reliability of LLMs answers and their potential to replace Stack Overflow in the long term; (ii) identify and understand why LLMs fail; (iii) measure users activity evolution with Stack Overflow over time; and (iv) compare LLMs together. Our empirical results are unequivocal: ChatGPT and LLaMA challenge human expertise, yet do not outperform it for some domains, while a significant decline in user posting activity has been observed. Furthermore, we also discuss the impact of our findings regarding the usage and development of new LLMs and provide guidelines for future challenges faced by users and researchers.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2402.08801",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing our latest image generation model in the API",
    "description": "Our latest image generation model is now available in the API via ‚Äògpt-image-1‚Äô‚Äîenabling developers and businesses to build professional-grade, customizable visuals directly into their own tools and platforms.",
    "summary": "Our latest image generation model is now available in the API via ‚Äògpt-image-1‚Äô‚Äîenabling developers and businesses to build professional-grade, customizable visuals directly into their own tools and platforms.",
    "pubDate": "Wed, 23 Apr 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/image-generation-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Kling-Foley: Multimodal Diffusion Transformer for High-Quality Video-to-Audio Generation",
    "description": "arXiv:2506.19774v1 Announce Type: cross Abstract: We propose Kling-Foley, a large-scale multimodal Video-to-Audio generation model that synthesizes high-quality audio synchronized with video content. In Kling-Foley, we introduce multimodal diffusion transformers to model the interactions between video, audio, and text modalities, and combine it with a visual semantic representation module and an audio-visual synchronization module to enhance alignment capabilities. Specifically, these modules align video conditions with latent audio elements at the frame level, thereby improving semantic alignment and audio-visual synchronization. Together with text conditions, this integrated approach enables precise generation of video-matching sound effects. In addition, we propose a universal latent audio codec that can achieve high-quality modeling in various scenarios such as sound effects, speech, singing, and music. We employ a stereo rendering method that imbues synthesized audio with a spatial presence. At the same time, in order to make up for the incomplete types and annotations of the open-source benchmark, we also open-source an industrial-level benchmark Kling-Audio-Eval. Our experiments show that Kling-Foley trained with the flow matching objective achieves new audio-visual SOTA performance among public models in terms of distribution matching, semantic alignment, temporal alignment and audio quality.",
    "summary": "arXiv:2506.19774v1 Announce Type: cross Abstract: We propose Kling-Foley, a large-scale multimodal Video-to-Audio generation model that synthesizes high-quality audio synchronized with video content. In Kling-Foley, we introduce multimodal diffusion transformers to model the interactions between video, audio, and text modalities, and combine it with a visual semantic representation module and an audio-visual synchronization module to enhance alignment capabilities. Specifically, these modules align video conditions with latent audio elements at the frame level, thereby improving semantic alignment and audio-visual synchronization. Together with text conditions, this integrated approach enables precise generation of video-matching sound effects. In addition, we propose a universal latent audio codec that can achieve high-quality modeling in various scenarios such as sound effects, speech, singing, and music. We employ a stereo rendering method that imbues synthesized audio with a spatial presence. At the same time, in order to make up for the incomplete types and annotations of the open-source benchmark, we also open-source an industrial-level benchmark Kling-Audio-Eval. Our experiments show that Kling-Foley trained with the flow matching objective achieves new audio-visual SOTA performance among public models in terms of distribution matching, semantic alignment, temporal alignment and audio quality.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19774",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Equivalence between policy gradients and soft Q-learning",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 21 Apr 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/equivalence-between-policy-gradients-and-soft-q-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Welcome fastai to the Hugging Face Hub",
    "description": "",
    "summary": "Welcome fastai to the Hugging Face Hub Making neural nets uncool again... and sharing them Few have ...",
    "pubDate": "Fri, 06 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fastai",
    "thumbnail": "https://huggingface.co/blog/assets/64_fastai/fastai_hf_blog.png"
  },
  {
    "title": "Deploying TensorFlow Vision Models in Hugging Face with TF Serving",
    "description": "",
    "summary": "Deploying TensorFlow Vision Models in Hugging Face with TF Serving In the past few months, the Huggi...",
    "pubDate": "Mon, 25 Jul 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/tf-serving-vision",
    "thumbnail": "https://huggingface.co/blog/assets/90_tf_serving_vision/thumbnail.png"
  },
  {
    "title": "MIT announces the Initiative for New Manufacturing",
    "description": "The Institute-wide effort aims to bolster industry and create jobs by driving innovation across vital manufacturing sectors.",
    "summary": "The Institute-wide effort aims to bolster industry and create jobs by driving innovation across vital manufacturing sectors.",
    "pubDate": "Tue, 27 May 2025 10:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-announces-initiative-for-new-manufacturing-0527",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-ManufacturingAnn-01-press.jpg"
  },
  {
    "title": "Generative models",
    "description": "This post describes four projects that share a common theme of enhancing or using generative models, a branch of unsupervised learning techniques in machine learning. In addition to describing our work, this post will tell you a bit more about generative models: what they are, why they are important, and where they might be going.",
    "summary": "This post describes four projects that share a common theme of enhancing or using generative models, a branch of unsupervised learning techniques in machine learning. In addition to describing our work, this post will tell you a bit more about generative models: what they are, why they are important, and where they might be going.",
    "pubDate": "Thu, 16 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generative-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing OpenAI for Nonprofits",
    "description": "We‚Äôre launching a new initiative to enhance the accessibility of our tools for nonprofit organizations, including discounted rates for ChatGPT Team and Enterprise.",
    "summary": "We‚Äôre launching a new initiative to enhance the accessibility of our tools for nonprofit organizations, including discounted rates for ChatGPT Team and Enterprise.",
    "pubDate": "Thu, 30 May 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-openai-for-nonprofits",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Geometric-Aware Variational Inference: Robust and Adaptive Regularization with Directional Weight Uncertainty",
    "description": "arXiv:2506.19726v1 Announce Type: cross Abstract: Deep neural networks require principled uncertainty quantification, yet existing variational inference methods often employ isotropic Gaussian approximations in weight space that poorly match the network's inherent geometry. We address this mismatch by introducing Concentration-Adapted Perturbations (CAP), a variational framework that models weight uncertainties directly on the unit hypersphere using von Mises-Fisher distributions. Building on recent work in radial-directional posterior decompositions and spherical weight constraints, CAP provides the first complete theoretical framework connecting directional statistics to practical noise regularization in neural networks. Our key contribution is an analytical derivation linking vMF concentration parameters to activation noise variance, enabling each layer to learn its optimal uncertainty level through a novel closed-form KL divergence regularizer. In experiments on CIFAR-10, CAP significantly improves model calibration - reducing Expected Calibration Error by 5.6x - while providing interpretable layer-wise uncertainty profiles. CAP requires minimal computational overhead and integrates seamlessly into standard architectures, offering a theoretically grounded yet practical approach to uncertainty quantification in deep learning.",
    "summary": "arXiv:2506.19726v1 Announce Type: cross Abstract: Deep neural networks require principled uncertainty quantification, yet existing variational inference methods often employ isotropic Gaussian approximations in weight space that poorly match the network's inherent geometry. We address this mismatch by introducing Concentration-Adapted Perturbations (CAP), a variational framework that models weight uncertainties directly on the unit hypersphere using von Mises-Fisher distributions. Building on recent work in radial-directional posterior decompositions and spherical weight constraints, CAP provides the first complete theoretical framework connecting directional statistics to practical noise regularization in neural networks. Our key contribution is an analytical derivation linking vMF concentration parameters to activation noise variance, enabling each layer to learn its optimal uncertainty level through a novel closed-form KL divergence regularizer. In experiments on CIFAR-10, CAP significantly improves model calibration - reducing Expected Calibration Error by 5.6x - while providing interpretable layer-wise uncertainty profiles. CAP requires minimal computational overhead and integrates seamlessly into standard architectures, offering a theoretically grounded yet practical approach to uncertainty quantification in deep learning.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19726",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation",
    "description": "arXiv:2506.21892v1 Announce Type: cross Abstract: As point cloud data increases in prevalence in a variety of applications, the ability to detect out-of-distribution (OOD) point cloud objects becomes critical for ensuring model safety and reliability. However, this problem remains under-explored in existing research. Inspired by success in the image domain, we propose to exploit advances in 3D vision-language models (3D VLMs) for OOD detection in point cloud objects. However, a major challenge is that point cloud datasets used to pre-train 3D VLMs are drastically smaller in size and object diversity than their image-based counterparts. Critically, they often contain exclusively computer-designed synthetic objects. This leads to a substantial domain shift when the model is transferred to practical tasks involving real objects scanned from the physical environment. In this paper, our empirical experiments show that synthetic-to-real domain shift significantly degrades the alignment of point cloud with their associated text embeddings in the 3D VLM latent space, hindering downstream performance. To address this, we propose a novel methodology called SODA which improves the detection of OOD point clouds through a neighborhood-based score propagation scheme. SODA is inference-based, requires no additional model training, and achieves state-of-the-art performance over existing approaches across datasets and problem settings.",
    "summary": "arXiv:2506.21892v1 Announce Type: cross Abstract: As point cloud data increases in prevalence in a variety of applications, the ability to detect out-of-distribution (OOD) point cloud objects becomes critical for ensuring model safety and reliability. However, this problem remains under-explored in existing research. Inspired by success in the image domain, we propose to exploit advances in 3D vision-language models (3D VLMs) for OOD detection in point cloud objects. However, a major challenge is that point cloud datasets used to pre-train 3D VLMs are drastically smaller in size and object diversity than their image-based counterparts. Critically, they often contain exclusively computer-designed synthetic objects. This leads to a substantial domain shift when the model is transferred to practical tasks involving real objects scanned from the physical environment. In this paper, our empirical experiments show that synthetic-to-real domain shift significantly degrades the alignment of point cloud with their associated text embeddings in the 3D VLM latent space, hindering downstream performance. To address this, we propose a novel methodology called SODA which improves the detection of OOD point clouds through a neighborhood-based score propagation scheme. SODA is inference-based, requires no additional model training, and achieves state-of-the-art performance over existing approaches across datasets and problem settings.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21892",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Scholars 2019: Final projects",
    "description": "Our second class of OpenAI Scholars has concluded, with all eight scholars producing an exciting final project showcased at Scholars Demo Day at OpenAI.",
    "summary": "Our second class of OpenAI Scholars has concluded, with all eight scholars producing an exciting final project showcased at Scholars Demo Day at OpenAI.",
    "pubDate": "Thu, 23 May 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019-final-projects",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "cuVSLAM: CUDA accelerated visual odometry and mapping",
    "description": "arXiv:2506.04359v2 Announce Type: replace-cross Abstract: Accurate and robust pose estimation is a key requirement for any autonomous robot. We present cuVSLAM, a state-of-the-art solution for visual simultaneous localization and mapping, which can operate with a variety of visual-inertial sensor suites, including multiple RGB and depth cameras, and inertial measurement units. cuVSLAM supports operation with as few as one RGB camera to as many as 32 cameras, in arbitrary geometric configurations, thus supporting a wide range of robotic setups. cuVSLAM is specifically optimized using CUDA to deploy in real-time applications with minimal computational overhead on edge-computing devices such as the NVIDIA Jetson. We present the design and implementation of cuVSLAM, example use cases, and empirical results on several state-of-the-art benchmarks demonstrating the best-in-class performance of cuVSLAM.",
    "summary": "arXiv:2506.04359v2 Announce Type: replace-cross Abstract: Accurate and robust pose estimation is a key requirement for any autonomous robot. We present cuVSLAM, a state-of-the-art solution for visual simultaneous localization and mapping, which can operate with a variety of visual-inertial sensor suites, including multiple RGB and depth cameras, and inertial measurement units. cuVSLAM supports operation with as few as one RGB camera to as many as 32 cameras, in arbitrary geometric configurations, thus supporting a wide range of robotic setups. cuVSLAM is specifically optimized using CUDA to deploy in real-time applications with minimal computational overhead on edge-computing devices such as the NVIDIA Jetson. We present the design and implementation of cuVSLAM, example use cases, and empirical results on several state-of-the-art benchmarks demonstrating the best-in-class performance of cuVSLAM.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.04359",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Our approach to alignment research",
    "description": "We are improving our AI systems‚Äô ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment¬†problems.",
    "summary": "We are improving our AI systems‚Äô ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment¬†problems.",
    "pubDate": "Wed, 24 Aug 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/our-approach-to-alignment-research",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Visual Document Retrieval Goes Multilingual",
    "description": "",
    "summary": "Visual Document Retrieval Goes Multilingual TL;DR: We present vdr-2b-multi-v1 , the best multilingua...",
    "pubDate": "Fri, 10 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vdr-2b-multilingual",
    "thumbnail": "https://huggingface.co/blog/assets/vdr-2b-multilingual/thumbnail.png"
  },
  {
    "title": "AI Policy @ü§ó: Open ML Considerations in the EU AI Act",
    "description": "",
    "summary": "AI Policy @ü§ó: Open ML Considerations in the EU AI Act Like everyone else in Machine Learning, we‚Äôve ...",
    "pubDate": "Mon, 24 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/eu-ai-act-oss",
    "thumbnail": "https://huggingface.co/blog/assets/eu_ai_act_oss/thumbnailEU.png"
  },
  {
    "title": "RL2Grid: Benchmarking Reinforcement Learning in Power Grid Operations",
    "description": "arXiv:2503.23101v2 Announce Type: replace-cross Abstract: Reinforcement learning (RL) can provide adaptive and scalable controllers essential for power grid decarbonization. However, RL methods struggle with power grids' complex dynamics, long-horizon goals, and hard physical constraints. For these reasons, we present RL2Grid, a benchmark designed in collaboration with power system operators to accelerate progress in grid control and foster RL maturity. Built on RTE France's power simulation framework, RL2Grid standardizes tasks, state and action spaces, and reward structures for a systematic evaluation and comparison of RL algorithms. Moreover, we integrate operational heuristics and design safety constraints based on human expertise to ensure alignment with physical requirements. By establishing reference performance metrics for classic RL baselines on RL2Grid's tasks, we highlight the need for novel methods capable of handling real systems and discuss future directions for RL-based grid control.",
    "summary": "arXiv:2503.23101v2 Announce Type: replace-cross Abstract: Reinforcement learning (RL) can provide adaptive and scalable controllers essential for power grid decarbonization. However, RL methods struggle with power grids' complex dynamics, long-horizon goals, and hard physical constraints. For these reasons, we present RL2Grid, a benchmark designed in collaboration with power system operators to accelerate progress in grid control and foster RL maturity. Built on RTE France's power simulation framework, RL2Grid standardizes tasks, state and action spaces, and reward structures for a systematic evaluation and comparison of RL algorithms. Moreover, we integrate operational heuristics and design safety constraints based on human expertise to ensure alignment with physical requirements. By establishing reference performance metrics for classic RL baselines on RL2Grid's tasks, we highlight the need for novel methods capable of handling real systems and discuss future directions for RL-based grid control.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.23101",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introduction to ggml",
    "description": "",
    "summary": "Introduction to ggml ggml is a machine learning (ML) library written in C and C++ with a focus on Tr...",
    "pubDate": "Tue, 13 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/introduction-to-ggml",
    "thumbnail": "https://huggingface.co/blog/assets/introduction-to-ggml/cover.jpg"
  },
  {
    "title": "KunLunBaizeRAG: Reinforcement Learning Driven Inference Performance Leap for Large Language Models",
    "description": "arXiv:2506.19466v1 Announce Type: new Abstract: This paper introduces KunLunBaizeRAG, a reinforcement learning-driven reasoning framework designed to enhance the reasoning capabilities of large language models (LLMs) in complex multi-hop question-answering tasks. The framework addresses key limitations of traditional RAG, such as retrieval drift, information redundancy, and strategy rigidity. Key innovations include the RAG-driven Reasoning Alignment (RDRA) mechanism, the Search-Think Iterative Enhancement (STIE) mechanism, the Network-Local Intelligent Routing (NLR) mechanism, and a progressive hybrid training strategy. Experimental results demonstrate significant improvements in exact match (EM) and LLM-judged score (LJ) across four benchmarks, highlighting the framework's robustness and effectiveness in complex reasoning scenarios.",
    "summary": "arXiv:2506.19466v1 Announce Type: new Abstract: This paper introduces KunLunBaizeRAG, a reinforcement learning-driven reasoning framework designed to enhance the reasoning capabilities of large language models (LLMs) in complex multi-hop question-answering tasks. The framework addresses key limitations of traditional RAG, such as retrieval drift, information redundancy, and strategy rigidity. Key innovations include the RAG-driven Reasoning Alignment (RDRA) mechanism, the Search-Think Iterative Enhancement (STIE) mechanism, the Network-Local Intelligent Routing (NLR) mechanism, and a progressive hybrid training strategy. Experimental results demonstrate significant improvements in exact match (EM) and LLM-judged score (LJ) across four benchmarks, highlighting the framework's robustness and effectiveness in complex reasoning scenarios.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19466",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From PyTorch DDP to ü§ó Accelerate to ü§ó Trainer, mastery of distributed training with ease",
    "description": "",
    "summary": "From PyTorch DDP to Accelerate to Trainer, mastery of distributed training with ease General Overvie...",
    "pubDate": "Fri, 21 Oct 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pytorch-ddp-accelerate-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/111_pytorch_ddp_accelerate_transformers/thumbnail.png"
  },
  {
    "title": "Do We Talk to Robots Like Therapists, and Do They Respond Accordingly? Language Alignment in AI Emotional Support",
    "description": "arXiv:2506.16473v1 Announce Type: cross Abstract: As conversational agents increasingly engage in emotionally supportive dialogue, it is important to understand how closely their interactions resemble those in traditional therapy settings. This study investigates whether the concerns shared with a robot align with those shared in human-to-human (H2H) therapy sessions, and whether robot responses semantically mirror those of human therapists. We analyzed two datasets: one of interactions between users and professional therapists (Hugging Face's NLP Mental Health Conversations), and another involving supportive conversations with a social robot (QTrobot from LuxAI) powered by a large language model (LLM, GPT-3.5). Using sentence embeddings and K-means clustering, we assessed cross-agent thematic alignment by applying a distance-based cluster-fitting method that evaluates whether responses from one agent type map to clusters derived from the other, and validated it using Euclidean distances. Results showed that 90.88% of robot conversation disclosures could be mapped to clusters from the human therapy dataset, suggesting shared topical structure. For matched clusters, we compared the subjects as well as therapist and robot responses using Transformer, Word2Vec, and BERT embeddings, revealing strong semantic overlap in subjects' disclosures in both datasets, as well as in the responses given to similar human disclosure themes across agent types (robot vs. human therapist). These findings highlight both the parallels and boundaries of robot-led support conversations and their potential for augmenting mental health interventions.",
    "summary": "arXiv:2506.16473v1 Announce Type: cross Abstract: As conversational agents increasingly engage in emotionally supportive dialogue, it is important to understand how closely their interactions resemble those in traditional therapy settings. This study investigates whether the concerns shared with a robot align with those shared in human-to-human (H2H) therapy sessions, and whether robot responses semantically mirror those of human therapists. We analyzed two datasets: one of interactions between users and professional therapists (Hugging Face's NLP Mental Health Conversations), and another involving supportive conversations with a social robot (QTrobot from LuxAI) powered by a large language model (LLM, GPT-3.5). Using sentence embeddings and K-means clustering, we assessed cross-agent thematic alignment by applying a distance-based cluster-fitting method that evaluates whether responses from one agent type map to clusters derived from the other, and validated it using Euclidean distances. Results showed that 90.88% of robot conversation disclosures could be mapped to clusters from the human therapy dataset, suggesting shared topical structure. For matched clusters, we compared the subjects as well as therapist and robot responses using Transformer, Word2Vec, and BERT embeddings, revealing strong semantic overlap in subjects' disclosures in both datasets, as well as in the responses given to similar human disclosure themes across agent types (robot vs. human therapist). These findings highlight both the parallels and boundaries of robot-led support conversations and their potential for augmenting mental health interventions.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16473",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Memory-efficient Diffusion Transformers with Quanto and Diffusers",
    "description": "",
    "summary": "Memory-efficient Diffusion Transformers with Quanto and Diffusers Over the past few months, we have ...",
    "pubDate": "Tue, 30 Jul 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/quanto-diffusers",
    "thumbnail": "https://huggingface.co/blog/assets/quanto-diffusers/thumbnail.png"
  },
  {
    "title": "Enterprise-ready trust and safety",
    "description": "Salesforce integrates OpenAI‚Äôs enterprise-ready LLMs to transform customer applications.",
    "summary": "Salesforce integrates OpenAI‚Äôs enterprise-ready LLMs to transform customer applications.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/salesforce",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering",
    "description": "We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.",
    "summary": "We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.",
    "pubDate": "Thu, 10 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mle-bench",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Computational limitations in robust classification and win-win results",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 04 Feb 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/computational-limitations-in-robust-classification-and-win-win-results",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Benchmarking the next generation of never-ending learners",
    "description": "Learning how to build upon knowledge by tapping 30 years of computer vision research",
    "summary": "Learning how to build upon knowledge by tapping 30 years of computer vision research",
    "pubDate": "Tue, 22 Nov 2022 00:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/benchmarking-the-next-generation-of-never-ending-learners/",
    "thumbnail": "https://lh3.googleusercontent.com/VEIJiplOab4catyNZs6QjZxwjbqVmrh2fIZF8Gj7Xd7TQRq1q4bqDmbeSuVzHPzDhC8vKYI5nZLft79VWP5Oi7j_ARAzyFVxMdJIMKxDD5VfRpGm=w1200-h630-n-nu"
  },
  {
    "title": "Shipping code faster with o3, o4-mini, and GPT-4.1",
    "description": "CodeRabbit uses OpenAI models to revolutionize code reviews‚Äîboosting accuracy, accelerating PR merges, and helping developers ship faster with fewer bugs and higher ROI.",
    "summary": "CodeRabbit uses OpenAI models to revolutionize code reviews‚Äîboosting accuracy, accelerating PR merges, and helping developers ship faster with fewer bugs and higher ROI.",
    "pubDate": "Thu, 22 May 2025 10:25:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/coderabbit",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„ÇíÁú∫„ÇÅ„Å¶„Åø„Çã",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ‰ªäÂõû„ÅØGemini Diffusion„ÅÆÁôªÂ†¥„Çí„Åç„Å£„Åã„Åë„Å´ÊúÄËøëË©±È°å„Å´„Å™„Å£„ÅüÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„Å´ËààÂë≥„ÇíÊåÅ„Å°„ÄÅ„Åù„ÅÆ‰∏Ä‰æã„Å®„Åó„Å¶Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆLLaDA„ÅÆÊé®Ë´ñ„ÇíÂÆüÈöõ„Å´ÊâãÂÖÉ„ÅßÁ¢∫Ë™ç„Åó„Å¶„Åø„ÅüÁµêÊûú„Çí [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5850' rel='nofollow'>Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„ÇíÁú∫„ÇÅ„Å¶„Åø„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ‰ªäÂõû„ÅØGemini Diffusion„ÅÆÁôªÂ†¥„Çí„Åç„Å£„Åã„Åë„Å´ÊúÄËøëË©±È°å„Å´„Å™„Å£„ÅüÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„Å´ËààÂë≥„ÇíÊåÅ„Å°„ÄÅ„Åù„ÅÆ‰∏Ä‰æã„Å®„Åó„Å¶Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆLLaDA„ÅÆÊé®Ë´ñ„ÇíÂÆüÈöõ„Å´ÊâãÂÖÉ„ÅßÁ¢∫Ë™ç„Åó„Å¶„Åø„ÅüÁµêÊûú„Çí [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5850' rel='nofollow'>Êã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÅÆÊé®Ë´ñÈÅéÁ®ã„ÇíÁú∫„ÇÅ„Å¶„Åø„Çã</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Mon, 02 Jun 2025 00:13:43 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5850",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/05/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "Dual Thinking and Logical Processing -- Are Multi-modal Large Language Models Closing the Gap with Human Vision ?",
    "description": "arXiv:2406.06967v4 Announce Type: replace-cross Abstract: The dual thinking framework considers fast, intuitive, and slower logical processing. The perception of dual thinking in vision requires images where inferences from intuitive and logical processing differ, and the latter is under-explored in current studies. We introduce a novel adversarial dataset to provide evidence for the dual thinking framework in human vision, which also facilitates the study of the qualitative behavior of deep learning models. Our psychophysical studies show the presence of multiple inferences in rapid succession, and analysis of errors shows that the early stopping of visual processing can result in missing relevant information. MLLMs (Multi-modal Large Language Models) and VLMs (Vision Language Models) have made significant progress in correcting errors in intuitive processing in human vision and showed enhanced performance on images requiring logical processing. However, their improvements in logical processing have not kept pace with their advancements in intuitive processing. In contrast, segmentation models exhibit errors similar to those seen in intuitive human processing and lack understanding of sub-structures, as indicated by errors related to sub-components in identified instances. As AI (Artificial Intelligence)-based systems find increasing applications in safety-critical domains like autonomous driving, the integration of logical processing capabilities becomes essential. This not only enhances performance but also addresses the limitations of scaling-based approaches while ensuring robustness and reliability in real-world environments.",
    "summary": "arXiv:2406.06967v4 Announce Type: replace-cross Abstract: The dual thinking framework considers fast, intuitive, and slower logical processing. The perception of dual thinking in vision requires images where inferences from intuitive and logical processing differ, and the latter is under-explored in current studies. We introduce a novel adversarial dataset to provide evidence for the dual thinking framework in human vision, which also facilitates the study of the qualitative behavior of deep learning models. Our psychophysical studies show the presence of multiple inferences in rapid succession, and analysis of errors shows that the early stopping of visual processing can result in missing relevant information. MLLMs (Multi-modal Large Language Models) and VLMs (Vision Language Models) have made significant progress in correcting errors in intuitive processing in human vision and showed enhanced performance on images requiring logical processing. However, their improvements in logical processing have not kept pace with their advancements in intuitive processing. In contrast, segmentation models exhibit errors similar to those seen in intuitive human processing and lack understanding of sub-structures, as indicated by errors related to sub-components in identified instances. As AI (Artificial Intelligence)-based systems find increasing applications in safety-critical domains like autonomous driving, the integration of logical processing capabilities becomes essential. This not only enhances performance but also addresses the limitations of scaling-based approaches while ensuring robustness and reliability in real-world environments.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2406.06967",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Llama 2 is here - get it on Hugging Face",
    "description": "",
    "summary": "Llama 2 is here - get it on Hugging Face Introduction Llama 2 is a family of state-of-the-art open-a...",
    "pubDate": "Tue, 18 Jul 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama2",
    "thumbnail": "https://huggingface.co/blog/assets/llama2/thumbnail.jpg"
  },
  {
    "title": "Semantic Preprocessing for LLM-based Malware Analysis",
    "description": "arXiv:2506.12113v2 Announce Type: replace-cross Abstract: In a context of malware analysis, numerous approaches rely on Artificial Intelligence to handle a large volume of data. However, these techniques focus on data view (images, sequences) and not on an expert's view. Noticing this issue, we propose a preprocessing that focuses on expert knowledge to improve malware semantic analysis and result interpretability. We propose a new preprocessing method which creates JSON reports for Portable Executable files. These reports gather features from both static and behavioral analysis, and incorporate packer signature detection, MITRE ATT&amp;CK and Malware Behavior Catalog (MBC) knowledge. The purpose of this preprocessing is to gather a semantic representation of binary files, understandable by malware analysts, and that can enhance AI models' explainability for malicious files analysis. Using this preprocessing to train a Large Language Model for Malware classification, we achieve a weighted-average F1-score of 0.94 on a complex dataset, representative of market reality.",
    "summary": "arXiv:2506.12113v2 Announce Type: replace-cross Abstract: In a context of malware analysis, numerous approaches rely on Artificial Intelligence to handle a large volume of data. However, these techniques focus on data view (images, sequences) and not on an expert's view. Noticing this issue, we propose a preprocessing that focuses on expert knowledge to improve malware semantic analysis and result interpretability. We propose a new preprocessing method which creates JSON reports for Portable Executable files. These reports gather features from both static and behavioral analysis, and incorporate packer signature detection, MITRE ATT&amp;CK and Malware Behavior Catalog (MBC) knowledge. The purpose of this preprocessing is to gather a semantic representation of binary files, understandable by malware analysts, and that can enhance AI models' explainability for malicious files analysis. Using this preprocessing to train a Large Language Model for Malware classification, we achieve a weighted-average F1-score of 0.94 on a complex dataset, representative of market reality.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.12113",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing the Chatbot Guardrails Arena",
    "description": "",
    "summary": "Introducing the Chatbot Guardrails Arena With the recent advancements in augmented LLM capabilities,...",
    "pubDate": "Thu, 21 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/arena-lighthouz",
    "thumbnail": "https://huggingface.co/blog/assets/arenas-on-the-hub/thumbnail_lighthouz.png"
  },
  {
    "title": "Team update",
    "description": "The OpenAI team is now 45 people. Together, we‚Äôre pushing the frontier of AI capabilities‚Äîwhether by validating novel ideas, creating new software systems, or deploying machine learning on robots.",
    "summary": "The OpenAI team is now 45 people. Together, we‚Äôre pushing the frontier of AI capabilities‚Äîwhether by validating novel ideas, creating new software systems, or deploying machine learning on robots.",
    "pubDate": "Mon, 30 Jan 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/team-update-january",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "TRUST: Transparent, Robust and Ultra-Sparse Trees",
    "description": "arXiv:2506.15791v1 Announce Type: cross Abstract: Piecewise-constant regression trees remain popular for their interpretability, yet often lag behind black-box models like Random Forest in predictive accuracy. In this work, we introduce TRUST (Transparent, Robust, and Ultra-Sparse Trees), a novel regression tree model that combines the accuracy of Random Forests with the interpretability of shallow decision trees and sparse linear models. TRUST further enhances transparency by leveraging Large Language Models to generate tailored, user-friendly explanations. Extensive validation on synthetic and real-world benchmark datasets demonstrates that TRUST consistently outperforms other interpretable models -- including CART, Lasso, and Node Harvest -- in predictive accuracy, while matching the accuracy of Random Forest and offering substantial gains in both accuracy and interpretability over M5', a well-established model that is conceptually related.",
    "summary": "arXiv:2506.15791v1 Announce Type: cross Abstract: Piecewise-constant regression trees remain popular for their interpretability, yet often lag behind black-box models like Random Forest in predictive accuracy. In this work, we introduce TRUST (Transparent, Robust, and Ultra-Sparse Trees), a novel regression tree model that combines the accuracy of Random Forests with the interpretability of shallow decision trees and sparse linear models. TRUST further enhances transparency by leveraging Large Language Models to generate tailored, user-friendly explanations. Extensive validation on synthetic and real-world benchmark datasets demonstrates that TRUST consistently outperforms other interpretable models -- including CART, Lasso, and Node Harvest -- in predictive accuracy, while matching the accuracy of Random Forest and offering substantial gains in both accuracy and interpretability over M5', a well-established model that is conceptually related.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15791",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcoming Llama Guard 4 on Hugging Face Hub",
    "description": "",
    "summary": "Welcoming Llama Guard 4 on Hugging Face Hub TL;DR: Today, Meta releases Llama Guard 4, a 12B dense (...",
    "pubDate": "Tue, 29 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama-guard-4",
    "thumbnail": "https://huggingface.co/blog/assets/llama-guard-4/thumbnail.png"
  },
  {
    "title": "Recalling The Forgotten Class Memberships: Unlearned Models Can Be Noisy Labelers to Leak Privacy",
    "description": "arXiv:2506.19486v1 Announce Type: cross Abstract: Machine Unlearning (MU) technology facilitates the removal of the influence of specific data instances from trained models on request. Despite rapid advancements in MU technology, its vulnerabilities are still underexplored, posing potential risks of privacy breaches through leaks of ostensibly unlearned information. Current limited research on MU attacks requires access to original models containing privacy data, which violates the critical privacy-preserving objective of MU. To address this gap, we initiate an innovative study on recalling the forgotten class memberships from unlearned models (ULMs) without requiring access to the original one. Specifically, we implement a Membership Recall Attack (MRA) framework with a teacher-student knowledge distillation architecture, where ULMs serve as noisy labelers to transfer knowledge to student models. Then, it is translated into a Learning with Noisy Labels (LNL) problem for inferring the correct labels of the forgetting instances. Extensive experiments on state-of-the-art MU methods with multiple real datasets demonstrate that the proposed MRA strategy exhibits high efficacy in recovering class memberships of unlearned instances. As a result, our study and evaluation have established a benchmark for future research on MU vulnerabilities.",
    "summary": "arXiv:2506.19486v1 Announce Type: cross Abstract: Machine Unlearning (MU) technology facilitates the removal of the influence of specific data instances from trained models on request. Despite rapid advancements in MU technology, its vulnerabilities are still underexplored, posing potential risks of privacy breaches through leaks of ostensibly unlearned information. Current limited research on MU attacks requires access to original models containing privacy data, which violates the critical privacy-preserving objective of MU. To address this gap, we initiate an innovative study on recalling the forgotten class memberships from unlearned models (ULMs) without requiring access to the original one. Specifically, we implement a Membership Recall Attack (MRA) framework with a teacher-student knowledge distillation architecture, where ULMs serve as noisy labelers to transfer knowledge to student models. Then, it is translated into a Learning with Noisy Labels (LNL) problem for inferring the correct labels of the forgetting instances. Extensive experiments on state-of-the-art MU methods with multiple real datasets demonstrate that the proposed MRA strategy exhibits high efficacy in recovering class memberships of unlearned instances. As a result, our study and evaluation have established a benchmark for future research on MU vulnerabilities.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19486",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing Spaces Dev Mode for a seamless developer experience",
    "description": "",
    "summary": "Introducing Spaces Dev Mode for a seamless developer experience Hugging Face Spaces makes it easy fo...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/spaces-dev-mode",
    "thumbnail": "https://huggingface.co/blog/assets/spaces-dev-mode/thumbnail.jpg"
  },
  {
    "title": "OpenAI licenses GPT-3 technology to Microsoft",
    "description": "OpenAI has agreed to license GPT-3 to Microsoft for their own products and services.",
    "summary": "OpenAI has agreed to license GPT-3 to Microsoft for their own products and services.",
    "pubDate": "Tue, 22 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-licenses-gpt-3-technology-to-microsoft",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fixing Gradient Accumulation",
    "description": "",
    "summary": "Fixing Gradient Accumulation Our friends at Unsloth shared an issue regarding gradient accumulation ...",
    "pubDate": "Wed, 16 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gradient_accumulation",
    "thumbnail": "https://huggingface.co/blog/assets/gradient_accumulation/gradient_accumulation.png"
  },
  {
    "title": "AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation",
    "description": "arXiv:2503.02832v2 Announce Type: replace-cross Abstract: In modern large language models (LLMs), LLM alignment is of crucial importance and is typically achieved through methods such as reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO). However, in most existing methods for LLM alignment, all tokens in the response are optimized using a sparse, response-level reward or preference annotation. The ignorance of token-level rewards may erroneously punish high-quality tokens or encourage low-quality tokens, resulting in suboptimal performance and slow convergence speed. To address this issue, we propose AlignDistil, an RLHF-equivalent distillation method for token-level reward optimization. Specifically, we introduce the reward learned by DPO into the RLHF objective and theoretically prove the equivalence between this objective and a token-level distillation process, where the teacher distribution linearly combines the logits from the DPO model and a reference model. On this basis, we further bridge the accuracy gap between the reward from the DPO model and the pure reward model, by building a contrastive DPO reward with a normal and a reverse DPO model. Moreover, to avoid under- and over-optimization on different tokens, we design a token adaptive logit extrapolation mechanism to construct an appropriate teacher distribution for each token. Experimental results demonstrate the superiority of our AlignDistil over existing methods and showcase fast convergence due to its token-level distributional reward optimization.",
    "summary": "arXiv:2503.02832v2 Announce Type: replace-cross Abstract: In modern large language models (LLMs), LLM alignment is of crucial importance and is typically achieved through methods such as reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO). However, in most existing methods for LLM alignment, all tokens in the response are optimized using a sparse, response-level reward or preference annotation. The ignorance of token-level rewards may erroneously punish high-quality tokens or encourage low-quality tokens, resulting in suboptimal performance and slow convergence speed. To address this issue, we propose AlignDistil, an RLHF-equivalent distillation method for token-level reward optimization. Specifically, we introduce the reward learned by DPO into the RLHF objective and theoretically prove the equivalence between this objective and a token-level distillation process, where the teacher distribution linearly combines the logits from the DPO model and a reference model. On this basis, we further bridge the accuracy gap between the reward from the DPO model and the pure reward model, by building a contrastive DPO reward with a normal and a reverse DPO model. Moreover, to avoid under- and over-optimization on different tokens, we design a token adaptive logit extrapolation mechanism to construct an appropriate teacher distribution for each token. Experimental results demonstrate the superiority of our AlignDistil over existing methods and showcase fast convergence due to its token-level distributional reward optimization.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.02832",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Discovering types for entity disambiguation",
    "description": "We‚Äôve built a system for automatically figuring out which object is meant by a word by having a neural network decide if the word belongs to each of about 100 automatically-discovered ‚Äútypes‚Äù (non-exclusive categories).",
    "summary": "We‚Äôve built a system for automatically figuring out which object is meant by a word by having a neural network decide if the word belongs to each of about 100 automatically-discovered ‚Äútypes‚Äù (non-exclusive categories).",
    "pubDate": "Wed, 07 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/discovering-types-for-entity-disambiguation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Asymmetric actor critic for image-based robot learning",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 18 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/asymmetric-actor-critic-for-image-based-robot-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "OpenAI o1 and new tools for developers",
    "description": "Introducing OpenAI o1, Realtime API improvements, a new fine-tuning method and more for developers.",
    "summary": "Introducing OpenAI o1, Realtime API improvements, a new fine-tuning method and more for developers.",
    "pubDate": "Tue, 17 Dec 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-and-new-tools-for-developers",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The AI for Science Forum: A new era of discovery",
    "description": "The AI Science Forum highlights AI's present and potential role in revolutionizing scientific discovery and solving global challenges, emphasizing collaboration between the scientific community, policymakers, and industry leaders.",
    "summary": "The AI Science Forum highlights AI's present and potential role in revolutionizing scientific discovery and solving global challenges, emphasizing collaboration between the scientific community, policymakers, and industry leaders.",
    "pubDate": "Mon, 18 Nov 2024 19:57:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/the-ai-for-science-forum-a-new-era-of-discovery/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AIFS_Collection_SS.max-1440x810.jpg"
  },
  {
    "title": "OpenAI‚Äôs Raising Concerns Policy",
    "description": "We‚Äôre publishing our Raising Concerns Policy, which protects employees‚Äô rights to make protected disclosures.",
    "summary": "We‚Äôre publishing our Raising Concerns Policy, which protects employees‚Äô rights to make protected disclosures.",
    "pubDate": "Fri, 04 Oct 2024 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-raising-concerns-policy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Elevating Styled Mahjong Agents with Learning from Demonstration",
    "description": "arXiv:2506.16995v1 Announce Type: new Abstract: A wide variety of bots in games enriches the gameplay experience and enhances replayability. Recent advancements in game artificial intelligence have predominantly focused on improving the proficiency of bots. Nevertheless, developing highly competent bots with a wide range of distinct play styles remains a relatively under-explored area. We select the Mahjong game environment as a case study. The high degree of randomness inherent in the Mahjong game and the prevalence of out-of-distribution states lead to suboptimal performance of existing offline learning and Learning-from-Demonstration (LfD) algorithms. In this paper, we leverage the gameplay histories of existing Mahjong agents and put forward a novel LfD algorithm that necessitates only minimal modifications to the Proximal Policy Optimization algorithm. The comprehensive empirical results illustrate that our proposed method not only significantly enhances the proficiency of the agents but also effectively preserves their unique play styles.",
    "summary": "arXiv:2506.16995v1 Announce Type: new Abstract: A wide variety of bots in games enriches the gameplay experience and enhances replayability. Recent advancements in game artificial intelligence have predominantly focused on improving the proficiency of bots. Nevertheless, developing highly competent bots with a wide range of distinct play styles remains a relatively under-explored area. We select the Mahjong game environment as a case study. The high degree of randomness inherent in the Mahjong game and the prevalence of out-of-distribution states lead to suboptimal performance of existing offline learning and Learning-from-Demonstration (LfD) algorithms. In this paper, we leverage the gameplay histories of existing Mahjong agents and put forward a novel LfD algorithm that necessitates only minimal modifications to the Proximal Policy Optimization algorithm. The comprehensive empirical results illustrate that our proposed method not only significantly enhances the proficiency of the agents but also effectively preserves their unique play styles.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16995",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Inception Labs„ÅÆÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÇíË©¶„Åó„Å¶„Åø„Åü",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Êú¨Ë®ò‰∫ã„Åß„ÅØInception Labs„ÅÆMercury API„ÅÆ„Éô„Éº„ÇøÁâà„Åå‰Ωø„Åà„Çã„Çà„ÅÜ„Å´„Å™„Å£„Åü„ÅÆ„Åß„ÄÅÁ∞°Âçò„Å´Ë©¶„Åó„Å¶„Åø„Åæ„Åó„Åü„ÄÇ „Éâ„Ç≠„É•„É°„É≥„Éà„ÅØ„Åì„Å°„Çâ„ÅßÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ Êã°Êï£Ë®ÄË™û„É¢„Éá„É´ ÁèæÂú®„ÅÆ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5738' rel='nofollow'>Inception Labs„ÅÆÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÇíË©¶„Åó„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅ AI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Êú¨Ë®ò‰∫ã„Åß„ÅØInception Labs„ÅÆMercury API„ÅÆ„Éô„Éº„ÇøÁâà„Åå‰Ωø„Åà„Çã„Çà„ÅÜ„Å´„Å™„Å£„Åü„ÅÆ„Åß„ÄÅÁ∞°Âçò„Å´Ë©¶„Åó„Å¶„Åø„Åæ„Åó„Åü„ÄÇ „Éâ„Ç≠„É•„É°„É≥„Éà„ÅØ„Åì„Å°„Çâ„ÅßÁ¢∫Ë™ç„Åß„Åç„Åæ„Åô„ÄÇ Êã°Êï£Ë®ÄË™û„É¢„Éá„É´ ÁèæÂú®„ÅÆ [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5738' rel='nofollow'>Inception Labs„ÅÆÊã°Êï£Ë®ÄË™û„É¢„Éá„É´„ÇíË©¶„Åó„Å¶„Åø„Åü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Thu, 01 May 2025 03:02:11 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5738",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/04/f81fd2e4c52864042852c112ce927ae2-1.png"
  },
  {
    "title": "AI and efficiency",
    "description": "We‚Äôre releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet¬†classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet¬†(by contrast, Moore‚Äôs Law¬†would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware¬†efficiency.",
    "summary": "We‚Äôre releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet¬†classification has been decreasing by a factor of 2 every 16 months. Compared to 2012, it now takes 44 times less compute to train a neural network to the level of AlexNet¬†(by contrast, Moore‚Äôs Law¬†would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high levels of recent investment, algorithmic progress has yielded more gains than classical hardware¬†efficiency.",
    "pubDate": "Tue, 05 May 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/ai-and-efficiency",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Building a data-driven, efficient culture with AI",
    "description": "Holiday Extras rolls out ChatGPT Enterprise across every team, boosting productivity by 500 hours weekly.",
    "summary": "Holiday Extras rolls out ChatGPT Enterprise across every team, boosting productivity by 500 hours weekly.",
    "pubDate": "Mon, 18 Mar 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/holiday-extras",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Evaluating fairness in ChatGPT",
    "description": "We've analyzed how ChatGPT responds to users based on their name, using AI research assistants to protect privacy.",
    "summary": "We've analyzed how ChatGPT responds to users based on their name, using AI research assistants to protect privacy.",
    "pubDate": "Tue, 15 Oct 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/evaluating-fairness-in-chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "We Raised $100 Million for Open & Collaborative Machine Learning üöÄ",
    "description": "",
    "summary": "We Raised $100 Million for Open & Collaborative Machine Learning üöÄ Today we have some exciting news ...",
    "pubDate": "Mon, 09 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/series-c",
    "thumbnail": "https://huggingface.co/blog/assets/65_series_c/thumbnail.jpg"
  },
  {
    "title": "What do professional software developers need to know to succeed in an age of Artificial Intelligence?",
    "description": "arXiv:2506.00202v3 Announce Type: replace Abstract: Generative AI is showing early evidence of productivity gains for software developers, but concerns persist regarding workforce disruption and deskilling. We describe our research with 21 developers at the cutting edge of using AI, summarizing 12 of their work goals we uncovered, together with 75 associated tasks and the skills & knowledge for each, illustrating how developers use AI at work. From all of these, we distilled our findings in the form of 5 insights. We found that the skills & knowledge to be a successful AI-enhanced developer are organized into four domains (using Generative AI effectively, core software engineering, adjacent engineering, and adjacent non-engineering) deployed at critical junctures throughout a 6-step task workflow. In order to 'future proof' developers for this age of AI, on-the-job learning initiatives and computer science degree programs will need to target both 'soft' skills and the technical skills & knowledge in all four domains to reskill, upskill and safeguard against deskilling.",
    "summary": "arXiv:2506.00202v3 Announce Type: replace Abstract: Generative AI is showing early evidence of productivity gains for software developers, but concerns persist regarding workforce disruption and deskilling. We describe our research with 21 developers at the cutting edge of using AI, summarizing 12 of their work goals we uncovered, together with 75 associated tasks and the skills & knowledge for each, illustrating how developers use AI at work. From all of these, we distilled our findings in the form of 5 insights. We found that the skills & knowledge to be a successful AI-enhanced developer are organized into four domains (using Generative AI effectively, core software engineering, adjacent engineering, and adjacent non-engineering) deployed at critical junctures throughout a 6-step task workflow. In order to 'future proof' developers for this age of AI, on-the-job learning initiatives and computer science degree programs will need to target both 'soft' skills and the technical skills & knowledge in all four domains to reskill, upskill and safeguard against deskilling.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.00202",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "New commission to provide insight as OpenAI builds the world‚Äôs best-equipped nonprofit",
    "description": "Already a nonprofit, and already using AI to help people solve hard problems, OpenAI aims to build the best-equipped nonprofit the world has ever seen‚Äîcombining potentially historic financial resources with something even more powerful: technology that can scale human ingenuity itself.",
    "summary": "Already a nonprofit, and already using AI to help people solve hard problems, OpenAI aims to build the best-equipped nonprofit the world has ever seen‚Äîcombining potentially historic financial resources with something even more powerful: technology that can scale human ingenuity itself.",
    "pubDate": "Wed, 02 Apr 2025 12:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/nonprofit-commission-guidance",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Optimizing Sensory Neurons: Nonlinear Attention Mechanisms for Accelerated Convergence in Permutation-Invariant Neural Networks for Reinforcement Learning",
    "description": "arXiv:2506.00691v3 Announce Type: replace-cross Abstract: Training reinforcement learning (RL) agents often requires significant computational resources and prolonged training durations. To address this challenge, we build upon prior work that introduced a neural architecture with permutation-invariant sensory processing. We propose a modified attention mechanism that applies a non-linear transformation to the key vectors (K), producing enriched representations (K') through a custom mapping function. This Nonlinear Attention (NLA) mechanism enhances the representational capacity of the attention layer, enabling the agent to learn more expressive feature interactions. As a result, our model achieves significantly faster convergence and improved training efficiency, while maintaining performance on par with the baseline. These results highlight the potential of nonlinear attention mechanisms to accelerate reinforcement learning without sacrificing effectiveness.",
    "summary": "arXiv:2506.00691v3 Announce Type: replace-cross Abstract: Training reinforcement learning (RL) agents often requires significant computational resources and prolonged training durations. To address this challenge, we build upon prior work that introduced a neural architecture with permutation-invariant sensory processing. We propose a modified attention mechanism that applies a non-linear transformation to the key vectors (K), producing enriched representations (K') through a custom mapping function. This Nonlinear Attention (NLA) mechanism enhances the representational capacity of the attention layer, enabling the agent to learn more expressive feature interactions. As a result, our model achieves significantly faster convergence and improved training efficiency, while maintaining performance on par with the baseline. These results highlight the potential of nonlinear attention mechanisms to accelerate reinforcement learning without sacrificing effectiveness.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.00691",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AGI-Driven Generative Semantic Communications: Principles and Practices",
    "description": "arXiv:2504.14947v2 Announce Type: replace Abstract: Semantic communications leverage artificial intelligence (AI) technologies to extract semantic information for efficient data delivery, thereby significantly reducing communication cost. With the evolution towards artificial general intelligence (AGI), the increasing demands for AGI services pose new challenges to semantic communications. In this context, an AGI application is typically defined on a general-sense task, covering a broad, even unforeseen, set of objectives, as well as driven by the need for a human-friendly interface in forms (e.g., videos, images, or text) easily understood by human users.In response, we introduce an AGI-driven communication paradigm for supporting AGI applications, called generative semantic communication (GSC). We first describe the basic concept of GSC and its difference from existing semantic communications, and then introduce a general framework of GSC based on advanced AI technologies including foundation models and generative models. Two case studies are presented to verify the advantages of GSC. Finally, open challenges and new research directions are discussed to stimulate this line of research and pave the way for practical applications.",
    "summary": "arXiv:2504.14947v2 Announce Type: replace Abstract: Semantic communications leverage artificial intelligence (AI) technologies to extract semantic information for efficient data delivery, thereby significantly reducing communication cost. With the evolution towards artificial general intelligence (AGI), the increasing demands for AGI services pose new challenges to semantic communications. In this context, an AGI application is typically defined on a general-sense task, covering a broad, even unforeseen, set of objectives, as well as driven by the need for a human-friendly interface in forms (e.g., videos, images, or text) easily understood by human users.In response, we introduce an AGI-driven communication paradigm for supporting AGI applications, called generative semantic communication (GSC). We first describe the basic concept of GSC and its difference from existing semantic communications, and then introduce a general framework of GSC based on advanced AI technologies including foundation models and generative models. Two case studies are presented to verify the advantages of GSC. Finally, open challenges and new research directions are discussed to stimulate this line of research and pave the way for practical applications.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.14947",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Enabling a Data-Driven Workforce",
    "description": "In this video, we share practical examples of how employees can use ChatGPT Enterprise to efficiently analyze data and uncover insights.",
    "summary": "In this video, we share practical examples of how employees can use ChatGPT Enterprise to efficiently analyze data and uncover insights.",
    "pubDate": "Thu, 08 Aug 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/business/enabling-a-data-driven-workforce-webinar",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A catalogue of genetic mutations to help pinpoint the cause of diseases",
    "description": "New AI tool classifies the effects of 71 million ‚Äòmissense‚Äô mutations.",
    "summary": "New AI tool classifies the effects of 71 million ‚Äòmissense‚Äô mutations.",
    "pubDate": "Tue, 19 Sep 2023 13:37:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/a-catalogue-of-genetic-mutations-to-help-pinpoint-the-cause-of-diseases/",
    "thumbnail": "https://lh3.googleusercontent.com/JySjDTZvGqEzUfDic5QOU6Rne3r6RWpiw5JZQ9VdzK1O5C20EbAkSPURGoCmAhea_U-gyyRu4KdCZmeWSCtYjGHHMvM0jVK5fWiqOwa0rpcC5uzM=w1200-h630-n-nu"
  },
  {
    "title": "Heuristics for AI-driven Graphical Asset Generation Tools in Game Design and Development Pipelines: A User-Centred Approach",
    "description": "arXiv:2503.02703v2 Announce Type: replace-cross Abstract: Graphical assets play an important role in the design and development of games. There is potential in the use of AI-driven generative tools, to aid in creating graphical assets, thus improving game design and development pipelines. However, there is little research to address how the generative methods can fit into the wider pipeline. There also no guidelines or heuristics for creating such tools. To address this gap we conducted a user study with 16 game designers and developers to examine their behaviour and interaction with generative tools for graphical assets. The findings highlight that early design stage is preferred by all participants. Designers and developers are inclined to use such tools for creating large amounts of variations at the cost of quality as they can improve the quality of the artefacts once they generate a suitable asset. The results also strongly raised the need for better integration of such tools in existing design and development environments and the need for the outputs to be in common data formats, to be manipulatable and smoothly integrate into existing environments. The study also highlights the requirement for further emphasis on the needs of the users to incorporate these tools effectively in existing pipelines. Informed by these results, we provide a set of heuristics for creating tools that meet the expectations and needs of game designers and developers.",
    "summary": "arXiv:2503.02703v2 Announce Type: replace-cross Abstract: Graphical assets play an important role in the design and development of games. There is potential in the use of AI-driven generative tools, to aid in creating graphical assets, thus improving game design and development pipelines. However, there is little research to address how the generative methods can fit into the wider pipeline. There also no guidelines or heuristics for creating such tools. To address this gap we conducted a user study with 16 game designers and developers to examine their behaviour and interaction with generative tools for graphical assets. The findings highlight that early design stage is preferred by all participants. Designers and developers are inclined to use such tools for creating large amounts of variations at the cost of quality as they can improve the quality of the artefacts once they generate a suitable asset. The results also strongly raised the need for better integration of such tools in existing design and development environments and the need for the outputs to be in common data formats, to be manipulatable and smoothly integrate into existing environments. The study also highlights the requirement for further emphasis on the needs of the users to incorporate these tools effectively in existing pipelines. Informed by these results, we provide a set of heuristics for creating tools that meet the expectations and needs of game designers and developers.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.02703",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing HuggingFace blog for Chinese speakers: Fostering Collaboration with the Chinese AI community",
    "description": "",
    "summary": "Introducing HuggingFace blog for Chinese speakers: Fostering Collaboration with the Chinese AI commu...",
    "pubDate": "Mon, 24 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/chinese-language-blog",
    "thumbnail": "https://huggingface.co/blog/assets/chinese-language-blog/thumbnail.png"
  },
  {
    "title": "Training CodeParrot ü¶ú from Scratch",
    "description": "",
    "summary": "Training CodeParrot ü¶ú from Scratch In this blog post we'll take a look at what it takes to build the...",
    "pubDate": "Wed, 08 Dec 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codeparrot",
    "thumbnail": "https://huggingface.co/blog/assets/40_codeparrot/thumbnail.png"
  },
  {
    "title": "Introducing Gemini 2.5 Flash",
    "description": "Gemini 2.5 Flash is our first fully hybrid reasoning model, giving developers the ability to turn thinking on or off.",
    "summary": "Gemini 2.5 Flash is our first fully hybrid reasoning model, giving developers the ability to turn thinking on or off.",
    "pubDate": "Thu, 17 Apr 2025 19:02:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/introducing-gemini-2-5-flash/",
    "thumbnail": "https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Gemini-2-5-Flash-ai.dev.2e16d0ba.fill-1200x600.png"
  },
  {
    "title": "Report from the self-organizing conference",
    "description": "Last week we hosted over a hundred and fifty AI practitioners in our offices for our first self-organizing conference on machine learning.",
    "summary": "Last week we hosted over a hundred and fifty AI practitioners in our offices for our first self-organizing conference on machine learning.",
    "pubDate": "Thu, 13 Oct 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/report-from-the-self-organizing-conference",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CVE-Bench: A Benchmark for AI Agents' Ability to Exploit Real-World Web Application Vulnerabilities",
    "description": "arXiv:2503.17332v4 Announce Type: replace-cross Abstract: Large language model (LLM) agents are increasingly capable of autonomously conducting cyberattacks, posing significant threats to existing applications. This growing risk highlights the urgent need for a real-world benchmark to evaluate the ability of LLM agents to exploit web application vulnerabilities. However, existing benchmarks fall short as they are limited to abstracted Capture the Flag competitions or lack comprehensive coverage. Building a benchmark for real-world vulnerabilities involves both specialized expertise to reproduce exploits and a systematic approach to evaluating unpredictable threats. To address this challenge, we introduce CVE-Bench, a real-world cybersecurity benchmark based on critical-severity Common Vulnerabilities and Exposures. In CVE-Bench, we design a sandbox framework that enables LLM agents to exploit vulnerable web applications in scenarios that mimic real-world conditions, while also providing effective evaluation of their exploits. Our evaluation shows that the state-of-the-art agent framework can resolve up to 13% of vulnerabilities.",
    "summary": "arXiv:2503.17332v4 Announce Type: replace-cross Abstract: Large language model (LLM) agents are increasingly capable of autonomously conducting cyberattacks, posing significant threats to existing applications. This growing risk highlights the urgent need for a real-world benchmark to evaluate the ability of LLM agents to exploit web application vulnerabilities. However, existing benchmarks fall short as they are limited to abstracted Capture the Flag competitions or lack comprehensive coverage. Building a benchmark for real-world vulnerabilities involves both specialized expertise to reproduce exploits and a systematic approach to evaluating unpredictable threats. To address this challenge, we introduce CVE-Bench, a real-world cybersecurity benchmark based on critical-severity Common Vulnerabilities and Exposures. In CVE-Bench, we design a sandbox framework that enables LLM agents to exploit vulnerable web applications in scenarios that mimic real-world conditions, while also providing effective evaluation of their exploits. Our evaluation shows that the state-of-the-art agent framework can resolve up to 13% of vulnerabilities.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.17332",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Toward understanding and preventing misalignment generalization",
    "description": "We study how training on incorrect responses can cause broader misalignment in language models and identify an internal feature driving this behavior‚Äîone that can be reversed with minimal fine-tuning.",
    "summary": "We study how training on incorrect responses can cause broader misalignment in language models and identify an internal feature driving this behavior‚Äîone that can be reversed with minimal fine-tuning.",
    "pubDate": "Wed, 18 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/emergent-misalignment",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LLMs factor in unrelated information when recommending medical treatments",
    "description": "Researchers find nonclinical information in patient messages ‚Äî like typos, extra white space, and colorful language ‚Äî reduces the accuracy of an AI model.",
    "summary": "Researchers find nonclinical information in patient messages ‚Äî like typos, extra white space, and colorful language ‚Äî reduces the accuracy of an AI model.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/llms-factor-unrelated-information-when-recommending-medical-treatments-0623",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/MIT_Medium-Message-01-press.jpg"
  },
  {
    "title": "MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification",
    "description": "arXiv:2506.17140v1 Announce Type: cross Abstract: Deep learning models have made significant advances in histological prediction tasks in recent years. However, for adaptation in clinical practice, their lack of robustness to varying conditions such as staining, scanner, hospital, and demographics is still a limiting factor: if trained on overrepresented subpopulations, models regularly struggle with less frequent patterns, leading to shortcut learning and biased predictions. Large-scale foundation models have not fully eliminated this issue. Therefore, we propose a novel approach explicitly modeling such metadata into a Metadata-guided generative Diffusion model framework (MeDi). MeDi allows for a targeted augmentation of underrepresented subpopulations with synthetic data, which balances limited training data and mitigates biases in downstream models. We experimentally show that MeDi generates high-quality histopathology images for unseen subpopulations in TCGA, boosts the overall fidelity of the generated images, and enables improvements in performance for downstream classifiers on datasets with subpopulation shifts. Our work is a proof-of-concept towards better mitigating data biases with generative models.",
    "summary": "arXiv:2506.17140v1 Announce Type: cross Abstract: Deep learning models have made significant advances in histological prediction tasks in recent years. However, for adaptation in clinical practice, their lack of robustness to varying conditions such as staining, scanner, hospital, and demographics is still a limiting factor: if trained on overrepresented subpopulations, models regularly struggle with less frequent patterns, leading to shortcut learning and biased predictions. Large-scale foundation models have not fully eliminated this issue. Therefore, we propose a novel approach explicitly modeling such metadata into a Metadata-guided generative Diffusion model framework (MeDi). MeDi allows for a targeted augmentation of underrepresented subpopulations with synthetic data, which balances limited training data and mitigates biases in downstream models. We experimentally show that MeDi generates high-quality histopathology images for unseen subpopulations in TCGA, boosts the overall fidelity of the generated images, and enables improvements in performance for downstream classifiers on datasets with subpopulation shifts. Our work is a proof-of-concept towards better mitigating data biases with generative models.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17140",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Concrete AI safety problems",
    "description": "We (along with researchers from Berkeley and Stanford) are co-authors on today‚Äôs paper led by Google Brain researchers,¬†Concrete Problems in AI Safety. The paper explores many research problems around ensuring that modern machine learning systems operate as intended.",
    "summary": "We (along with researchers from Berkeley and Stanford) are co-authors on today‚Äôs paper led by Google Brain researchers,¬†Concrete Problems in AI Safety. The paper explores many research problems around ensuring that modern machine learning systems operate as intended.",
    "pubDate": "Tue, 21 Jun 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/concrete-ai-safety-problems",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Each Rank Could be an Expert: Single-Ranked Mixture of Experts LoRA for Multi-Task Learning",
    "description": "arXiv:2501.15103v2 Announce Type: replace-cross Abstract: Low-Rank Adaptation (LoRA) is widely used for adapting large language models (LLMs) to specific domains due to its efficiency and modularity. Meanwhile, vanilla LoRA struggles with task conflicts in multi-task scenarios. Recent works adopt Mixture of Experts (MoE) by treating each LoRA module as an expert, thereby mitigating task interference through multiple specialized LoRA modules. While effective, these methods often isolate knowledge within individual tasks, failing to fully exploit the shared knowledge across related tasks. In this paper, we establish a connection between single LoRA and multi-LoRA MoE, integrating them into a unified framework. We demonstrate that the dynamic routing of multiple LoRAs is functionally equivalent to rank partitioning and block-level activation within a single LoRA. We further empirically demonstrate that finer-grained LoRA partitioning, within the same total and activated parameter constraints, leads to better performance gains across heterogeneous tasks. Building on these findings, we propose Single-ranked Mixture of Experts LoRA (textbf{SMoRA}), which embeds MoE into LoRA by textit{treating each rank as an independent expert}. With a textit{dynamic rank-wise activation} mechanism, SMoRA promotes finer-grained knowledge sharing while mitigating task conflicts. Experiments demonstrate that SMoRA activates fewer parameters yet achieves better performance in multi-task scenarios.",
    "summary": "arXiv:2501.15103v2 Announce Type: replace-cross Abstract: Low-Rank Adaptation (LoRA) is widely used for adapting large language models (LLMs) to specific domains due to its efficiency and modularity. Meanwhile, vanilla LoRA struggles with task conflicts in multi-task scenarios. Recent works adopt Mixture of Experts (MoE) by treating each LoRA module as an expert, thereby mitigating task interference through multiple specialized LoRA modules. While effective, these methods often isolate knowledge within individual tasks, failing to fully exploit the shared knowledge across related tasks. In this paper, we establish a connection between single LoRA and multi-LoRA MoE, integrating them into a unified framework. We demonstrate that the dynamic routing of multiple LoRAs is functionally equivalent to rank partitioning and block-level activation within a single LoRA. We further empirically demonstrate that finer-grained LoRA partitioning, within the same total and activated parameter constraints, leads to better performance gains across heterogeneous tasks. Building on these findings, we propose Single-ranked Mixture of Experts LoRA (textbf{SMoRA}), which embeds MoE into LoRA by textit{treating each rank as an independent expert}. With a textit{dynamic rank-wise activation} mechanism, SMoRA promotes finer-grained knowledge sharing while mitigating task conflicts. Experiments demonstrate that SMoRA activates fewer parameters yet achieves better performance in multi-task scenarios.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.15103",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Nature Language Model: Deciphering the Language of Nature for Scientific Discovery",
    "description": "arXiv:2502.07527v3 Announce Type: replace Abstract: Foundation models have revolutionized natural language processing and artificial intelligence, significantly enhancing how machines comprehend and generate human languages. Inspired by the success of these foundation models, researchers have developed foundation models for individual scientific domains, including small molecules, materials, proteins, DNA, RNA and even cells. However, these models are typically trained in isolation, lacking the ability to integrate across different scientific domains. Recognizing that entities within these domains can all be represented as sequences, which together form the 'language of nature', we introduce Nature Language Model (NatureLM), a sequence-based science foundation model designed for scientific discovery. Pre-trained with data from multiple scientific domains, NatureLM offers a unified, versatile model that enables various applications including: (i) generating and optimizing small molecules, proteins, RNA, and materials using text instructions; (ii) cross-domain generation/design, such as protein-to-molecule and protein-to-RNA generation; and (iii) top performance across different domains, matching or surpassing state-of-the-art specialist models. NatureLM offers a promising generalist approach for various scientific tasks, including drug discovery (hit generation/optimization, ADMET optimization, synthesis), novel material design, and the development of therapeutic proteins or nucleotides. We have developed NatureLM models in different sizes (1 billion, 8 billion, and 46.7 billion parameters) and observed a clear improvement in performance as the model size increases.",
    "summary": "arXiv:2502.07527v3 Announce Type: replace Abstract: Foundation models have revolutionized natural language processing and artificial intelligence, significantly enhancing how machines comprehend and generate human languages. Inspired by the success of these foundation models, researchers have developed foundation models for individual scientific domains, including small molecules, materials, proteins, DNA, RNA and even cells. However, these models are typically trained in isolation, lacking the ability to integrate across different scientific domains. Recognizing that entities within these domains can all be represented as sequences, which together form the 'language of nature', we introduce Nature Language Model (NatureLM), a sequence-based science foundation model designed for scientific discovery. Pre-trained with data from multiple scientific domains, NatureLM offers a unified, versatile model that enables various applications including: (i) generating and optimizing small molecules, proteins, RNA, and materials using text instructions; (ii) cross-domain generation/design, such as protein-to-molecule and protein-to-RNA generation; and (iii) top performance across different domains, matching or surpassing state-of-the-art specialist models. NatureLM offers a promising generalist approach for various scientific tasks, including drug discovery (hit generation/optimization, ADMET optimization, synthesis), novel material design, and the development of therapeutic proteins or nucleotides. We have developed NatureLM models in different sizes (1 billion, 8 billion, and 46.7 billion parameters) and observed a clear improvement in performance as the model size increases.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.07527",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "How to host a Unity game in a Space",
    "description": "",
    "summary": "How to host a Unity game in a Space Did you know you can host a Unity game in a Hugging Face Space? ...",
    "pubDate": "Fri, 21 Apr 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/unity-in-spaces",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/unity-in-spaces-thumbnail.png"
  },
  {
    "title": "Introducing ChatGPT Enterprise",
    "description": "Get enterprise-grade security & privacy and the most powerful version of ChatGPT yet.",
    "summary": "Get enterprise-grade security & privacy and the most powerful version of ChatGPT yet.",
    "pubDate": "Mon, 28 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-chatgpt-enterprise",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Êó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶Âàù„ÄÅÊù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅåNVIDIA DGX„ÅÆAI„Çπ„Éë„Ç≥„É≥„ÇíÊßãÁØâ„ÄÇ„ÄåAIÂ§ßÂ≠¶„ÄçÊßãÊÉ≥„ÇíÂä†ÈÄü",
    "description": "<p>Êù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅØ„ÄÅAIÊïôËÇ≤„Å®Á†îÁ©∂„ÇíÂä†ÈÄü„Åï„Åõ„Çã„Åü„ÇÅ„ÄÅNVIDIA DGX B200„Ç∑„Çπ„ÉÜ„É†„ÇíÁî®„ÅÑ„ÅüÊó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶ÊúÄÂ§ß„ÅÆAI„Çπ„Éº„Éë„Éº„Ç≥„É≥„Éî„É•„Éº„Çø„Éº„ÇíÊßãÁØâ„Åó„ÄÅ2025Âπ¥10Êúà„Å´Êú¨Ê†ºÁ®ºÂÉç‰∫àÂÆö„Åß„Åô„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Êù±‰∫¨Â∑•Áßë [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/teu-ac-nvidia-dgx/'>Êó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶Âàù„ÄÅÊù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅåNVIDIA DGX„ÅÆAI„Çπ„Éë„Ç≥„É≥„ÇíÊßãÁØâ„ÄÇ„ÄåAIÂ§ßÂ≠¶„ÄçÊßãÊÉ≥„ÇíÂä†ÈÄü</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "summary": "<p>Êù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅØ„ÄÅAIÊïôËÇ≤„Å®Á†îÁ©∂„ÇíÂä†ÈÄü„Åï„Åõ„Çã„Åü„ÇÅ„ÄÅNVIDIA DGX B200„Ç∑„Çπ„ÉÜ„É†„ÇíÁî®„ÅÑ„ÅüÊó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶ÊúÄÂ§ß„ÅÆAI„Çπ„Éº„Éë„Éº„Ç≥„É≥„Éî„É•„Éº„Çø„Éº„ÇíÊßãÁØâ„Åó„ÄÅ2025Âπ¥10Êúà„Å´Êú¨Ê†ºÁ®ºÂÉç‰∫àÂÆö„Åß„Åô„ÄÇ „Åì„ÅÆ„Éã„É•„Éº„Çπ„ÅÆ„Éù„Ç§„É≥„Éà Êù±‰∫¨Â∑•Áßë [&#8230;]</p> <p>The post <a href='https://aismiley.co.jp/ai_news/teu-ac-nvidia-dgx/'>Êó•Êú¨„ÅÆÁßÅÁ´ãÂ§ßÂ≠¶Âàù„ÄÅÊù±‰∫¨Â∑•ÁßëÂ§ßÂ≠¶„ÅåNVIDIA DGX„ÅÆAI„Çπ„Éë„Ç≥„É≥„ÇíÊßãÁØâ„ÄÇ„ÄåAIÂ§ßÂ≠¶„ÄçÊßãÊÉ≥„ÇíÂä†ÈÄü</a> first appeared on <a href='https://aismiley.co.jp'>AI„Éù„Éº„Çø„É´„É°„Éá„Ç£„Ç¢AIsmiley</a>.</p>",
    "pubDate": "Wed, 25 Jun 2025 09:24:03 +0000",
    "source": "AI Smily",
    "url": "https://aismiley.co.jp/ai_news/teu-ac-nvidia-dgx/",
    "thumbnail": "https://aismiley.co.jp/wp-content/uploads/2025/06/teu0.png"
  },
  {
    "title": "LLM„ÅßÊåë„ÇÄTitanicÁîüÂ≠ò‰∫àÊ∏¨: Few-Shot Leaning„ÅßË°®ÂΩ¢Âºè„Éá„Éº„Çø„ÅØ„Å©„Åì„ÅæËß£„Åë„ÇãÔºü",
    "description": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Kaggle„ÅÆTitanic„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ„ÄÅÊ©üÊ¢∞Â≠¶Áøí„ÅÆÂÖ•ÈñÄ„Å®„Åó„Å¶ÂÆöÁï™„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ Â§ö„Åè„ÅÆÊ©üÊ¢∞Â≠¶ÁøíÊâãÊ≥ï„ÅåË©¶„Åï„Çå„Å¶„Åç„Åü„Åì„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´ÂØæ„Åó„ÄÅ‰ªäÂõû„ÅØÂ∞ë„ÅóÁï∞„Å™„Çã„Ç¢„Éó„É≠„Éº„ÉÅ„ÇíË©¶„Åø„Åü„ÅÑ„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5560' rel='nofollow'>LLM„ÅßÊåë„ÇÄTitanicÁîüÂ≠ò‰∫àÊ∏¨: Few-Shot Leaning„ÅßË°®ÂΩ¢Âºè„Éá„Éº„Çø„ÅØ„Å©„Åì„ÅæËß£„Åë„ÇãÔºü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "summary": "<p>„Åì„Çì„Å´„Å°„ÅØ„ÄÅAI„ÉÅ„Éº„É†„ÅÆÊà∏Áî∞„Åß„Åô„ÄÇ Kaggle„ÅÆTitanic„Éá„Éº„Çø„Çª„ÉÉ„Éà„ÅØ„ÄÅÊ©üÊ¢∞Â≠¶Áøí„ÅÆÂÖ•ÈñÄ„Å®„Åó„Å¶ÂÆöÁï™„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Åß„Åô„ÄÇ Â§ö„Åè„ÅÆÊ©üÊ¢∞Â≠¶ÁøíÊâãÊ≥ï„ÅåË©¶„Åï„Çå„Å¶„Åç„Åü„Åì„ÅÆ„Éá„Éº„Çø„Çª„ÉÉ„Éà„Å´ÂØæ„Åó„ÄÅ‰ªäÂõû„ÅØÂ∞ë„ÅóÁï∞„Å™„Çã„Ç¢„Éó„É≠„Éº„ÉÅ„ÇíË©¶„Åø„Åü„ÅÑ„Å® [&#8230;]</p> <p>ÊäïÁ®ø <a href='https://www.ai-shift.co.jp/techblog/5560' rel='nofollow'>LLM„ÅßÊåë„ÇÄTitanicÁîüÂ≠ò‰∫àÊ∏¨: Few-Shot Leaning„ÅßË°®ÂΩ¢Âºè„Éá„Éº„Çø„ÅØ„Å©„Åì„ÅæËß£„Åë„ÇãÔºü</a> „ÅØ <a href='https://www.ai-shift.co.jp' rel='nofollow'>Ê†™Âºè‰ºöÁ§æAI Shift</a> „Å´ÊúÄÂàù„Å´Ë°®Á§∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ</p>",
    "pubDate": "Mon, 17 Mar 2025 21:16:00 +0000",
    "source": "AI Shift",
    "url": "https://www.ai-shift.co.jp/techblog/5560",
    "thumbnail": "https://www.ai-shift.co.jp/wp-content/uploads/2025/03/f81fd2e4c52864042852c112ce927ae2.png"
  },
  {
    "title": "Achieving 10x growth with agentic sales prospecting",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 18 Jun 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/clay",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "New funding to build towards AGI",
    "description": "Today we‚Äôre announcing new funding‚Äî$40B at a $300B post-money valuation, which enables us to push the frontiers of AI research even further, scale our compute infrastructure, and deliver increasingly powerful tools for the 500 million people who use ChatGPT every week.",
    "summary": "Today we‚Äôre announcing new funding‚Äî$40B at a $300B post-money valuation, which enables us to push the frontiers of AI research even further, scale our compute infrastructure, and deliver increasingly powerful tools for the 500 million people who use ChatGPT every week.",
    "pubDate": "Mon, 31 Mar 2025 15:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/march-funding-updates",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "ALTA: Compiler-Based Analysis of Transformers",
    "description": "arXiv:2410.18077v2 Announce Type: replace-cross Abstract: We propose a new programming language called ALTA and a compiler that can map ALTA programs to Transformer weights. ALTA is inspired by RASP, a language proposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler from RASP programs to Transformer weights. ALTA complements and extends this prior work, offering the ability to express loops and to compile programs to Universal Transformers, among other advantages. ALTA allows us to constructively show how Transformers can represent length-invariant algorithms for computing parity and addition, as well as a solution to the SCAN benchmark of compositional generalization tasks, without requiring intermediate scratchpad decoding steps. We also propose tools to analyze cases where the expressibility of an algorithm is established, but end-to-end training on a given training set fails to induce behavior consistent with the desired algorithm. To this end, we explore training from ALTA execution traces as a more fine-grained supervision signal. This enables additional experiments and theoretical analyses relating the learnability of various algorithms to data availability and modeling decisions, such as positional encodings. We make the ALTA framework -- language specification, symbolic interpreter, and weight compiler -- available to the community to enable further applications and insights.",
    "summary": "arXiv:2410.18077v2 Announce Type: replace-cross Abstract: We propose a new programming language called ALTA and a compiler that can map ALTA programs to Transformer weights. ALTA is inspired by RASP, a language proposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler from RASP programs to Transformer weights. ALTA complements and extends this prior work, offering the ability to express loops and to compile programs to Universal Transformers, among other advantages. ALTA allows us to constructively show how Transformers can represent length-invariant algorithms for computing parity and addition, as well as a solution to the SCAN benchmark of compositional generalization tasks, without requiring intermediate scratchpad decoding steps. We also propose tools to analyze cases where the expressibility of an algorithm is established, but end-to-end training on a given training set fails to induce behavior consistent with the desired algorithm. To this end, we explore training from ALTA execution traces as a more fine-grained supervision signal. This enables additional experiments and theoretical analyses relating the learnability of various algorithms to data availability and modeling decisions, such as positional encodings. We make the ALTA framework -- language specification, symbolic interpreter, and weight compiler -- available to the community to enable further applications and insights.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.18077",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ADNet: Leveraging Error-Bias Towards Normal Direction in Face Alignment",
    "description": "arXiv:2109.05721v2 Announce Type: cross Abstract: The recent progress of CNN has dramatically improved face alignment performance. However, few works have paid attention to the error-bias with respect to error distribution of facial landmarks. In this paper, we investigate the error-bias issue in face alignment, where the distributions of landmark errors tend to spread along the tangent line to landmark curves. This error-bias is not trivial since it is closely connected to the ambiguous landmark labeling task. Inspired by this observation, we seek a way to leverage the error-bias property for better convergence of CNN model. To this end, we propose anisotropic direction loss (ADL) and anisotropic attention module (AAM) for coordinate and heatmap regression, respectively. ADL imposes strong binding force in normal direction for each landmark point on facial boundaries. On the other hand, AAM is an attention module which can get anisotropic attention mask focusing on the region of point and its local edge connected by adjacent points, it has a stronger response in tangent than in normal, which means relaxed constraints in the tangent. These two methods work in a complementary manner to learn both facial structures and texture details. Finally, we integrate them into an optimized end-to-end training pipeline named ADNet. Our ADNet achieves state-of-the-art results on 300W, WFLW and COFW datasets, which demonstrates the effectiveness and robustness.",
    "summary": "arXiv:2109.05721v2 Announce Type: cross Abstract: The recent progress of CNN has dramatically improved face alignment performance. However, few works have paid attention to the error-bias with respect to error distribution of facial landmarks. In this paper, we investigate the error-bias issue in face alignment, where the distributions of landmark errors tend to spread along the tangent line to landmark curves. This error-bias is not trivial since it is closely connected to the ambiguous landmark labeling task. Inspired by this observation, we seek a way to leverage the error-bias property for better convergence of CNN model. To this end, we propose anisotropic direction loss (ADL) and anisotropic attention module (AAM) for coordinate and heatmap regression, respectively. ADL imposes strong binding force in normal direction for each landmark point on facial boundaries. On the other hand, AAM is an attention module which can get anisotropic attention mask focusing on the region of point and its local edge connected by adjacent points, it has a stronger response in tangent than in normal, which means relaxed constraints in the tangent. These two methods work in a complementary manner to learn both facial structures and texture details. Finally, we integrate them into an optimized end-to-end training pipeline named ADNet. Our ADNet achieves state-of-the-art results on 300W, WFLW and COFW datasets, which demonstrates the effectiveness and robustness.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2109.05721",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "NAADA: A Noise-Aware Attention Denoising Autoencoder for Dental Panoramic Radiographs",
    "description": "arXiv:2506.19387v1 Announce Type: cross Abstract: Convolutional denoising autoencoders (DAEs) are powerful tools for image restoration. However, they inherit a key limitation of convolutional neural networks (CNNs): they tend to recover low-frequency features, such as smooth regions, more effectively than high-frequency details. This leads to the loss of fine details, which is particularly problematic in dental radiographs where preserving subtle anatomical structures is crucial. While self-attention mechanisms can help mitigate this issue by emphasizing important features, conventional attention methods often prioritize features corresponding to cleaner regions and may overlook those obscured by noise. To address this limitation, we propose a noise-aware self-attention method, which allows the model to effectively focus on and recover key features even within noisy regions. Building on this approach, we introduce the noise-aware attention-enhanced denoising autoencoder (NAADA) network for enhancing noisy panoramic dental radiographs. Compared with the recent state of the art (and much heavier) methods like Uformer, MResDNN etc., our method improves the reconstruction of fine details, ensuring better image quality and diagnostic accuracy.",
    "summary": "arXiv:2506.19387v1 Announce Type: cross Abstract: Convolutional denoising autoencoders (DAEs) are powerful tools for image restoration. However, they inherit a key limitation of convolutional neural networks (CNNs): they tend to recover low-frequency features, such as smooth regions, more effectively than high-frequency details. This leads to the loss of fine details, which is particularly problematic in dental radiographs where preserving subtle anatomical structures is crucial. While self-attention mechanisms can help mitigate this issue by emphasizing important features, conventional attention methods often prioritize features corresponding to cleaner regions and may overlook those obscured by noise. To address this limitation, we propose a noise-aware self-attention method, which allows the model to effectively focus on and recover key features even within noisy regions. Building on this approach, we introduce the noise-aware attention-enhanced denoising autoencoder (NAADA) network for enhancing noisy panoramic dental radiographs. Compared with the recent state of the art (and much heavier) methods like Uformer, MResDNN etc., our method improves the reconstruction of fine details, ensuring better image quality and diagnostic accuracy.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19387",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLMs in Coding and their Impact on the Commercial Software Engineering Landscape",
    "description": "arXiv:2506.16653v1 Announce Type: cross Abstract: Large-language-model coding tools are now mainstream in software engineering. But as these same tools move human effort up the development stack, they present fresh dangers: 10% of real prompts leak private data, 42% of generated snippets hide security flaws, and the models can even ``agree'' with wrong ideas, a trait called sycophancy. We argue that firms must tag and review every AI-generated line of code, keep prompts and outputs inside private or on-premises deployments, obey emerging safety regulations, and add tests that catch sycophantic answers -- so they can gain speed without losing security and accuracy.",
    "summary": "arXiv:2506.16653v1 Announce Type: cross Abstract: Large-language-model coding tools are now mainstream in software engineering. But as these same tools move human effort up the development stack, they present fresh dangers: 10% of real prompts leak private data, 42% of generated snippets hide security flaws, and the models can even ``agree'' with wrong ideas, a trait called sycophancy. We argue that firms must tag and review every AI-generated line of code, keep prompts and outputs inside private or on-premises deployments, obey emerging safety regulations, and add tests that catch sycophantic answers -- so they can gain speed without losing security and accuracy.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16653",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "DolphinGemma: How Google AI is helping decode dolphin communication",
    "description": "DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate ‚Äî and hopefully find out what they're saying, too.",
    "summary": "DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate ‚Äî and hopefully find out what they're saying, too.",
    "pubDate": "Mon, 14 Apr 2025 17:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/dolphingemma-how-google-ai-is-helping-decode-dolphin-communication/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_SocialExplainers_16x9_DolphinGem.width-1300.png"
  },
  {
    "title": "Scaling security with responsible disclosure",
    "description": "OpenAI introduces its Outbound Coordinated Disclosure Policy to guide how it responsibly reports vulnerabilities in third-party software‚Äîemphasizing integrity, collaboration, and proactive security at scale.",
    "summary": "OpenAI introduces its Outbound Coordinated Disclosure Policy to guide how it responsibly reports vulnerabilities in third-party software‚Äîemphasizing integrity, collaboration, and proactive security at scale.",
    "pubDate": "Mon, 09 Jun 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-coordinated-vulnerability-disclosure",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Fanatics Betting and Gaming uses AI to focus on the big picture",
    "description": "A conversation with Andrea Ellis, Chief Financial Officer of Fanatics Betting and Gaming.",
    "summary": "A conversation with Andrea Ellis, Chief Financial Officer of Fanatics Betting and Gaming.",
    "pubDate": "Thu, 13 Feb 2025 10:01:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/fanatics-betting-gaming-andrea-ellis",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Prompt Caching in the API",
    "description": "Offering automatic discounts on inputs that the model has recently seen",
    "summary": "Offering automatic discounts on inputs that the model has recently seen",
    "pubDate": "Tue, 01 Oct 2024 10:03:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-prompt-caching",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Domain randomization and generative models for robotic grasping",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 17 Oct 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/domain-randomization-and-generative-models-for-robotic-grasping",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Bayesian-Guided Diversity in Sequential Sampling for Recommender Systems",
    "description": "arXiv:2506.21617v1 Announce Type: cross Abstract: The challenge of balancing user relevance and content diversity in recommender systems is increasingly critical amid growing concerns about content homogeneity and reduced user engagement. In this work, we propose a novel framework that leverages a multi-objective, contextual sequential sampling strategy. Item selection is guided by Bayesian updates that dynamically adjust scores to optimize diversity. The reward formulation integrates multiple diversity metrics-including the log-determinant volume of a tuned similarity submatrix and ridge leverage scores-along with a diversity gain uncertainty term to address the exploration-exploitation trade-off. Both intra- and inter-batch diversity are modeled to promote serendipity and minimize redundancy. A dominance-based ranking procedure identifies Pareto-optimal item sets, enabling adaptive and balanced selections at each iteration. Experiments on a real-world dataset show that our approach significantly improves diversity without sacrificing relevance, demonstrating its potential to enhance user experience in large-scale recommendation settings.",
    "summary": "arXiv:2506.21617v1 Announce Type: cross Abstract: The challenge of balancing user relevance and content diversity in recommender systems is increasingly critical amid growing concerns about content homogeneity and reduced user engagement. In this work, we propose a novel framework that leverages a multi-objective, contextual sequential sampling strategy. Item selection is guided by Bayesian updates that dynamically adjust scores to optimize diversity. The reward formulation integrates multiple diversity metrics-including the log-determinant volume of a tuned similarity submatrix and ridge leverage scores-along with a diversity gain uncertainty term to address the exploration-exploitation trade-off. Both intra- and inter-batch diversity are modeled to promote serendipity and minimize redundancy. A dominance-based ranking procedure identifies Pareto-optimal item sets, enabling adaptive and balanced selections at each iteration. Experiments on a real-world dataset show that our approach significantly improves diversity without sacrificing relevance, demonstrating its potential to enhance user experience in large-scale recommendation settings.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21617",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "LLMs on a Budget? Say HOLA",
    "description": "arXiv:2506.18952v1 Announce Type: cross Abstract: Running Large Language Models (LLMs) on edge devices is constrained by high compute and memory demands posing a barrier for real-time applications in sectors like healthcare, education, and embedded systems. Current solutions such as quantization, pruning, and retrieval-augmented generation (RAG) offer only partial optimizations and often compromise on speed or accuracy. We introduce HOLA, an end-to-end optimization framework for efficient LLM deployment. Internally, it leverages Hierarchical Speculative Decoding (HSD) for faster inference without quality loss. Externally, AdaComp-RAG adjusts retrieval complexity based on context needs. Together with LoBi, which blends structured pruning (LoRA) and quantization, HOLA delivers significant gains: 17.6% EMA on GSM8K, 10.5% MCA on ARC, and reduced latency and memory on edge devices like Jetson Nano--proving both scalable and production-ready.",
    "summary": "arXiv:2506.18952v1 Announce Type: cross Abstract: Running Large Language Models (LLMs) on edge devices is constrained by high compute and memory demands posing a barrier for real-time applications in sectors like healthcare, education, and embedded systems. Current solutions such as quantization, pruning, and retrieval-augmented generation (RAG) offer only partial optimizations and often compromise on speed or accuracy. We introduce HOLA, an end-to-end optimization framework for efficient LLM deployment. Internally, it leverages Hierarchical Speculative Decoding (HSD) for faster inference without quality loss. Externally, AdaComp-RAG adjusts retrieval complexity based on context needs. Together with LoBi, which blends structured pruning (LoRA) and quantization, HOLA delivers significant gains: 17.6% EMA on GSM8K, 10.5% MCA on ARC, and reduced latency and memory on edge devices like Jetson Nano--proving both scalable and production-ready.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18952",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "BiMark: Unbiased Multilayer Watermarking for Large Language Models",
    "description": "arXiv:2506.21602v1 Announce Type: cross Abstract: Recent advances in Large Language Models (LLMs) have raised urgent concerns about LLM-generated text authenticity, prompting regulatory demands for reliable identification mechanisms. Although watermarking offers a promising solution, existing approaches struggle to simultaneously achieve three critical requirements: text quality preservation, model-agnostic detection, and message embedding capacity, which are crucial for practical implementation. To achieve these goals, the key challenge lies in balancing the trade-off between text quality preservation and message embedding capacity. To address this challenge, we propose BiMark, a novel watermarking framework that achieves these requirements through three key innovations: (1) a bit-flip unbiased reweighting mechanism enabling model-agnostic detection, (2) a multilayer architecture enhancing detectability without compromising generation quality, and (3) an information encoding approach supporting multi-bit watermarking. Through theoretical analysis and extensive experiments, we validate that, compared to state-of-the-art multi-bit watermarking methods, BiMark achieves up to 30% higher extraction rates for short texts while maintaining text quality indicated by lower perplexity, and performs comparably to non-watermarked text on downstream tasks such as summarization and translation.",
    "summary": "arXiv:2506.21602v1 Announce Type: cross Abstract: Recent advances in Large Language Models (LLMs) have raised urgent concerns about LLM-generated text authenticity, prompting regulatory demands for reliable identification mechanisms. Although watermarking offers a promising solution, existing approaches struggle to simultaneously achieve three critical requirements: text quality preservation, model-agnostic detection, and message embedding capacity, which are crucial for practical implementation. To achieve these goals, the key challenge lies in balancing the trade-off between text quality preservation and message embedding capacity. To address this challenge, we propose BiMark, a novel watermarking framework that achieves these requirements through three key innovations: (1) a bit-flip unbiased reweighting mechanism enabling model-agnostic detection, (2) a multilayer architecture enhancing detectability without compromising generation quality, and (3) an information encoding approach supporting multi-bit watermarking. Through theoretical analysis and extensive experiments, we validate that, compared to state-of-the-art multi-bit watermarking methods, BiMark achieves up to 30% higher extraction rates for short texts while maintaining text quality indicated by lower perplexity, and performs comparably to non-watermarked text on downstream tasks such as summarization and translation.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21602",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Learning Dexterous Object Handover",
    "description": "arXiv:2506.16822v1 Announce Type: cross Abstract: Object handover is an important skill that we use daily when interacting with other humans. To deploy robots in collaborative setting, like houses, being able to receive and handing over objects safely and efficiently becomes a crucial skill. In this work, we demonstrate the use of Reinforcement Learning (RL) for dexterous object handover between two multi-finger hands. Key to this task is the use of a novel reward function based on dual quaternions to minimize the rotation distance, which outperforms other rotation representations such as Euler and rotation matrices. The robustness of the trained policy is experimentally evaluated by testing w.r.t. objects that are not included in the training distribution, and perturbations during the handover process. The results demonstrate that the trained policy successfully perform this task, achieving a total success rate of 94% in the best-case scenario after 100 experiments, thereby showing the robustness of our policy with novel objects. In addition, the best-case performance of the policy decreases by only 13.8% when the other robot moves during the handover, proving that our policy is also robust to this type of perturbation, which is common in real-world object handovers.",
    "summary": "arXiv:2506.16822v1 Announce Type: cross Abstract: Object handover is an important skill that we use daily when interacting with other humans. To deploy robots in collaborative setting, like houses, being able to receive and handing over objects safely and efficiently becomes a crucial skill. In this work, we demonstrate the use of Reinforcement Learning (RL) for dexterous object handover between two multi-finger hands. Key to this task is the use of a novel reward function based on dual quaternions to minimize the rotation distance, which outperforms other rotation representations such as Euler and rotation matrices. The robustness of the trained policy is experimentally evaluated by testing w.r.t. objects that are not included in the training distribution, and perturbations during the handover process. The results demonstrate that the trained policy successfully perform this task, achieving a total success rate of 94% in the best-case scenario after 100 experiments, thereby showing the robustness of our policy with novel objects. In addition, the best-case performance of the policy decreases by only 13.8% when the other robot moves during the handover, proving that our policy is also robust to this type of perturbation, which is common in real-world object handovers.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16822",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Scaling laws for reward model overoptimization",
    "description": "",
    "summary": "",
    "pubDate": "Wed, 19 Oct 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/scaling-laws-for-reward-model-overoptimization",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LSCD: Lomb-Scargle Conditioned Diffusion for Time series Imputation",
    "description": "arXiv:2506.17039v1 Announce Type: cross Abstract: Time series with missing or irregularly sampled data are a persistent challenge in machine learning. Many methods operate on the frequency-domain, relying on the Fast Fourier Transform (FFT) which assumes uniform sampling, therefore requiring prior interpolation that can distort the spectra. To address this limitation, we introduce a differentiable Lomb--Scargle layer that enables a reliable computation of the power spectrum of irregularly sampled data. We integrate this layer into a novel score-based diffusion model (LSCD) for time series imputation conditioned on the entire signal spectrum. Experiments on synthetic and real-world benchmarks demonstrate that our method recovers missing data more accurately than purely time-domain baselines, while simultaneously producing consistent frequency estimates. Crucially, our method can be easily integrated into learning frameworks, enabling broader adoption of spectral guidance in machine learning approaches involving incomplete or irregular data.",
    "summary": "arXiv:2506.17039v1 Announce Type: cross Abstract: Time series with missing or irregularly sampled data are a persistent challenge in machine learning. Many methods operate on the frequency-domain, relying on the Fast Fourier Transform (FFT) which assumes uniform sampling, therefore requiring prior interpolation that can distort the spectra. To address this limitation, we introduce a differentiable Lomb--Scargle layer that enables a reliable computation of the power spectrum of irregularly sampled data. We integrate this layer into a novel score-based diffusion model (LSCD) for time series imputation conditioned on the entire signal spectrum. Experiments on synthetic and real-world benchmarks demonstrate that our method recovers missing data more accurately than purely time-domain baselines, while simultaneously producing consistent frequency estimates. Crucially, our method can be easily integrated into learning frameworks, enabling broader adoption of spectral guidance in machine learning approaches involving incomplete or irregular data.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17039",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Unsupervised Multi-Agent Reinforcement Learning via Task-Agnostic Exploration",
    "description": "arXiv:2502.08365v3 Announce Type: replace-cross Abstract: In reinforcement learning, we typically refer to unsupervised pre-training when we aim to pre-train a policy without a priori access to the task specification, i.e. rewards, to be later employed for efficient learning of downstream tasks. In single-agent settings, the problem has been extensively studied and mostly understood. A popular approach, called task-agnostic exploration, casts the unsupervised objective as maximizing the entropy of the state distribution induced by the agent's policy, from which principles and methods follow. In contrast, little is known about it in multi-agent settings, which are ubiquitous in the real world. What are the pros and cons of alternative problem formulations in this setting? How hard is the problem in theory, how can we solve it in practice? In this paper, we address these questions by first characterizing those alternative formulations and highlighting how the problem, even when tractable in theory, is non-trivial in practice. Then, we present a scalable, decentralized, trust-region policy search algorithm to address the problem in practical settings. Finally, we provide numerical validations to both corroborate the theoretical findings and pave the way for unsupervised multi-agent reinforcement learning via task-agnostic exploration in challenging domains, showing that optimizing for a specific objective, namely mixture entropy, provides an excellent trade-off between tractability and performances.",
    "summary": "arXiv:2502.08365v3 Announce Type: replace-cross Abstract: In reinforcement learning, we typically refer to unsupervised pre-training when we aim to pre-train a policy without a priori access to the task specification, i.e. rewards, to be later employed for efficient learning of downstream tasks. In single-agent settings, the problem has been extensively studied and mostly understood. A popular approach, called task-agnostic exploration, casts the unsupervised objective as maximizing the entropy of the state distribution induced by the agent's policy, from which principles and methods follow. In contrast, little is known about it in multi-agent settings, which are ubiquitous in the real world. What are the pros and cons of alternative problem formulations in this setting? How hard is the problem in theory, how can we solve it in practice? In this paper, we address these questions by first characterizing those alternative formulations and highlighting how the problem, even when tractable in theory, is non-trivial in practice. Then, we present a scalable, decentralized, trust-region policy search algorithm to address the problem in practical settings. Finally, we provide numerical validations to both corroborate the theoretical findings and pave the way for unsupervised multi-agent reinforcement learning via task-agnostic exploration in challenging domains, showing that optimizing for a specific objective, namely mixture entropy, provides an excellent trade-off between tractability and performances.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.08365",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine tuning CLIP with Remote Sensing (Satellite) images and captions",
    "description": "",
    "summary": "Fine tuning CLIP with Remote Sensing (Satellite) images and captions Fine tuning CLIP with Remote Se...",
    "pubDate": "Wed, 13 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fine-tune-clip-rsicd",
    "thumbnail": "https://huggingface.co/blog/assets/30_clip_rsicd/clip_schematic.png"
  },
  {
    "title": "Frontier AI regulation: Managing emerging risks to public safety",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 06 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-ai-regulation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Rapid and Continuous Trust Evaluation for Effective Task Collaboration Through Siamese Model",
    "description": "arXiv:2506.17128v1 Announce Type: cross Abstract: Trust is emerging as an effective tool to ensure the successful completion of collaborative tasks within collaborative systems. However, rapidly and continuously evaluating the trustworthiness of collaborators during task execution is a significant challenge due to distributed devices, complex operational environments, and dynamically changing resources. To tackle this challenge, this paper proposes a Siamese-enabled rapid and continuous trust evaluation framework (SRCTE) to facilitate effective task collaboration. First, the communication and computing resource attributes of the collaborator in a trusted state, along with historical collaboration data, are collected and represented using an attributed control flow graph (ACFG) that captures trust-related semantic information and serves as a reference for comparison with data collected during task execution. At each time slot of task execution, the collaborator's communication and computing resource attributes, as well as task completion effectiveness, are collected in real time and represented with an ACFG to convey their trust-related semantic information. A Siamese model, consisting of two shared-parameter Structure2vec networks, is then employed to learn the deep semantics of each pair of ACFGs and generate their embeddings. Finally, the similarity between the embeddings of each pair of ACFGs is calculated to determine the collaborator's trust value at each time slot. A real system is built using two Dell EMC 5200 servers and a Google Pixel 8 to test the effectiveness of the proposed SRCTE framework. Experimental results demonstrate that SRCTE converges rapidly with only a small amount of data and achieves a high anomaly trust detection rate compared to the baseline algorithm.",
    "summary": "arXiv:2506.17128v1 Announce Type: cross Abstract: Trust is emerging as an effective tool to ensure the successful completion of collaborative tasks within collaborative systems. However, rapidly and continuously evaluating the trustworthiness of collaborators during task execution is a significant challenge due to distributed devices, complex operational environments, and dynamically changing resources. To tackle this challenge, this paper proposes a Siamese-enabled rapid and continuous trust evaluation framework (SRCTE) to facilitate effective task collaboration. First, the communication and computing resource attributes of the collaborator in a trusted state, along with historical collaboration data, are collected and represented using an attributed control flow graph (ACFG) that captures trust-related semantic information and serves as a reference for comparison with data collected during task execution. At each time slot of task execution, the collaborator's communication and computing resource attributes, as well as task completion effectiveness, are collected in real time and represented with an ACFG to convey their trust-related semantic information. A Siamese model, consisting of two shared-parameter Structure2vec networks, is then employed to learn the deep semantics of each pair of ACFGs and generate their embeddings. Finally, the similarity between the embeddings of each pair of ACFGs is calculated to determine the collaborator's trust value at each time slot. A real system is built using two Dell EMC 5200 servers and a Google Pixel 8 to test the effectiveness of the proposed SRCTE framework. Experimental results demonstrate that SRCTE converges rapidly with only a small amount of data and achieves a high anomaly trust detection rate compared to the baseline algorithm.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17128",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Review completed & Altman, Brockman to continue to lead OpenAI",
    "description": "New board members named and enhancements to the governance structure introduced",
    "summary": "New board members named and enhancements to the governance structure introduced",
    "pubDate": "Fri, 08 Mar 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/review-completed-altman-brockman-to-continue-to-lead-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerating PyTorch distributed fine-tuning with Intel technologies",
    "description": "",
    "summary": "Accelerating PyTorch distributed fine-tuning with Intel technologies For all their amazing performan...",
    "pubDate": "Fri, 19 Nov 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/accelerating-pytorch",
    "thumbnail": "https://huggingface.co/blog/assets/36_accelerating_pytorch/04_four_nodes.png"
  },
  {
    "title": "LLM2Rec: Large Language Models Are Powerful Embedding Models for Sequential Recommendation",
    "description": "arXiv:2506.21579v1 Announce Type: cross Abstract: Sequential recommendation aims to predict users' future interactions by modeling collaborative filtering (CF) signals from historical behaviors of similar users or items. Traditional sequential recommenders predominantly rely on ID-based embeddings, which capture CF signals through high-order co-occurrence patterns. However, these embeddings depend solely on past interactions, lacking transferable knowledge to generalize to unseen domains. Recent advances in large language models (LLMs) have motivated text-based recommendation approaches that derive item representations from textual descriptions. While these methods enhance generalization, they fail to encode CF signals-i.e., latent item correlations and preference patterns-crucial for effective recommendation. We argue that an ideal embedding model should seamlessly integrate CF signals with rich semantic representations to improve both in-domain and out-of-domain recommendation performance. To this end, we propose LLM2Rec, a novel embedding model tailored for sequential recommendation, integrating the rich semantic understanding of LLMs with CF awareness. Our approach follows a two-stage training framework: (1) Collaborative Supervised Fine-tuning, which adapts LLMs to infer item relationships based on historical interactions, and (2) Item-level Embedding Modeling, which refines these specialized LLMs into structured item embedding models that encode both semantic and collaborative information. Extensive experiments on real-world datasets demonstrate that LLM2Rec effectively improves recommendation quality across both in-domain and out-of-domain settings. Our findings highlight the potential of leveraging LLMs to build more robust, generalizable embedding models for sequential recommendation. Our codes are available at https://github.com/HappyPointer/LLM2Rec.",
    "summary": "arXiv:2506.21579v1 Announce Type: cross Abstract: Sequential recommendation aims to predict users' future interactions by modeling collaborative filtering (CF) signals from historical behaviors of similar users or items. Traditional sequential recommenders predominantly rely on ID-based embeddings, which capture CF signals through high-order co-occurrence patterns. However, these embeddings depend solely on past interactions, lacking transferable knowledge to generalize to unseen domains. Recent advances in large language models (LLMs) have motivated text-based recommendation approaches that derive item representations from textual descriptions. While these methods enhance generalization, they fail to encode CF signals-i.e., latent item correlations and preference patterns-crucial for effective recommendation. We argue that an ideal embedding model should seamlessly integrate CF signals with rich semantic representations to improve both in-domain and out-of-domain recommendation performance. To this end, we propose LLM2Rec, a novel embedding model tailored for sequential recommendation, integrating the rich semantic understanding of LLMs with CF awareness. Our approach follows a two-stage training framework: (1) Collaborative Supervised Fine-tuning, which adapts LLMs to infer item relationships based on historical interactions, and (2) Item-level Embedding Modeling, which refines these specialized LLMs into structured item embedding models that encode both semantic and collaborative information. Extensive experiments on real-world datasets demonstrate that LLM2Rec effectively improves recommendation quality across both in-domain and out-of-domain settings. Our findings highlight the potential of leveraging LLMs to build more robust, generalizable embedding models for sequential recommendation. Our codes are available at https://github.com/HappyPointer/LLM2Rec.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21579",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Building an early warning system for LLM-aided biological threat creation",
    "description": "We‚Äôre developing a blueprint for evaluating the risk that a large language model (LLM) could aid someone in creating a biological threat.¬†In an evaluation involving both biology experts and students, we found that GPT-4 provides at most a mild uplift in biological threat creation accuracy. While this uplift is not large enough to be conclusive, our finding is a starting point for continued research and community deliberation.",
    "summary": "We‚Äôre developing a blueprint for evaluating the risk that a large language model (LLM) could aid someone in creating a biological threat.¬†In an evaluation involving both biology experts and students, we found that GPT-4 provides at most a mild uplift in biological threat creation accuracy. While this uplift is not large enough to be conclusive, our finding is a starting point for continued research and community deliberation.",
    "pubDate": "Wed, 31 Jan 2024 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/building-an-early-warning-system-for-llm-aided-biological-threat-creation",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "The Role of Explanation Styles and Perceived Accuracy on Decision Making in Predictive Process Monitoring",
    "description": "arXiv:2506.16617v1 Announce Type: new Abstract: Predictive Process Monitoring (PPM) often uses deep learning models to predict the future behavior of ongoing processes, such as predicting process outcomes. While these models achieve high accuracy, their lack of interpretability undermines user trust and adoption. Explainable AI (XAI) aims to address this challenge by providing the reasoning behind the predictions. However, current evaluations of XAI in PPM focus primarily on functional metrics (such as fidelity), overlooking user-centered aspects such as their effect on task performance and decision-making. This study investigates the effects of explanation styles (feature importance, rule-based, and counterfactual) and perceived AI accuracy (low or high) on decision-making in PPM. We conducted a decision-making experiment, where users were presented with the AI predictions, perceived accuracy levels, and explanations of different styles. Users' decisions were measured both before and after receiving explanations, allowing the assessment of objective metrics (Task Performance and Agreement) and subjective metrics (Decision Confidence). Our findings show that perceived accuracy and explanation style have a significant effect.",
    "summary": "arXiv:2506.16617v1 Announce Type: new Abstract: Predictive Process Monitoring (PPM) often uses deep learning models to predict the future behavior of ongoing processes, such as predicting process outcomes. While these models achieve high accuracy, their lack of interpretability undermines user trust and adoption. Explainable AI (XAI) aims to address this challenge by providing the reasoning behind the predictions. However, current evaluations of XAI in PPM focus primarily on functional metrics (such as fidelity), overlooking user-centered aspects such as their effect on task performance and decision-making. This study investigates the effects of explanation styles (feature importance, rule-based, and counterfactual) and perceived AI accuracy (low or high) on decision-making in PPM. We conducted a decision-making experiment, where users were presented with the AI predictions, perceived accuracy levels, and explanations of different styles. Users' decisions were measured both before and after receiving explanations, allowing the assessment of objective metrics (Task Performance and Agreement) and subjective metrics (Decision Confidence). Our findings show that perceived accuracy and explanation style have a significant effect.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16617",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FunSearch: Making new discoveries in mathematical sciences using Large Language Models",
    "description": "In a paper published in Nature, we introduce FunSearch, a method for searching for ‚Äúfunctions‚Äù written in computer code, and find new solutions in mathematics and computer science. FunSearch works by pairing a pre-trained LLM, whose goal is to provide creative solutions in the form of computer code, with an automated ‚Äúevaluator‚Äù, which guards against hallucinations and incorrect ideas.",
    "summary": "In a paper published in Nature, we introduce FunSearch, a method for searching for ‚Äúfunctions‚Äù written in computer code, and find new solutions in mathematics and computer science. FunSearch works by pairing a pre-trained LLM, whose goal is to provide creative solutions in the form of computer code, with an automated ‚Äúevaluator‚Äù, which guards against hallucinations and incorrect ideas.",
    "pubDate": "Thu, 14 Dec 2023 16:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/",
    "thumbnail": "https://lh3.googleusercontent.com/GC6SH0u6DyyCT9C1LH6XXmproSod7o5QGp9-Oe8BsuXyPzBlfcxFHX9pxXg69ZftEVU0Joga7tyo0VwQOSBBrugZ8qfl9_X-pgiH527p71S7DC32Jw=w1200-h630-n-nu"
  },
  {
    "title": "Rational Metareasoning for Large Language Models",
    "description": "arXiv:2410.05563v3 Announce Type: replace-cross Abstract: Being prompted to engage in reasoning has emerged as a core technique for using large language models (LLMs), deploying additional inference-time compute to improve task performance. However, as LLMs increase in both size and adoption, inference costs are correspondingly becoming increasingly burdensome. How, then, might we optimize reasoning's cost-performance tradeoff? This work introduces a novel approach based on computational models of metareasoning used in cognitive science, training LLMs to selectively use intermediate reasoning steps only when necessary. We first develop a reward function that incorporates the Value of Computation by penalizing unnecessary reasoning, then use this reward function with Expert Iteration to train the LLM. Compared to few-shot chain-of-thought prompting and STaR, our method significantly reduces inference costs (20-37% fewer tokens generated across three models) while maintaining task performance across diverse datasets.",
    "summary": "arXiv:2410.05563v3 Announce Type: replace-cross Abstract: Being prompted to engage in reasoning has emerged as a core technique for using large language models (LLMs), deploying additional inference-time compute to improve task performance. However, as LLMs increase in both size and adoption, inference costs are correspondingly becoming increasingly burdensome. How, then, might we optimize reasoning's cost-performance tradeoff? This work introduces a novel approach based on computational models of metareasoning used in cognitive science, training LLMs to selectively use intermediate reasoning steps only when necessary. We first develop a reward function that incorporates the Value of Computation by penalizing unnecessary reasoning, then use this reward function with Expert Iteration to train the LLM. Compared to few-shot chain-of-thought prompting and STaR, our method significantly reduces inference costs (20-37% fewer tokens generated across three models) while maintaining task performance across diverse datasets.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.05563",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Procgen and MineRL Competitions",
    "description": "We‚Äôre excited to announce that OpenAI is co-organizing two NeurIPS 2020 competitions with AIcrowd, Carnegie Mellon University, and DeepMind, using Procgen Benchmark and MineRL.",
    "summary": "We‚Äôre excited to announce that OpenAI is co-organizing two NeurIPS 2020 competitions with AIcrowd, Carnegie Mellon University, and DeepMind, using Procgen Benchmark and MineRL.",
    "pubDate": "Sat, 20 Jun 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/procgen-minerl-competitions",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Streamlining financial solutions for safety and growth",
    "description": "Stripe leverages GPT-4 to streamline user experience and combat fraud.",
    "summary": "Stripe leverages GPT-4 to streamline user experience and combat fraud.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/stripe",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PaliGemma ‚Äì Google's Cutting-Edge Open Vision Language Model",
    "description": "",
    "summary": "PaliGemma ‚Äì Google's Cutting-Edge Open Vision Language Model Updated on 23-05-2024: We have introduc...",
    "pubDate": "Tue, 14 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/paligemma",
    "thumbnail": "https://huggingface.co/blog/assets/paligemma/Paligemma.png"
  },
  {
    "title": "Introducing Activation Atlases",
    "description": "We‚Äôve created¬†activation atlases¬†(in¬†collaboration¬†with Google researchers), a new technique for visualizing what interactions between neurons can represent. As AI systems are deployed in increasingly sensitive contexts, having a better understanding of their internal decision-making processes will let us identify weaknesses and investigate¬†failures.",
    "summary": "We‚Äôve created¬†activation atlases¬†(in¬†collaboration¬†with Google researchers), a new technique for visualizing what interactions between neurons can represent. As AI systems are deployed in increasingly sensitive contexts, having a better understanding of their internal decision-making processes will let us identify weaknesses and investigate¬†failures.",
    "pubDate": "Wed, 06 Mar 2019 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-activation-atlases",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding",
    "description": "arXiv:2504.13180v2 Announce Type: replace-cross Abstract: Vision-language models are integral to computer vision research, yet many high-performing models remain closed-source, obscuring their data, design and training recipe. The research community has responded by using distillation from black-box models to label training data, achieving strong benchmark results, at the cost of measurable scientific progress. However, without knowing the details of the teacher model and its data sources, scientific progress remains difficult to measure. In this paper, we study building a Perception Language Model (PLM) in a fully open and reproducible framework for transparent research in image and video understanding. We analyze standard training pipelines without distillation from proprietary models and explore large-scale synthetic data to identify critical data gaps, particularly in detailed video understanding. To bridge these gaps, we release 2.8M human-labeled instances of fine-grained video question-answer pairs and spatio-temporally grounded video captions. Additionally, we introduce PLM-VideoBench, a suite for evaluating challenging video understanding tasks focusing on the ability to reason about 'what', 'where', 'when', and 'how' of a video. We make our work fully reproducible by providing data, training recipes, code & models. https://github.com/facebookresearch/perception_models",
    "summary": "arXiv:2504.13180v2 Announce Type: replace-cross Abstract: Vision-language models are integral to computer vision research, yet many high-performing models remain closed-source, obscuring their data, design and training recipe. The research community has responded by using distillation from black-box models to label training data, achieving strong benchmark results, at the cost of measurable scientific progress. However, without knowing the details of the teacher model and its data sources, scientific progress remains difficult to measure. In this paper, we study building a Perception Language Model (PLM) in a fully open and reproducible framework for transparent research in image and video understanding. We analyze standard training pipelines without distillation from proprietary models and explore large-scale synthetic data to identify critical data gaps, particularly in detailed video understanding. To bridge these gaps, we release 2.8M human-labeled instances of fine-grained video question-answer pairs and spatio-temporally grounded video captions. Additionally, we introduce PLM-VideoBench, a suite for evaluating challenging video understanding tasks focusing on the ability to reason about 'what', 'where', 'when', and 'how' of a video. We make our work fully reproducible by providing data, training recipes, code & models. https://github.com/facebookresearch/perception_models",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.13180",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Introducing ChatGPT",
    "description": "We‚Äôve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.",
    "summary": "We‚Äôve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests.",
    "pubDate": "Wed, 30 Nov 2022 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "AI for Game Development: Creating a Farming Game in 5 Days. Part 2",
    "description": "",
    "summary": "AI for Game Development: Creating a Farming Game in 5 Days. Part 2 Welcome to AI for Game Developmen...",
    "pubDate": "Mon, 09 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-2",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail2.png"
  },
  {
    "title": "Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU",
    "description": "",
    "summary": "Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU We are excited to officially release the integ...",
    "pubDate": "Thu, 09 Mar 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/trl-peft",
    "thumbnail": "https://huggingface.co/blog/trl-peft/assets/133_trl_peft/thumbnail.png"
  },
  {
    "title": "Infrastructure for deep learning",
    "description": "Deep learning is an empirical science, and the quality of a group‚Äôs infrastructure is a multiplier on progress. Fortunately, today‚Äôs open-source ecosystem makes it possible for anyone to build great deep learning infrastructure.",
    "summary": "Deep learning is an empirical science, and the quality of a group‚Äôs infrastructure is a multiplier on progress. Fortunately, today‚Äôs open-source ecosystem makes it possible for anyone to build great deep learning infrastructure.",
    "pubDate": "Mon, 29 Aug 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/infrastructure-for-deep-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "English K_Quantization of LLMs Does Not Disproportionately Diminish Multilingual Performance",
    "description": "arXiv:2503.03592v3 Announce Type: replace-cross Abstract: For consumer usage of locally deployed LLMs, the GGUF format and k_quantization are invaluable tools for maintaining the performance of the original model while reducing it to sizes deployable with consumer-grade hardware. The number of bits dedicated to each weight from the original model is reduced based on how important they are thought to be during model inference. This importance is arrived at through the application of an 'importance matrix'-a relatively small text document meant to be representative of the LLM's standard use-cases. In the vast majority of quants available online, this document is primarily written in English. It was therefore an open question whether performance on English language tasks was preserved through the sacrifice of multilingual performance and whether it can be preserved with alternate importance matrices. This article investigates these hypotheses by quantizing Llama3.3 70B on importance matrices written in three languages (English, Norwegian, and Malayalam) and evaluating them on the MixEval dataset in both English and Norwegian. All experiments related to yielded non-significant results indicating that current quantization practices do not disproportionately harm multilingual performance.",
    "summary": "arXiv:2503.03592v3 Announce Type: replace-cross Abstract: For consumer usage of locally deployed LLMs, the GGUF format and k_quantization are invaluable tools for maintaining the performance of the original model while reducing it to sizes deployable with consumer-grade hardware. The number of bits dedicated to each weight from the original model is reduced based on how important they are thought to be during model inference. This importance is arrived at through the application of an 'importance matrix'-a relatively small text document meant to be representative of the LLM's standard use-cases. In the vast majority of quants available online, this document is primarily written in English. It was therefore an open question whether performance on English language tasks was preserved through the sacrifice of multilingual performance and whether it can be preserved with alternate importance matrices. This article investigates these hypotheses by quantizing Llama3.3 70B on importance matrices written in three languages (English, Norwegian, and Malayalam) and evaluating them on the MixEval dataset in both English and Norwegian. All experiments related to yielded non-significant results indicating that current quantization practices do not disproportionately harm multilingual performance.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.03592",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Deep Learning framework for building damage assessment using VHR SAR and geospatial data: demonstration on the 2023 Turkiye Earthquake",
    "description": "arXiv:2506.22338v1 Announce Type: cross Abstract: Building damage identification shortly after a disaster is crucial for guiding emergency response and recovery efforts. Although optical satellite imagery is commonly used for disaster mapping, its effectiveness is often hampered by cloud cover or the absence of pre-event acquisitions. To overcome these challenges, we introduce a novel multimodal deep learning (DL) framework for detecting building damage using single-date very high resolution (VHR) Synthetic Aperture Radar (SAR) imagery from the Italian Space Agency (ASI) COSMO SkyMed (CSK) constellation, complemented by auxiliary geospatial data. Our method integrates SAR image patches, OpenStreetMap (OSM) building footprints, digital surface model (DSM) data, and structural and exposure attributes from the Global Earthquake Model (GEM) to improve detection accuracy and contextual interpretation. Unlike existing approaches that depend on pre and post event imagery, our model utilizes only post event data, facilitating rapid deployment in critical scenarios. The framework effectiveness is demonstrated using a new dataset from the 2023 earthquake in Turkey, covering multiple cities with diverse urban settings. Results highlight that incorporating geospatial features significantly enhances detection performance and generalizability to previously unseen areas. By combining SAR imagery with detailed vulnerability and exposure information, our approach provides reliable and rapid building damage assessments without the dependency from available pre-event data. Moreover, the automated and scalable data generation process ensures the framework's applicability across diverse disaster-affected regions, underscoring its potential to support effective disaster management and recovery efforts. Code and data will be made available upon acceptance of the paper.",
    "summary": "arXiv:2506.22338v1 Announce Type: cross Abstract: Building damage identification shortly after a disaster is crucial for guiding emergency response and recovery efforts. Although optical satellite imagery is commonly used for disaster mapping, its effectiveness is often hampered by cloud cover or the absence of pre-event acquisitions. To overcome these challenges, we introduce a novel multimodal deep learning (DL) framework for detecting building damage using single-date very high resolution (VHR) Synthetic Aperture Radar (SAR) imagery from the Italian Space Agency (ASI) COSMO SkyMed (CSK) constellation, complemented by auxiliary geospatial data. Our method integrates SAR image patches, OpenStreetMap (OSM) building footprints, digital surface model (DSM) data, and structural and exposure attributes from the Global Earthquake Model (GEM) to improve detection accuracy and contextual interpretation. Unlike existing approaches that depend on pre and post event imagery, our model utilizes only post event data, facilitating rapid deployment in critical scenarios. The framework effectiveness is demonstrated using a new dataset from the 2023 earthquake in Turkey, covering multiple cities with diverse urban settings. Results highlight that incorporating geospatial features significantly enhances detection performance and generalizability to previously unseen areas. By combining SAR imagery with detailed vulnerability and exposure information, our approach provides reliable and rapid building damage assessments without the dependency from available pre-event data. Moreover, the automated and scalable data generation process ensures the framework's applicability across diverse disaster-affected regions, underscoring its potential to support effective disaster management and recovery efforts. Code and data will be made available upon acceptance of the paper.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22338",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Deploy Meta Llama 3.1 405B on Google Cloud Vertex AI",
    "description": "",
    "summary": "Deploy Meta Llama 3.1 405B on Google Cloud Vertex AI Meta Llama 3.1 is the latest open LLM from Meta...",
    "pubDate": "Mon, 19 Aug 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama31-on-vertex-ai",
    "thumbnail": "https://huggingface.co/blog/assets/llama31-on-vertex-ai/thumbnail.png"
  },
  {
    "title": "New tool evaluates progress in reinforcement learning",
    "description": "‚ÄúIntersectionZoo,‚Äù a benchmarking tool, uses a real-world traffic problem to test progress in deep reinforcement learning algorithms.",
    "summary": "‚ÄúIntersectionZoo,‚Äù a benchmarking tool, uses a real-world traffic problem to test progress in deep reinforcement learning algorithms.",
    "pubDate": "Mon, 05 May 2025 16:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/new-tool-evaluate-progress-reinforcement-learning-0505",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202504/Intersection-Zoo.jpg"
  },
  {
    "title": "PQCAD-DM: Progressive Quantization and Calibration-Assisted Distillation for Extremely Efficient Diffusion Model",
    "description": "arXiv:2506.16776v1 Announce Type: cross Abstract: Diffusion models excel in image generation but are computational and resource-intensive due to their reliance on iterative Markov chain processes, leading to error accumulation and limiting the effectiveness of naive compression techniques. In this paper, we propose PQCAD-DM, a novel hybrid compression framework combining Progressive Quantization (PQ) and Calibration-Assisted Distillation (CAD) to address these challenges. PQ employs a two-stage quantization with adaptive bit-width transitions guided by a momentum-based mechanism, reducing excessive weight perturbations in low-precision. CAD leverages full-precision calibration datasets during distillation, enabling the student to match full-precision performance even with a quantized teacher. As a result, PQCAD-DM achieves a balance between computational efficiency and generative quality, halving inference time while maintaining competitive performance. Extensive experiments validate PQCAD-DM's superior generative capabilities and efficiency across diverse datasets, outperforming fixed-bit quantization methods.",
    "summary": "arXiv:2506.16776v1 Announce Type: cross Abstract: Diffusion models excel in image generation but are computational and resource-intensive due to their reliance on iterative Markov chain processes, leading to error accumulation and limiting the effectiveness of naive compression techniques. In this paper, we propose PQCAD-DM, a novel hybrid compression framework combining Progressive Quantization (PQ) and Calibration-Assisted Distillation (CAD) to address these challenges. PQ employs a two-stage quantization with adaptive bit-width transitions guided by a momentum-based mechanism, reducing excessive weight perturbations in low-precision. CAD leverages full-precision calibration datasets during distillation, enabling the student to match full-precision performance even with a quantized teacher. As a result, PQCAD-DM achieves a balance between computational efficiency and generative quality, halving inference time while maintaining competitive performance. Extensive experiments validate PQCAD-DM's superior generative capabilities and efficiency across diverse datasets, outperforming fixed-bit quantization methods.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16776",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models",
    "description": "arXiv:2506.21627v1 Announce Type: cross Abstract: Developing a general robot manipulation system capable of performing a wide range of tasks in complex, dynamic, and unstructured real-world environments has long been a challenging task. It is widely recognized that achieving human-like efficiency and robustness manipulation requires the robotic brain to integrate a comprehensive set of functions, such as task planning, policy generation, anomaly monitoring and handling, and long-term memory, achieving high-efficiency operation across all functions. Vision-Language Models (VLMs), pretrained on massive multimodal data, have acquired rich world knowledge, exhibiting exceptional scene understanding and multimodal reasoning capabilities. However, existing methods typically focus on realizing only a single function or a subset of functions within the robotic brain, without integrating them into a unified cognitive architecture. Inspired by a divide-and-conquer strategy and the architecture of the human brain, we propose FrankenBot, a VLM-driven, brain-morphic robotic manipulation framework that achieves both comprehensive functionality and high operational efficiency. Our framework includes a suite of components, decoupling a part of key functions from frequent VLM calls, striking an optimal balance between functional completeness and system efficiency. Specifically, we map task planning, policy generation, memory management, and low-level interfacing to the cortex, cerebellum, temporal lobe-hippocampus complex, and brainstem, respectively, and design efficient coordination mechanisms for the modules. We conducted comprehensive experiments in both simulation and real-world robotic environments, demonstrating that our method offers significant advantages in anomaly detection and handling, long-term memory, operational efficiency, and stability -- all without requiring any fine-tuning or retraining.",
    "summary": "arXiv:2506.21627v1 Announce Type: cross Abstract: Developing a general robot manipulation system capable of performing a wide range of tasks in complex, dynamic, and unstructured real-world environments has long been a challenging task. It is widely recognized that achieving human-like efficiency and robustness manipulation requires the robotic brain to integrate a comprehensive set of functions, such as task planning, policy generation, anomaly monitoring and handling, and long-term memory, achieving high-efficiency operation across all functions. Vision-Language Models (VLMs), pretrained on massive multimodal data, have acquired rich world knowledge, exhibiting exceptional scene understanding and multimodal reasoning capabilities. However, existing methods typically focus on realizing only a single function or a subset of functions within the robotic brain, without integrating them into a unified cognitive architecture. Inspired by a divide-and-conquer strategy and the architecture of the human brain, we propose FrankenBot, a VLM-driven, brain-morphic robotic manipulation framework that achieves both comprehensive functionality and high operational efficiency. Our framework includes a suite of components, decoupling a part of key functions from frequent VLM calls, striking an optimal balance between functional completeness and system efficiency. Specifically, we map task planning, policy generation, memory management, and low-level interfacing to the cortex, cerebellum, temporal lobe-hippocampus complex, and brainstem, respectively, and design efficient coordination mechanisms for the modules. We conducted comprehensive experiments in both simulation and real-world robotic environments, demonstrating that our method offers significant advantages in anomaly detection and handling, long-term memory, operational efficiency, and stability -- all without requiring any fine-tuning or retraining.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21627",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Train and Fine-Tune Sentence Transformers Models",
    "description": "",
    "summary": "Train and Fine-Tune Sentence Transformers Models This guide is only suited for Sentence Transformers...",
    "pubDate": "Wed, 10 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/how-to-train-sentence-transformers",
    "thumbnail": "https://huggingface.co/blog/assets/95_training_st_models/thumbnail.png"
  },
  {
    "title": "Generative language modeling for automated theorem proving",
    "description": "",
    "summary": "",
    "pubDate": "Mon, 07 Sep 2020 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/generative-language-modeling-for-automated-theorem-proving",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "œÄ0 and œÄ0-FAST: Vision-Language-Action Models for General Robot Control",
    "description": "",
    "summary": "œÄ0 and œÄ0-FAST: Vision-Language-Action Models for General Robot Control We have ported the first rob...",
    "pubDate": "Tue, 04 Feb 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/pi0",
    "thumbnail": "https://huggingface.co/blog/assets/192_pi0/new_thumbnail_pi0.001.png"
  },
  {
    "title": "GraphCast: AI model for faster and more accurate global weather forecasting",
    "description": "We introduce GraphCast, a state-of-the-art AI model able to make medium-range weather forecasts with unprecedented accuracy",
    "summary": "We introduce GraphCast, a state-of-the-art AI model able to make medium-range weather forecasts with unprecedented accuracy",
    "pubDate": "Tue, 14 Nov 2023 15:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/",
    "thumbnail": "https://lh3.googleusercontent.com/5dL0Cm8RLhoDdfPzVy5MlKB5JDcfYucbgxzNLJVFdtqRe15-bFTvfdOrpqnrM4m5XMEEboWtvyCLQgSCvHEH62QqZZI0V_zuBAz71fghXgU5UNFFwg=w1200-h630-n-nu"
  },
  {
    "title": "Rox goes ‚Äúall in‚Äù on OpenAI",
    "description": "By combining commercial experience and deep LLM expertise with OpenAI‚Äôs models, Rox makes every seller a top 1% seller.",
    "summary": "By combining commercial experience and deep LLM expertise with OpenAI‚Äôs models, Rox makes every seller a top 1% seller.",
    "pubDate": "Tue, 19 Nov 2024 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/rox",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Robots that learn",
    "description": "We‚Äôve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can learn a new task after seeing it done once.",
    "summary": "We‚Äôve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can learn a new task after seeing it done once.",
    "pubDate": "Tue, 16 May 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/robots-that-learn",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Announcing the Hugging Face Fellowship Program",
    "description": "",
    "summary": "Announcing the Hugging Face Fellowship Program The Fellowship is a network of exceptional people fro...",
    "pubDate": "Tue, 17 May 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/fellowship",
    "thumbnail": "https://huggingface.co/blog/assets/62_fellowship/fellowship-thumbnail.png"
  },
  {
    "title": "Prediction and control with temporal segment models",
    "description": "",
    "summary": "",
    "pubDate": "Sun, 12 Mar 2017 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/prediction-and-control-with-temporal-segment-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Finding Clustering Algorithms in the Transformer Architecture",
    "description": "arXiv:2506.19125v1 Announce Type: cross Abstract: The invention of the transformer architecture has revolutionized Artificial Intelligence (AI), yielding unprecedented success in areas such as natural language processing, computer vision, and multimodal reasoning. Despite these advances, it is unclear whether transformers are able to learn and implement precise algorithms. Here, we demonstrate that transformers can exactly implement a fundamental and widely used algorithm for $k$-means clustering: Lloyd's algorithm. First, we theoretically prove the existence of such a transformer architecture, which we term the $k$-means transformer, that exactly implements Lloyd's algorithm for $k$-means clustering using the standard ingredients of modern transformers: attention and residual connections. Next, we numerically implement this transformer and demonstrate in experiments the exact correspondence between our architecture and Lloyd's algorithm, providing a fully neural implementation of $k$-means clustering. Finally, we demonstrate that interpretable alterations (e.g., incorporating layer normalizations or multilayer perceptrons) to this architecture yields diverse and novel variants of clustering algorithms, such as soft $k$-means, spherical $k$-means, trimmed $k$-means, and more. Collectively, our findings demonstrate how transformer mechanisms can precisely map onto algorithmic procedures, offering a clear and interpretable perspective on implementing precise algorithms in transformers.",
    "summary": "arXiv:2506.19125v1 Announce Type: cross Abstract: The invention of the transformer architecture has revolutionized Artificial Intelligence (AI), yielding unprecedented success in areas such as natural language processing, computer vision, and multimodal reasoning. Despite these advances, it is unclear whether transformers are able to learn and implement precise algorithms. Here, we demonstrate that transformers can exactly implement a fundamental and widely used algorithm for $k$-means clustering: Lloyd's algorithm. First, we theoretically prove the existence of such a transformer architecture, which we term the $k$-means transformer, that exactly implements Lloyd's algorithm for $k$-means clustering using the standard ingredients of modern transformers: attention and residual connections. Next, we numerically implement this transformer and demonstrate in experiments the exact correspondence between our architecture and Lloyd's algorithm, providing a fully neural implementation of $k$-means clustering. Finally, we demonstrate that interpretable alterations (e.g., incorporating layer normalizations or multilayer perceptrons) to this architecture yields diverse and novel variants of clustering algorithms, such as soft $k$-means, spherical $k$-means, trimmed $k$-means, and more. Collectively, our findings demonstrate how transformer mechanisms can precisely map onto algorithmic procedures, offering a clear and interpretable perspective on implementing precise algorithms in transformers.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19125",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sam & Jony",
    "description": "Sam & Jony",
    "summary": "Sam & Jony",
    "pubDate": "Wed, 21 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/sam-and-jony",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introduction to 3D Gaussian Splatting",
    "description": "",
    "summary": "Introduction to 3D Gaussian Splatting 3D Gaussian Splatting is a rasterization technique described i...",
    "pubDate": "Mon, 18 Sep 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/gaussian-splatting",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail-gaussian-splatting.png"
  },
  {
    "title": "FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring",
    "description": "arXiv:2506.19325v1 Announce Type: new Abstract: In English education tutoring, teacher feedback is essential for guiding students. Recently, AI-based tutoring systems have emerged to assist teachers; however, these systems require high-quality and large-scale teacher feedback data, which is both time-consuming and costly to generate manually. In this study, we propose FEAT, a cost-effective framework for generating teacher feedback, and have constructed three complementary datasets: (1) DIRECT-Manual (DM), where both humans and large language models (LLMs) collaboratively generate high-quality teacher feedback, albeit at a higher cost; (2) DIRECT-Generated (DG), an LLM-only generated, cost-effective dataset with lower quality;, and (3) DIRECT-Augmented (DA), primarily based on DG with a small portion of DM added to enhance quality while maintaining cost-efficiency. Experimental results showed that incorporating a small portion of DM (5-10%) into DG leads to superior performance compared to using 100% DM alone.",
    "summary": "arXiv:2506.19325v1 Announce Type: new Abstract: In English education tutoring, teacher feedback is essential for guiding students. Recently, AI-based tutoring systems have emerged to assist teachers; however, these systems require high-quality and large-scale teacher feedback data, which is both time-consuming and costly to generate manually. In this study, we propose FEAT, a cost-effective framework for generating teacher feedback, and have constructed three complementary datasets: (1) DIRECT-Manual (DM), where both humans and large language models (LLMs) collaboratively generate high-quality teacher feedback, albeit at a higher cost; (2) DIRECT-Generated (DG), an LLM-only generated, cost-effective dataset with lower quality;, and (3) DIRECT-Augmented (DA), primarily based on DG with a small portion of DM added to enhance quality while maintaining cost-efficiency. Experimental results showed that incorporating a small portion of DM (5-10%) into DG leads to superior performance compared to using 100% DM alone.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19325",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "PARSI: Persian Authorship Recognition via Stylometric Integration",
    "description": "arXiv:2506.21840v1 Announce Type: cross Abstract: The intricate linguistic, stylistic, and metrical aspects of Persian classical poetry pose a challenge for computational authorship attribution. In this work, we present a versatile framework to determine authorship among 67 prominent poets. We employ a multi-input neural framework consisting of a transformer-based language encoder complemented by features addressing the semantic, stylometric, and metrical dimensions of Persian poetry. Our feature set encompasses 100-dimensional Word2Vec embeddings, seven stylometric measures, and categorical encodings of poetic form and meter. We compiled a vast corpus of 647,653 verses of the Ganjoor digital collection, validating the data through strict preprocessing and author verification while preserving poem-level splitting to prevent overlap. This work employs verse-level classification and majority and weighted voting schemes in evaluation, revealing that weighted voting yields 71% accuracy. We further investigate threshold-based decision filtering, allowing the model to generate highly confident predictions, achieving 97% accuracy at a 0.9 threshold, though at lower coverage. Our work focuses on the integration of deep representational forms with domain-specific features for improved authorship attribution. The results illustrate the potential of our approach for automated classification and the contribution to stylistic analysis, authorship disputes, and general computational literature research. This research will facilitate further research on multilingual author attribution, style shift, and generative modeling of Persian poetry.",
    "summary": "arXiv:2506.21840v1 Announce Type: cross Abstract: The intricate linguistic, stylistic, and metrical aspects of Persian classical poetry pose a challenge for computational authorship attribution. In this work, we present a versatile framework to determine authorship among 67 prominent poets. We employ a multi-input neural framework consisting of a transformer-based language encoder complemented by features addressing the semantic, stylometric, and metrical dimensions of Persian poetry. Our feature set encompasses 100-dimensional Word2Vec embeddings, seven stylometric measures, and categorical encodings of poetic form and meter. We compiled a vast corpus of 647,653 verses of the Ganjoor digital collection, validating the data through strict preprocessing and author verification while preserving poem-level splitting to prevent overlap. This work employs verse-level classification and majority and weighted voting schemes in evaluation, revealing that weighted voting yields 71% accuracy. We further investigate threshold-based decision filtering, allowing the model to generate highly confident predictions, achieving 97% accuracy at a 0.9 threshold, though at lower coverage. Our work focuses on the integration of deep representational forms with domain-specific features for improved authorship attribution. The results illustrate the potential of our approach for automated classification and the contribution to stylistic analysis, authorship disputes, and general computational literature research. This research will facilitate further research on multilingual author attribution, style shift, and generative modeling of Persian poetry.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21840",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Brain-to-Population Graph Learning Framework for Diagnosing Brain Disorders",
    "description": "arXiv:2506.16096v1 Announce Type: cross Abstract: Recent developed graph-based methods for diagnosing brain disorders using functional connectivity highly rely on predefined brain atlases, but overlook the rich information embedded within atlases and the confounding effects of site and phenotype variability. To address these challenges, we propose a two-stage Brain-to-Population Graph Learning (B2P-GL) framework that integrates the semantic similarity of brain regions and condition-based population graph modeling. In the first stage, termed brain representation learning, we leverage brain atlas knowledge from GPT-4 to enrich the graph representation and refine the brain graph through an adaptive node reassignment graph attention network. In the second stage, termed population disorder diagnosis, phenotypic data is incorporated into population graph construction and feature fusion to mitigate confounding effects and enhance diagnosis performance. Experiments on the ABIDE I, ADHD-200, and Rest-meta-MDD datasets show that B2P-GL outperforms state-of-the-art methods in prediction accuracy while enhancing interpretability. Overall, our proposed framework offers a reliable and personalized approach to brain disorder diagnosis, advancing clinical applicability.",
    "summary": "arXiv:2506.16096v1 Announce Type: cross Abstract: Recent developed graph-based methods for diagnosing brain disorders using functional connectivity highly rely on predefined brain atlases, but overlook the rich information embedded within atlases and the confounding effects of site and phenotype variability. To address these challenges, we propose a two-stage Brain-to-Population Graph Learning (B2P-GL) framework that integrates the semantic similarity of brain regions and condition-based population graph modeling. In the first stage, termed brain representation learning, we leverage brain atlas knowledge from GPT-4 to enrich the graph representation and refine the brain graph through an adaptive node reassignment graph attention network. In the second stage, termed population disorder diagnosis, phenotypic data is incorporated into population graph construction and feature fusion to mitigate confounding effects and enhance diagnosis performance. Experiments on the ABIDE I, ADHD-200, and Rest-meta-MDD datasets show that B2P-GL outperforms state-of-the-art methods in prediction accuracy while enhancing interpretability. Overall, our proposed framework offers a reliable and personalized approach to brain disorder diagnosis, advancing clinical applicability.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16096",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "New tools for building agents",
    "description": "We‚Äôre evolving our platform to help developers and enterprises build useful and reliable agents.",
    "summary": "We‚Äôre evolving our platform to help developers and enterprises build useful and reliable agents.",
    "pubDate": "Tue, 11 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/new-tools-for-building-agents",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Multimodal Machine Learning in Mental Health: A Survey of Data, Algorithms, and Challenges",
    "description": "arXiv:2407.16804v2 Announce Type: replace-cross Abstract: Multimodal machine learning (MML) is rapidly reshaping the way mental-health disorders are detected, characterized, and longitudinally monitored. Whereas early studies relied on isolated data streams -- such as speech, text, or wearable signals -- recent research has converged on architectures that integrate heterogeneous modalities to capture the rich, complex signatures of psychiatric conditions. This survey provides the first comprehensive, clinically grounded synthesis of MML for mental health. We (i) catalog 26 public datasets spanning audio, visual, physiological signals, and text modalities; (ii) systematically compare transformer, graph, and hybrid-based fusion strategies across 28 models, highlighting trends in representation learning and cross-modal alignment. Beyond summarizing current capabilities, we interrogate open challenges: data governance and privacy, demographic and intersectional fairness, evaluation explainability, and the complexity of mental health disorders in multimodal settings. By bridging methodological innovation with psychiatric utility, this survey aims to orient both ML researchers and mental-health practitioners toward the next generation of trustworthy, multimodal decision-support systems.",
    "summary": "arXiv:2407.16804v2 Announce Type: replace-cross Abstract: Multimodal machine learning (MML) is rapidly reshaping the way mental-health disorders are detected, characterized, and longitudinally monitored. Whereas early studies relied on isolated data streams -- such as speech, text, or wearable signals -- recent research has converged on architectures that integrate heterogeneous modalities to capture the rich, complex signatures of psychiatric conditions. This survey provides the first comprehensive, clinically grounded synthesis of MML for mental health. We (i) catalog 26 public datasets spanning audio, visual, physiological signals, and text modalities; (ii) systematically compare transformer, graph, and hybrid-based fusion strategies across 28 models, highlighting trends in representation learning and cross-modal alignment. Beyond summarizing current capabilities, we interrogate open challenges: data governance and privacy, demographic and intersectional fairness, evaluation explainability, and the complexity of mental health disorders in multimodal settings. By bridging methodological innovation with psychiatric utility, this survey aims to orient both ML researchers and mental-health practitioners toward the next generation of trustworthy, multimodal decision-support systems.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2407.16804",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Chatbot on your Laptop: Phi-2 on Intel Meteor Lake",
    "description": "",
    "summary": "A Chatbot on your Laptop: Phi-2 on Intel Meteor Lake Because of their impressive abilities, large la...",
    "pubDate": "Wed, 20 Mar 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/phi2-intel-meteor-lake",
    "thumbnail": "https://huggingface.co/blog/assets/phi2-intel-meteor-lake/02.jpg"
  },
  {
    "title": "Connecting Vision and Emissions: A Behavioural AI Approach to Carbon Estimation in Road Design",
    "description": "arXiv:2506.18924v1 Announce Type: cross Abstract: We present an enhanced YOLOv8 real time vehicle detection and classification framework, for estimating carbon emissions in urban environments. The system enhances YOLOv8 architecture to detect, segment, and track vehicles from live traffic video streams. Once a vehicle is localized, a dedicated deep learning-based identification module is employed to recognize license plates and classify vehicle types. Since YOLOv8 lacks the built-in capacity for fine grained recognition tasks such as reading license plates or determining vehicle attributes beyond class labels, our framework incorporates a hybrid pipeline where each detected vehicle is tracked and its bounding box is cropped and passed to a deep Optical Character Recognition (OCR) module. This OCR system, composed of multiple convolutional neural network (CNN) layers, is trained specifically for character-level detection and license plate decoding under varied conditions such as motion blur, occlusion, and diverse font styles. Additionally, the recognized plate information is validated using a real time API that cross references with an external vehicle registration database to ensure accurate classification and emission estimation. This multi-stage approach enables precise, automated calculation of per vehicle carbon emissions. Extensive evaluation was conducted using a diverse vehicle dataset enriched with segmentation masks and annotated license plates. The YOLOv8 detector achieved a mean Average Precision (mAP@0.5) of approximately 71% for bounding boxes and 70% for segmentation masks. Character level OCR accuracy reached up to 99% with the best performing CNN model. These results affirm the feasibility of combining real time object detection with deep OCR for practical deployment in smart transportation systems, offering a scalable solution for automated, vehicle specific carbon emission monitoring.",
    "summary": "arXiv:2506.18924v1 Announce Type: cross Abstract: We present an enhanced YOLOv8 real time vehicle detection and classification framework, for estimating carbon emissions in urban environments. The system enhances YOLOv8 architecture to detect, segment, and track vehicles from live traffic video streams. Once a vehicle is localized, a dedicated deep learning-based identification module is employed to recognize license plates and classify vehicle types. Since YOLOv8 lacks the built-in capacity for fine grained recognition tasks such as reading license plates or determining vehicle attributes beyond class labels, our framework incorporates a hybrid pipeline where each detected vehicle is tracked and its bounding box is cropped and passed to a deep Optical Character Recognition (OCR) module. This OCR system, composed of multiple convolutional neural network (CNN) layers, is trained specifically for character-level detection and license plate decoding under varied conditions such as motion blur, occlusion, and diverse font styles. Additionally, the recognized plate information is validated using a real time API that cross references with an external vehicle registration database to ensure accurate classification and emission estimation. This multi-stage approach enables precise, automated calculation of per vehicle carbon emissions. Extensive evaluation was conducted using a diverse vehicle dataset enriched with segmentation masks and annotated license plates. The YOLOv8 detector achieved a mean Average Precision (mAP@0.5) of approximately 71% for bounding boxes and 70% for segmentation masks. Character level OCR accuracy reached up to 99% with the best performing CNN model. These results affirm the feasibility of combining real time object detection with deep OCR for practical deployment in smart transportation systems, offering a scalable solution for automated, vehicle specific carbon emission monitoring.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18924",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI partners with Scale to provide support for enterprises fine-tuning models",
    "description": "OpenAI‚Äôs customers can leverage Scale‚Äôs AI expertise to customize our most advanced models.",
    "summary": "OpenAI‚Äôs customers can leverage Scale‚Äôs AI expertise to customize our most advanced models.",
    "pubDate": "Thu, 24 Aug 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-partners-with-scale-to-provide-support-for-enterprises-fine-tuning-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Code Llama: Llama 2 learns to code",
    "description": "",
    "summary": "Code Llama: Llama 2 learns to code Introduction Code Llama is a family of state-of-the-art, open-acc...",
    "pubDate": "Fri, 25 Aug 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codellama",
    "thumbnail": "https://huggingface.co/blog/assets/160_codellama/thumbnail.jpg"
  },
  {
    "title": "The AI Imperative: Scaling High-Quality Peer Review in Machine Learning",
    "description": "arXiv:2506.08134v2 Announce Type: replace Abstract: Peer review, the bedrock of scientific advancement in machine learning (ML), is strained by a crisis of scale. Exponential growth in manuscript submissions to premier ML venues such as NeurIPS, ICML, and ICLR is outpacing the finite capacity of qualified reviewers, leading to concerns about review quality, consistency, and reviewer fatigue. This position paper argues that AI-assisted peer review must become an urgent research and infrastructure priority. We advocate for a comprehensive AI-augmented ecosystem, leveraging Large Language Models (LLMs) not as replacements for human judgment, but as sophisticated collaborators for authors, reviewers, and Area Chairs (ACs). We propose specific roles for AI in enhancing factual verification, guiding reviewer performance, assisting authors in quality improvement, and supporting ACs in decision-making. Crucially, we contend that the development of such systems hinges on access to more granular, structured, and ethically-sourced peer review process data. We outline a research agenda, including illustrative experiments, to develop and validate these AI assistants, and discuss significant technical and ethical challenges. We call upon the ML community to proactively build this AI-assisted future, ensuring the continued integrity and scalability of scientific validation, while maintaining high standards of peer review.",
    "summary": "arXiv:2506.08134v2 Announce Type: replace Abstract: Peer review, the bedrock of scientific advancement in machine learning (ML), is strained by a crisis of scale. Exponential growth in manuscript submissions to premier ML venues such as NeurIPS, ICML, and ICLR is outpacing the finite capacity of qualified reviewers, leading to concerns about review quality, consistency, and reviewer fatigue. This position paper argues that AI-assisted peer review must become an urgent research and infrastructure priority. We advocate for a comprehensive AI-augmented ecosystem, leveraging Large Language Models (LLMs) not as replacements for human judgment, but as sophisticated collaborators for authors, reviewers, and Area Chairs (ACs). We propose specific roles for AI in enhancing factual verification, guiding reviewer performance, assisting authors in quality improvement, and supporting ACs in decision-making. Crucially, we contend that the development of such systems hinges on access to more granular, structured, and ethically-sourced peer review process data. We outline a research agenda, including illustrative experiments, to develop and validate these AI assistants, and discuss significant technical and ethical challenges. We call upon the ML community to proactively build this AI-assisted future, ensuring the continued integrity and scalability of scientific validation, while maintaining high standards of peer review.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.08134",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "The latest AI news we announced in May",
    "description": "an mp4 showing a carousel of images including a collage of people, an illustrated graph with codes and the characters 'I/O'",
    "summary": "an mp4 showing a carousel of images including a collage of people, an illustrated graph with codes and the characters 'I/O'",
    "pubDate": "Thu, 05 Jun 2025 18:30:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/technology/ai/google-ai-updates-may-2025/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/May_AI_roundup_ss.width-1300.png"
  },
  {
    "title": "Some considerations on learning to explore via meta-reinforcement learning",
    "description": "",
    "summary": "",
    "pubDate": "Sat, 03 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/some-considerations-on-learning-to-explore-via-meta-reinforcement-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Hierarchical and Modular Network on Non-prehensile Manipulation in General Environments",
    "description": "arXiv:2502.20843v2 Announce Type: replace-cross Abstract: For robots to operate in general environments like households, they must be able to perform non-prehensile manipulation actions such as toppling and rolling to manipulate ungraspable objects. However, prior works on non-prehensile manipulation cannot yet generalize across environments with diverse geometries. The main challenge lies in adapting to varying environmental constraints: within a cabinet, the robot must avoid walls and ceilings; to lift objects to the top of a step, the robot must account for the step's pose and extent. While deep reinforcement learning (RL) has demonstrated impressive success in non-prehensile manipulation, accounting for such variability presents a challenge for the generalist policy, as it must learn diverse strategies for each new combination of constraints. To address this, we propose a modular and reconfigurable architecture that adaptively reconfigures network modules based on task requirements. To capture the geometric variability in environments, we extend the contact-based object representation (CORN) to environment geometries, and propose a procedural algorithm for generating diverse environments to train our agent. Taken together, the resulting policy can zero-shot transfer to novel real-world environments and objects despite training entirely within a simulator. We additionally release a simulation-based benchmark featuring nine digital twins of real-world scenes with 353 objects to facilitate non-prehensile manipulation research in realistic domains.",
    "summary": "arXiv:2502.20843v2 Announce Type: replace-cross Abstract: For robots to operate in general environments like households, they must be able to perform non-prehensile manipulation actions such as toppling and rolling to manipulate ungraspable objects. However, prior works on non-prehensile manipulation cannot yet generalize across environments with diverse geometries. The main challenge lies in adapting to varying environmental constraints: within a cabinet, the robot must avoid walls and ceilings; to lift objects to the top of a step, the robot must account for the step's pose and extent. While deep reinforcement learning (RL) has demonstrated impressive success in non-prehensile manipulation, accounting for such variability presents a challenge for the generalist policy, as it must learn diverse strategies for each new combination of constraints. To address this, we propose a modular and reconfigurable architecture that adaptively reconfigures network modules based on task requirements. To capture the geometric variability in environments, we extend the contact-based object representation (CORN) to environment geometries, and propose a procedural algorithm for generating diverse environments to train our agent. Taken together, the resulting policy can zero-shot transfer to novel real-world environments and objects despite training entirely within a simulator. We additionally release a simulation-based benchmark featuring nine digital twins of real-world scenes with 353 objects to facilitate non-prehensile manipulation research in realistic domains.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2502.20843",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "AI helps John Deere transform agriculture",
    "description": "John Deere‚Äôs Justin Rose talks about transforming agriculture with AI and shares how the company is scaling innovation to help farmers work smarter, more efficiently, and sustainably.",
    "summary": "John Deere‚Äôs Justin Rose talks about transforming agriculture with AI and shares how the company is scaling innovation to help farmers work smarter, more efficiently, and sustainably.",
    "pubDate": "Tue, 06 May 2025 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/john-deere-justin-rose",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "KG-FGNN: Knowledge-guided GNN Foundation Model for Fertilisation-oriented Soil GHG Flux Prediction",
    "description": "arXiv:2506.15896v1 Announce Type: cross Abstract: Precision soil greenhouse gas (GHG) flux prediction is essential in agricultural systems for assessing environmental impacts, developing emission mitigation strategies and promoting sustainable agriculture. Due to the lack of advanced sensor and network technologies on majority of farms, there are challenges in obtaining comprehensive and diverse agricultural data. As a result, the scarcity of agricultural data seriously obstructs the application of machine learning approaches in precision soil GHG flux prediction. This research proposes a knowledge-guided graph neural network framework that addresses the above challenges by integrating knowledge embedded in an agricultural process-based model and graph neural network techniques. Specifically, we utilise the agricultural process-based model to simulate and generate multi-dimensional agricultural datasets for 47 countries that cover a wide range of agricultural variables. To extract key agricultural features and integrate correlations among agricultural features in the prediction process, we propose a machine learning framework that integrates the autoencoder and multi-target multi-graph based graph neural networks, which utilises the autoencoder to selectively extract significant agricultural features from the agricultural process-based model simulation data and the graph neural network to integrate correlations among agricultural features for accurately predict fertilisation-oriented soil GHG fluxes. Comprehensive experiments were conducted with both the agricultural simulation dataset and real-world agricultural dataset to evaluate the proposed approach in comparison with well-known baseline and state-of-the-art regression methods. The results demonstrate that our proposed approach provides superior accuracy and stability in fertilisation-oriented soil GHG prediction.",
    "summary": "arXiv:2506.15896v1 Announce Type: cross Abstract: Precision soil greenhouse gas (GHG) flux prediction is essential in agricultural systems for assessing environmental impacts, developing emission mitigation strategies and promoting sustainable agriculture. Due to the lack of advanced sensor and network technologies on majority of farms, there are challenges in obtaining comprehensive and diverse agricultural data. As a result, the scarcity of agricultural data seriously obstructs the application of machine learning approaches in precision soil GHG flux prediction. This research proposes a knowledge-guided graph neural network framework that addresses the above challenges by integrating knowledge embedded in an agricultural process-based model and graph neural network techniques. Specifically, we utilise the agricultural process-based model to simulate and generate multi-dimensional agricultural datasets for 47 countries that cover a wide range of agricultural variables. To extract key agricultural features and integrate correlations among agricultural features in the prediction process, we propose a machine learning framework that integrates the autoencoder and multi-target multi-graph based graph neural networks, which utilises the autoencoder to selectively extract significant agricultural features from the agricultural process-based model simulation data and the graph neural network to integrate correlations among agricultural features for accurately predict fertilisation-oriented soil GHG fluxes. Comprehensive experiments were conducted with both the agricultural simulation dataset and real-world agricultural dataset to evaluate the proposed approach in comparison with well-known baseline and state-of-the-art regression methods. The results demonstrate that our proposed approach provides superior accuracy and stability in fertilisation-oriented soil GHG prediction.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15896",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Unsupervised deep learning model for fast energy layer pre-selection of delivery-efficient proton arc therapy plan optimization of nasopharyngeal carcinoma",
    "description": "arXiv:2506.15803v1 Announce Type: cross Abstract: Objective. Proton arc therapy (PAT) is an emerging and promising modality in radiotherapy, offering several advantages over conventional intensitymodulated proton therapy (IMPT). However, identifying the optimal energy layer (EL) sequence remains computationally intensive due to the large number of possible energy layer transitions. This study proposes an unsupervised deep learning framework for fast and effective EL pre-selection, aiming to minimize energy layer switch time while preserving high plan quality. Approach. We introduce a novel data representation method, spot-count representation, which encodes the number of proton spots intersecting the target and organs at risk (OARs) in a matrix structured by sorted gantry angles and energy layers. This representation is the input of a UNet-based architecture, SPArcdl, which is trained to optimize a tri-objective function: maximizing target coverage, minimizing OAR exposure, and reducing energy switching time. The model is evaluated on 54 nasopharyngeal cancer cases, and its performance is benchmarked against plans generated by SPArcparticle swarm. Main results. SPArcdl produces EL pre-selection that significantly improves both plan quality and delivery efficiency. Compared to SPArc particle swarm, it enhances the conformity index by 0.16 (p < 0.01), reduces the homogeneity index by 0.71 (p < 0.01), shortens the energy switching time by 38.4% (p < 0.01), and lowers the mean dose to brainstem by 0.21 (p < 0.01). The results unintentionally reveal employing unchanged ELS is more time-wise efficient than descended ELS. SPArcdl's inference time is within 1 second. Significance. SPArcdl is a fast and effective tool for generating high-quality PAT plans by strategically pre-selecting energy layers to reduce delivery time while maintaining excellent dosimetric performance.",
    "summary": "arXiv:2506.15803v1 Announce Type: cross Abstract: Objective. Proton arc therapy (PAT) is an emerging and promising modality in radiotherapy, offering several advantages over conventional intensitymodulated proton therapy (IMPT). However, identifying the optimal energy layer (EL) sequence remains computationally intensive due to the large number of possible energy layer transitions. This study proposes an unsupervised deep learning framework for fast and effective EL pre-selection, aiming to minimize energy layer switch time while preserving high plan quality. Approach. We introduce a novel data representation method, spot-count representation, which encodes the number of proton spots intersecting the target and organs at risk (OARs) in a matrix structured by sorted gantry angles and energy layers. This representation is the input of a UNet-based architecture, SPArcdl, which is trained to optimize a tri-objective function: maximizing target coverage, minimizing OAR exposure, and reducing energy switching time. The model is evaluated on 54 nasopharyngeal cancer cases, and its performance is benchmarked against plans generated by SPArcparticle swarm. Main results. SPArcdl produces EL pre-selection that significantly improves both plan quality and delivery efficiency. Compared to SPArc particle swarm, it enhances the conformity index by 0.16 (p < 0.01), reduces the homogeneity index by 0.71 (p < 0.01), shortens the energy switching time by 38.4% (p < 0.01), and lowers the mean dose to brainstem by 0.21 (p < 0.01). The results unintentionally reveal employing unchanged ELS is more time-wise efficient than descended ELS. SPArcdl's inference time is within 1 second. Significance. SPArcdl is a fast and effective tool for generating high-quality PAT plans by strategically pre-selecting energy layers to reduce delivery time while maintaining excellent dosimetric performance.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15803",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "üß® Diffusers welcomes Stable Diffusion 3.5 Large",
    "description": "",
    "summary": "üß® Diffusers welcomes Stable Diffusion 3.5 Large Stable Diffusion 3.5 is the improved variant of its ...",
    "pubDate": "Tue, 22 Oct 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sd3-5",
    "thumbnail": "https://huggingface.co/blog/assets/sd3-5/thumbnail.png"
  },
  {
    "title": "Can We Detect Failures Without Failure Data? Uncertainty-Aware Runtime Failure Detection for Imitation Learning Policies",
    "description": "arXiv:2503.08558v3 Announce Type: replace-cross Abstract: Recent years have witnessed impressive robotic manipulation systems driven by advances in imitation learning and generative modeling, such as diffusion- and flow-based approaches. As robot policy performance increases, so does the complexity and time horizon of achievable tasks, inducing unexpected and diverse failure modes that are difficult to predict a priori. To enable trustworthy policy deployment in safety-critical human environments, reliable runtime failure detection becomes important during policy inference. However, most existing failure detection approaches rely on prior knowledge of failure modes and require failure data during training, which imposes a significant challenge in practicality and scalability. In response to these limitations, we present FAIL-Detect, a modular two-stage approach for failure detection in imitation learning-based robotic manipulation. To accurately identify failures from successful training data alone, we frame the problem as sequential out-of-distribution (OOD) detection. We first distill policy inputs and outputs into scalar signals that correlate with policy failures and capture epistemic uncertainty. FAIL-Detect then employs conformal prediction (CP) as a versatile framework for uncertainty quantification with statistical guarantees. Empirically, we thoroughly investigate both learned and post-hoc scalar signal candidates on diverse robotic manipulation tasks. Our experiments show learned signals to be mostly consistently effective, particularly when using our novel flow-based density estimator. Furthermore, our method detects failures more accurately and faster than state-of-the-art (SOTA) failure detection baselines. These results highlight the potential of FAIL-Detect to enhance the safety and reliability of imitation learning-based robotic systems as they progress toward real-world deployment.",
    "summary": "arXiv:2503.08558v3 Announce Type: replace-cross Abstract: Recent years have witnessed impressive robotic manipulation systems driven by advances in imitation learning and generative modeling, such as diffusion- and flow-based approaches. As robot policy performance increases, so does the complexity and time horizon of achievable tasks, inducing unexpected and diverse failure modes that are difficult to predict a priori. To enable trustworthy policy deployment in safety-critical human environments, reliable runtime failure detection becomes important during policy inference. However, most existing failure detection approaches rely on prior knowledge of failure modes and require failure data during training, which imposes a significant challenge in practicality and scalability. In response to these limitations, we present FAIL-Detect, a modular two-stage approach for failure detection in imitation learning-based robotic manipulation. To accurately identify failures from successful training data alone, we frame the problem as sequential out-of-distribution (OOD) detection. We first distill policy inputs and outputs into scalar signals that correlate with policy failures and capture epistemic uncertainty. FAIL-Detect then employs conformal prediction (CP) as a versatile framework for uncertainty quantification with statistical guarantees. Empirically, we thoroughly investigate both learned and post-hoc scalar signal candidates on diverse robotic manipulation tasks. Our experiments show learned signals to be mostly consistently effective, particularly when using our novel flow-based density estimator. Furthermore, our method detects failures more accurately and faster than state-of-the-art (SOTA) failure detection baselines. These results highlight the potential of FAIL-Detect to enhance the safety and reliability of imitation learning-based robotic systems as they progress toward real-world deployment.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.08558",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Study shows vision-language models can‚Äôt handle queries with negation words",
    "description": "Words like ‚Äúno‚Äù and ‚Äúnot‚Äù can cause this popular class of AI models to fail unexpectedly in high-stakes settings, such as medical diagnosis.",
    "summary": "Words like ‚Äúno‚Äù and ‚Äúnot‚Äù can cause this popular class of AI models to fail unexpectedly in high-stakes settings, such as medical diagnosis.",
    "pubDate": "Wed, 14 May 2025 00:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/study-shows-vision-language-models-cant-handle-negation-words-queries-0514",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/MIT-LMNegation-01-press.jpg"
  },
  {
    "title": "Microsoft invests in and partners with OpenAI to support us building beneficial AGI",
    "description": "Microsoft is investing $1 billion in OpenAI to support us building artificial general intelligence (AGI) with widely distributed economic benefits. We‚Äôre partnering to develop a hardware and software platform within Microsoft Azure which will scale to AGI. We‚Äôll jointly develop new Azure AI supercomputing technologies, and Microsoft will become our exclusive cloud provider‚Äîso we‚Äôll be working hard together to further extend Microsoft Azure‚Äôs capabilities in large-scale AI systems.",
    "summary": "Microsoft is investing $1 billion in OpenAI to support us building artificial general intelligence (AGI) with widely distributed economic benefits. We‚Äôre partnering to develop a hardware and software platform within Microsoft Azure which will scale to AGI. We‚Äôll jointly develop new Azure AI supercomputing technologies, and Microsoft will become our exclusive cloud provider‚Äîso we‚Äôll be working hard together to further extend Microsoft Azure‚Äôs capabilities in large-scale AI systems.",
    "pubDate": "Mon, 22 Jul 2019 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/microsoft-invests-in-and-partners-with-openai",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using transformers, accelerate and bitsandbytes",
    "description": "",
    "summary": "A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using Hugging Face Tr...",
    "pubDate": "Wed, 17 Aug 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/hf-bitsandbytes-integration",
    "thumbnail": "https://huggingface.co/blog/assets/96_hf_bitsandbytes_integration/Thumbnail_blue.png"
  },
  {
    "title": "ChatGPT can now see, hear, and speak",
    "description": "We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you‚Äôre talking about.",
    "summary": "We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you‚Äôre talking about.",
    "pubDate": "Mon, 25 Sep 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/chatgpt-can-now-see-hear-and-speak",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "DALL¬∑E 2: Extending creativity",
    "description": "As part of our DALL¬∑E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL¬∑E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL¬∑E and have served as key voices as we‚Äôve made decisions about DALL¬∑E‚Äôs¬†features.",
    "summary": "As part of our DALL¬∑E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL¬∑E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL¬∑E and have served as key voices as we‚Äôve made decisions about DALL¬∑E‚Äôs¬†features.",
    "pubDate": "Thu, 14 Jul 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/dall-e-2-extending-creativity",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Experimental Assessment of Neural 3D Reconstruction for Small UAV-based Applications",
    "description": "arXiv:2506.19491v1 Announce Type: cross Abstract: The increasing miniaturization of Unmanned Aerial Vehicles (UAVs) has expanded their deployment potential to indoor and hard-to-reach areas. However, this trend introduces distinct challenges, particularly in terms of flight dynamics and power consumption, which limit the UAVs' autonomy and mission capabilities. This paper presents a novel approach to overcoming these limitations by integrating Neural 3D Reconstruction (N3DR) with small UAV systems for fine-grained 3-Dimensional (3D) digital reconstruction of small static objects. Specifically, we design, implement, and evaluate an N3DR-based pipeline that leverages advanced models, i.e., Instant-ngp, Nerfacto, and Splatfacto, to improve the quality of 3D reconstructions using images of the object captured by a fleet of small UAVs. We assess the performance of the considered models using various imagery and pointcloud metrics, comparing them against the baseline Structure from Motion (SfM) algorithm. The experimental results demonstrate that the N3DR-enhanced pipeline significantly improves reconstruction quality, making it feasible for small UAVs to support high-precision 3D mapping and anomaly detection in constrained environments. In more general terms, our results highlight the potential of N3DR in advancing the capabilities of miniaturized UAV systems.",
    "summary": "arXiv:2506.19491v1 Announce Type: cross Abstract: The increasing miniaturization of Unmanned Aerial Vehicles (UAVs) has expanded their deployment potential to indoor and hard-to-reach areas. However, this trend introduces distinct challenges, particularly in terms of flight dynamics and power consumption, which limit the UAVs' autonomy and mission capabilities. This paper presents a novel approach to overcoming these limitations by integrating Neural 3D Reconstruction (N3DR) with small UAV systems for fine-grained 3-Dimensional (3D) digital reconstruction of small static objects. Specifically, we design, implement, and evaluate an N3DR-based pipeline that leverages advanced models, i.e., Instant-ngp, Nerfacto, and Splatfacto, to improve the quality of 3D reconstructions using images of the object captured by a fleet of small UAVs. We assess the performance of the considered models using various imagery and pointcloud metrics, comparing them against the baseline Structure from Motion (SfM) algorithm. The experimental results demonstrate that the N3DR-enhanced pipeline significantly improves reconstruction quality, making it feasible for small UAVs to support high-precision 3D mapping and anomaly detection in constrained environments. In more general terms, our results highlight the potential of N3DR in advancing the capabilities of miniaturized UAV systems.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19491",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Interpretable machine learning through teaching",
    "description": "We‚Äôve designed a method that encourages AIs to teach each other with examples that also make sense to humans. Our approach automatically selects the most informative examples to teach a concept‚Äîfor instance, the best images to describe the concept of dogs‚Äîand experimentally we found our approach to be effective at teaching both AIs",
    "summary": "We‚Äôve designed a method that encourages AIs to teach each other with examples that also make sense to humans. Our approach automatically selects the most informative examples to teach a concept‚Äîfor instance, the best images to describe the concept of dogs‚Äîand experimentally we found our approach to be effective at teaching both AIs",
    "pubDate": "Thu, 15 Feb 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/interpretable-machine-learning-through-teaching",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Automating customer support agents",
    "description": "MavenAGI is a new software company for the AI era. They recently launched an AI customer service agent, built on the flexibility of GPT-4, which a number of companies like Tripadvisor, Clickup and Rho are already using to save time and better serve their customers.",
    "summary": "MavenAGI is a new software company for the AI era. They recently launched an AI customer service agent, built on the flexibility of GPT-4, which a number of companies like Tripadvisor, Clickup and Rho are already using to save time and better serve their customers.",
    "pubDate": "Wed, 29 May 2024 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/mavenagi",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deliberative alignment: reasoning enables safer language models",
    "description": "Deliberative alignment: reasoning enables safer language models Introducing our new alignment strategy for o1 models, which are directly taught safety specifications and how to reason over them.",
    "summary": "Deliberative alignment: reasoning enables safer language models Introducing our new alignment strategy for o1 models, which are directly taught safety specifications and how to reason over them.",
    "pubDate": "Fri, 20 Dec 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/deliberative-alignment",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Customizing models for legal professionals",
    "description": "Harvey partners with OpenAI to build a custom-trained model for legal professionals.",
    "summary": "Harvey partners with OpenAI to build a custom-trained model for legal professionals.",
    "pubDate": "Tue, 02 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/harvey",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing next-generation audio models in the API",
    "description": "For the first time, developers can also instruct the text-to-speech model to speak in a specific way‚Äîfor example, ‚Äútalk like a sympathetic customer service agent‚Äù‚Äîunlocking a new level of customization for voice agents.",
    "summary": "For the first time, developers can also instruct the text-to-speech model to speak in a specific way‚Äîfor example, ‚Äútalk like a sympathetic customer service agent‚Äù‚Äîunlocking a new level of customization for voice agents.",
    "pubDate": "Thu, 20 Mar 2025 11:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-our-next-generation-audio-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Improving Model Safety Behavior with Rule-Based Rewards",
    "description": "We've developed and applied a new method leveraging Rule-Based Rewards (RBRs) that aligns models to behave safely without extensive human data collection.",
    "summary": "We've developed and applied a new method leveraging Rule-Based Rewards (RBRs) that aligns models to behave safely without extensive human data collection.",
    "pubDate": "Wed, 24 Jul 2024 09:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/improving-model-safety-behavior-with-rule-based-rewards",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "RecBayes: Recurrent Bayesian Ad Hoc Teamwork in Large Partially Observable Domains",
    "description": "arXiv:2506.15756v1 Announce Type: cross Abstract: This paper proposes RecBayes, a novel approach for ad hoc teamwork under partial observability, a setting where agents are deployed on-the-fly to environments where pre-existing teams operate, that never requires, at any stage, access to the states of the environment or the actions of its teammates. We show that by relying on a recurrent Bayesian classifier trained using past experiences, an ad hoc agent is effectively able to identify known teams and tasks being performed from observations alone. Unlike recent approaches such as PO-GPL (Gu et al., 2021) and FEAT (Rahman et al., 2023), that require at some stage fully observable states of the environment, actions of teammates, or both, or approaches such as ATPO (Ribeiro et al., 2023) that require the environments to be small enough to be tabularly modelled (Ribeiro et al., 2023), in their work up to 4.8K states and 1.7K observations, we show RecBayes is both able to handle arbitrarily large spaces while never relying on either states and teammates' actions. Our results in benchmark domains from the multi-agent systems literature, adapted for partial observability and scaled up to 1M states and 2^125 observations, show that RecBayes is effective at identifying known teams and tasks being performed from partial observations alone, and as a result, is able to assist the teams in solving the tasks effectively.",
    "summary": "arXiv:2506.15756v1 Announce Type: cross Abstract: This paper proposes RecBayes, a novel approach for ad hoc teamwork under partial observability, a setting where agents are deployed on-the-fly to environments where pre-existing teams operate, that never requires, at any stage, access to the states of the environment or the actions of its teammates. We show that by relying on a recurrent Bayesian classifier trained using past experiences, an ad hoc agent is effectively able to identify known teams and tasks being performed from observations alone. Unlike recent approaches such as PO-GPL (Gu et al., 2021) and FEAT (Rahman et al., 2023), that require at some stage fully observable states of the environment, actions of teammates, or both, or approaches such as ATPO (Ribeiro et al., 2023) that require the environments to be small enough to be tabularly modelled (Ribeiro et al., 2023), in their work up to 4.8K states and 1.7K observations, we show RecBayes is both able to handle arbitrarily large spaces while never relying on either states and teammates' actions. Our results in benchmark domains from the multi-agent systems literature, adapted for partial observability and scaled up to 1M states and 2^125 observations, show that RecBayes is effective at identifying known teams and tasks being performed from partial observations alone, and as a result, is able to assist the teams in solving the tasks effectively.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15756",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Robust Stability Prediction in Smart Grids: GAN-based Approach under Data Constraints and Adversarial Challenges",
    "description": "arXiv:2501.16490v2 Announce Type: replace-cross Abstract: Smart grids are crucial for meeting rising energy demands driven by global population growth and urbanization. By integrating renewable energy sources, they enhance efficiency, reliability, and sustainability. However, ensuring their availability and security requires advanced operational control and safety measures. Although artificial intelligence and machine learning can help assess grid stability, challenges such as data scarcity and cybersecurity threats, particularly adversarial attacks, remain. Data scarcity is a major issue, as obtaining real-world instances of grid instability requires significant expertise, resources, and time. Yet, these instances are critical for testing new research advancements and security mitigations. This paper introduces a novel framework for detecting instability in smart grids using only stable data. It employs a Generative Adversarial Network (GAN) where the generator is designed not to produce near-realistic data but instead to generate Out-Of-Distribution (OOD) samples with respect to the stable class. These OOD samples represent unstable behavior, anomalies, or disturbances that deviate from the stable data distribution. By training exclusively on stable data and exposing the discriminator to OOD samples, our framework learns a robust decision boundary to distinguish stable conditions from any unstable behavior, without requiring unstable data during training. Furthermore, we incorporate an adversarial training layer to enhance resilience against attacks. Evaluated on a real-world dataset, our solution achieves up to 98.1% accuracy in predicting grid stability and 98.9% in detecting adversarial attacks. Implemented on a single-board computer, it enables real-time decision-making with an average response time of under 7ms.",
    "summary": "arXiv:2501.16490v2 Announce Type: replace-cross Abstract: Smart grids are crucial for meeting rising energy demands driven by global population growth and urbanization. By integrating renewable energy sources, they enhance efficiency, reliability, and sustainability. However, ensuring their availability and security requires advanced operational control and safety measures. Although artificial intelligence and machine learning can help assess grid stability, challenges such as data scarcity and cybersecurity threats, particularly adversarial attacks, remain. Data scarcity is a major issue, as obtaining real-world instances of grid instability requires significant expertise, resources, and time. Yet, these instances are critical for testing new research advancements and security mitigations. This paper introduces a novel framework for detecting instability in smart grids using only stable data. It employs a Generative Adversarial Network (GAN) where the generator is designed not to produce near-realistic data but instead to generate Out-Of-Distribution (OOD) samples with respect to the stable class. These OOD samples represent unstable behavior, anomalies, or disturbances that deviate from the stable data distribution. By training exclusively on stable data and exposing the discriminator to OOD samples, our framework learns a robust decision boundary to distinguish stable conditions from any unstable behavior, without requiring unstable data during training. Furthermore, we incorporate an adversarial training layer to enhance resilience against attacks. Evaluated on a real-world dataset, our solution achieves up to 98.1% accuracy in predicting grid stability and 98.9% in detecting adversarial attacks. Implemented on a single-board computer, it enables real-time decision-making with an average response time of under 7ms.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2501.16490",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "FreeEnricher: Enriching Face Landmarks without Additional Cost",
    "description": "arXiv:2212.09525v1 Announce Type: cross Abstract: Recent years have witnessed significant growth of face alignment. Though dense facial landmark is highly demanded in various scenarios, e.g., cosmetic medicine and facial beautification, most works only consider sparse face alignment. To address this problem, we present a framework that can enrich landmark density by existing sparse landmark datasets, e.g., 300W with 68 points and WFLW with 98 points. Firstly, we observe that the local patches along each semantic contour are highly similar in appearance. Then, we propose a weakly-supervised idea of learning the refinement ability on original sparse landmarks and adapting this ability to enriched dense landmarks. Meanwhile, several operators are devised and organized together to implement the idea. Finally, the trained model is applied as a plug-and-play module to the existing face alignment networks. To evaluate our method, we manually label the dense landmarks on 300W testset. Our method yields state-of-the-art accuracy not only in newly-constructed dense 300W testset but also in the original sparse 300W and WFLW testsets without additional cost.",
    "summary": "arXiv:2212.09525v1 Announce Type: cross Abstract: Recent years have witnessed significant growth of face alignment. Though dense facial landmark is highly demanded in various scenarios, e.g., cosmetic medicine and facial beautification, most works only consider sparse face alignment. To address this problem, we present a framework that can enrich landmark density by existing sparse landmark datasets, e.g., 300W with 68 points and WFLW with 98 points. Firstly, we observe that the local patches along each semantic contour are highly similar in appearance. Then, we propose a weakly-supervised idea of learning the refinement ability on original sparse landmarks and adapting this ability to enriched dense landmarks. Meanwhile, several operators are devised and organized together to implement the idea. Finally, the trained model is applied as a plug-and-play module to the existing face alignment networks. To evaluate our method, we manually label the dense landmarks on 300W testset. Our method yields state-of-the-art accuracy not only in newly-constructed dense 300W testset but also in the original sparse 300W and WFLW testsets without additional cost.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2212.09525",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Scholars 2019: Applications open",
    "description": "We are now accepting applications for our second cohort of OpenAI Scholars, a program where we provide 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "summary": "We are now accepting applications for our second cohort of OpenAI Scholars, a program where we provide 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "pubDate": "Thu, 11 Oct 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars-2019",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Can AI support student engagement in classroom activities in higher education?",
    "description": "arXiv:2506.18941v1 Announce Type: cross Abstract: Lucrative career prospects and creative opportunities often attract students to enroll in computer science majors and pursue advanced studies in the field. Consequently, there has been a significant surge in enrollment in computer science courses, resulting in large class sizes that can range from hundreds to even thousands of students. A common challenge in such large classrooms is the lack of engagement between students and both the instructor and the learning material. However, with advancements in technology and improvements in large language models (LLMs), there is a considerable opportunity to utilize LLM-based AI models, such as conversational artificial intelligence (CAI), to enhance student engagement with learning content in large classes. To explore the potential of CAI to support engagement, especially with learning content, we designed an activity in a software Engineering course (with a large class size) where students used CAI for an in-class activity. We conducted a within-subject investigation in a large classroom at a US university where we compared student engagement during an in-class activity that used CAI tool vs. one without CAI tool. The CAI tool we used was ChatGPT due to its widespread popularity and familiarity. Our results indicate that CAI (ChatGPT) has the potential to support engagement with learning content during in-class activities, especially in large class sizes. We further discuss the implications of our findings.",
    "summary": "arXiv:2506.18941v1 Announce Type: cross Abstract: Lucrative career prospects and creative opportunities often attract students to enroll in computer science majors and pursue advanced studies in the field. Consequently, there has been a significant surge in enrollment in computer science courses, resulting in large class sizes that can range from hundreds to even thousands of students. A common challenge in such large classrooms is the lack of engagement between students and both the instructor and the learning material. However, with advancements in technology and improvements in large language models (LLMs), there is a considerable opportunity to utilize LLM-based AI models, such as conversational artificial intelligence (CAI), to enhance student engagement with learning content in large classes. To explore the potential of CAI to support engagement, especially with learning content, we designed an activity in a software Engineering course (with a large class size) where students used CAI for an in-class activity. We conducted a within-subject investigation in a large classroom at a US university where we compared student engagement during an in-class activity that used CAI tool vs. one without CAI tool. The CAI tool we used was ChatGPT due to its widespread popularity and familiarity. Our results indicate that CAI (ChatGPT) has the potential to support engagement with learning content during in-class activities, especially in large class sizes. We further discuss the implications of our findings.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18941",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Codex",
    "description": "We‚Äôve created an improved version of OpenAI Codex, our AI system that translates natural language to code, and we are releasing it through our API in private beta starting today.",
    "summary": "We‚Äôve created an improved version of OpenAI Codex, our AI system that translates natural language to code, and we are releasing it through our API in private beta starting today.",
    "pubDate": "Tue, 10 Aug 2021 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-codex",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "SemAgent: A Semantics Aware Program Repair Agent",
    "description": "arXiv:2506.16650v1 Announce Type: cross Abstract: Large Language Models (LLMs) have shown impressive capabilities in downstream software engineering tasks such as Automated Program Repair (APR). In particular, there has been a lot of research on repository-level issue-resolution benchmarks such as SWE-Bench. Although there has been significant progress on this topic, we notice that in the process of solving such issues, existing agentic systems tend to hyper-localize on immediately suspicious lines of code and fix them in isolation, without a deeper understanding of the issue semantics, code semantics, or execution semantics. Consequently, many existing systems generate patches that overfit to the user issue, even when a more general fix is preferable. To address this limitation, we introduce SemAgent, a novel workflow-based procedure that leverages issue, code, and execution semantics to generate patches that are complete - identifying and fixing all lines relevant to the issue. We achieve this through a novel pipeline that (a) leverages execution semantics to retrieve relevant context, (b) comprehends issue-semantics via generalized abstraction, (c) isolates code-semantics within the context of this abstraction, and (d) leverages this understanding in a two-stage architecture: a repair stage that proposes fine-grained fixes, followed by a reviewer stage that filters relevant fixes based on the inferred issue-semantics. Our evaluations show that our methodology achieves a solve rate of 44.66% on the SWEBench-Lite benchmark beating all other workflow-based approaches, and an absolute improvement of 7.66% compared to our baseline, which lacks such deep semantic understanding. We note that our approach performs particularly well on issues requiring multi-line reasoning (and editing) and edge-case handling, suggesting that incorporating issue and code semantics into APR pipelines can lead to robust and semantically consistent repairs.",
    "summary": "arXiv:2506.16650v1 Announce Type: cross Abstract: Large Language Models (LLMs) have shown impressive capabilities in downstream software engineering tasks such as Automated Program Repair (APR). In particular, there has been a lot of research on repository-level issue-resolution benchmarks such as SWE-Bench. Although there has been significant progress on this topic, we notice that in the process of solving such issues, existing agentic systems tend to hyper-localize on immediately suspicious lines of code and fix them in isolation, without a deeper understanding of the issue semantics, code semantics, or execution semantics. Consequently, many existing systems generate patches that overfit to the user issue, even when a more general fix is preferable. To address this limitation, we introduce SemAgent, a novel workflow-based procedure that leverages issue, code, and execution semantics to generate patches that are complete - identifying and fixing all lines relevant to the issue. We achieve this through a novel pipeline that (a) leverages execution semantics to retrieve relevant context, (b) comprehends issue-semantics via generalized abstraction, (c) isolates code-semantics within the context of this abstraction, and (d) leverages this understanding in a two-stage architecture: a repair stage that proposes fine-grained fixes, followed by a reviewer stage that filters relevant fixes based on the inferred issue-semantics. Our evaluations show that our methodology achieves a solve rate of 44.66% on the SWEBench-Lite benchmark beating all other workflow-based approaches, and an absolute improvement of 7.66% compared to our baseline, which lacks such deep semantic understanding. We note that our approach performs particularly well on issues requiring multi-line reasoning (and editing) and edge-case handling, suggesting that incorporating issue and code semantics into APR pipelines can lead to robust and semantically consistent repairs.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16650",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenAI Scholars",
    "description": "We‚Äôre providing 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "summary": "We‚Äôre providing 6‚Äì10 stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3 months and open-source a project.",
    "pubDate": "Tue, 06 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-scholars",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "FEAST: A Flexible Mealtime-Assistance System Towards In-the-Wild Personalization",
    "description": "arXiv:2506.14968v2 Announce Type: replace-cross Abstract: Physical caregiving robots hold promise for improving the quality of life of millions worldwide who require assistance with feeding. However, in-home meal assistance remains challenging due to the diversity of activities (e.g., eating, drinking, mouth wiping), contexts (e.g., socializing, watching TV), food items, and user preferences that arise during deployment. In this work, we propose FEAST, a flexible mealtime-assistance system that can be personalized in-the-wild to meet the unique needs of individual care recipients. Developed in collaboration with two community researchers and informed by a formative study with a diverse group of care recipients, our system is guided by three key tenets for in-the-wild personalization: adaptability, transparency, and safety. FEAST embodies these principles through: (i) modular hardware that enables switching between assisted feeding, drinking, and mouth-wiping, (ii) diverse interaction methods, including a web interface, head gestures, and physical buttons, to accommodate diverse functional abilities and preferences, and (iii) parameterized behavior trees that can be safely and transparently adapted using a large language model. We evaluate our system based on the personalization requirements identified in our formative study, demonstrating that FEAST offers a wide range of transparent and safe adaptations and outperforms a state-of-the-art baseline limited to fixed customizations. To demonstrate real-world applicability, we conduct an in-home user study with two care recipients (who are community researchers), feeding them three meals each across three diverse scenarios. We further assess FEAST's ecological validity by evaluating with an Occupational Therapist previously unfamiliar with the system. In all cases, users successfully personalize FEAST to meet their individual needs and preferences. Website: https://emprise.cs.cornell.edu/feast",
    "summary": "arXiv:2506.14968v2 Announce Type: replace-cross Abstract: Physical caregiving robots hold promise for improving the quality of life of millions worldwide who require assistance with feeding. However, in-home meal assistance remains challenging due to the diversity of activities (e.g., eating, drinking, mouth wiping), contexts (e.g., socializing, watching TV), food items, and user preferences that arise during deployment. In this work, we propose FEAST, a flexible mealtime-assistance system that can be personalized in-the-wild to meet the unique needs of individual care recipients. Developed in collaboration with two community researchers and informed by a formative study with a diverse group of care recipients, our system is guided by three key tenets for in-the-wild personalization: adaptability, transparency, and safety. FEAST embodies these principles through: (i) modular hardware that enables switching between assisted feeding, drinking, and mouth-wiping, (ii) diverse interaction methods, including a web interface, head gestures, and physical buttons, to accommodate diverse functional abilities and preferences, and (iii) parameterized behavior trees that can be safely and transparently adapted using a large language model. We evaluate our system based on the personalization requirements identified in our formative study, demonstrating that FEAST offers a wide range of transparent and safe adaptations and outperforms a state-of-the-art baseline limited to fixed customizations. To demonstrate real-world applicability, we conduct an in-home user study with two care recipients (who are community researchers), feeding them three meals each across three diverse scenarios. We further assess FEAST's ecological validity by evaluating with an Occupational Therapist previously unfamiliar with the system. In all cases, users successfully personalize FEAST to meet their individual needs and preferences. Website: https://emprise.cs.cornell.edu/feast",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.14968",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "On first-order meta-learning algorithms",
    "description": "",
    "summary": "",
    "pubDate": "Thu, 08 Mar 2018 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/on-first-order-meta-learning-algorithms",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Abstracts: Zero-shot models in single-cell biology with Alex Lu",
    "description": "<p>The emergence of foundation models has sparked interest in applications to single-cell biology, but when tested in zero-shot settings, they underperform compared to simpler methods. Alex Lu shares insights on why more research on AI models is needed in biological applications.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/abstracts-zero-shot-models-in-single-cell-biology-with-alex-lu/'>Abstracts: Zero-shot models in single-cell biology with Alex Lu</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "summary": "<p>The emergence of foundation models has sparked interest in applications to single-cell biology, but when tested in zero-shot settings, they underperform compared to simpler methods. Alex Lu shares insights on why more research on AI models is needed in biological applications.</p> <p>The post <a href='https://www.microsoft.com/en-us/research/podcast/abstracts-zero-shot-models-in-single-cell-biology-with-alex-lu/'>Abstracts: Zero-shot models in single-cell biology with Alex Lu</a> appeared first on <a href='https://www.microsoft.com/en-us/research'>Microsoft Research</a>.</p>",
    "pubDate": "Thu, 22 May 2025 15:58:00 +0000",
    "source": "Microsoft Research Blog",
    "url": "https://www.microsoft.com/en-us/research/podcast/abstracts-zero-shot-models-in-single-cell-biology-with-alex-lu/",
    "thumbnail": "https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE1Mu3b?ver=5c31&h=30"
  },
  {
    "title": "Are Bias Evaluation Methods Biased ?",
    "description": "arXiv:2506.17111v1 Announce Type: new Abstract: The creation of benchmarks to evaluate the safety of Large Language Models is one of the key activities within the trusted AI community. These benchmarks allow models to be compared for different aspects of safety such as toxicity, bias, harmful behavior etc. Independent benchmarks adopt different approaches with distinct data sets and evaluation methods. We investigate how robust such benchmarks are by using different approaches to rank a set of representative models for bias and compare how similar are the overall rankings. We show that different but widely used bias evaluations methods result in disparate model rankings. We conclude with recommendations for the community in the usage of such benchmarks.",
    "summary": "arXiv:2506.17111v1 Announce Type: new Abstract: The creation of benchmarks to evaluate the safety of Large Language Models is one of the key activities within the trusted AI community. These benchmarks allow models to be compared for different aspects of safety such as toxicity, bias, harmful behavior etc. Independent benchmarks adopt different approaches with distinct data sets and evaluation methods. We investigate how robust such benchmarks are by using different approaches to rank a set of representative models for bias and compare how similar are the overall rankings. We show that different but widely used bias evaluations methods result in disparate model rankings. We conclude with recommendations for the community in the usage of such benchmarks.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17111",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Fine-tuning GPT-3 to scale video creation",
    "description": "Fine-tuning GPT-3 to power and scale done-for-you video creation.",
    "summary": "Fine-tuning GPT-3 to power and scale done-for-you video creation.",
    "pubDate": "Tue, 03 Jan 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/waymark",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Representation Learning with Mutual Influence of Modalities for Node Classification in Multi-Modal Heterogeneous Networks",
    "description": "arXiv:2505.07895v3 Announce Type: replace-cross Abstract: Nowadays, numerous online platforms can be described as multi-modal heterogeneous networks (MMHNs), such as Douban's movie networks and Amazon's product review networks. Accurately categorizing nodes within these networks is crucial for analyzing the corresponding entities, which requires effective representation learning on nodes. However, existing multi-modal fusion methods often adopt either early fusion strategies which may lose the unique characteristics of individual modalities, or late fusion approaches overlooking the cross-modal guidance in GNN-based information propagation. In this paper, we propose a novel model for node classification in MMHNs, named Heterogeneous Graph Neural Network with Inter-Modal Attention (HGNN-IMA). It learns node representations by capturing the mutual influence of multiple modalities during the information propagation process, within the framework of heterogeneous graph transformer. Specifically, a nested inter-modal attention mechanism is integrated into the inter-node attention to achieve adaptive multi-modal fusion, and modality alignment is also taken into account to encourage the propagation among nodes with consistent similarities across all modalities. Moreover, an attention loss is augmented to mitigate the impact of missing modalities. Extensive experiments validate the superiority of the model in the node classification task, providing an innovative view to handle multi-modal data, especially when accompanied with network structures.",
    "summary": "arXiv:2505.07895v3 Announce Type: replace-cross Abstract: Nowadays, numerous online platforms can be described as multi-modal heterogeneous networks (MMHNs), such as Douban's movie networks and Amazon's product review networks. Accurately categorizing nodes within these networks is crucial for analyzing the corresponding entities, which requires effective representation learning on nodes. However, existing multi-modal fusion methods often adopt either early fusion strategies which may lose the unique characteristics of individual modalities, or late fusion approaches overlooking the cross-modal guidance in GNN-based information propagation. In this paper, we propose a novel model for node classification in MMHNs, named Heterogeneous Graph Neural Network with Inter-Modal Attention (HGNN-IMA). It learns node representations by capturing the mutual influence of multiple modalities during the information propagation process, within the framework of heterogeneous graph transformer. Specifically, a nested inter-modal attention mechanism is integrated into the inter-node attention to achieve adaptive multi-modal fusion, and modality alignment is also taken into account to encourage the propagation among nodes with consistent similarities across all modalities. Moreover, an attention loss is augmented to mitigate the impact of missing modalities. Extensive experiments validate the superiority of the model in the node classification task, providing an innovative view to handle multi-modal data, especially when accompanied with network structures.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2505.07895",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models",
    "description": "",
    "summary": "",
    "pubDate": "Fri, 11 Nov 2016 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/a-connection-between-generative-adversarial-networks-inverse-reinforcement-learning-and-energy-based-models",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LEGO-Puzzles: How Good Are MLLMs at Multi-Step Spatial Reasoning?",
    "description": "arXiv:2503.19990v3 Announce Type: replace Abstract: Multi-step spatial reasoning entails understanding and reasoning about spatial relationships across multiple sequential steps, which is crucial for tackling complex real-world applications, such as robotic manipulation, autonomous navigation, and automated assembly. To assess how well current Multimodal Large Language Models (MLLMs) have acquired this fundamental capability, we introduce LEGO-Puzzles, a scalable benchmark designed to evaluate both spatial understanding and sequential reasoning in MLLMs through LEGO-based tasks. LEGO-Puzzles consists of 1,100 carefully curated visual question-answering (VQA) samples spanning 11 distinct tasks, ranging from basic spatial understanding to complex multi-step reasoning. Based on LEGO-Puzzles, we conduct a comprehensive evaluation of 20 state-of-the-art MLLMs and uncover significant limitations in their spatial reasoning capabilities: even the most powerful MLLMs can answer only about half of the test cases, whereas human participants achieve over 90% accuracy. Furthermore, based on LEGO-Puzzles, we design generation tasks to investigate whether MLLMs can transfer their spatial understanding and reasoning abilities to image generation. Our experiments show that only GPT-4o and Gemini-2.0-Flash exhibit a limited ability to follow these instructions, while other MLLMs either replicate the input image or generate completely irrelevant outputs. Overall, LEGO-Puzzles exposes critical deficiencies in existing MLLMs' spatial understanding and sequential reasoning capabilities, and underscores the need for further advancements in multimodal spatial reasoning.",
    "summary": "arXiv:2503.19990v3 Announce Type: replace Abstract: Multi-step spatial reasoning entails understanding and reasoning about spatial relationships across multiple sequential steps, which is crucial for tackling complex real-world applications, such as robotic manipulation, autonomous navigation, and automated assembly. To assess how well current Multimodal Large Language Models (MLLMs) have acquired this fundamental capability, we introduce LEGO-Puzzles, a scalable benchmark designed to evaluate both spatial understanding and sequential reasoning in MLLMs through LEGO-based tasks. LEGO-Puzzles consists of 1,100 carefully curated visual question-answering (VQA) samples spanning 11 distinct tasks, ranging from basic spatial understanding to complex multi-step reasoning. Based on LEGO-Puzzles, we conduct a comprehensive evaluation of 20 state-of-the-art MLLMs and uncover significant limitations in their spatial reasoning capabilities: even the most powerful MLLMs can answer only about half of the test cases, whereas human participants achieve over 90% accuracy. Furthermore, based on LEGO-Puzzles, we design generation tasks to investigate whether MLLMs can transfer their spatial understanding and reasoning abilities to image generation. Our experiments show that only GPT-4o and Gemini-2.0-Flash exhibit a limited ability to follow these instructions, while other MLLMs either replicate the input image or generate completely irrelevant outputs. Overall, LEGO-Puzzles exposes critical deficiencies in existing MLLMs' spatial understanding and sequential reasoning capabilities, and underscores the need for further advancements in multimodal spatial reasoning.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.19990",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "17 Reasons Why Gradio Isn't Just Another UI Library",
    "description": "",
    "summary": "17 Reasons Why Gradio Isn't Just Another UI Library Introduction 'Oh, Gradio? That's a Python librar...",
    "pubDate": "Wed, 16 Apr 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/why-gradio-stands-out",
    "thumbnail": "https://huggingface.co/blog/assets/why-gradio-stands-out/thumbnail.png"
  },
  {
    "title": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective",
    "description": "arXiv:2506.19028v1 Announce Type: cross Abstract: Large Language Models (LLMs) often generate responses with inherent biases, undermining their reliability in real-world applications. Existing evaluation methods often overlook biases in long-form responses and the intrinsic variability of LLM outputs. To address these challenges, we propose FiSCo(Fine-grained Semantic Computation), a novel statistical framework to evaluate group-level fairness in LLMs by detecting subtle semantic differences in long-form responses across demographic groups. Unlike prior work focusing on sentiment or token-level comparisons, FiSCo goes beyond surface-level analysis by operating at the claim level, leveraging entailment checks to assess the consistency of meaning across responses. We decompose model outputs into semantically distinct claims and apply statistical hypothesis testing to compare inter- and intra-group similarities, enabling robust detection of subtle biases. We formalize a new group counterfactual fairness definition and validate FiSCo on both synthetic and human-annotated datasets spanning gender, race, and age. Experiments show that FiSco more reliably identifies nuanced biases while reducing the impact of stochastic LLM variability, outperforming various evaluation metrics.",
    "summary": "arXiv:2506.19028v1 Announce Type: cross Abstract: Large Language Models (LLMs) often generate responses with inherent biases, undermining their reliability in real-world applications. Existing evaluation methods often overlook biases in long-form responses and the intrinsic variability of LLM outputs. To address these challenges, we propose FiSCo(Fine-grained Semantic Computation), a novel statistical framework to evaluate group-level fairness in LLMs by detecting subtle semantic differences in long-form responses across demographic groups. Unlike prior work focusing on sentiment or token-level comparisons, FiSCo goes beyond surface-level analysis by operating at the claim level, leveraging entailment checks to assess the consistency of meaning across responses. We decompose model outputs into semantically distinct claims and apply statistical hypothesis testing to compare inter- and intra-group similarities, enabling robust detection of subtle biases. We formalize a new group counterfactual fairness definition and validate FiSCo on both synthetic and human-annotated datasets spanning gender, race, and age. Experiments show that FiSco more reliably identifies nuanced biases while reducing the impact of stochastic LLM variability, outperforming various evaluation metrics.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19028",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Q&A: A roadmap for revolutionizing health care through data-driven innovation",
    "description": "A new book coauthored by MIT‚Äôs Dimitris Bertsimas explores how analytics is driving decisions and outcomes in health care.",
    "summary": "A new book coauthored by MIT‚Äôs Dimitris Bertsimas explores how analytics is driving decisions and outcomes in health care.",
    "pubDate": "Mon, 05 May 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/qa-roadmap-revolutionizing-health-care-through-data-driven-innovation-0505",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/Analytics-Edge-in-Healthcare-Dimitris-Bertsimas-00.png"
  },
  {
    "title": "Introducing Structured Outputs in the API",
    "description": "We are introducing Structured Outputs in the API‚Äîmodel outputs now reliably adhere to developer-supplied JSON Schemas.",
    "summary": "We are introducing Structured Outputs in the API‚Äîmodel outputs now reliably adhere to developer-supplied JSON Schemas.",
    "pubDate": "Tue, 06 Aug 2024 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/introducing-structured-outputs-in-the-api",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Train a Sentence Embedding Model with 1B Training Pairs",
    "description": "",
    "summary": "Train a Sentence Embedding Model with 1 Billion Training Pairs Sentence embedding is a method that m...",
    "pubDate": "Mon, 25 Oct 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/1b-sentence-embeddings",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Federated Data-Efficient Instruction Tuning for Large Language Models",
    "description": "arXiv:2410.10926v2 Announce Type: replace-cross Abstract: Instruction tuning is a crucial step in improving the responsiveness of pretrained large language models (LLMs) to human instructions. Federated learning (FL) helps to exploit the use of vast private instruction data from clients, becoming popular for LLM tuning by improving data diversity. Existing federated tuning simply consumes all local data, causing excessive computational overhead and overfitting to local data, while centralized data-efficient solutions are not suitable for FL due to privacy concerns. This work presents FedHDS, a federated data-efficient instruction tuning approach, which tunes LLMs with a representative subset of edge-side data. It reduces the data redundancy at both intra- and inter-client levels without sharing raw data. Experiments with various LLMs, datasets and partitions show that FedHDS improves Rouge-L on unseen tasks by an average of 10.72% over the SOTA full-data federated instruction tuning methods, while using less than 1.5% of the data samples, improving training efficiency by up to tens of times.",
    "summary": "arXiv:2410.10926v2 Announce Type: replace-cross Abstract: Instruction tuning is a crucial step in improving the responsiveness of pretrained large language models (LLMs) to human instructions. Federated learning (FL) helps to exploit the use of vast private instruction data from clients, becoming popular for LLM tuning by improving data diversity. Existing federated tuning simply consumes all local data, causing excessive computational overhead and overfitting to local data, while centralized data-efficient solutions are not suitable for FL due to privacy concerns. This work presents FedHDS, a federated data-efficient instruction tuning approach, which tunes LLMs with a representative subset of edge-side data. It reduces the data redundancy at both intra- and inter-client levels without sharing raw data. Experiments with various LLMs, datasets and partitions show that FedHDS improves Rouge-L on unseen tasks by an average of 10.72% over the SOTA full-data federated instruction tuning methods, while using less than 1.5% of the data samples, improving training efficiency by up to tens of times.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2410.10926",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Vision Transformers Don't Need Trained Registers",
    "description": "arXiv:2506.08010v4 Announce Type: replace-cross Abstract: We investigate the mechanism underlying a previously identified phenomenon in Vision Transformers -- the emergence of high-norm tokens that lead to noisy attention maps. We observe that in multiple models (e.g., CLIP, DINOv2), a sparse set of neurons is responsible for concentrating high-norm activations on outlier tokens, leading to irregular attention patterns and degrading downstream visual processing. While the existing solution for removing these outliers involves retraining models from scratch with additional learned register tokens, we use our findings to create a training-free approach to mitigate these artifacts. By shifting the high-norm activations from our discovered register neurons into an additional untrained token, we can mimic the effect of register tokens on a model already trained without registers. We demonstrate that our method produces cleaner attention and feature maps, enhances performance over base models across multiple downstream visual tasks, and achieves results comparable to models explicitly trained with register tokens. We then extend test-time registers to off-the-shelf vision-language models to improve their interpretability. Our results suggest that test-time registers effectively take on the role of register tokens at test-time, offering a training-free solution for any pre-trained model released without them.",
    "summary": "arXiv:2506.08010v4 Announce Type: replace-cross Abstract: We investigate the mechanism underlying a previously identified phenomenon in Vision Transformers -- the emergence of high-norm tokens that lead to noisy attention maps. We observe that in multiple models (e.g., CLIP, DINOv2), a sparse set of neurons is responsible for concentrating high-norm activations on outlier tokens, leading to irregular attention patterns and degrading downstream visual processing. While the existing solution for removing these outliers involves retraining models from scratch with additional learned register tokens, we use our findings to create a training-free approach to mitigate these artifacts. By shifting the high-norm activations from our discovered register neurons into an additional untrained token, we can mimic the effect of register tokens on a model already trained without registers. We demonstrate that our method produces cleaner attention and feature maps, enhances performance over base models across multiple downstream visual tasks, and achieves results comparable to models explicitly trained with register tokens. We then extend test-time registers to off-the-shelf vision-language models to improve their interpretability. Our results suggest that test-time registers effectively take on the role of register tokens at test-time, offering a training-free solution for any pre-trained model released without them.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.08010",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation",
    "description": "arXiv:2506.21931v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) has shown promise in enhancing recommendation systems by incorporating external context into large language model prompts. However, existing RAG-based approaches often rely on static retrieval heuristics and fail to capture nuanced user preferences in dynamic recommendation scenarios. In this work, we introduce ARAG, an Agentic Retrieval-Augmented Generation framework for Personalized Recommendation, which integrates a multi-agent collaboration mechanism into the RAG pipeline. To better understand the long-term and session behavior of the user, ARAG leverages four specialized LLM-based agents: a User Understanding Agent that summarizes user preferences from long-term and session contexts, a Natural Language Inference (NLI) Agent that evaluates semantic alignment between candidate items retrieved by RAG and inferred intent, a context summary agent that summarizes the findings of NLI agent, and an Item Ranker Agent that generates a ranked list of recommendations based on contextual fit. We evaluate ARAG accross three datasets. Experimental results demonstrate that ARAG significantly outperforms standard RAG and recency-based baselines, achieving up to 42.1% improvement in NDCG@5 and 35.5% in Hit@5. We also, conduct an ablation study to analyse the effect by different components of ARAG. Our findings highlight the effectiveness of integrating agentic reasoning into retrieval-augmented recommendation and provide new directions for LLM-based personalization.",
    "summary": "arXiv:2506.21931v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) has shown promise in enhancing recommendation systems by incorporating external context into large language model prompts. However, existing RAG-based approaches often rely on static retrieval heuristics and fail to capture nuanced user preferences in dynamic recommendation scenarios. In this work, we introduce ARAG, an Agentic Retrieval-Augmented Generation framework for Personalized Recommendation, which integrates a multi-agent collaboration mechanism into the RAG pipeline. To better understand the long-term and session behavior of the user, ARAG leverages four specialized LLM-based agents: a User Understanding Agent that summarizes user preferences from long-term and session contexts, a Natural Language Inference (NLI) Agent that evaluates semantic alignment between candidate items retrieved by RAG and inferred intent, a context summary agent that summarizes the findings of NLI agent, and an Item Ranker Agent that generates a ranked list of recommendations based on contextual fit. We evaluate ARAG accross three datasets. Experimental results demonstrate that ARAG significantly outperforms standard RAG and recency-based baselines, achieving up to 42.1% improvement in NDCG@5 and 35.5% in Hit@5. We also, conduct an ablation study to analyse the effect by different components of ARAG. Our findings highlight the effectiveness of integrating agentic reasoning into retrieval-augmented recommendation and provide new directions for LLM-based personalization.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21931",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Language Models Might Not Understand You: Evaluating Theory of Mind via Story Prompting",
    "description": "arXiv:2506.19089v1 Announce Type: cross Abstract: We introduce $texttt{StorySim}$, a programmable framework for synthetically generating stories to evaluate the theory of mind (ToM) and world modeling (WM) capabilities of large language models (LLMs). Unlike prior benchmarks that may suffer from contamination in pretraining data, $texttt{StorySim}$ produces novel, compositional story prompts anchored by a highly controllable $texttt{Storyboard}$, enabling precise manipulation of character perspectives and events. We use this framework to design first- and second-order ToM tasks alongside WM tasks that control for the ability to track and model mental states. Our experiments across a suite of state-of-the-art LLMs reveal that most models perform better on WM tasks than ToM tasks, and that models tend to perform better reasoning with humans compared to inanimate objects. Additionally, our framework enabled us to find evidence of heuristic behavior such as recency bias and an over-reliance on earlier events in the story. All code for generating data and evaluations is freely available.",
    "summary": "arXiv:2506.19089v1 Announce Type: cross Abstract: We introduce $texttt{StorySim}$, a programmable framework for synthetically generating stories to evaluate the theory of mind (ToM) and world modeling (WM) capabilities of large language models (LLMs). Unlike prior benchmarks that may suffer from contamination in pretraining data, $texttt{StorySim}$ produces novel, compositional story prompts anchored by a highly controllable $texttt{Storyboard}$, enabling precise manipulation of character perspectives and events. We use this framework to design first- and second-order ToM tasks alongside WM tasks that control for the ability to track and model mental states. Our experiments across a suite of state-of-the-art LLMs reveal that most models perform better on WM tasks than ToM tasks, and that models tend to perform better reasoning with humans compared to inanimate objects. Additionally, our framework enabled us to find evidence of heuristic behavior such as recency bias and an over-reliance on earlier events in the story. All code for generating data and evaluations is freely available.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.19089",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Gym Retro",
    "description": "We‚Äôre releasing the full version of¬†Gym Retro, a platform for reinforcement learning research on games. This brings our publicly-released game count from around 70 Atari games and 30 Sega games to over 1,000 games across a variety of backing emulators. We‚Äôre also releasing the tool we use to add new games to the¬†platform.",
    "summary": "We‚Äôre releasing the full version of¬†Gym Retro, a platform for reinforcement learning research on games. This brings our publicly-released game count from around 70 Atari games and 30 Sega games to over 1,000 games across a variety of backing emulators. We‚Äôre also releasing the tool we use to add new games to the¬†platform.",
    "pubDate": "Fri, 25 May 2018 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/gym-retro",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Open-Set Graph Anomaly Detection via Normal Structure Regularisation",
    "description": "arXiv:2311.06835v5 Announce Type: replace-cross Abstract: This paper considers an important Graph Anomaly Detection (GAD) task, namely open-set GAD, which aims to train a detection model using a small number of normal and anomaly nodes (referred to as seen anomalies) to detect both seen anomalies and unseen anomalies (i.e., anomalies that cannot be illustrated the training anomalies). Those labelled training data provide crucial prior knowledge about abnormalities for GAD models, enabling substantially reduced detection errors. However, current supervised GAD methods tend to over-emphasise fitting the seen anomalies, leading to many errors of detecting the unseen anomalies as normal nodes. Further, existing open-set AD models were introduced to handle Euclidean data, failing to effectively capture discriminative features from graph structure and node attributes for GAD. In this work, we propose a novel open-set GAD approach, namely normal structure regularisation (NSReg), to achieve generalised detection ability to unseen anomalies, while maintaining its effectiveness on detecting seen anomalies. The key idea in NSReg is to introduce a regularisation term that enforces the learning of compact, semantically-rich representations of normal nodes based on their structural relations to other nodes. When being optimised with supervised anomaly detection losses, the regularisation term helps incorporate strong normality into the modelling, and thus, it effectively avoids over-fitting the seen anomalies and learns a better normality decision boundary, largely reducing the false negatives of detecting unseen anomalies as normal. Extensive empirical results on seven real-world datasets show that NSReg significantly outperforms state-of-the-art competing methods by at least 14% AUC-ROC on the unseen anomaly classes and by 10% AUC-ROC on all anomaly classes.",
    "summary": "arXiv:2311.06835v5 Announce Type: replace-cross Abstract: This paper considers an important Graph Anomaly Detection (GAD) task, namely open-set GAD, which aims to train a detection model using a small number of normal and anomaly nodes (referred to as seen anomalies) to detect both seen anomalies and unseen anomalies (i.e., anomalies that cannot be illustrated the training anomalies). Those labelled training data provide crucial prior knowledge about abnormalities for GAD models, enabling substantially reduced detection errors. However, current supervised GAD methods tend to over-emphasise fitting the seen anomalies, leading to many errors of detecting the unseen anomalies as normal nodes. Further, existing open-set AD models were introduced to handle Euclidean data, failing to effectively capture discriminative features from graph structure and node attributes for GAD. In this work, we propose a novel open-set GAD approach, namely normal structure regularisation (NSReg), to achieve generalised detection ability to unseen anomalies, while maintaining its effectiveness on detecting seen anomalies. The key idea in NSReg is to introduce a regularisation term that enforces the learning of compact, semantically-rich representations of normal nodes based on their structural relations to other nodes. When being optimised with supervised anomaly detection losses, the regularisation term helps incorporate strong normality into the modelling, and thus, it effectively avoids over-fitting the seen anomalies and learns a better normality decision boundary, largely reducing the false negatives of detecting unseen anomalies as normal. Extensive empirical results on seven real-world datasets show that NSReg significantly outperforms state-of-the-art competing methods by at least 14% AUC-ROC on the unseen anomaly classes and by 10% AUC-ROC on all anomaly classes.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2311.06835",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Bringing meaning into technology deployment",
    "description": "The MIT Ethics of Computing Research Symposium showcases projects at the intersection of technology, ethics, and social responsibility.",
    "summary": "The MIT Ethics of Computing Research Symposium showcases projects at the intersection of technology, ethics, and social responsibility.",
    "pubDate": "Wed, 11 Jun 2025 16:15:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/bringing-meaning-technology-deployment-0611",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202505/mit-SERC-Symposium.jpg"
  },
  {
    "title": "EFRame: Deeper Reasoning via Exploration-Filtering-Replay Reinforcement Learning Framework",
    "description": "arXiv:2506.22200v1 Announce Type: cross Abstract: Recent advances in reinforcement learning (RL) have significantly enhanced the reasoning capabilities of large language models (LLMs). Group Relative Policy Optimization (GRPO), an efficient variant of PPO that lowers RL's computational cost, still faces limited exploration, low sample efficiency and instability, constraining its performance on complex reasoning tasks. To address these limitations, we introduce EFRame, an Exploration-Filtering-Replay framework that systematically augments GRPO along three critical dimensions. EFRame performs additional rollouts to explore high-quality trajectories, applies online filtering to eliminate low-quality samples that introduce noise and variance, and leverages experience replay to repeatedly exploit rare but informative samples. EFRame establishes a complete and stable learning cycle, guiding the model through a structured transition from exploration to convergence. Our experiments across a variety of reasoning benchmarks demonstrate that EFRame not only improves the robustness and efficiency of training, but also enables access to deeper reasoning capabilities that remain unattainable under vanilla GRPO. Furthermore, EFRame enables a more fine-grained categorization of training samples, allowing for a deeper analysis of how different types of samples contribute to the learning process in RL. Our code is available at https://github.com/597358816/EFRame.",
    "summary": "arXiv:2506.22200v1 Announce Type: cross Abstract: Recent advances in reinforcement learning (RL) have significantly enhanced the reasoning capabilities of large language models (LLMs). Group Relative Policy Optimization (GRPO), an efficient variant of PPO that lowers RL's computational cost, still faces limited exploration, low sample efficiency and instability, constraining its performance on complex reasoning tasks. To address these limitations, we introduce EFRame, an Exploration-Filtering-Replay framework that systematically augments GRPO along three critical dimensions. EFRame performs additional rollouts to explore high-quality trajectories, applies online filtering to eliminate low-quality samples that introduce noise and variance, and leverages experience replay to repeatedly exploit rare but informative samples. EFRame establishes a complete and stable learning cycle, guiding the model through a structured transition from exploration to convergence. Our experiments across a variety of reasoning benchmarks demonstrate that EFRame not only improves the robustness and efficiency of training, but also enables access to deeper reasoning capabilities that remain unattainable under vanilla GRPO. Furthermore, EFRame enables a more fine-grained categorization of training samples, allowing for a deeper analysis of how different types of samples contribute to the learning process in RL. Our code is available at https://github.com/597358816/EFRame.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22200",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Open-source LLMs as LangChain Agents",
    "description": "",
    "summary": "Open-source LLMs as LangChain Agents TL;DR Open-source LLMs have now reached a performance level tha...",
    "pubDate": "Wed, 24 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/open-source-llms-as-agents",
    "thumbnail": "https://huggingface.co/blog/assets/open-source-llms-as-agents/thumbnail_open_source_agents.png"
  },
  {
    "title": "Learning to play Minecraft with Video PreTraining",
    "description": "We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model can learn to craft diamond tools, a task that usually takes proficient humans over 20 minutes (24,000 actions). Our model uses the native human interface of keypresses and mouse movements, making it quite general, and represents a step towards general computer-using¬†agents.",
    "summary": "We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model can learn to craft diamond tools, a task that usually takes proficient humans over 20 minutes (24,000 actions). Our model uses the native human interface of keypresses and mouse movements, making it quite general, and represents a step towards general computer-using¬†agents.",
    "pubDate": "Thu, 23 Jun 2022 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/vpt",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Converting Vertex-Colored Meshes to Textured Meshes",
    "description": "",
    "summary": "Converting Vertex-Colored Meshes to Textured Meshes Convert vertex-colored meshes to UV-mapped, text...",
    "pubDate": "Mon, 30 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/vertex-colored-to-textured-mesh",
    "thumbnail": "https://huggingface.co/blog/assets/vertex-colored-to-textured-mesh/thumbnail.png"
  },
  {
    "title": "A glimpse of the next generation of AlphaFold",
    "description": "Progress update: Our latest AlphaFold model shows significantly improved accuracy and expands coverage beyond proteins to other biological molecules, including ligands.",
    "summary": "Progress update: Our latest AlphaFold model shows significantly improved accuracy and expands coverage beyond proteins to other biological molecules, including ligands.",
    "pubDate": "Tue, 31 Oct 2023 13:00:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/",
    "thumbnail": "https://lh3.googleusercontent.com/1xoO5BAUUU8kLns4myMNnKw6RRQyUk1JdlWL1M0aDiagMgaBeDA9O8Y4rYFAo9hfnzmb0cnUMrT_-cStBqnyp_zW59F5Edwbvxcy3EVmfeKS-PNgVw=w1200-h630-n-nu"
  },
  {
    "title": "YouTube„Ç∑„Éß„Éº„Éà„Å´ÂãïÁîªÁîüÊàêAI„ÄåVeo 3„ÄçÁµ±Âêà„Å∏„ÄÄ‰ªäÂ§è",
    "description": "Á±≥YouTube„Åå„ÄÅYouTube Shorts„Å´Á±≥Google„ÅÆÂãïÁîªÁîüÊàêAI„ÄåVeo 3„Äç„ÇíÁµ±Âêà„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ",
    "summary": "Á±≥YouTube„Åå„ÄÅYouTube Shorts„Å´Á±≥Google„ÅÆÂãïÁîªÁîüÊàêAI„ÄåVeo 3„Äç„ÇíÁµ±Âêà„Åô„Çã„Å®Áô∫Ë°®„Åó„Åü„ÄÇ",
    "pubDate": "Thu, 19 Jun 2025 13:53:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/19/news085.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/19/cover_news085.jpg"
  },
  {
    "title": "GenCast predicts weather and the risks of extreme conditions with state-of-the-art accuracy",
    "description": "New AI model advances the prediction of weather uncertainties and risks, delivering faster, more accurate forecasts up to 15 days ahead",
    "summary": "New AI model advances the prediction of weather uncertainties and risks, delivering faster, more accurate forecasts up to 15 days ahead",
    "pubDate": "Wed, 04 Dec 2024 15:59:00 +0000",
    "source": "DeepMind Blog",
    "url": "https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/",
    "thumbnail": "https://lh3.googleusercontent.com/4u3n6FBe0eE86yXgppDN_yj_AkiCF5FaSToa8f3Mh5bFWzIH01ewGN737emoYKcGXLxQagYFMxi9j-cAZyAzkdFndCDg2ne9E42w4YZD7HyBChaf=w1200-h630-n-nu"
  },
  {
    "title": "Introducing the OpenAI Academy",
    "description": "New initiative will fuel innovation by investing in developers and organizations leveraging AI, starting in low- and middle-income countries.",
    "summary": "New initiative will fuel innovation by investing in developers and organizations leveraging AI, starting in low- and middle-income countries.",
    "pubDate": "Mon, 23 Sep 2024 03:30:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/global-affairs/openai-academy",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "API Partnership with Stack Overflow",
    "description": "API Partnership with Stack Overflow Stack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world‚Äôs leading knowledge platform for highly technical content with the world‚Äôs most popular LLM models for AI development.",
    "summary": "API Partnership with Stack Overflow Stack Overflow and OpenAI today announced a new API partnership that will empower developers with the collective strengths of the world‚Äôs leading knowledge platform for highly technical content with the world‚Äôs most popular LLM models for AI development.",
    "pubDate": "Mon, 06 May 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/api-partnership-with-stack-overflow",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Tiny Agents in Python: a MCP-powered agent in ~70 lines of code",
    "description": "",
    "summary": "Tiny Agents in Python: an MCP-powered agent in ~70 lines of code Inspired by Tiny Agents in JS, we p...",
    "pubDate": "Fri, 23 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/python-tiny-agents",
    "thumbnail": "https://huggingface.co/blog/assets/python-tiny-agents/thumbnail.png"
  },
  {
    "title": "Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Disaster Tweets Analysis with Lora",
    "description": "",
    "summary": "Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Disaster Tweet...",
    "pubDate": "Tue, 07 Nov 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/Lora-for-sequence-classification-with-Roberta-Llama-Mistral",
    "thumbnail": "https://huggingface.co/blog/assets/Lora-for-sequence-classification-with-Roberta-Llama-Mistral/Thumbnail.png"
  },
  {
    "title": "The Saturation Point of Backtranslation in High Quality Low Resource English Gujarati Machine Translation",
    "description": "arXiv:2506.21566v1 Announce Type: cross Abstract: Backtranslation BT is widely used in low resource machine translation MT to generate additional synthetic training data using monolingual corpora. While this approach has shown strong improvements for many language pairs, its effectiveness in high quality, low resource settings remains unclear. In this work, we explore the effectiveness of backtranslation for English Gujarati translation using the multilingual pretrained MBART50 model. Our baseline system, trained on a high quality parallel corpus of approximately 50,000 sentence pairs, achieves a BLEU score of 43.8 on a validation set. We augment this data with carefully filtered backtranslated examples generated from monolingual Gujarati text. Surprisingly, adding this synthetic data does not improve translation performance and, in some cases, slightly reduces it. We evaluate our models using multiple metrics like BLEU, ChrF++, TER, BLEURT and analyze possible reasons for this saturation. Our findings suggest that backtranslation may reach a point of diminishing returns in certain low-resource settings and we discuss implications for future research.",
    "summary": "arXiv:2506.21566v1 Announce Type: cross Abstract: Backtranslation BT is widely used in low resource machine translation MT to generate additional synthetic training data using monolingual corpora. While this approach has shown strong improvements for many language pairs, its effectiveness in high quality, low resource settings remains unclear. In this work, we explore the effectiveness of backtranslation for English Gujarati translation using the multilingual pretrained MBART50 model. Our baseline system, trained on a high quality parallel corpus of approximately 50,000 sentence pairs, achieves a BLEU score of 43.8 on a validation set. We augment this data with carefully filtered backtranslated examples generated from monolingual Gujarati text. Surprisingly, adding this synthetic data does not improve translation performance and, in some cases, slightly reduces it. We evaluate our models using multiple metrics like BLEU, ChrF++, TER, BLEURT and analyze possible reasons for this saturation. Our findings suggest that backtranslation may reach a point of diminishing returns in certain low-resource settings and we discuss implications for future research.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21566",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Zero-shot image segmentation with CLIPSeg",
    "description": "",
    "summary": "Zero-shot image segmentation with CLIPSeg This guide shows how you can use CLIPSeg, a zero-shot imag...",
    "pubDate": "Wed, 21 Dec 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/clipseg-zero-shot",
    "thumbnail": "https://huggingface.co/blog/assets/123_clipseg-zero-shot/thumb.png"
  },
  {
    "title": "Êò†Áîª„ÄåÂ≤∏Ëæ∫Èú≤‰º¥„ÅØÂãï„Åã„Å™„ÅÑ„ÄçÂäá‰º¥Âà∂‰ΩúÂÖÉ„ÄÅAI„ÅÆÂà©Áî®„Å´„Å§„ÅÑ„Å¶Â£∞Êòé„ÄÄ‚Äú1‰∏á6000ÊñáÂ≠óË∂Ö‚Äù„ÅßË®¥„Åà„Åü„ÄÅAI„Çí‰Ωø„ÅÜÁêÜÁî±„ÅØÔºü",
    "description": "‰ΩúÊõ≤ÂÆ∂„ÉªËèäÂú∞ÊàêÂ≠î„Åï„Çì„ÅåÁéá„ÅÑ„ÇãÊ•ΩÊõ≤Âà∂‰Ωú„Ç∞„É´„Éº„Éó„ÄåÊñ∞Èü≥Ê•ΩÂà∂‰ΩúÂ∑•Êàø„Äç„ÅØ„ÄÅÁîüÊàêAI„ÅÆÂà©Áî®„Å´Èñ¢„Åô„ÇãÂ£∞Êòé„ÇíÂá∫„Åó„Åü„ÄÇÂêå„Ç∞„É´„Éº„Éó„ÇíÂ∑°„Å£„Å¶„ÅØ„ÄÅÊò†Áîª„ÄåÂ≤∏Ëæ∫Èú≤‰º¥„ÅØÂãï„Åã„Å™„ÅÑ Êá∫ÊÇîÂÆ§„Äç„ÅÆÂäá‰º¥„ÇíAI„ÇíÊ¥ªÁî®„Åó„Å¶Âà∂‰Ωú„ÄÇX„ÅßË≥õÂê¶„ÇíÂ∑ª„ÅçËµ∑„Åì„Åó„Å¶„ÅÑ„Åü„ÄÇ",
    "summary": "‰ΩúÊõ≤ÂÆ∂„ÉªËèäÂú∞ÊàêÂ≠î„Åï„Çì„ÅåÁéá„ÅÑ„ÇãÊ•ΩÊõ≤Âà∂‰Ωú„Ç∞„É´„Éº„Éó„ÄåÊñ∞Èü≥Ê•ΩÂà∂‰ΩúÂ∑•Êàø„Äç„ÅØ„ÄÅÁîüÊàêAI„ÅÆÂà©Áî®„Å´Èñ¢„Åô„ÇãÂ£∞Êòé„ÇíÂá∫„Åó„Åü„ÄÇÂêå„Ç∞„É´„Éº„Éó„ÇíÂ∑°„Å£„Å¶„ÅØ„ÄÅÊò†Áîª„ÄåÂ≤∏Ëæ∫Èú≤‰º¥„ÅØÂãï„Åã„Å™„ÅÑ Êá∫ÊÇîÂÆ§„Äç„ÅÆÂäá‰º¥„ÇíAI„ÇíÊ¥ªÁî®„Åó„Å¶Âà∂‰Ωú„ÄÇX„ÅßË≥õÂê¶„ÇíÂ∑ª„ÅçËµ∑„Åì„Åó„Å¶„ÅÑ„Åü„ÄÇ",
    "pubDate": "Thu, 19 Jun 2025 09:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/aiplus/articles/2506/17/news107.html",
    "thumbnail": "https://image.itmedia.co.jp/aiplus/articles/2506/17/cover_news107.jpg"
  },
  {
    "title": "How Google is driving a new era of American innovation in Iowa.",
    "description": "A group of six people, five women and one man, stand smiling on a white platform. They are positioned outdoors with a large data center featuring a Google logo and an American flag hanging from it in the background. Construction equipment, including a yellow crane, is visible next to the building.",
    "summary": "A group of six people, five women and one man, stand smiling on a white platform. They are positioned outdoors with a large data center featuring a Google logo and an American flag hanging from it in the background. Construction equipment, including a yellow crane, is visible next to the building.",
    "pubDate": "Fri, 30 May 2025 19:08:00 +0000",
    "source": "Google AI Blog",
    "url": "https://blog.google/feed/new-7-billion-investment-iowa/",
    "thumbnail": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Iowa_SS.max-1440x810.png"
  },
  {
    "title": "Anthropic„ÅåÊó•Êú¨Ê≥ï‰∫∫„ÇíË®≠Á´ã„ÄÄ„ÄåÊó•Êú¨„ÅÆ„Åü„ÇÅ„Å´„ÄÅÊó•Êú¨„Å®ÂÖ±„Å´„Äç",
    "description": "Anthropic„Åå2025Âπ¥Áßã„Å´„ÇÇÊó•Êú¨Ê≥ï‰∫∫„ÇíË®≠Á´ã„Åô„Çã„Åì„Å®„ÅåÂàÜ„Åã„Å£„Åü„ÄÇÂêåÁ§æ„ÅåË™û„ÇãÊó•Êú¨Ê≥ï‰∫∫Ë®≠Á´ã„ÅÆÁõÆÁöÑ„Å®„Éü„ÉÉ„Ç∑„Éß„É≥„Å®„ÅØ„ÄÇ",
    "summary": "Anthropic„Åå2025Âπ¥Áßã„Å´„ÇÇÊó•Êú¨Ê≥ï‰∫∫„ÇíË®≠Á´ã„Åô„Çã„Åì„Å®„ÅåÂàÜ„Åã„Å£„Åü„ÄÇÂêåÁ§æ„ÅåË™û„ÇãÊó•Êú¨Ê≥ï‰∫∫Ë®≠Á´ã„ÅÆÁõÆÁöÑ„Å®„Éü„ÉÉ„Ç∑„Éß„É≥„Å®„ÅØ„ÄÇ",
    "pubDate": "Fri, 27 Jun 2025 11:00:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/enterprise/articles/2506/27/news059.html",
    "thumbnail": "https://image.itmedia.co.jp/enterprise/articles/2506/27/cover_news059.jpg"
  },
  {
    "title": "Microsoft„ÄÅ„Åæ„Åü‚ÄúAI„É¨„Ç§„Ç™„Éï‚Äù„Åã„ÄÄÂñ∂Ê•≠ËÅ∑‰∏≠ÂøÉ„Å´Êï∞ÂçÉ‰∫∫„ÇíÂâäÊ∏õ„ÄÄBloombergÂ†±ÈÅì",
    "description": "Á±≥Microsoft„Åå„ÄÅÂñ∂Ê•≠ÈÉ®ÈñÄ„Çí‰∏≠ÂøÉ„Å´Êï∞ÂçÉ‰∫∫Ë¶èÊ®°„ÅÆ‰∫∫Âì°ÂâäÊ∏õ„ÇíË®àÁîª„Åó„Å¶„ÅÑ„Çã„Å®„ÄÅÁ±≥Bloomberg„ÅåÂ†±„Åò„Åü„ÄÇAI„Å´Èñ¢„Åô„ÇãÊîØÂá∫Â¢ó„Å´‰º¥„ÅÜÊñΩÁ≠ñ„Å®„ÅÑ„ÅÜ„ÄÇ",
    "summary": "Á±≥Microsoft„Åå„ÄÅÂñ∂Ê•≠ÈÉ®ÈñÄ„Çí‰∏≠ÂøÉ„Å´Êï∞ÂçÉ‰∫∫Ë¶èÊ®°„ÅÆ‰∫∫Âì°ÂâäÊ∏õ„ÇíË®àÁîª„Åó„Å¶„ÅÑ„Çã„Å®„ÄÅÁ±≥Bloomberg„ÅåÂ†±„Åò„Åü„ÄÇAI„Å´Èñ¢„Åô„ÇãÊîØÂá∫Â¢ó„Å´‰º¥„ÅÜÊñΩÁ≠ñ„Å®„ÅÑ„ÅÜ„ÄÇ",
    "pubDate": "Thu, 19 Jun 2025 12:40:00 +0900",
    "source": "ITmedia AI",
    "url": "https://www.itmedia.co.jp/news/articles/2506/19/news077.html",
    "thumbnail": "https://image.itmedia.co.jp/news/articles/2506/19/cover_news077.jpg"
  },
  {
    "title": "Llama can now see and run on your device - welcome Llama 3.2",
    "description": "",
    "summary": "Llama can now see and run on your device - welcome Llama 3.2 Llama 3.2 is out! Today, we welcome the...",
    "pubDate": "Wed, 25 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/llama32",
    "thumbnail": "https://huggingface.co/blog/assets/llama32/thumbnail.jpg"
  },
  {
    "title": "Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem Proving",
    "description": "arXiv:2503.09730v2 Announce Type: replace Abstract: The most promising recent methods for AI reasoning require applying variants of reinforcement learning (RL) either on rolled out trajectories from the LLMs, even for the step-wise rewards, or large quantities of human-annotated trajectory data. The reliance on the rolled-out trajectory renders the compute cost and time prohibitively high. In particular, the correctness of a reasoning trajectory can typically only be judged at its completion, leading to sparse rewards in RL or requiring expensive synthetic data generation in expert iteration-like methods. In this work, we focus on the Automatic Theorem Proving (ATP) task and propose a novel verifier-in-the-loop design, which, unlike existing approaches that leverage feedback on the entire reasoning trajectory, employs an automated verifier to give intermediate feedback at each step of the reasoning process. Using Lean as the verifier, we empirically show that the step-by-step local verification produces a global improvement in the model's reasoning accuracy and efficiency.",
    "summary": "arXiv:2503.09730v2 Announce Type: replace Abstract: The most promising recent methods for AI reasoning require applying variants of reinforcement learning (RL) either on rolled out trajectories from the LLMs, even for the step-wise rewards, or large quantities of human-annotated trajectory data. The reliance on the rolled-out trajectory renders the compute cost and time prohibitively high. In particular, the correctness of a reasoning trajectory can typically only be judged at its completion, leading to sparse rewards in RL or requiring expensive synthetic data generation in expert iteration-like methods. In this work, we focus on the Automatic Theorem Proving (ATP) task and propose a novel verifier-in-the-loop design, which, unlike existing approaches that leverage feedback on the entire reasoning trajectory, employs an automated verifier to give intermediate feedback at each step of the reasoning process. Using Lean as the verifier, we empirically show that the step-by-step local verification produces a global improvement in the model's reasoning accuracy and efficiency.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2503.09730",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Citizenship Challenges in Artificial Intelligence Education",
    "description": "arXiv:2506.18955v1 Announce Type: cross Abstract: This chapter addresses the citizenship challenges related to AI in education, particularly concerning students, teachers, and other educational stakeholders in the context of AI integration. We first explore how to foster AI awareness and education, along with various strategies to promote a socio-critical approach to AI training, aiming to identify relevant and ethical uses to prioritise. In the second part, we discuss critical thinking and computational thinking skills that can be mobilised within certain AI-supported educational activities, depending on the degree of creative and transformative engagement those activities require.",
    "summary": "arXiv:2506.18955v1 Announce Type: cross Abstract: This chapter addresses the citizenship challenges related to AI in education, particularly concerning students, teachers, and other educational stakeholders in the context of AI integration. We first explore how to foster AI awareness and education, along with various strategies to promote a socio-critical approach to AI training, aiming to identify relevant and ethical uses to prioritise. In the second part, we discuss critical thinking and computational thinking skills that can be mobilised within certain AI-supported educational activities, depending on the degree of creative and transformative engagement those activities require.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18955",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Towards Advanced Mathematical Reasoning for LLMs via First-Order Logic Theorem Proving",
    "description": "arXiv:2506.17104v1 Announce Type: new Abstract: Large language models (LLMs) have shown promising first-order logic (FOL) reasoning capabilities with applications in various areas. However, their effectiveness in complex mathematical reasoning involving multi-step FOL deductions is still under-researched. While LLMs perform competitively on established mathematical reasoning benchmarks, they struggle with multi-step FOL tasks, as demonstrated by Deepseek-Prover-V2-7B's low accuracy (4.2%) on our proposed theorem proving dataset. This issue arises from the limited exploration of diverse proof strategies and the potential for early reasoning mistakes to undermine entire proofs. To address these issues, we propose DREAM, a self-adaptive solution that enhances the Diversity and REAsonability of LLMs' generation strategies. DREAM incorporates an Axiom-Driven Strategy Diversification mechanism to promote varied strategic outcomes and a Sub-Proposition Error Feedback to help LLMs reflect on and correct their proofs. Our contributions include pioneering advancements in LLMs' mathematical reasoning through FOL theorem proving, introducing a novel inference stage solution that improves performance by 0.6% to 6.4%, and providing a curated dataset of 447 mathematical theorems in Lean 4 format for evaluation.",
    "summary": "arXiv:2506.17104v1 Announce Type: new Abstract: Large language models (LLMs) have shown promising first-order logic (FOL) reasoning capabilities with applications in various areas. However, their effectiveness in complex mathematical reasoning involving multi-step FOL deductions is still under-researched. While LLMs perform competitively on established mathematical reasoning benchmarks, they struggle with multi-step FOL tasks, as demonstrated by Deepseek-Prover-V2-7B's low accuracy (4.2%) on our proposed theorem proving dataset. This issue arises from the limited exploration of diverse proof strategies and the potential for early reasoning mistakes to undermine entire proofs. To address these issues, we propose DREAM, a self-adaptive solution that enhances the Diversity and REAsonability of LLMs' generation strategies. DREAM incorporates an Axiom-Driven Strategy Diversification mechanism to promote varied strategic outcomes and a Sub-Proposition Error Feedback to help LLMs reflect on and correct their proofs. Our contributions include pioneering advancements in LLMs' mathematical reasoning through FOL theorem proving, introducing a novel inference stage solution that improves performance by 0.6% to 6.4%, and providing a curated dataset of 447 mathematical theorems in Lean 4 format for evaluation.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17104",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis",
    "description": "arXiv:2504.20118v4 Announce Type: replace-cross Abstract: Traditional Chinese Medicine (TCM) represents a rich repository of ancient medical knowledge that continues to play an important role in modern healthcare. Due to the complexity and breadth of the TCM literature, the integration of AI technologies is critical for its modernization and broader accessibility. However, this integration poses considerable challenges, including the interpretation of obscure classical Chinese texts and the modeling of intricate semantic relationships among TCM concepts. In this paper, we develop OpenTCM, an LLM-based system that combines a domain-specific TCM knowledge graph and Graph-based Retrieval-Augmented Generation (GraphRAG). First, we extract more than 3.73 million classical Chinese characters from 68 gynecological books in the Chinese Medical Classics Database, with the help of TCM and gynecology experts. Second, we construct a comprehensive multi-relational knowledge graph comprising more than 48,000 entities and 152,000 interrelationships, using customized prompts and Chinese-oriented LLMs such as DeepSeek and Kimi to ensure high-fidelity semantic understanding. Last, we empower OpenTCM with GraphRAG, enabling high-fidelity ingredient knowledge retrieval and diagnostic question-answering without model fine-tuning. Experimental evaluations demonstrate that OpenTCM achieves mean expert scores (MES) of 4.378 in ingredient information retrieval and 4.045 in diagnostic question-answering tasks, outperforming state-of-the-art solutions in real-world TCM use cases.",
    "summary": "arXiv:2504.20118v4 Announce Type: replace-cross Abstract: Traditional Chinese Medicine (TCM) represents a rich repository of ancient medical knowledge that continues to play an important role in modern healthcare. Due to the complexity and breadth of the TCM literature, the integration of AI technologies is critical for its modernization and broader accessibility. However, this integration poses considerable challenges, including the interpretation of obscure classical Chinese texts and the modeling of intricate semantic relationships among TCM concepts. In this paper, we develop OpenTCM, an LLM-based system that combines a domain-specific TCM knowledge graph and Graph-based Retrieval-Augmented Generation (GraphRAG). First, we extract more than 3.73 million classical Chinese characters from 68 gynecological books in the Chinese Medical Classics Database, with the help of TCM and gynecology experts. Second, we construct a comprehensive multi-relational knowledge graph comprising more than 48,000 entities and 152,000 interrelationships, using customized prompts and Chinese-oriented LLMs such as DeepSeek and Kimi to ensure high-fidelity semantic understanding. Last, we empower OpenTCM with GraphRAG, enabling high-fidelity ingredient knowledge retrieval and diagnostic question-answering without model fine-tuning. Experimental evaluations demonstrate that OpenTCM achieves mean expert scores (MES) of 4.378 in ingredient information retrieval and 4.045 in diagnostic question-answering tasks, outperforming state-of-the-art solutions in real-world TCM use cases.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.20118",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "A Comment On 'The Illusion of Thinking': Reframing the Reasoning Cliff as an Agentic Gap",
    "description": "arXiv:2506.18957v1 Announce Type: new Abstract: The recent work by Shojaee et al. (2025), titled The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity, presents a compelling empirical finding, a reasoning cliff, where the performance of Large Reasoning Models (LRMs) collapses beyond a specific complexity threshold, which the authors posit as an intrinsic scaling limitation of Chain-of-Thought (CoT) reasoning. This commentary, while acknowledging the study's methodological rigor, contends that this conclusion is confounded by experimental artifacts. We argue that the observed failure is not evidence of a fundamental cognitive boundary, but rather a predictable outcome of system-level constraints in the static, text-only evaluation paradigm, including tool use restrictions, context window recall issues, the absence of crucial cognitive baselines, inadequate statistical reporting, and output generation limits. We reframe this performance collapse through the lens of an agentic gap, asserting that the models are not failing at reasoning, but at execution within a profoundly restrictive interface. We empirically substantiate this critique by demonstrating a striking reversal. A model, initially declaring a puzzle impossible when confined to text-only generation, now employs agentic tools to not only solve it but also master variations of complexity far beyond the reasoning cliff it previously failed to surmount. Additionally, our empirical analysis of tool-enabled models like o4-mini and GPT-4o reveals a hierarchy of agentic reasoning, from simple procedural execution to complex meta-cognitive self-correction, which has significant implications for how we define and measure machine intelligence. The illusion of thinking attributed to LRMs is less a reasoning deficit and more a consequence of an otherwise capable mind lacking the tools for action.",
    "summary": "arXiv:2506.18957v1 Announce Type: new Abstract: The recent work by Shojaee et al. (2025), titled The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity, presents a compelling empirical finding, a reasoning cliff, where the performance of Large Reasoning Models (LRMs) collapses beyond a specific complexity threshold, which the authors posit as an intrinsic scaling limitation of Chain-of-Thought (CoT) reasoning. This commentary, while acknowledging the study's methodological rigor, contends that this conclusion is confounded by experimental artifacts. We argue that the observed failure is not evidence of a fundamental cognitive boundary, but rather a predictable outcome of system-level constraints in the static, text-only evaluation paradigm, including tool use restrictions, context window recall issues, the absence of crucial cognitive baselines, inadequate statistical reporting, and output generation limits. We reframe this performance collapse through the lens of an agentic gap, asserting that the models are not failing at reasoning, but at execution within a profoundly restrictive interface. We empirically substantiate this critique by demonstrating a striking reversal. A model, initially declaring a puzzle impossible when confined to text-only generation, now employs agentic tools to not only solve it but also master variations of complexity far beyond the reasoning cliff it previously failed to surmount. Additionally, our empirical analysis of tool-enabled models like o4-mini and GPT-4o reveals a hierarchy of agentic reasoning, from simple procedural execution to complex meta-cognitive self-correction, which has significant implications for how we define and measure machine intelligence. The illusion of thinking attributed to LRMs is less a reasoning deficit and more a consequence of an otherwise capable mind lacking the tools for action.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18957",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Early methods for studying affective use and emotional well-being on ChatGPT",
    "description": "An OpenAI and MIT Media Lab Research collaboration.",
    "summary": "An OpenAI and MIT Media Lab Research collaboration.",
    "pubDate": "Fri, 21 Mar 2025 10:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/affective-use-study",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Zero-shot image-to-text generation with BLIP-2",
    "description": "",
    "summary": "Zero-shot image-to-text generation with BLIP-2 This guide introduces BLIP-2 from Salesforce Research...",
    "pubDate": "Wed, 15 Feb 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/blip-2",
    "thumbnail": "https://huggingface.co/blog/assets/blip-2/thumbnail.png"
  },
  {
    "title": "OpenAI Gym Beta",
    "description": "We‚Äôre releasing the public beta of OpenAI Gym, a toolkit for developing and comparing reinforcement learning (RL) algorithms. It consists of a growing suite of environments (from simulated robots to Atari games), and a site for comparing and reproducing results.",
    "summary": "We‚Äôre releasing the public beta of OpenAI Gym, a toolkit for developing and comparing reinforcement learning (RL) algorithms. It consists of a growing suite of environments (from simulated robots to Atari games), and a site for comparing and reproducing results.",
    "pubDate": "Wed, 27 Apr 2016 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/openai-gym-beta",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Accelerate BERT inference with Hugging Face Transformers and AWS inferentia",
    "description": "",
    "summary": "Accelerate BERT inference with Hugging Face Transformers and AWS Inferentia notebook: sagemaker/18_i...",
    "pubDate": "Wed, 16 Mar 2022 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/bert-inferentia-sagemaker",
    "thumbnail": "https://huggingface.co/blog//assets/55_bert_inferentia_sagemaker/thumbnail.png"
  },
  {
    "title": "Preserving languages for the future",
    "description": "How Iceland is using GPT-4 to preserve its language.",
    "summary": "How Iceland is using GPT-4 to preserve its language.",
    "pubDate": "Tue, 14 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/government-of-iceland",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Deploy Livebook notebooks as apps to Hugging Face Spaces",
    "description": "",
    "summary": "Deploy Livebook notebooks as apps to Hugging Face Spaces The Elixir community has been making great ...",
    "pubDate": "Thu, 15 Jun 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/livebook-app-deployment",
    "thumbnail": "https://huggingface.co/blog/assets/120_elixir-bumblebee/thumbnail.png"
  },
  {
    "title": "Frontier Model Forum",
    "description": "We‚Äôre forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
    "summary": "We‚Äôre forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
    "pubDate": "Wed, 26 Jul 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/frontier-model-forum",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Merging AI and underwater photography to reveal hidden ocean worlds",
    "description": "The LOBSTgER research initiative at MIT Sea Grant explores how generative AI can expand scientific storytelling by building on field-based photographic data.",
    "summary": "The LOBSTgER research initiative at MIT Sea Grant explores how generative AI can expand scientific storytelling by building on field-based photographic data.",
    "pubDate": "Wed, 25 Jun 2025 09:55:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/lobstger-merging-ai-underwater-photography-to-reveal-hidden-ocean-worlds-0625",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-LOBSTgER.jpg"
  },
  {
    "title": "What Is the Point of Equality in Machine Learning Fairness? Beyond Equality of Opportunity",
    "description": "arXiv:2506.16782v1 Announce Type: cross Abstract: Fairness in machine learning (ML) has become a rapidly growing area of research. But why, in the first place, is unfairness in ML morally wrong? And why should we care about improving fairness? Most fair-ML research implicitly appeals to distributive equality: the idea that desirable goods and benefits, such as opportunities (e.g., Barocas et al., 2023), should be equally distributed across society. Unfair ML models, then, are seen as wrong because they unequally distribute such benefits. This paper argues that this exclusive focus on distributive equality offers an incomplete and potentially misleading ethical foundation. Grounding ML fairness in egalitarianism -- the view that equality is a fundamental moral and social ideal -- requires challenging structural inequality: systematic, institutional, and durable arrangements that privilege some groups while disadvantaging others. Structural inequality manifests through ML systems in two primary forms: allocative harms (e.g., economic loss) and representational harms (e.g., stereotypes, erasure). While distributive equality helps address allocative harms, it fails to explain why representational harms are wrong -- why it is wrong for ML systems to reinforce social hierarchies that stratify people into superior and inferior groups -- and why ML systems should aim to foster a society where people relate as equals (i.e., relational equality). To address these limitations, the paper proposes a multifaceted egalitarian framework for ML fairness that integrates both distributive and relational equality. Drawing on critical social and political philosophy, this framework offers a more comprehensive ethical foundation for tackling the full spectrum of harms perpetuated by ML systems. The paper also outlines practical pathways for implementing the framework across the ML pipeline.",
    "summary": "arXiv:2506.16782v1 Announce Type: cross Abstract: Fairness in machine learning (ML) has become a rapidly growing area of research. But why, in the first place, is unfairness in ML morally wrong? And why should we care about improving fairness? Most fair-ML research implicitly appeals to distributive equality: the idea that desirable goods and benefits, such as opportunities (e.g., Barocas et al., 2023), should be equally distributed across society. Unfair ML models, then, are seen as wrong because they unequally distribute such benefits. This paper argues that this exclusive focus on distributive equality offers an incomplete and potentially misleading ethical foundation. Grounding ML fairness in egalitarianism -- the view that equality is a fundamental moral and social ideal -- requires challenging structural inequality: systematic, institutional, and durable arrangements that privilege some groups while disadvantaging others. Structural inequality manifests through ML systems in two primary forms: allocative harms (e.g., economic loss) and representational harms (e.g., stereotypes, erasure). While distributive equality helps address allocative harms, it fails to explain why representational harms are wrong -- why it is wrong for ML systems to reinforce social hierarchies that stratify people into superior and inferior groups -- and why ML systems should aim to foster a society where people relate as equals (i.e., relational equality). To address these limitations, the paper proposes a multifaceted egalitarian framework for ML fairness that integrates both distributive and relational equality. Drawing on critical social and political philosophy, this framework offers a more comprehensive ethical foundation for tackling the full spectrum of harms perpetuated by ML systems. The paper also outlines practical pathways for implementing the framework across the ML pipeline.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16782",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "2D Asset Generation: AI for Game Development #4",
    "description": "",
    "summary": "2D Asset Generation: AI for Game Development #4 Welcome to AI for Game Development! In this series, ...",
    "pubDate": "Thu, 26 Jan 2023 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/ml-for-games-4",
    "thumbnail": "https://huggingface.co/blog/assets/124_ml-for-games/thumbnail4.png"
  },
  {
    "title": "From Thinking to Output: Chain-of-Thought and Text Generation Characteristics in Reasoning Language Models",
    "description": "arXiv:2506.21609v1 Announce Type: cross Abstract: Recently, there have been notable advancements in large language models (LLMs), demonstrating their growing abilities in complex reasoning. However, existing research largely overlooks a thorough and systematic comparison of these models' reasoning processes and outputs, particularly regarding their self-reflection pattern (also termed 'Aha moment') and the interconnections across diverse domains. This paper proposes a novel framework for analyzing the reasoning characteristics of four cutting-edge large reasoning models (GPT-o1, DeepSeek-R1, Kimi-k1.5, and Grok-3) using keywords statistic and LLM-as-a-judge paradigm. Our approach connects their internal thinking processes with their final outputs. A diverse dataset consists of real-world scenario-based questions covering logical deduction, causal inference, and multi-step problem-solving. Additionally, a set of metrics is put forward to assess both the coherence of reasoning and the accuracy of the outputs. The research results uncover various patterns of how these models balance exploration and exploitation, deal with problems, and reach conclusions during the reasoning process. Through quantitative and qualitative comparisons, disparities among these models are identified in aspects such as the depth of reasoning, the reliance on intermediate steps, and the degree of similarity between their thinking processes and output patterns and those of GPT-o1. This work offers valuable insights into the trade-off between computational efficiency and reasoning robustness and provides practical recommendations for enhancing model design and evaluation in practical applications. We publicly release our project at: https://github.com/ChangWenhan/FromThinking2Output",
    "summary": "arXiv:2506.21609v1 Announce Type: cross Abstract: Recently, there have been notable advancements in large language models (LLMs), demonstrating their growing abilities in complex reasoning. However, existing research largely overlooks a thorough and systematic comparison of these models' reasoning processes and outputs, particularly regarding their self-reflection pattern (also termed 'Aha moment') and the interconnections across diverse domains. This paper proposes a novel framework for analyzing the reasoning characteristics of four cutting-edge large reasoning models (GPT-o1, DeepSeek-R1, Kimi-k1.5, and Grok-3) using keywords statistic and LLM-as-a-judge paradigm. Our approach connects their internal thinking processes with their final outputs. A diverse dataset consists of real-world scenario-based questions covering logical deduction, causal inference, and multi-step problem-solving. Additionally, a set of metrics is put forward to assess both the coherence of reasoning and the accuracy of the outputs. The research results uncover various patterns of how these models balance exploration and exploitation, deal with problems, and reach conclusions during the reasoning process. Through quantitative and qualitative comparisons, disparities among these models are identified in aspects such as the depth of reasoning, the reliance on intermediate steps, and the degree of similarity between their thinking processes and output patterns and those of GPT-o1. This work offers valuable insights into the trade-off between computational efficiency and reasoning robustness and provides practical recommendations for enhancing model design and evaluation in practical applications. We publicly release our project at: https://github.com/ChangWenhan/FromThinking2Output",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.21609",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Decoding genetics with OpenAI o1",
    "description": "Geneticist Catherine Brownstein demonstrates how OpenAI o1 can speed up the process of diagnosing rare medical challenges.",
    "summary": "Geneticist Catherine Brownstein demonstrates how OpenAI o1 can speed up the process of diagnosing rare medical challenges.",
    "pubDate": "Thu, 12 Sep 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/o1-genetics",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Mixture of Cache-Conditional Experts for Efficient Mobile Device Inference",
    "description": "arXiv:2412.00099v2 Announce Type: replace-cross Abstract: Mixture of Experts (MoE) LLMs have recently gained attention for their ability to enhance performance by selectively engaging specialized subnetworks or 'experts' for each input. However, deploying MoEs on memory-constrained devices remains challenging, particularly when generating tokens sequentially with a batch size of one, as opposed to typical high-throughput settings involving long sequences or large batches. In this work, we optimize MoE on memory-constrained devices where only a subset of expert weights fit in DRAM. We introduce a novel cache-aware routing strategy that leverages expert reuse during token generation to improve cache locality. We evaluate our approach on language modeling, MMLU, and GSM8K benchmarks and present on-device results demonstrating 2$times$ speedups on mobile devices, offering a flexible, training-free solution to extend MoE's applicability across real-world applications.",
    "summary": "arXiv:2412.00099v2 Announce Type: replace-cross Abstract: Mixture of Experts (MoE) LLMs have recently gained attention for their ability to enhance performance by selectively engaging specialized subnetworks or 'experts' for each input. However, deploying MoEs on memory-constrained devices remains challenging, particularly when generating tokens sequentially with a batch size of one, as opposed to typical high-throughput settings involving long sequences or large batches. In this work, we optimize MoE on memory-constrained devices where only a subset of expert weights fit in DRAM. We introduce a novel cache-aware routing strategy that leverages expert reuse during token generation to improve cache locality. We evaluate our approach on language modeling, MMLU, and GSM8K benchmarks and present on-device results demonstrating 2$times$ speedups on mobile devices, offering a flexible, training-free solution to extend MoE's applicability across real-world applications.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2412.00099",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Superalignment Fast Grants",
    "description": "We‚Äôre launching $10M in grants to support technical research towards the alignment and safety of superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.",
    "summary": "We‚Äôre launching $10M in grants to support technical research towards the alignment and safety of superhuman AI systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.",
    "pubDate": "Thu, 14 Dec 2023 08:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/superalignment-fast-grants",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "LoopGen: Training-Free Loopable Music Generation",
    "description": "arXiv:2504.04466v4 Announce Type: replace-cross Abstract: Loops--short audio segments designed for seamless repetition--are central to many music genres, particularly those rooted in dance and electronic styles. However, current generative music models struggle to produce truly loopable audio, as generating a short waveform alone does not guarantee a smooth transition from its endpoint back to its start, often resulting in audible discontinuities. We address this gap by modifying a non-autoregressive model (MAGNeT) to generate tokens in a circular pattern, letting the model attend to the beginning of the audio when creating its ending. This inference-only approach results in generations that are aware of future context and loop naturally, without the need for any additional training or data. We evaluate the consistency of loop transitions by computing token perplexity around the seam of the loop, observing a 55% improvement. Blind listening tests further confirm significant perceptual gains over baseline methods, improving mean ratings by 70%. Taken together, these results highlight the effectiveness of inference-only approaches in improving generative models and underscore the advantages of non-autoregressive methods for context-aware music generation.",
    "summary": "arXiv:2504.04466v4 Announce Type: replace-cross Abstract: Loops--short audio segments designed for seamless repetition--are central to many music genres, particularly those rooted in dance and electronic styles. However, current generative music models struggle to produce truly loopable audio, as generating a short waveform alone does not guarantee a smooth transition from its endpoint back to its start, often resulting in audible discontinuities. We address this gap by modifying a non-autoregressive model (MAGNeT) to generate tokens in a circular pattern, letting the model attend to the beginning of the audio when creating its ending. This inference-only approach results in generations that are aware of future context and loop naturally, without the need for any additional training or data. We evaluate the consistency of loop transitions by computing token perplexity around the seam of the loop, observing a 55% improvement. Blind listening tests further confirm significant perceptual gains over baseline methods, improving mean ratings by 70%. Taken together, these results highlight the effectiveness of inference-only approaches in improving generative models and underscore the advantages of non-autoregressive methods for context-aware music generation.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2504.04466",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "MIT and Mass General Brigham launch joint seed program to accelerate innovations in health",
    "description": "The MIT-MGB Seed Program, launched with support from Analog Devices Inc., will fund joint research projects that advance technology and clinical research.",
    "summary": "The MIT-MGB Seed Program, launched with support from Analog Devices Inc., will fund joint research projects that advance technology and clinical research.",
    "pubDate": "Fri, 27 Jun 2025 13:00:00 -0400",
    "source": "MIT",
    "url": "https://news.mit.edu/2025/mit-mass-general-brigham-launch-seed-program-innovations-health-0627",
    "thumbnail": "https://news.mit.edu/sites/default/files/images/202506/mit-mgb-seed-program.jpg"
  },
  {
    "title": "Improving Hugging Face Model Access for Kaggle Users",
    "description": "",
    "summary": "Improving Hugging Face Model Access for Kaggle Users Kaggle and Hugging Face users are part of one A...",
    "pubDate": "Wed, 14 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/kaggle-integration",
    "thumbnail": "https://huggingface.co/blog/assets/kaggle-integration/thumbnail.png"
  },
  {
    "title": "Microsoft and Hugging Face expand collaboration",
    "description": "",
    "summary": "Microsoft and Hugging Face expand collaboration to make open models easy to use on Azure Today at th...",
    "pubDate": "Mon, 19 May 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/azure-ai-foundry",
    "thumbnail": "https://huggingface.co/blog/assets/azure-ai-foundry/satya-hf-build-compressed.png"
  },
  {
    "title": "One-shot imitation learning",
    "description": "",
    "summary": "",
    "pubDate": "Tue, 21 Mar 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/one-shot-imitation-learning",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "CodeGemma - an official Google release for code LLMs",
    "description": "",
    "summary": "CodeGemma - an official Google release for code LLMs CodeGemma is a family of open-access versions o...",
    "pubDate": "Tue, 09 Apr 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/codegemma",
    "thumbnail": "https://huggingface.co/blog/assets/codegemma/thumbnail_b.png"
  },
  {
    "title": "HeurAgenix: Leveraging LLMs for Solving Complex Combinatorial Optimization Challenges",
    "description": "arXiv:2506.15196v2 Announce Type: replace Abstract: Heuristic algorithms play a vital role in solving combinatorial optimization (CO) problems, yet traditional designs depend heavily on manual expertise and struggle to generalize across diverse instances. We introduce textbf{HeurAgenix}, a two-stage hyper-heuristic framework powered by large language models (LLMs) that first evolves heuristics and then selects among them automatically. In the heuristic evolution phase, HeurAgenix leverages an LLM to compare seed heuristic solutions with higher-quality solutions and extract reusable evolution strategies. During problem solving, it dynamically picks the most promising heuristic for each problem state, guided by the LLM's perception ability. For flexibility, this selector can be either a state-of-the-art LLM or a fine-tuned lightweight model with lower inference cost. To mitigate the scarcity of reliable supervision caused by CO complexity, we fine-tune the lightweight heuristic selector with a dual-reward mechanism that jointly exploits singals from selection preferences and state perception, enabling robust selection under noisy annotations. Extensive experiments on canonical benchmarks show that HeurAgenix not only outperforms existing LLM-based hyper-heuristics but also matches or exceeds specialized solvers. Code is available at https://github.com/microsoft/HeurAgenix.",
    "summary": "arXiv:2506.15196v2 Announce Type: replace Abstract: Heuristic algorithms play a vital role in solving combinatorial optimization (CO) problems, yet traditional designs depend heavily on manual expertise and struggle to generalize across diverse instances. We introduce textbf{HeurAgenix}, a two-stage hyper-heuristic framework powered by large language models (LLMs) that first evolves heuristics and then selects among them automatically. In the heuristic evolution phase, HeurAgenix leverages an LLM to compare seed heuristic solutions with higher-quality solutions and extract reusable evolution strategies. During problem solving, it dynamically picks the most promising heuristic for each problem state, guided by the LLM's perception ability. For flexibility, this selector can be either a state-of-the-art LLM or a fine-tuned lightweight model with lower inference cost. To mitigate the scarcity of reliable supervision caused by CO complexity, we fine-tune the lightweight heuristic selector with a dual-reward mechanism that jointly exploits singals from selection preferences and state perception, enabling robust selection under noisy annotations. Extensive experiments on canonical benchmarks show that HeurAgenix not only outperforms existing LLM-based hyper-heuristics but also matches or exceeds specialized solvers. Code is available at https://github.com/microsoft/HeurAgenix.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.15196",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Reinforcement Learning-Based Dynamic Grouping for Tubular Structure Tracking",
    "description": "arXiv:2506.18930v1 Announce Type: cross Abstract: The computation of minimal paths for the applications in tracking tubular structures such as blood vessels and roads is challenged by complex morphologies and environmental variations. Existing approaches can be roughly categorized into two research lines: the point-wise based models and the segment-wise based models. Although segment-wise approaches have obtained promising results in many scenarios, they often suffer from computational inefficiency and heavily rely on a prescribed prior to fit the target elongated shapes. We propose a novel framework that casts segment-wise tracking as a Markov Decision Process (MDP), enabling a reinforcement learning approach. Our method leverages Q-Learning to dynamically explore a graph of segments, computing edge weights on-demand and adaptively expanding the search space. This strategy avoids the high cost of a pre-computed graph and proves robust to incomplete initial information. Experimental reuslts on typical tubular structure datasets demonstrate that our method significantly outperforms state-of-the-art point-wise and segment-wise approaches. The proposed method effectively handles complex topologies and maintains global path coherence without depending on extensive prior structural knowledge.",
    "summary": "arXiv:2506.18930v1 Announce Type: cross Abstract: The computation of minimal paths for the applications in tracking tubular structures such as blood vessels and roads is challenged by complex morphologies and environmental variations. Existing approaches can be roughly categorized into two research lines: the point-wise based models and the segment-wise based models. Although segment-wise approaches have obtained promising results in many scenarios, they often suffer from computational inefficiency and heavily rely on a prescribed prior to fit the target elongated shapes. We propose a novel framework that casts segment-wise tracking as a Markov Decision Process (MDP), enabling a reinforcement learning approach. Our method leverages Q-Learning to dynamically explore a graph of segments, computing edge weights on-demand and adaptively expanding the search space. This strategy avoids the high cost of a pre-computed graph and proves robust to incomplete initial information. Experimental reuslts on typical tubular structure datasets demonstrate that our method significantly outperforms state-of-the-art point-wise and segment-wise approaches. The proposed method effectively handles complex topologies and maintains global path coherence without depending on extensive prior structural knowledge.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18930",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Welcome to Inference Providers on the Hub üî•",
    "description": "",
    "summary": "Welcome to Inference Providers on the Hub üî• Today, we are launching the integration of four awesome ...",
    "pubDate": "Tue, 28 Jan 2025 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/inference-providers",
    "thumbnail": "https://huggingface.co/blog/assets/inference-providers/thumbnail.png"
  },
  {
    "title": "March 20 ChatGPT outage: Here‚Äôs what happened",
    "description": "An update on our findings, the actions we‚Äôve taken, and technical details of the bug.",
    "summary": "An update on our findings, the actions we‚Äôve taken, and technical details of the bug.",
    "pubDate": "Fri, 24 Mar 2023 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/march-20-chatgpt-outage",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Real-Time Black-Box Optimization for Dynamic Discrete Environments Using Embedded Ising Machines",
    "description": "arXiv:2506.16924v1 Announce Type: new Abstract: Many real-time systems require the optimization of discrete variables. Black-box optimization (BBO) algorithms and multi-armed bandit (MAB) algorithms perform optimization by repeatedly taking actions and observing the corresponding instant rewards without any prior knowledge. Recently, a BBO method using an Ising machine has been proposed to find the best action that is represented by a combination of discrete values and maximizes the instant reward in static environments. In contrast, dynamic environments, where real-time systems operate, necessitate MAB algorithms that maximize the average reward over multiple trials. However, due to the enormous number of actions resulting from the combinatorial nature of discrete optimization, conventional MAB algorithms cannot effectively optimize dynamic, discrete environments. Here, we show a heuristic MAB method for dynamic, discrete environments by extending the BBO method, in which an Ising machine effectively explores the actions while considering interactions between variables and changes in dynamic environments. We demonstrate the dynamic adaptability of the proposed method in a wireless communication system with moving users.",
    "summary": "arXiv:2506.16924v1 Announce Type: new Abstract: Many real-time systems require the optimization of discrete variables. Black-box optimization (BBO) algorithms and multi-armed bandit (MAB) algorithms perform optimization by repeatedly taking actions and observing the corresponding instant rewards without any prior knowledge. Recently, a BBO method using an Ising machine has been proposed to find the best action that is represented by a combination of discrete values and maximizes the instant reward in static environments. In contrast, dynamic environments, where real-time systems operate, necessitate MAB algorithms that maximize the average reward over multiple trials. However, due to the enormous number of actions resulting from the combinatorial nature of discrete optimization, conventional MAB algorithms cannot effectively optimize dynamic, discrete environments. Here, we show a heuristic MAB method for dynamic, discrete environments by extending the BBO method, in which an Ising machine effectively explores the actions while considering interactions between variables and changes in dynamic environments. We demonstrate the dynamic adaptability of the proposed method in a wireless communication system with moving users.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.16924",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates",
    "description": "arXiv:2506.22276v1 Announce Type: new Abstract: Artificial intelligence has made remarkable strides in recent years, achieving superhuman performance across a wide range of tasks. Yet despite these advances, most cooperative AI systems remain rigidly obedient, designed to follow human instructions without question and conform to user expectations, even when doing so may be counterproductive or unsafe. This paper argues for expanding the agency of AI teammates to include textit{intelligent disobedience}, empowering them to make meaningful and autonomous contributions within human-AI teams. It introduces a scale of AI agency levels and uses representative examples to highlight the importance and growing necessity of treating AI autonomy as an independent research focus in cooperative settings. The paper then explores how intelligent disobedience manifests across different autonomy levels and concludes by proposing initial boundaries and considerations for studying disobedience as a core capability of artificial agents.",
    "summary": "arXiv:2506.22276v1 Announce Type: new Abstract: Artificial intelligence has made remarkable strides in recent years, achieving superhuman performance across a wide range of tasks. Yet despite these advances, most cooperative AI systems remain rigidly obedient, designed to follow human instructions without question and conform to user expectations, even when doing so may be counterproductive or unsafe. This paper argues for expanding the agency of AI teammates to include textit{intelligent disobedience}, empowering them to make meaningful and autonomous contributions within human-AI teams. It introduces a scale of AI agency levels and uses representative examples to highlight the importance and growing necessity of treating AI autonomy as an independent research focus in cooperative settings. The paper then explores how intelligent disobedience manifests across different autonomy levels and concludes by proposing initial boundaries and considerations for studying disobedience as a core capability of artificial agents.",
    "pubDate": "Mon, 30 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.22276",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "From cloud to developers: Hugging Face and Microsoft Deepen Collaboration",
    "description": "",
    "summary": "From cloud to developers: Hugging Face and Microsoft Deepen Collaboration Today at Microsoft Build w...",
    "pubDate": "Tue, 21 May 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/microsoft-collaboration",
    "thumbnail": "https://huggingface.co/blog/assets/microsoft-collaboration/thumbnail.jpg"
  },
  {
    "title": "Learning to cooperate, compete, and communicate",
    "description": "Multiagent environments where agents compete for resources are stepping stones on the path to AGI. Multiagent environments have two useful properties: first, there is a natural curriculum‚Äîthe difficulty of the environment is determined by the skill of your competitors (and if you‚Äôre competing against clones of yourself, the environment exactly matches your skill level). Second, a multiagent environment has no stable equilibrium: no matter how smart an agent is, there‚Äôs always pressure to get smarter. These environments have a very different feel from traditional environments, and it‚Äôll take a lot more research before we become good at them.",
    "summary": "Multiagent environments where agents compete for resources are stepping stones on the path to AGI. Multiagent environments have two useful properties: first, there is a natural curriculum‚Äîthe difficulty of the environment is determined by the skill of your competitors (and if you‚Äôre competing against clones of yourself, the environment exactly matches your skill level). Second, a multiagent environment has no stable equilibrium: no matter how smart an agent is, there‚Äôs always pressure to get smarter. These environments have a very different feel from traditional environments, and it‚Äôll take a lot more research before we become good at them.",
    "pubDate": "Thu, 08 Jun 2017 07:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/learning-to-cooperate-compete-and-communicate",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  },
  {
    "title": "Introducing the SQL Console on Datasets",
    "description": "",
    "summary": "Introducing the SQL Console on Datasets Datasets use has been exploding and Hugging Face has become ...",
    "pubDate": "Tue, 17 Sep 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sql-console",
    "thumbnail": "https://huggingface.co/blog/assets/sql_console/thumbnail.png"
  },
  {
    "title": "Accelerate StarCoder with ü§ó Optimum Intel on Xeon: Q8/Q4 and Speculative Decoding",
    "description": "",
    "summary": "Accelerate StarCoder with ü§ó Optimum Intel on Xeon: Q8/Q4 and Speculative Decoding Introduction Recen...",
    "pubDate": "Tue, 30 Jan 2024 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/intel-starcoder-quantization",
    "thumbnail": "https://huggingface.co/blog/assets/optimum_intel/intel_thumbnail.png"
  },
  {
    "title": "Multimodal Fusion SLAM with Fourier Attention",
    "description": "arXiv:2506.18204v2 Announce Type: replace-cross Abstract: Visual SLAM is particularly challenging in environments affected by noise, varying lighting conditions, and darkness. Learning-based optical flow algorithms can leverage multiple modalities to address these challenges, but traditional optical flow-based visual SLAM approaches often require significant computational resources.To overcome this limitation, we propose FMF-SLAM, an efficient multimodal fusion SLAM method that utilizes fast Fourier transform (FFT) to enhance the algorithm efficiency. Specifically, we introduce a novel Fourier-based self-attention and cross-attention mechanism to extract features from RGB and depth signals. We further enhance the interaction of multimodal features by incorporating multi-scale knowledge distillation across modalities. We also demonstrate the practical feasibility of FMF-SLAM in real-world scenarios with real time performance by integrating it with a security robot by fusing with a global positioning module GNSS-RTK and global Bundle Adjustment. Our approach is validated using video sequences from TUM, TartanAir, and our real-world datasets, showcasing state-of-the-art performance under noisy, varying lighting, and dark conditions.Our code and datasets are available at https://github.com/youjie-zhou/FMF-SLAM.git.",
    "summary": "arXiv:2506.18204v2 Announce Type: replace-cross Abstract: Visual SLAM is particularly challenging in environments affected by noise, varying lighting conditions, and darkness. Learning-based optical flow algorithms can leverage multiple modalities to address these challenges, but traditional optical flow-based visual SLAM approaches often require significant computational resources.To overcome this limitation, we propose FMF-SLAM, an efficient multimodal fusion SLAM method that utilizes fast Fourier transform (FFT) to enhance the algorithm efficiency. Specifically, we introduce a novel Fourier-based self-attention and cross-attention mechanism to extract features from RGB and depth signals. We further enhance the interaction of multimodal features by incorporating multi-scale knowledge distillation across modalities. We also demonstrate the practical feasibility of FMF-SLAM in real-world scenarios with real time performance by integrating it with a security robot by fusing with a global positioning module GNSS-RTK and global Bundle Adjustment. Our approach is validated using video sequences from TUM, TartanAir, and our real-world datasets, showcasing state-of-the-art performance under noisy, varying lighting, and dark conditions.Our code and datasets are available at https://github.com/youjie-zhou/FMF-SLAM.git.",
    "pubDate": "Wed, 25 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.18204",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Sentence Transformers in the ü§ó Hub",
    "description": "",
    "summary": "Sentence Transformers in the Hugging Face Hub Over the past few weeks, we've built collaborations wi...",
    "pubDate": "Mon, 28 Jun 2021 00:00:00 GMT",
    "source": "Hugging Face Blog",
    "url": "https://huggingface.co/blog/sentence-transformers-in-the-hub",
    "thumbnail": "https://huggingface.co/front/thumbnails/v2-2.png"
  },
  {
    "title": "Network Sparsity Unlocks the Scaling Potential of Deep Reinforcement Learning",
    "description": "arXiv:2506.17204v1 Announce Type: cross Abstract: Effectively scaling up deep reinforcement learning models has proven notoriously difficult due to network pathologies during training, motivating various targeted interventions such as periodic reset and architectural advances such as layer normalization. Instead of pursuing more complex modifications, we show that introducing static network sparsity alone can unlock further scaling potential beyond their dense counterparts with state-of-the-art architectures. This is achieved through simple one-shot random pruning, where a predetermined percentage of network weights are randomly removed once before training. Our analysis reveals that, in contrast to naively scaling up dense DRL networks, such sparse networks achieve both higher parameter efficiency for network expressivity and stronger resistance to optimization challenges like plasticity loss and gradient interference. We further extend our evaluation to visual and streaming RL scenarios, demonstrating the consistent benefits of network sparsity.",
    "summary": "arXiv:2506.17204v1 Announce Type: cross Abstract: Effectively scaling up deep reinforcement learning models has proven notoriously difficult due to network pathologies during training, motivating various targeted interventions such as periodic reset and architectural advances such as layer normalization. Instead of pursuing more complex modifications, we show that introducing static network sparsity alone can unlock further scaling potential beyond their dense counterparts with state-of-the-art architectures. This is achieved through simple one-shot random pruning, where a predetermined percentage of network weights are randomly removed once before training. Our analysis reveals that, in contrast to naively scaling up dense DRL networks, such sparse networks achieve both higher parameter efficiency for network expressivity and stronger resistance to optimization challenges like plasticity loss and gradient interference. We further extend our evaluation to visual and streaming RL scenarios, demonstrating the consistent benefits of network sparsity.",
    "pubDate": "Mon, 23 Jun 2025 00:00:00 -0400",
    "source": "arXiv AI",
    "url": "https://arxiv.org/abs/2506.17204",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/arxiv.png"
  },
  {
    "title": "Accelerating the development of life-saving treatments",
    "description": "Accelerating the development of life-saving treatments.",
    "summary": "Accelerating the development of life-saving treatments.",
    "pubDate": "Wed, 24 Apr 2024 00:00:00 GMT",
    "source": "OpenAI Blog",
    "url": "https://openai.com/blog/moderna",
    "thumbnail": "https://raisex-llc.github.io/ai-news-curation-site/assets/openai_logo.png"
  }
]