#!/usr/bin/env python3
"""
feed_fetcher.py
RSS â†’ Markdown å¤‰æ› + ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒæŠ½å‡º
astro-site/src/content/posts/ ã« .md ã‚’è¿½åŠ ã™ã‚‹ã€‚
"""

import feedparser
import requests
import trafilatura
import yaml
import hashlib
import os
import sys
import re
from datetime import datetime
from pathlib import Path
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from dateutil import parser  # æŸ”è»Ÿãªæ—¥ä»˜å‡¦ç†ç”¨

ROOT = Path(__file__).resolve().parent
CONTENT_DIR = ROOT / "astro-site" / "src" / "content" / "posts"
CONTENT_DIR.mkdir(parents=True, exist_ok=True)

# âœ… RSS URLä¸€è¦§ã‚’èª­ã¿è¾¼ã‚€
with open(ROOT / "rss_sources.yml", "r", encoding="utf-8") as f:
    SOURCES = yaml.safe_load(f)["sources"]

DATE_FMT_MD = "%Y-%m-%d"


def slugify(text: str) -> str:
    text = text.lower()
    text = re.sub(r"[^\w\s-]", "", text)         # è‹±æ•°å­—ãƒ»ç©ºç™½ãƒ»ãƒã‚¤ãƒ•ãƒ³ä»¥å¤–ã‚’é™¤å»
    text = re.sub(r"[\s_]+", "-", text)          # ç©ºç™½ã¨ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’ãƒã‚¤ãƒ•ãƒ³åŒ–
    return text.strip("-")


def extract_thumbnail(url):
    """OGPç”»åƒãƒ»Twitterã‚«ãƒ¼ãƒ‰ãƒ»imgã‚¿ã‚°ã‹ã‚‰ç”»åƒURLæŠ½å‡ºï¼ˆçµ¶å¯¾ãƒ‘ã‚¹å¯¾å¿œ + ãƒ­ã‚°å‡ºåŠ›ï¼‰"""
    try:
        res = requests.get(url, timeout=10, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(res.text, "html.parser")

        # OGPç”»åƒ
        og = soup.find("meta", property="og:image")
        if og and og.get("content"):
            print(f"[OGP] {url} â†’ {og['content']}")
            return og["content"]

        # Twitterã‚«ãƒ¼ãƒ‰
        tw = soup.find("meta", attrs={"name": "twitter:image"})
        if tw and tw.get("content"):
            print(f"[Twitter] {url} â†’ {tw['content']}")
            return tw["content"]

        # æœ€åˆã® img ã‚¿ã‚° â†’ çµ¶å¯¾URLåŒ–
        img = soup.find("img")
        if img and img.get("src"):
            abs_url = urljoin(url, img["src"])
            print(f"[img tag] {url} â†’ {abs_url}")
            return abs_url

    except Exception as e:
        print(f"[thumbnail error] {url} â†’ {e}")
    print(f"[No image found] {url}")
    return ""


def write_post(title, description, date, source, url, thumbnail):
    try:
        slug = slugify(title or hashlib.md5(url.encode()).hexdigest())
        dt = parser.parse(date)
        date_str = dt.strftime(DATE_FMT_MD)
        filename = f"{date_str}-{slug}.md"
        filepath = CONTENT_DIR / filename

        content = f"""---
title: {title or 'Untitled'}
description: "{(description or '').strip().replace('"', "'")}"
pubDate: {date}
source: {source}
url: {url}
thumbnail: "{thumbnail or ''}"
---

"""
        filepath.write_text(content, encoding="utf-8")
        print(f"âœ… saved: {filename}")
    except Exception as e:
        print(f"âŒ Failed to write post '{title}': {e}")
        raise


def main():
    try:
        for source in SOURCES:
            url = source["url"]
            media = source["name"]
            feed = feedparser.parse(url)
            print(f"ğŸ“° {media} - {url}")

            for entry in feed.entries:
                title = entry.get("title", "")
                summary = entry.get("summary", "")
                link = entry.get("link", "")
                pub = entry.get("published", "")

                if not title or not pub or not link:
                    continue

                thumb = extract_thumbnail(link)
                write_post(title, summary, pub, media, link, thumb)
    except Exception as e:
        print(f"\nâŒ Unhandled Error: {e}")
        sys.exit(1)

    sys.exit(0)


if __name__ == "__main__":
    main()
