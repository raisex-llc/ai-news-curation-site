#!/usr/bin/env python3
"""
feed_fetcher.py
RSS â†’ Markdown å¤‰æ› + ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒæŠ½å‡º
astro-site/src/content/posts/ ã« .md ã‚’è¿½åŠ ã™ã‚‹ã€‚
"""

import feedparser
import requests
import trafilatura
import yaml
import hashlib
import os
import sys
from datetime import datetime
from pathlib import Path
from bs4 import BeautifulSoup
from urllib.parse import urljoin

ROOT = Path(__file__).resolve().parent
CONTENT_DIR = ROOT / "astro-site" / "src" / "content" / "posts"
CONTENT_DIR.mkdir(parents=True, exist_ok=True)

# âœ… RSS URLä¸€è¦§ã‚’èª­ã¿è¾¼ã‚€
with open(ROOT / "rss_sources.yml", "r", encoding="utf-8") as f:
    SOURCES = yaml.safe_load(f)["sources"]

DATE_FMT_MD = "%Y-%m-%d"


def slugify(text: str) -> str:
    return (
        text.lower()
        .replace(" ", "-")
        .replace("/", "-")
        .replace(":", "-")
        .replace("?", "")
        .replace("&", "")
        .replace("=", "")
    )


def extract_thumbnail(url):
    """OGPç”»åƒãƒ»Twitterã‚«ãƒ¼ãƒ‰ãƒ»imgã‚¿ã‚°ã‹ã‚‰ç”»åƒURLæŠ½å‡ºï¼ˆçµ¶å¯¾ãƒ‘ã‚¹å¯¾å¿œ + ãƒ­ã‚°å‡ºåŠ›ï¼‰"""
    try:
        res = requests.get(url, timeout=10, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(res.text, "html.parser")

        # OGPç”»åƒ
        og = soup.find("meta", property="og:image")
        if og and og.get("content"):
            print(f"[OGP] {url} â†’ {og['content']}")
            return og["content"]

        # Twitterã‚«ãƒ¼ãƒ‰
        tw = soup.find("meta", attrs={"name": "twitter:image"})
        if tw and tw.get("content"):
            print(f"[Twitter] {url} â†’ {tw['content']}")
            return tw["content"]

        # æœ€åˆã® img ã‚¿ã‚° â†’ çµ¶å¯¾URLåŒ–
        img = soup.find("img")
        if img and img.get("src"):
            abs_url = urljoin(url, img["src"])
            print(f"[img tag] {url} â†’ {abs_url}")
            return abs_url

    except Exception as e:
        print(f"[thumbnail error] {url} â†’ {e}")
    print(f"[No image found] {url}")
    return ""


def write_post(title, description, date, source, url, thumbnail):
    try:
        slug = slugify(title or hashlib.md5(url.encode()).hexdigest())
        # âœ… ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆï¼š+0000 å½¢å¼ã«å¯¾å¿œï¼ˆ%Z â†’ %zï¼‰
        dt = datetime.strptime(date, "%a, %d %b %Y %H:%M:%S %z")
        date_str = dt.strftime(DATE_FMT_MD)
        filename = f"{date_str}-{slug}.md"
        filepath = CONTENT_DIR / filename

        content = f"""---
title: {title or 'Untitled'}
description: "{description.strip().replace('"', "'") if description else ''}"
pubDate: {date}
source: {source}
url: {url}
thumbnail: {thumbnail}
---

"""
        filepath.write_text(content, encoding="utf-8")
        print(f"âœ… saved: {filename}")
    except Exception as e:
        print(f"âŒ Failed to write post '{title}': {e}")
        raise


def main():
    try:
        for source in SOURCES:
            url = source["url"]
            media = source["name"]
            feed = feedparser.parse(url)
            print(f"ğŸ“° {media} - {url}")

            for entry in feed.entries:
                title = entry.get("title", "")
                summary = entry.get("summary", "")
                link = entry.get("link", "")
                pub = entry.get("published", "")

                if not title or not pub or not link:
                    continue

                thumb = extract_thumbnail(link)
                write_post(title, summary, pub, media, link, thumb)
    except Exception as e:
        print(f"\nâŒ Unhandled Error: {e}")
        sys.exit(1)

    sys.exit(0)


if __name__ == "__main__":
    main()
